INFO - Siam-FC - Running command 'main'
INFO - Siam-FC - Started run with ID "241"
INFO - root - preproces -- siamese_fc_color
WARNING - root - root is not explicitly specified, using default value: None
INFO - root - For training, we use instance size 255 - 2 * 8 ...
WARNING - root - init_method is not explicitly specified, using default value: None
INFO - root - Model moving average is disabled since decay factor is 0
111111111 Tensor("siamese_fc/conv5/concat:0", shape=(8, 6, 6, 256), dtype=float32) Tensor("siamese_fc/conv4/concat:0", shape=(8, 8, 8, 384), dtype=float32)
Tensor("siamese_fc/conv5/def/transpose:0", shape=(8, 384, 8, 8), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/db1/weights:0' shape=(256, 384, 3, 3) dtype=float32_ref> Tensor("siamese_fc/conv5/def/transpose_1:0", shape=(8, 18, 6, 6), dtype=float32)
111111111 Tensor("siamese_fc_1/conv5/concat:0", shape=(8, 20, 20, 256), dtype=float32) Tensor("siamese_fc_1/conv4/concat:0", shape=(8, 22, 22, 384), dtype=float32)
Tensor("siamese_fc_1/conv5/def/transpose:0", shape=(8, 384, 22, 22), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/db1/weights:0' shape=(256, 384, 3, 3) dtype=float32_ref> Tensor("siamese_fc_1/conv5/def/transpose_1:0", shape=(8, 18, 20, 20), dtype=float32)
Tensor("detection/add:0", shape=(8, 15, 15), dtype=float32)
2017-12-12 07:57:58.562367: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-12 07:57:58.562405: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-12 07:57:58.562411: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-12 07:57:58.562415: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-12 07:57:58.562419: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-12 07:57:58.899148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 5791:00:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2017-12-12 07:57:58.899186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-12-12 07:57:58.899193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-12-12 07:57:58.899201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 5791:00:00.0)
INFO:tensorflow:Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-2-SGD-lr0.1-decay7000-nosplit-clip50-shortcut1/model.ckpt-40000
INFO - tensorflow - Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-2-SGD-lr0.1-decay7000-nosplit-clip50-shortcut1/model.ckpt-40000
INFO - root - Starting threads 0 ...

INFO - root - training for 332500 steps
INFO - root - 2017-12-12 07:58:01.877167: step 0, loss = 0.65, batch loss = 0.59 (3.6 examples/sec; 2.251 sec/batch; 207h:54m:58s remains)
2017-12-12 07:58:02.320519: I tensorflow/core/kernels/logging_ops.cc:79] [[[-3.0799801 -2.8867216 -2.8137007 -2.9804847 -3.2899904 -3.511982 -3.4517639 -3.0015352 -2.2854257 -1.7358181 -1.7318192 -2.2397809 -2.8905435 -3.3466158 -3.5681634][-3.0096512 -2.7529225 -2.6734278 -2.8965259 -3.2249334 -3.3662975 -3.1457915 -2.4414859 -1.4403946 -0.7734139 -0.8930378 -1.629261 -2.4663172 -3.011306 -3.2780724][-2.809813 -2.5228682 -2.4844005 -2.776381 -3.0465903 -2.9549823 -2.4049404 -1.3092642 -0.0032680035 0.63266206 0.20141673 -0.87974072 -1.9657623 -2.6268296 -2.9387705][-2.4860954 -2.1952446 -2.2118876 -2.5399485 -2.6612267 -2.1859121 -1.1366966 0.47105002 2.0578535 2.4962242 1.5847371 0.051124811 -1.3695309 -2.2080002 -2.605032][-2.103292 -1.8286376 -1.8871682 -2.1972632 -2.1138663 -1.1873462 0.44829774 2.6082137 4.3772221 4.4290781 2.9133937 0.885031 -0.86648965 -1.8719845 -2.3621306][-1.7799106 -1.5598416 -1.6523666 -1.8862689 -1.544024 -0.14644074 2.0660994 4.6598616 6.3469667 5.771059 3.58094 1.1415269 -0.76680255 -1.7856381 -2.2865982][-1.68098 -1.5363441 -1.6355424 -1.7338889 -1.1060824 0.66012931 3.1651962 5.7490377 6.9459295 5.6710682 3.0458486 0.55601907 -1.151691 -1.9519004 -2.3530428][-1.799825 -1.6948006 -1.7363729 -1.675369 -0.84699225 1.0143592 3.3428571 5.3641558 5.781188 4.0424366 1.4801099 -0.6013763 -1.8108177 -2.266068 -2.5139394][-1.9839463 -1.8180118 -1.712081 -1.5134976 -0.66394997 0.98411155 2.791199 3.9934151 3.6907675 1.8668416 -0.24372602 -1.6903353 -2.3674884 -2.5499506 -2.6975274][-2.1910152 -1.9173834 -1.6410584 -1.3453319 -0.62699151 0.61262012 1.802501 2.2724259 1.5539625 -0.029585123 -1.532922 -2.3701594 -2.664047 -2.7341037 -2.870018][-2.4280963 -2.1361485 -1.8132031 -1.5092547 -0.98150086 -0.16834497 0.4880898 0.47749639 -0.29653788 -1.413271 -2.3084252 -2.6886349 -2.78125 -2.8512642 -3.0226414][-2.7153211 -2.511224 -2.2780964 -2.0359154 -1.6811497 -1.2229867 -0.97237825 -1.2053025 -1.7522011 -2.2785373 -2.6270623 -2.7180285 -2.7588263 -2.8977909 -3.1248083][-2.8794188 -2.7867339 -2.7031331 -2.5872145 -2.4321399 -2.2972679 -2.3293257 -2.5741363 -2.7355981 -2.6560159 -2.5548158 -2.5099435 -2.6254687 -2.8818703 -3.1657412][-2.8770742 -2.8266258 -2.8643689 -2.9065828 -2.9739091 -3.0848675 -3.2004128 -3.2517061 -2.9756498 -2.4095192 -2.0550036 -2.0699773 -2.3939428 -2.8116503 -3.1416903][-2.6696754 -2.6335025 -2.7712014 -2.9675703 -3.2086115 -3.3995798 -3.3646173 -3.079216 -2.4283481 -1.6141846 -1.2760892 -1.546792 -2.1486819 -2.7054343 -3.0438323]]...]
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFCtest/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFCtest/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-12 07:58:04.840274: step 10, loss = 0.41, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 20h:24m:50s remains)
INFO - root - 2017-12-12 07:58:07.034089: step 20, loss = 0.52, batch loss = 0.46 (36.9 examples/sec; 0.217 sec/batch; 20h:02m:25s remains)
(239, 239, 3)
/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFCtest
(239, 239, 3)
(239, 239, 3)
INFO - root - 2017-12-12 07:58:09.202071: step 30, loss = 0.48, batch loss = 0.43 (36.9 examples/sec; 0.217 sec/batch; 20h:02m:35s remains)
INFO - root - 2017-12-12 07:58:11.363036: step 40, loss = 0.44, batch loss = 0.38 (38.0 examples/sec; 0.210 sec/batch; 19h:25m:26s remains)
INFO - root - 2017-12-12 07:58:13.548879: step 50, loss = 0.39, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 20h:28m:31s remains)
INFO - root - 2017-12-12 07:58:15.716323: step 60, loss = 0.64, batch loss = 0.58 (37.0 examples/sec; 0.216 sec/batch; 19h:57m:39s remains)
INFO - root - 2017-12-12 07:58:17.871087: step 70, loss = 0.28, batch loss = 0.22 (36.8 examples/sec; 0.218 sec/batch; 20h:05m:19s remains)
(239, 239, 3)
(239, 239, 3)
(239, 239, 3)
(239, 239, 3)
(239, 239, 3)
INFO - root - 2017-12-12 07:58:20.060825: step 80, loss = 0.31, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 20h:01m:31s remains)
INFO - root - 2017-12-12 07:58:22.249618: step 90, loss = 0.36, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 20h:02m:00s remains)
INFO - root - 2017-12-12 07:58:24.421040: step 100, loss = 0.46, batch loss = 0.41 (37.0 examples/sec; 0.216 sec/batch; 19h:58m:32s remains)
2017-12-12 07:58:24.723413: I tensorflow/core/kernels/logging_ops.cc:79] [[[-4.2838268 -4.0834675 -3.3240423 -1.9670296 -0.72228813 -0.24720073 -0.44278765 -1.2601523 -2.4425802 -3.678272 -4.457633 -4.3857327 -3.7449355 -2.7543721 -1.8580242][-4.1797938 -3.8041127 -2.8814812 -1.4210172 -0.063924789 0.554018 0.50100136 -0.19734216 -1.3397808 -2.5961061 -3.43606 -3.47785 -2.9906695 -2.2478089 -1.6845145][-4.1520014 -3.7637281 -2.8616588 -1.4324296 -0.012772083 0.775898 0.897974 0.34005642 -0.72686267 -1.9502406 -2.8044956 -2.952908 -2.6242521 -2.085659 -1.701685][-4.08595 -3.7765155 -3.0030918 -1.6986089 -0.29878545 0.58863926 0.81623983 0.36453152 -0.59715438 -1.727092 -2.5453305 -2.7668433 -2.5668211 -2.1672902 -1.8224829][-3.9453647 -3.6926439 -3.0107098 -1.8000112 -0.42602754 0.53585005 0.85897541 0.53735876 -0.28573489 -1.3395367 -2.175431 -2.499311 -2.4146953 -2.1017814 -1.7312336][-3.8020744 -3.5345616 -2.814254 -1.5617135 -0.12654066 0.96074533 1.4300671 1.2896957 0.61313534 -0.44506955 -1.4228754 -1.9426885 -2.0191793 -1.7778201 -1.3558862][-3.7588208 -3.4842303 -2.709029 -1.3987632 0.090632915 1.2900119 1.9204197 1.9861927 1.466095 0.38690567 -0.751524 -1.4817607 -1.7377982 -1.5516348 -1.061749][-3.8082371 -3.5725119 -2.8061788 -1.5092866 -0.048881531 1.1670036 1.871407 2.0405574 1.6019092 0.52208471 -0.64813876 -1.4225817 -1.7373097 -1.5451727 -1.005517][-3.8371363 -3.6461251 -2.9324837 -1.7007904 -0.32516527 0.82845449 1.4973817 1.5955386 1.0783219 -0.019125938 -1.0866177 -1.7070885 -1.9103416 -1.6351891 -1.0756454][-3.7356081 -3.537672 -2.8743155 -1.7439604 -0.50457358 0.53705406 1.1276536 1.0736623 0.37633228 -0.76845765 -1.688123 -2.060782 -2.0610964 -1.6867645 -1.1632397][-3.5527487 -3.3114529 -2.7016282 -1.7191153 -0.682436 0.19138145 0.69798279 0.54069662 -0.26450491 -1.3823755 -2.1314516 -2.2707272 -2.0920753 -1.6712515 -1.2473283][-3.3956611 -3.1270223 -2.5974779 -1.8086464 -1.038497 -0.41503549 -0.053917408 -0.26424098 -1.0235107 -1.9609081 -2.494802 -2.4641013 -2.19439 -1.8005927 -1.5169384][-3.274936 -2.9815164 -2.498539 -1.8605947 -1.3371859 -1.0104234 -0.90936136 -1.2374611 -1.906175 -2.5778894 -2.8549693 -2.6880832 -2.3777041 -2.0404508 -1.8933219][-3.1943624 -2.9015141 -2.4405627 -1.8909804 -1.5249403 -1.4226868 -1.5729835 -2.0352159 -2.6336551 -3.0820534 -3.1572797 -2.9070997 -2.5764623 -2.282577 -2.2210689][-3.1529787 -2.921875 -2.5355949 -2.08605 -1.8097675 -1.7972504 -2.0434918 -2.516223 -3.0114722 -3.3094387 -3.2967968 -3.0503578 -2.7478693 -2.5009456 -2.46134]]...]
INFO - root - 2017-12-12 07:58:26.882354: step 110, loss = 0.47, batch loss = 0.41 (37.1 examples/sec; 0.216 sec/batch; 19h:54m:22s remains)
(239, 239, 3)
(239, 239, 3)
(239, 239, 3)
(239, 239, 3)
INFO - root - 2017-12-12 07:58:29.053366: step 120, loss = 0.69, batch loss = 0.63 (37.3 examples/sec; 0.215 sec/batch; 19h:49m:18s remains)
INFO - root - 2017-12-12 07:58:31.227285: step 130, loss = 0.38, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 20h:14m:10s remains)
INFO - root - 2017-12-12 07:58:33.397020: step 140, loss = 0.39, batch loss = 0.33 (37.3 examples/sec; 0.214 sec/batch; 19h:46m:29s remains)
INFO - root - 2017-12-12 07:58:35.574873: step 150, loss = 0.68, batch loss = 0.62 (36.2 examples/sec; 0.221 sec/batch; 20h:24m:49s remains)
INFO - root - 2017-12-12 07:58:37.767889: step 160, loss = 0.40, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 20h:04m:01s remains)
(239, 239, 3)
(239, 239, 3)
(239, 239, 3)
(239, 239, 3)
(239, 239, 3)
INFO - root - 2017-12-12 07:58:39.958787: step 170, loss = 0.38, batch loss = 0.32 (38.0 examples/sec; 0.211 sec/batch; 19h:26m:26s remains)
INFO - root - 2017-12-12 07:58:42.135969: step 180, loss = 0.43, batch loss = 0.37 (36.9 examples/sec; 0.217 sec/batch; 20h:02m:23s remains)
INFO - root - 2017-12-12 07:58:44.340171: step 190, loss = 0.43, batch loss = 0.37 (37.1 examples/sec; 0.215 sec/batch; 19h:53m:13s remains)
INFO - root - 2017-12-12 07:58:46.526736: step 200, loss = 0.30, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 20h:07m:41s remains)
2017-12-12 07:58:46.817933: I tensorflow/core/kernels/logging_ops.cc:79] [[[-4.9602027 -4.974421 -4.8541408 -4.7288694 -4.7055683 -4.6572905 -4.6060805 -4.7006931 -4.9248886 -4.85528 -4.4624548 -4.2496257 -4.3671093 -4.5788035 -4.7500224][-5.2517977 -5.2886925 -5.1445441 -5.0310912 -5.0679173 -5.0019588 -4.8772511 -4.9473476 -5.1649561 -4.9959412 -4.3670096 -4.002902 -4.1375694 -4.44326 -4.7105832][-4.9574962 -4.9354944 -4.6958122 -4.49858 -4.4902973 -4.3960452 -4.3479648 -4.6442146 -5.0519161 -4.8749185 -4.0039458 -3.3568583 -3.3275688 -3.5758364 -3.8695025][-4.4214182 -4.3340697 -4.0146618 -3.6404357 -3.3934798 -3.1214993 -3.1263113 -3.7677941 -4.5670934 -4.5720263 -3.5730281 -2.6048036 -2.2875783 -2.3879509 -2.73982][-3.5848196 -3.4969146 -3.2212758 -2.6846533 -2.025573 -1.2515168 -0.95832086 -1.8034109 -3.1383507 -3.619832 -2.7961137 -1.7116389 -1.2211783 -1.2823117 -1.7800673][-2.0232871 -1.905768 -1.7344661 -1.1378868 -0.0870657 1.2909946 2.0461459 1.0980959 -0.83518219 -1.9877427 -1.6438208 -0.74536967 -0.2845788 -0.3784337 -0.91419625][-0.56472206 -0.37398911 -0.31721663 0.28742862 1.6718326 3.5645437 4.717299 3.7490664 1.3792982 -0.38328481 -0.6702311 -0.18737864 0.10536408 -0.035645723 -0.51897764][-0.47609806 -0.35763383 -0.51548004 -0.03441453 1.449851 3.574224 4.9591403 4.1832051 1.851778 -0.11184621 -0.84564209 -0.78929925 -0.69836783 -0.88247323 -1.3104069][-1.5554245 -1.5256455 -1.8903108 -1.6765025 -0.47287798 1.3857818 2.6569185 2.1403303 0.259974 -1.423285 -2.1871266 -2.3082952 -2.2739348 -2.3995898 -2.73386][-2.9416366 -2.7860656 -3.08412 -3.0107687 -2.1749392 -0.82578349 0.13093543 -0.15214944 -1.4207146 -2.5698509 -3.0645249 -3.1119807 -3.009645 -3.0871465 -3.4504347][-4.29837 -3.9700403 -4.0264707 -3.9001169 -3.3034377 -2.4033508 -1.7157367 -1.7391444 -2.3824158 -2.9798329 -3.1533661 -3.0425434 -2.8657219 -3.0157115 -3.6052136][-5.4333291 -5.0126338 -4.8430948 -4.6658897 -4.3162813 -3.8396306 -3.4031274 -3.2409482 -3.4490857 -3.6900282 -3.6544013 -3.3914156 -3.095041 -3.2279081 -3.8979039][-6.0304747 -5.5634241 -5.2003884 -4.9787869 -4.8568048 -4.7711568 -4.61033 -4.4311595 -4.4484358 -4.5212765 -4.3775525 -4.0021129 -3.5662942 -3.5613704 -4.0739546][-5.9119296 -5.4447241 -4.9474778 -4.6436896 -4.5852313 -4.6969566 -4.7212172 -4.6208463 -4.5997143 -4.5910287 -4.3875132 -3.9587753 -3.463707 -3.345401 -3.6904106][-4.9194546 -4.5582523 -4.1230292 -3.8419745 -3.7867537 -3.910912 -3.9753935 -3.9166095 -3.8574414 -3.7762766 -3.571949 -3.2156224 -2.8381166 -2.7887614 -3.1462631]]...]
