INFO - Siam-FC - Running command 'main'
INFO - Siam-FC - Started run with ID "41"
INFO - root - Creating training directory: /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC
INFO - root - preproces -- siamese_fc_color
WARNING - root - root is not explicitly specified, using default value: None
INFO - root - For training, we use instance size 255 - 2 * 8 ...
WARNING - root - init_method is not explicitly specified, using default value: None
sdiufhasudf Tensor("siamese_fc/conv5/split:0", shape=(8, 8, 8, 192), dtype=float32)
sdfah Tensor("siamese_fc/conv5/def/offset2/BiasAdd:0", shape=(8, 8, 8, 72), dtype=float32)
Tensor("siamese_fc/conv5/def/transpose:0", shape=(8, 192, 8, 8), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(128, 192, 3, 3) dtype=float32_ref> Tensor("siamese_fc/conv5/def/transpose_1:0", shape=(8, 72, 8, 8), dtype=float32)
ddd Tensor("siamese_fc/conv5/def/b1/transpose:0", shape=(8, 6, 6, 128), dtype=float32)
sdiufhasudf Tensor("siamese_fc_1/conv5/split:0", shape=(8, 22, 22, 192), dtype=float32)
sdfah Tensor("siamese_fc_1/conv5/def/offset2/BiasAdd:0", shape=(8, 22, 22, 72), dtype=float32)
Tensor("siamese_fc_1/conv5/def/transpose:0", shape=(8, 192, 22, 22), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(128, 192, 3, 3) dtype=float32_ref> Tensor("siamese_fc_1/conv5/def/transpose_1:0", shape=(8, 72, 22, 22), dtype=float32)
ddd Tensor("siamese_fc_1/conv5/def/b1/transpose:0", shape=(8, 20, 20, 128), dtype=float32)
INFO - root - Model moving average is disabled since decay factor is 0
2017-12-03 06:55:56.424679: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-03 06:55:56.424713: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-03 06:55:56.424719: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-03 06:55:56.424724: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-03 06:55:56.424728: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-03 06:55:57.000905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 5791:00:00.0
Total memory: 11.17GiB
Free memory: 11.11GiB
2017-12-03 06:55:57.000943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-12-03 06:55:57.000951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-12-03 06:55:57.000959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 5791:00:00.0)
INFO:tensorflow:Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO - tensorflow - Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO - root - Starting threads 0 ...

INFO - root - training for 332500 steps
INFO - root - 2017-12-03 06:55:59.957409: step 0, loss = 1.13, batch loss = 1.04 (3.6 examples/sec; 2.240 sec/batch; 206h:52m:29s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-03 06:56:02.438675: step 10, loss = 1.10, batch loss = 1.00 (44.9 examples/sec; 0.178 sec/batch; 16h:27m:11s remains)
INFO - root - 2017-12-03 06:56:04.271745: step 20, loss = 1.18, batch loss = 1.09 (43.1 examples/sec; 0.186 sec/batch; 17h:07m:56s remains)
INFO - root - 2017-12-03 06:56:06.105113: step 30, loss = 1.08, batch loss = 0.98 (44.2 examples/sec; 0.181 sec/batch; 16h:42m:39s remains)
INFO - root - 2017-12-03 06:56:07.925264: step 40, loss = 1.09, batch loss = 0.99 (43.2 examples/sec; 0.185 sec/batch; 17h:06m:07s remains)
INFO - root - 2017-12-03 06:56:09.752300: step 50, loss = 1.04, batch loss = 0.94 (45.7 examples/sec; 0.175 sec/batch; 16h:10m:48s remains)
INFO - root - 2017-12-03 06:56:11.597879: step 60, loss = 1.08, batch loss = 0.99 (42.0 examples/sec; 0.191 sec/batch; 17h:35m:43s remains)
INFO - root - 2017-12-03 06:56:13.420633: step 70, loss = 1.07, batch loss = 0.97 (43.7 examples/sec; 0.183 sec/batch; 16h:53m:24s remains)
INFO - root - 2017-12-03 06:56:15.273271: step 80, loss = 1.18, batch loss = 1.08 (43.9 examples/sec; 0.182 sec/batch; 16h:49m:18s remains)
INFO - root - 2017-12-03 06:56:17.108562: step 90, loss = 1.20, batch loss = 1.10 (44.2 examples/sec; 0.181 sec/batch; 16h:43m:07s remains)
INFO - root - 2017-12-03 06:56:18.941200: step 100, loss = 1.13, batch loss = 1.03 (43.7 examples/sec; 0.183 sec/batch; 16h:53m:29s remains)
INFO - root - 2017-12-03 06:56:20.856408: step 110, loss = 1.12, batch loss = 1.02 (44.3 examples/sec; 0.181 sec/batch; 16h:41m:26s remains)
INFO - root - 2017-12-03 06:56:22.689028: step 120, loss = 1.22, batch loss = 1.13 (43.3 examples/sec; 0.185 sec/batch; 17h:03m:50s remains)
INFO - root - 2017-12-03 06:56:24.529425: step 130, loss = 1.11, batch loss = 1.01 (43.5 examples/sec; 0.184 sec/batch; 16h:59m:14s remains)
INFO - root - 2017-12-03 06:56:26.332287: step 140, loss = 1.09, batch loss = 1.00 (43.8 examples/sec; 0.183 sec/batch; 16h:52m:01s remains)
INFO - root - 2017-12-03 06:56:28.165403: step 150, loss = 1.11, batch loss = 1.01 (43.1 examples/sec; 0.186 sec/batch; 17h:08m:31s remains)
INFO - root - 2017-12-03 06:56:30.001043: step 160, loss = 1.23, batch loss = 1.13 (44.8 examples/sec; 0.178 sec/batch; 16h:28m:12s remains)
INFO - root - 2017-12-03 06:56:31.829445: step 170, loss = 1.04, batch loss = 0.94 (45.2 examples/sec; 0.177 sec/batch; 16h:19m:18s remains)
INFO - root - 2017-12-03 06:56:33.672696: step 180, loss = 1.09, batch loss = 0.99 (43.1 examples/sec; 0.186 sec/batch; 17h:09m:05s remains)
INFO - root - 2017-12-03 06:56:35.503656: step 190, loss = 0.99, batch loss = 0.89 (44.1 examples/sec; 0.181 sec/batch; 16h:44m:54s remains)
INFO - root - 2017-12-03 06:56:37.340505: step 200, loss = 1.05, batch loss = 0.96 (44.5 examples/sec; 0.180 sec/batch; 16h:36m:13s remains)
INFO - root - 2017-12-03 06:56:39.241180: step 210, loss = 1.11, batch loss = 1.01 (44.0 examples/sec; 0.182 sec/batch; 16h:47m:36s remains)
INFO - root - 2017-12-03 06:56:41.064599: step 220, loss = 1.14, batch loss = 1.05 (45.0 examples/sec; 0.178 sec/batch; 16h:25m:06s remains)
INFO - root - 2017-12-03 06:56:42.904085: step 230, loss = 1.07, batch loss = 0.98 (42.1 examples/sec; 0.190 sec/batch; 17h:32m:56s remains)
INFO - root - 2017-12-03 06:56:44.741116: step 240, loss = 1.30, batch loss = 1.21 (42.8 examples/sec; 0.187 sec/batch; 17h:16m:11s remains)
INFO - root - 2017-12-03 06:56:46.546225: step 250, loss = 1.10, batch loss = 1.00 (43.0 examples/sec; 0.186 sec/batch; 17h:09m:42s remains)
INFO - root - 2017-12-03 06:56:48.381555: step 260, loss = 1.30, batch loss = 1.20 (43.9 examples/sec; 0.182 sec/batch; 16h:49m:46s remains)
INFO - root - 2017-12-03 06:56:50.208165: step 270, loss = 1.21, batch loss = 1.12 (44.1 examples/sec; 0.181 sec/batch; 16h:44m:31s remains)
INFO - root - 2017-12-03 06:56:52.033456: step 280, loss = 1.07, batch loss = 0.97 (42.8 examples/sec; 0.187 sec/batch; 17h:14m:45s remains)
INFO - root - 2017-12-03 06:56:53.862559: step 290, loss = 1.05, batch loss = 0.95 (43.5 examples/sec; 0.184 sec/batch; 16h:57m:44s remains)
INFO - root - 2017-12-03 06:56:55.716896: step 300, loss = 1.09, batch loss = 1.00 (42.9 examples/sec; 0.187 sec/batch; 17h:13m:19s remains)
INFO - root - 2017-12-03 06:56:57.606852: step 310, loss = 1.09, batch loss = 0.99 (43.5 examples/sec; 0.184 sec/batch; 16h:58m:21s remains)
INFO - root - 2017-12-03 06:56:59.438177: step 320, loss = 1.19, batch loss = 1.10 (43.4 examples/sec; 0.185 sec/batch; 17h:01m:30s remains)
INFO - root - 2017-12-03 06:57:01.295946: step 330, loss = 1.14, batch loss = 1.04 (43.3 examples/sec; 0.185 sec/batch; 17h:02m:53s remains)
INFO - root - 2017-12-03 06:57:03.149596: step 340, loss = 1.13, batch loss = 1.03 (42.3 examples/sec; 0.189 sec/batch; 17h:25m:48s remains)
INFO - root - 2017-12-03 06:57:05.001584: step 350, loss = 1.19, batch loss = 1.10 (43.3 examples/sec; 0.185 sec/batch; 17h:01m:45s remains)
INFO - root - 2017-12-03 06:57:06.856517: step 360, loss = 1.12, batch loss = 1.02 (45.5 examples/sec; 0.176 sec/batch; 16h:13m:44s remains)
INFO - root - 2017-12-03 06:57:08.708065: step 370, loss = 1.26, batch loss = 1.16 (40.6 examples/sec; 0.197 sec/batch; 18h:11m:10s remains)
INFO - root - 2017-12-03 06:57:10.562394: step 380, loss = 1.25, batch loss = 1.16 (41.6 examples/sec; 0.192 sec/batch; 17h:44m:27s remains)
INFO - root - 2017-12-03 06:57:12.403757: step 390, loss = 1.06, batch loss = 0.96 (43.2 examples/sec; 0.185 sec/batch; 17h:04m:22s remains)
INFO - root - 2017-12-03 06:57:14.238838: step 400, loss = 1.05, batch loss = 0.95 (43.0 examples/sec; 0.186 sec/batch; 17h:09m:27s remains)
INFO - root - 2017-12-03 06:57:16.159116: step 410, loss = 1.10, batch loss = 1.00 (43.9 examples/sec; 0.182 sec/batch; 16h:48m:32s remains)
INFO - root - 2017-12-03 06:57:18.002220: step 420, loss = 1.26, batch loss = 1.16 (40.9 examples/sec; 0.196 sec/batch; 18h:03m:17s remains)
INFO - root - 2017-12-03 06:57:19.841138: step 430, loss = 1.07, batch loss = 0.97 (44.8 examples/sec; 0.179 sec/batch; 16h:27m:59s remains)
INFO - root - 2017-12-03 06:57:21.677270: step 440, loss = 1.14, batch loss = 1.04 (43.9 examples/sec; 0.182 sec/batch; 16h:47m:27s remains)
INFO - root - 2017-12-03 06:57:23.528928: step 450, loss = 1.14, batch loss = 1.05 (43.3 examples/sec; 0.185 sec/batch; 17h:02m:19s remains)
INFO - root - 2017-12-03 06:57:25.384715: step 460, loss = 1.00, batch loss = 0.90 (43.8 examples/sec; 0.183 sec/batch; 16h:50m:14s remains)
INFO - root - 2017-12-03 06:57:27.243476: step 470, loss = 1.02, batch loss = 0.92 (40.5 examples/sec; 0.197 sec/batch; 18h:11m:46s remains)
INFO - root - 2017-12-03 06:57:29.093771: step 480, loss = 1.22, batch loss = 1.13 (41.8 examples/sec; 0.191 sec/batch; 17h:38m:01s remains)
INFO - root - 2017-12-03 06:57:30.921564: step 490, loss = 1.11, batch loss = 1.01 (44.4 examples/sec; 0.180 sec/batch; 16h:36m:02s remains)
INFO - root - 2017-12-03 06:57:32.763629: step 500, loss = 1.09, batch loss = 0.99 (42.4 examples/sec; 0.189 sec/batch; 17h:23m:20s remains)
INFO - root - 2017-12-03 06:57:34.676070: step 510, loss = 1.04, batch loss = 0.95 (41.8 examples/sec; 0.192 sec/batch; 17h:39m:56s remains)
INFO - root - 2017-12-03 06:57:36.509524: step 520, loss = 1.32, batch loss = 1.22 (42.8 examples/sec; 0.187 sec/batch; 17h:14m:14s remains)
INFO - root - 2017-12-03 06:57:38.354661: step 530, loss = 1.02, batch loss = 0.92 (43.0 examples/sec; 0.186 sec/batch; 17h:09m:14s remains)
INFO - root - 2017-12-03 06:57:40.193143: step 540, loss = 1.04, batch loss = 0.95 (44.3 examples/sec; 0.181 sec/batch; 16h:39m:23s remains)
INFO - root - 2017-12-03 06:57:42.025939: step 550, loss = 0.96, batch loss = 0.86 (44.9 examples/sec; 0.178 sec/batch; 16h:25m:18s remains)
INFO - root - 2017-12-03 06:57:43.869541: step 560, loss = 1.08, batch loss = 0.98 (43.4 examples/sec; 0.184 sec/batch; 17h:00m:16s remains)
INFO - root - 2017-12-03 06:57:45.691641: step 570, loss = 1.10, batch loss = 1.00 (43.9 examples/sec; 0.182 sec/batch; 16h:49m:10s remains)
INFO - root - 2017-12-03 06:57:47.511016: step 580, loss = 1.07, batch loss = 0.97 (44.1 examples/sec; 0.182 sec/batch; 16h:44m:03s remains)
INFO - root - 2017-12-03 06:57:49.344530: step 590, loss = 0.96, batch loss = 0.86 (43.0 examples/sec; 0.186 sec/batch; 17h:09m:47s remains)
INFO - root - 2017-12-03 06:57:51.175235: step 600, loss = 1.22, batch loss = 1.12 (44.3 examples/sec; 0.180 sec/batch; 16h:37m:58s remains)
INFO - root - 2017-12-03 06:57:53.082414: step 610, loss = 1.20, batch loss = 1.10 (45.7 examples/sec; 0.175 sec/batch; 16h:08m:33s remains)
INFO - root - 2017-12-03 06:57:54.925059: step 620, loss = 1.06, batch loss = 0.96 (44.2 examples/sec; 0.181 sec/batch; 16h:40m:36s remains)
INFO - root - 2017-12-03 06:57:56.751615: step 630, loss = 1.12, batch loss = 1.02 (42.6 examples/sec; 0.188 sec/batch; 17h:18m:42s remains)
INFO - root - 2017-12-03 06:57:58.585182: step 640, loss = 0.99, batch loss = 0.89 (43.8 examples/sec; 0.183 sec/batch; 16h:49m:56s remains)
INFO - root - 2017-12-03 06:58:00.438140: step 650, loss = 1.15, batch loss = 1.06 (44.7 examples/sec; 0.179 sec/batch; 16h:30m:54s remains)
INFO - root - 2017-12-03 06:58:02.286319: step 660, loss = 0.97, batch loss = 0.88 (44.7 examples/sec; 0.179 sec/batch; 16h:30m:21s remains)
INFO - root - 2017-12-03 06:58:04.127864: step 670, loss = 0.97, batch loss = 0.88 (45.0 examples/sec; 0.178 sec/batch; 16h:22m:52s remains)
INFO - root - 2017-12-03 06:58:05.990864: step 680, loss = 1.13, batch loss = 1.03 (43.0 examples/sec; 0.186 sec/batch; 17h:07m:55s remains)
INFO - root - 2017-12-03 06:58:07.830307: step 690, loss = 0.85, batch loss = 0.75 (42.9 examples/sec; 0.187 sec/batch; 17h:11m:25s remains)
INFO - root - 2017-12-03 06:58:09.677715: step 700, loss = 1.11, batch loss = 1.02 (43.4 examples/sec; 0.184 sec/batch; 16h:58m:51s remains)
INFO - root - 2017-12-03 06:58:11.590637: step 710, loss = 1.12, batch loss = 1.03 (44.6 examples/sec; 0.179 sec/batch; 16h:31m:03s remains)
INFO - root - 2017-12-03 06:58:13.401846: step 720, loss = 1.03, batch loss = 0.93 (43.0 examples/sec; 0.186 sec/batch; 17h:09m:43s remains)
INFO - root - 2017-12-03 06:58:15.253684: step 730, loss = 1.10, batch loss = 1.00 (44.0 examples/sec; 0.182 sec/batch; 16h:46m:09s remains)
INFO - root - 2017-12-03 06:58:17.088136: step 740, loss = 1.02, batch loss = 0.92 (44.1 examples/sec; 0.181 sec/batch; 16h:42m:26s remains)
INFO - root - 2017-12-03 06:58:18.922068: step 750, loss = 1.00, batch loss = 0.91 (44.2 examples/sec; 0.181 sec/batch; 16h:40m:51s remains)
INFO - root - 2017-12-03 06:58:20.777331: step 760, loss = 1.06, batch loss = 0.97 (42.4 examples/sec; 0.189 sec/batch; 17h:23m:36s remains)
INFO - root - 2017-12-03 06:58:22.639323: step 770, loss = 1.18, batch loss = 1.08 (41.8 examples/sec; 0.191 sec/batch; 17h:37m:54s remains)
INFO - root - 2017-12-03 06:58:24.468875: step 780, loss = 1.11, batch loss = 1.02 (43.5 examples/sec; 0.184 sec/batch; 16h:57m:01s remains)
INFO - root - 2017-12-03 06:58:26.315010: step 790, loss = 1.14, batch loss = 1.05 (44.2 examples/sec; 0.181 sec/batch; 16h:40m:46s remains)
INFO - root - 2017-12-03 06:58:28.151477: step 800, loss = 1.05, batch loss = 0.96 (43.8 examples/sec; 0.183 sec/batch; 16h:49m:35s remains)
INFO - root - 2017-12-03 06:58:30.046372: step 810, loss = 1.04, batch loss = 0.94 (44.2 examples/sec; 0.181 sec/batch; 16h:40m:32s remains)
INFO - root - 2017-12-03 06:58:31.878206: step 820, loss = 0.97, batch loss = 0.87 (42.7 examples/sec; 0.188 sec/batch; 17h:16m:33s remains)
INFO - root - 2017-12-03 06:58:33.709572: step 830, loss = 1.07, batch loss = 0.97 (43.6 examples/sec; 0.183 sec/batch; 16h:53m:56s remains)
INFO - root - 2017-12-03 06:58:35.548418: step 840, loss = 1.17, batch loss = 1.08 (44.1 examples/sec; 0.181 sec/batch; 16h:42m:54s remains)
INFO - root - 2017-12-03 06:58:37.372019: step 850, loss = 0.97, batch loss = 0.87 (43.7 examples/sec; 0.183 sec/batch; 16h:51m:44s remains)
INFO - root - 2017-12-03 06:58:39.214258: step 860, loss = 1.09, batch loss = 0.99 (42.6 examples/sec; 0.188 sec/batch; 17h:17m:56s remains)
INFO - root - 2017-12-03 06:58:41.087113: step 870, loss = 1.16, batch loss = 1.07 (43.1 examples/sec; 0.186 sec/batch; 17h:06m:34s remains)
INFO - root - 2017-12-03 06:58:42.920078: step 880, loss = 1.12, batch loss = 1.02 (42.2 examples/sec; 0.189 sec/batch; 17h:27m:18s remains)
INFO - root - 2017-12-03 06:58:44.768500: step 890, loss = 0.88, batch loss = 0.78 (44.1 examples/sec; 0.182 sec/batch; 16h:43m:34s remains)
INFO - root - 2017-12-03 06:58:46.607787: step 900, loss = 1.07, batch loss = 0.98 (42.6 examples/sec; 0.188 sec/batch; 17h:18m:08s remains)
INFO - root - 2017-12-03 06:58:48.541813: step 910, loss = 1.16, batch loss = 1.06 (43.4 examples/sec; 0.184 sec/batch; 16h:59m:33s remains)
INFO - root - 2017-12-03 06:58:50.369818: step 920, loss = 1.18, batch loss = 1.08 (42.6 examples/sec; 0.188 sec/batch; 17h:17m:09s remains)
INFO - root - 2017-12-03 06:58:52.204725: step 930, loss = 1.20, batch loss = 1.10 (45.0 examples/sec; 0.178 sec/batch; 16h:22m:59s remains)
INFO - root - 2017-12-03 06:58:54.046891: step 940, loss = 1.12, batch loss = 1.03 (41.1 examples/sec; 0.194 sec/batch; 17h:54m:19s remains)
INFO - root - 2017-12-03 06:58:55.893245: step 950, loss = 1.13, batch loss = 1.03 (43.1 examples/sec; 0.186 sec/batch; 17h:06m:16s remains)
INFO - root - 2017-12-03 06:58:57.742251: step 960, loss = 1.18, batch loss = 1.08 (43.7 examples/sec; 0.183 sec/batch; 16h:51m:08s remains)
INFO - root - 2017-12-03 06:58:59.574108: step 970, loss = 1.00, batch loss = 0.90 (44.4 examples/sec; 0.180 sec/batch; 16h:36m:25s remains)
INFO - root - 2017-12-03 06:59:01.424412: step 980, loss = 1.01, batch loss = 0.91 (44.7 examples/sec; 0.179 sec/batch; 16h:29m:23s remains)
INFO - root - 2017-12-03 06:59:03.280857: step 990, loss = 1.06, batch loss = 0.96 (44.1 examples/sec; 0.181 sec/batch; 16h:42m:04s remains)
INFO - root - 2017-12-03 06:59:05.120813: step 1000, loss = 1.02, batch loss = 0.92 (44.4 examples/sec; 0.180 sec/batch; 16h:34m:29s remains)
INFO - root - 2017-12-03 06:59:07.025885: step 1010, loss = 1.03, batch loss = 0.93 (43.6 examples/sec; 0.184 sec/batch; 16h:53m:48s remains)
INFO - root - 2017-12-03 06:59:08.862053: step 1020, loss = 0.99, batch loss = 0.89 (44.3 examples/sec; 0.181 sec/batch; 16h:38m:10s remains)
INFO - root - 2017-12-03 06:59:10.704351: step 1030, loss = 1.00, batch loss = 0.90 (42.3 examples/sec; 0.189 sec/batch; 17h:25m:04s remains)
INFO - root - 2017-12-03 06:59:12.527134: step 1040, loss = 1.20, batch loss = 1.10 (44.1 examples/sec; 0.181 sec/batch; 16h:41m:20s remains)
INFO - root - 2017-12-03 06:59:14.365928: step 1050, loss = 1.05, batch loss = 0.95 (43.9 examples/sec; 0.182 sec/batch; 16h:47m:08s remains)
INFO - root - 2017-12-03 06:59:16.221182: step 1060, loss = 1.06, batch loss = 0.96 (42.4 examples/sec; 0.189 sec/batch; 17h:22m:38s remains)
INFO - root - 2017-12-03 06:59:18.043362: step 1070, loss = 1.01, batch loss = 0.91 (44.2 examples/sec; 0.181 sec/batch; 16h:39m:24s remains)
INFO - root - 2017-12-03 06:59:19.895821: step 1080, loss = 1.05, batch loss = 0.95 (43.8 examples/sec; 0.183 sec/batch; 16h:49m:41s remains)
INFO - root - 2017-12-03 06:59:21.763547: step 1090, loss = 0.91, batch loss = 0.82 (41.9 examples/sec; 0.191 sec/batch; 17h:33m:48s remains)
INFO - root - 2017-12-03 06:59:23.617040: step 1100, loss = 1.03, batch loss = 0.93 (42.2 examples/sec; 0.190 sec/batch; 17h:27m:52s remains)
INFO - root - 2017-12-03 06:59:25.556747: step 1110, loss = 1.00, batch loss = 0.90 (43.4 examples/sec; 0.184 sec/batch; 16h:58m:47s remains)
INFO - root - 2017-12-03 06:59:27.411694: step 1120, loss = 0.95, batch loss = 0.85 (42.5 examples/sec; 0.188 sec/batch; 17h:19m:00s remains)
INFO - root - 2017-12-03 06:59:29.250193: step 1130, loss = 1.04, batch loss = 0.94 (43.8 examples/sec; 0.183 sec/batch; 16h:49m:06s remains)
INFO - root - 2017-12-03 06:59:31.079416: step 1140, loss = 1.08, batch loss = 0.98 (44.1 examples/sec; 0.181 sec/batch; 16h:40m:43s remains)
INFO - root - 2017-12-03 06:59:32.912127: step 1150, loss = 0.94, batch loss = 0.85 (42.8 examples/sec; 0.187 sec/batch; 17h:11m:28s remains)
INFO - root - 2017-12-03 06:59:34.762300: step 1160, loss = 1.10, batch loss = 1.00 (43.4 examples/sec; 0.184 sec/batch; 16h:56m:46s remains)
INFO - root - 2017-12-03 06:59:36.621171: step 1170, loss = 1.01, batch loss = 0.91 (44.0 examples/sec; 0.182 sec/batch; 16h:43m:43s remains)
INFO - root - 2017-12-03 06:59:38.470975: step 1180, loss = 1.20, batch loss = 1.10 (42.5 examples/sec; 0.188 sec/batch; 17h:18m:18s remains)
INFO - root - 2017-12-03 06:59:40.328249: step 1190, loss = 1.06, batch loss = 0.96 (44.1 examples/sec; 0.181 sec/batch; 16h:41m:44s remains)
INFO - root - 2017-12-03 06:59:42.163599: step 1200, loss = 1.10, batch loss = 1.01 (45.2 examples/sec; 0.177 sec/batch; 16h:17m:25s remains)
INFO - root - 2017-12-03 06:59:44.049015: step 1210, loss = 1.06, batch loss = 0.96 (44.5 examples/sec; 0.180 sec/batch; 16h:33m:20s remains)
INFO - root - 2017-12-03 06:59:45.903087: step 1220, loss = 1.00, batch loss = 0.90 (44.3 examples/sec; 0.181 sec/batch; 16h:37m:09s remains)
INFO - root - 2017-12-03 06:59:47.745227: step 1230, loss = 1.07, batch loss = 0.97 (43.0 examples/sec; 0.186 sec/batch; 17h:07m:56s remains)
INFO - root - 2017-12-03 06:59:49.579391: step 1240, loss = 1.10, batch loss = 1.01 (43.7 examples/sec; 0.183 sec/batch; 16h:49m:58s remains)
INFO - root - 2017-12-03 06:59:51.437409: step 1250, loss = 1.10, batch loss = 1.00 (43.8 examples/sec; 0.183 sec/batch; 16h:48m:52s remains)
INFO - root - 2017-12-03 06:59:53.286751: step 1260, loss = 1.00, batch loss = 0.91 (43.1 examples/sec; 0.186 sec/batch; 17h:04m:45s remains)
INFO - root - 2017-12-03 06:59:55.116313: step 1270, loss = 0.86, batch loss = 0.76 (45.1 examples/sec; 0.177 sec/batch; 16h:19m:10s remains)
INFO - root - 2017-12-03 06:59:56.966010: step 1280, loss = 1.00, batch loss = 0.90 (45.2 examples/sec; 0.177 sec/batch; 16h:16m:21s remains)
INFO - root - 2017-12-03 06:59:58.823700: step 1290, loss = 1.06, batch loss = 0.97 (44.3 examples/sec; 0.180 sec/batch; 16h:36m:11s remains)
INFO - root - 2017-12-03 07:00:00.667639: step 1300, loss = 1.14, batch loss = 1.05 (43.0 examples/sec; 0.186 sec/batch; 17h:07m:57s remains)
INFO - root - 2017-12-03 07:00:02.596657: step 1310, loss = 1.00, batch loss = 0.90 (44.8 examples/sec; 0.178 sec/batch; 16h:24m:47s remains)
INFO - root - 2017-12-03 07:00:04.463371: step 1320, loss = 1.08, batch loss = 0.98 (44.4 examples/sec; 0.180 sec/batch; 16h:34m:45s remains)
INFO - root - 2017-12-03 07:00:06.300257: step 1330, loss = 1.08, batch loss = 0.99 (45.0 examples/sec; 0.178 sec/batch; 16h:21m:21s remains)
INFO - root - 2017-12-03 07:00:08.133970: step 1340, loss = 0.99, batch loss = 0.90 (42.3 examples/sec; 0.189 sec/batch; 17h:23m:54s remains)
INFO - root - 2017-12-03 07:00:09.988094: step 1350, loss = 1.04, batch loss = 0.94 (42.7 examples/sec; 0.187 sec/batch; 17h:14m:03s remains)
INFO - root - 2017-12-03 07:00:11.836064: step 1360, loss = 1.05, batch loss = 0.96 (43.6 examples/sec; 0.184 sec/batch; 16h:52m:45s remains)
INFO - root - 2017-12-03 07:00:13.671957: step 1370, loss = 1.04, batch loss = 0.94 (42.6 examples/sec; 0.188 sec/batch; 17h:16m:11s remains)
INFO - root - 2017-12-03 07:00:15.497564: step 1380, loss = 1.01, batch loss = 0.91 (44.6 examples/sec; 0.179 sec/batch; 16h:30m:32s remains)
INFO - root - 2017-12-03 07:00:17.351768: step 1390, loss = 0.96, batch loss = 0.87 (44.7 examples/sec; 0.179 sec/batch; 16h:27m:12s remains)
INFO - root - 2017-12-03 07:00:19.194738: step 1400, loss = 1.03, batch loss = 0.93 (42.5 examples/sec; 0.188 sec/batch; 17h:19m:53s remains)
INFO - root - 2017-12-03 07:00:21.181736: step 1410, loss = 1.07, batch loss = 0.98 (43.6 examples/sec; 0.184 sec/batch; 16h:53m:16s remains)
INFO - root - 2017-12-03 07:00:23.047897: step 1420, loss = 1.13, batch loss = 1.03 (43.7 examples/sec; 0.183 sec/batch; 16h:49m:59s remains)
INFO - root - 2017-12-03 07:00:24.907823: step 1430, loss = 1.07, batch loss = 0.97 (41.9 examples/sec; 0.191 sec/batch; 17h:33m:13s remains)
INFO - root - 2017-12-03 07:00:26.726719: step 1440, loss = 1.14, batch loss = 1.04 (42.8 examples/sec; 0.187 sec/batch; 17h:12m:08s remains)
INFO - root - 2017-12-03 07:00:28.561639: step 1450, loss = 0.99, batch loss = 0.90 (44.5 examples/sec; 0.180 sec/batch; 16h:32m:00s remains)
INFO - root - 2017-12-03 07:00:30.397680: step 1460, loss = 0.93, batch loss = 0.84 (43.4 examples/sec; 0.184 sec/batch; 16h:56m:29s remains)
INFO - root - 2017-12-03 07:00:32.222308: step 1470, loss = 1.06, batch loss = 0.97 (44.3 examples/sec; 0.181 sec/batch; 16h:36m:47s remains)
INFO - root - 2017-12-03 07:00:34.059360: step 1480, loss = 1.11, batch loss = 1.01 (43.6 examples/sec; 0.183 sec/batch; 16h:51m:58s remains)
INFO - root - 2017-12-03 07:00:35.910942: step 1490, loss = 0.99, batch loss = 0.90 (44.3 examples/sec; 0.180 sec/batch; 16h:35m:21s remains)
INFO - root - 2017-12-03 07:00:37.782929: step 1500, loss = 0.99, batch loss = 0.89 (43.4 examples/sec; 0.184 sec/batch; 16h:56m:36s remains)
INFO - root - 2017-12-03 07:00:39.701359: step 1510, loss = 0.96, batch loss = 0.86 (43.7 examples/sec; 0.183 sec/batch; 16h:49m:39s remains)
INFO - root - 2017-12-03 07:00:41.553799: step 1520, loss = 1.00, batch loss = 0.90 (44.6 examples/sec; 0.179 sec/batch; 16h:28m:37s remains)
INFO - root - 2017-12-03 07:00:43.409949: step 1530, loss = 1.10, batch loss = 1.00 (43.0 examples/sec; 0.186 sec/batch; 17h:05m:16s remains)
INFO - root - 2017-12-03 07:00:45.241207: step 1540, loss = 0.98, batch loss = 0.88 (42.7 examples/sec; 0.188 sec/batch; 17h:14m:37s remains)
INFO - root - 2017-12-03 07:00:47.076258: step 1550, loss = 1.04, batch loss = 0.94 (44.9 examples/sec; 0.178 sec/batch; 16h:23m:33s remains)
INFO - root - 2017-12-03 07:00:48.933000: step 1560, loss = 1.14, batch loss = 1.05 (42.1 examples/sec; 0.190 sec/batch; 17h:28m:57s remains)
INFO - root - 2017-12-03 07:00:50.756530: step 1570, loss = 1.04, batch loss = 0.94 (43.2 examples/sec; 0.185 sec/batch; 17h:02m:05s remains)
INFO - root - 2017-12-03 07:00:52.595765: step 1580, loss = 0.96, batch loss = 0.86 (43.5 examples/sec; 0.184 sec/batch; 16h:53m:38s remains)
INFO - root - 2017-12-03 07:00:54.437532: step 1590, loss = 1.06, batch loss = 0.96 (43.1 examples/sec; 0.186 sec/batch; 17h:04m:48s remains)
INFO - root - 2017-12-03 07:00:56.270542: step 1600, loss = 0.93, batch loss = 0.83 (44.2 examples/sec; 0.181 sec/batch; 16h:37m:23s remains)
INFO - root - 2017-12-03 07:00:58.169920: step 1610, loss = 0.97, batch loss = 0.87 (44.0 examples/sec; 0.182 sec/batch; 16h:42m:59s remains)
INFO - root - 2017-12-03 07:01:00.046411: step 1620, loss = 0.97, batch loss = 0.87 (43.7 examples/sec; 0.183 sec/batch; 16h:49m:47s remains)
INFO - root - 2017-12-03 07:01:01.898210: step 1630, loss = 1.08, batch loss = 0.98 (44.0 examples/sec; 0.182 sec/batch; 16h:42m:26s remains)
INFO - root - 2017-12-03 07:01:03.737188: step 1640, loss = 1.00, batch loss = 0.91 (44.2 examples/sec; 0.181 sec/batch; 16h:38m:38s remains)
INFO - root - 2017-12-03 07:01:05.570204: step 1650, loss = 1.06, batch loss = 0.96 (43.5 examples/sec; 0.184 sec/batch; 16h:53m:38s remains)
INFO - root - 2017-12-03 07:01:07.394297: step 1660, loss = 0.97, batch loss = 0.87 (44.6 examples/sec; 0.179 sec/batch; 16h:29m:04s remains)
INFO - root - 2017-12-03 07:01:09.257989: step 1670, loss = 1.06, batch loss = 0.96 (42.3 examples/sec; 0.189 sec/batch; 17h:23m:39s remains)
INFO - root - 2017-12-03 07:01:11.146892: step 1680, loss = 0.96, batch loss = 0.87 (43.7 examples/sec; 0.183 sec/batch; 16h:48m:55s remains)
INFO - root - 2017-12-03 07:01:12.980904: step 1690, loss = 1.11, batch loss = 1.01 (43.1 examples/sec; 0.186 sec/batch; 17h:03m:33s remains)
INFO - root - 2017-12-03 07:01:14.810313: step 1700, loss = 1.01, batch loss = 0.91 (43.3 examples/sec; 0.185 sec/batch; 16h:59m:03s remains)
INFO - root - 2017-12-03 07:01:16.733105: step 1710, loss = 1.01, batch loss = 0.92 (42.4 examples/sec; 0.189 sec/batch; 17h:19m:37s remains)
INFO - root - 2017-12-03 07:01:18.583639: step 1720, loss = 0.96, batch loss = 0.86 (44.3 examples/sec; 0.181 sec/batch; 16h:36m:36s remains)
INFO - root - 2017-12-03 07:01:20.463762: step 1730, loss = 0.92, batch loss = 0.82 (41.7 examples/sec; 0.192 sec/batch; 17h:37m:24s remains)
INFO - root - 2017-12-03 07:01:22.291921: step 1740, loss = 0.97, batch loss = 0.87 (43.8 examples/sec; 0.183 sec/batch; 16h:47m:37s remains)
INFO - root - 2017-12-03 07:01:24.138371: step 1750, loss = 1.11, batch loss = 1.01 (44.1 examples/sec; 0.182 sec/batch; 16h:40m:52s remains)
INFO - root - 2017-12-03 07:01:25.984382: step 1760, loss = 1.08, batch loss = 0.99 (44.6 examples/sec; 0.179 sec/batch; 16h:28m:30s remains)
INFO - root - 2017-12-03 07:01:27.828523: step 1770, loss = 1.05, batch loss = 0.95 (41.1 examples/sec; 0.195 sec/batch; 17h:52m:11s remains)
INFO - root - 2017-12-03 07:01:29.671411: step 1780, loss = 1.07, batch loss = 0.97 (44.1 examples/sec; 0.182 sec/batch; 16h:40m:49s remains)
INFO - root - 2017-12-03 07:01:31.522151: step 1790, loss = 0.99, batch loss = 0.90 (44.3 examples/sec; 0.180 sec/batch; 16h:34m:24s remains)
INFO - root - 2017-12-03 07:01:33.354344: step 1800, loss = 1.16, batch loss = 1.06 (44.2 examples/sec; 0.181 sec/batch; 16h:37m:35s remains)
INFO - root - 2017-12-03 07:01:35.246448: step 1810, loss = 1.00, batch loss = 0.91 (43.7 examples/sec; 0.183 sec/batch; 16h:48m:53s remains)
INFO - root - 2017-12-03 07:01:37.102558: step 1820, loss = 1.05, batch loss = 0.95 (43.9 examples/sec; 0.182 sec/batch; 16h:43m:14s remains)
INFO - root - 2017-12-03 07:01:38.957799: step 1830, loss = 1.04, batch loss = 0.95 (42.5 examples/sec; 0.188 sec/batch; 17h:17m:33s remains)
INFO - root - 2017-12-03 07:01:40.794291: step 1840, loss = 0.98, batch loss = 0.88 (44.3 examples/sec; 0.181 sec/batch; 16h:36m:15s remains)
INFO - root - 2017-12-03 07:01:42.639215: step 1850, loss = 1.02, batch loss = 0.92 (44.6 examples/sec; 0.179 sec/batch; 16h:28m:24s remains)
INFO - root - 2017-12-03 07:01:44.478047: step 1860, loss = 1.09, batch loss = 0.99 (43.0 examples/sec; 0.186 sec/batch; 17h:05m:39s remains)
INFO - root - 2017-12-03 07:01:46.307592: step 1870, loss = 0.93, batch loss = 0.83 (43.7 examples/sec; 0.183 sec/batch; 16h:49m:54s remains)
INFO - root - 2017-12-03 07:01:48.142991: step 1880, loss = 0.99, batch loss = 0.90 (44.2 examples/sec; 0.181 sec/batch; 16h:37m:50s remains)
INFO - root - 2017-12-03 07:01:50.000159: step 1890, loss = 1.25, batch loss = 1.15 (43.9 examples/sec; 0.182 sec/batch; 16h:44m:45s remains)
INFO - root - 2017-12-03 07:01:51.852579: step 1900, loss = 0.87, batch loss = 0.77 (42.7 examples/sec; 0.187 sec/batch; 17h:13m:05s remains)
INFO - root - 2017-12-03 07:01:53.768565: step 1910, loss = 1.04, batch loss = 0.94 (43.9 examples/sec; 0.182 sec/batch; 16h:43m:40s remains)
INFO - root - 2017-12-03 07:01:55.622094: step 1920, loss = 1.00, batch loss = 0.90 (42.1 examples/sec; 0.190 sec/batch; 17h:27m:12s remains)
INFO - root - 2017-12-03 07:01:57.463158: step 1930, loss = 0.91, batch loss = 0.81 (43.3 examples/sec; 0.185 sec/batch; 16h:58m:44s remains)
INFO - root - 2017-12-03 07:01:59.320375: step 1940, loss = 1.04, batch loss = 0.95 (44.0 examples/sec; 0.182 sec/batch; 16h:41m:02s remains)
INFO - root - 2017-12-03 07:02:01.159882: step 1950, loss = 1.14, batch loss = 1.05 (43.2 examples/sec; 0.185 sec/batch; 17h:00m:56s remains)
INFO - root - 2017-12-03 07:02:02.993816: step 1960, loss = 1.05, batch loss = 0.96 (42.9 examples/sec; 0.187 sec/batch; 17h:07m:26s remains)
INFO - root - 2017-12-03 07:02:04.820829: step 1970, loss = 1.04, batch loss = 0.94 (43.8 examples/sec; 0.183 sec/batch; 16h:45m:32s remains)
INFO - root - 2017-12-03 07:02:06.652883: step 1980, loss = 1.03, batch loss = 0.93 (43.6 examples/sec; 0.184 sec/batch; 16h:50m:51s remains)
INFO - root - 2017-12-03 07:02:08.504376: step 1990, loss = 1.05, batch loss = 0.95 (43.0 examples/sec; 0.186 sec/batch; 17h:05m:31s remains)
INFO - root - 2017-12-03 07:02:10.360957: step 2000, loss = 0.91, batch loss = 0.82 (41.2 examples/sec; 0.194 sec/batch; 17h:50m:44s remains)
INFO - root - 2017-12-03 07:02:12.275503: step 2010, loss = 0.96, batch loss = 0.87 (44.0 examples/sec; 0.182 sec/batch; 16h:41m:00s remains)
INFO - root - 2017-12-03 07:02:14.137415: step 2020, loss = 1.09, batch loss = 1.00 (42.4 examples/sec; 0.189 sec/batch; 17h:18m:48s remains)
INFO - root - 2017-12-03 07:02:15.985051: step 2030, loss = 1.02, batch loss = 0.92 (42.9 examples/sec; 0.187 sec/batch; 17h:07m:52s remains)
INFO - root - 2017-12-03 07:02:17.845115: step 2040, loss = 1.05, batch loss = 0.95 (44.2 examples/sec; 0.181 sec/batch; 16h:36m:11s remains)
INFO - root - 2017-12-03 07:02:19.680589: step 2050, loss = 0.93, batch loss = 0.84 (43.0 examples/sec; 0.186 sec/batch; 17h:03m:37s remains)
INFO - root - 2017-12-03 07:02:21.522264: step 2060, loss = 1.00, batch loss = 0.90 (42.2 examples/sec; 0.190 sec/batch; 17h:24m:02s remains)
INFO - root - 2017-12-03 07:02:23.379553: step 2070, loss = 1.05, batch loss = 0.96 (43.1 examples/sec; 0.186 sec/batch; 17h:01m:39s remains)
INFO - root - 2017-12-03 07:02:25.234910: step 2080, loss = 1.07, batch loss = 0.97 (44.1 examples/sec; 0.181 sec/batch; 16h:38m:29s remains)
INFO - root - 2017-12-03 07:02:27.066297: step 2090, loss = 1.06, batch loss = 0.96 (43.7 examples/sec; 0.183 sec/batch; 16h:48m:23s remains)
INFO - root - 2017-12-03 07:02:28.921981: step 2100, loss = 1.11, batch loss = 1.01 (43.1 examples/sec; 0.186 sec/batch; 17h:02m:54s remains)
INFO - root - 2017-12-03 07:02:30.834403: step 2110, loss = 0.93, batch loss = 0.83 (44.8 examples/sec; 0.179 sec/batch; 16h:24m:02s remains)
INFO - root - 2017-12-03 07:02:32.671314: step 2120, loss = 0.98, batch loss = 0.88 (42.1 examples/sec; 0.190 sec/batch; 17h:25m:41s remains)
INFO - root - 2017-12-03 07:02:34.496965: step 2130, loss = 1.07, batch loss = 0.97 (44.6 examples/sec; 0.179 sec/batch; 16h:27m:27s remains)
INFO - root - 2017-12-03 07:02:36.350691: step 2140, loss = 1.22, batch loss = 1.12 (44.6 examples/sec; 0.179 sec/batch; 16h:27m:34s remains)
INFO - root - 2017-12-03 07:02:38.208196: step 2150, loss = 1.16, batch loss = 1.06 (39.7 examples/sec; 0.202 sec/batch; 18h:29m:32s remains)
INFO - root - 2017-12-03 07:02:40.048222: step 2160, loss = 1.01, batch loss = 0.92 (43.4 examples/sec; 0.184 sec/batch; 16h:54m:05s remains)
INFO - root - 2017-12-03 07:02:41.929868: step 2170, loss = 1.06, batch loss = 0.96 (40.9 examples/sec; 0.196 sec/batch; 17h:58m:08s remains)
INFO - root - 2017-12-03 07:02:43.772546: step 2180, loss = 0.99, batch loss = 0.90 (43.4 examples/sec; 0.184 sec/batch; 16h:54m:28s remains)
INFO - root - 2017-12-03 07:02:45.619782: step 2190, loss = 0.97, batch loss = 0.88 (44.7 examples/sec; 0.179 sec/batch; 16h:24m:47s remains)
INFO - root - 2017-12-03 07:02:47.462736: step 2200, loss = 1.07, batch loss = 0.97 (44.0 examples/sec; 0.182 sec/batch; 16h:40m:45s remains)
INFO - root - 2017-12-03 07:02:49.356269: step 2210, loss = 0.85, batch loss = 0.75 (44.6 examples/sec; 0.179 sec/batch; 16h:27m:00s remains)
INFO - root - 2017-12-03 07:02:51.190330: step 2220, loss = 0.95, batch loss = 0.85 (44.1 examples/sec; 0.181 sec/batch; 16h:39m:04s remains)
INFO - root - 2017-12-03 07:02:53.043784: step 2230, loss = 1.02, batch loss = 0.92 (42.8 examples/sec; 0.187 sec/batch; 17h:09m:15s remains)
INFO - root - 2017-12-03 07:02:54.879842: step 2240, loss = 1.15, batch loss = 1.05 (44.5 examples/sec; 0.180 sec/batch; 16h:29m:38s remains)
INFO - root - 2017-12-03 07:02:56.716628: step 2250, loss = 0.97, batch loss = 0.88 (43.1 examples/sec; 0.186 sec/batch; 17h:02m:16s remains)
INFO - root - 2017-12-03 07:02:58.568351: step 2260, loss = 0.88, batch loss = 0.78 (42.7 examples/sec; 0.188 sec/batch; 17h:12m:04s remains)
INFO - root - 2017-12-03 07:03:00.396172: step 2270, loss = 1.11, batch loss = 1.01 (43.4 examples/sec; 0.184 sec/batch; 16h:55m:24s remains)
INFO - root - 2017-12-03 07:03:02.230134: step 2280, loss = 1.13, batch loss = 1.04 (44.2 examples/sec; 0.181 sec/batch; 16h:35m:25s remains)
INFO - root - 2017-12-03 07:03:04.067683: step 2290, loss = 1.02, batch loss = 0.93 (43.5 examples/sec; 0.184 sec/batch; 16h:52m:48s remains)
INFO - root - 2017-12-03 07:03:05.914530: step 2300, loss = 1.10, batch loss = 1.00 (43.9 examples/sec; 0.182 sec/batch; 16h:43m:38s remains)
INFO - root - 2017-12-03 07:03:07.861122: step 2310, loss = 1.14, batch loss = 1.04 (43.1 examples/sec; 0.186 sec/batch; 17h:01m:16s remains)
INFO - root - 2017-12-03 07:03:09.712177: step 2320, loss = 0.96, batch loss = 0.86 (44.3 examples/sec; 0.180 sec/batch; 16h:32m:51s remains)
INFO - root - 2017-12-03 07:03:11.564322: step 2330, loss = 1.07, batch loss = 0.97 (44.4 examples/sec; 0.180 sec/batch; 16h:31m:23s remains)
INFO - root - 2017-12-03 07:03:13.422017: step 2340, loss = 1.05, batch loss = 0.95 (43.0 examples/sec; 0.186 sec/batch; 17h:04m:26s remains)
INFO - root - 2017-12-03 07:03:15.265574: step 2350, loss = 0.90, batch loss = 0.80 (44.4 examples/sec; 0.180 sec/batch; 16h:32m:25s remains)
INFO - root - 2017-12-03 07:03:17.105853: step 2360, loss = 1.16, batch loss = 1.07 (43.3 examples/sec; 0.185 sec/batch; 16h:56m:29s remains)
INFO - root - 2017-12-03 07:03:18.933643: step 2370, loss = 1.08, batch loss = 0.98 (43.8 examples/sec; 0.183 sec/batch; 16h:44m:17s remains)
INFO - root - 2017-12-03 07:03:20.763847: step 2380, loss = 1.01, batch loss = 0.92 (44.3 examples/sec; 0.181 sec/batch; 16h:34m:24s remains)
INFO - root - 2017-12-03 07:03:22.595948: step 2390, loss = 1.07, batch loss = 0.97 (42.2 examples/sec; 0.190 sec/batch; 17h:23m:10s remains)
INFO - root - 2017-12-03 07:03:24.451403: step 2400, loss = 0.94, batch loss = 0.84 (42.7 examples/sec; 0.187 sec/batch; 17h:10m:07s remains)
INFO - root - 2017-12-03 07:03:26.368407: step 2410, loss = 0.99, batch loss = 0.89 (43.4 examples/sec; 0.184 sec/batch; 16h:53m:37s remains)
INFO - root - 2017-12-03 07:03:28.203358: step 2420, loss = 1.03, batch loss = 0.94 (43.8 examples/sec; 0.183 sec/batch; 16h:45m:16s remains)
INFO - root - 2017-12-03 07:03:30.037354: step 2430, loss = 1.07, batch loss = 0.98 (44.0 examples/sec; 0.182 sec/batch; 16h:39m:34s remains)
INFO - root - 2017-12-03 07:03:31.871609: step 2440, loss = 1.09, batch loss = 0.99 (42.5 examples/sec; 0.188 sec/batch; 17h:16m:27s remains)
INFO - root - 2017-12-03 07:03:33.720394: step 2450, loss = 0.97, batch loss = 0.87 (44.4 examples/sec; 0.180 sec/batch; 16h:30m:38s remains)
INFO - root - 2017-12-03 07:03:35.558685: step 2460, loss = 1.12, batch loss = 1.02 (43.9 examples/sec; 0.182 sec/batch; 16h:41m:20s remains)
INFO - root - 2017-12-03 07:03:37.407471: step 2470, loss = 1.12, batch loss = 1.02 (44.2 examples/sec; 0.181 sec/batch; 16h:36m:30s remains)
INFO - root - 2017-12-03 07:03:39.267540: step 2480, loss = 0.92, batch loss = 0.82 (42.5 examples/sec; 0.188 sec/batch; 17h:15m:01s remains)
INFO - root - 2017-12-03 07:03:41.113567: step 2490, loss = 0.92, batch loss = 0.82 (42.6 examples/sec; 0.188 sec/batch; 17h:12m:19s remains)
INFO - root - 2017-12-03 07:03:42.959749: step 2500, loss = 0.96, batch loss = 0.87 (43.3 examples/sec; 0.185 sec/batch; 16h:56m:20s remains)
INFO - root - 2017-12-03 07:03:44.884236: step 2510, loss = 1.09, batch loss = 0.99 (43.2 examples/sec; 0.185 sec/batch; 16h:57m:23s remains)
INFO - root - 2017-12-03 07:03:46.771183: step 2520, loss = 0.97, batch loss = 0.87 (43.8 examples/sec; 0.183 sec/batch; 16h:44m:31s remains)
INFO - root - 2017-12-03 07:03:48.611057: step 2530, loss = 1.01, batch loss = 0.91 (44.3 examples/sec; 0.181 sec/batch; 16h:33m:45s remains)
INFO - root - 2017-12-03 07:03:50.444688: step 2540, loss = 0.90, batch loss = 0.81 (45.0 examples/sec; 0.178 sec/batch; 16h:17m:35s remains)
INFO - root - 2017-12-03 07:03:52.282461: step 2550, loss = 1.04, batch loss = 0.94 (41.7 examples/sec; 0.192 sec/batch; 17h:34m:50s remains)
INFO - root - 2017-12-03 07:03:54.116004: step 2560, loss = 0.97, batch loss = 0.87 (43.3 examples/sec; 0.185 sec/batch; 16h:56m:11s remains)
INFO - root - 2017-12-03 07:03:55.970040: step 2570, loss = 0.97, batch loss = 0.88 (44.9 examples/sec; 0.178 sec/batch; 16h:20m:41s remains)
INFO - root - 2017-12-03 07:03:57.803314: step 2580, loss = 0.98, batch loss = 0.89 (42.7 examples/sec; 0.187 sec/batch; 17h:09m:38s remains)
INFO - root - 2017-12-03 07:03:59.660057: step 2590, loss = 1.10, batch loss = 1.00 (44.0 examples/sec; 0.182 sec/batch; 16h:39m:27s remains)
INFO - root - 2017-12-03 07:04:01.502565: step 2600, loss = 1.02, batch loss = 0.92 (44.3 examples/sec; 0.181 sec/batch; 16h:33m:14s remains)
INFO - root - 2017-12-03 07:04:03.407759: step 2610, loss = 0.97, batch loss = 0.87 (42.5 examples/sec; 0.188 sec/batch; 17h:15m:31s remains)
INFO - root - 2017-12-03 07:04:05.235918: step 2620, loss = 1.06, batch loss = 0.97 (44.4 examples/sec; 0.180 sec/batch; 16h:31m:26s remains)
INFO - root - 2017-12-03 07:04:07.079033: step 2630, loss = 0.97, batch loss = 0.88 (42.4 examples/sec; 0.189 sec/batch; 17h:16m:51s remains)
INFO - root - 2017-12-03 07:04:08.893049: step 2640, loss = 1.13, batch loss = 1.03 (44.4 examples/sec; 0.180 sec/batch; 16h:31m:39s remains)
INFO - root - 2017-12-03 07:04:10.764396: step 2650, loss = 1.04, batch loss = 0.94 (44.4 examples/sec; 0.180 sec/batch; 16h:29m:50s remains)
INFO - root - 2017-12-03 07:04:12.614625: step 2660, loss = 1.01, batch loss = 0.91 (43.7 examples/sec; 0.183 sec/batch; 16h:47m:27s remains)
INFO - root - 2017-12-03 07:04:14.475622: step 2670, loss = 1.16, batch loss = 1.06 (43.1 examples/sec; 0.186 sec/batch; 17h:01m:05s remains)
INFO - root - 2017-12-03 07:04:16.298451: step 2680, loss = 1.10, batch loss = 1.00 (42.8 examples/sec; 0.187 sec/batch; 17h:07m:06s remains)
INFO - root - 2017-12-03 07:04:18.148031: step 2690, loss = 1.07, batch loss = 0.97 (42.8 examples/sec; 0.187 sec/batch; 17h:08m:10s remains)
INFO - root - 2017-12-03 07:04:19.997723: step 2700, loss = 1.07, batch loss = 0.97 (43.4 examples/sec; 0.184 sec/batch; 16h:53m:11s remains)
INFO - root - 2017-12-03 07:04:21.915702: step 2710, loss = 0.91, batch loss = 0.81 (43.6 examples/sec; 0.183 sec/batch; 16h:48m:35s remains)
INFO - root - 2017-12-03 07:04:23.757268: step 2720, loss = 1.06, batch loss = 0.96 (44.5 examples/sec; 0.180 sec/batch; 16h:28m:42s remains)
INFO - root - 2017-12-03 07:04:25.612156: step 2730, loss = 1.18, batch loss = 1.08 (41.9 examples/sec; 0.191 sec/batch; 17h:29m:44s remains)
INFO - root - 2017-12-03 07:04:27.448977: step 2740, loss = 1.12, batch loss = 1.02 (42.8 examples/sec; 0.187 sec/batch; 17h:07m:43s remains)
INFO - root - 2017-12-03 07:04:29.308534: step 2750, loss = 1.07, batch loss = 0.97 (41.4 examples/sec; 0.193 sec/batch; 17h:42m:20s remains)
INFO - root - 2017-12-03 07:04:31.169464: step 2760, loss = 0.99, batch loss = 0.89 (43.8 examples/sec; 0.183 sec/batch; 16h:44m:19s remains)
INFO - root - 2017-12-03 07:04:33.009369: step 2770, loss = 1.05, batch loss = 0.96 (43.4 examples/sec; 0.184 sec/batch; 16h:53m:26s remains)
INFO - root - 2017-12-03 07:04:34.860836: step 2780, loss = 1.15, batch loss = 1.05 (43.0 examples/sec; 0.186 sec/batch; 17h:01m:23s remains)
INFO - root - 2017-12-03 07:04:36.688201: step 2790, loss = 1.07, batch loss = 0.97 (44.1 examples/sec; 0.181 sec/batch; 16h:36m:54s remains)
INFO - root - 2017-12-03 07:04:38.556016: step 2800, loss = 1.11, batch loss = 1.01 (44.0 examples/sec; 0.182 sec/batch; 16h:40m:12s remains)
INFO - root - 2017-12-03 07:04:40.467356: step 2810, loss = 1.02, batch loss = 0.92 (41.5 examples/sec; 0.193 sec/batch; 17h:39m:59s remains)
INFO - root - 2017-12-03 07:04:42.316991: step 2820, loss = 1.07, batch loss = 0.98 (42.2 examples/sec; 0.189 sec/batch; 17h:20m:46s remains)
INFO - root - 2017-12-03 07:04:44.185941: step 2830, loss = 0.99, batch loss = 0.89 (42.9 examples/sec; 0.186 sec/batch; 17h:04m:23s remains)
INFO - root - 2017-12-03 07:04:46.023510: step 2840, loss = 1.21, batch loss = 1.11 (45.2 examples/sec; 0.177 sec/batch; 16h:12m:35s remains)
INFO - root - 2017-12-03 07:04:47.862424: step 2850, loss = 1.12, batch loss = 1.02 (43.0 examples/sec; 0.186 sec/batch; 17h:02m:08s remains)
INFO - root - 2017-12-03 07:04:49.707384: step 2860, loss = 0.92, batch loss = 0.82 (42.7 examples/sec; 0.187 sec/batch; 17h:09m:49s remains)
INFO - root - 2017-12-03 07:04:51.536730: step 2870, loss = 1.11, batch loss = 1.01 (44.6 examples/sec; 0.179 sec/batch; 16h:24m:21s remains)
INFO - root - 2017-12-03 07:04:53.371619: step 2880, loss = 1.06, batch loss = 0.96 (43.9 examples/sec; 0.182 sec/batch; 16h:41m:00s remains)
INFO - root - 2017-12-03 07:04:55.231497: step 2890, loss = 1.12, batch loss = 1.02 (42.8 examples/sec; 0.187 sec/batch; 17h:07m:19s remains)
INFO - root - 2017-12-03 07:04:57.057912: step 2900, loss = 1.09, batch loss = 0.99 (45.2 examples/sec; 0.177 sec/batch; 16h:12m:12s remains)
INFO - root - 2017-12-03 07:04:58.974899: step 2910, loss = 1.11, batch loss = 1.01 (43.1 examples/sec; 0.186 sec/batch; 16h:59m:09s remains)
INFO - root - 2017-12-03 07:05:00.808353: step 2920, loss = 0.97, batch loss = 0.88 (43.9 examples/sec; 0.182 sec/batch; 16h:41m:36s remains)
INFO - root - 2017-12-03 07:05:02.664465: step 2930, loss = 1.21, batch loss = 1.11 (43.6 examples/sec; 0.183 sec/batch; 16h:46m:46s remains)
INFO - root - 2017-12-03 07:05:04.508060: step 2940, loss = 0.97, batch loss = 0.87 (43.2 examples/sec; 0.185 sec/batch; 16h:58m:18s remains)
INFO - root - 2017-12-03 07:05:06.342538: step 2950, loss = 1.07, batch loss = 0.98 (42.9 examples/sec; 0.186 sec/batch; 17h:03m:16s remains)
INFO - root - 2017-12-03 07:05:08.173411: step 2960, loss = 1.21, batch loss = 1.11 (44.6 examples/sec; 0.179 sec/batch; 16h:25m:20s remains)
INFO - root - 2017-12-03 07:05:10.006668: step 2970, loss = 1.05, batch loss = 0.96 (44.5 examples/sec; 0.180 sec/batch; 16h:26m:32s remains)
INFO - root - 2017-12-03 07:05:11.836762: step 2980, loss = 1.25, batch loss = 1.15 (44.9 examples/sec; 0.178 sec/batch; 16h:19m:05s remains)
INFO - root - 2017-12-03 07:05:13.683695: step 2990, loss = 1.16, batch loss = 1.07 (42.4 examples/sec; 0.189 sec/batch; 17h:15m:19s remains)
INFO - root - 2017-12-03 07:05:15.501343: step 3000, loss = 1.05, batch loss = 0.96 (45.3 examples/sec; 0.177 sec/batch; 16h:10m:04s remains)
INFO - root - 2017-12-03 07:05:17.406464: step 3010, loss = 1.05, batch loss = 0.96 (43.4 examples/sec; 0.184 sec/batch; 16h:52m:54s remains)
INFO - root - 2017-12-03 07:05:19.237060: step 3020, loss = 1.08, batch loss = 0.99 (44.0 examples/sec; 0.182 sec/batch; 16h:38m:52s remains)
INFO - root - 2017-12-03 07:05:21.067247: step 3030, loss = 1.02, batch loss = 0.92 (42.7 examples/sec; 0.188 sec/batch; 17h:09m:36s remains)
INFO - root - 2017-12-03 07:05:22.958910: step 3040, loss = 1.01, batch loss = 0.92 (41.9 examples/sec; 0.191 sec/batch; 17h:27m:44s remains)
INFO - root - 2017-12-03 07:05:24.792202: step 3050, loss = 1.10, batch loss = 1.01 (43.7 examples/sec; 0.183 sec/batch; 16h:44m:56s remains)
INFO - root - 2017-12-03 07:05:26.626101: step 3060, loss = 1.11, batch loss = 1.01 (43.6 examples/sec; 0.183 sec/batch; 16h:47m:11s remains)
INFO - root - 2017-12-03 07:05:28.470774: step 3070, loss = 1.10, batch loss = 1.00 (42.9 examples/sec; 0.186 sec/batch; 17h:03m:12s remains)
INFO - root - 2017-12-03 07:05:30.293067: step 3080, loss = 0.78, batch loss = 0.69 (44.6 examples/sec; 0.180 sec/batch; 16h:25m:45s remains)
INFO - root - 2017-12-03 07:05:32.147400: step 3090, loss = 1.11, batch loss = 1.02 (44.7 examples/sec; 0.179 sec/batch; 16h:21m:59s remains)
INFO - root - 2017-12-03 07:05:33.962514: step 3100, loss = 0.95, batch loss = 0.85 (45.3 examples/sec; 0.177 sec/batch; 16h:09m:49s remains)
INFO - root - 2017-12-03 07:05:35.857560: step 3110, loss = 1.15, batch loss = 1.06 (44.1 examples/sec; 0.181 sec/batch; 16h:34m:51s remains)
INFO - root - 2017-12-03 07:05:37.686284: step 3120, loss = 1.02, batch loss = 0.92 (44.7 examples/sec; 0.179 sec/batch; 16h:22m:53s remains)
INFO - root - 2017-12-03 07:05:39.577910: step 3130, loss = 0.99, batch loss = 0.89 (40.1 examples/sec; 0.199 sec/batch; 18h:14m:07s remains)
INFO - root - 2017-12-03 07:05:41.437278: step 3140, loss = 1.12, batch loss = 1.03 (43.0 examples/sec; 0.186 sec/batch; 17h:02m:19s remains)
INFO - root - 2017-12-03 07:05:43.277784: step 3150, loss = 1.03, batch loss = 0.93 (44.3 examples/sec; 0.181 sec/batch; 16h:32m:06s remains)
INFO - root - 2017-12-03 07:05:45.114630: step 3160, loss = 0.94, batch loss = 0.84 (42.8 examples/sec; 0.187 sec/batch; 17h:06m:12s remains)
INFO - root - 2017-12-03 07:05:46.946560: step 3170, loss = 0.86, batch loss = 0.77 (43.2 examples/sec; 0.185 sec/batch; 16h:55m:43s remains)
INFO - root - 2017-12-03 07:05:48.803363: step 3180, loss = 1.03, batch loss = 0.94 (43.3 examples/sec; 0.185 sec/batch; 16h:55m:02s remains)
INFO - root - 2017-12-03 07:05:50.636796: step 3190, loss = 1.02, batch loss = 0.93 (41.9 examples/sec; 0.191 sec/batch; 17h:27m:07s remains)
INFO - root - 2017-12-03 07:05:52.461134: step 3200, loss = 1.06, batch loss = 0.96 (45.5 examples/sec; 0.176 sec/batch; 16h:05m:56s remains)
INFO - root - 2017-12-03 07:05:54.376204: step 3210, loss = 1.09, batch loss = 0.99 (43.6 examples/sec; 0.183 sec/batch; 16h:45m:59s remains)
INFO - root - 2017-12-03 07:05:56.229916: step 3220, loss = 1.19, batch loss = 1.10 (42.7 examples/sec; 0.187 sec/batch; 17h:07m:39s remains)
INFO - root - 2017-12-03 07:05:58.083273: step 3230, loss = 1.00, batch loss = 0.91 (43.8 examples/sec; 0.183 sec/batch; 16h:42m:32s remains)
INFO - root - 2017-12-03 07:05:59.927813: step 3240, loss = 1.05, batch loss = 0.95 (43.5 examples/sec; 0.184 sec/batch; 16h:48m:26s remains)
INFO - root - 2017-12-03 07:06:01.757075: step 3250, loss = 1.00, batch loss = 0.91 (43.2 examples/sec; 0.185 sec/batch; 16h:56m:01s remains)
INFO - root - 2017-12-03 07:06:03.612953: step 3260, loss = 0.84, batch loss = 0.74 (38.6 examples/sec; 0.207 sec/batch; 18h:57m:05s remains)
INFO - root - 2017-12-03 07:06:05.463682: step 3270, loss = 0.91, batch loss = 0.81 (42.9 examples/sec; 0.187 sec/batch; 17h:04m:22s remains)
INFO - root - 2017-12-03 07:06:07.296482: step 3280, loss = 1.03, batch loss = 0.93 (44.6 examples/sec; 0.179 sec/batch; 16h:23m:16s remains)
INFO - root - 2017-12-03 07:06:09.167318: step 3290, loss = 0.82, batch loss = 0.73 (44.8 examples/sec; 0.179 sec/batch; 16h:20m:19s remains)
INFO - root - 2017-12-03 07:06:11.039495: step 3300, loss = 0.90, batch loss = 0.80 (40.4 examples/sec; 0.198 sec/batch; 18h:07m:13s remains)
INFO - root - 2017-12-03 07:06:12.944147: step 3310, loss = 1.03, batch loss = 0.93 (43.4 examples/sec; 0.184 sec/batch; 16h:51m:18s remains)
INFO - root - 2017-12-03 07:06:14.818127: step 3320, loss = 1.01, batch loss = 0.92 (43.8 examples/sec; 0.183 sec/batch; 16h:42m:31s remains)
INFO - root - 2017-12-03 07:06:16.650573: step 3330, loss = 1.05, batch loss = 0.95 (42.8 examples/sec; 0.187 sec/batch; 17h:06m:17s remains)
INFO - root - 2017-12-03 07:06:18.506049: step 3340, loss = 0.85, batch loss = 0.75 (43.8 examples/sec; 0.183 sec/batch; 16h:42m:27s remains)
INFO - root - 2017-12-03 07:06:20.357860: step 3350, loss = 0.98, batch loss = 0.89 (43.8 examples/sec; 0.183 sec/batch; 16h:43m:03s remains)
INFO - root - 2017-12-03 07:06:22.192797: step 3360, loss = 0.98, batch loss = 0.88 (44.5 examples/sec; 0.180 sec/batch; 16h:26m:57s remains)
INFO - root - 2017-12-03 07:06:24.025136: step 3370, loss = 0.91, batch loss = 0.81 (43.4 examples/sec; 0.184 sec/batch; 16h:51m:03s remains)
INFO - root - 2017-12-03 07:06:25.861098: step 3380, loss = 0.97, batch loss = 0.88 (43.5 examples/sec; 0.184 sec/batch; 16h:48m:20s remains)
INFO - root - 2017-12-03 07:06:27.687636: step 3390, loss = 1.11, batch loss = 1.01 (44.0 examples/sec; 0.182 sec/batch; 16h:38m:05s remains)
INFO - root - 2017-12-03 07:06:29.545968: step 3400, loss = 0.87, batch loss = 0.77 (42.8 examples/sec; 0.187 sec/batch; 17h:04m:59s remains)
INFO - root - 2017-12-03 07:06:31.477879: step 3410, loss = 1.14, batch loss = 1.04 (44.9 examples/sec; 0.178 sec/batch; 16h:17m:11s remains)
INFO - root - 2017-12-03 07:06:33.337202: step 3420, loss = 0.93, batch loss = 0.83 (43.2 examples/sec; 0.185 sec/batch; 16h:56m:49s remains)
INFO - root - 2017-12-03 07:06:35.191824: step 3430, loss = 0.98, batch loss = 0.88 (42.7 examples/sec; 0.187 sec/batch; 17h:07m:04s remains)
INFO - root - 2017-12-03 07:06:37.024349: step 3440, loss = 0.87, batch loss = 0.77 (43.1 examples/sec; 0.186 sec/batch; 16h:58m:25s remains)
INFO - root - 2017-12-03 07:06:38.889680: step 3450, loss = 0.91, batch loss = 0.81 (43.3 examples/sec; 0.185 sec/batch; 16h:52m:53s remains)
INFO - root - 2017-12-03 07:06:40.739526: step 3460, loss = 1.06, batch loss = 0.96 (44.4 examples/sec; 0.180 sec/batch; 16h:28m:17s remains)
INFO - root - 2017-12-03 07:06:42.563463: step 3470, loss = 0.99, batch loss = 0.89 (43.2 examples/sec; 0.185 sec/batch; 16h:54m:39s remains)
INFO - root - 2017-12-03 07:06:44.421386: step 3480, loss = 1.14, batch loss = 1.04 (43.5 examples/sec; 0.184 sec/batch; 16h:48m:55s remains)
INFO - root - 2017-12-03 07:06:46.302635: step 3490, loss = 1.15, batch loss = 1.06 (43.2 examples/sec; 0.185 sec/batch; 16h:56m:32s remains)
INFO - root - 2017-12-03 07:06:48.147504: step 3500, loss = 0.97, batch loss = 0.87 (43.4 examples/sec; 0.184 sec/batch; 16h:49m:45s remains)
INFO - root - 2017-12-03 07:06:50.088368: step 3510, loss = 1.06, batch loss = 0.96 (43.8 examples/sec; 0.183 sec/batch; 16h:42m:34s remains)
INFO - root - 2017-12-03 07:06:51.917099: step 3520, loss = 1.02, batch loss = 0.93 (43.4 examples/sec; 0.184 sec/batch; 16h:50m:33s remains)
INFO - root - 2017-12-03 07:06:53.750471: step 3530, loss = 1.02, batch loss = 0.92 (43.1 examples/sec; 0.186 sec/batch; 16h:58m:16s remains)
INFO - root - 2017-12-03 07:06:55.607913: step 3540, loss = 1.04, batch loss = 0.94 (43.0 examples/sec; 0.186 sec/batch; 16h:59m:59s remains)
INFO - root - 2017-12-03 07:06:57.459019: step 3550, loss = 1.00, batch loss = 0.91 (44.9 examples/sec; 0.178 sec/batch; 16h:16m:29s remains)
INFO - root - 2017-12-03 07:06:59.311909: step 3560, loss = 1.08, batch loss = 0.98 (42.7 examples/sec; 0.188 sec/batch; 17h:08m:19s remains)
INFO - root - 2017-12-03 07:07:01.142848: step 3570, loss = 1.03, batch loss = 0.93 (45.2 examples/sec; 0.177 sec/batch; 16h:10m:56s remains)
INFO - root - 2017-12-03 07:07:03.011743: step 3580, loss = 0.94, batch loss = 0.85 (41.4 examples/sec; 0.193 sec/batch; 17h:38m:07s remains)
INFO - root - 2017-12-03 07:07:04.870751: step 3590, loss = 0.96, batch loss = 0.86 (43.2 examples/sec; 0.185 sec/batch; 16h:54m:06s remains)
INFO - root - 2017-12-03 07:07:06.733236: step 3600, loss = 0.96, batch loss = 0.86 (42.1 examples/sec; 0.190 sec/batch; 17h:21m:52s remains)
INFO - root - 2017-12-03 07:07:08.635153: step 3610, loss = 1.13, batch loss = 1.03 (43.0 examples/sec; 0.186 sec/batch; 16h:59m:19s remains)
INFO - root - 2017-12-03 07:07:10.491544: step 3620, loss = 1.03, batch loss = 0.93 (45.3 examples/sec; 0.177 sec/batch; 16h:07m:42s remains)
INFO - root - 2017-12-03 07:07:12.331275: step 3630, loss = 0.99, batch loss = 0.89 (42.7 examples/sec; 0.188 sec/batch; 17h:08m:03s remains)
INFO - root - 2017-12-03 07:07:14.166630: step 3640, loss = 1.12, batch loss = 1.02 (41.9 examples/sec; 0.191 sec/batch; 17h:26m:36s remains)
INFO - root - 2017-12-03 07:07:16.012501: step 3650, loss = 1.16, batch loss = 1.06 (43.9 examples/sec; 0.182 sec/batch; 16h:38m:29s remains)
INFO - root - 2017-12-03 07:07:17.866835: step 3660, loss = 1.10, batch loss = 1.00 (43.3 examples/sec; 0.185 sec/batch; 16h:51m:50s remains)
INFO - root - 2017-12-03 07:07:19.700585: step 3670, loss = 1.05, batch loss = 0.95 (43.0 examples/sec; 0.186 sec/batch; 16h:59m:44s remains)
INFO - root - 2017-12-03 07:07:21.529115: step 3680, loss = 0.97, batch loss = 0.87 (44.5 examples/sec; 0.180 sec/batch; 16h:25m:54s remains)
INFO - root - 2017-12-03 07:07:23.370357: step 3690, loss = 1.05, batch loss = 0.95 (42.0 examples/sec; 0.190 sec/batch; 17h:23m:55s remains)
INFO - root - 2017-12-03 07:07:25.202582: step 3700, loss = 1.17, batch loss = 1.07 (41.4 examples/sec; 0.193 sec/batch; 17h:38m:34s remains)
INFO - root - 2017-12-03 07:07:27.148040: step 3710, loss = 0.91, batch loss = 0.81 (42.8 examples/sec; 0.187 sec/batch; 17h:04m:55s remains)
INFO - root - 2017-12-03 07:07:28.997667: step 3720, loss = 1.05, batch loss = 0.95 (43.2 examples/sec; 0.185 sec/batch; 16h:55m:26s remains)
INFO - root - 2017-12-03 07:07:30.846712: step 3730, loss = 1.03, batch loss = 0.93 (42.0 examples/sec; 0.191 sec/batch; 17h:24m:55s remains)
INFO - root - 2017-12-03 07:07:32.671870: step 3740, loss = 1.30, batch loss = 1.20 (43.5 examples/sec; 0.184 sec/batch; 16h:47m:01s remains)
INFO - root - 2017-12-03 07:07:34.520365: step 3750, loss = 0.94, batch loss = 0.84 (43.6 examples/sec; 0.184 sec/batch; 16h:45m:55s remains)
INFO - root - 2017-12-03 07:07:36.361902: step 3760, loss = 1.02, batch loss = 0.93 (42.3 examples/sec; 0.189 sec/batch; 17h:15m:05s remains)
INFO - root - 2017-12-03 07:07:38.197628: step 3770, loss = 0.96, batch loss = 0.86 (44.3 examples/sec; 0.181 sec/batch; 16h:29m:44s remains)
INFO - root - 2017-12-03 07:07:40.068698: step 3780, loss = 1.05, batch loss = 0.95 (42.5 examples/sec; 0.188 sec/batch; 17h:11m:28s remains)
INFO - root - 2017-12-03 07:07:41.923498: step 3790, loss = 1.04, batch loss = 0.94 (44.8 examples/sec; 0.179 sec/batch; 16h:17m:56s remains)
INFO - root - 2017-12-03 07:07:43.787467: step 3800, loss = 1.00, batch loss = 0.90 (42.1 examples/sec; 0.190 sec/batch; 17h:22m:06s remains)
INFO - root - 2017-12-03 07:07:45.693461: step 3810, loss = 1.16, batch loss = 1.06 (44.4 examples/sec; 0.180 sec/batch; 16h:26m:03s remains)
INFO - root - 2017-12-03 07:07:47.541669: step 3820, loss = 0.94, batch loss = 0.84 (42.9 examples/sec; 0.187 sec/batch; 17h:01m:59s remains)
INFO - root - 2017-12-03 07:07:49.400986: step 3830, loss = 1.32, batch loss = 1.22 (44.0 examples/sec; 0.182 sec/batch; 16h:34m:55s remains)
INFO - root - 2017-12-03 07:07:51.275203: step 3840, loss = 1.00, batch loss = 0.90 (39.7 examples/sec; 0.202 sec/batch; 18h:23m:59s remains)
INFO - root - 2017-12-03 07:07:53.135707: step 3850, loss = 0.89, batch loss = 0.79 (43.2 examples/sec; 0.185 sec/batch; 16h:54m:02s remains)
INFO - root - 2017-12-03 07:07:54.987446: step 3860, loss = 1.12, batch loss = 1.03 (41.3 examples/sec; 0.194 sec/batch; 17h:41m:10s remains)
INFO - root - 2017-12-03 07:07:56.862196: step 3870, loss = 1.12, batch loss = 1.02 (41.8 examples/sec; 0.191 sec/batch; 17h:28m:27s remains)
INFO - root - 2017-12-03 07:07:58.703246: step 3880, loss = 1.14, batch loss = 1.05 (43.2 examples/sec; 0.185 sec/batch; 16h:54m:34s remains)
INFO - root - 2017-12-03 07:08:00.545903: step 3890, loss = 0.92, batch loss = 0.83 (41.2 examples/sec; 0.194 sec/batch; 17h:43m:56s remains)
INFO - root - 2017-12-03 07:08:02.448688: step 3900, loss = 1.11, batch loss = 1.01 (42.3 examples/sec; 0.189 sec/batch; 17h:14m:45s remains)
INFO - root - 2017-12-03 07:08:04.388489: step 3910, loss = 1.06, batch loss = 0.96 (42.9 examples/sec; 0.187 sec/batch; 17h:01m:59s remains)
INFO - root - 2017-12-03 07:08:06.228744: step 3920, loss = 0.83, batch loss = 0.73 (43.8 examples/sec; 0.183 sec/batch; 16h:41m:20s remains)
INFO - root - 2017-12-03 07:08:08.084204: step 3930, loss = 0.90, batch loss = 0.81 (43.9 examples/sec; 0.182 sec/batch; 16h:38m:28s remains)
INFO - root - 2017-12-03 07:08:09.952098: step 3940, loss = 1.08, batch loss = 0.99 (42.5 examples/sec; 0.188 sec/batch; 17h:11m:07s remains)
INFO - root - 2017-12-03 07:08:11.815709: step 3950, loss = 1.10, batch loss = 1.00 (42.0 examples/sec; 0.190 sec/batch; 17h:22m:58s remains)
INFO - root - 2017-12-03 07:08:13.661340: step 3960, loss = 1.00, batch loss = 0.90 (43.3 examples/sec; 0.185 sec/batch; 16h:50m:53s remains)
INFO - root - 2017-12-03 07:08:15.519416: step 3970, loss = 0.99, batch loss = 0.89 (43.3 examples/sec; 0.185 sec/batch; 16h:51m:53s remains)
INFO - root - 2017-12-03 07:08:17.369630: step 3980, loss = 1.10, batch loss = 1.01 (43.3 examples/sec; 0.185 sec/batch; 16h:51m:00s remains)
INFO - root - 2017-12-03 07:08:19.202853: step 3990, loss = 1.17, batch loss = 1.07 (44.4 examples/sec; 0.180 sec/batch; 16h:25m:32s remains)
INFO - root - 2017-12-03 07:08:21.033817: step 4000, loss = 0.89, batch loss = 0.80 (44.4 examples/sec; 0.180 sec/batch; 16h:25m:53s remains)
INFO - root - 2017-12-03 07:08:22.968638: step 4010, loss = 0.99, batch loss = 0.90 (44.1 examples/sec; 0.181 sec/batch; 16h:32m:09s remains)
INFO - root - 2017-12-03 07:08:24.811221: step 4020, loss = 1.11, batch loss = 1.02 (41.2 examples/sec; 0.194 sec/batch; 17h:44m:12s remains)
INFO - root - 2017-12-03 07:08:26.630825: step 4030, loss = 1.14, batch loss = 1.04 (44.8 examples/sec; 0.178 sec/batch; 16h:16m:46s remains)
INFO - root - 2017-12-03 07:08:28.504485: step 4040, loss = 1.31, batch loss = 1.21 (42.5 examples/sec; 0.188 sec/batch; 17h:11m:37s remains)
INFO - root - 2017-12-03 07:08:30.358234: step 4050, loss = 1.22, batch loss = 1.13 (44.5 examples/sec; 0.180 sec/batch; 16h:25m:12s remains)
INFO - root - 2017-12-03 07:08:32.220108: step 4060, loss = 1.48, batch loss = 1.38 (41.5 examples/sec; 0.193 sec/batch; 17h:34m:04s remains)
INFO - root - 2017-12-03 07:08:34.049051: step 4070, loss = 1.02, batch loss = 0.93 (43.1 examples/sec; 0.186 sec/batch; 16h:56m:28s remains)
INFO - root - 2017-12-03 07:08:35.889945: step 4080, loss = 1.09, batch loss = 0.99 (43.7 examples/sec; 0.183 sec/batch; 16h:41m:49s remains)
INFO - root - 2017-12-03 07:08:37.732852: step 4090, loss = 1.20, batch loss = 1.10 (43.5 examples/sec; 0.184 sec/batch; 16h:46m:04s remains)
INFO - root - 2017-12-03 07:08:39.613034: step 4100, loss = 1.33, batch loss = 1.24 (44.1 examples/sec; 0.181 sec/batch; 16h:33m:23s remains)
INFO - root - 2017-12-03 07:08:41.531839: step 4110, loss = 1.38, batch loss = 1.28 (41.9 examples/sec; 0.191 sec/batch; 17h:25m:39s remains)
INFO - root - 2017-12-03 07:08:43.402853: step 4120, loss = 1.19, batch loss = 1.09 (43.4 examples/sec; 0.184 sec/batch; 16h:47m:50s remains)
INFO - root - 2017-12-03 07:08:45.264321: step 4130, loss = 1.17, batch loss = 1.08 (43.5 examples/sec; 0.184 sec/batch; 16h:46m:45s remains)
INFO - root - 2017-12-03 07:08:47.131756: step 4140, loss = 1.32, batch loss = 1.23 (42.2 examples/sec; 0.190 sec/batch; 17h:18m:34s remains)
INFO - root - 2017-12-03 07:08:48.982491: step 4150, loss = 1.15, batch loss = 1.05 (43.9 examples/sec; 0.182 sec/batch; 16h:36m:33s remains)
INFO - root - 2017-12-03 07:08:50.835958: step 4160, loss = 1.18, batch loss = 1.08 (42.1 examples/sec; 0.190 sec/batch; 17h:18m:40s remains)
INFO - root - 2017-12-03 07:08:52.671412: step 4170, loss = 1.27, batch loss = 1.17 (41.2 examples/sec; 0.194 sec/batch; 17h:42m:06s remains)
INFO - root - 2017-12-03 07:08:54.506760: step 4180, loss = 1.13, batch loss = 1.03 (41.4 examples/sec; 0.193 sec/batch; 17h:37m:04s remains)
INFO - root - 2017-12-03 07:08:56.365143: step 4190, loss = 1.18, batch loss = 1.08 (40.8 examples/sec; 0.196 sec/batch; 17h:52m:35s remains)
INFO - root - 2017-12-03 07:08:58.213322: step 4200, loss = 1.26, batch loss = 1.16 (42.3 examples/sec; 0.189 sec/batch; 17h:14m:22s remains)
INFO - root - 2017-12-03 07:09:00.138643: step 4210, loss = 1.20, batch loss = 1.10 (44.4 examples/sec; 0.180 sec/batch; 16h:26m:20s remains)
INFO - root - 2017-12-03 07:09:02.014905: step 4220, loss = 1.09, batch loss = 0.99 (42.7 examples/sec; 0.188 sec/batch; 17h:06m:01s remains)
INFO - root - 2017-12-03 07:09:03.844747: step 4230, loss = 1.42, batch loss = 1.33 (45.4 examples/sec; 0.176 sec/batch; 16h:04m:23s remains)
INFO - root - 2017-12-03 07:09:05.715735: step 4240, loss = 1.22, batch loss = 1.12 (41.8 examples/sec; 0.191 sec/batch; 17h:26m:04s remains)
INFO - root - 2017-12-03 07:09:07.581128: step 4250, loss = 1.40, batch loss = 1.30 (41.6 examples/sec; 0.192 sec/batch; 17h:32m:08s remains)
INFO - root - 2017-12-03 07:09:09.429546: step 4260, loss = 1.22, batch loss = 1.12 (43.6 examples/sec; 0.183 sec/batch; 16h:43m:28s remains)
INFO - root - 2017-12-03 07:09:11.293220: step 4270, loss = 1.01, batch loss = 0.91 (41.7 examples/sec; 0.192 sec/batch; 17h:28m:32s remains)
INFO - root - 2017-12-03 07:09:13.124427: step 4280, loss = 1.23, batch loss = 1.13 (43.1 examples/sec; 0.186 sec/batch; 16h:54m:57s remains)
INFO - root - 2017-12-03 07:09:14.983806: step 4290, loss = 1.01, batch loss = 0.91 (43.0 examples/sec; 0.186 sec/batch; 16h:57m:08s remains)
INFO - root - 2017-12-03 07:09:16.830309: step 4300, loss = 1.01, batch loss = 0.91 (43.6 examples/sec; 0.183 sec/batch; 16h:43m:37s remains)
INFO - root - 2017-12-03 07:09:18.770841: step 4310, loss = 1.10, batch loss = 1.00 (43.5 examples/sec; 0.184 sec/batch; 16h:44m:59s remains)
INFO - root - 2017-12-03 07:09:20.620430: step 4320, loss = 1.11, batch loss = 1.02 (42.1 examples/sec; 0.190 sec/batch; 17h:20m:33s remains)
INFO - root - 2017-12-03 07:09:22.492593: step 4330, loss = 1.16, batch loss = 1.06 (43.5 examples/sec; 0.184 sec/batch; 16h:45m:57s remains)
INFO - root - 2017-12-03 07:09:24.335762: step 4340, loss = 1.17, batch loss = 1.08 (41.8 examples/sec; 0.191 sec/batch; 17h:26m:24s remains)
INFO - root - 2017-12-03 07:09:26.177337: step 4350, loss = 1.05, batch loss = 0.95 (43.9 examples/sec; 0.182 sec/batch; 16h:36m:05s remains)
INFO - root - 2017-12-03 07:09:28.033516: step 4360, loss = 0.94, batch loss = 0.84 (42.3 examples/sec; 0.189 sec/batch; 17h:15m:30s remains)
INFO - root - 2017-12-03 07:09:29.941765: step 4370, loss = 1.18, batch loss = 1.08 (44.8 examples/sec; 0.179 sec/batch; 16h:17m:24s remains)
INFO - root - 2017-12-03 07:09:31.782018: step 4380, loss = 1.24, batch loss = 1.14 (43.9 examples/sec; 0.182 sec/batch; 16h:35m:40s remains)
INFO - root - 2017-12-03 07:09:33.685937: step 4390, loss = 1.25, batch loss = 1.15 (39.8 examples/sec; 0.201 sec/batch; 18h:18m:52s remains)
INFO - root - 2017-12-03 07:09:36.431970: step 4400, loss = 1.30, batch loss = 1.20 (20.6 examples/sec; 0.388 sec/batch; 35h:23m:37s remains)
INFO - root - 2017-12-03 07:09:39.799521: step 4410, loss = 1.11, batch loss = 1.02 (18.1 examples/sec; 0.441 sec/batch; 40h:12m:44s remains)
INFO - root - 2017-12-03 07:09:43.704722: step 4420, loss = 1.04, batch loss = 0.94 (21.4 examples/sec; 0.373 sec/batch; 34h:01m:15s remains)
INFO - root - 2017-12-03 07:09:47.505654: step 4430, loss = 1.18, batch loss = 1.08 (24.9 examples/sec; 0.321 sec/batch; 29h:16m:15s remains)
INFO - root - 2017-12-03 07:09:51.342148: step 4440, loss = 1.11, batch loss = 1.01 (17.9 examples/sec; 0.447 sec/batch; 40h:42m:43s remains)
INFO - root - 2017-12-03 07:09:55.169160: step 4450, loss = 1.17, batch loss = 1.07 (23.6 examples/sec; 0.339 sec/batch; 30h:55m:30s remains)
INFO - root - 2017-12-03 07:09:58.961861: step 4460, loss = 1.35, batch loss = 1.25 (21.4 examples/sec; 0.375 sec/batch; 34h:08m:20s remains)
INFO - root - 2017-12-03 07:10:04.024637: step 4470, loss = 1.06, batch loss = 0.97 (31.3 examples/sec; 0.256 sec/batch; 23h:18m:10s remains)
INFO - root - 2017-12-03 07:10:07.657655: step 4480, loss = 1.16, batch loss = 1.06 (19.4 examples/sec; 0.413 sec/batch; 37h:38m:33s remains)
INFO - root - 2017-12-03 07:10:11.443543: step 4490, loss = 1.05, batch loss = 0.95 (20.8 examples/sec; 0.384 sec/batch; 35h:01m:16s remains)
INFO - root - 2017-12-03 07:10:15.460122: step 4500, loss = 1.10, batch loss = 1.00 (22.9 examples/sec; 0.350 sec/batch; 31h:52m:06s remains)
INFO - root - 2017-12-03 07:10:18.853400: step 4510, loss = 1.09, batch loss = 0.99 (18.6 examples/sec; 0.431 sec/batch; 39h:15m:08s remains)
INFO - root - 2017-12-03 07:10:22.709857: step 4520, loss = 0.92, batch loss = 0.83 (21.9 examples/sec; 0.365 sec/batch; 33h:16m:19s remains)
INFO - root - 2017-12-03 07:10:26.570512: step 4530, loss = 1.07, batch loss = 0.97 (25.4 examples/sec; 0.315 sec/batch; 28h:41m:15s remains)
INFO - root - 2017-12-03 07:10:30.351886: step 4540, loss = 0.90, batch loss = 0.80 (17.5 examples/sec; 0.457 sec/batch; 41h:40m:13s remains)
INFO - root - 2017-12-03 07:10:34.286267: step 4550, loss = 1.03, batch loss = 0.93 (17.7 examples/sec; 0.452 sec/batch; 41h:11m:57s remains)
INFO - root - 2017-12-03 07:10:37.824867: step 4560, loss = 0.86, batch loss = 0.76 (23.2 examples/sec; 0.344 sec/batch; 31h:21m:27s remains)
INFO - root - 2017-12-03 07:10:41.617426: step 4570, loss = 1.34, batch loss = 1.24 (22.7 examples/sec; 0.352 sec/batch; 32h:02m:49s remains)
INFO - root - 2017-12-03 07:10:45.325128: step 4580, loss = 1.04, batch loss = 0.94 (22.1 examples/sec; 0.362 sec/batch; 32h:58m:50s remains)
INFO - root - 2017-12-03 07:10:48.823090: step 4590, loss = 0.82, batch loss = 0.72 (22.8 examples/sec; 0.351 sec/batch; 31h:56m:24s remains)
INFO - root - 2017-12-03 07:10:52.593354: step 4600, loss = 0.90, batch loss = 0.80 (26.6 examples/sec; 0.301 sec/batch; 27h:25m:27s remains)
INFO - root - 2017-12-03 07:10:56.533942: step 4610, loss = 1.01, batch loss = 0.92 (18.6 examples/sec; 0.431 sec/batch; 39h:13m:46s remains)
INFO - root - 2017-12-03 07:11:00.222648: step 4620, loss = 1.09, batch loss = 1.00 (24.8 examples/sec; 0.322 sec/batch; 29h:20m:25s remains)
INFO - root - 2017-12-03 07:11:03.580910: step 4630, loss = 1.06, batch loss = 0.96 (21.9 examples/sec; 0.366 sec/batch; 33h:19m:13s remains)
INFO - root - 2017-12-03 07:11:07.289194: step 4640, loss = 1.21, batch loss = 1.11 (22.5 examples/sec; 0.356 sec/batch; 32h:22m:53s remains)
INFO - root - 2017-12-03 07:11:10.850359: step 4650, loss = 1.02, batch loss = 0.92 (28.1 examples/sec; 0.285 sec/batch; 25h:55m:46s remains)
INFO - root - 2017-12-03 07:11:14.375668: step 4660, loss = 1.02, batch loss = 0.92 (43.0 examples/sec; 0.186 sec/batch; 16h:55m:57s remains)
INFO - root - 2017-12-03 07:11:17.889734: step 4670, loss = 0.96, batch loss = 0.86 (42.2 examples/sec; 0.190 sec/batch; 17h:16m:51s remains)
INFO - root - 2017-12-03 07:11:21.749663: step 4680, loss = 1.06, batch loss = 0.97 (24.2 examples/sec; 0.330 sec/batch; 30h:05m:06s remains)
INFO - root - 2017-12-03 07:11:25.687053: step 4690, loss = 1.40, batch loss = 1.31 (22.6 examples/sec; 0.353 sec/batch; 32h:10m:06s remains)
INFO - root - 2017-12-03 07:11:29.469106: step 4700, loss = 1.33, batch loss = 1.23 (21.9 examples/sec; 0.365 sec/batch; 33h:16m:34s remains)
INFO - root - 2017-12-03 07:11:33.579837: step 4710, loss = 1.22, batch loss = 1.12 (18.8 examples/sec; 0.426 sec/batch; 38h:45m:09s remains)
INFO - root - 2017-12-03 07:11:37.078122: step 4720, loss = 1.22, batch loss = 1.12 (18.1 examples/sec; 0.442 sec/batch; 40h:15m:52s remains)
INFO - root - 2017-12-03 07:11:40.248830: step 4730, loss = 1.42, batch loss = 1.32 (24.4 examples/sec; 0.327 sec/batch; 29h:48m:23s remains)
INFO - root - 2017-12-03 07:11:43.450632: step 4740, loss = 1.65, batch loss = 1.55 (18.4 examples/sec; 0.436 sec/batch; 39h:41m:22s remains)
INFO - root - 2017-12-03 07:11:47.273808: step 4750, loss = 1.10, batch loss = 1.00 (20.6 examples/sec; 0.388 sec/batch; 35h:21m:35s remains)
INFO - root - 2017-12-03 07:11:51.338179: step 4760, loss = 1.22, batch loss = 1.12 (18.5 examples/sec; 0.432 sec/batch; 39h:21m:50s remains)
INFO - root - 2017-12-03 07:11:54.753877: step 4770, loss = 1.15, batch loss = 1.05 (18.6 examples/sec; 0.429 sec/batch; 39h:05m:42s remains)
INFO - root - 2017-12-03 07:11:58.525741: step 4780, loss = 1.17, batch loss = 1.07 (21.0 examples/sec; 0.381 sec/batch; 34h:40m:45s remains)
INFO - root - 2017-12-03 07:12:02.190406: step 4790, loss = 1.17, batch loss = 1.07 (19.2 examples/sec; 0.417 sec/batch; 37h:56m:54s remains)
INFO - root - 2017-12-03 07:12:05.607811: step 4800, loss = 1.36, batch loss = 1.26 (17.4 examples/sec; 0.461 sec/batch; 41h:56m:45s remains)
INFO - root - 2017-12-03 07:12:09.785490: step 4810, loss = 1.47, batch loss = 1.37 (18.7 examples/sec; 0.428 sec/batch; 38h:56m:06s remains)
INFO - root - 2017-12-03 07:12:13.709945: step 4820, loss = 1.33, batch loss = 1.23 (17.7 examples/sec; 0.451 sec/batch; 41h:03m:15s remains)
INFO - root - 2017-12-03 07:12:17.470166: step 4830, loss = 0.99, batch loss = 0.89 (16.9 examples/sec; 0.472 sec/batch; 42h:57m:47s remains)
INFO - root - 2017-12-03 07:12:21.309334: step 4840, loss = 0.96, batch loss = 0.86 (21.7 examples/sec; 0.368 sec/batch; 33h:30m:23s remains)
INFO - root - 2017-12-03 07:12:25.209721: step 4850, loss = 0.97, batch loss = 0.87 (22.3 examples/sec; 0.359 sec/batch; 32h:41m:39s remains)
INFO - root - 2017-12-03 07:12:29.297827: step 4860, loss = 1.02, batch loss = 0.92 (22.6 examples/sec; 0.355 sec/batch; 32h:16m:00s remains)
INFO - root - 2017-12-03 07:12:32.820946: step 4870, loss = 0.95, batch loss = 0.86 (23.0 examples/sec; 0.349 sec/batch; 31h:43m:09s remains)
INFO - root - 2017-12-03 07:12:36.592355: step 4880, loss = 1.04, batch loss = 0.94 (22.3 examples/sec; 0.358 sec/batch; 32h:35m:27s remains)
INFO - root - 2017-12-03 07:12:39.705274: step 4890, loss = 1.10, batch loss = 1.00 (43.7 examples/sec; 0.183 sec/batch; 16h:40m:30s remains)
INFO - root - 2017-12-03 07:12:43.507735: step 4900, loss = 1.22, batch loss = 1.12 (18.9 examples/sec; 0.424 sec/batch; 38h:33m:37s remains)
INFO - root - 2017-12-03 07:12:47.548723: step 4910, loss = 1.14, batch loss = 1.04 (20.1 examples/sec; 0.397 sec/batch; 36h:07m:58s remains)
INFO - root - 2017-12-03 07:12:51.506260: step 4920, loss = 1.15, batch loss = 1.05 (17.5 examples/sec; 0.456 sec/batch; 41h:31m:42s remains)
INFO - root - 2017-12-03 07:12:55.437021: step 4930, loss = 0.93, batch loss = 0.83 (26.9 examples/sec; 0.298 sec/batch; 27h:06m:29s remains)
INFO - root - 2017-12-03 07:12:59.134911: step 4940, loss = 1.10, batch loss = 1.00 (20.5 examples/sec; 0.390 sec/batch; 35h:26m:33s remains)
INFO - root - 2017-12-03 07:13:02.849144: step 4950, loss = 1.00, batch loss = 0.90 (17.5 examples/sec; 0.458 sec/batch; 41h:40m:27s remains)
INFO - root - 2017-12-03 07:13:06.561987: step 4960, loss = 0.97, batch loss = 0.87 (23.1 examples/sec; 0.346 sec/batch; 31h:26m:45s remains)
INFO - root - 2017-12-03 07:13:09.932344: step 4970, loss = 0.98, batch loss = 0.88 (19.4 examples/sec; 0.413 sec/batch; 37h:36m:20s remains)
INFO - root - 2017-12-03 07:13:13.602115: step 4980, loss = 1.02, batch loss = 0.92 (24.9 examples/sec; 0.321 sec/batch; 29h:12m:05s remains)
INFO - root - 2017-12-03 07:13:17.056892: step 4990, loss = 1.22, batch loss = 1.12 (20.3 examples/sec; 0.393 sec/batch; 35h:46m:11s remains)
INFO - root - 2017-12-03 07:13:21.085507: step 5000, loss = 0.86, batch loss = 0.76 (20.5 examples/sec; 0.390 sec/batch; 35h:27m:17s remains)
INFO - root - 2017-12-03 07:13:25.196593: step 5010, loss = 1.10, batch loss = 1.00 (19.7 examples/sec; 0.407 sec/batch; 37h:00m:36s remains)
INFO - root - 2017-12-03 07:13:29.223125: step 5020, loss = 1.20, batch loss = 1.11 (23.2 examples/sec; 0.345 sec/batch; 31h:21m:39s remains)
INFO - root - 2017-12-03 07:13:33.099113: step 5030, loss = 1.21, batch loss = 1.11 (20.0 examples/sec; 0.400 sec/batch; 36h:21m:25s remains)
INFO - root - 2017-12-03 07:13:36.930789: step 5040, loss = 0.93, batch loss = 0.83 (17.0 examples/sec; 0.470 sec/batch; 42h:47m:08s remains)
INFO - root - 2017-12-03 07:13:40.708396: step 5050, loss = 0.99, batch loss = 0.90 (23.4 examples/sec; 0.341 sec/batch; 31h:02m:05s remains)
INFO - root - 2017-12-03 07:13:44.665357: step 5060, loss = 1.20, batch loss = 1.10 (22.3 examples/sec; 0.359 sec/batch; 32h:40m:50s remains)
INFO - root - 2017-12-03 07:13:48.435276: step 5070, loss = 0.98, batch loss = 0.88 (23.9 examples/sec; 0.335 sec/batch; 30h:27m:01s remains)
INFO - root - 2017-12-03 07:13:52.547598: step 5080, loss = 0.90, batch loss = 0.80 (17.6 examples/sec; 0.455 sec/batch; 41h:21m:52s remains)
INFO - root - 2017-12-03 07:13:56.291872: step 5090, loss = 0.87, batch loss = 0.77 (22.1 examples/sec; 0.362 sec/batch; 32h:56m:13s remains)
INFO - root - 2017-12-03 07:14:00.152764: step 5100, loss = 0.98, batch loss = 0.88 (21.0 examples/sec; 0.380 sec/batch; 34h:34m:04s remains)
INFO - root - 2017-12-03 07:14:03.921322: step 5110, loss = 1.19, batch loss = 1.09 (23.1 examples/sec; 0.346 sec/batch; 31h:27m:55s remains)
INFO - root - 2017-12-03 07:14:07.669102: step 5120, loss = 1.04, batch loss = 0.94 (23.5 examples/sec; 0.341 sec/batch; 31h:00m:52s remains)
INFO - root - 2017-12-03 07:14:11.143468: step 5130, loss = 0.92, batch loss = 0.82 (19.9 examples/sec; 0.402 sec/batch; 36h:30m:55s remains)
INFO - root - 2017-12-03 07:14:14.693753: step 5140, loss = 0.87, batch loss = 0.77 (42.9 examples/sec; 0.187 sec/batch; 16h:57m:38s remains)
INFO - root - 2017-12-03 07:14:18.372494: step 5150, loss = 1.11, batch loss = 1.01 (23.2 examples/sec; 0.345 sec/batch; 31h:20m:13s remains)
INFO - root - 2017-12-03 07:14:21.928442: step 5160, loss = 0.95, batch loss = 0.86 (21.3 examples/sec; 0.375 sec/batch; 34h:08m:35s remains)
INFO - root - 2017-12-03 07:14:25.816200: step 5170, loss = 0.93, batch loss = 0.84 (20.0 examples/sec; 0.400 sec/batch; 36h:20m:22s remains)
INFO - root - 2017-12-03 07:14:29.718334: step 5180, loss = 0.93, batch loss = 0.84 (18.9 examples/sec; 0.423 sec/batch; 38h:25m:15s remains)
INFO - root - 2017-12-03 07:14:33.776835: step 5190, loss = 0.86, batch loss = 0.76 (21.4 examples/sec; 0.374 sec/batch; 34h:02m:00s remains)
INFO - root - 2017-12-03 07:14:37.268399: step 5200, loss = 0.89, batch loss = 0.80 (18.5 examples/sec; 0.432 sec/batch; 39h:18m:30s remains)
INFO - root - 2017-12-03 07:14:41.044124: step 5210, loss = 0.91, batch loss = 0.81 (21.7 examples/sec; 0.368 sec/batch; 33h:29m:40s remains)
INFO - root - 2017-12-03 07:14:44.869851: step 5220, loss = 1.02, batch loss = 0.92 (40.5 examples/sec; 0.198 sec/batch; 17h:58m:05s remains)
INFO - root - 2017-12-03 07:14:48.276590: step 5230, loss = 0.80, batch loss = 0.71 (20.6 examples/sec; 0.389 sec/batch; 35h:23m:07s remains)
INFO - root - 2017-12-03 07:14:51.797412: step 5240, loss = 0.98, batch loss = 0.88 (43.8 examples/sec; 0.182 sec/batch; 16h:35m:24s remains)
INFO - root - 2017-12-03 07:14:55.170554: step 5250, loss = 1.01, batch loss = 0.91 (17.8 examples/sec; 0.449 sec/batch; 40h:46m:53s remains)
INFO - root - 2017-12-03 07:14:58.800523: step 5260, loss = 0.96, batch loss = 0.86 (21.7 examples/sec; 0.369 sec/batch; 33h:33m:55s remains)
INFO - root - 2017-12-03 07:15:02.405135: step 5270, loss = 0.92, batch loss = 0.82 (23.8 examples/sec; 0.336 sec/batch; 30h:30m:52s remains)
INFO - root - 2017-12-03 07:15:06.302513: step 5280, loss = 0.92, batch loss = 0.82 (22.1 examples/sec; 0.363 sec/batch; 32h:57m:43s remains)
INFO - root - 2017-12-03 07:15:09.843408: step 5290, loss = 0.90, batch loss = 0.80 (21.7 examples/sec; 0.368 sec/batch; 33h:26m:51s remains)
INFO - root - 2017-12-03 07:15:13.558898: step 5300, loss = 1.02, batch loss = 0.92 (20.2 examples/sec; 0.395 sec/batch; 35h:55m:02s remains)
INFO - root - 2017-12-03 07:15:17.256468: step 5310, loss = 0.96, batch loss = 0.86 (18.8 examples/sec; 0.425 sec/batch; 38h:40m:14s remains)
INFO - root - 2017-12-03 07:15:20.447956: step 5320, loss = 0.87, batch loss = 0.77 (30.2 examples/sec; 0.265 sec/batch; 24h:04m:07s remains)
INFO - root - 2017-12-03 07:15:24.234424: step 5330, loss = 1.04, batch loss = 0.94 (17.7 examples/sec; 0.451 sec/batch; 41h:00m:56s remains)
INFO - root - 2017-12-03 07:15:27.858850: step 5340, loss = 0.91, batch loss = 0.81 (23.6 examples/sec; 0.339 sec/batch; 30h:50m:13s remains)
INFO - root - 2017-12-03 07:15:31.560959: step 5350, loss = 0.89, batch loss = 0.80 (26.8 examples/sec; 0.299 sec/batch; 27h:08m:17s remains)
INFO - root - 2017-12-03 07:15:35.545353: step 5360, loss = 0.92, batch loss = 0.82 (20.4 examples/sec; 0.392 sec/batch; 35h:35m:52s remains)
INFO - root - 2017-12-03 07:15:39.324097: step 5370, loss = 1.04, batch loss = 0.94 (20.3 examples/sec; 0.394 sec/batch; 35h:45m:36s remains)
INFO - root - 2017-12-03 07:15:43.194878: step 5380, loss = 0.96, batch loss = 0.86 (22.6 examples/sec; 0.354 sec/batch; 32h:11m:26s remains)
INFO - root - 2017-12-03 07:15:46.773300: step 5390, loss = 1.40, batch loss = 1.30 (22.1 examples/sec; 0.362 sec/batch; 32h:52m:25s remains)
INFO - root - 2017-12-03 07:15:50.677428: step 5400, loss = 1.14, batch loss = 1.04 (20.0 examples/sec; 0.399 sec/batch; 36h:15m:16s remains)
INFO - root - 2017-12-03 07:15:54.685709: step 5410, loss = 1.01, batch loss = 0.91 (16.7 examples/sec; 0.478 sec/batch; 43h:25m:18s remains)
INFO - root - 2017-12-03 07:15:58.081490: step 5420, loss = 0.94, batch loss = 0.84 (21.4 examples/sec; 0.374 sec/batch; 33h:59m:10s remains)
INFO - root - 2017-12-03 07:16:01.968947: step 5430, loss = 1.08, batch loss = 0.98 (22.0 examples/sec; 0.364 sec/batch; 33h:05m:25s remains)
INFO - root - 2017-12-03 07:16:05.584874: step 5440, loss = 1.03, batch loss = 0.93 (20.0 examples/sec; 0.399 sec/batch; 36h:15m:20s remains)
INFO - root - 2017-12-03 07:16:09.617921: step 5450, loss = 1.30, batch loss = 1.20 (20.6 examples/sec; 0.389 sec/batch; 35h:21m:34s remains)
INFO - root - 2017-12-03 07:16:13.233709: step 5460, loss = 0.80, batch loss = 0.71 (23.5 examples/sec; 0.341 sec/batch; 30h:59m:11s remains)
INFO - root - 2017-12-03 07:16:16.670468: step 5470, loss = 1.01, batch loss = 0.91 (23.0 examples/sec; 0.348 sec/batch; 31h:38m:06s remains)
INFO - root - 2017-12-03 07:16:20.619000: step 5480, loss = 1.04, batch loss = 0.95 (22.5 examples/sec; 0.355 sec/batch; 32h:15m:58s remains)
INFO - root - 2017-12-03 07:16:24.536247: step 5490, loss = 1.18, batch loss = 1.08 (22.6 examples/sec; 0.353 sec/batch; 32h:05m:17s remains)
INFO - root - 2017-12-03 07:16:28.430116: step 5500, loss = 1.03, batch loss = 0.93 (23.0 examples/sec; 0.348 sec/batch; 31h:34m:11s remains)
INFO - root - 2017-12-03 07:16:32.374169: step 5510, loss = 1.02, batch loss = 0.92 (27.8 examples/sec; 0.288 sec/batch; 26h:10m:10s remains)
INFO - root - 2017-12-03 07:16:35.951368: step 5520, loss = 1.15, batch loss = 1.06 (34.0 examples/sec; 0.235 sec/batch; 21h:22m:22s remains)
INFO - root - 2017-12-03 07:16:39.852695: step 5530, loss = 1.38, batch loss = 1.29 (19.0 examples/sec; 0.420 sec/batch; 38h:11m:03s remains)
INFO - root - 2017-12-03 07:16:43.361482: step 5540, loss = 0.94, batch loss = 0.84 (23.1 examples/sec; 0.346 sec/batch; 31h:24m:51s remains)
INFO - root - 2017-12-03 07:16:47.183995: step 5550, loss = 0.81, batch loss = 0.71 (16.9 examples/sec; 0.473 sec/batch; 42h:59m:31s remains)
INFO - root - 2017-12-03 07:16:50.771311: step 5560, loss = 0.99, batch loss = 0.89 (18.7 examples/sec; 0.428 sec/batch; 38h:51m:33s remains)
INFO - root - 2017-12-03 07:16:54.295577: step 5570, loss = 1.17, batch loss = 1.07 (19.7 examples/sec; 0.407 sec/batch; 36h:58m:01s remains)
INFO - root - 2017-12-03 07:16:57.738779: step 5580, loss = 1.25, batch loss = 1.15 (23.4 examples/sec; 0.342 sec/batch; 31h:05m:14s remains)
INFO - root - 2017-12-03 07:17:01.117932: step 5590, loss = 1.26, batch loss = 1.16 (16.5 examples/sec; 0.485 sec/batch; 44h:04m:34s remains)
INFO - root - 2017-12-03 07:17:04.784645: step 5600, loss = 1.03, batch loss = 0.93 (20.2 examples/sec; 0.397 sec/batch; 36h:00m:20s remains)
INFO - root - 2017-12-03 07:17:08.517946: step 5610, loss = 1.01, batch loss = 0.91 (21.0 examples/sec; 0.380 sec/batch; 34h:32m:51s remains)
INFO - root - 2017-12-03 07:17:12.135742: step 5620, loss = 1.17, batch loss = 1.07 (25.3 examples/sec; 0.316 sec/batch; 28h:43m:05s remains)
INFO - root - 2017-12-03 07:17:15.996059: step 5630, loss = 0.93, batch loss = 0.83 (16.9 examples/sec; 0.473 sec/batch; 42h:59m:03s remains)
INFO - root - 2017-12-03 07:17:19.761454: step 5640, loss = 0.86, batch loss = 0.76 (20.1 examples/sec; 0.398 sec/batch; 36h:10m:43s remains)
INFO - root - 2017-12-03 07:17:23.657667: step 5650, loss = 0.96, batch loss = 0.86 (18.5 examples/sec; 0.433 sec/batch; 39h:19m:18s remains)
INFO - root - 2017-12-03 07:17:27.157583: step 5660, loss = 0.95, batch loss = 0.85 (23.3 examples/sec; 0.344 sec/batch; 31h:14m:01s remains)
INFO - root - 2017-12-03 07:17:31.095159: step 5670, loss = 0.93, batch loss = 0.83 (17.9 examples/sec; 0.448 sec/batch; 40h:40m:23s remains)
INFO - root - 2017-12-03 07:17:34.775496: step 5680, loss = 1.09, batch loss = 0.99 (17.5 examples/sec; 0.458 sec/batch; 41h:36m:29s remains)
INFO - root - 2017-12-03 07:17:38.499837: step 5690, loss = 1.12, batch loss = 1.02 (22.8 examples/sec; 0.351 sec/batch; 31h:53m:45s remains)
INFO - root - 2017-12-03 07:17:42.059150: step 5700, loss = 0.76, batch loss = 0.66 (27.9 examples/sec; 0.286 sec/batch; 26h:00m:21s remains)
INFO - root - 2017-12-03 07:17:46.072506: step 5710, loss = 1.07, batch loss = 0.98 (22.5 examples/sec; 0.355 sec/batch; 32h:15m:22s remains)
INFO - root - 2017-12-03 07:17:49.975003: step 5720, loss = 1.00, batch loss = 0.90 (22.5 examples/sec; 0.356 sec/batch; 32h:17m:23s remains)
INFO - root - 2017-12-03 07:17:53.514935: step 5730, loss = 1.01, batch loss = 0.91 (19.9 examples/sec; 0.402 sec/batch; 36h:28m:08s remains)
INFO - root - 2017-12-03 07:17:56.954990: step 5740, loss = 1.13, batch loss = 1.03 (22.4 examples/sec; 0.357 sec/batch; 32h:24m:37s remains)
INFO - root - 2017-12-03 07:18:00.944189: step 5750, loss = 1.11, batch loss = 1.01 (18.0 examples/sec; 0.444 sec/batch; 40h:20m:13s remains)
INFO - root - 2017-12-03 07:18:04.779627: step 5760, loss = 1.21, batch loss = 1.11 (18.0 examples/sec; 0.445 sec/batch; 40h:23m:12s remains)
INFO - root - 2017-12-03 07:18:08.583557: step 5770, loss = 0.87, batch loss = 0.77 (22.8 examples/sec; 0.351 sec/batch; 31h:51m:22s remains)
INFO - root - 2017-12-03 07:18:12.055159: step 5780, loss = 1.15, batch loss = 1.05 (22.0 examples/sec; 0.364 sec/batch; 33h:00m:04s remains)
INFO - root - 2017-12-03 07:18:15.840076: step 5790, loss = 1.15, batch loss = 1.05 (24.4 examples/sec; 0.327 sec/batch; 29h:42m:35s remains)
INFO - root - 2017-12-03 07:18:19.667255: step 5800, loss = 1.10, batch loss = 1.01 (18.1 examples/sec; 0.442 sec/batch; 40h:04m:57s remains)
INFO - root - 2017-12-03 07:18:23.438949: step 5810, loss = 0.80, batch loss = 0.70 (18.2 examples/sec; 0.439 sec/batch; 39h:50m:03s remains)
INFO - root - 2017-12-03 07:18:26.852843: step 5820, loss = 0.85, batch loss = 0.75 (18.8 examples/sec; 0.425 sec/batch; 38h:32m:43s remains)
INFO - root - 2017-12-03 07:18:30.589673: step 5830, loss = 0.94, batch loss = 0.84 (18.8 examples/sec; 0.425 sec/batch; 38h:32m:07s remains)
INFO - root - 2017-12-03 07:18:34.353603: step 5840, loss = 0.98, batch loss = 0.88 (19.3 examples/sec; 0.414 sec/batch; 37h:33m:19s remains)
INFO - root - 2017-12-03 07:18:38.263677: step 5850, loss = 0.88, batch loss = 0.78 (17.5 examples/sec; 0.456 sec/batch; 41h:24m:40s remains)
INFO - root - 2017-12-03 07:18:42.074242: step 5860, loss = 0.89, batch loss = 0.79 (30.9 examples/sec; 0.259 sec/batch; 23h:31m:17s remains)
INFO - root - 2017-12-03 07:18:45.329724: step 5870, loss = 1.24, batch loss = 1.14 (17.8 examples/sec; 0.450 sec/batch; 40h:51m:31s remains)
INFO - root - 2017-12-03 07:18:49.105683: step 5880, loss = 1.09, batch loss = 0.99 (19.7 examples/sec; 0.407 sec/batch; 36h:54m:10s remains)
INFO - root - 2017-12-03 07:18:52.732497: step 5890, loss = 1.17, batch loss = 1.07 (26.2 examples/sec; 0.305 sec/batch; 27h:42m:08s remains)
INFO - root - 2017-12-03 07:18:56.237438: step 5900, loss = 1.18, batch loss = 1.08 (35.3 examples/sec; 0.227 sec/batch; 20h:33m:14s remains)
INFO - root - 2017-12-03 07:18:59.713920: step 5910, loss = 1.06, batch loss = 0.96 (42.6 examples/sec; 0.188 sec/batch; 17h:02m:43s remains)
INFO - root - 2017-12-03 07:19:03.542378: step 5920, loss = 0.98, batch loss = 0.88 (22.8 examples/sec; 0.351 sec/batch; 31h:49m:44s remains)
INFO - root - 2017-12-03 07:19:07.162350: step 5930, loss = 1.12, batch loss = 1.02 (20.4 examples/sec; 0.392 sec/batch; 35h:33m:13s remains)
INFO - root - 2017-12-03 07:19:10.376115: step 5940, loss = 1.04, batch loss = 0.94 (23.0 examples/sec; 0.348 sec/batch; 31h:33m:25s remains)
INFO - root - 2017-12-03 07:19:14.015985: step 5950, loss = 1.08, batch loss = 0.98 (17.7 examples/sec; 0.451 sec/batch; 40h:55m:01s remains)
INFO - root - 2017-12-03 07:19:17.512925: step 5960, loss = 0.97, batch loss = 0.87 (17.4 examples/sec; 0.460 sec/batch; 41h:41m:40s remains)
INFO - root - 2017-12-03 07:19:21.047061: step 5970, loss = 0.95, batch loss = 0.85 (21.2 examples/sec; 0.377 sec/batch; 34h:11m:39s remains)
INFO - root - 2017-12-03 07:19:24.939386: step 5980, loss = 1.09, batch loss = 0.99 (16.2 examples/sec; 0.493 sec/batch; 44h:45m:24s remains)
INFO - root - 2017-12-03 07:19:28.713683: step 5990, loss = 1.27, batch loss = 1.16 (24.0 examples/sec; 0.334 sec/batch; 30h:16m:01s remains)
INFO - root - 2017-12-03 07:19:32.425502: step 6000, loss = 0.82, batch loss = 0.72 (19.5 examples/sec; 0.411 sec/batch; 37h:16m:05s remains)
INFO - root - 2017-12-03 07:19:36.000058: step 6010, loss = 1.06, batch loss = 0.95 (19.0 examples/sec; 0.421 sec/batch; 38h:12m:58s remains)
INFO - root - 2017-12-03 07:19:39.476938: step 6020, loss = 1.05, batch loss = 0.94 (21.6 examples/sec; 0.371 sec/batch; 33h:37m:44s remains)
INFO - root - 2017-12-03 07:19:43.299141: step 6030, loss = 1.06, batch loss = 0.95 (23.4 examples/sec; 0.342 sec/batch; 30h:58m:21s remains)
INFO - root - 2017-12-03 07:19:46.849284: step 6040, loss = 0.88, batch loss = 0.77 (38.3 examples/sec; 0.209 sec/batch; 18h:56m:12s remains)
INFO - root - 2017-12-03 07:19:50.666501: step 6050, loss = 1.27, batch loss = 1.16 (39.4 examples/sec; 0.203 sec/batch; 18h:24m:24s remains)
INFO - root - 2017-12-03 07:19:54.235479: step 6060, loss = 0.88, batch loss = 0.78 (21.1 examples/sec; 0.379 sec/batch; 34h:22m:07s remains)
INFO - root - 2017-12-03 07:19:57.744464: step 6070, loss = 1.07, batch loss = 0.97 (18.0 examples/sec; 0.444 sec/batch; 40h:15m:08s remains)
INFO - root - 2017-12-03 07:20:01.446399: step 6080, loss = 1.02, batch loss = 0.92 (22.5 examples/sec; 0.356 sec/batch; 32h:16m:02s remains)
INFO - root - 2017-12-03 07:20:05.045616: step 6090, loss = 1.04, batch loss = 0.93 (23.9 examples/sec; 0.335 sec/batch; 30h:22m:54s remains)
INFO - root - 2017-12-03 07:20:08.821445: step 6100, loss = 1.12, batch loss = 1.02 (18.2 examples/sec; 0.440 sec/batch; 39h:51m:19s remains)
INFO - root - 2017-12-03 07:20:12.588570: step 6110, loss = 1.14, batch loss = 1.03 (22.1 examples/sec; 0.361 sec/batch; 32h:45m:58s remains)
INFO - root - 2017-12-03 07:20:16.082966: step 6120, loss = 1.21, batch loss = 1.10 (28.8 examples/sec; 0.278 sec/batch; 25h:10m:42s remains)
INFO - root - 2017-12-03 07:20:19.663721: step 6130, loss = 1.03, batch loss = 0.93 (21.0 examples/sec; 0.381 sec/batch; 34h:29m:49s remains)
INFO - root - 2017-12-03 07:20:23.433354: step 6140, loss = 1.52, batch loss = 1.41 (18.8 examples/sec; 0.425 sec/batch; 38h:30m:25s remains)
INFO - root - 2017-12-03 07:20:27.192996: step 6150, loss = 1.17, batch loss = 1.06 (22.2 examples/sec; 0.360 sec/batch; 32h:36m:03s remains)
INFO - root - 2017-12-03 07:20:31.068163: step 6160, loss = 1.16, batch loss = 1.05 (17.9 examples/sec; 0.448 sec/batch; 40h:34m:06s remains)
INFO - root - 2017-12-03 07:20:34.803467: step 6170, loss = 1.20, batch loss = 1.10 (22.5 examples/sec; 0.356 sec/batch; 32h:16m:11s remains)
INFO - root - 2017-12-03 07:20:38.299791: step 6180, loss = 0.97, batch loss = 0.87 (25.8 examples/sec; 0.310 sec/batch; 28h:04m:04s remains)
INFO - root - 2017-12-03 07:20:42.113545: step 6190, loss = 1.01, batch loss = 0.91 (17.1 examples/sec; 0.469 sec/batch; 42h:31m:12s remains)
INFO - root - 2017-12-03 07:20:45.975617: step 6200, loss = 1.05, batch loss = 0.95 (25.0 examples/sec; 0.320 sec/batch; 29h:00m:23s remains)
INFO - root - 2017-12-03 07:20:49.626914: step 6210, loss = 1.02, batch loss = 0.91 (18.6 examples/sec; 0.430 sec/batch; 39h:01m:00s remains)
INFO - root - 2017-12-03 07:20:52.910386: step 6220, loss = 1.18, batch loss = 1.07 (28.5 examples/sec; 0.281 sec/batch; 25h:25m:33s remains)
INFO - root - 2017-12-03 07:20:56.676872: step 6230, loss = 1.03, batch loss = 0.93 (22.0 examples/sec; 0.364 sec/batch; 33h:01m:30s remains)
INFO - root - 2017-12-03 07:21:00.179244: step 6240, loss = 1.05, batch loss = 0.94 (22.9 examples/sec; 0.349 sec/batch; 31h:39m:23s remains)
INFO - root - 2017-12-03 07:21:04.041127: step 6250, loss = 0.92, batch loss = 0.81 (21.1 examples/sec; 0.379 sec/batch; 34h:20m:37s remains)
INFO - root - 2017-12-03 07:21:07.875513: step 6260, loss = 1.20, batch loss = 1.09 (20.2 examples/sec; 0.395 sec/batch; 35h:48m:27s remains)
INFO - root - 2017-12-03 07:21:11.016256: step 6270, loss = 1.14, batch loss = 1.03 (43.1 examples/sec; 0.186 sec/batch; 16h:49m:08s remains)
INFO - root - 2017-12-03 07:21:14.588216: step 6280, loss = 1.06, batch loss = 0.96 (35.6 examples/sec; 0.225 sec/batch; 20h:22m:11s remains)
INFO - root - 2017-12-03 07:21:17.959332: step 6290, loss = 1.42, batch loss = 1.32 (23.0 examples/sec; 0.347 sec/batch; 31h:27m:54s remains)
INFO - root - 2017-12-03 07:21:21.767205: step 6300, loss = 1.18, batch loss = 1.07 (16.7 examples/sec; 0.479 sec/batch; 43h:23m:36s remains)
INFO - root - 2017-12-03 07:21:25.205476: step 6310, loss = 1.12, batch loss = 1.02 (24.3 examples/sec; 0.330 sec/batch; 29h:53m:16s remains)
INFO - root - 2017-12-03 07:21:28.905809: step 6320, loss = 0.97, batch loss = 0.86 (19.8 examples/sec; 0.403 sec/batch; 36h:30m:58s remains)
INFO - root - 2017-12-03 07:21:32.621275: step 6330, loss = 1.01, batch loss = 0.90 (21.7 examples/sec; 0.369 sec/batch; 33h:23m:44s remains)
INFO - root - 2017-12-03 07:21:36.291495: step 6340, loss = 1.07, batch loss = 0.97 (22.3 examples/sec; 0.359 sec/batch; 32h:29m:01s remains)
INFO - root - 2017-12-03 07:21:40.047230: step 6350, loss = 1.04, batch loss = 0.93 (17.7 examples/sec; 0.453 sec/batch; 41h:01m:47s remains)
INFO - root - 2017-12-03 07:21:43.889615: step 6360, loss = 1.31, batch loss = 1.21 (22.8 examples/sec; 0.351 sec/batch; 31h:45m:45s remains)
INFO - root - 2017-12-03 07:21:47.697227: step 6370, loss = 0.99, batch loss = 0.89 (22.4 examples/sec; 0.357 sec/batch; 32h:17m:53s remains)
INFO - root - 2017-12-03 07:21:51.323526: step 6380, loss = 1.04, batch loss = 0.94 (18.3 examples/sec; 0.437 sec/batch; 39h:36m:55s remains)
INFO - root - 2017-12-03 07:21:55.011430: step 6390, loss = 1.07, batch loss = 0.96 (17.4 examples/sec; 0.459 sec/batch; 41h:35m:58s remains)
INFO - root - 2017-12-03 07:21:58.601646: step 6400, loss = 1.14, batch loss = 1.03 (21.7 examples/sec; 0.369 sec/batch; 33h:25m:48s remains)
INFO - root - 2017-12-03 07:22:02.557496: step 6410, loss = 1.04, batch loss = 0.93 (18.4 examples/sec; 0.436 sec/batch; 39h:27m:26s remains)
INFO - root - 2017-12-03 07:22:06.340043: step 6420, loss = 1.15, batch loss = 1.04 (18.8 examples/sec; 0.426 sec/batch; 38h:35m:20s remains)
INFO - root - 2017-12-03 07:22:10.115708: step 6430, loss = 1.31, batch loss = 1.20 (19.6 examples/sec; 0.409 sec/batch; 37h:02m:56s remains)
INFO - root - 2017-12-03 07:22:13.990655: step 6440, loss = 1.06, batch loss = 0.96 (17.9 examples/sec; 0.448 sec/batch; 40h:31m:57s remains)
INFO - root - 2017-12-03 07:22:17.868430: step 6450, loss = 0.84, batch loss = 0.74 (21.3 examples/sec; 0.376 sec/batch; 34h:03m:47s remains)
INFO - root - 2017-12-03 07:22:21.593775: step 6460, loss = 1.08, batch loss = 0.97 (23.3 examples/sec; 0.344 sec/batch; 31h:09m:28s remains)
INFO - root - 2017-12-03 07:22:25.402644: step 6470, loss = 1.05, batch loss = 0.94 (19.1 examples/sec; 0.419 sec/batch; 37h:58m:19s remains)
INFO - root - 2017-12-03 07:22:28.798054: step 6480, loss = 0.99, batch loss = 0.89 (21.3 examples/sec; 0.376 sec/batch; 34h:04m:58s remains)
INFO - root - 2017-12-03 07:22:32.445655: step 6490, loss = 1.27, batch loss = 1.17 (18.0 examples/sec; 0.444 sec/batch; 40h:10m:03s remains)
INFO - root - 2017-12-03 07:22:36.444950: step 6500, loss = 1.23, batch loss = 1.13 (18.5 examples/sec; 0.433 sec/batch; 39h:13m:41s remains)
INFO - root - 2017-12-03 07:22:40.278676: step 6510, loss = 1.16, batch loss = 1.05 (23.2 examples/sec; 0.345 sec/batch; 31h:13m:24s remains)
INFO - root - 2017-12-03 07:22:44.045031: step 6520, loss = 1.34, batch loss = 1.23 (22.6 examples/sec; 0.354 sec/batch; 32h:03m:55s remains)
INFO - root - 2017-12-03 07:22:47.869833: step 6530, loss = 1.20, batch loss = 1.09 (17.0 examples/sec; 0.471 sec/batch; 42h:41m:21s remains)
INFO - root - 2017-12-03 07:22:51.717572: step 6540, loss = 0.91, batch loss = 0.80 (21.5 examples/sec; 0.372 sec/batch; 33h:39m:55s remains)
INFO - root - 2017-12-03 07:22:55.096147: step 6550, loss = 0.80, batch loss = 0.70 (17.5 examples/sec; 0.458 sec/batch; 41h:30m:32s remains)
INFO - root - 2017-12-03 07:22:58.800970: step 6560, loss = 1.08, batch loss = 0.97 (34.8 examples/sec; 0.230 sec/batch; 20h:49m:26s remains)
INFO - root - 2017-12-03 07:23:02.343523: step 6570, loss = 0.97, batch loss = 0.87 (23.0 examples/sec; 0.348 sec/batch; 31h:28m:56s remains)
INFO - root - 2017-12-03 07:23:05.892968: step 6580, loss = 0.90, batch loss = 0.80 (21.9 examples/sec; 0.366 sec/batch; 33h:08m:10s remains)
INFO - root - 2017-12-03 07:23:09.537702: step 6590, loss = 0.79, batch loss = 0.68 (18.6 examples/sec; 0.430 sec/batch; 38h:54m:26s remains)
INFO - root - 2017-12-03 07:23:13.122479: step 6600, loss = 1.17, batch loss = 1.06 (23.6 examples/sec; 0.339 sec/batch; 30h:41m:04s remains)
INFO - root - 2017-12-03 07:23:17.016297: step 6610, loss = 0.96, batch loss = 0.85 (17.5 examples/sec; 0.456 sec/batch; 41h:18m:29s remains)
INFO - root - 2017-12-03 07:23:20.480243: step 6620, loss = 0.99, batch loss = 0.88 (42.2 examples/sec; 0.189 sec/batch; 17h:08m:58s remains)
INFO - root - 2017-12-03 07:23:24.107381: step 6630, loss = 1.01, batch loss = 0.91 (17.4 examples/sec; 0.459 sec/batch; 41h:30m:29s remains)
INFO - root - 2017-12-03 07:23:27.932469: step 6640, loss = 0.97, batch loss = 0.86 (21.1 examples/sec; 0.380 sec/batch; 34h:23m:10s remains)
INFO - root - 2017-12-03 07:23:31.664486: step 6650, loss = 1.15, batch loss = 1.04 (25.1 examples/sec; 0.318 sec/batch; 28h:49m:28s remains)
INFO - root - 2017-12-03 07:23:34.658576: step 6660, loss = 1.35, batch loss = 1.24 (30.3 examples/sec; 0.264 sec/batch; 23h:52m:13s remains)
INFO - root - 2017-12-03 07:23:38.484996: step 6670, loss = 1.20, batch loss = 1.09 (19.2 examples/sec; 0.416 sec/batch; 37h:39m:58s remains)
INFO - root - 2017-12-03 07:23:41.790782: step 6680, loss = 0.92, batch loss = 0.81 (20.1 examples/sec; 0.397 sec/batch; 35h:57m:48s remains)
INFO - root - 2017-12-03 07:23:45.572247: step 6690, loss = 1.18, batch loss = 1.08 (22.2 examples/sec; 0.360 sec/batch; 32h:36m:22s remains)
INFO - root - 2017-12-03 07:23:49.438251: step 6700, loss = 1.08, batch loss = 0.97 (20.9 examples/sec; 0.383 sec/batch; 34h:39m:14s remains)
INFO - root - 2017-12-03 07:23:53.582194: step 6710, loss = 1.17, batch loss = 1.07 (18.3 examples/sec; 0.437 sec/batch; 39h:31m:44s remains)
INFO - root - 2017-12-03 07:23:57.293770: step 6720, loss = 1.45, batch loss = 1.34 (22.8 examples/sec; 0.352 sec/batch; 31h:49m:11s remains)
INFO - root - 2017-12-03 07:24:01.154983: step 6730, loss = 1.10, batch loss = 0.99 (19.6 examples/sec; 0.409 sec/batch; 37h:00m:53s remains)
INFO - root - 2017-12-03 07:24:04.540728: step 6740, loss = 0.92, batch loss = 0.81 (17.8 examples/sec; 0.450 sec/batch; 40h:42m:54s remains)
INFO - root - 2017-12-03 07:24:08.205373: step 6750, loss = 0.96, batch loss = 0.85 (24.6 examples/sec; 0.325 sec/batch; 29h:26m:17s remains)
INFO - root - 2017-12-03 07:24:12.180266: step 6760, loss = 1.10, batch loss = 0.99 (21.3 examples/sec; 0.375 sec/batch; 33h:54m:59s remains)
INFO - root - 2017-12-03 07:24:15.895742: step 6770, loss = 1.41, batch loss = 1.30 (25.5 examples/sec; 0.314 sec/batch; 28h:24m:45s remains)
INFO - root - 2017-12-03 07:24:19.755552: step 6780, loss = 1.26, batch loss = 1.16 (19.1 examples/sec; 0.419 sec/batch; 37h:52m:29s remains)
INFO - root - 2017-12-03 07:24:23.434631: step 6790, loss = 1.05, batch loss = 0.95 (24.3 examples/sec; 0.329 sec/batch; 29h:47m:02s remains)
INFO - root - 2017-12-03 07:24:26.724048: step 6800, loss = 0.87, batch loss = 0.76 (18.0 examples/sec; 0.445 sec/batch; 40h:18m:17s remains)
INFO - root - 2017-12-03 07:24:30.604670: step 6810, loss = 0.89, batch loss = 0.78 (22.6 examples/sec; 0.354 sec/batch; 32h:03m:26s remains)
INFO - root - 2017-12-03 07:24:33.817998: step 6820, loss = 0.86, batch loss = 0.76 (23.4 examples/sec; 0.341 sec/batch; 30h:52m:16s remains)
INFO - root - 2017-12-03 07:24:37.468847: step 6830, loss = 1.17, batch loss = 1.06 (24.7 examples/sec; 0.323 sec/batch; 29h:15m:45s remains)
INFO - root - 2017-12-03 07:24:41.314242: step 6840, loss = 0.89, batch loss = 0.78 (22.5 examples/sec; 0.356 sec/batch; 32h:12m:23s remains)
INFO - root - 2017-12-03 07:24:44.793848: step 6850, loss = 0.98, batch loss = 0.87 (21.7 examples/sec; 0.369 sec/batch; 33h:22m:03s remains)
INFO - root - 2017-12-03 07:24:48.623058: step 6860, loss = 1.16, batch loss = 1.05 (17.2 examples/sec; 0.465 sec/batch; 42h:05m:54s remains)
INFO - root - 2017-12-03 07:24:52.519523: step 6870, loss = 0.93, batch loss = 0.82 (21.8 examples/sec; 0.367 sec/batch; 33h:12m:18s remains)
INFO - root - 2017-12-03 07:24:56.255925: step 6880, loss = 0.99, batch loss = 0.88 (20.2 examples/sec; 0.396 sec/batch; 35h:50m:29s remains)
INFO - root - 2017-12-03 07:25:00.204204: step 6890, loss = 1.06, batch loss = 0.95 (21.5 examples/sec; 0.372 sec/batch; 33h:37m:38s remains)
INFO - root - 2017-12-03 07:25:03.851617: step 6900, loss = 1.01, batch loss = 0.90 (23.0 examples/sec; 0.348 sec/batch; 31h:26m:39s remains)
INFO - root - 2017-12-03 07:25:07.244718: step 6910, loss = 1.26, batch loss = 1.15 (18.7 examples/sec; 0.427 sec/batch; 38h:36m:52s remains)
INFO - root - 2017-12-03 07:25:10.801401: step 6920, loss = 1.22, batch loss = 1.11 (22.9 examples/sec; 0.349 sec/batch; 31h:32m:34s remains)
INFO - root - 2017-12-03 07:25:14.981018: step 6930, loss = 0.88, batch loss = 0.77 (17.6 examples/sec; 0.456 sec/batch; 41h:11m:42s remains)
INFO - root - 2017-12-03 07:25:18.894791: step 6940, loss = 1.13, batch loss = 1.02 (17.2 examples/sec; 0.465 sec/batch; 42h:05m:09s remains)
INFO - root - 2017-12-03 07:25:22.046129: step 6950, loss = 0.96, batch loss = 0.85 (42.1 examples/sec; 0.190 sec/batch; 17h:12m:05s remains)
INFO - root - 2017-12-03 07:25:26.075505: step 6960, loss = 1.27, batch loss = 1.16 (17.5 examples/sec; 0.457 sec/batch; 41h:21m:12s remains)
INFO - root - 2017-12-03 07:25:29.804333: step 6970, loss = 1.22, batch loss = 1.11 (20.2 examples/sec; 0.396 sec/batch; 35h:46m:18s remains)
INFO - root - 2017-12-03 07:25:33.469849: step 6980, loss = 0.99, batch loss = 0.88 (21.0 examples/sec; 0.382 sec/batch; 34h:30m:23s remains)
INFO - root - 2017-12-03 07:25:37.216284: step 6990, loss = 0.98, batch loss = 0.87 (24.7 examples/sec; 0.324 sec/batch; 29h:19m:02s remains)
INFO - root - 2017-12-03 07:25:40.282109: step 7000, loss = 1.24, batch loss = 1.13 (28.6 examples/sec; 0.280 sec/batch; 25h:18m:29s remains)
INFO - root - 2017-12-03 07:25:43.849246: step 7010, loss = 0.71, batch loss = 0.60 (21.1 examples/sec; 0.379 sec/batch; 34h:18m:07s remains)
INFO - root - 2017-12-03 07:25:47.600798: step 7020, loss = 1.00, batch loss = 0.89 (22.7 examples/sec; 0.352 sec/batch; 31h:48m:34s remains)
INFO - root - 2017-12-03 07:25:51.431669: step 7030, loss = 1.06, batch loss = 0.95 (18.1 examples/sec; 0.442 sec/batch; 39h:55m:36s remains)
INFO - root - 2017-12-03 07:25:54.666717: step 7040, loss = 0.88, batch loss = 0.77 (23.8 examples/sec; 0.336 sec/batch; 30h:20m:48s remains)
INFO - root - 2017-12-03 07:25:58.388105: step 7050, loss = 0.95, batch loss = 0.84 (22.9 examples/sec; 0.349 sec/batch; 31h:31m:08s remains)
INFO - root - 2017-12-03 07:26:02.022861: step 7060, loss = 1.08, batch loss = 0.97 (23.9 examples/sec; 0.335 sec/batch; 30h:19m:00s remains)
INFO - root - 2017-12-03 07:26:05.227791: step 7070, loss = 0.89, batch loss = 0.78 (22.0 examples/sec; 0.364 sec/batch; 32h:52m:35s remains)
INFO - root - 2017-12-03 07:26:09.018907: step 7080, loss = 1.01, batch loss = 0.90 (20.3 examples/sec; 0.393 sec/batch; 35h:33m:13s remains)
INFO - root - 2017-12-03 07:26:12.817123: step 7090, loss = 0.94, batch loss = 0.83 (27.0 examples/sec; 0.296 sec/batch; 26h:47m:50s remains)
INFO - root - 2017-12-03 07:26:16.518599: step 7100, loss = 0.92, batch loss = 0.81 (18.3 examples/sec; 0.438 sec/batch; 39h:36m:05s remains)
INFO - root - 2017-12-03 07:26:20.227300: step 7110, loss = 0.81, batch loss = 0.70 (25.3 examples/sec; 0.317 sec/batch; 28h:37m:53s remains)
INFO - root - 2017-12-03 07:26:23.751551: step 7120, loss = 0.85, batch loss = 0.74 (30.7 examples/sec; 0.260 sec/batch; 23h:32m:02s remains)
INFO - root - 2017-12-03 07:26:27.361914: step 7130, loss = 0.95, batch loss = 0.84 (17.2 examples/sec; 0.464 sec/batch; 41h:58m:38s remains)
INFO - root - 2017-12-03 07:26:31.132128: step 7140, loss = 0.91, batch loss = 0.80 (22.9 examples/sec; 0.349 sec/batch; 31h:31m:35s remains)
INFO - root - 2017-12-03 07:26:34.996155: step 7150, loss = 0.84, batch loss = 0.73 (18.2 examples/sec; 0.439 sec/batch; 39h:39m:52s remains)
INFO - root - 2017-12-03 07:26:38.827003: step 7160, loss = 1.00, batch loss = 0.89 (21.2 examples/sec; 0.378 sec/batch; 34h:10m:01s remains)
INFO - root - 2017-12-03 07:26:42.661148: step 7170, loss = 1.04, batch loss = 0.93 (22.1 examples/sec; 0.361 sec/batch; 32h:39m:48s remains)
INFO - root - 2017-12-03 07:26:45.897778: step 7180, loss = 0.89, batch loss = 0.78 (25.7 examples/sec; 0.311 sec/batch; 28h:08m:22s remains)
INFO - root - 2017-12-03 07:26:49.738271: step 7190, loss = 0.95, batch loss = 0.84 (25.9 examples/sec; 0.309 sec/batch; 27h:56m:55s remains)
INFO - root - 2017-12-03 07:26:53.736175: step 7200, loss = 1.13, batch loss = 1.02 (17.4 examples/sec; 0.459 sec/batch; 41h:29m:48s remains)
INFO - root - 2017-12-03 07:26:57.542636: step 7210, loss = 0.85, batch loss = 0.74 (21.7 examples/sec; 0.369 sec/batch; 33h:22m:16s remains)
INFO - root - 2017-12-03 07:27:01.397726: step 7220, loss = 0.74, batch loss = 0.63 (24.1 examples/sec; 0.331 sec/batch; 29h:55m:55s remains)
INFO - root - 2017-12-03 07:27:04.961676: step 7230, loss = 0.91, batch loss = 0.80 (23.3 examples/sec; 0.344 sec/batch; 31h:04m:12s remains)
INFO - root - 2017-12-03 07:27:08.772094: step 7240, loss = 0.73, batch loss = 0.61 (22.0 examples/sec; 0.363 sec/batch; 32h:49m:53s remains)
INFO - root - 2017-12-03 07:27:12.308888: step 7250, loss = 0.89, batch loss = 0.78 (24.3 examples/sec; 0.330 sec/batch; 29h:47m:24s remains)
INFO - root - 2017-12-03 07:27:15.772700: step 7260, loss = 0.78, batch loss = 0.67 (44.0 examples/sec; 0.182 sec/batch; 16h:25m:49s remains)
INFO - root - 2017-12-03 07:27:19.197598: step 7270, loss = 0.73, batch loss = 0.62 (43.5 examples/sec; 0.184 sec/batch; 16h:36m:34s remains)
INFO - root - 2017-12-03 07:27:22.431004: step 7280, loss = 0.86, batch loss = 0.75 (19.7 examples/sec; 0.407 sec/batch; 36h:43m:22s remains)
INFO - root - 2017-12-03 07:27:26.370180: step 7290, loss = 0.85, batch loss = 0.74 (16.8 examples/sec; 0.475 sec/batch; 42h:53m:32s remains)
INFO - root - 2017-12-03 07:27:29.889143: step 7300, loss = 0.67, batch loss = 0.56 (20.7 examples/sec; 0.386 sec/batch; 34h:50m:49s remains)
INFO - root - 2017-12-03 07:27:33.687168: step 7310, loss = 0.89, batch loss = 0.78 (23.6 examples/sec; 0.339 sec/batch; 30h:39m:31s remains)
INFO - root - 2017-12-03 07:27:37.430823: step 7320, loss = 0.85, batch loss = 0.74 (17.4 examples/sec; 0.460 sec/batch; 41h:35m:23s remains)
INFO - root - 2017-12-03 07:27:41.162026: step 7330, loss = 0.79, batch loss = 0.68 (21.1 examples/sec; 0.378 sec/batch; 34h:10m:50s remains)
INFO - root - 2017-12-03 07:27:45.246498: step 7340, loss = 0.80, batch loss = 0.69 (20.1 examples/sec; 0.399 sec/batch; 36h:02m:06s remains)
INFO - root - 2017-12-03 07:27:48.857223: step 7350, loss = 0.90, batch loss = 0.79 (26.5 examples/sec; 0.302 sec/batch; 27h:18m:31s remains)
INFO - root - 2017-12-03 07:27:51.781933: step 7360, loss = 0.83, batch loss = 0.72 (42.6 examples/sec; 0.188 sec/batch; 16h:57m:05s remains)
INFO - root - 2017-12-03 07:27:55.374248: step 7370, loss = 1.06, batch loss = 0.95 (22.0 examples/sec; 0.364 sec/batch; 32h:54m:54s remains)
INFO - root - 2017-12-03 07:27:59.052496: step 7380, loss = 1.18, batch loss = 1.07 (21.2 examples/sec; 0.378 sec/batch; 34h:09m:14s remains)
INFO - root - 2017-12-03 07:28:02.613699: step 7390, loss = 0.87, batch loss = 0.76 (17.0 examples/sec; 0.472 sec/batch; 42h:36m:21s remains)
INFO - root - 2017-12-03 07:28:06.253875: step 7400, loss = 0.97, batch loss = 0.86 (18.5 examples/sec; 0.432 sec/batch; 38h:59m:22s remains)
INFO - root - 2017-12-03 07:28:10.158826: step 7410, loss = 0.90, batch loss = 0.79 (23.3 examples/sec; 0.344 sec/batch; 31h:03m:46s remains)
INFO - root - 2017-12-03 07:28:13.886143: step 7420, loss = 0.77, batch loss = 0.66 (18.2 examples/sec; 0.439 sec/batch; 39h:37m:03s remains)
INFO - root - 2017-12-03 07:28:17.450315: step 7430, loss = 0.99, batch loss = 0.88 (22.8 examples/sec; 0.352 sec/batch; 31h:45m:04s remains)
INFO - root - 2017-12-03 07:28:21.418537: step 7440, loss = 0.86, batch loss = 0.75 (20.0 examples/sec; 0.401 sec/batch; 36h:11m:54s remains)
INFO - root - 2017-12-03 07:28:25.482670: step 7450, loss = 0.93, batch loss = 0.82 (18.6 examples/sec; 0.431 sec/batch; 38h:53m:54s remains)
INFO - root - 2017-12-03 07:28:29.060179: step 7460, loss = 0.94, batch loss = 0.83 (17.9 examples/sec; 0.447 sec/batch; 40h:21m:11s remains)
INFO - root - 2017-12-03 07:28:32.587642: step 7470, loss = 0.81, batch loss = 0.69 (28.2 examples/sec; 0.284 sec/batch; 25h:39m:15s remains)
INFO - root - 2017-12-03 07:28:36.360773: step 7480, loss = 0.85, batch loss = 0.74 (21.9 examples/sec; 0.365 sec/batch; 32h:59m:47s remains)
INFO - root - 2017-12-03 07:28:40.264448: step 7490, loss = 0.78, batch loss = 0.67 (18.8 examples/sec; 0.425 sec/batch; 38h:21m:54s remains)
INFO - root - 2017-12-03 07:28:43.988041: step 7500, loss = 1.08, batch loss = 0.96 (25.0 examples/sec; 0.320 sec/batch; 28h:51m:57s remains)
INFO - root - 2017-12-03 07:28:47.558060: step 7510, loss = 1.08, batch loss = 0.97 (18.9 examples/sec; 0.422 sec/batch; 38h:07m:38s remains)
INFO - root - 2017-12-03 07:28:51.043284: step 7520, loss = 0.98, batch loss = 0.86 (31.2 examples/sec; 0.256 sec/batch; 23h:08m:11s remains)
INFO - root - 2017-12-03 07:28:54.566922: step 7530, loss = 0.78, batch loss = 0.67 (23.4 examples/sec; 0.342 sec/batch; 30h:49m:40s remains)
INFO - root - 2017-12-03 07:28:58.294061: step 7540, loss = 0.78, batch loss = 0.67 (17.9 examples/sec; 0.447 sec/batch; 40h:21m:05s remains)
INFO - root - 2017-12-03 07:29:01.929256: step 7550, loss = 0.91, batch loss = 0.80 (28.0 examples/sec; 0.286 sec/batch; 25h:46m:47s remains)
INFO - root - 2017-12-03 07:29:05.622474: step 7560, loss = 1.19, batch loss = 1.07 (20.9 examples/sec; 0.382 sec/batch; 34h:28m:12s remains)
INFO - root - 2017-12-03 07:29:09.401713: step 7570, loss = 0.92, batch loss = 0.80 (19.3 examples/sec; 0.416 sec/batch; 37h:30m:12s remains)
INFO - root - 2017-12-03 07:29:13.140327: step 7580, loss = 0.89, batch loss = 0.78 (22.6 examples/sec; 0.354 sec/batch; 31h:56m:50s remains)
INFO - root - 2017-12-03 07:29:16.436339: step 7590, loss = 0.71, batch loss = 0.59 (35.8 examples/sec; 0.223 sec/batch; 20h:09m:13s remains)
INFO - root - 2017-12-03 07:29:19.519855: step 7600, loss = 0.94, batch loss = 0.83 (41.4 examples/sec; 0.193 sec/batch; 17h:26m:50s remains)
INFO - root - 2017-12-03 07:29:23.476205: step 7610, loss = 0.75, batch loss = 0.64 (22.6 examples/sec; 0.355 sec/batch; 31h:59m:49s remains)
INFO - root - 2017-12-03 07:29:27.082840: step 7620, loss = 0.77, batch loss = 0.65 (25.8 examples/sec; 0.311 sec/batch; 28h:01m:36s remains)
INFO - root - 2017-12-03 07:29:30.776109: step 7630, loss = 1.09, batch loss = 0.98 (22.5 examples/sec; 0.356 sec/batch; 32h:07m:19s remains)
INFO - root - 2017-12-03 07:29:34.639675: step 7640, loss = 0.98, batch loss = 0.87 (17.4 examples/sec; 0.460 sec/batch; 41h:32m:36s remains)
INFO - root - 2017-12-03 07:29:38.323921: step 7650, loss = 0.96, batch loss = 0.85 (22.7 examples/sec; 0.352 sec/batch; 31h:46m:47s remains)
INFO - root - 2017-12-03 07:29:42.328200: step 7660, loss = 1.17, batch loss = 1.05 (24.2 examples/sec; 0.330 sec/batch; 29h:47m:34s remains)
INFO - root - 2017-12-03 07:29:46.405993: step 7670, loss = 1.11, batch loss = 0.99 (21.8 examples/sec; 0.367 sec/batch; 33h:09m:24s remains)
INFO - root - 2017-12-03 07:29:50.155986: step 7680, loss = 1.46, batch loss = 1.34 (17.7 examples/sec; 0.453 sec/batch; 40h:52m:13s remains)
INFO - root - 2017-12-03 07:29:53.895111: step 7690, loss = 0.87, batch loss = 0.75 (23.3 examples/sec; 0.343 sec/batch; 30h:59m:25s remains)
INFO - root - 2017-12-03 07:29:57.879736: step 7700, loss = 1.12, batch loss = 1.00 (17.8 examples/sec; 0.449 sec/batch; 40h:31m:11s remains)
INFO - root - 2017-12-03 07:30:01.362461: step 7710, loss = 0.90, batch loss = 0.78 (20.9 examples/sec; 0.384 sec/batch; 34h:36m:55s remains)
INFO - root - 2017-12-03 07:30:05.024546: step 7720, loss = 1.55, batch loss = 1.43 (35.7 examples/sec; 0.224 sec/batch; 20h:11m:19s remains)
INFO - root - 2017-12-03 07:30:08.852269: step 7730, loss = 1.24, batch loss = 1.12 (22.4 examples/sec; 0.358 sec/batch; 32h:15m:08s remains)
INFO - root - 2017-12-03 07:30:12.735577: step 7740, loss = 1.14, batch loss = 1.01 (23.8 examples/sec; 0.337 sec/batch; 30h:22m:50s remains)
INFO - root - 2017-12-03 07:30:16.348487: step 7750, loss = 1.21, batch loss = 1.09 (43.0 examples/sec; 0.186 sec/batch; 16h:46m:43s remains)
INFO - root - 2017-12-03 07:30:20.106069: step 7760, loss = 1.32, batch loss = 1.20 (18.2 examples/sec; 0.440 sec/batch; 39h:41m:46s remains)
INFO - root - 2017-12-03 07:30:23.716105: step 7770, loss = 1.24, batch loss = 1.11 (24.0 examples/sec; 0.334 sec/batch; 30h:07m:19s remains)
INFO - root - 2017-12-03 07:30:27.594491: step 7780, loss = 1.07, batch loss = 0.95 (16.4 examples/sec; 0.489 sec/batch; 44h:04m:43s remains)
INFO - root - 2017-12-03 07:30:31.499669: step 7790, loss = 1.19, batch loss = 1.07 (22.1 examples/sec; 0.362 sec/batch; 32h:38m:17s remains)
INFO - root - 2017-12-03 07:30:35.314528: step 7800, loss = 1.35, batch loss = 1.22 (21.8 examples/sec; 0.367 sec/batch; 33h:04m:13s remains)
INFO - root - 2017-12-03 07:30:38.984402: step 7810, loss = 1.28, batch loss = 1.15 (22.8 examples/sec; 0.351 sec/batch; 31h:37m:02s remains)
INFO - root - 2017-12-03 07:30:43.051148: step 7820, loss = 0.99, batch loss = 0.87 (17.3 examples/sec; 0.463 sec/batch; 41h:46m:56s remains)
INFO - root - 2017-12-03 07:30:46.716022: step 7830, loss = 1.56, batch loss = 1.44 (26.2 examples/sec; 0.306 sec/batch; 27h:33m:18s remains)
INFO - root - 2017-12-03 07:30:50.569371: step 7840, loss = 1.35, batch loss = 1.20 (18.0 examples/sec; 0.444 sec/batch; 40h:04m:36s remains)
INFO - root - 2017-12-03 07:30:54.235804: step 7850, loss = 0.98, batch loss = 0.84 (21.9 examples/sec; 0.365 sec/batch; 32h:52m:25s remains)
INFO - root - 2017-12-03 07:30:58.068791: step 7860, loss = 1.25, batch loss = 1.10 (18.5 examples/sec; 0.432 sec/batch; 38h:56m:21s remains)
INFO - root - 2017-12-03 07:31:01.912854: step 7870, loss = 1.36, batch loss = 1.21 (22.1 examples/sec; 0.361 sec/batch; 32h:34m:19s remains)
INFO - root - 2017-12-03 07:31:05.619438: step 7880, loss = 1.22, batch loss = 1.08 (22.5 examples/sec; 0.356 sec/batch; 32h:06m:34s remains)
INFO - root - 2017-12-03 07:31:09.726346: step 7890, loss = 1.18, batch loss = 1.03 (17.7 examples/sec; 0.453 sec/batch; 40h:51m:09s remains)
INFO - root - 2017-12-03 07:31:13.590700: step 7900, loss = 1.32, batch loss = 1.17 (17.1 examples/sec; 0.468 sec/batch; 42h:10m:33s remains)
INFO - root - 2017-12-03 07:31:16.953769: step 7910, loss = 1.35, batch loss = 1.20 (21.3 examples/sec; 0.375 sec/batch; 33h:51m:12s remains)
INFO - root - 2017-12-03 07:31:20.597916: step 7920, loss = 1.47, batch loss = 1.32 (18.1 examples/sec; 0.443 sec/batch; 39h:57m:32s remains)
INFO - root - 2017-12-03 07:31:24.533809: step 7930, loss = 1.28, batch loss = 1.13 (17.7 examples/sec; 0.453 sec/batch; 40h:47m:59s remains)
INFO - root - 2017-12-03 07:31:27.746495: step 7940, loss = 1.34, batch loss = 1.19 (22.8 examples/sec; 0.350 sec/batch; 31h:35m:21s remains)
INFO - root - 2017-12-03 07:31:31.486734: step 7950, loss = 1.97, batch loss = 1.82 (19.7 examples/sec; 0.407 sec/batch; 36h:42m:00s remains)
INFO - root - 2017-12-03 07:31:35.105407: step 7960, loss = 1.31, batch loss = 1.16 (27.2 examples/sec; 0.294 sec/batch; 26h:32m:48s remains)
INFO - root - 2017-12-03 07:31:38.423955: step 7970, loss = 1.35, batch loss = 1.20 (21.1 examples/sec; 0.380 sec/batch; 34h:13m:06s remains)
INFO - root - 2017-12-03 07:31:41.534965: step 7980, loss = 1.04, batch loss = 0.89 (41.8 examples/sec; 0.192 sec/batch; 17h:15m:48s remains)
INFO - root - 2017-12-03 07:31:45.326788: step 7990, loss = 0.86, batch loss = 0.70 (18.6 examples/sec; 0.431 sec/batch; 38h:50m:59s remains)
INFO - root - 2017-12-03 07:31:48.786443: step 8000, loss = 1.09, batch loss = 0.93 (17.3 examples/sec; 0.462 sec/batch; 41h:39m:55s remains)
INFO - root - 2017-12-03 07:31:52.207835: step 8010, loss = 1.51, batch loss = 1.35 (27.0 examples/sec; 0.296 sec/batch; 26h:42m:37s remains)
INFO - root - 2017-12-03 07:31:55.796628: step 8020, loss = 1.45, batch loss = 1.29 (21.0 examples/sec; 0.382 sec/batch; 34h:23m:49s remains)
INFO - root - 2017-12-03 07:31:59.720631: step 8030, loss = 1.23, batch loss = 1.07 (19.4 examples/sec; 0.412 sec/batch; 37h:10m:05s remains)
INFO - root - 2017-12-03 07:32:03.470903: step 8040, loss = 1.35, batch loss = 1.19 (20.8 examples/sec; 0.384 sec/batch; 34h:35m:05s remains)
INFO - root - 2017-12-03 07:32:07.379466: step 8050, loss = 1.38, batch loss = 1.22 (18.5 examples/sec; 0.433 sec/batch; 39h:02m:50s remains)
INFO - root - 2017-12-03 07:32:11.222205: step 8060, loss = 1.26, batch loss = 1.10 (23.6 examples/sec; 0.339 sec/batch; 30h:31m:10s remains)
INFO - root - 2017-12-03 07:32:14.672098: step 8070, loss = 1.50, batch loss = 1.33 (25.3 examples/sec; 0.316 sec/batch; 28h:31m:03s remains)
INFO - root - 2017-12-03 07:32:18.507385: step 8080, loss = 1.21, batch loss = 1.05 (22.7 examples/sec; 0.353 sec/batch; 31h:46m:13s remains)
INFO - root - 2017-12-03 07:32:22.019928: step 8090, loss = 1.97, batch loss = 1.81 (18.8 examples/sec; 0.426 sec/batch; 38h:22m:44s remains)
INFO - root - 2017-12-03 07:32:25.736523: step 8100, loss = 2.21, batch loss = 2.05 (30.4 examples/sec; 0.263 sec/batch; 23h:40m:50s remains)
INFO - root - 2017-12-03 07:32:29.234579: step 8110, loss = 1.70, batch loss = 1.54 (23.3 examples/sec; 0.344 sec/batch; 30h:57m:19s remains)
INFO - root - 2017-12-03 07:32:32.782952: step 8120, loss = 1.26, batch loss = 1.09 (20.1 examples/sec; 0.398 sec/batch; 35h:51m:05s remains)
INFO - root - 2017-12-03 07:32:36.615649: step 8130, loss = 1.12, batch loss = 0.96 (24.2 examples/sec; 0.330 sec/batch; 29h:44m:18s remains)
INFO - root - 2017-12-03 07:32:40.112972: step 8140, loss = 1.48, batch loss = 1.32 (22.6 examples/sec; 0.354 sec/batch; 31h:52m:13s remains)
INFO - root - 2017-12-03 07:32:43.898058: step 8150, loss = 1.42, batch loss = 1.26 (20.4 examples/sec; 0.393 sec/batch; 35h:22m:29s remains)
INFO - root - 2017-12-03 07:32:47.368543: step 8160, loss = 1.10, batch loss = 0.93 (30.4 examples/sec; 0.263 sec/batch; 23h:41m:04s remains)
INFO - root - 2017-12-03 07:32:51.284257: step 8170, loss = 1.46, batch loss = 1.30 (22.1 examples/sec; 0.362 sec/batch; 32h:34m:15s remains)
INFO - root - 2017-12-03 07:32:55.217248: step 8180, loss = 1.50, batch loss = 1.34 (25.7 examples/sec; 0.311 sec/batch; 28h:01m:28s remains)
INFO - root - 2017-12-03 07:32:59.069215: step 8190, loss = 1.34, batch loss = 1.17 (22.1 examples/sec; 0.362 sec/batch; 32h:36m:33s remains)
INFO - root - 2017-12-03 07:33:02.315773: step 8200, loss = 1.48, batch loss = 1.31 (36.9 examples/sec; 0.217 sec/batch; 19h:33m:11s remains)
INFO - root - 2017-12-03 07:33:06.043916: step 8210, loss = 2.18, batch loss = 2.01 (21.3 examples/sec; 0.376 sec/batch; 33h:51m:49s remains)
INFO - root - 2017-12-03 07:33:09.532503: step 8220, loss = 2.08, batch loss = 1.91 (22.1 examples/sec; 0.361 sec/batch; 32h:33m:11s remains)
INFO - root - 2017-12-03 07:33:12.863640: step 8230, loss = 1.70, batch loss = 1.53 (30.9 examples/sec; 0.259 sec/batch; 23h:20m:55s remains)
INFO - root - 2017-12-03 07:33:16.441120: step 8240, loss = 2.52, batch loss = 2.35 (20.1 examples/sec; 0.399 sec/batch; 35h:55m:41s remains)
INFO - root - 2017-12-03 07:33:19.725328: step 8250, loss = 1.92, batch loss = 1.75 (21.4 examples/sec; 0.374 sec/batch; 33h:41m:40s remains)
INFO - root - 2017-12-03 07:33:23.135366: step 8260, loss = 1.92, batch loss = 1.75 (17.8 examples/sec; 0.448 sec/batch; 40h:23m:38s remains)
INFO - root - 2017-12-03 07:33:26.617620: step 8270, loss = 2.54, batch loss = 2.37 (16.8 examples/sec; 0.477 sec/batch; 42h:58m:20s remains)
INFO - root - 2017-12-03 07:33:30.374644: step 8280, loss = 2.21, batch loss = 2.04 (23.0 examples/sec; 0.348 sec/batch; 31h:21m:38s remains)
INFO - root - 2017-12-03 07:33:34.134849: step 8290, loss = 2.10, batch loss = 1.92 (17.7 examples/sec; 0.453 sec/batch; 40h:45m:12s remains)
INFO - root - 2017-12-03 07:33:37.714593: step 8300, loss = 2.20, batch loss = 2.03 (22.3 examples/sec; 0.358 sec/batch; 32h:16m:59s remains)
INFO - root - 2017-12-03 07:33:41.596127: step 8310, loss = 1.93, batch loss = 1.76 (18.1 examples/sec; 0.442 sec/batch; 39h:45m:53s remains)
INFO - root - 2017-12-03 07:33:45.231151: step 8320, loss = 2.40, batch loss = 2.22 (21.3 examples/sec; 0.376 sec/batch; 33h:51m:26s remains)
INFO - root - 2017-12-03 07:33:48.721505: step 8330, loss = 2.71, batch loss = 2.54 (23.1 examples/sec; 0.346 sec/batch; 31h:11m:11s remains)
INFO - root - 2017-12-03 07:33:52.375026: step 8340, loss = 2.34, batch loss = 2.16 (22.7 examples/sec; 0.352 sec/batch; 31h:42m:22s remains)
INFO - root - 2017-12-03 07:33:56.191415: step 8350, loss = 2.22, batch loss = 2.02 (23.5 examples/sec; 0.340 sec/batch; 30h:36m:37s remains)
INFO - root - 2017-12-03 07:33:59.518253: step 8360, loss = 2.04, batch loss = 1.84 (18.6 examples/sec; 0.430 sec/batch; 38h:40m:46s remains)
INFO - root - 2017-12-03 07:34:03.243150: step 8370, loss = 2.48, batch loss = 2.28 (22.1 examples/sec; 0.362 sec/batch; 32h:34m:40s remains)
INFO - root - 2017-12-03 07:34:06.974416: step 8380, loss = 3.04, batch loss = 2.84 (25.8 examples/sec; 0.310 sec/batch; 27h:53m:27s remains)
INFO - root - 2017-12-03 07:34:10.657914: step 8390, loss = 2.45, batch loss = 2.25 (20.8 examples/sec; 0.386 sec/batch; 34h:42m:35s remains)
INFO - root - 2017-12-03 07:34:13.978617: step 8400, loss = 2.43, batch loss = 2.24 (18.9 examples/sec; 0.424 sec/batch; 38h:08m:15s remains)
INFO - root - 2017-12-03 07:34:17.938664: step 8410, loss = 2.63, batch loss = 2.43 (20.5 examples/sec; 0.391 sec/batch; 35h:11m:42s remains)
INFO - root - 2017-12-03 07:34:21.577925: step 8420, loss = 2.70, batch loss = 2.50 (21.8 examples/sec; 0.366 sec/batch; 32h:57m:41s remains)
INFO - root - 2017-12-03 07:34:25.381374: step 8430, loss = 3.11, batch loss = 2.87 (22.4 examples/sec; 0.358 sec/batch; 32h:12m:10s remains)
INFO - root - 2017-12-03 07:34:29.236667: step 8440, loss = 3.94, batch loss = 3.69 (17.3 examples/sec; 0.463 sec/batch; 41h:40m:27s remains)
INFO - root - 2017-12-03 07:34:33.026919: step 8450, loss = 2.45, batch loss = 2.20 (23.1 examples/sec; 0.346 sec/batch; 31h:09m:43s remains)
INFO - root - 2017-12-03 07:34:36.673751: step 8460, loss = 3.20, batch loss = 2.95 (35.1 examples/sec; 0.228 sec/batch; 20h:31m:42s remains)
INFO - root - 2017-12-03 07:34:40.107715: step 8470, loss = 2.65, batch loss = 2.40 (17.5 examples/sec; 0.457 sec/batch; 41h:08m:21s remains)
INFO - root - 2017-12-03 07:34:44.027664: step 8480, loss = 3.09, batch loss = 2.83 (18.5 examples/sec; 0.432 sec/batch; 38h:54m:01s remains)
INFO - root - 2017-12-03 07:34:47.500908: step 8490, loss = 3.60, batch loss = 3.25 (22.2 examples/sec; 0.360 sec/batch; 32h:24m:57s remains)
INFO - root - 2017-12-03 07:34:51.222357: step 8500, loss = 3.65, batch loss = 3.29 (21.3 examples/sec; 0.376 sec/batch; 33h:48m:34s remains)
INFO - root - 2017-12-03 07:34:55.281700: step 8510, loss = 3.86, batch loss = 3.51 (19.0 examples/sec; 0.421 sec/batch; 37h:54m:01s remains)
INFO - root - 2017-12-03 07:34:58.962977: step 8520, loss = 3.52, batch loss = 3.16 (18.2 examples/sec; 0.439 sec/batch; 39h:32m:07s remains)
INFO - root - 2017-12-03 07:35:02.768072: step 8530, loss = 3.05, batch loss = 2.69 (25.1 examples/sec; 0.319 sec/batch; 28h:40m:56s remains)
INFO - root - 2017-12-03 07:35:06.036349: step 8540, loss = 4.30, batch loss = 3.94 (17.6 examples/sec; 0.455 sec/batch; 40h:54m:20s remains)
INFO - root - 2017-12-03 07:35:09.257033: step 8550, loss = 4.32, batch loss = 3.96 (32.5 examples/sec; 0.246 sec/batch; 22h:09m:27s remains)
INFO - root - 2017-12-03 07:35:12.790509: step 8560, loss = 3.52, batch loss = 3.17 (21.9 examples/sec; 0.366 sec/batch; 32h:55m:11s remains)
INFO - root - 2017-12-03 07:35:16.676618: step 8570, loss = 4.81, batch loss = 4.42 (23.8 examples/sec; 0.336 sec/batch; 30h:13m:36s remains)
INFO - root - 2017-12-03 07:35:19.916915: step 8580, loss = 4.74, batch loss = 4.36 (25.4 examples/sec; 0.315 sec/batch; 28h:20m:59s remains)
INFO - root - 2017-12-03 07:35:23.389334: step 8590, loss = 3.47, batch loss = 3.09 (21.7 examples/sec; 0.369 sec/batch; 33h:11m:12s remains)
INFO - root - 2017-12-03 07:35:27.218639: step 8600, loss = 5.06, batch loss = 4.67 (18.5 examples/sec; 0.432 sec/batch; 38h:51m:43s remains)
INFO - root - 2017-12-03 07:35:31.140658: step 8610, loss = 5.21, batch loss = 4.83 (20.0 examples/sec; 0.399 sec/batch; 35h:54m:30s remains)
INFO - root - 2017-12-03 07:35:35.032462: step 8620, loss = 5.20, batch loss = 4.82 (24.0 examples/sec; 0.334 sec/batch; 30h:02m:48s remains)
INFO - root - 2017-12-03 07:35:38.638647: step 8630, loss = 5.48, batch loss = 5.08 (21.8 examples/sec; 0.368 sec/batch; 33h:04m:07s remains)
INFO - root - 2017-12-03 07:35:42.190779: step 8640, loss = 4.97, batch loss = 4.56 (23.2 examples/sec; 0.346 sec/batch; 31h:04m:54s remains)
INFO - root - 2017-12-03 07:35:46.092706: step 8650, loss = 4.75, batch loss = 4.34 (23.1 examples/sec; 0.347 sec/batch; 31h:13m:03s remains)
INFO - root - 2017-12-03 07:35:50.005506: step 8660, loss = 5.54, batch loss = 5.12 (19.0 examples/sec; 0.421 sec/batch; 37h:50m:32s remains)
INFO - root - 2017-12-03 07:35:53.896828: step 8670, loss = 6.19, batch loss = 5.78 (20.1 examples/sec; 0.399 sec/batch; 35h:51m:25s remains)
INFO - root - 2017-12-03 07:35:57.791184: step 8680, loss = 7.03, batch loss = 6.61 (17.6 examples/sec; 0.454 sec/batch; 40h:49m:36s remains)
INFO - root - 2017-12-03 07:36:01.662323: step 8690, loss = 6.33, batch loss = 5.91 (23.4 examples/sec; 0.342 sec/batch; 30h:44m:41s remains)
INFO - root - 2017-12-03 07:36:05.271797: step 8700, loss = 7.19, batch loss = 6.77 (19.5 examples/sec; 0.411 sec/batch; 36h:58m:44s remains)
INFO - root - 2017-12-03 07:36:09.044339: step 8710, loss = 8.05, batch loss = 7.63 (22.4 examples/sec; 0.358 sec/batch; 32h:09m:26s remains)
INFO - root - 2017-12-03 07:36:12.828929: step 8720, loss = 7.72, batch loss = 7.30 (19.4 examples/sec; 0.413 sec/batch; 37h:09m:05s remains)
INFO - root - 2017-12-03 07:36:16.605716: step 8730, loss = 7.84, batch loss = 7.41 (18.8 examples/sec; 0.427 sec/batch; 38h:22m:07s remains)
INFO - root - 2017-12-03 07:36:20.288072: step 8740, loss = 8.96, batch loss = 8.52 (19.3 examples/sec; 0.414 sec/batch; 37h:14m:43s remains)
INFO - root - 2017-12-03 07:36:23.992482: step 8750, loss = 8.95, batch loss = 8.51 (26.3 examples/sec; 0.305 sec/batch; 27h:23m:44s remains)
INFO - root - 2017-12-03 07:36:27.389951: step 8760, loss = 9.31, batch loss = 8.87 (22.3 examples/sec; 0.360 sec/batch; 32h:19m:56s remains)
INFO - root - 2017-12-03 07:36:31.146262: step 8770, loss = 10.65, batch loss = 10.21 (17.4 examples/sec; 0.459 sec/batch; 41h:16m:39s remains)
INFO - root - 2017-12-03 07:36:34.623335: step 8780, loss = 10.68, batch loss = 10.23 (20.5 examples/sec; 0.390 sec/batch; 35h:05m:11s remains)
INFO - root - 2017-12-03 07:36:38.134413: step 8790, loss = 10.36, batch loss = 9.91 (16.2 examples/sec; 0.495 sec/batch; 44h:30m:37s remains)
INFO - root - 2017-12-03 07:36:41.684201: step 8800, loss = 15.05, batch loss = 14.59 (17.6 examples/sec; 0.454 sec/batch; 40h:48m:56s remains)
INFO - root - 2017-12-03 07:36:45.678350: step 8810, loss = 15.19, batch loss = 14.73 (16.9 examples/sec; 0.472 sec/batch; 42h:28m:25s remains)
INFO - root - 2017-12-03 07:36:49.431607: step 8820, loss = 16.25, batch loss = 15.76 (22.3 examples/sec; 0.359 sec/batch; 32h:17m:24s remains)
INFO - root - 2017-12-03 07:36:53.082989: step 8830, loss = 14.11, batch loss = 13.49 (22.9 examples/sec; 0.350 sec/batch; 31h:28m:02s remains)
INFO - root - 2017-12-03 07:36:56.775506: step 8840, loss = 15.11, batch loss = 14.46 (24.0 examples/sec; 0.333 sec/batch; 29h:58m:45s remains)
INFO - root - 2017-12-03 07:37:00.280323: step 8850, loss = 15.93, batch loss = 15.27 (43.1 examples/sec; 0.186 sec/batch; 16h:41m:15s remains)
INFO - root - 2017-12-03 07:37:03.810024: step 8860, loss = 16.36, batch loss = 15.68 (25.5 examples/sec; 0.314 sec/batch; 28h:14m:07s remains)
INFO - root - 2017-12-03 07:37:06.666088: step 8870, loss = 17.28, batch loss = 16.59 (22.8 examples/sec; 0.352 sec/batch; 31h:35m:59s remains)
INFO - root - 2017-12-03 07:37:10.405174: step 8880, loss = 20.58, batch loss = 19.81 (17.6 examples/sec; 0.454 sec/batch; 40h:51m:15s remains)
INFO - root - 2017-12-03 07:37:14.262510: step 8890, loss = 21.38, batch loss = 20.60 (23.2 examples/sec; 0.345 sec/batch; 30h:59m:51s remains)
INFO - root - 2017-12-03 07:37:17.664026: step 8900, loss = 22.75, batch loss = 21.97 (21.8 examples/sec; 0.366 sec/batch; 32h:54m:58s remains)
INFO - root - 2017-12-03 07:37:21.358235: step 8910, loss = 26.37, batch loss = 25.59 (20.1 examples/sec; 0.398 sec/batch; 35h:45m:02s remains)
INFO - root - 2017-12-03 07:37:25.100518: step 8920, loss = 28.11, batch loss = 27.32 (18.2 examples/sec; 0.439 sec/batch; 39h:26m:45s remains)
INFO - root - 2017-12-03 07:37:28.793413: step 8930, loss = 23.94, batch loss = 22.28 (22.6 examples/sec; 0.354 sec/batch; 31h:48m:00s remains)
INFO - root - 2017-12-03 07:37:32.560997: step 8940, loss = 25.94, batch loss = 24.28 (20.3 examples/sec; 0.393 sec/batch; 35h:21m:37s remains)
INFO - root - 2017-12-03 07:37:36.187010: step 8950, loss = 25.20, batch loss = 23.52 (21.9 examples/sec; 0.365 sec/batch; 32h:49m:26s remains)
INFO - root - 2017-12-03 07:37:40.094611: step 8960, loss = 28.74, batch loss = 27.06 (22.1 examples/sec; 0.362 sec/batch; 32h:31m:36s remains)
INFO - root - 2017-12-03 07:37:44.005033: step 8970, loss = 29.86, batch loss = 28.18 (17.7 examples/sec; 0.452 sec/batch; 40h:36m:28s remains)
INFO - root - 2017-12-03 07:37:47.667253: step 8980, loss = 35.15, batch loss = 33.46 (19.7 examples/sec; 0.406 sec/batch; 36h:27m:45s remains)
INFO - root - 2017-12-03 07:37:51.249946: step 8990, loss = 37.33, batch loss = 35.63 (24.1 examples/sec; 0.332 sec/batch; 29h:50m:18s remains)
INFO - root - 2017-12-03 07:37:54.795060: step 9000, loss = 41.98, batch loss = 40.14 (20.4 examples/sec; 0.393 sec/batch; 35h:18m:58s remains)
INFO - root - 2017-12-03 07:37:58.822032: step 9010, loss = 52.21, batch loss = 48.54 (17.7 examples/sec; 0.452 sec/batch; 40h:35m:36s remains)
INFO - root - 2017-12-03 07:38:02.483780: step 9020, loss = 58.97, batch loss = 55.27 (21.5 examples/sec; 0.372 sec/batch; 33h:26m:57s remains)
INFO - root - 2017-12-03 07:38:05.880383: step 9030, loss = 69.65, batch loss = 65.84 (23.8 examples/sec; 0.336 sec/batch; 30h:09m:18s remains)
INFO - root - 2017-12-03 07:38:09.279074: step 9040, loss = 86.47, batch loss = 82.63 (22.0 examples/sec; 0.363 sec/batch; 32h:35m:56s remains)
INFO - root - 2017-12-03 07:38:12.643976: step 9050, loss = 107.31, batch loss = 103.46 (23.6 examples/sec; 0.340 sec/batch; 30h:30m:53s remains)
INFO - root - 2017-12-03 07:38:16.072452: step 9060, loss = 120.68, batch loss = 116.81 (22.9 examples/sec; 0.349 sec/batch; 31h:23m:11s remains)
INFO - root - 2017-12-03 07:38:19.466722: step 9070, loss = 177.49, batch loss = 173.47 (23.3 examples/sec; 0.343 sec/batch; 30h:49m:23s remains)
INFO - root - 2017-12-03 07:38:23.068920: step 9080, loss = 247.57, batch loss = 243.38 (28.3 examples/sec; 0.282 sec/batch; 25h:22m:31s remains)
INFO - root - 2017-12-03 07:38:26.616384: step 9090, loss = 414.02, batch loss = 409.77 (22.0 examples/sec; 0.363 sec/batch; 32h:36m:28s remains)
INFO - root - 2017-12-03 07:38:30.434775: step 9100, loss = 582.05, batch loss = 1.26 (24.8 examples/sec; 0.323 sec/batch; 28h:58m:48s remains)
INFO - root - 2017-12-03 07:38:34.339280: step 9110, loss = 582.03, batch loss = 1.24 (21.7 examples/sec; 0.369 sec/batch; 33h:06m:23s remains)
INFO - root - 2017-12-03 07:38:37.805104: step 9120, loss = 582.16, batch loss = 1.37 (21.3 examples/sec; 0.375 sec/batch; 33h:43m:29s remains)
INFO - root - 2017-12-03 07:38:41.380417: step 9130, loss = 581.95, batch loss = 1.16 (25.2 examples/sec; 0.317 sec/batch; 28h:30m:53s remains)
INFO - root - 2017-12-03 07:38:44.852002: step 9140, loss = 581.90, batch loss = 1.12 (22.5 examples/sec; 0.356 sec/batch; 31h:56m:30s remains)
INFO - root - 2017-12-03 07:38:48.758087: step 9150, loss = 581.76, batch loss = 0.97 (21.7 examples/sec; 0.368 sec/batch; 33h:04m:23s remains)
INFO - root - 2017-12-03 07:38:52.662537: step 9160, loss = 582.03, batch loss = 1.24 (19.5 examples/sec; 0.411 sec/batch; 36h:53m:35s remains)
INFO - root - 2017-12-03 07:38:56.379346: step 9170, loss = 581.88, batch loss = 1.09 (21.4 examples/sec; 0.374 sec/batch; 33h:37m:46s remains)
INFO - root - 2017-12-03 07:38:59.938294: step 9180, loss = 581.99, batch loss = 1.20 (16.4 examples/sec; 0.488 sec/batch; 43h:50m:13s remains)
INFO - root - 2017-12-03 07:39:03.608452: step 9190, loss = 582.00, batch loss = 1.21 (24.0 examples/sec; 0.334 sec/batch; 29h:58m:52s remains)
INFO - root - 2017-12-03 07:39:07.115192: step 9200, loss = 582.06, batch loss = 1.27 (25.0 examples/sec; 0.320 sec/batch; 28h:44m:50s remains)
INFO - root - 2017-12-03 07:39:11.139460: step 9210, loss = 581.90, batch loss = 1.11 (19.7 examples/sec; 0.407 sec/batch; 36h:33m:03s remains)
INFO - root - 2017-12-03 07:39:14.889123: step 9220, loss = 582.17, batch loss = 1.38 (20.5 examples/sec; 0.390 sec/batch; 34h:59m:00s remains)
INFO - root - 2017-12-03 07:39:18.621269: step 9230, loss = 581.76, batch loss = 0.97 (19.3 examples/sec; 0.414 sec/batch; 37h:08m:28s remains)
INFO - root - 2017-12-03 07:39:21.951529: step 9240, loss = 581.90, batch loss = 1.12 (19.6 examples/sec; 0.408 sec/batch; 36h:37m:06s remains)
INFO - root - 2017-12-03 07:39:25.612938: step 9250, loss = 582.04, batch loss = 1.25 (29.4 examples/sec; 0.272 sec/batch; 24h:25m:25s remains)
INFO - root - 2017-12-03 07:39:29.459477: step 9260, loss = 581.95, batch loss = 1.16 (18.4 examples/sec; 0.434 sec/batch; 38h:59m:38s remains)
INFO - root - 2017-12-03 07:39:33.125731: step 9270, loss = 582.12, batch loss = 1.34 (20.7 examples/sec; 0.387 sec/batch; 34h:45m:03s remains)
INFO - root - 2017-12-03 07:39:36.835740: step 9280, loss = 582.04, batch loss = 1.25 (20.2 examples/sec; 0.396 sec/batch; 35h:32m:48s remains)
INFO - root - 2017-12-03 07:39:40.274303: step 9290, loss = 582.05, batch loss = 1.26 (18.2 examples/sec; 0.439 sec/batch; 39h:22m:25s remains)
INFO - root - 2017-12-03 07:39:43.861736: step 9300, loss = 581.83, batch loss = 1.04 (22.6 examples/sec; 0.354 sec/batch; 31h:47m:10s remains)
INFO - root - 2017-12-03 07:39:48.019082: step 9310, loss = 581.91, batch loss = 1.12 (22.0 examples/sec; 0.364 sec/batch; 32h:41m:18s remains)
INFO - root - 2017-12-03 07:39:52.061684: step 9320, loss = 582.06, batch loss = 1.27 (21.3 examples/sec; 0.375 sec/batch; 33h:40m:43s remains)
INFO - root - 2017-12-03 07:39:55.724190: step 9330, loss = 581.94, batch loss = 1.15 (33.0 examples/sec; 0.242 sec/batch; 21h:45m:40s remains)
INFO - root - 2017-12-03 07:39:59.432876: step 9340, loss = 582.06, batch loss = 1.27 (19.5 examples/sec; 0.411 sec/batch; 36h:53m:07s remains)
INFO - root - 2017-12-03 07:40:02.903414: step 9350, loss = 582.21, batch loss = 1.42 (21.9 examples/sec; 0.366 sec/batch; 32h:48m:31s remains)
INFO - root - 2017-12-03 07:40:06.811139: step 9360, loss = 581.83, batch loss = 1.05 (22.7 examples/sec; 0.352 sec/batch; 31h:36m:32s remains)
INFO - root - 2017-12-03 07:40:10.325612: step 9370, loss = 582.12, batch loss = 1.33 (24.1 examples/sec; 0.332 sec/batch; 29h:47m:55s remains)
INFO - root - 2017-12-03 07:40:13.941857: step 9380, loss = 581.94, batch loss = 1.15 (29.9 examples/sec; 0.268 sec/batch; 24h:00m:59s remains)
INFO - root - 2017-12-03 07:40:17.727527: step 9390, loss = 581.84, batch loss = 1.06 (23.0 examples/sec; 0.347 sec/batch; 31h:09m:28s remains)
INFO - root - 2017-12-03 07:40:21.139641: step 9400, loss = 582.02, batch loss = 1.24 (24.6 examples/sec; 0.325 sec/batch; 29h:07m:41s remains)
INFO - root - 2017-12-03 07:40:24.793095: step 9410, loss = 582.01, batch loss = 1.22 (22.9 examples/sec; 0.350 sec/batch; 31h:23m:17s remains)
INFO - root - 2017-12-03 07:40:28.434840: step 9420, loss = 582.08, batch loss = 1.29 (17.5 examples/sec; 0.456 sec/batch; 40h:55m:26s remains)
INFO - root - 2017-12-03 07:40:31.934514: step 9430, loss = 581.90, batch loss = 1.12 (18.4 examples/sec; 0.435 sec/batch; 39h:03m:46s remains)
INFO - root - 2017-12-03 07:40:35.388922: step 9440, loss = 582.16, batch loss = 1.38 (23.1 examples/sec; 0.346 sec/batch; 31h:04m:18s remains)
INFO - root - 2017-12-03 07:40:39.089774: step 9450, loss = 581.93, batch loss = 1.14 (16.6 examples/sec; 0.481 sec/batch; 43h:07m:46s remains)
INFO - root - 2017-12-03 07:40:42.750994: step 9460, loss = 582.03, batch loss = 1.25 (22.9 examples/sec; 0.350 sec/batch; 31h:22m:12s remains)
INFO - root - 2017-12-03 07:40:46.441523: step 9470, loss = 581.96, batch loss = 1.18 (27.2 examples/sec; 0.294 sec/batch; 26h:22m:56s remains)
INFO - root - 2017-12-03 07:40:50.472225: step 9480, loss = 581.95, batch loss = 1.16 (18.4 examples/sec; 0.434 sec/batch; 38h:55m:24s remains)
INFO - root - 2017-12-03 07:40:53.565529: step 9490, loss = 581.85, batch loss = 1.06 (24.9 examples/sec; 0.321 sec/batch; 28h:47m:53s remains)
INFO - root - 2017-12-03 07:40:57.008141: step 9500, loss = 582.15, batch loss = 1.37 (32.2 examples/sec; 0.248 sec/batch; 22h:16m:48s remains)
INFO - root - 2017-12-03 07:41:00.502059: step 9510, loss = 582.12, batch loss = 1.33 (40.0 examples/sec; 0.200 sec/batch; 17h:55m:55s remains)
INFO - root - 2017-12-03 07:41:04.041881: step 9520, loss = 581.97, batch loss = 1.18 (18.4 examples/sec; 0.434 sec/batch; 38h:55m:18s remains)
INFO - root - 2017-12-03 07:41:07.698413: step 9530, loss = 582.18, batch loss = 1.39 (22.8 examples/sec; 0.351 sec/batch; 31h:28m:44s remains)
INFO - root - 2017-12-03 07:41:11.292321: step 9540, loss = 581.96, batch loss = 1.17 (23.0 examples/sec; 0.348 sec/batch; 31h:12m:13s remains)
INFO - root - 2017-12-03 07:41:14.913918: step 9550, loss = 582.14, batch loss = 1.36 (19.4 examples/sec; 0.413 sec/batch; 37h:02m:06s remains)
INFO - root - 2017-12-03 07:41:18.641870: step 9560, loss = 581.87, batch loss = 1.09 (23.4 examples/sec; 0.342 sec/batch; 30h:40m:06s remains)
INFO - root - 2017-12-03 07:41:22.324393: step 9570, loss = 581.96, batch loss = 1.17 (18.6 examples/sec; 0.429 sec/batch; 38h:30m:15s remains)
INFO - root - 2017-12-03 07:41:26.025209: step 9580, loss = 582.00, batch loss = 1.22 (25.7 examples/sec; 0.311 sec/batch; 27h:53m:57s remains)
INFO - root - 2017-12-03 07:41:29.760479: step 9590, loss = 582.15, batch loss = 1.37 (18.7 examples/sec; 0.429 sec/batch; 38h:26m:41s remains)
INFO - root - 2017-12-03 07:41:33.384922: step 9600, loss = 582.07, batch loss = 1.29 (25.0 examples/sec; 0.320 sec/batch; 28h:44m:19s remains)
INFO - root - 2017-12-03 07:41:36.952993: step 9610, loss = 581.93, batch loss = 1.15 (23.4 examples/sec; 0.342 sec/batch; 30h:40m:25s remains)
INFO - root - 2017-12-03 07:41:40.778020: step 9620, loss = 582.09, batch loss = 1.30 (23.3 examples/sec; 0.344 sec/batch; 30h:49m:38s remains)
INFO - root - 2017-12-03 07:41:44.206252: step 9630, loss = 581.87, batch loss = 1.08 (26.2 examples/sec; 0.305 sec/batch; 27h:22m:58s remains)
INFO - root - 2017-12-03 07:41:47.653425: step 9640, loss = 582.05, batch loss = 1.26 (23.5 examples/sec; 0.340 sec/batch; 30h:31m:04s remains)
INFO - root - 2017-12-03 07:41:51.108841: step 9650, loss = 582.05, batch loss = 1.26 (21.6 examples/sec; 0.370 sec/batch; 33h:10m:06s remains)
INFO - root - 2017-12-03 07:41:54.950471: step 9660, loss = 582.03, batch loss = 1.24 (20.3 examples/sec; 0.394 sec/batch; 35h:21m:55s remains)
INFO - root - 2017-12-03 07:41:58.404916: step 9670, loss = 582.04, batch loss = 1.26 (17.4 examples/sec; 0.460 sec/batch; 41h:17m:32s remains)
INFO - root - 2017-12-03 07:42:02.086836: step 9680, loss = 582.05, batch loss = 1.27 (27.2 examples/sec; 0.294 sec/batch; 26h:22m:43s remains)
INFO - root - 2017-12-03 07:42:05.464005: step 9690, loss = 581.95, batch loss = 1.16 (24.6 examples/sec; 0.326 sec/batch; 29h:12m:23s remains)
INFO - root - 2017-12-03 07:42:09.306140: step 9700, loss = 582.09, batch loss = 1.30 (22.8 examples/sec; 0.350 sec/batch; 31h:25m:36s remains)
INFO - root - 2017-12-03 07:42:13.323909: step 9710, loss = 582.21, batch loss = 1.42 (21.4 examples/sec; 0.374 sec/batch; 33h:32m:53s remains)
INFO - root - 2017-12-03 07:42:17.332977: step 9720, loss = 582.30, batch loss = 1.51 (20.2 examples/sec; 0.397 sec/batch; 35h:34m:25s remains)
INFO - root - 2017-12-03 07:42:20.907276: step 9730, loss = 581.98, batch loss = 1.19 (20.1 examples/sec; 0.397 sec/batch; 35h:36m:12s remains)
INFO - root - 2017-12-03 07:42:24.639828: step 9740, loss = 581.85, batch loss = 1.07 (19.1 examples/sec; 0.419 sec/batch; 37h:35m:10s remains)
INFO - root - 2017-12-03 07:42:28.424101: step 9750, loss = 581.93, batch loss = 1.14 (23.3 examples/sec; 0.343 sec/batch; 30h:45m:26s remains)
INFO - root - 2017-12-03 07:42:32.296926: step 9760, loss = 581.85, batch loss = 1.06 (22.4 examples/sec; 0.357 sec/batch; 31h:57m:58s remains)
INFO - root - 2017-12-03 07:42:36.225910: step 9770, loss = 582.10, batch loss = 1.31 (22.7 examples/sec; 0.353 sec/batch; 31h:36m:08s remains)
INFO - root - 2017-12-03 07:42:40.143697: step 9780, loss = 582.08, batch loss = 1.29 (22.8 examples/sec; 0.351 sec/batch; 31h:30m:35s remains)
INFO - root - 2017-12-03 07:42:43.173067: step 9790, loss = 581.86, batch loss = 1.07 (21.7 examples/sec; 0.369 sec/batch; 33h:04m:14s remains)
INFO - root - 2017-12-03 07:42:46.996014: step 9800, loss = 581.85, batch loss = 1.06 (22.5 examples/sec; 0.356 sec/batch; 31h:54m:41s remains)
INFO - root - 2017-12-03 07:42:50.257711: step 9810, loss = 582.04, batch loss = 1.26 (22.5 examples/sec; 0.355 sec/batch; 31h:50m:02s remains)
INFO - root - 2017-12-03 07:42:53.221530: step 9820, loss = 581.96, batch loss = 1.18 (44.8 examples/sec; 0.179 sec/batch; 16h:00m:19s remains)
INFO - root - 2017-12-03 07:42:56.802259: step 9830, loss = 582.05, batch loss = 1.26 (30.1 examples/sec; 0.265 sec/batch; 23h:47m:12s remains)
INFO - root - 2017-12-03 07:43:00.333101: step 9840, loss = 582.07, batch loss = 1.28 (20.0 examples/sec; 0.401 sec/batch; 35h:54m:04s remains)
INFO - root - 2017-12-03 07:43:04.197927: step 9850, loss = 581.87, batch loss = 1.08 (24.6 examples/sec; 0.325 sec/batch; 29h:07m:55s remains)
INFO - root - 2017-12-03 07:43:08.115758: step 9860, loss = 582.03, batch loss = 1.24 (25.4 examples/sec; 0.315 sec/batch; 28h:16m:05s remains)
INFO - root - 2017-12-03 07:43:11.714970: step 9870, loss = 581.97, batch loss = 1.19 (24.5 examples/sec; 0.327 sec/batch; 29h:16m:25s remains)
INFO - root - 2017-12-03 07:43:15.189295: step 9880, loss = 581.85, batch loss = 1.06 (25.7 examples/sec; 0.311 sec/batch; 27h:54m:38s remains)
INFO - root - 2017-12-03 07:43:18.072326: step 9890, loss = 581.95, batch loss = 1.16 (40.4 examples/sec; 0.198 sec/batch; 17h:43m:49s remains)
INFO - root - 2017-12-03 07:43:21.947990: step 9900, loss = 582.05, batch loss = 1.27 (18.5 examples/sec; 0.432 sec/batch; 38h:42m:03s remains)
INFO - root - 2017-12-03 07:43:25.682977: step 9910, loss = 581.89, batch loss = 1.10 (20.0 examples/sec; 0.400 sec/batch; 35h:48m:18s remains)
INFO - root - 2017-12-03 07:43:29.709987: step 9920, loss = 581.88, batch loss = 1.10 (18.0 examples/sec; 0.444 sec/batch; 39h:44m:58s remains)
INFO - root - 2017-12-03 07:43:33.400272: step 9930, loss = 581.95, batch loss = 1.16 (21.0 examples/sec; 0.380 sec/batch; 34h:04m:43s remains)
INFO - root - 2017-12-03 07:43:37.312303: step 9940, loss = 581.86, batch loss = 1.07 (23.4 examples/sec; 0.342 sec/batch; 30h:39m:07s remains)
INFO - root - 2017-12-03 07:43:41.065710: step 9950, loss = 581.98, batch loss = 1.19 (18.9 examples/sec; 0.423 sec/batch; 37h:52m:18s remains)
INFO - root - 2017-12-03 07:43:44.617320: step 9960, loss = 581.78, batch loss = 0.99 (21.6 examples/sec; 0.371 sec/batch; 33h:12m:32s remains)
INFO - root - 2017-12-03 07:43:48.417259: step 9970, loss = 582.13, batch loss = 1.34 (23.6 examples/sec; 0.339 sec/batch; 30h:20m:42s remains)
INFO - root - 2017-12-03 07:43:51.900711: step 9980, loss = 582.01, batch loss = 1.23 (24.9 examples/sec; 0.322 sec/batch; 28h:48m:28s remains)
INFO - root - 2017-12-03 07:43:55.294974: step 9990, loss = 581.93, batch loss = 1.15 (21.6 examples/sec; 0.371 sec/batch; 33h:11m:57s remains)
INFO - root - 2017-12-03 07:43:59.025438: step 10000, loss = 582.04, batch loss = 1.25 (18.3 examples/sec; 0.437 sec/batch; 39h:06m:48s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-10000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-10000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-03 07:44:03.193761: step 10010, loss = 581.87, batch loss = 1.09 (23.2 examples/sec; 0.345 sec/batch; 30h:52m:11s remains)
INFO - root - 2017-12-03 07:44:06.767365: step 10020, loss = 581.91, batch loss = 1.12 (28.9 examples/sec; 0.277 sec/batch; 24h:47m:36s remains)
INFO - root - 2017-12-03 07:44:10.329314: step 10030, loss = 581.95, batch loss = 1.17 (23.6 examples/sec; 0.338 sec/batch; 30h:18m:46s remains)
INFO - root - 2017-12-03 07:44:13.866301: step 10040, loss = 581.96, batch loss = 1.18 (17.9 examples/sec; 0.448 sec/batch; 40h:08m:03s remains)
INFO - root - 2017-12-03 07:44:17.153319: step 10050, loss = 581.90, batch loss = 1.11 (24.4 examples/sec; 0.327 sec/batch; 29h:19m:56s remains)
INFO - root - 2017-12-03 07:44:20.896618: step 10060, loss = 581.87, batch loss = 1.08 (22.5 examples/sec; 0.356 sec/batch; 31h:52m:57s remains)
INFO - root - 2017-12-03 07:44:24.723117: step 10070, loss = 582.08, batch loss = 1.29 (20.1 examples/sec; 0.399 sec/batch; 35h:44m:03s remains)
INFO - root - 2017-12-03 07:44:28.217101: step 10080, loss = 582.03, batch loss = 1.24 (22.7 examples/sec; 0.353 sec/batch; 31h:35m:12s remains)
INFO - root - 2017-12-03 07:44:31.652535: step 10090, loss = 582.10, batch loss = 1.31 (22.6 examples/sec; 0.353 sec/batch; 31h:38m:20s remains)
INFO - root - 2017-12-03 07:44:35.138617: step 10100, loss = 582.05, batch loss = 1.27 (18.4 examples/sec; 0.434 sec/batch; 38h:53m:52s remains)
INFO - root - 2017-12-03 07:44:39.185390: step 10110, loss = 581.99, batch loss = 1.20 (18.2 examples/sec; 0.439 sec/batch; 39h:18m:29s remains)
INFO - root - 2017-12-03 07:44:42.619005: step 10120, loss = 581.87, batch loss = 1.08 (17.5 examples/sec; 0.458 sec/batch; 41h:02m:55s remains)
INFO - root - 2017-12-03 07:44:46.313859: step 10130, loss = 581.90, batch loss = 1.12 (25.0 examples/sec; 0.321 sec/batch; 28h:42m:32s remains)
INFO - root - 2017-12-03 07:44:50.091650: step 10140, loss = 581.95, batch loss = 1.16 (17.2 examples/sec; 0.466 sec/batch; 41h:42m:12s remains)
INFO - root - 2017-12-03 07:44:53.849840: step 10150, loss = 581.96, batch loss = 1.17 (25.7 examples/sec; 0.311 sec/batch; 27h:49m:28s remains)
INFO - root - 2017-12-03 07:44:57.775305: step 10160, loss = 582.05, batch loss = 1.26 (23.8 examples/sec; 0.336 sec/batch; 30h:04m:12s remains)
INFO - root - 2017-12-03 07:45:01.430573: step 10170, loss = 582.09, batch loss = 1.30 (18.8 examples/sec; 0.425 sec/batch; 38h:00m:42s remains)
INFO - root - 2017-12-03 07:45:05.114410: step 10180, loss = 581.91, batch loss = 1.12 (22.9 examples/sec; 0.349 sec/batch; 31h:15m:49s remains)
INFO - root - 2017-12-03 07:45:08.957711: step 10190, loss = 582.05, batch loss = 1.26 (20.6 examples/sec; 0.389 sec/batch; 34h:48m:23s remains)
INFO - root - 2017-12-03 07:45:12.651697: step 10200, loss = 582.03, batch loss = 1.24 (17.3 examples/sec; 0.461 sec/batch; 41h:17m:38s remains)
INFO - root - 2017-12-03 07:45:16.615830: step 10210, loss = 581.91, batch loss = 1.12 (20.4 examples/sec; 0.392 sec/batch; 35h:07m:43s remains)
INFO - root - 2017-12-03 07:45:19.825662: step 10220, loss = 581.85, batch loss = 1.07 (18.9 examples/sec; 0.424 sec/batch; 37h:54m:50s remains)
INFO - root - 2017-12-03 07:45:23.789940: step 10230, loss = 581.83, batch loss = 1.04 (18.3 examples/sec; 0.437 sec/batch; 39h:05m:53s remains)
INFO - root - 2017-12-03 07:45:27.282329: step 10240, loss = 581.88, batch loss = 1.09 (22.8 examples/sec; 0.351 sec/batch; 31h:25m:41s remains)
INFO - root - 2017-12-03 07:45:30.838181: step 10250, loss = 581.93, batch loss = 1.14 (22.2 examples/sec; 0.360 sec/batch; 32h:12m:56s remains)
INFO - root - 2017-12-03 07:45:34.668637: step 10260, loss = 581.89, batch loss = 1.10 (23.0 examples/sec; 0.348 sec/batch; 31h:08m:09s remains)
INFO - root - 2017-12-03 07:45:38.344161: step 10270, loss = 582.06, batch loss = 1.27 (22.6 examples/sec; 0.354 sec/batch; 31h:39m:43s remains)
INFO - root - 2017-12-03 07:45:41.848108: step 10280, loss = 582.02, batch loss = 1.24 (21.6 examples/sec; 0.370 sec/batch; 33h:08m:02s remains)
INFO - root - 2017-12-03 07:45:45.597421: step 10290, loss = 582.03, batch loss = 1.24 (18.0 examples/sec; 0.444 sec/batch; 39h:46m:15s remains)
INFO - root - 2017-12-03 07:45:49.391687: step 10300, loss = 582.05, batch loss = 1.26 (21.0 examples/sec; 0.380 sec/batch; 34h:02m:02s remains)
INFO - root - 2017-12-03 07:45:53.354238: step 10310, loss = 581.94, batch loss = 1.15 (23.3 examples/sec; 0.343 sec/batch; 30h:43m:20s remains)
INFO - root - 2017-12-03 07:45:56.783589: step 10320, loss = 582.26, batch loss = 1.47 (25.0 examples/sec; 0.320 sec/batch; 28h:38m:20s remains)
INFO - root - 2017-12-03 07:46:00.766277: step 10330, loss = 582.09, batch loss = 1.30 (23.3 examples/sec; 0.344 sec/batch; 30h:46m:13s remains)
INFO - root - 2017-12-03 07:46:04.430176: step 10340, loss = 582.09, batch loss = 1.30 (25.1 examples/sec; 0.318 sec/batch; 28h:29m:46s remains)
INFO - root - 2017-12-03 07:46:08.264776: step 10350, loss = 581.86, batch loss = 1.07 (18.8 examples/sec; 0.426 sec/batch; 38h:09m:44s remains)
INFO - root - 2017-12-03 07:46:11.539124: step 10360, loss = 582.05, batch loss = 1.26 (19.5 examples/sec; 0.410 sec/batch; 36h:39m:29s remains)
INFO - root - 2017-12-03 07:46:14.831598: step 10370, loss = 582.08, batch loss = 1.29 (32.9 examples/sec; 0.243 sec/batch; 21h:44m:24s remains)
INFO - root - 2017-12-03 07:46:18.633560: step 10380, loss = 582.18, batch loss = 1.40 (22.0 examples/sec; 0.364 sec/batch; 32h:34m:46s remains)
INFO - root - 2017-12-03 07:46:22.332303: step 10390, loss = 581.97, batch loss = 1.19 (26.3 examples/sec; 0.304 sec/batch; 27h:09m:56s remains)
INFO - root - 2017-12-03 07:46:25.698522: step 10400, loss = 582.20, batch loss = 1.41 (17.5 examples/sec; 0.456 sec/batch; 40h:48m:47s remains)
INFO - root - 2017-12-03 07:46:29.457173: step 10410, loss = 581.83, batch loss = 1.04 (20.4 examples/sec; 0.392 sec/batch; 35h:05m:37s remains)
INFO - root - 2017-12-03 07:46:33.058744: step 10420, loss = 582.30, batch loss = 1.51 (24.7 examples/sec; 0.324 sec/batch; 29h:00m:36s remains)
INFO - root - 2017-12-03 07:46:36.482956: step 10430, loss = 581.93, batch loss = 1.14 (23.1 examples/sec; 0.346 sec/batch; 30h:59m:39s remains)
INFO - root - 2017-12-03 07:46:39.815594: step 10440, loss = 581.93, batch loss = 1.14 (21.1 examples/sec; 0.379 sec/batch; 33h:56m:09s remains)
INFO - root - 2017-12-03 07:46:43.199747: step 10450, loss = 581.89, batch loss = 1.10 (31.2 examples/sec; 0.256 sec/batch; 22h:55m:06s remains)
INFO - root - 2017-12-03 07:46:47.077710: step 10460, loss = 581.95, batch loss = 1.16 (18.2 examples/sec; 0.439 sec/batch; 39h:15m:31s remains)
INFO - root - 2017-12-03 07:46:50.713393: step 10470, loss = 581.99, batch loss = 1.20 (25.5 examples/sec; 0.314 sec/batch; 28h:05m:15s remains)
INFO - root - 2017-12-03 07:46:54.091763: step 10480, loss = 581.94, batch loss = 1.15 (22.9 examples/sec; 0.349 sec/batch; 31h:11m:08s remains)
INFO - root - 2017-12-03 07:46:57.820870: step 10490, loss = 582.31, batch loss = 1.53 (18.4 examples/sec; 0.435 sec/batch; 38h:53m:36s remains)
INFO - root - 2017-12-03 07:47:01.430372: step 10500, loss = 581.94, batch loss = 1.15 (22.7 examples/sec; 0.353 sec/batch; 31h:34m:41s remains)
INFO - root - 2017-12-03 07:47:05.161330: step 10510, loss = 581.81, batch loss = 1.02 (21.1 examples/sec; 0.380 sec/batch; 33h:59m:18s remains)
INFO - root - 2017-12-03 07:47:08.761641: step 10520, loss = 582.08, batch loss = 1.29 (21.4 examples/sec; 0.374 sec/batch; 33h:25m:08s remains)
INFO - root - 2017-12-03 07:47:12.452450: step 10530, loss = 581.95, batch loss = 1.16 (26.0 examples/sec; 0.308 sec/batch; 27h:31m:43s remains)
INFO - root - 2017-12-03 07:47:15.720070: step 10540, loss = 581.98, batch loss = 1.19 (18.6 examples/sec; 0.429 sec/batch; 38h:21m:51s remains)
INFO - root - 2017-12-03 07:47:19.248905: step 10550, loss = 582.03, batch loss = 1.24 (19.8 examples/sec; 0.405 sec/batch; 36h:12m:40s remains)
INFO - root - 2017-12-03 07:47:22.764115: step 10560, loss = 582.19, batch loss = 1.40 (23.5 examples/sec; 0.341 sec/batch; 30h:27m:28s remains)
INFO - root - 2017-12-03 07:47:26.625030: step 10570, loss = 581.98, batch loss = 1.19 (22.6 examples/sec; 0.355 sec/batch; 31h:42m:11s remains)
INFO - root - 2017-12-03 07:47:30.417645: step 10580, loss = 582.01, batch loss = 1.22 (17.0 examples/sec; 0.470 sec/batch; 41h:59m:11s remains)
INFO - root - 2017-12-03 07:47:34.035840: step 10590, loss = 582.07, batch loss = 1.28 (18.3 examples/sec; 0.437 sec/batch; 39h:06m:46s remains)
INFO - root - 2017-12-03 07:47:37.788681: step 10600, loss = 582.04, batch loss = 1.26 (22.4 examples/sec; 0.357 sec/batch; 31h:57m:39s remains)
INFO - root - 2017-12-03 07:47:41.612192: step 10610, loss = 582.07, batch loss = 1.28 (17.6 examples/sec; 0.454 sec/batch; 40h:35m:36s remains)
INFO - root - 2017-12-03 07:47:44.958869: step 10620, loss = 581.84, batch loss = 1.05 (17.8 examples/sec; 0.448 sec/batch; 40h:04m:33s remains)
INFO - root - 2017-12-03 07:47:48.557264: step 10630, loss = 581.94, batch loss = 1.15 (21.2 examples/sec; 0.377 sec/batch; 33h:43m:28s remains)
INFO - root - 2017-12-03 07:47:52.345645: step 10640, loss = 582.02, batch loss = 1.23 (18.8 examples/sec; 0.425 sec/batch; 37h:58m:39s remains)
INFO - root - 2017-12-03 07:47:56.046771: step 10650, loss = 581.89, batch loss = 1.10 (21.5 examples/sec; 0.373 sec/batch; 33h:19m:30s remains)
INFO - root - 2017-12-03 07:47:59.883867: step 10660, loss = 581.87, batch loss = 1.09 (23.1 examples/sec; 0.346 sec/batch; 30h:56m:19s remains)
INFO - root - 2017-12-03 07:48:03.295221: step 10670, loss = 581.97, batch loss = 1.18 (23.0 examples/sec; 0.348 sec/batch; 31h:05m:06s remains)
INFO - root - 2017-12-03 07:48:06.819030: step 10680, loss = 582.01, batch loss = 1.22 (31.5 examples/sec; 0.254 sec/batch; 22h:41m:05s remains)
INFO - root - 2017-12-03 07:48:10.560405: step 10690, loss = 581.90, batch loss = 1.12 (24.6 examples/sec; 0.325 sec/batch; 29h:04m:34s remains)
INFO - root - 2017-12-03 07:48:13.517243: step 10700, loss = 581.91, batch loss = 1.12 (32.9 examples/sec; 0.243 sec/batch; 21h:44m:22s remains)
INFO - root - 2017-12-03 07:48:17.397365: step 10710, loss = 582.21, batch loss = 1.43 (26.1 examples/sec; 0.306 sec/batch; 27h:23m:13s remains)
INFO - root - 2017-12-03 07:48:20.934168: step 10720, loss = 581.93, batch loss = 1.15 (19.6 examples/sec; 0.408 sec/batch; 36h:29m:14s remains)
INFO - root - 2017-12-03 07:48:24.420866: step 10730, loss = 581.91, batch loss = 1.12 (43.3 examples/sec; 0.185 sec/batch; 16h:31m:15s remains)
INFO - root - 2017-12-03 07:48:27.982674: step 10740, loss = 581.89, batch loss = 1.10 (24.5 examples/sec; 0.327 sec/batch; 29h:11m:58s remains)
INFO - root - 2017-12-03 07:48:31.805345: step 10750, loss = 581.97, batch loss = 1.18 (19.8 examples/sec; 0.405 sec/batch; 36h:10m:20s remains)
INFO - root - 2017-12-03 07:48:35.577213: step 10760, loss = 582.04, batch loss = 1.26 (20.1 examples/sec; 0.397 sec/batch; 35h:31m:20s remains)
INFO - root - 2017-12-03 07:48:38.923946: step 10770, loss = 582.07, batch loss = 1.29 (18.8 examples/sec; 0.425 sec/batch; 37h:59m:52s remains)
INFO - root - 2017-12-03 07:48:42.602460: step 10780, loss = 582.02, batch loss = 1.23 (21.4 examples/sec; 0.373 sec/batch; 33h:20m:02s remains)
INFO - root - 2017-12-03 07:48:46.133268: step 10790, loss = 581.93, batch loss = 1.14 (33.2 examples/sec; 0.241 sec/batch; 21h:31m:36s remains)
INFO - root - 2017-12-03 07:48:49.835987: step 10800, loss = 581.96, batch loss = 1.18 (22.5 examples/sec; 0.356 sec/batch; 31h:49m:46s remains)
INFO - root - 2017-12-03 07:48:53.618952: step 10810, loss = 581.92, batch loss = 1.13 (18.6 examples/sec; 0.429 sec/batch; 38h:21m:46s remains)
INFO - root - 2017-12-03 07:48:56.996200: step 10820, loss = 582.18, batch loss = 1.39 (19.5 examples/sec; 0.410 sec/batch; 36h:40m:10s remains)
INFO - root - 2017-12-03 07:49:00.878591: step 10830, loss = 581.90, batch loss = 1.11 (18.7 examples/sec; 0.427 sec/batch; 38h:10m:58s remains)
INFO - root - 2017-12-03 07:49:04.039606: step 10840, loss = 581.99, batch loss = 1.20 (26.0 examples/sec; 0.307 sec/batch; 27h:27m:42s remains)
INFO - root - 2017-12-03 07:49:07.798039: step 10850, loss = 581.80, batch loss = 1.01 (19.3 examples/sec; 0.415 sec/batch; 37h:03m:27s remains)
INFO - root - 2017-12-03 07:49:11.167255: step 10860, loss = 581.92, batch loss = 1.14 (17.8 examples/sec; 0.450 sec/batch; 40h:10m:42s remains)
INFO - root - 2017-12-03 07:49:14.611310: step 10870, loss = 581.96, batch loss = 1.18 (23.4 examples/sec; 0.342 sec/batch; 30h:31m:13s remains)
INFO - root - 2017-12-03 07:49:18.357438: step 10880, loss = 581.87, batch loss = 1.08 (22.1 examples/sec; 0.362 sec/batch; 32h:21m:50s remains)
INFO - root - 2017-12-03 07:49:21.942802: step 10890, loss = 581.95, batch loss = 1.17 (19.5 examples/sec; 0.410 sec/batch; 36h:37m:15s remains)
INFO - root - 2017-12-03 07:49:25.795903: step 10900, loss = 582.07, batch loss = 1.28 (22.0 examples/sec; 0.363 sec/batch; 32h:25m:08s remains)
INFO - root - 2017-12-03 07:49:29.750750: step 10910, loss = 581.90, batch loss = 1.11 (18.1 examples/sec; 0.443 sec/batch; 39h:33m:11s remains)
INFO - root - 2017-12-03 07:49:33.520457: step 10920, loss = 582.17, batch loss = 1.38 (25.1 examples/sec; 0.318 sec/batch; 28h:27m:01s remains)
INFO - root - 2017-12-03 07:49:36.983278: step 10930, loss = 582.10, batch loss = 1.31 (36.5 examples/sec; 0.219 sec/batch; 19h:35m:00s remains)
INFO - root - 2017-12-03 07:49:40.746355: step 10940, loss = 582.01, batch loss = 1.22 (17.6 examples/sec; 0.455 sec/batch; 40h:40m:06s remains)
INFO - root - 2017-12-03 07:49:44.437114: step 10950, loss = 582.28, batch loss = 1.49 (22.4 examples/sec; 0.357 sec/batch; 31h:54m:25s remains)
INFO - root - 2017-12-03 07:49:48.233637: step 10960, loss = 581.96, batch loss = 1.17 (23.1 examples/sec; 0.346 sec/batch; 30h:53m:05s remains)
INFO - root - 2017-12-03 07:49:52.203841: step 10970, loss = 581.91, batch loss = 1.12 (21.6 examples/sec; 0.370 sec/batch; 33h:02m:41s remains)
INFO - root - 2017-12-03 07:49:55.484787: step 10980, loss = 581.90, batch loss = 1.12 (18.2 examples/sec; 0.438 sec/batch; 39h:09m:34s remains)
INFO - root - 2017-12-03 07:49:59.119438: step 10990, loss = 582.01, batch loss = 1.22 (24.8 examples/sec; 0.323 sec/batch; 28h:51m:13s remains)
INFO - root - 2017-12-03 07:50:03.064013: step 11000, loss = 581.95, batch loss = 1.17 (22.9 examples/sec; 0.349 sec/batch; 31h:08m:49s remains)
INFO - root - 2017-12-03 07:50:06.780938: step 11010, loss = 582.08, batch loss = 1.29 (23.7 examples/sec; 0.338 sec/batch; 30h:08m:37s remains)
INFO - root - 2017-12-03 07:50:10.331818: step 11020, loss = 581.93, batch loss = 1.14 (20.3 examples/sec; 0.393 sec/batch; 35h:06m:28s remains)
INFO - root - 2017-12-03 07:50:14.138869: step 11030, loss = 582.00, batch loss = 1.21 (25.8 examples/sec; 0.310 sec/batch; 27h:43m:21s remains)
INFO - root - 2017-12-03 07:50:17.501063: step 11040, loss = 582.04, batch loss = 1.25 (43.8 examples/sec; 0.183 sec/batch; 16h:18m:36s remains)
INFO - root - 2017-12-03 07:50:20.304046: step 11050, loss = 582.02, batch loss = 1.23 (18.7 examples/sec; 0.428 sec/batch; 38h:11m:18s remains)
INFO - root - 2017-12-03 07:50:23.751302: step 11060, loss = 581.92, batch loss = 1.13 (22.4 examples/sec; 0.357 sec/batch; 31h:51m:46s remains)
INFO - root - 2017-12-03 07:50:27.581036: step 11070, loss = 581.92, batch loss = 1.13 (19.4 examples/sec; 0.413 sec/batch; 36h:52m:28s remains)
INFO - root - 2017-12-03 07:50:31.109471: step 11080, loss = 581.88, batch loss = 1.09 (17.4 examples/sec; 0.461 sec/batch; 41h:08m:21s remains)
INFO - root - 2017-12-03 07:50:34.657678: step 11090, loss = 582.17, batch loss = 1.38 (18.7 examples/sec; 0.428 sec/batch; 38h:14m:54s remains)
INFO - root - 2017-12-03 07:50:38.193823: step 11100, loss = 581.87, batch loss = 1.09 (22.9 examples/sec; 0.349 sec/batch; 31h:09m:25s remains)
INFO - root - 2017-12-03 07:50:41.839216: step 11110, loss = 581.91, batch loss = 1.13 (22.4 examples/sec; 0.357 sec/batch; 31h:53m:30s remains)
INFO - root - 2017-12-03 07:50:45.090479: step 11120, loss = 581.95, batch loss = 1.17 (30.1 examples/sec; 0.266 sec/batch; 23h:43m:44s remains)
INFO - root - 2017-12-03 07:50:48.444349: step 11130, loss = 581.89, batch loss = 1.10 (22.9 examples/sec; 0.350 sec/batch; 31h:14m:04s remains)
INFO - root - 2017-12-03 07:50:52.147716: step 11140, loss = 581.80, batch loss = 1.01 (24.2 examples/sec; 0.331 sec/batch; 29h:31m:27s remains)
INFO - root - 2017-12-03 07:50:55.660440: step 11150, loss = 582.09, batch loss = 1.30 (19.2 examples/sec; 0.416 sec/batch; 37h:07m:29s remains)
INFO - root - 2017-12-03 07:50:59.609500: step 11160, loss = 581.90, batch loss = 1.11 (22.8 examples/sec; 0.352 sec/batch; 31h:23m:07s remains)
INFO - root - 2017-12-03 07:51:03.447369: step 11170, loss = 581.92, batch loss = 1.14 (22.9 examples/sec; 0.350 sec/batch; 31h:14m:06s remains)
INFO - root - 2017-12-03 07:51:07.036763: step 11180, loss = 581.97, batch loss = 1.19 (22.0 examples/sec; 0.364 sec/batch; 32h:28m:43s remains)
INFO - root - 2017-12-03 07:51:10.694948: step 11190, loss = 582.17, batch loss = 1.38 (24.8 examples/sec; 0.322 sec/batch; 28h:45m:27s remains)
INFO - root - 2017-12-03 07:51:14.616516: step 11200, loss = 582.13, batch loss = 1.34 (22.5 examples/sec; 0.356 sec/batch; 31h:44m:36s remains)
INFO - root - 2017-12-03 07:51:18.511308: step 11210, loss = 581.98, batch loss = 1.19 (23.6 examples/sec; 0.339 sec/batch; 30h:15m:56s remains)
INFO - root - 2017-12-03 07:51:22.364525: step 11220, loss = 581.95, batch loss = 1.16 (18.6 examples/sec; 0.430 sec/batch; 38h:21m:31s remains)
INFO - root - 2017-12-03 07:51:26.142551: step 11230, loss = 582.00, batch loss = 1.21 (20.7 examples/sec; 0.386 sec/batch; 34h:26m:50s remains)
INFO - root - 2017-12-03 07:51:29.744155: step 11240, loss = 581.97, batch loss = 1.18 (24.5 examples/sec; 0.326 sec/batch; 29h:07m:04s remains)
INFO - root - 2017-12-03 07:51:33.255744: step 11250, loss = 581.93, batch loss = 1.14 (21.0 examples/sec; 0.380 sec/batch; 33h:56m:18s remains)
INFO - root - 2017-12-03 07:51:37.133636: step 11260, loss = 581.90, batch loss = 1.12 (22.1 examples/sec; 0.363 sec/batch; 32h:21m:42s remains)
INFO - root - 2017-12-03 07:51:40.683328: step 11270, loss = 581.85, batch loss = 1.06 (18.5 examples/sec; 0.431 sec/batch; 38h:29m:23s remains)
INFO - root - 2017-12-03 07:51:43.989526: step 11280, loss = 582.03, batch loss = 1.24 (22.2 examples/sec; 0.361 sec/batch; 32h:13m:34s remains)
INFO - root - 2017-12-03 07:51:47.776395: step 11290, loss = 582.00, batch loss = 1.22 (19.7 examples/sec; 0.407 sec/batch; 36h:19m:07s remains)
INFO - root - 2017-12-03 07:51:51.447926: step 11300, loss = 582.01, batch loss = 1.22 (18.2 examples/sec; 0.439 sec/batch; 39h:12m:10s remains)
INFO - root - 2017-12-03 07:51:55.081870: step 11310, loss = 582.10, batch loss = 1.32 (23.6 examples/sec; 0.339 sec/batch; 30h:13m:55s remains)
INFO - root - 2017-12-03 07:51:58.736360: step 11320, loss = 581.90, batch loss = 1.11 (26.2 examples/sec; 0.305 sec/batch; 27h:11m:59s remains)
INFO - root - 2017-12-03 07:52:02.281673: step 11330, loss = 581.90, batch loss = 1.11 (21.7 examples/sec; 0.368 sec/batch; 32h:49m:36s remains)
INFO - root - 2017-12-03 07:52:06.227679: step 11340, loss = 581.91, batch loss = 1.12 (24.0 examples/sec; 0.333 sec/batch; 29h:40m:54s remains)
INFO - root - 2017-12-03 07:52:09.635089: step 11350, loss = 582.07, batch loss = 1.28 (22.3 examples/sec; 0.359 sec/batch; 32h:01m:16s remains)
INFO - root - 2017-12-03 07:52:13.018866: step 11360, loss = 581.85, batch loss = 1.07 (22.6 examples/sec; 0.354 sec/batch; 31h:34m:57s remains)
INFO - root - 2017-12-03 07:52:17.000689: step 11370, loss = 581.98, batch loss = 1.19 (19.0 examples/sec; 0.422 sec/batch; 37h:37m:05s remains)
INFO - root - 2017-12-03 07:52:20.549563: step 11380, loss = 581.82, batch loss = 1.04 (22.7 examples/sec; 0.352 sec/batch; 31h:24m:09s remains)
INFO - root - 2017-12-03 07:52:24.442307: step 11390, loss = 581.88, batch loss = 1.09 (21.8 examples/sec; 0.367 sec/batch; 32h:42m:49s remains)
INFO - root - 2017-12-03 07:52:27.737680: step 11400, loss = 581.90, batch loss = 1.11 (18.4 examples/sec; 0.436 sec/batch; 38h:53m:03s remains)
INFO - root - 2017-12-03 07:52:31.334535: step 11410, loss = 582.09, batch loss = 1.30 (18.8 examples/sec; 0.426 sec/batch; 38h:02m:24s remains)
INFO - root - 2017-12-03 07:52:35.203893: step 11420, loss = 581.89, batch loss = 1.10 (20.5 examples/sec; 0.391 sec/batch; 34h:49m:49s remains)
INFO - root - 2017-12-03 07:52:38.726522: step 11430, loss = 582.15, batch loss = 1.36 (23.5 examples/sec; 0.340 sec/batch; 30h:18m:35s remains)
INFO - root - 2017-12-03 07:52:42.253056: step 11440, loss = 582.00, batch loss = 1.21 (45.3 examples/sec; 0.177 sec/batch; 15h:45m:01s remains)
INFO - root - 2017-12-03 07:52:45.515054: step 11450, loss = 581.87, batch loss = 1.08 (22.0 examples/sec; 0.363 sec/batch; 32h:23m:04s remains)
INFO - root - 2017-12-03 07:52:49.126620: step 11460, loss = 581.85, batch loss = 1.07 (22.4 examples/sec; 0.358 sec/batch; 31h:53m:27s remains)
INFO - root - 2017-12-03 07:52:52.621263: step 11470, loss = 581.93, batch loss = 1.15 (32.3 examples/sec; 0.248 sec/batch; 22h:06m:55s remains)
INFO - root - 2017-12-03 07:52:56.205075: step 11480, loss = 582.10, batch loss = 1.32 (23.5 examples/sec; 0.340 sec/batch; 30h:19m:44s remains)
INFO - root - 2017-12-03 07:52:59.753740: step 11490, loss = 582.03, batch loss = 1.24 (23.9 examples/sec; 0.334 sec/batch; 29h:47m:19s remains)
INFO - root - 2017-12-03 07:53:03.388363: step 11500, loss = 582.02, batch loss = 1.23 (24.6 examples/sec; 0.326 sec/batch; 29h:01m:44s remains)
INFO - root - 2017-12-03 07:53:07.180949: step 11510, loss = 582.03, batch loss = 1.24 (23.0 examples/sec; 0.348 sec/batch; 31h:01m:00s remains)
INFO - root - 2017-12-03 07:53:10.973533: step 11520, loss = 581.83, batch loss = 1.05 (18.4 examples/sec; 0.434 sec/batch; 38h:39m:51s remains)
INFO - root - 2017-12-03 07:53:14.777175: step 11530, loss = 581.87, batch loss = 1.09 (23.7 examples/sec; 0.338 sec/batch; 30h:08m:13s remains)
INFO - root - 2017-12-03 07:53:18.012390: step 11540, loss = 582.13, batch loss = 1.34 (18.3 examples/sec; 0.436 sec/batch; 38h:52m:19s remains)
INFO - root - 2017-12-03 07:53:21.813318: step 11550, loss = 581.98, batch loss = 1.19 (19.7 examples/sec; 0.406 sec/batch; 36h:13m:08s remains)
INFO - root - 2017-12-03 07:53:25.804648: step 11560, loss = 581.82, batch loss = 1.04 (23.6 examples/sec; 0.338 sec/batch; 30h:09m:29s remains)
INFO - root - 2017-12-03 07:53:29.544925: step 11570, loss = 581.93, batch loss = 1.15 (16.4 examples/sec; 0.487 sec/batch; 43h:22m:35s remains)
INFO - root - 2017-12-03 07:53:33.269265: step 11580, loss = 582.21, batch loss = 1.42 (24.3 examples/sec; 0.329 sec/batch; 29h:21m:19s remains)
INFO - root - 2017-12-03 07:53:36.746249: step 11590, loss = 581.88, batch loss = 1.10 (20.1 examples/sec; 0.398 sec/batch; 35h:29m:03s remains)
INFO - root - 2017-12-03 07:53:40.266861: step 11600, loss = 581.91, batch loss = 1.13 (17.7 examples/sec; 0.453 sec/batch; 40h:22m:40s remains)
INFO - root - 2017-12-03 07:53:44.062280: step 11610, loss = 581.81, batch loss = 1.03 (24.3 examples/sec; 0.330 sec/batch; 29h:22m:38s remains)
INFO - root - 2017-12-03 07:53:47.225594: step 11620, loss = 582.04, batch loss = 1.26 (17.7 examples/sec; 0.453 sec/batch; 40h:23m:09s remains)
INFO - root - 2017-12-03 07:53:50.779520: step 11630, loss = 581.84, batch loss = 1.05 (20.6 examples/sec; 0.388 sec/batch; 34h:37m:08s remains)
INFO - root - 2017-12-03 07:53:54.334794: step 11640, loss = 582.17, batch loss = 1.38 (44.5 examples/sec; 0.180 sec/batch; 16h:01m:19s remains)
INFO - root - 2017-12-03 07:53:57.760537: step 11650, loss = 582.00, batch loss = 1.21 (22.9 examples/sec; 0.350 sec/batch; 31h:08m:57s remains)
INFO - root - 2017-12-03 07:54:01.433010: step 11660, loss = 582.02, batch loss = 1.24 (24.1 examples/sec; 0.332 sec/batch; 29h:37m:11s remains)
INFO - root - 2017-12-03 07:54:05.414410: step 11670, loss = 581.84, batch loss = 1.06 (18.7 examples/sec; 0.428 sec/batch; 38h:06m:55s remains)
INFO - root - 2017-12-03 07:54:09.014443: step 11680, loss = 581.86, batch loss = 1.07 (24.4 examples/sec; 0.328 sec/batch; 29h:11m:47s remains)
INFO - root - 2017-12-03 07:54:12.901570: step 11690, loss = 581.96, batch loss = 1.18 (20.5 examples/sec; 0.391 sec/batch; 34h:49m:56s remains)
INFO - root - 2017-12-03 07:54:16.492654: step 11700, loss = 581.92, batch loss = 1.13 (25.5 examples/sec; 0.314 sec/batch; 27h:58m:21s remains)
INFO - root - 2017-12-03 07:54:20.056520: step 11710, loss = 581.91, batch loss = 1.13 (29.9 examples/sec; 0.268 sec/batch; 23h:51m:29s remains)
INFO - root - 2017-12-03 07:54:23.997993: step 11720, loss = 582.10, batch loss = 1.31 (23.9 examples/sec; 0.334 sec/batch; 29h:47m:51s remains)
INFO - root - 2017-12-03 07:54:27.875074: step 11730, loss = 581.83, batch loss = 1.04 (22.1 examples/sec; 0.361 sec/batch; 32h:11m:15s remains)
INFO - root - 2017-12-03 07:54:31.720836: step 11740, loss = 581.95, batch loss = 1.16 (18.9 examples/sec; 0.422 sec/batch; 37h:37m:59s remains)
INFO - root - 2017-12-03 07:54:35.395596: step 11750, loss = 581.84, batch loss = 1.05 (23.3 examples/sec; 0.344 sec/batch; 30h:37m:36s remains)
INFO - root - 2017-12-03 07:54:39.343788: step 11760, loss = 581.94, batch loss = 1.16 (22.5 examples/sec; 0.355 sec/batch; 31h:39m:46s remains)
INFO - root - 2017-12-03 07:54:43.162128: step 11770, loss = 582.09, batch loss = 1.31 (19.0 examples/sec; 0.422 sec/batch; 37h:34m:08s remains)
INFO - root - 2017-12-03 07:54:46.538945: step 11780, loss = 581.86, batch loss = 1.07 (23.0 examples/sec; 0.348 sec/batch; 31h:02m:45s remains)
INFO - root - 2017-12-03 07:54:50.102176: step 11790, loss = 582.10, batch loss = 1.32 (25.0 examples/sec; 0.320 sec/batch; 28h:27m:58s remains)
INFO - root - 2017-12-03 07:54:54.037642: step 11800, loss = 581.97, batch loss = 1.18 (22.3 examples/sec; 0.358 sec/batch; 31h:56m:07s remains)
INFO - root - 2017-12-03 07:54:58.059471: step 11810, loss = 581.95, batch loss = 1.16 (18.7 examples/sec; 0.429 sec/batch; 38h:11m:08s remains)
INFO - root - 2017-12-03 07:55:01.656758: step 11820, loss = 582.13, batch loss = 1.34 (24.6 examples/sec; 0.325 sec/batch; 28h:56m:25s remains)
INFO - root - 2017-12-03 07:55:05.094507: step 11830, loss = 582.03, batch loss = 1.25 (23.0 examples/sec; 0.347 sec/batch; 30h:56m:27s remains)
INFO - root - 2017-12-03 07:55:08.632024: step 11840, loss = 581.95, batch loss = 1.16 (17.9 examples/sec; 0.446 sec/batch; 39h:45m:24s remains)
INFO - root - 2017-12-03 07:55:12.718389: step 11850, loss = 581.93, batch loss = 1.14 (17.9 examples/sec; 0.447 sec/batch; 39h:46m:16s remains)
INFO - root - 2017-12-03 07:55:16.348048: step 11860, loss = 582.01, batch loss = 1.22 (21.0 examples/sec; 0.380 sec/batch; 33h:51m:08s remains)
INFO - root - 2017-12-03 07:55:19.984074: step 11870, loss = 582.21, batch loss = 1.42 (24.3 examples/sec; 0.330 sec/batch; 29h:22m:41s remains)
INFO - root - 2017-12-03 07:55:23.708650: step 11880, loss = 582.09, batch loss = 1.31 (20.8 examples/sec; 0.385 sec/batch; 34h:17m:44s remains)
INFO - root - 2017-12-03 07:55:26.908074: step 11890, loss = 581.97, batch loss = 1.19 (42.5 examples/sec; 0.188 sec/batch; 16h:44m:43s remains)
INFO - root - 2017-12-03 07:55:30.436537: step 11900, loss = 582.30, batch loss = 1.51 (24.2 examples/sec; 0.331 sec/batch; 29h:26m:55s remains)
INFO - root - 2017-12-03 07:55:34.037143: step 11910, loss = 582.08, batch loss = 1.29 (18.1 examples/sec; 0.441 sec/batch; 39h:15m:39s remains)
INFO - root - 2017-12-03 07:55:37.405099: step 11920, loss = 581.79, batch loss = 1.01 (18.4 examples/sec; 0.434 sec/batch; 38h:36m:54s remains)
INFO - root - 2017-12-03 07:55:40.960188: step 11930, loss = 582.04, batch loss = 1.25 (24.4 examples/sec; 0.328 sec/batch; 29h:11m:42s remains)
INFO - root - 2017-12-03 07:55:44.717897: step 11940, loss = 582.15, batch loss = 1.36 (19.4 examples/sec; 0.412 sec/batch; 36h:39m:18s remains)
INFO - root - 2017-12-03 07:55:47.719450: step 11950, loss = 581.95, batch loss = 1.16 (19.9 examples/sec; 0.402 sec/batch; 35h:48m:04s remains)
INFO - root - 2017-12-03 07:55:51.295610: step 11960, loss = 581.88, batch loss = 1.10 (20.5 examples/sec; 0.390 sec/batch; 34h:43m:54s remains)
INFO - root - 2017-12-03 07:55:55.097928: step 11970, loss = 581.84, batch loss = 1.05 (20.3 examples/sec; 0.393 sec/batch; 35h:01m:04s remains)
INFO - root - 2017-12-03 07:55:58.920683: step 11980, loss = 582.00, batch loss = 1.21 (19.5 examples/sec; 0.411 sec/batch; 36h:34m:28s remains)
INFO - root - 2017-12-03 07:56:02.829824: step 11990, loss = 581.89, batch loss = 1.11 (18.9 examples/sec; 0.423 sec/batch; 37h:36m:59s remains)
INFO - root - 2017-12-03 07:56:06.673304: step 12000, loss = 581.91, batch loss = 1.12 (22.7 examples/sec; 0.352 sec/batch; 31h:20m:00s remains)
INFO - root - 2017-12-03 07:56:10.070228: step 12010, loss = 581.94, batch loss = 1.15 (44.3 examples/sec; 0.181 sec/batch; 16h:04m:27s remains)
INFO - root - 2017-12-03 07:56:13.740228: step 12020, loss = 581.97, batch loss = 1.18 (24.9 examples/sec; 0.321 sec/batch; 28h:35m:42s remains)
INFO - root - 2017-12-03 07:56:17.150301: step 12030, loss = 581.91, batch loss = 1.12 (43.2 examples/sec; 0.185 sec/batch; 16h:29m:22s remains)
INFO - root - 2017-12-03 07:56:20.476123: step 12040, loss = 581.97, batch loss = 1.19 (21.5 examples/sec; 0.373 sec/batch; 33h:09m:36s remains)
INFO - root - 2017-12-03 07:56:24.045265: step 12050, loss = 582.07, batch loss = 1.29 (24.3 examples/sec; 0.330 sec/batch; 29h:21m:05s remains)
INFO - root - 2017-12-03 07:56:27.888632: step 12060, loss = 582.08, batch loss = 1.30 (21.1 examples/sec; 0.379 sec/batch; 33h:42m:59s remains)
INFO - root - 2017-12-03 07:56:31.397803: step 12070, loss = 581.83, batch loss = 1.05 (19.5 examples/sec; 0.411 sec/batch; 36h:34m:52s remains)
INFO - root - 2017-12-03 07:56:34.573998: step 12080, loss = 581.85, batch loss = 1.06 (24.1 examples/sec; 0.333 sec/batch; 29h:35m:47s remains)
INFO - root - 2017-12-03 07:56:38.012993: step 12090, loss = 581.85, batch loss = 1.06 (20.4 examples/sec; 0.391 sec/batch; 34h:49m:06s remains)
INFO - root - 2017-12-03 07:56:41.540614: step 12100, loss = 582.00, batch loss = 1.21 (23.8 examples/sec; 0.336 sec/batch; 29h:56m:01s remains)
INFO - root - 2017-12-03 07:56:45.566031: step 12110, loss = 582.03, batch loss = 1.24 (18.4 examples/sec; 0.434 sec/batch; 38h:39m:17s remains)
INFO - root - 2017-12-03 07:56:49.150123: step 12120, loss = 581.99, batch loss = 1.20 (23.4 examples/sec; 0.342 sec/batch; 30h:26m:52s remains)
INFO - root - 2017-12-03 07:56:53.044381: step 12130, loss = 581.98, batch loss = 1.19 (23.1 examples/sec; 0.346 sec/batch; 30h:49m:01s remains)
INFO - root - 2017-12-03 07:56:56.629081: step 12140, loss = 581.99, batch loss = 1.21 (25.4 examples/sec; 0.315 sec/batch; 28h:02m:47s remains)
INFO - root - 2017-12-03 07:57:00.446808: step 12150, loss = 581.68, batch loss = 0.89 (17.8 examples/sec; 0.448 sec/batch; 39h:54m:33s remains)
INFO - root - 2017-12-03 07:57:04.020520: step 12160, loss = 581.92, batch loss = 1.13 (26.2 examples/sec; 0.305 sec/batch; 27h:09m:16s remains)
INFO - root - 2017-12-03 07:57:07.812205: step 12170, loss = 581.95, batch loss = 1.16 (18.5 examples/sec; 0.432 sec/batch; 38h:24m:24s remains)
INFO - root - 2017-12-03 07:57:11.276263: step 12180, loss = 581.95, batch loss = 1.17 (25.8 examples/sec; 0.310 sec/batch; 27h:32m:56s remains)
INFO - root - 2017-12-03 07:57:14.946788: step 12190, loss = 581.85, batch loss = 1.06 (18.0 examples/sec; 0.445 sec/batch; 39h:38m:08s remains)
INFO - root - 2017-12-03 07:57:18.011377: step 12200, loss = 582.01, batch loss = 1.22 (23.9 examples/sec; 0.335 sec/batch; 29h:49m:37s remains)
INFO - root - 2017-12-03 07:57:21.671392: step 12210, loss = 582.04, batch loss = 1.26 (18.1 examples/sec; 0.441 sec/batch; 39h:16m:04s remains)
INFO - root - 2017-12-03 07:57:25.208451: step 12220, loss = 581.90, batch loss = 1.12 (17.6 examples/sec; 0.455 sec/batch; 40h:29m:32s remains)
INFO - root - 2017-12-03 07:57:28.824276: step 12230, loss = 581.99, batch loss = 1.21 (23.7 examples/sec; 0.337 sec/batch; 29h:58m:01s remains)
INFO - root - 2017-12-03 07:57:32.590796: step 12240, loss = 581.85, batch loss = 1.06 (23.3 examples/sec; 0.343 sec/batch; 30h:32m:44s remains)
INFO - root - 2017-12-03 07:57:35.874217: step 12250, loss = 582.05, batch loss = 1.26 (18.2 examples/sec; 0.439 sec/batch; 39h:05m:16s remains)
INFO - root - 2017-12-03 07:57:39.506444: step 12260, loss = 582.00, batch loss = 1.21 (21.7 examples/sec; 0.369 sec/batch; 32h:47m:48s remains)
INFO - root - 2017-12-03 07:57:43.237755: step 12270, loss = 582.00, batch loss = 1.21 (18.7 examples/sec; 0.428 sec/batch; 38h:06m:46s remains)
INFO - root - 2017-12-03 07:57:46.832996: step 12280, loss = 581.93, batch loss = 1.14 (23.6 examples/sec; 0.338 sec/batch; 30h:05m:41s remains)
INFO - root - 2017-12-03 07:57:50.558287: step 12290, loss = 582.06, batch loss = 1.27 (18.0 examples/sec; 0.443 sec/batch; 39h:25m:29s remains)
INFO - root - 2017-12-03 07:57:54.433365: step 12300, loss = 581.83, batch loss = 1.04 (22.8 examples/sec; 0.350 sec/batch; 31h:09m:18s remains)
INFO - root - 2017-12-03 07:57:58.325821: step 12310, loss = 582.13, batch loss = 1.34 (25.6 examples/sec; 0.313 sec/batch; 27h:48m:05s remains)
INFO - root - 2017-12-03 07:58:01.783083: step 12320, loss = 581.96, batch loss = 1.17 (23.8 examples/sec; 0.336 sec/batch; 29h:53m:08s remains)
INFO - root - 2017-12-03 07:58:05.185859: step 12330, loss = 581.95, batch loss = 1.17 (25.8 examples/sec; 0.310 sec/batch; 27h:32m:37s remains)
INFO - root - 2017-12-03 07:58:08.618276: step 12340, loss = 581.98, batch loss = 1.20 (23.2 examples/sec; 0.345 sec/batch; 30h:40m:16s remains)
INFO - root - 2017-12-03 07:58:12.133099: step 12350, loss = 581.89, batch loss = 1.11 (26.6 examples/sec; 0.300 sec/batch; 26h:43m:04s remains)
INFO - root - 2017-12-03 07:58:15.913094: step 12360, loss = 582.10, batch loss = 1.31 (21.5 examples/sec; 0.373 sec/batch; 33h:08m:21s remains)
INFO - root - 2017-12-03 07:58:19.436294: step 12370, loss = 582.26, batch loss = 1.48 (26.1 examples/sec; 0.306 sec/batch; 27h:12m:24s remains)
INFO - root - 2017-12-03 07:58:23.300199: step 12380, loss = 581.90, batch loss = 1.11 (20.1 examples/sec; 0.398 sec/batch; 35h:22m:58s remains)
INFO - root - 2017-12-03 07:58:26.964424: step 12390, loss = 581.94, batch loss = 1.15 (25.5 examples/sec; 0.313 sec/batch; 27h:51m:27s remains)
INFO - root - 2017-12-03 07:58:30.498003: step 12400, loss = 582.08, batch loss = 1.29 (18.5 examples/sec; 0.433 sec/batch; 38h:27m:48s remains)
INFO - root - 2017-12-03 07:58:34.203024: step 12410, loss = 582.11, batch loss = 1.32 (23.7 examples/sec; 0.338 sec/batch; 30h:02m:19s remains)
INFO - root - 2017-12-03 07:58:37.363857: step 12420, loss = 582.13, batch loss = 1.34 (44.4 examples/sec; 0.180 sec/batch; 16h:00m:35s remains)
INFO - root - 2017-12-03 07:58:41.166484: step 12430, loss = 582.06, batch loss = 1.27 (17.7 examples/sec; 0.451 sec/batch; 40h:06m:59s remains)
INFO - root - 2017-12-03 07:58:44.663152: step 12440, loss = 582.13, batch loss = 1.34 (28.9 examples/sec; 0.277 sec/batch; 24h:37m:45s remains)
INFO - root - 2017-12-03 07:58:47.988380: step 12450, loss = 581.97, batch loss = 1.19 (44.0 examples/sec; 0.182 sec/batch; 16h:09m:54s remains)
INFO - root - 2017-12-03 07:58:51.474860: step 12460, loss = 581.92, batch loss = 1.13 (25.8 examples/sec; 0.310 sec/batch; 27h:33m:51s remains)
INFO - root - 2017-12-03 07:58:54.825269: step 12470, loss = 582.14, batch loss = 1.36 (25.4 examples/sec; 0.315 sec/batch; 27h:58m:38s remains)
INFO - root - 2017-12-03 07:58:58.534651: step 12480, loss = 581.92, batch loss = 1.14 (18.3 examples/sec; 0.436 sec/batch; 38h:45m:43s remains)
INFO - root - 2017-12-03 07:59:02.179052: step 12490, loss = 582.06, batch loss = 1.28 (23.4 examples/sec; 0.342 sec/batch; 30h:24m:37s remains)
INFO - root - 2017-12-03 07:59:05.624053: step 12500, loss = 581.85, batch loss = 1.06 (29.8 examples/sec; 0.268 sec/batch; 23h:49m:51s remains)
INFO - root - 2017-12-03 07:59:08.953159: step 12510, loss = 582.13, batch loss = 1.35 (22.9 examples/sec; 0.350 sec/batch; 31h:04m:06s remains)
INFO - root - 2017-12-03 07:59:12.496083: step 12520, loss = 582.14, batch loss = 1.36 (23.2 examples/sec; 0.345 sec/batch; 30h:40m:51s remains)
INFO - root - 2017-12-03 07:59:15.956452: step 12530, loss = 582.04, batch loss = 1.25 (23.9 examples/sec; 0.334 sec/batch; 29h:41m:43s remains)
INFO - root - 2017-12-03 07:59:19.302247: step 12540, loss = 581.88, batch loss = 1.10 (26.0 examples/sec; 0.307 sec/batch; 27h:17m:49s remains)
INFO - root - 2017-12-03 07:59:22.700061: step 12550, loss = 582.11, batch loss = 1.32 (25.5 examples/sec; 0.314 sec/batch; 27h:53m:08s remains)
INFO - root - 2017-12-03 07:59:26.028789: step 12560, loss = 582.11, batch loss = 1.32 (43.7 examples/sec; 0.183 sec/batch; 16h:17m:02s remains)
INFO - root - 2017-12-03 07:59:29.136293: step 12570, loss = 581.90, batch loss = 1.11 (44.0 examples/sec; 0.182 sec/batch; 16h:09m:31s remains)
INFO - root - 2017-12-03 07:59:33.072491: step 12580, loss = 581.90, batch loss = 1.12 (22.7 examples/sec; 0.353 sec/batch; 31h:22m:04s remains)
INFO - root - 2017-12-03 07:59:36.710300: step 12590, loss = 581.86, batch loss = 1.08 (42.0 examples/sec; 0.190 sec/batch; 16h:54m:44s remains)
INFO - root - 2017-12-03 07:59:39.908130: step 12600, loss = 582.09, batch loss = 1.30 (16.1 examples/sec; 0.497 sec/batch; 44h:07m:41s remains)
INFO - root - 2017-12-03 07:59:43.615511: step 12610, loss = 581.97, batch loss = 1.18 (23.9 examples/sec; 0.335 sec/batch; 29h:43m:23s remains)
INFO - root - 2017-12-03 07:59:47.096523: step 12620, loss = 581.90, batch loss = 1.12 (25.7 examples/sec; 0.312 sec/batch; 27h:41m:13s remains)
INFO - root - 2017-12-03 07:59:50.552361: step 12630, loss = 582.14, batch loss = 1.35 (19.5 examples/sec; 0.411 sec/batch; 36h:32m:12s remains)
INFO - root - 2017-12-03 07:59:54.041581: step 12640, loss = 582.02, batch loss = 1.23 (19.6 examples/sec; 0.408 sec/batch; 36h:14m:47s remains)
INFO - root - 2017-12-03 07:59:57.966699: step 12650, loss = 581.96, batch loss = 1.17 (21.3 examples/sec; 0.376 sec/batch; 33h:22m:02s remains)
INFO - root - 2017-12-03 08:00:01.867585: step 12660, loss = 582.07, batch loss = 1.28 (23.3 examples/sec; 0.343 sec/batch; 30h:30m:04s remains)
INFO - root - 2017-12-03 08:00:05.413446: step 12670, loss = 581.94, batch loss = 1.15 (37.8 examples/sec; 0.212 sec/batch; 18h:48m:35s remains)
INFO - root - 2017-12-03 08:00:09.257446: step 12680, loss = 581.92, batch loss = 1.13 (24.6 examples/sec; 0.325 sec/batch; 28h:52m:33s remains)
INFO - root - 2017-12-03 08:00:12.904598: step 12690, loss = 581.92, batch loss = 1.14 (17.1 examples/sec; 0.468 sec/batch; 41h:35m:58s remains)
INFO - root - 2017-12-03 08:00:16.669288: step 12700, loss = 581.94, batch loss = 1.15 (22.0 examples/sec; 0.363 sec/batch; 32h:16m:58s remains)
INFO - root - 2017-12-03 08:00:20.112294: step 12710, loss = 582.10, batch loss = 1.32 (23.6 examples/sec; 0.338 sec/batch; 30h:03m:26s remains)
INFO - root - 2017-12-03 08:00:24.037603: step 12720, loss = 582.10, batch loss = 1.31 (19.0 examples/sec; 0.422 sec/batch; 37h:28m:15s remains)
INFO - root - 2017-12-03 08:00:27.424415: step 12730, loss = 581.97, batch loss = 1.18 (22.0 examples/sec; 0.364 sec/batch; 32h:18m:04s remains)
INFO - root - 2017-12-03 08:00:30.962805: step 12740, loss = 582.07, batch loss = 1.28 (27.6 examples/sec; 0.290 sec/batch; 25h:47m:26s remains)
INFO - root - 2017-12-03 08:00:34.227399: step 12750, loss = 581.99, batch loss = 1.21 (22.1 examples/sec; 0.362 sec/batch; 32h:08m:51s remains)
INFO - root - 2017-12-03 08:00:37.932662: step 12760, loss = 581.79, batch loss = 1.01 (25.0 examples/sec; 0.320 sec/batch; 28h:25m:08s remains)
INFO - root - 2017-12-03 08:00:41.672397: step 12770, loss = 582.01, batch loss = 1.22 (30.6 examples/sec; 0.261 sec/batch; 23h:11m:51s remains)
INFO - root - 2017-12-03 08:00:45.375457: step 12780, loss = 582.09, batch loss = 1.30 (23.9 examples/sec; 0.334 sec/batch; 29h:41m:51s remains)
INFO - root - 2017-12-03 08:00:48.957220: step 12790, loss = 581.93, batch loss = 1.14 (31.8 examples/sec; 0.252 sec/batch; 22h:21m:50s remains)
INFO - root - 2017-12-03 08:00:52.674729: step 12800, loss = 582.05, batch loss = 1.27 (23.7 examples/sec; 0.337 sec/batch; 29h:56m:33s remains)
INFO - root - 2017-12-03 08:00:56.197477: step 12810, loss = 581.83, batch loss = 1.04 (23.0 examples/sec; 0.348 sec/batch; 30h:52m:32s remains)
INFO - root - 2017-12-03 08:00:59.602343: step 12820, loss = 581.87, batch loss = 1.09 (23.3 examples/sec; 0.344 sec/batch; 30h:33m:17s remains)
INFO - root - 2017-12-03 08:01:02.647439: step 12830, loss = 581.97, batch loss = 1.18 (22.7 examples/sec; 0.352 sec/batch; 31h:16m:50s remains)
INFO - root - 2017-12-03 08:01:06.185334: step 12840, loss = 581.86, batch loss = 1.07 (17.9 examples/sec; 0.446 sec/batch; 39h:36m:17s remains)
INFO - root - 2017-12-03 08:01:10.021244: step 12850, loss = 581.98, batch loss = 1.19 (20.5 examples/sec; 0.391 sec/batch; 34h:43m:13s remains)
INFO - root - 2017-12-03 08:01:13.596102: step 12860, loss = 582.10, batch loss = 1.31 (22.7 examples/sec; 0.352 sec/batch; 31h:15m:53s remains)
INFO - root - 2017-12-03 08:01:16.794603: step 12870, loss = 581.85, batch loss = 1.07 (22.6 examples/sec; 0.353 sec/batch; 31h:22m:37s remains)
INFO - root - 2017-12-03 08:01:20.579723: step 12880, loss = 581.97, batch loss = 1.18 (23.0 examples/sec; 0.348 sec/batch; 30h:52m:16s remains)
INFO - root - 2017-12-03 08:01:24.306687: step 12890, loss = 581.85, batch loss = 1.06 (28.7 examples/sec; 0.279 sec/batch; 24h:44m:41s remains)
INFO - root - 2017-12-03 08:01:27.968586: step 12900, loss = 581.94, batch loss = 1.15 (16.2 examples/sec; 0.495 sec/batch; 43h:54m:49s remains)
INFO - root - 2017-12-03 08:01:31.443261: step 12910, loss = 581.89, batch loss = 1.10 (19.3 examples/sec; 0.415 sec/batch; 36h:48m:53s remains)
INFO - root - 2017-12-03 08:01:34.914284: step 12920, loss = 581.99, batch loss = 1.21 (24.0 examples/sec; 0.334 sec/batch; 29h:37m:53s remains)
INFO - root - 2017-12-03 08:01:38.620113: step 12930, loss = 582.02, batch loss = 1.24 (19.9 examples/sec; 0.402 sec/batch; 35h:38m:49s remains)
INFO - root - 2017-12-03 08:01:41.907950: step 12940, loss = 582.05, batch loss = 1.26 (45.2 examples/sec; 0.177 sec/batch; 15h:43m:05s remains)
INFO - root - 2017-12-03 08:01:45.615574: step 12950, loss = 581.99, batch loss = 1.20 (18.6 examples/sec; 0.429 sec/batch; 38h:06m:11s remains)
INFO - root - 2017-12-03 08:01:49.069602: step 12960, loss = 581.96, batch loss = 1.17 (18.6 examples/sec; 0.429 sec/batch; 38h:05m:07s remains)
INFO - root - 2017-12-03 08:01:52.654602: step 12970, loss = 582.01, batch loss = 1.22 (23.4 examples/sec; 0.342 sec/batch; 30h:19m:00s remains)
INFO - root - 2017-12-03 08:01:56.398254: step 12980, loss = 582.05, batch loss = 1.27 (17.9 examples/sec; 0.447 sec/batch; 39h:38m:32s remains)
INFO - root - 2017-12-03 08:02:00.287387: step 12990, loss = 582.26, batch loss = 1.47 (17.9 examples/sec; 0.447 sec/batch; 39h:40m:42s remains)
INFO - root - 2017-12-03 08:02:03.952405: step 13000, loss = 582.31, batch loss = 1.52 (20.8 examples/sec; 0.384 sec/batch; 34h:04m:45s remains)
INFO - root - 2017-12-03 08:02:07.555480: step 13010, loss = 581.95, batch loss = 1.16 (31.0 examples/sec; 0.258 sec/batch; 22h:52m:19s remains)
INFO - root - 2017-12-03 08:02:10.850877: step 13020, loss = 581.86, batch loss = 1.07 (23.2 examples/sec; 0.345 sec/batch; 30h:37m:14s remains)
INFO - root - 2017-12-03 08:02:14.537956: step 13030, loss = 582.07, batch loss = 1.28 (24.4 examples/sec; 0.328 sec/batch; 29h:04m:05s remains)
INFO - root - 2017-12-03 08:02:18.432625: step 13040, loss = 582.06, batch loss = 1.27 (22.9 examples/sec; 0.349 sec/batch; 30h:58m:25s remains)
INFO - root - 2017-12-03 08:02:22.069914: step 13050, loss = 582.19, batch loss = 1.40 (20.2 examples/sec; 0.396 sec/batch; 35h:06m:44s remains)
INFO - root - 2017-12-03 08:02:25.933996: step 13060, loss = 581.89, batch loss = 1.11 (18.4 examples/sec; 0.436 sec/batch; 38h:39m:24s remains)
INFO - root - 2017-12-03 08:02:29.434373: step 13070, loss = 582.12, batch loss = 1.33 (17.4 examples/sec; 0.460 sec/batch; 40h:48m:27s remains)
INFO - root - 2017-12-03 08:02:33.133327: step 13080, loss = 582.05, batch loss = 1.26 (21.6 examples/sec; 0.371 sec/batch; 32h:54m:12s remains)
INFO - root - 2017-12-03 08:02:36.860007: step 13090, loss = 581.96, batch loss = 1.17 (20.5 examples/sec; 0.390 sec/batch; 34h:34m:18s remains)
INFO - root - 2017-12-03 08:02:40.557298: step 13100, loss = 582.13, batch loss = 1.34 (22.1 examples/sec; 0.363 sec/batch; 32h:11m:01s remains)
INFO - root - 2017-12-03 08:02:44.145155: step 13110, loss = 582.15, batch loss = 1.36 (31.8 examples/sec; 0.252 sec/batch; 22h:19m:46s remains)
INFO - root - 2017-12-03 08:02:48.022025: step 13120, loss = 582.07, batch loss = 1.28 (23.4 examples/sec; 0.342 sec/batch; 30h:20m:09s remains)
INFO - root - 2017-12-03 08:02:52.001026: step 13130, loss = 581.86, batch loss = 1.07 (23.1 examples/sec; 0.347 sec/batch; 30h:44m:45s remains)
INFO - root - 2017-12-03 08:02:55.842814: step 13140, loss = 581.88, batch loss = 1.10 (18.3 examples/sec; 0.437 sec/batch; 38h:44m:08s remains)
INFO - root - 2017-12-03 08:02:59.084238: step 13150, loss = 581.97, batch loss = 1.19 (17.4 examples/sec; 0.461 sec/batch; 40h:51m:21s remains)
INFO - root - 2017-12-03 08:03:02.712397: step 13160, loss = 581.88, batch loss = 1.10 (22.4 examples/sec; 0.358 sec/batch; 31h:44m:29s remains)
INFO - root - 2017-12-03 08:03:05.924533: step 13170, loss = 582.09, batch loss = 1.30 (19.2 examples/sec; 0.416 sec/batch; 36h:56m:08s remains)
INFO - root - 2017-12-03 08:03:09.581937: step 13180, loss = 582.02, batch loss = 1.23 (25.8 examples/sec; 0.310 sec/batch; 27h:31m:07s remains)
INFO - root - 2017-12-03 08:03:13.210678: step 13190, loss = 581.87, batch loss = 1.09 (23.0 examples/sec; 0.347 sec/batch; 30h:47m:27s remains)
INFO - root - 2017-12-03 08:03:17.031390: step 13200, loss = 581.96, batch loss = 1.17 (22.1 examples/sec; 0.363 sec/batch; 32h:09m:33s remains)
INFO - root - 2017-12-03 08:03:21.026448: step 13210, loss = 581.87, batch loss = 1.08 (23.8 examples/sec; 0.336 sec/batch; 29h:45m:41s remains)
INFO - root - 2017-12-03 08:03:25.000538: step 13220, loss = 582.06, batch loss = 1.27 (20.7 examples/sec; 0.386 sec/batch; 34h:14m:20s remains)
INFO - root - 2017-12-03 08:03:28.836637: step 13230, loss = 582.33, batch loss = 1.54 (24.4 examples/sec; 0.328 sec/batch; 29h:05m:23s remains)
INFO - root - 2017-12-03 08:03:32.640085: step 13240, loss = 582.20, batch loss = 1.41 (23.5 examples/sec; 0.341 sec/batch; 30h:14m:59s remains)
INFO - root - 2017-12-03 08:03:36.418278: step 13250, loss = 581.97, batch loss = 1.18 (21.1 examples/sec; 0.379 sec/batch; 33h:35m:44s remains)
INFO - root - 2017-12-03 08:03:40.213457: step 13260, loss = 581.98, batch loss = 1.19 (23.6 examples/sec; 0.339 sec/batch; 30h:04m:27s remains)
INFO - root - 2017-12-03 08:03:43.880034: step 13270, loss = 582.22, batch loss = 1.43 (21.3 examples/sec; 0.375 sec/batch; 33h:16m:35s remains)
INFO - root - 2017-12-03 08:03:47.070669: step 13280, loss = 581.91, batch loss = 1.12 (24.2 examples/sec; 0.330 sec/batch; 29h:15m:15s remains)
INFO - root - 2017-12-03 08:03:50.953369: step 13290, loss = 581.99, batch loss = 1.20 (25.8 examples/sec; 0.310 sec/batch; 27h:28m:37s remains)
INFO - root - 2017-12-03 08:03:53.908382: step 13300, loss = 581.97, batch loss = 1.19 (29.6 examples/sec; 0.270 sec/batch; 23h:55m:39s remains)
INFO - root - 2017-12-03 08:03:57.826531: step 13310, loss = 582.08, batch loss = 1.29 (23.5 examples/sec; 0.340 sec/batch; 30h:10m:12s remains)
INFO - root - 2017-12-03 08:04:01.410863: step 13320, loss = 581.79, batch loss = 1.00 (20.3 examples/sec; 0.394 sec/batch; 34h:54m:35s remains)
INFO - root - 2017-12-03 08:04:05.057364: step 13330, loss = 582.15, batch loss = 1.36 (24.0 examples/sec; 0.333 sec/batch; 29h:32m:27s remains)
INFO - root - 2017-12-03 08:04:08.974431: step 13340, loss = 581.78, batch loss = 1.00 (22.9 examples/sec; 0.350 sec/batch; 31h:00m:04s remains)
INFO - root - 2017-12-03 08:04:12.642497: step 13350, loss = 582.00, batch loss = 1.21 (18.4 examples/sec; 0.434 sec/batch; 38h:30m:59s remains)
INFO - root - 2017-12-03 08:04:16.022783: step 13360, loss = 581.97, batch loss = 1.18 (18.7 examples/sec; 0.429 sec/batch; 38h:01m:32s remains)
INFO - root - 2017-12-03 08:04:19.849462: step 13370, loss = 581.90, batch loss = 1.11 (23.4 examples/sec; 0.342 sec/batch; 30h:16m:30s remains)
INFO - root - 2017-12-03 08:04:23.251722: step 13380, loss = 581.77, batch loss = 0.98 (23.0 examples/sec; 0.347 sec/batch; 30h:47m:12s remains)
INFO - root - 2017-12-03 08:04:27.062443: step 13390, loss = 581.89, batch loss = 1.10 (23.1 examples/sec; 0.346 sec/batch; 30h:40m:10s remains)
INFO - root - 2017-12-03 08:04:30.501528: step 13400, loss = 582.04, batch loss = 1.25 (25.8 examples/sec; 0.310 sec/batch; 27h:29m:45s remains)
INFO - root - 2017-12-03 08:04:34.687469: step 13410, loss = 581.88, batch loss = 1.09 (23.8 examples/sec; 0.336 sec/batch; 29h:47m:54s remains)
INFO - root - 2017-12-03 08:04:38.549045: step 13420, loss = 582.09, batch loss = 1.30 (23.8 examples/sec; 0.336 sec/batch; 29h:46m:57s remains)
INFO - root - 2017-12-03 08:04:42.213956: step 13430, loss = 581.99, batch loss = 1.20 (18.3 examples/sec; 0.437 sec/batch; 38h:43m:52s remains)
INFO - root - 2017-12-03 08:04:45.740406: step 13440, loss = 582.02, batch loss = 1.24 (28.5 examples/sec; 0.281 sec/batch; 24h:52m:45s remains)
INFO - root - 2017-12-03 08:04:49.293439: step 13450, loss = 581.72, batch loss = 0.93 (25.3 examples/sec; 0.317 sec/batch; 28h:04m:07s remains)
INFO - root - 2017-12-03 08:04:53.062015: step 13460, loss = 582.00, batch loss = 1.21 (19.3 examples/sec; 0.414 sec/batch; 36h:42m:58s remains)
INFO - root - 2017-12-03 08:04:56.785620: step 13470, loss = 581.90, batch loss = 1.11 (22.8 examples/sec; 0.351 sec/batch; 31h:06m:41s remains)
INFO - root - 2017-12-03 08:05:00.463977: step 13480, loss = 581.88, batch loss = 1.10 (22.7 examples/sec; 0.353 sec/batch; 31h:16m:11s remains)
INFO - root - 2017-12-03 08:05:04.330512: step 13490, loss = 582.00, batch loss = 1.21 (17.7 examples/sec; 0.452 sec/batch; 40h:04m:10s remains)
INFO - root - 2017-12-03 08:05:07.959138: step 13500, loss = 581.86, batch loss = 1.07 (26.0 examples/sec; 0.308 sec/batch; 27h:17m:28s remains)
INFO - root - 2017-12-03 08:05:11.607840: step 13510, loss = 582.01, batch loss = 1.23 (19.2 examples/sec; 0.418 sec/batch; 37h:00m:48s remains)
INFO - root - 2017-12-03 08:05:15.613425: step 13520, loss = 582.03, batch loss = 1.24 (17.1 examples/sec; 0.467 sec/batch; 41h:20m:49s remains)
INFO - root - 2017-12-03 08:05:19.232682: step 13530, loss = 582.08, batch loss = 1.29 (23.4 examples/sec; 0.342 sec/batch; 30h:20m:04s remains)
INFO - root - 2017-12-03 08:05:22.678714: step 13540, loss = 582.01, batch loss = 1.22 (21.5 examples/sec; 0.372 sec/batch; 32h:59m:40s remains)
INFO - root - 2017-12-03 08:05:26.620210: step 13550, loss = 581.90, batch loss = 1.11 (26.2 examples/sec; 0.305 sec/batch; 27h:00m:38s remains)
INFO - root - 2017-12-03 08:05:29.947733: step 13560, loss = 581.85, batch loss = 1.07 (32.6 examples/sec; 0.245 sec/batch; 21h:44m:26s remains)
INFO - root - 2017-12-03 08:05:33.632639: step 13570, loss = 581.93, batch loss = 1.14 (23.2 examples/sec; 0.344 sec/batch; 30h:29m:43s remains)
INFO - root - 2017-12-03 08:05:37.354921: step 13580, loss = 582.10, batch loss = 1.31 (21.2 examples/sec; 0.378 sec/batch; 33h:28m:58s remains)
INFO - root - 2017-12-03 08:05:41.061685: step 13590, loss = 581.83, batch loss = 1.04 (20.3 examples/sec; 0.393 sec/batch; 34h:49m:36s remains)
INFO - root - 2017-12-03 08:05:44.805546: step 13600, loss = 581.68, batch loss = 0.89 (23.9 examples/sec; 0.335 sec/batch; 29h:40m:38s remains)
INFO - root - 2017-12-03 08:05:48.544744: step 13610, loss = 581.83, batch loss = 1.04 (20.1 examples/sec; 0.398 sec/batch; 35h:12m:42s remains)
INFO - root - 2017-12-03 08:05:52.207332: step 13620, loss = 581.82, batch loss = 1.03 (19.9 examples/sec; 0.403 sec/batch; 35h:39m:16s remains)
INFO - root - 2017-12-03 08:05:56.070677: step 13630, loss = 581.87, batch loss = 1.09 (20.7 examples/sec; 0.387 sec/batch; 34h:16m:39s remains)
INFO - root - 2017-12-03 08:06:00.002439: step 13640, loss = 582.05, batch loss = 1.26 (19.7 examples/sec; 0.406 sec/batch; 35h:59m:23s remains)
INFO - root - 2017-12-03 08:06:03.543027: step 13650, loss = 581.96, batch loss = 1.17 (24.1 examples/sec; 0.332 sec/batch; 29h:21m:41s remains)
INFO - root - 2017-12-03 08:06:07.107932: step 13660, loss = 581.91, batch loss = 1.12 (23.3 examples/sec; 0.343 sec/batch; 30h:21m:59s remains)
INFO - root - 2017-12-03 08:06:10.652254: step 13670, loss = 581.93, batch loss = 1.15 (25.4 examples/sec; 0.315 sec/batch; 27h:51m:40s remains)
INFO - root - 2017-12-03 08:06:14.469269: step 13680, loss = 581.83, batch loss = 1.04 (24.1 examples/sec; 0.333 sec/batch; 29h:27m:09s remains)
INFO - root - 2017-12-03 08:06:18.275670: step 13690, loss = 581.99, batch loss = 1.20 (21.0 examples/sec; 0.381 sec/batch; 33h:42m:33s remains)
INFO - root - 2017-12-03 08:06:21.759561: step 13700, loss = 581.96, batch loss = 1.18 (19.4 examples/sec; 0.411 sec/batch; 36h:25m:41s remains)
INFO - root - 2017-12-03 08:06:25.729620: step 13710, loss = 581.91, batch loss = 1.12 (17.3 examples/sec; 0.461 sec/batch; 40h:50m:31s remains)
INFO - root - 2017-12-03 08:06:29.312203: step 13720, loss = 582.00, batch loss = 1.22 (19.4 examples/sec; 0.412 sec/batch; 36h:26m:58s remains)
INFO - root - 2017-12-03 08:06:32.847274: step 13730, loss = 581.82, batch loss = 1.04 (43.7 examples/sec; 0.183 sec/batch; 16h:12m:18s remains)
INFO - root - 2017-12-03 08:06:36.230692: step 13740, loss = 581.89, batch loss = 1.10 (44.6 examples/sec; 0.179 sec/batch; 15h:53m:20s remains)
INFO - root - 2017-12-03 08:06:39.150657: step 13750, loss = 581.88, batch loss = 1.09 (33.1 examples/sec; 0.242 sec/batch; 21h:24m:10s remains)
INFO - root - 2017-12-03 08:06:42.262155: step 13760, loss = 582.23, batch loss = 1.45 (20.0 examples/sec; 0.400 sec/batch; 35h:24m:21s remains)
INFO - root - 2017-12-03 08:06:45.943043: step 13770, loss = 581.90, batch loss = 1.11 (22.6 examples/sec; 0.355 sec/batch; 31h:23m:16s remains)
INFO - root - 2017-12-03 08:06:49.896318: step 13780, loss = 581.96, batch loss = 1.17 (25.0 examples/sec; 0.321 sec/batch; 28h:23m:06s remains)
INFO - root - 2017-12-03 08:06:53.745463: step 13790, loss = 581.96, batch loss = 1.17 (18.9 examples/sec; 0.423 sec/batch; 37h:29m:20s remains)
INFO - root - 2017-12-03 08:06:57.083799: step 13800, loss = 581.87, batch loss = 1.09 (22.6 examples/sec; 0.354 sec/batch; 31h:19m:16s remains)
INFO - root - 2017-12-03 08:07:00.717176: step 13810, loss = 582.04, batch loss = 1.25 (31.7 examples/sec; 0.252 sec/batch; 22h:19m:20s remains)
INFO - root - 2017-12-03 08:07:04.495474: step 13820, loss = 581.79, batch loss = 1.01 (22.5 examples/sec; 0.355 sec/batch; 31h:26m:08s remains)
INFO - root - 2017-12-03 08:07:08.317166: step 13830, loss = 581.86, batch loss = 1.07 (23.8 examples/sec; 0.336 sec/batch; 29h:44m:41s remains)
INFO - root - 2017-12-03 08:07:11.921324: step 13840, loss = 581.91, batch loss = 1.12 (33.6 examples/sec; 0.238 sec/batch; 21h:03m:23s remains)
INFO - root - 2017-12-03 08:07:15.802913: step 13850, loss = 582.01, batch loss = 1.22 (25.7 examples/sec; 0.312 sec/batch; 27h:35m:18s remains)
INFO - root - 2017-12-03 08:07:19.376580: step 13860, loss = 581.88, batch loss = 1.09 (26.0 examples/sec; 0.308 sec/batch; 27h:14m:08s remains)
INFO - root - 2017-12-03 08:07:23.209766: step 13870, loss = 582.08, batch loss = 1.29 (22.2 examples/sec; 0.360 sec/batch; 31h:50m:58s remains)
INFO - root - 2017-12-03 08:07:26.924405: step 13880, loss = 581.91, batch loss = 1.13 (20.4 examples/sec; 0.393 sec/batch; 34h:45m:59s remains)
INFO - root - 2017-12-03 08:07:30.154774: step 13890, loss = 582.17, batch loss = 1.38 (24.0 examples/sec; 0.334 sec/batch; 29h:33m:02s remains)
INFO - root - 2017-12-03 08:07:33.764975: step 13900, loss = 582.16, batch loss = 1.37 (17.5 examples/sec; 0.458 sec/batch; 40h:32m:25s remains)
INFO - root - 2017-12-03 08:07:37.478431: step 13910, loss = 581.86, batch loss = 1.08 (24.4 examples/sec; 0.327 sec/batch; 28h:57m:39s remains)
INFO - root - 2017-12-03 08:07:40.916409: step 13920, loss = 582.06, batch loss = 1.28 (24.6 examples/sec; 0.326 sec/batch; 28h:48m:30s remains)
INFO - root - 2017-12-03 08:07:44.386100: step 13930, loss = 581.80, batch loss = 1.02 (34.2 examples/sec; 0.234 sec/batch; 20h:43m:01s remains)
INFO - root - 2017-12-03 08:07:47.927901: step 13940, loss = 582.02, batch loss = 1.23 (24.2 examples/sec; 0.331 sec/batch; 29h:16m:41s remains)
INFO - root - 2017-12-03 08:07:51.598273: step 13950, loss = 581.95, batch loss = 1.16 (25.8 examples/sec; 0.311 sec/batch; 27h:28m:46s remains)
INFO - root - 2017-12-03 08:07:55.043922: step 13960, loss = 581.78, batch loss = 0.99 (28.6 examples/sec; 0.280 sec/batch; 24h:46m:34s remains)
INFO - root - 2017-12-03 08:07:58.650395: step 13970, loss = 581.92, batch loss = 1.13 (17.3 examples/sec; 0.462 sec/batch; 40h:51m:30s remains)
INFO - root - 2017-12-03 08:08:02.194122: step 13980, loss = 581.85, batch loss = 1.06 (23.6 examples/sec; 0.339 sec/batch; 30h:00m:57s remains)
INFO - root - 2017-12-03 08:08:05.559397: step 13990, loss = 581.84, batch loss = 1.06 (43.7 examples/sec; 0.183 sec/batch; 16h:10m:46s remains)
INFO - root - 2017-12-03 08:08:07.377627: step 14000, loss = 582.10, batch loss = 1.31 (45.6 examples/sec; 0.175 sec/batch; 15h:31m:22s remains)
INFO - root - 2017-12-03 08:08:09.245963: step 14010, loss = 581.90, batch loss = 1.11 (45.0 examples/sec; 0.178 sec/batch; 15h:43m:26s remains)
INFO - root - 2017-12-03 08:08:11.066734: step 14020, loss = 582.05, batch loss = 1.27 (42.8 examples/sec; 0.187 sec/batch; 16h:32m:54s remains)
INFO - root - 2017-12-03 08:08:12.858790: step 14030, loss = 581.99, batch loss = 1.20 (45.5 examples/sec; 0.176 sec/batch; 15h:34m:11s remains)
INFO - root - 2017-12-03 08:08:14.682038: step 14040, loss = 581.94, batch loss = 1.16 (44.4 examples/sec; 0.180 sec/batch; 15h:56m:34s remains)
INFO - root - 2017-12-03 08:08:16.465433: step 14050, loss = 581.97, batch loss = 1.18 (44.8 examples/sec; 0.179 sec/batch; 15h:48m:03s remains)
INFO - root - 2017-12-03 08:08:18.306413: step 14060, loss = 582.01, batch loss = 1.22 (43.9 examples/sec; 0.182 sec/batch; 16h:07m:47s remains)
INFO - root - 2017-12-03 08:08:20.126658: step 14070, loss = 581.91, batch loss = 1.13 (44.1 examples/sec; 0.181 sec/batch; 16h:02m:04s remains)
INFO - root - 2017-12-03 08:08:21.933615: step 14080, loss = 581.90, batch loss = 1.11 (44.0 examples/sec; 0.182 sec/batch; 16h:05m:39s remains)
INFO - root - 2017-12-03 08:08:23.728871: step 14090, loss = 582.01, batch loss = 1.22 (44.8 examples/sec; 0.178 sec/batch; 15h:46m:37s remains)
INFO - root - 2017-12-03 08:08:25.563388: step 14100, loss = 581.99, batch loss = 1.21 (44.2 examples/sec; 0.181 sec/batch; 16h:00m:40s remains)
INFO - root - 2017-12-03 08:08:27.456246: step 14110, loss = 581.75, batch loss = 0.96 (44.1 examples/sec; 0.181 sec/batch; 16h:01m:37s remains)
INFO - root - 2017-12-03 08:08:29.273373: step 14120, loss = 581.71, batch loss = 0.92 (45.2 examples/sec; 0.177 sec/batch; 15h:39m:25s remains)
INFO - root - 2017-12-03 08:08:31.086042: step 14130, loss = 581.89, batch loss = 1.10 (43.9 examples/sec; 0.182 sec/batch; 16h:06m:19s remains)
INFO - root - 2017-12-03 08:08:32.896109: step 14140, loss = 581.77, batch loss = 0.98 (44.6 examples/sec; 0.179 sec/batch; 15h:50m:59s remains)
INFO - root - 2017-12-03 08:08:34.689020: step 14150, loss = 581.98, batch loss = 1.19 (43.9 examples/sec; 0.182 sec/batch; 16h:07m:15s remains)
INFO - root - 2017-12-03 08:08:36.473150: step 14160, loss = 582.11, batch loss = 1.33 (44.1 examples/sec; 0.181 sec/batch; 16h:02m:11s remains)
INFO - root - 2017-12-03 08:08:38.292170: step 14170, loss = 581.97, batch loss = 1.18 (44.6 examples/sec; 0.179 sec/batch; 15h:51m:30s remains)
INFO - root - 2017-12-03 08:08:40.076468: step 14180, loss = 581.93, batch loss = 1.15 (45.0 examples/sec; 0.178 sec/batch; 15h:43m:34s remains)
INFO - root - 2017-12-03 08:08:41.881018: step 14190, loss = 581.96, batch loss = 1.17 (44.1 examples/sec; 0.182 sec/batch; 16h:02m:56s remains)
INFO - root - 2017-12-03 08:08:43.676360: step 14200, loss = 581.91, batch loss = 1.12 (43.1 examples/sec; 0.185 sec/batch; 16h:24m:03s remains)
INFO - root - 2017-12-03 08:08:45.539259: step 14210, loss = 582.00, batch loss = 1.21 (44.0 examples/sec; 0.182 sec/batch; 16h:05m:24s remains)
INFO - root - 2017-12-03 08:08:47.354797: step 14220, loss = 581.91, batch loss = 1.12 (44.4 examples/sec; 0.180 sec/batch; 15h:55m:11s remains)
INFO - root - 2017-12-03 08:08:49.165195: step 14230, loss = 582.03, batch loss = 1.25 (44.6 examples/sec; 0.180 sec/batch; 15h:52m:23s remains)
INFO - root - 2017-12-03 08:08:50.945618: step 14240, loss = 582.15, batch loss = 1.36 (45.0 examples/sec; 0.178 sec/batch; 15h:42m:31s remains)
INFO - root - 2017-12-03 08:08:52.761854: step 14250, loss = 582.11, batch loss = 1.32 (45.8 examples/sec; 0.175 sec/batch; 15h:26m:12s remains)
INFO - root - 2017-12-03 08:08:54.570507: step 14260, loss = 582.24, batch loss = 1.45 (43.3 examples/sec; 0.185 sec/batch; 16h:20m:46s remains)
INFO - root - 2017-12-03 08:08:56.380776: step 14270, loss = 582.10, batch loss = 1.31 (42.9 examples/sec; 0.186 sec/batch; 16h:29m:07s remains)
INFO - root - 2017-12-03 08:08:58.203737: step 14280, loss = 582.04, batch loss = 1.25 (44.7 examples/sec; 0.179 sec/batch; 15h:49m:21s remains)
INFO - root - 2017-12-03 08:09:00.022349: step 14290, loss = 581.89, batch loss = 1.10 (45.2 examples/sec; 0.177 sec/batch; 15h:37m:40s remains)
INFO - root - 2017-12-03 08:09:01.824897: step 14300, loss = 581.85, batch loss = 1.06 (42.1 examples/sec; 0.190 sec/batch; 16h:46m:45s remains)
INFO - root - 2017-12-03 08:09:03.674789: step 14310, loss = 582.17, batch loss = 1.38 (44.2 examples/sec; 0.181 sec/batch; 15h:59m:16s remains)
INFO - root - 2017-12-03 08:09:05.506022: step 14320, loss = 581.83, batch loss = 1.04 (43.8 examples/sec; 0.183 sec/batch; 16h:08m:29s remains)
INFO - root - 2017-12-03 08:09:07.314531: step 14330, loss = 582.09, batch loss = 1.30 (43.9 examples/sec; 0.182 sec/batch; 16h:05m:44s remains)
INFO - root - 2017-12-03 08:09:09.095421: step 14340, loss = 582.11, batch loss = 1.32 (44.0 examples/sec; 0.182 sec/batch; 16h:03m:54s remains)
INFO - root - 2017-12-03 08:09:10.926331: step 14350, loss = 582.14, batch loss = 1.35 (45.1 examples/sec; 0.178 sec/batch; 15h:41m:21s remains)
INFO - root - 2017-12-03 08:09:12.724384: step 14360, loss = 581.84, batch loss = 1.05 (44.2 examples/sec; 0.181 sec/batch; 15h:58m:39s remains)
INFO - root - 2017-12-03 08:09:14.535688: step 14370, loss = 581.93, batch loss = 1.14 (44.9 examples/sec; 0.178 sec/batch; 15h:43m:52s remains)
INFO - root - 2017-12-03 08:09:16.347620: step 14380, loss = 581.77, batch loss = 0.98 (46.0 examples/sec; 0.174 sec/batch; 15h:22m:30s remains)
INFO - root - 2017-12-03 08:09:18.160329: step 14390, loss = 581.92, batch loss = 1.13 (44.8 examples/sec; 0.179 sec/batch; 15h:46m:27s remains)
INFO - root - 2017-12-03 08:09:19.977536: step 14400, loss = 581.97, batch loss = 1.18 (45.4 examples/sec; 0.176 sec/batch; 15h:34m:37s remains)
INFO - root - 2017-12-03 08:09:21.865268: step 14410, loss = 582.04, batch loss = 1.25 (43.8 examples/sec; 0.183 sec/batch; 16h:08m:37s remains)
INFO - root - 2017-12-03 08:09:23.687705: step 14420, loss = 581.84, batch loss = 1.05 (45.0 examples/sec; 0.178 sec/batch; 15h:43m:14s remains)
INFO - root - 2017-12-03 08:09:25.509518: step 14430, loss = 581.94, batch loss = 1.16 (45.0 examples/sec; 0.178 sec/batch; 15h:42m:57s remains)
INFO - root - 2017-12-03 08:09:27.310245: step 14440, loss = 582.05, batch loss = 1.26 (43.2 examples/sec; 0.185 sec/batch; 16h:20m:57s remains)
INFO - root - 2017-12-03 08:09:29.115822: step 14450, loss = 581.92, batch loss = 1.13 (43.8 examples/sec; 0.183 sec/batch; 16h:07m:29s remains)
INFO - root - 2017-12-03 08:09:30.899869: step 14460, loss = 581.91, batch loss = 1.13 (45.0 examples/sec; 0.178 sec/batch; 15h:43m:19s remains)
INFO - root - 2017-12-03 08:09:32.714562: step 14470, loss = 581.91, batch loss = 1.12 (44.4 examples/sec; 0.180 sec/batch; 15h:54m:26s remains)
INFO - root - 2017-12-03 08:09:34.529169: step 14480, loss = 581.90, batch loss = 1.12 (44.7 examples/sec; 0.179 sec/batch; 15h:49m:36s remains)
INFO - root - 2017-12-03 08:09:36.316186: step 14490, loss = 582.11, batch loss = 1.32 (44.9 examples/sec; 0.178 sec/batch; 15h:45m:11s remains)
INFO - root - 2017-12-03 08:09:38.123216: step 14500, loss = 581.99, batch loss = 1.20 (43.6 examples/sec; 0.183 sec/batch; 16h:12m:22s remains)
INFO - root - 2017-12-03 08:09:40.023933: step 14510, loss = 581.95, batch loss = 1.16 (42.2 examples/sec; 0.190 sec/batch; 16h:44m:24s remains)
INFO - root - 2017-12-03 08:09:41.848396: step 14520, loss = 582.03, batch loss = 1.24 (45.4 examples/sec; 0.176 sec/batch; 15h:34m:06s remains)
INFO - root - 2017-12-03 08:09:43.640084: step 14530, loss = 581.87, batch loss = 1.08 (44.1 examples/sec; 0.182 sec/batch; 16h:01m:56s remains)
INFO - root - 2017-12-03 08:09:45.434921: step 14540, loss = 582.18, batch loss = 1.39 (43.6 examples/sec; 0.183 sec/batch; 16h:11m:22s remains)
INFO - root - 2017-12-03 08:09:47.256280: step 14550, loss = 581.83, batch loss = 1.04 (43.5 examples/sec; 0.184 sec/batch; 16h:13m:36s remains)
INFO - root - 2017-12-03 08:09:49.050615: step 14560, loss = 582.16, batch loss = 1.37 (45.1 examples/sec; 0.177 sec/batch; 15h:40m:01s remains)
INFO - root - 2017-12-03 08:09:50.852869: step 14570, loss = 581.90, batch loss = 1.12 (44.4 examples/sec; 0.180 sec/batch; 15h:55m:38s remains)
INFO - root - 2017-12-03 08:09:52.664861: step 14580, loss = 581.87, batch loss = 1.08 (44.9 examples/sec; 0.178 sec/batch; 15h:44m:54s remains)
INFO - root - 2017-12-03 08:09:54.494656: step 14590, loss = 582.23, batch loss = 1.44 (44.4 examples/sec; 0.180 sec/batch; 15h:54m:07s remains)
INFO - root - 2017-12-03 08:09:56.296573: step 14600, loss = 581.89, batch loss = 1.10 (45.3 examples/sec; 0.177 sec/batch; 15h:36m:07s remains)
INFO - root - 2017-12-03 08:09:58.184055: step 14610, loss = 582.13, batch loss = 1.34 (44.8 examples/sec; 0.179 sec/batch; 15h:46m:42s remains)
INFO - root - 2017-12-03 08:10:00.001787: step 14620, loss = 581.89, batch loss = 1.10 (43.8 examples/sec; 0.183 sec/batch; 16h:08m:05s remains)
INFO - root - 2017-12-03 08:10:01.818139: step 14630, loss = 582.04, batch loss = 1.25 (45.0 examples/sec; 0.178 sec/batch; 15h:41m:09s remains)
INFO - root - 2017-12-03 08:10:03.619775: step 14640, loss = 581.98, batch loss = 1.20 (44.3 examples/sec; 0.181 sec/batch; 15h:56m:58s remains)
INFO - root - 2017-12-03 08:10:05.411937: step 14650, loss = 581.90, batch loss = 1.11 (45.0 examples/sec; 0.178 sec/batch; 15h:41m:17s remains)
INFO - root - 2017-12-03 08:10:07.211744: step 14660, loss = 582.06, batch loss = 1.28 (45.4 examples/sec; 0.176 sec/batch; 15h:33m:47s remains)
INFO - root - 2017-12-03 08:10:09.025028: step 14670, loss = 581.90, batch loss = 1.11 (43.3 examples/sec; 0.185 sec/batch; 16h:18m:52s remains)
INFO - root - 2017-12-03 08:10:10.835384: step 14680, loss = 581.80, batch loss = 1.02 (44.0 examples/sec; 0.182 sec/batch; 16h:03m:41s remains)
INFO - root - 2017-12-03 08:10:12.638426: step 14690, loss = 582.03, batch loss = 1.24 (45.2 examples/sec; 0.177 sec/batch; 15h:38m:26s remains)
INFO - root - 2017-12-03 08:10:14.442446: step 14700, loss = 581.90, batch loss = 1.11 (42.8 examples/sec; 0.187 sec/batch; 16h:29m:55s remains)
INFO - root - 2017-12-03 08:10:16.306569: step 14710, loss = 581.99, batch loss = 1.20 (43.9 examples/sec; 0.182 sec/batch; 16h:04m:06s remains)
INFO - root - 2017-12-03 08:10:18.115152: step 14720, loss = 581.99, batch loss = 1.20 (45.1 examples/sec; 0.177 sec/batch; 15h:39m:09s remains)
INFO - root - 2017-12-03 08:10:19.922590: step 14730, loss = 581.88, batch loss = 1.09 (44.9 examples/sec; 0.178 sec/batch; 15h:43m:47s remains)
INFO - root - 2017-12-03 08:10:21.732295: step 14740, loss = 581.98, batch loss = 1.19 (43.2 examples/sec; 0.185 sec/batch; 16h:20m:09s remains)
INFO - root - 2017-12-03 08:10:23.537286: step 14750, loss = 581.98, batch loss = 1.19 (44.9 examples/sec; 0.178 sec/batch; 15h:43m:23s remains)
INFO - root - 2017-12-03 08:10:25.358091: step 14760, loss = 582.18, batch loss = 1.40 (43.6 examples/sec; 0.184 sec/batch; 16h:12m:40s remains)
INFO - root - 2017-12-03 08:10:27.156940: step 14770, loss = 582.03, batch loss = 1.25 (44.8 examples/sec; 0.178 sec/batch; 15h:45m:13s remains)
INFO - root - 2017-12-03 08:10:28.955819: step 14780, loss = 581.90, batch loss = 1.11 (44.0 examples/sec; 0.182 sec/batch; 16h:02m:49s remains)
INFO - root - 2017-12-03 08:10:30.771810: step 14790, loss = 581.97, batch loss = 1.18 (43.2 examples/sec; 0.185 sec/batch; 16h:21m:00s remains)
INFO - root - 2017-12-03 08:10:32.583288: step 14800, loss = 582.04, batch loss = 1.25 (45.4 examples/sec; 0.176 sec/batch; 15h:33m:42s remains)
INFO - root - 2017-12-03 08:10:34.428271: step 14810, loss = 581.78, batch loss = 1.00 (44.7 examples/sec; 0.179 sec/batch; 15h:48m:15s remains)
INFO - root - 2017-12-03 08:10:36.268826: step 14820, loss = 581.98, batch loss = 1.19 (43.3 examples/sec; 0.185 sec/batch; 16h:19m:03s remains)
INFO - root - 2017-12-03 08:10:38.100768: step 14830, loss = 582.03, batch loss = 1.24 (44.5 examples/sec; 0.180 sec/batch; 15h:52m:20s remains)
INFO - root - 2017-12-03 08:10:39.898666: step 14840, loss = 582.15, batch loss = 1.37 (45.1 examples/sec; 0.177 sec/batch; 15h:39m:44s remains)
INFO - root - 2017-12-03 08:10:41.708803: step 14850, loss = 582.03, batch loss = 1.25 (43.6 examples/sec; 0.183 sec/batch; 16h:11m:04s remains)
INFO - root - 2017-12-03 08:10:43.513329: step 14860, loss = 582.00, batch loss = 1.22 (45.1 examples/sec; 0.177 sec/batch; 15h:38m:03s remains)
INFO - root - 2017-12-03 08:10:45.297292: step 14870, loss = 581.84, batch loss = 1.06 (45.0 examples/sec; 0.178 sec/batch; 15h:41m:34s remains)
INFO - root - 2017-12-03 08:10:47.129498: step 14880, loss = 581.88, batch loss = 1.10 (43.8 examples/sec; 0.183 sec/batch; 16h:07m:54s remains)
INFO - root - 2017-12-03 08:10:48.944864: step 14890, loss = 582.04, batch loss = 1.26 (43.5 examples/sec; 0.184 sec/batch; 16h:12m:50s remains)
INFO - root - 2017-12-03 08:10:50.740212: step 14900, loss = 581.93, batch loss = 1.15 (45.4 examples/sec; 0.176 sec/batch; 15h:33m:19s remains)
INFO - root - 2017-12-03 08:10:52.598312: step 14910, loss = 582.01, batch loss = 1.22 (44.3 examples/sec; 0.181 sec/batch; 15h:56m:44s remains)
INFO - root - 2017-12-03 08:10:54.426585: step 14920, loss = 581.86, batch loss = 1.07 (45.7 examples/sec; 0.175 sec/batch; 15h:26m:28s remains)
INFO - root - 2017-12-03 08:10:56.229607: step 14930, loss = 582.13, batch loss = 1.34 (44.6 examples/sec; 0.179 sec/batch; 15h:49m:49s remains)
INFO - root - 2017-12-03 08:10:58.027715: step 14940, loss = 582.07, batch loss = 1.28 (45.6 examples/sec; 0.175 sec/batch; 15h:28m:37s remains)
INFO - root - 2017-12-03 08:10:59.822967: step 14950, loss = 581.92, batch loss = 1.13 (44.0 examples/sec; 0.182 sec/batch; 16h:02m:42s remains)
INFO - root - 2017-12-03 08:11:01.621804: step 14960, loss = 581.96, batch loss = 1.17 (43.4 examples/sec; 0.184 sec/batch; 16h:14m:36s remains)
INFO - root - 2017-12-03 08:11:03.422745: step 14970, loss = 581.89, batch loss = 1.11 (44.1 examples/sec; 0.181 sec/batch; 15h:59m:55s remains)
INFO - root - 2017-12-03 08:11:05.220857: step 14980, loss = 582.12, batch loss = 1.33 (45.1 examples/sec; 0.178 sec/batch; 15h:39m:38s remains)
INFO - root - 2017-12-03 08:11:07.020561: step 14990, loss = 581.96, batch loss = 1.18 (44.7 examples/sec; 0.179 sec/batch; 15h:46m:16s remains)
INFO - root - 2017-12-03 08:11:08.851682: step 15000, loss = 581.89, batch loss = 1.10 (44.5 examples/sec; 0.180 sec/batch; 15h:51m:14s remains)
INFO - root - 2017-12-03 08:11:10.750818: step 15010, loss = 582.02, batch loss = 1.23 (45.4 examples/sec; 0.176 sec/batch; 15h:32m:48s remains)
INFO - root - 2017-12-03 08:11:12.542724: step 15020, loss = 581.86, batch loss = 1.07 (45.0 examples/sec; 0.178 sec/batch; 15h:40m:13s remains)
INFO - root - 2017-12-03 08:11:14.343993: step 15030, loss = 582.03, batch loss = 1.24 (44.2 examples/sec; 0.181 sec/batch; 15h:58m:30s remains)
INFO - root - 2017-12-03 08:11:16.145422: step 15040, loss = 581.89, batch loss = 1.10 (44.5 examples/sec; 0.180 sec/batch; 15h:52m:06s remains)
INFO - root - 2017-12-03 08:11:17.949269: step 15050, loss = 582.11, batch loss = 1.32 (43.9 examples/sec; 0.182 sec/batch; 16h:03m:29s remains)
INFO - root - 2017-12-03 08:11:19.759883: step 15060, loss = 581.92, batch loss = 1.13 (45.8 examples/sec; 0.175 sec/batch; 15h:24m:26s remains)
INFO - root - 2017-12-03 08:11:21.586186: step 15070, loss = 581.84, batch loss = 1.05 (43.4 examples/sec; 0.184 sec/batch; 16h:14m:13s remains)
INFO - root - 2017-12-03 08:11:23.376947: step 15080, loss = 581.95, batch loss = 1.16 (44.4 examples/sec; 0.180 sec/batch; 15h:52m:12s remains)
INFO - root - 2017-12-03 08:11:25.205578: step 15090, loss = 581.80, batch loss = 1.02 (44.9 examples/sec; 0.178 sec/batch; 15h:42m:18s remains)
INFO - root - 2017-12-03 08:11:27.031160: step 15100, loss = 582.09, batch loss = 1.30 (44.2 examples/sec; 0.181 sec/batch; 15h:56m:28s remains)
INFO - root - 2017-12-03 08:11:28.913120: step 15110, loss = 582.20, batch loss = 1.41 (45.6 examples/sec; 0.176 sec/batch; 15h:28m:22s remains)
INFO - root - 2017-12-03 08:11:30.696005: step 15120, loss = 582.15, batch loss = 1.37 (45.0 examples/sec; 0.178 sec/batch; 15h:41m:23s remains)
INFO - root - 2017-12-03 08:11:32.499008: step 15130, loss = 582.11, batch loss = 1.32 (46.0 examples/sec; 0.174 sec/batch; 15h:19m:05s remains)
INFO - root - 2017-12-03 08:11:34.286253: step 15140, loss = 581.97, batch loss = 1.18 (44.9 examples/sec; 0.178 sec/batch; 15h:41m:50s remains)
INFO - root - 2017-12-03 08:11:36.084540: step 15150, loss = 581.97, batch loss = 1.18 (45.2 examples/sec; 0.177 sec/batch; 15h:36m:36s remains)
INFO - root - 2017-12-03 08:11:37.881652: step 15160, loss = 582.01, batch loss = 1.22 (42.7 examples/sec; 0.187 sec/batch; 16h:31m:17s remains)
INFO - root - 2017-12-03 08:11:39.669616: step 15170, loss = 582.02, batch loss = 1.24 (45.3 examples/sec; 0.177 sec/batch; 15h:33m:40s remains)
INFO - root - 2017-12-03 08:11:41.483898: step 15180, loss = 582.04, batch loss = 1.25 (45.2 examples/sec; 0.177 sec/batch; 15h:36m:43s remains)
INFO - root - 2017-12-03 08:11:43.287407: step 15190, loss = 581.95, batch loss = 1.16 (44.1 examples/sec; 0.181 sec/batch; 15h:59m:43s remains)
INFO - root - 2017-12-03 08:11:45.073771: step 15200, loss = 581.89, batch loss = 1.10 (44.7 examples/sec; 0.179 sec/batch; 15h:45m:31s remains)
INFO - root - 2017-12-03 08:11:46.956334: step 15210, loss = 582.05, batch loss = 1.26 (44.9 examples/sec; 0.178 sec/batch; 15h:42m:09s remains)
INFO - root - 2017-12-03 08:11:48.746951: step 15220, loss = 581.93, batch loss = 1.14 (44.7 examples/sec; 0.179 sec/batch; 15h:46m:03s remains)
INFO - root - 2017-12-03 08:11:50.551728: step 15230, loss = 581.96, batch loss = 1.17 (45.3 examples/sec; 0.177 sec/batch; 15h:34m:44s remains)
INFO - root - 2017-12-03 08:11:52.364169: step 15240, loss = 581.88, batch loss = 1.09 (43.4 examples/sec; 0.184 sec/batch; 16h:14m:19s remains)
INFO - root - 2017-12-03 08:11:54.149330: step 15250, loss = 581.94, batch loss = 1.15 (45.4 examples/sec; 0.176 sec/batch; 15h:31m:07s remains)
INFO - root - 2017-12-03 08:11:55.954458: step 15260, loss = 581.92, batch loss = 1.14 (45.0 examples/sec; 0.178 sec/batch; 15h:40m:46s remains)
INFO - root - 2017-12-03 08:11:57.762014: step 15270, loss = 581.98, batch loss = 1.19 (42.9 examples/sec; 0.186 sec/batch; 16h:25m:04s remains)
INFO - root - 2017-12-03 08:11:59.566278: step 15280, loss = 582.00, batch loss = 1.21 (44.7 examples/sec; 0.179 sec/batch; 15h:45m:36s remains)
INFO - root - 2017-12-03 08:12:01.382200: step 15290, loss = 582.05, batch loss = 1.26 (43.7 examples/sec; 0.183 sec/batch; 16h:08m:52s remains)
INFO - root - 2017-12-03 08:12:03.186235: step 15300, loss = 581.96, batch loss = 1.17 (42.7 examples/sec; 0.187 sec/batch; 16h:29m:27s remains)
INFO - root - 2017-12-03 08:12:05.057818: step 15310, loss = 581.81, batch loss = 1.03 (43.8 examples/sec; 0.183 sec/batch; 16h:06m:02s remains)
INFO - root - 2017-12-03 08:12:06.879951: step 15320, loss = 582.05, batch loss = 1.26 (45.2 examples/sec; 0.177 sec/batch; 15h:35m:51s remains)
INFO - root - 2017-12-03 08:12:08.703660: step 15330, loss = 581.93, batch loss = 1.15 (44.9 examples/sec; 0.178 sec/batch; 15h:41m:57s remains)
INFO - root - 2017-12-03 08:12:10.500243: step 15340, loss = 581.90, batch loss = 1.11 (44.9 examples/sec; 0.178 sec/batch; 15h:42m:05s remains)
INFO - root - 2017-12-03 08:12:12.331754: step 15350, loss = 582.15, batch loss = 1.36 (44.8 examples/sec; 0.179 sec/batch; 15h:43m:34s remains)
INFO - root - 2017-12-03 08:12:14.184603: step 15360, loss = 581.89, batch loss = 1.10 (44.6 examples/sec; 0.179 sec/batch; 15h:47m:06s remains)
INFO - root - 2017-12-03 08:12:15.989409: step 15370, loss = 581.76, batch loss = 0.97 (43.9 examples/sec; 0.182 sec/batch; 16h:03m:49s remains)
INFO - root - 2017-12-03 08:12:17.795262: step 15380, loss = 581.87, batch loss = 1.08 (45.2 examples/sec; 0.177 sec/batch; 15h:36m:10s remains)
INFO - root - 2017-12-03 08:12:19.618758: step 15390, loss = 581.75, batch loss = 0.97 (44.4 examples/sec; 0.180 sec/batch; 15h:53m:01s remains)
INFO - root - 2017-12-03 08:12:21.413984: step 15400, loss = 581.82, batch loss = 1.03 (44.0 examples/sec; 0.182 sec/batch; 16h:01m:32s remains)
INFO - root - 2017-12-03 08:12:23.325600: step 15410, loss = 581.88, batch loss = 1.09 (45.3 examples/sec; 0.176 sec/batch; 15h:32m:38s remains)
INFO - root - 2017-12-03 08:12:25.113103: step 15420, loss = 582.04, batch loss = 1.25 (44.3 examples/sec; 0.181 sec/batch; 15h:53m:58s remains)
INFO - root - 2017-12-03 08:12:26.923850: step 15430, loss = 582.09, batch loss = 1.30 (43.4 examples/sec; 0.184 sec/batch; 16h:14m:03s remains)
INFO - root - 2017-12-03 08:12:28.742792: step 15440, loss = 582.14, batch loss = 1.35 (43.2 examples/sec; 0.185 sec/batch; 16h:18m:21s remains)
INFO - root - 2017-12-03 08:12:30.527835: step 15450, loss = 582.03, batch loss = 1.24 (44.4 examples/sec; 0.180 sec/batch; 15h:51m:10s remains)
INFO - root - 2017-12-03 08:12:32.341514: step 15460, loss = 581.97, batch loss = 1.19 (44.3 examples/sec; 0.181 sec/batch; 15h:54m:53s remains)
INFO - root - 2017-12-03 08:12:34.120749: step 15470, loss = 581.94, batch loss = 1.16 (44.7 examples/sec; 0.179 sec/batch; 15h:44m:42s remains)
INFO - root - 2017-12-03 08:12:35.946041: step 15480, loss = 581.92, batch loss = 1.13 (44.2 examples/sec; 0.181 sec/batch; 15h:55m:23s remains)
INFO - root - 2017-12-03 08:12:37.738962: step 15490, loss = 581.90, batch loss = 1.12 (44.6 examples/sec; 0.180 sec/batch; 15h:48m:28s remains)
INFO - root - 2017-12-03 08:12:39.577141: step 15500, loss = 582.05, batch loss = 1.26 (43.9 examples/sec; 0.182 sec/batch; 16h:03m:34s remains)
INFO - root - 2017-12-03 08:12:41.439306: step 15510, loss = 581.99, batch loss = 1.20 (44.9 examples/sec; 0.178 sec/batch; 15h:41m:05s remains)
INFO - root - 2017-12-03 08:12:43.242190: step 15520, loss = 581.89, batch loss = 1.10 (44.9 examples/sec; 0.178 sec/batch; 15h:40m:24s remains)
INFO - root - 2017-12-03 08:12:45.054673: step 15530, loss = 581.84, batch loss = 1.05 (43.1 examples/sec; 0.186 sec/batch; 16h:20m:09s remains)
INFO - root - 2017-12-03 08:12:46.841699: step 15540, loss = 582.13, batch loss = 1.34 (44.7 examples/sec; 0.179 sec/batch; 15h:45m:06s remains)
INFO - root - 2017-12-03 08:12:48.656505: step 15550, loss = 581.83, batch loss = 1.05 (44.4 examples/sec; 0.180 sec/batch; 15h:52m:10s remains)
INFO - root - 2017-12-03 08:12:50.445545: step 15560, loss = 581.88, batch loss = 1.09 (43.3 examples/sec; 0.185 sec/batch; 16h:16m:34s remains)
INFO - root - 2017-12-03 08:12:52.263877: step 15570, loss = 582.03, batch loss = 1.24 (43.5 examples/sec; 0.184 sec/batch; 16h:10m:26s remains)
INFO - root - 2017-12-03 08:12:54.076300: step 15580, loss = 581.77, batch loss = 0.99 (44.3 examples/sec; 0.181 sec/batch; 15h:53m:57s remains)
INFO - root - 2017-12-03 08:12:55.892137: step 15590, loss = 582.07, batch loss = 1.28 (43.4 examples/sec; 0.184 sec/batch; 16h:12m:55s remains)
INFO - root - 2017-12-03 08:12:57.700086: step 15600, loss = 581.88, batch loss = 1.09 (44.9 examples/sec; 0.178 sec/batch; 15h:41m:48s remains)
INFO - root - 2017-12-03 08:12:59.569745: step 15610, loss = 582.03, batch loss = 1.24 (44.4 examples/sec; 0.180 sec/batch; 15h:50m:41s remains)
INFO - root - 2017-12-03 08:13:01.385926: step 15620, loss = 581.88, batch loss = 1.09 (43.9 examples/sec; 0.182 sec/batch; 16h:03m:21s remains)
INFO - root - 2017-12-03 08:13:03.166877: step 15630, loss = 581.93, batch loss = 1.14 (45.0 examples/sec; 0.178 sec/batch; 15h:39m:25s remains)
INFO - root - 2017-12-03 08:13:04.974552: step 15640, loss = 581.90, batch loss = 1.11 (45.7 examples/sec; 0.175 sec/batch; 15h:25m:24s remains)
INFO - root - 2017-12-03 08:13:06.764316: step 15650, loss = 581.98, batch loss = 1.19 (45.1 examples/sec; 0.177 sec/batch; 15h:35m:52s remains)
INFO - root - 2017-12-03 08:13:08.583026: step 15660, loss = 581.81, batch loss = 1.02 (44.7 examples/sec; 0.179 sec/batch; 15h:45m:48s remains)
INFO - root - 2017-12-03 08:13:10.390580: step 15670, loss = 582.13, batch loss = 1.34 (44.5 examples/sec; 0.180 sec/batch; 15h:49m:26s remains)
INFO - root - 2017-12-03 08:13:12.205600: step 15680, loss = 581.89, batch loss = 1.10 (43.3 examples/sec; 0.185 sec/batch; 16h:14m:49s remains)
INFO - root - 2017-12-03 08:13:14.008661: step 15690, loss = 581.97, batch loss = 1.18 (44.3 examples/sec; 0.181 sec/batch; 15h:54m:27s remains)
INFO - root - 2017-12-03 08:13:15.808640: step 15700, loss = 581.88, batch loss = 1.10 (44.8 examples/sec; 0.179 sec/batch; 15h:43m:40s remains)
INFO - root - 2017-12-03 08:13:17.691388: step 15710, loss = 581.85, batch loss = 1.06 (45.4 examples/sec; 0.176 sec/batch; 15h:30m:54s remains)
INFO - root - 2017-12-03 08:13:19.503426: step 15720, loss = 581.74, batch loss = 0.95 (43.6 examples/sec; 0.183 sec/batch; 16h:08m:48s remains)
INFO - root - 2017-12-03 08:13:21.311806: step 15730, loss = 581.83, batch loss = 1.04 (43.8 examples/sec; 0.182 sec/batch; 16h:03m:16s remains)
INFO - root - 2017-12-03 08:13:23.104596: step 15740, loss = 582.09, batch loss = 1.31 (44.8 examples/sec; 0.179 sec/batch; 15h:42m:57s remains)
INFO - root - 2017-12-03 08:13:24.910331: step 15750, loss = 582.06, batch loss = 1.27 (44.6 examples/sec; 0.179 sec/batch; 15h:47m:24s remains)
INFO - root - 2017-12-03 08:13:26.721134: step 15760, loss = 582.16, batch loss = 1.37 (45.5 examples/sec; 0.176 sec/batch; 15h:28m:51s remains)
INFO - root - 2017-12-03 08:13:28.519596: step 15770, loss = 581.91, batch loss = 1.12 (44.7 examples/sec; 0.179 sec/batch; 15h:44m:26s remains)
INFO - root - 2017-12-03 08:13:30.312306: step 15780, loss = 581.96, batch loss = 1.17 (44.6 examples/sec; 0.179 sec/batch; 15h:46m:10s remains)
INFO - root - 2017-12-03 08:13:32.104647: step 15790, loss = 581.95, batch loss = 1.16 (44.3 examples/sec; 0.181 sec/batch; 15h:52m:46s remains)
INFO - root - 2017-12-03 08:13:33.883728: step 15800, loss = 581.61, batch loss = 0.83 (45.8 examples/sec; 0.175 sec/batch; 15h:21m:45s remains)
INFO - root - 2017-12-03 08:13:35.752554: step 15810, loss = 581.90, batch loss = 1.11 (44.9 examples/sec; 0.178 sec/batch; 15h:40m:28s remains)
INFO - root - 2017-12-03 08:13:37.537271: step 15820, loss = 581.97, batch loss = 1.18 (44.2 examples/sec; 0.181 sec/batch; 15h:56m:11s remains)
INFO - root - 2017-12-03 08:13:39.363408: step 15830, loss = 582.22, batch loss = 1.43 (41.8 examples/sec; 0.191 sec/batch; 16h:49m:48s remains)
INFO - root - 2017-12-03 08:13:41.182538: step 15840, loss = 581.94, batch loss = 1.15 (44.7 examples/sec; 0.179 sec/batch; 15h:43m:33s remains)
INFO - root - 2017-12-03 08:13:42.963467: step 15850, loss = 581.91, batch loss = 1.13 (44.6 examples/sec; 0.179 sec/batch; 15h:46m:49s remains)
INFO - root - 2017-12-03 08:13:44.753517: step 15860, loss = 581.87, batch loss = 1.09 (46.0 examples/sec; 0.174 sec/batch; 15h:18m:23s remains)
INFO - root - 2017-12-03 08:13:46.535686: step 15870, loss = 581.93, batch loss = 1.14 (45.5 examples/sec; 0.176 sec/batch; 15h:28m:06s remains)
INFO - root - 2017-12-03 08:13:48.338899: step 15880, loss = 582.08, batch loss = 1.29 (44.2 examples/sec; 0.181 sec/batch; 15h:55m:56s remains)
INFO - root - 2017-12-03 08:13:50.159313: step 15890, loss = 582.06, batch loss = 1.27 (43.7 examples/sec; 0.183 sec/batch; 16h:07m:02s remains)
INFO - root - 2017-12-03 08:13:51.950779: step 15900, loss = 581.89, batch loss = 1.11 (44.8 examples/sec; 0.178 sec/batch; 15h:41m:28s remains)
INFO - root - 2017-12-03 08:13:53.797479: step 15910, loss = 581.96, batch loss = 1.17 (44.5 examples/sec; 0.180 sec/batch; 15h:49m:16s remains)
INFO - root - 2017-12-03 08:13:55.607920: step 15920, loss = 581.92, batch loss = 1.13 (44.3 examples/sec; 0.180 sec/batch; 15h:52m:09s remains)
INFO - root - 2017-12-03 08:13:57.387151: step 15930, loss = 581.83, batch loss = 1.04 (44.8 examples/sec; 0.179 sec/batch; 15h:43m:06s remains)
INFO - root - 2017-12-03 08:13:59.175001: step 15940, loss = 581.74, batch loss = 0.95 (45.5 examples/sec; 0.176 sec/batch; 15h:26m:55s remains)
INFO - root - 2017-12-03 08:14:00.962853: step 15950, loss = 581.98, batch loss = 1.20 (44.1 examples/sec; 0.181 sec/batch; 15h:56m:34s remains)
INFO - root - 2017-12-03 08:14:02.776022: step 15960, loss = 582.12, batch loss = 1.33 (45.4 examples/sec; 0.176 sec/batch; 15h:29m:34s remains)
INFO - root - 2017-12-03 08:14:04.586529: step 15970, loss = 581.99, batch loss = 1.20 (43.5 examples/sec; 0.184 sec/batch; 16h:10m:34s remains)
INFO - root - 2017-12-03 08:14:06.379059: step 15980, loss = 581.94, batch loss = 1.15 (44.7 examples/sec; 0.179 sec/batch; 15h:44m:38s remains)
INFO - root - 2017-12-03 08:14:08.191400: step 15990, loss = 581.94, batch loss = 1.15 (43.8 examples/sec; 0.183 sec/batch; 16h:03m:54s remains)
INFO - root - 2017-12-03 08:14:09.980783: step 16000, loss = 581.84, batch loss = 1.05 (44.7 examples/sec; 0.179 sec/batch; 15h:45m:06s remains)
INFO - root - 2017-12-03 08:14:11.854482: step 16010, loss = 582.18, batch loss = 1.39 (45.1 examples/sec; 0.178 sec/batch; 15h:36m:31s remains)
INFO - root - 2017-12-03 08:14:13.665175: step 16020, loss = 582.15, batch loss = 1.36 (43.4 examples/sec; 0.184 sec/batch; 16h:11m:30s remains)
INFO - root - 2017-12-03 08:14:15.485398: step 16030, loss = 581.76, batch loss = 0.97 (43.2 examples/sec; 0.185 sec/batch; 16h:16m:32s remains)
INFO - root - 2017-12-03 08:14:17.281439: step 16040, loss = 581.99, batch loss = 1.20 (45.3 examples/sec; 0.177 sec/batch; 15h:31m:50s remains)
INFO - root - 2017-12-03 08:14:19.092332: step 16050, loss = 581.91, batch loss = 1.12 (45.5 examples/sec; 0.176 sec/batch; 15h:27m:31s remains)
INFO - root - 2017-12-03 08:14:20.890822: step 16060, loss = 581.85, batch loss = 1.06 (43.6 examples/sec; 0.184 sec/batch; 16h:08m:27s remains)
INFO - root - 2017-12-03 08:14:22.678925: step 16070, loss = 582.05, batch loss = 1.26 (45.3 examples/sec; 0.177 sec/batch; 15h:31m:05s remains)
INFO - root - 2017-12-03 08:14:24.475697: step 16080, loss = 581.94, batch loss = 1.15 (44.3 examples/sec; 0.180 sec/batch; 15h:51m:50s remains)
INFO - root - 2017-12-03 08:14:26.276531: step 16090, loss = 582.10, batch loss = 1.32 (45.8 examples/sec; 0.175 sec/batch; 15h:21m:56s remains)
INFO - root - 2017-12-03 08:14:28.073062: step 16100, loss = 582.04, batch loss = 1.25 (45.2 examples/sec; 0.177 sec/batch; 15h:33m:26s remains)
INFO - root - 2017-12-03 08:14:29.935526: step 16110, loss = 581.94, batch loss = 1.15 (43.8 examples/sec; 0.183 sec/batch; 16h:03m:08s remains)
INFO - root - 2017-12-03 08:14:31.703296: step 16120, loss = 581.89, batch loss = 1.10 (45.5 examples/sec; 0.176 sec/batch; 15h:27m:22s remains)
INFO - root - 2017-12-03 08:14:33.506824: step 16130, loss = 582.14, batch loss = 1.35 (44.1 examples/sec; 0.181 sec/batch; 15h:56m:01s remains)
INFO - root - 2017-12-03 08:14:35.295559: step 16140, loss = 581.98, batch loss = 1.19 (44.4 examples/sec; 0.180 sec/batch; 15h:50m:09s remains)
INFO - root - 2017-12-03 08:14:37.093801: step 16150, loss = 582.08, batch loss = 1.30 (43.6 examples/sec; 0.183 sec/batch; 16h:06m:24s remains)
INFO - root - 2017-12-03 08:14:38.858822: step 16160, loss = 581.86, batch loss = 1.07 (45.7 examples/sec; 0.175 sec/batch; 15h:23m:48s remains)
INFO - root - 2017-12-03 08:14:40.673956: step 16170, loss = 581.83, batch loss = 1.04 (44.3 examples/sec; 0.180 sec/batch; 15h:51m:37s remains)
INFO - root - 2017-12-03 08:14:42.455531: step 16180, loss = 581.99, batch loss = 1.20 (44.4 examples/sec; 0.180 sec/batch; 15h:49m:17s remains)
INFO - root - 2017-12-03 08:14:44.261234: step 16190, loss = 581.87, batch loss = 1.08 (44.5 examples/sec; 0.180 sec/batch; 15h:47m:04s remains)
INFO - root - 2017-12-03 08:14:46.074014: step 16200, loss = 581.99, batch loss = 1.20 (42.9 examples/sec; 0.186 sec/batch; 16h:22m:50s remains)
INFO - root - 2017-12-03 08:14:47.946476: step 16210, loss = 581.93, batch loss = 1.14 (43.3 examples/sec; 0.185 sec/batch; 16h:13m:46s remains)
INFO - root - 2017-12-03 08:14:49.731554: step 16220, loss = 581.98, batch loss = 1.19 (44.6 examples/sec; 0.179 sec/batch; 15h:45m:18s remains)
INFO - root - 2017-12-03 08:14:51.536485: step 16230, loss = 582.13, batch loss = 1.34 (45.7 examples/sec; 0.175 sec/batch; 15h:23m:09s remains)
INFO - root - 2017-12-03 08:14:53.351030: step 16240, loss = 582.15, batch loss = 1.36 (44.0 examples/sec; 0.182 sec/batch; 15h:58m:32s remains)
INFO - root - 2017-12-03 08:14:55.156847: step 16250, loss = 581.97, batch loss = 1.19 (44.2 examples/sec; 0.181 sec/batch; 15h:53m:52s remains)
INFO - root - 2017-12-03 08:14:56.966743: step 16260, loss = 582.04, batch loss = 1.26 (44.1 examples/sec; 0.181 sec/batch; 15h:55m:30s remains)
INFO - root - 2017-12-03 08:14:58.783520: step 16270, loss = 582.13, batch loss = 1.34 (43.6 examples/sec; 0.184 sec/batch; 16h:07m:56s remains)
INFO - root - 2017-12-03 08:15:00.563391: step 16280, loss = 582.25, batch loss = 1.47 (45.7 examples/sec; 0.175 sec/batch; 15h:22m:01s remains)
INFO - root - 2017-12-03 08:15:02.348692: step 16290, loss = 582.02, batch loss = 1.24 (44.9 examples/sec; 0.178 sec/batch; 15h:39m:43s remains)
INFO - root - 2017-12-03 08:15:04.144421: step 16300, loss = 582.08, batch loss = 1.29 (45.8 examples/sec; 0.175 sec/batch; 15h:20m:55s remains)
INFO - root - 2017-12-03 08:15:06.030295: step 16310, loss = 582.00, batch loss = 1.21 (44.3 examples/sec; 0.180 sec/batch; 15h:50m:45s remains)
INFO - root - 2017-12-03 08:15:07.845723: step 16320, loss = 581.76, batch loss = 0.97 (45.0 examples/sec; 0.178 sec/batch; 15h:37m:12s remains)
INFO - root - 2017-12-03 08:15:09.634219: step 16330, loss = 582.05, batch loss = 1.26 (45.3 examples/sec; 0.177 sec/batch; 15h:30m:15s remains)
INFO - root - 2017-12-03 08:15:11.445567: step 16340, loss = 582.18, batch loss = 1.40 (46.1 examples/sec; 0.174 sec/batch; 15h:14m:59s remains)
INFO - root - 2017-12-03 08:15:13.256352: step 16350, loss = 582.03, batch loss = 1.24 (43.7 examples/sec; 0.183 sec/batch; 16h:03m:59s remains)
INFO - root - 2017-12-03 08:15:15.053286: step 16360, loss = 581.98, batch loss = 1.19 (46.1 examples/sec; 0.173 sec/batch; 15h:14m:08s remains)
INFO - root - 2017-12-03 08:15:16.864038: step 16370, loss = 582.19, batch loss = 1.40 (44.0 examples/sec; 0.182 sec/batch; 15h:57m:44s remains)
INFO - root - 2017-12-03 08:15:18.658070: step 16380, loss = 582.03, batch loss = 1.25 (43.9 examples/sec; 0.182 sec/batch; 15h:59m:20s remains)
INFO - root - 2017-12-03 08:15:20.483145: step 16390, loss = 582.01, batch loss = 1.22 (45.2 examples/sec; 0.177 sec/batch; 15h:32m:53s remains)
INFO - root - 2017-12-03 08:15:22.312015: step 16400, loss = 582.01, batch loss = 1.23 (43.5 examples/sec; 0.184 sec/batch; 16h:09m:13s remains)
INFO - root - 2017-12-03 08:15:24.201338: step 16410, loss = 582.01, batch loss = 1.22 (44.0 examples/sec; 0.182 sec/batch; 15h:57m:01s remains)
INFO - root - 2017-12-03 08:15:25.995466: step 16420, loss = 582.01, batch loss = 1.23 (44.1 examples/sec; 0.181 sec/batch; 15h:55m:08s remains)
INFO - root - 2017-12-03 08:15:27.814519: step 16430, loss = 582.03, batch loss = 1.24 (45.1 examples/sec; 0.178 sec/batch; 15h:35m:16s remains)
INFO - root - 2017-12-03 08:15:29.640051: step 16440, loss = 581.96, batch loss = 1.17 (44.3 examples/sec; 0.180 sec/batch; 15h:50m:41s remains)
INFO - root - 2017-12-03 08:15:31.452450: step 16450, loss = 582.00, batch loss = 1.21 (43.0 examples/sec; 0.186 sec/batch; 16h:20m:56s remains)
INFO - root - 2017-12-03 08:15:33.247926: step 16460, loss = 581.86, batch loss = 1.08 (43.9 examples/sec; 0.182 sec/batch; 16h:00m:38s remains)
INFO - root - 2017-12-03 08:15:35.077996: step 16470, loss = 581.96, batch loss = 1.17 (44.4 examples/sec; 0.180 sec/batch; 15h:49m:37s remains)
INFO - root - 2017-12-03 08:15:36.864703: step 16480, loss = 582.05, batch loss = 1.26 (45.2 examples/sec; 0.177 sec/batch; 15h:32m:10s remains)
INFO - root - 2017-12-03 08:15:38.661711: step 16490, loss = 581.84, batch loss = 1.06 (44.8 examples/sec; 0.179 sec/batch; 15h:41m:05s remains)
INFO - root - 2017-12-03 08:15:40.501853: step 16500, loss = 581.90, batch loss = 1.11 (45.4 examples/sec; 0.176 sec/batch; 15h:28m:38s remains)
INFO - root - 2017-12-03 08:15:42.364767: step 16510, loss = 581.80, batch loss = 1.01 (45.4 examples/sec; 0.176 sec/batch; 15h:28m:14s remains)
INFO - root - 2017-12-03 08:15:44.163943: step 16520, loss = 581.92, batch loss = 1.13 (44.9 examples/sec; 0.178 sec/batch; 15h:38m:06s remains)
INFO - root - 2017-12-03 08:15:45.943177: step 16530, loss = 581.95, batch loss = 1.16 (46.0 examples/sec; 0.174 sec/batch; 15h:15m:22s remains)
INFO - root - 2017-12-03 08:15:47.739098: step 16540, loss = 581.93, batch loss = 1.14 (43.0 examples/sec; 0.186 sec/batch; 16h:18m:39s remains)
INFO - root - 2017-12-03 08:15:49.539592: step 16550, loss = 582.10, batch loss = 1.32 (45.1 examples/sec; 0.177 sec/batch; 15h:33m:15s remains)
INFO - root - 2017-12-03 08:15:51.329152: step 16560, loss = 581.90, batch loss = 1.11 (43.5 examples/sec; 0.184 sec/batch; 16h:07m:21s remains)
INFO - root - 2017-12-03 08:15:53.118787: step 16570, loss = 582.02, batch loss = 1.23 (44.8 examples/sec; 0.178 sec/batch; 15h:39m:32s remains)
INFO - root - 2017-12-03 08:15:54.947853: step 16580, loss = 581.88, batch loss = 1.09 (45.5 examples/sec; 0.176 sec/batch; 15h:25m:11s remains)
INFO - root - 2017-12-03 08:15:56.742311: step 16590, loss = 582.17, batch loss = 1.38 (44.6 examples/sec; 0.179 sec/batch; 15h:44m:02s remains)
INFO - root - 2017-12-03 08:15:58.534756: step 16600, loss = 582.00, batch loss = 1.21 (45.6 examples/sec; 0.175 sec/batch; 15h:23m:08s remains)
INFO - root - 2017-12-03 08:16:00.394436: step 16610, loss = 582.18, batch loss = 1.39 (44.6 examples/sec; 0.180 sec/batch; 15h:45m:11s remains)
INFO - root - 2017-12-03 08:16:02.183187: step 16620, loss = 581.79, batch loss = 1.00 (45.1 examples/sec; 0.178 sec/batch; 15h:34m:44s remains)
INFO - root - 2017-12-03 08:16:03.983330: step 16630, loss = 582.00, batch loss = 1.21 (44.1 examples/sec; 0.181 sec/batch; 15h:54m:44s remains)
INFO - root - 2017-12-03 08:16:05.790902: step 16640, loss = 582.03, batch loss = 1.24 (42.7 examples/sec; 0.187 sec/batch; 16h:26m:35s remains)
INFO - root - 2017-12-03 08:16:07.586658: step 16650, loss = 581.95, batch loss = 1.16 (45.0 examples/sec; 0.178 sec/batch; 15h:35m:44s remains)
INFO - root - 2017-12-03 08:16:09.408633: step 16660, loss = 582.01, batch loss = 1.22 (43.5 examples/sec; 0.184 sec/batch; 16h:08m:30s remains)
INFO - root - 2017-12-03 08:16:11.205778: step 16670, loss = 581.86, batch loss = 1.07 (43.3 examples/sec; 0.185 sec/batch; 16h:11m:34s remains)
INFO - root - 2017-12-03 08:16:13.017447: step 16680, loss = 582.00, batch loss = 1.21 (44.8 examples/sec; 0.179 sec/batch; 15h:40m:49s remains)
INFO - root - 2017-12-03 08:16:14.833871: step 16690, loss = 581.83, batch loss = 1.04 (45.7 examples/sec; 0.175 sec/batch; 15h:20m:33s remains)
INFO - root - 2017-12-03 08:16:16.616808: step 16700, loss = 582.02, batch loss = 1.23 (44.6 examples/sec; 0.179 sec/batch; 15h:44m:21s remains)
INFO - root - 2017-12-03 08:16:18.539887: step 16710, loss = 581.97, batch loss = 1.18 (44.4 examples/sec; 0.180 sec/batch; 15h:49m:03s remains)
INFO - root - 2017-12-03 08:16:20.324645: step 16720, loss = 581.78, batch loss = 1.00 (44.1 examples/sec; 0.181 sec/batch; 15h:54m:13s remains)
INFO - root - 2017-12-03 08:16:22.142243: step 16730, loss = 581.96, batch loss = 1.17 (44.6 examples/sec; 0.179 sec/batch; 15h:43m:13s remains)
INFO - root - 2017-12-03 08:16:23.930659: step 16740, loss = 581.96, batch loss = 1.18 (43.9 examples/sec; 0.182 sec/batch; 15h:59m:28s remains)
INFO - root - 2017-12-03 08:16:25.731904: step 16750, loss = 582.14, batch loss = 1.36 (45.3 examples/sec; 0.176 sec/batch; 15h:28m:35s remains)
INFO - root - 2017-12-03 08:16:27.544363: step 16760, loss = 581.92, batch loss = 1.13 (42.5 examples/sec; 0.188 sec/batch; 16h:29m:56s remains)
INFO - root - 2017-12-03 08:16:29.334637: step 16770, loss = 581.98, batch loss = 1.19 (45.1 examples/sec; 0.177 sec/batch; 15h:33m:58s remains)
INFO - root - 2017-12-03 08:16:31.128122: step 16780, loss = 582.00, batch loss = 1.21 (44.0 examples/sec; 0.182 sec/batch; 15h:56m:44s remains)
INFO - root - 2017-12-03 08:16:32.916133: step 16790, loss = 582.00, batch loss = 1.21 (44.5 examples/sec; 0.180 sec/batch; 15h:45m:54s remains)
INFO - root - 2017-12-03 08:16:34.713443: step 16800, loss = 581.86, batch loss = 1.07 (45.0 examples/sec; 0.178 sec/batch; 15h:34m:36s remains)
INFO - root - 2017-12-03 08:16:36.569992: step 16810, loss = 582.06, batch loss = 1.28 (43.5 examples/sec; 0.184 sec/batch; 16h:08m:32s remains)
INFO - root - 2017-12-03 08:16:38.359493: step 16820, loss = 582.28, batch loss = 1.49 (44.7 examples/sec; 0.179 sec/batch; 15h:42m:01s remains)
INFO - root - 2017-12-03 08:16:40.160723: step 16830, loss = 582.04, batch loss = 1.25 (44.6 examples/sec; 0.179 sec/batch; 15h:43m:26s remains)
INFO - root - 2017-12-03 08:16:41.944709: step 16840, loss = 582.09, batch loss = 1.30 (43.1 examples/sec; 0.186 sec/batch; 16h:17m:16s remains)
INFO - root - 2017-12-03 08:16:43.736113: step 16850, loss = 582.02, batch loss = 1.23 (44.4 examples/sec; 0.180 sec/batch; 15h:47m:18s remains)
INFO - root - 2017-12-03 08:16:45.526980: step 16860, loss = 581.85, batch loss = 1.06 (44.9 examples/sec; 0.178 sec/batch; 15h:38m:06s remains)
INFO - root - 2017-12-03 08:16:47.327548: step 16870, loss = 581.96, batch loss = 1.17 (45.3 examples/sec; 0.176 sec/batch; 15h:28m:20s remains)
INFO - root - 2017-12-03 08:16:49.108705: step 16880, loss = 581.73, batch loss = 0.94 (44.1 examples/sec; 0.181 sec/batch; 15h:53m:29s remains)
INFO - root - 2017-12-03 08:16:50.912190: step 16890, loss = 581.95, batch loss = 1.16 (45.2 examples/sec; 0.177 sec/batch; 15h:30m:12s remains)
INFO - root - 2017-12-03 08:16:52.723471: step 16900, loss = 581.76, batch loss = 0.98 (44.3 examples/sec; 0.181 sec/batch; 15h:50m:11s remains)
INFO - root - 2017-12-03 08:16:54.592183: step 16910, loss = 581.74, batch loss = 0.95 (43.9 examples/sec; 0.182 sec/batch; 15h:58m:15s remains)
INFO - root - 2017-12-03 08:16:56.387379: step 16920, loss = 581.98, batch loss = 1.19 (44.6 examples/sec; 0.179 sec/batch; 15h:43m:40s remains)
INFO - root - 2017-12-03 08:16:58.190714: step 16930, loss = 582.04, batch loss = 1.26 (44.6 examples/sec; 0.179 sec/batch; 15h:43m:48s remains)
INFO - root - 2017-12-03 08:16:59.971862: step 16940, loss = 581.96, batch loss = 1.17 (45.7 examples/sec; 0.175 sec/batch; 15h:20m:17s remains)
INFO - root - 2017-12-03 08:17:01.767765: step 16950, loss = 581.85, batch loss = 1.06 (45.0 examples/sec; 0.178 sec/batch; 15h:35m:53s remains)
INFO - root - 2017-12-03 08:17:03.579184: step 16960, loss = 582.07, batch loss = 1.28 (44.0 examples/sec; 0.182 sec/batch; 15h:56m:32s remains)
INFO - root - 2017-12-03 08:17:05.365143: step 16970, loss = 581.93, batch loss = 1.14 (45.3 examples/sec; 0.176 sec/batch; 15h:27m:57s remains)
INFO - root - 2017-12-03 08:17:07.173647: step 16980, loss = 582.12, batch loss = 1.33 (41.1 examples/sec; 0.195 sec/batch; 17h:02m:51s remains)
INFO - root - 2017-12-03 08:17:08.954234: step 16990, loss = 582.21, batch loss = 1.42 (45.1 examples/sec; 0.177 sec/batch; 15h:31m:54s remains)
INFO - root - 2017-12-03 08:17:10.756673: step 17000, loss = 582.24, batch loss = 1.45 (44.0 examples/sec; 0.182 sec/batch; 15h:56m:35s remains)
INFO - root - 2017-12-03 08:17:12.613423: step 17010, loss = 582.00, batch loss = 1.22 (43.8 examples/sec; 0.183 sec/batch; 15h:59m:54s remains)
INFO - root - 2017-12-03 08:17:14.401924: step 17020, loss = 582.01, batch loss = 1.22 (44.0 examples/sec; 0.182 sec/batch; 15h:56m:44s remains)
INFO - root - 2017-12-03 08:17:16.198330: step 17030, loss = 582.02, batch loss = 1.23 (43.8 examples/sec; 0.183 sec/batch; 15h:59m:46s remains)
INFO - root - 2017-12-03 08:17:18.018351: step 17040, loss = 582.03, batch loss = 1.24 (42.9 examples/sec; 0.187 sec/batch; 16h:21m:09s remains)
INFO - root - 2017-12-03 08:17:19.809352: step 17050, loss = 582.00, batch loss = 1.21 (45.0 examples/sec; 0.178 sec/batch; 15h:35m:30s remains)
INFO - root - 2017-12-03 08:17:21.632447: step 17060, loss = 581.97, batch loss = 1.19 (44.9 examples/sec; 0.178 sec/batch; 15h:36m:46s remains)
INFO - root - 2017-12-03 08:17:23.417201: step 17070, loss = 582.17, batch loss = 1.38 (44.6 examples/sec; 0.179 sec/batch; 15h:42m:17s remains)
INFO - root - 2017-12-03 08:17:25.212238: step 17080, loss = 581.94, batch loss = 1.15 (45.1 examples/sec; 0.177 sec/batch; 15h:32m:55s remains)
INFO - root - 2017-12-03 08:17:27.024720: step 17090, loss = 582.02, batch loss = 1.23 (42.3 examples/sec; 0.189 sec/batch; 16h:33m:20s remains)
INFO - root - 2017-12-03 08:17:28.827994: step 17100, loss = 581.85, batch loss = 1.07 (44.1 examples/sec; 0.182 sec/batch; 15h:54m:37s remains)
INFO - root - 2017-12-03 08:17:30.660507: step 17110, loss = 582.05, batch loss = 1.27 (45.0 examples/sec; 0.178 sec/batch; 15h:35m:13s remains)
INFO - root - 2017-12-03 08:17:32.444193: step 17120, loss = 582.12, batch loss = 1.33 (43.6 examples/sec; 0.183 sec/batch; 16h:03m:53s remains)
INFO - root - 2017-12-03 08:17:34.226687: step 17130, loss = 581.80, batch loss = 1.02 (44.7 examples/sec; 0.179 sec/batch; 15h:40m:00s remains)
INFO - root - 2017-12-03 08:17:36.047511: step 17140, loss = 581.99, batch loss = 1.21 (42.3 examples/sec; 0.189 sec/batch; 16h:33m:28s remains)
INFO - root - 2017-12-03 08:17:37.850782: step 17150, loss = 581.75, batch loss = 0.96 (43.8 examples/sec; 0.183 sec/batch; 16h:00m:55s remains)
INFO - root - 2017-12-03 08:17:39.665446: step 17160, loss = 582.03, batch loss = 1.24 (44.1 examples/sec; 0.181 sec/batch; 15h:53m:24s remains)
INFO - root - 2017-12-03 08:17:41.466497: step 17170, loss = 582.20, batch loss = 1.41 (45.2 examples/sec; 0.177 sec/batch; 15h:30m:29s remains)
INFO - root - 2017-12-03 08:17:43.250510: step 17180, loss = 582.07, batch loss = 1.28 (45.5 examples/sec; 0.176 sec/batch; 15h:24m:46s remains)
INFO - root - 2017-12-03 08:17:45.046000: step 17190, loss = 581.97, batch loss = 1.18 (45.1 examples/sec; 0.177 sec/batch; 15h:32m:14s remains)
INFO - root - 2017-12-03 08:17:46.831233: step 17200, loss = 582.06, batch loss = 1.27 (44.8 examples/sec; 0.179 sec/batch; 15h:39m:13s remains)
INFO - root - 2017-12-03 08:17:48.686986: step 17210, loss = 582.12, batch loss = 1.34 (45.3 examples/sec; 0.176 sec/batch; 15h:27m:16s remains)
INFO - root - 2017-12-03 08:17:50.482562: step 17220, loss = 581.86, batch loss = 1.07 (44.4 examples/sec; 0.180 sec/batch; 15h:47m:29s remains)
INFO - root - 2017-12-03 08:17:52.271571: step 17230, loss = 581.90, batch loss = 1.11 (44.0 examples/sec; 0.182 sec/batch; 15h:55m:53s remains)
INFO - root - 2017-12-03 08:17:54.084007: step 17240, loss = 581.80, batch loss = 1.02 (44.1 examples/sec; 0.181 sec/batch; 15h:52m:34s remains)
INFO - root - 2017-12-03 08:17:55.891111: step 17250, loss = 582.01, batch loss = 1.22 (43.7 examples/sec; 0.183 sec/batch; 16h:02m:44s remains)
INFO - root - 2017-12-03 08:17:57.699715: step 17260, loss = 581.86, batch loss = 1.07 (45.2 examples/sec; 0.177 sec/batch; 15h:28m:57s remains)
INFO - root - 2017-12-03 08:17:59.501486: step 17270, loss = 582.00, batch loss = 1.21 (44.2 examples/sec; 0.181 sec/batch; 15h:51m:50s remains)
INFO - root - 2017-12-03 08:18:01.283601: step 17280, loss = 581.90, batch loss = 1.11 (44.9 examples/sec; 0.178 sec/batch; 15h:36m:42s remains)
INFO - root - 2017-12-03 08:18:03.088247: step 17290, loss = 581.93, batch loss = 1.14 (44.5 examples/sec; 0.180 sec/batch; 15h:43m:58s remains)
INFO - root - 2017-12-03 08:18:04.878272: step 17300, loss = 581.99, batch loss = 1.20 (43.2 examples/sec; 0.185 sec/batch; 16h:12m:57s remains)
INFO - root - 2017-12-03 08:18:06.750393: step 17310, loss = 582.12, batch loss = 1.33 (44.8 examples/sec; 0.179 sec/batch; 15h:38m:39s remains)
INFO - root - 2017-12-03 08:18:08.561475: step 17320, loss = 581.90, batch loss = 1.11 (43.5 examples/sec; 0.184 sec/batch; 16h:06m:45s remains)
INFO - root - 2017-12-03 08:18:10.383190: step 17330, loss = 581.82, batch loss = 1.03 (44.4 examples/sec; 0.180 sec/batch; 15h:46m:58s remains)
INFO - root - 2017-12-03 08:18:12.171587: step 17340, loss = 582.24, batch loss = 1.45 (44.7 examples/sec; 0.179 sec/batch; 15h:40m:57s remains)
INFO - root - 2017-12-03 08:18:13.979657: step 17350, loss = 581.93, batch loss = 1.14 (43.2 examples/sec; 0.185 sec/batch; 16h:11m:56s remains)
INFO - root - 2017-12-03 08:18:15.772350: step 17360, loss = 581.98, batch loss = 1.19 (44.7 examples/sec; 0.179 sec/batch; 15h:39m:40s remains)
INFO - root - 2017-12-03 08:18:17.569724: step 17370, loss = 582.06, batch loss = 1.27 (43.9 examples/sec; 0.182 sec/batch; 15h:57m:27s remains)
INFO - root - 2017-12-03 08:18:19.366535: step 17380, loss = 581.88, batch loss = 1.09 (42.6 examples/sec; 0.188 sec/batch; 16h:27m:15s remains)
INFO - root - 2017-12-03 08:18:21.148421: step 17390, loss = 581.97, batch loss = 1.18 (44.5 examples/sec; 0.180 sec/batch; 15h:43m:20s remains)
INFO - root - 2017-12-03 08:18:22.959415: step 17400, loss = 581.92, batch loss = 1.14 (45.1 examples/sec; 0.178 sec/batch; 15h:32m:16s remains)
INFO - root - 2017-12-03 08:18:24.821899: step 17410, loss = 581.93, batch loss = 1.14 (43.7 examples/sec; 0.183 sec/batch; 16h:00m:21s remains)
INFO - root - 2017-12-03 08:18:26.631597: step 17420, loss = 581.97, batch loss = 1.18 (44.0 examples/sec; 0.182 sec/batch; 15h:55m:29s remains)
INFO - root - 2017-12-03 08:18:28.454504: step 17430, loss = 582.06, batch loss = 1.27 (45.0 examples/sec; 0.178 sec/batch; 15h:33m:01s remains)
INFO - root - 2017-12-03 08:18:30.261252: step 17440, loss = 581.78, batch loss = 0.99 (44.9 examples/sec; 0.178 sec/batch; 15h:34m:43s remains)
INFO - root - 2017-12-03 08:18:32.048183: step 17450, loss = 581.79, batch loss = 1.00 (43.9 examples/sec; 0.182 sec/batch; 15h:57m:41s remains)
INFO - root - 2017-12-03 08:18:33.847461: step 17460, loss = 582.02, batch loss = 1.23 (45.6 examples/sec; 0.175 sec/batch; 15h:20m:56s remains)
INFO - root - 2017-12-03 08:18:35.634584: step 17470, loss = 582.06, batch loss = 1.27 (45.3 examples/sec; 0.177 sec/batch; 15h:27m:30s remains)
INFO - root - 2017-12-03 08:18:37.430924: step 17480, loss = 581.91, batch loss = 1.13 (45.6 examples/sec; 0.175 sec/batch; 15h:21m:16s remains)
INFO - root - 2017-12-03 08:18:39.229206: step 17490, loss = 581.83, batch loss = 1.04 (43.5 examples/sec; 0.184 sec/batch; 16h:04m:56s remains)
INFO - root - 2017-12-03 08:18:41.001636: step 17500, loss = 581.82, batch loss = 1.03 (45.2 examples/sec; 0.177 sec/batch; 15h:28m:48s remains)
INFO - root - 2017-12-03 08:18:42.848411: step 17510, loss = 582.21, batch loss = 1.42 (44.7 examples/sec; 0.179 sec/batch; 15h:39m:01s remains)
INFO - root - 2017-12-03 08:18:44.658871: step 17520, loss = 582.21, batch loss = 1.42 (45.0 examples/sec; 0.178 sec/batch; 15h:33m:34s remains)
INFO - root - 2017-12-03 08:18:46.454700: step 17530, loss = 582.09, batch loss = 1.30 (44.8 examples/sec; 0.179 sec/batch; 15h:38m:25s remains)
INFO - root - 2017-12-03 08:18:48.248973: step 17540, loss = 581.90, batch loss = 1.12 (44.2 examples/sec; 0.181 sec/batch; 15h:50m:52s remains)
INFO - root - 2017-12-03 08:18:50.026594: step 17550, loss = 582.02, batch loss = 1.23 (45.1 examples/sec; 0.177 sec/batch; 15h:31m:38s remains)
INFO - root - 2017-12-03 08:18:51.814197: step 17560, loss = 582.02, batch loss = 1.23 (43.8 examples/sec; 0.183 sec/batch; 15h:59m:09s remains)
INFO - root - 2017-12-03 08:18:53.604935: step 17570, loss = 581.87, batch loss = 1.08 (44.3 examples/sec; 0.180 sec/batch; 15h:46m:49s remains)
INFO - root - 2017-12-03 08:18:55.421083: step 17580, loss = 581.85, batch loss = 1.06 (46.0 examples/sec; 0.174 sec/batch; 15h:13m:24s remains)
INFO - root - 2017-12-03 08:18:57.223813: step 17590, loss = 582.00, batch loss = 1.21 (45.2 examples/sec; 0.177 sec/batch; 15h:28m:09s remains)
INFO - root - 2017-12-03 08:18:59.018310: step 17600, loss = 582.04, batch loss = 1.25 (44.5 examples/sec; 0.180 sec/batch; 15h:44m:09s remains)
INFO - root - 2017-12-03 08:19:00.885964: step 17610, loss = 581.93, batch loss = 1.14 (44.9 examples/sec; 0.178 sec/batch; 15h:35m:02s remains)
INFO - root - 2017-12-03 08:19:02.679161: step 17620, loss = 582.02, batch loss = 1.23 (43.8 examples/sec; 0.183 sec/batch; 15h:58m:27s remains)
INFO - root - 2017-12-03 08:19:04.462040: step 17630, loss = 582.03, batch loss = 1.24 (44.7 examples/sec; 0.179 sec/batch; 15h:40m:09s remains)
INFO - root - 2017-12-03 08:19:06.260197: step 17640, loss = 582.17, batch loss = 1.38 (43.2 examples/sec; 0.185 sec/batch; 16h:11m:39s remains)
INFO - root - 2017-12-03 08:19:08.055914: step 17650, loss = 581.92, batch loss = 1.14 (44.9 examples/sec; 0.178 sec/batch; 15h:35m:15s remains)
INFO - root - 2017-12-03 08:19:09.853232: step 17660, loss = 582.03, batch loss = 1.24 (44.6 examples/sec; 0.179 sec/batch; 15h:40m:57s remains)
INFO - root - 2017-12-03 08:19:11.643887: step 17670, loss = 581.96, batch loss = 1.18 (45.0 examples/sec; 0.178 sec/batch; 15h:32m:27s remains)
INFO - root - 2017-12-03 08:19:13.446046: step 17680, loss = 581.96, batch loss = 1.18 (45.6 examples/sec; 0.176 sec/batch; 15h:21m:15s remains)
INFO - root - 2017-12-03 08:19:15.237646: step 17690, loss = 581.90, batch loss = 1.12 (44.6 examples/sec; 0.179 sec/batch; 15h:40m:14s remains)
INFO - root - 2017-12-03 08:19:17.044992: step 17700, loss = 582.02, batch loss = 1.24 (46.0 examples/sec; 0.174 sec/batch; 15h:12m:12s remains)
INFO - root - 2017-12-03 08:19:18.905816: step 17710, loss = 581.83, batch loss = 1.05 (43.2 examples/sec; 0.185 sec/batch; 16h:11m:49s remains)
INFO - root - 2017-12-03 08:19:20.693574: step 17720, loss = 581.93, batch loss = 1.14 (45.1 examples/sec; 0.177 sec/batch; 15h:29m:56s remains)
INFO - root - 2017-12-03 08:19:22.521416: step 17730, loss = 582.01, batch loss = 1.22 (44.0 examples/sec; 0.182 sec/batch; 15h:53m:53s remains)
INFO - root - 2017-12-03 08:19:24.341344: step 17740, loss = 581.84, batch loss = 1.05 (43.7 examples/sec; 0.183 sec/batch; 15h:59m:53s remains)
INFO - root - 2017-12-03 08:19:26.133532: step 17750, loss = 581.82, batch loss = 1.03 (45.4 examples/sec; 0.176 sec/batch; 15h:23m:57s remains)
INFO - root - 2017-12-03 08:19:27.930339: step 17760, loss = 582.01, batch loss = 1.22 (45.9 examples/sec; 0.174 sec/batch; 15h:13m:40s remains)
INFO - root - 2017-12-03 08:19:29.743228: step 17770, loss = 582.05, batch loss = 1.26 (43.3 examples/sec; 0.185 sec/batch; 16h:09m:47s remains)
INFO - root - 2017-12-03 08:19:31.523843: step 17780, loss = 581.88, batch loss = 1.09 (44.6 examples/sec; 0.179 sec/batch; 15h:40m:09s remains)
INFO - root - 2017-12-03 08:19:33.316161: step 17790, loss = 581.89, batch loss = 1.10 (45.0 examples/sec; 0.178 sec/batch; 15h:32m:47s remains)
INFO - root - 2017-12-03 08:19:35.102506: step 17800, loss = 581.86, batch loss = 1.08 (45.2 examples/sec; 0.177 sec/batch; 15h:28m:55s remains)
INFO - root - 2017-12-03 08:19:36.949699: step 17810, loss = 581.87, batch loss = 1.09 (45.0 examples/sec; 0.178 sec/batch; 15h:32m:54s remains)
INFO - root - 2017-12-03 08:19:38.753814: step 17820, loss = 582.04, batch loss = 1.25 (45.3 examples/sec; 0.177 sec/batch; 15h:25m:47s remains)
INFO - root - 2017-12-03 08:19:40.558514: step 17830, loss = 581.77, batch loss = 0.98 (44.1 examples/sec; 0.182 sec/batch; 15h:51m:56s remains)
INFO - root - 2017-12-03 08:19:42.368711: step 17840, loss = 582.01, batch loss = 1.22 (43.7 examples/sec; 0.183 sec/batch; 15h:59m:25s remains)
INFO - root - 2017-12-03 08:19:44.166661: step 17850, loss = 581.84, batch loss = 1.05 (44.5 examples/sec; 0.180 sec/batch; 15h:41m:45s remains)
INFO - root - 2017-12-03 08:19:45.954664: step 17860, loss = 581.89, batch loss = 1.10 (45.5 examples/sec; 0.176 sec/batch; 15h:21m:20s remains)
INFO - root - 2017-12-03 08:19:47.768844: step 17870, loss = 581.90, batch loss = 1.11 (44.0 examples/sec; 0.182 sec/batch; 15h:54m:18s remains)
INFO - root - 2017-12-03 08:19:49.542227: step 17880, loss = 581.89, batch loss = 1.10 (43.0 examples/sec; 0.186 sec/batch; 16h:15m:02s remains)
INFO - root - 2017-12-03 08:19:51.347183: step 17890, loss = 581.82, batch loss = 1.03 (44.5 examples/sec; 0.180 sec/batch; 15h:43m:24s remains)
INFO - root - 2017-12-03 08:19:53.152496: step 17900, loss = 582.10, batch loss = 1.31 (43.2 examples/sec; 0.185 sec/batch; 16h:11m:31s remains)
INFO - root - 2017-12-03 08:19:55.021550: step 17910, loss = 581.87, batch loss = 1.08 (42.9 examples/sec; 0.187 sec/batch; 16h:18m:45s remains)
INFO - root - 2017-12-03 08:19:56.792727: step 17920, loss = 582.00, batch loss = 1.21 (44.4 examples/sec; 0.180 sec/batch; 15h:45m:10s remains)
INFO - root - 2017-12-03 08:19:58.584268: step 17930, loss = 582.06, batch loss = 1.27 (44.9 examples/sec; 0.178 sec/batch; 15h:34m:15s remains)
INFO - root - 2017-12-03 08:20:00.376126: step 17940, loss = 581.82, batch loss = 1.03 (45.5 examples/sec; 0.176 sec/batch; 15h:22m:01s remains)
INFO - root - 2017-12-03 08:20:02.198991: step 17950, loss = 582.01, batch loss = 1.22 (43.1 examples/sec; 0.186 sec/batch; 16h:12m:40s remains)
INFO - root - 2017-12-03 08:20:03.980621: step 17960, loss = 581.87, batch loss = 1.09 (44.8 examples/sec; 0.178 sec/batch; 15h:35m:25s remains)
INFO - root - 2017-12-03 08:20:05.772432: step 17970, loss = 581.82, batch loss = 1.03 (45.8 examples/sec; 0.175 sec/batch; 15h:15m:53s remains)
INFO - root - 2017-12-03 08:20:07.556675: step 17980, loss = 582.06, batch loss = 1.27 (44.6 examples/sec; 0.179 sec/batch; 15h:39m:24s remains)
INFO - root - 2017-12-03 08:20:09.382517: step 17990, loss = 581.96, batch loss = 1.17 (43.1 examples/sec; 0.186 sec/batch; 16h:13m:23s remains)
INFO - root - 2017-12-03 08:20:11.210045: step 18000, loss = 581.93, batch loss = 1.14 (44.2 examples/sec; 0.181 sec/batch; 15h:48m:18s remains)
INFO - root - 2017-12-03 08:20:13.055816: step 18010, loss = 581.91, batch loss = 1.13 (44.6 examples/sec; 0.179 sec/batch; 15h:40m:11s remains)
INFO - root - 2017-12-03 08:20:14.833024: step 18020, loss = 582.14, batch loss = 1.35 (44.4 examples/sec; 0.180 sec/batch; 15h:43m:40s remains)
INFO - root - 2017-12-03 08:20:16.622753: step 18030, loss = 581.92, batch loss = 1.13 (43.5 examples/sec; 0.184 sec/batch; 16h:04m:51s remains)
INFO - root - 2017-12-03 08:20:18.404678: step 18040, loss = 581.96, batch loss = 1.18 (45.2 examples/sec; 0.177 sec/batch; 15h:26m:59s remains)
INFO - root - 2017-12-03 08:20:20.218232: step 18050, loss = 582.06, batch loss = 1.27 (45.0 examples/sec; 0.178 sec/batch; 15h:31m:14s remains)
INFO - root - 2017-12-03 08:20:22.016124: step 18060, loss = 581.77, batch loss = 0.99 (45.2 examples/sec; 0.177 sec/batch; 15h:26m:32s remains)
INFO - root - 2017-12-03 08:20:23.807474: step 18070, loss = 582.01, batch loss = 1.22 (46.3 examples/sec; 0.173 sec/batch; 15h:05m:42s remains)
INFO - root - 2017-12-03 08:20:25.621880: step 18080, loss = 582.10, batch loss = 1.31 (43.2 examples/sec; 0.185 sec/batch; 16h:09m:23s remains)
INFO - root - 2017-12-03 08:20:27.407422: step 18090, loss = 581.81, batch loss = 1.02 (44.4 examples/sec; 0.180 sec/batch; 15h:44m:23s remains)
INFO - root - 2017-12-03 08:20:29.188817: step 18100, loss = 581.93, batch loss = 1.14 (44.1 examples/sec; 0.181 sec/batch; 15h:50m:12s remains)
INFO - root - 2017-12-03 08:20:31.113830: step 18110, loss = 581.89, batch loss = 1.10 (45.2 examples/sec; 0.177 sec/batch; 15h:28m:12s remains)
INFO - root - 2017-12-03 08:20:32.911139: step 18120, loss = 582.02, batch loss = 1.24 (43.4 examples/sec; 0.184 sec/batch; 16h:05m:19s remains)
INFO - root - 2017-12-03 08:20:34.703103: step 18130, loss = 581.89, batch loss = 1.11 (44.7 examples/sec; 0.179 sec/batch; 15h:38m:15s remains)
INFO - root - 2017-12-03 08:20:36.517470: step 18140, loss = 582.01, batch loss = 1.23 (43.2 examples/sec; 0.185 sec/batch; 16h:11m:02s remains)
INFO - root - 2017-12-03 08:20:38.305435: step 18150, loss = 581.87, batch loss = 1.08 (45.2 examples/sec; 0.177 sec/batch; 15h:28m:13s remains)
INFO - root - 2017-12-03 08:20:40.095704: step 18160, loss = 582.03, batch loss = 1.24 (44.9 examples/sec; 0.178 sec/batch; 15h:33m:30s remains)
INFO - root - 2017-12-03 08:20:41.897605: step 18170, loss = 582.16, batch loss = 1.37 (44.6 examples/sec; 0.179 sec/batch; 15h:39m:41s remains)
INFO - root - 2017-12-03 08:20:43.708470: step 18180, loss = 582.16, batch loss = 1.37 (43.9 examples/sec; 0.182 sec/batch; 15h:54m:10s remains)
INFO - root - 2017-12-03 08:20:45.511787: step 18190, loss = 581.97, batch loss = 1.18 (45.0 examples/sec; 0.178 sec/batch; 15h:31m:25s remains)
INFO - root - 2017-12-03 08:20:47.304051: step 18200, loss = 581.77, batch loss = 0.98 (44.5 examples/sec; 0.180 sec/batch; 15h:41m:51s remains)
INFO - root - 2017-12-03 08:20:49.145686: step 18210, loss = 581.99, batch loss = 1.20 (44.9 examples/sec; 0.178 sec/batch; 15h:33m:46s remains)
INFO - root - 2017-12-03 08:20:50.954055: step 18220, loss = 581.96, batch loss = 1.17 (45.0 examples/sec; 0.178 sec/batch; 15h:30m:40s remains)
INFO - root - 2017-12-03 08:20:52.769092: step 18230, loss = 582.02, batch loss = 1.23 (45.2 examples/sec; 0.177 sec/batch; 15h:26m:03s remains)
INFO - root - 2017-12-03 08:20:54.570279: step 18240, loss = 582.03, batch loss = 1.24 (45.6 examples/sec; 0.175 sec/batch; 15h:18m:25s remains)
INFO - root - 2017-12-03 08:20:56.365799: step 18250, loss = 582.08, batch loss = 1.30 (44.9 examples/sec; 0.178 sec/batch; 15h:33m:03s remains)
INFO - root - 2017-12-03 08:20:58.157801: step 18260, loss = 582.00, batch loss = 1.21 (45.1 examples/sec; 0.177 sec/batch; 15h:29m:08s remains)
INFO - root - 2017-12-03 08:20:59.951891: step 18270, loss = 582.12, batch loss = 1.34 (44.7 examples/sec; 0.179 sec/batch; 15h:37m:18s remains)
INFO - root - 2017-12-03 08:21:01.742129: step 18280, loss = 581.99, batch loss = 1.20 (44.7 examples/sec; 0.179 sec/batch; 15h:38m:03s remains)
INFO - root - 2017-12-03 08:21:03.565167: step 18290, loss = 582.06, batch loss = 1.27 (43.4 examples/sec; 0.184 sec/batch; 16h:04m:27s remains)
INFO - root - 2017-12-03 08:21:05.336415: step 18300, loss = 582.04, batch loss = 1.25 (45.2 examples/sec; 0.177 sec/batch; 15h:27m:46s remains)
INFO - root - 2017-12-03 08:21:07.240262: step 18310, loss = 581.87, batch loss = 1.08 (43.2 examples/sec; 0.185 sec/batch; 16h:10m:27s remains)
INFO - root - 2017-12-03 08:21:09.069100: step 18320, loss = 581.94, batch loss = 1.15 (42.2 examples/sec; 0.190 sec/batch; 16h:33m:48s remains)
INFO - root - 2017-12-03 08:21:10.876939: step 18330, loss = 581.87, batch loss = 1.08 (45.6 examples/sec; 0.176 sec/batch; 15h:19m:03s remains)
INFO - root - 2017-12-03 08:21:12.662256: step 18340, loss = 581.95, batch loss = 1.17 (44.2 examples/sec; 0.181 sec/batch; 15h:47m:00s remains)
INFO - root - 2017-12-03 08:21:14.462320: step 18350, loss = 582.03, batch loss = 1.24 (44.7 examples/sec; 0.179 sec/batch; 15h:37m:50s remains)
INFO - root - 2017-12-03 08:21:16.240823: step 18360, loss = 582.02, batch loss = 1.23 (45.8 examples/sec; 0.175 sec/batch; 15h:14m:37s remains)
INFO - root - 2017-12-03 08:21:18.047914: step 18370, loss = 581.80, batch loss = 1.01 (45.4 examples/sec; 0.176 sec/batch; 15h:21m:47s remains)
INFO - root - 2017-12-03 08:21:19.847979: step 18380, loss = 581.93, batch loss = 1.14 (44.4 examples/sec; 0.180 sec/batch; 15h:43m:11s remains)
INFO - root - 2017-12-03 08:21:21.647593: step 18390, loss = 581.89, batch loss = 1.10 (45.8 examples/sec; 0.175 sec/batch; 15h:13m:38s remains)
INFO - root - 2017-12-03 08:21:23.480386: step 18400, loss = 581.99, batch loss = 1.20 (44.3 examples/sec; 0.180 sec/batch; 15h:44m:20s remains)
INFO - root - 2017-12-03 08:21:25.336328: step 18410, loss = 581.95, batch loss = 1.16 (45.9 examples/sec; 0.174 sec/batch; 15h:13m:13s remains)
INFO - root - 2017-12-03 08:21:27.139042: step 18420, loss = 582.08, batch loss = 1.29 (45.1 examples/sec; 0.178 sec/batch; 15h:29m:25s remains)
INFO - root - 2017-12-03 08:21:28.939829: step 18430, loss = 581.80, batch loss = 1.01 (44.0 examples/sec; 0.182 sec/batch; 15h:52m:08s remains)
INFO - root - 2017-12-03 08:21:30.745254: step 18440, loss = 581.97, batch loss = 1.18 (43.9 examples/sec; 0.182 sec/batch; 15h:53m:01s remains)
INFO - root - 2017-12-03 08:21:32.524420: step 18450, loss = 582.05, batch loss = 1.26 (44.6 examples/sec; 0.179 sec/batch; 15h:39m:18s remains)
INFO - root - 2017-12-03 08:21:34.320358: step 18460, loss = 582.13, batch loss = 1.35 (44.2 examples/sec; 0.181 sec/batch; 15h:46m:57s remains)
INFO - root - 2017-12-03 08:21:36.111652: step 18470, loss = 581.89, batch loss = 1.10 (43.5 examples/sec; 0.184 sec/batch; 16h:03m:20s remains)
INFO - root - 2017-12-03 08:21:37.920144: step 18480, loss = 582.03, batch loss = 1.24 (44.5 examples/sec; 0.180 sec/batch; 15h:41m:29s remains)
INFO - root - 2017-12-03 08:21:39.734507: step 18490, loss = 581.99, batch loss = 1.21 (44.6 examples/sec; 0.179 sec/batch; 15h:38m:22s remains)
INFO - root - 2017-12-03 08:21:41.571349: step 18500, loss = 581.99, batch loss = 1.21 (43.4 examples/sec; 0.184 sec/batch; 16h:05m:11s remains)
INFO - root - 2017-12-03 08:21:43.422123: step 18510, loss = 581.99, batch loss = 1.20 (44.9 examples/sec; 0.178 sec/batch; 15h:31m:35s remains)
INFO - root - 2017-12-03 08:21:45.227638: step 18520, loss = 581.91, batch loss = 1.12 (45.0 examples/sec; 0.178 sec/batch; 15h:31m:06s remains)
INFO - root - 2017-12-03 08:21:47.024067: step 18530, loss = 581.96, batch loss = 1.17 (43.7 examples/sec; 0.183 sec/batch; 15h:57m:52s remains)
INFO - root - 2017-12-03 08:21:48.810923: step 18540, loss = 581.99, batch loss = 1.20 (45.0 examples/sec; 0.178 sec/batch; 15h:30m:09s remains)
INFO - root - 2017-12-03 08:21:50.614071: step 18550, loss = 581.85, batch loss = 1.07 (42.1 examples/sec; 0.190 sec/batch; 16h:34m:38s remains)
INFO - root - 2017-12-03 08:21:52.408770: step 18560, loss = 582.05, batch loss = 1.26 (44.3 examples/sec; 0.181 sec/batch; 15h:44m:54s remains)
INFO - root - 2017-12-03 08:21:54.220657: step 18570, loss = 582.08, batch loss = 1.29 (45.6 examples/sec; 0.175 sec/batch; 15h:17m:11s remains)
INFO - root - 2017-12-03 08:21:56.022380: step 18580, loss = 581.88, batch loss = 1.09 (44.8 examples/sec; 0.179 sec/batch; 15h:34m:06s remains)
INFO - root - 2017-12-03 08:21:57.812668: step 18590, loss = 581.98, batch loss = 1.19 (45.3 examples/sec; 0.177 sec/batch; 15h:24m:27s remains)
INFO - root - 2017-12-03 08:21:59.632940: step 18600, loss = 582.09, batch loss = 1.30 (42.9 examples/sec; 0.187 sec/batch; 16h:15m:54s remains)
INFO - root - 2017-12-03 08:22:01.493897: step 18610, loss = 581.90, batch loss = 1.11 (43.9 examples/sec; 0.182 sec/batch; 15h:54m:24s remains)
INFO - root - 2017-12-03 08:22:03.287184: step 18620, loss = 582.17, batch loss = 1.38 (44.5 examples/sec; 0.180 sec/batch; 15h:39m:37s remains)
INFO - root - 2017-12-03 08:22:05.132809: step 18630, loss = 581.83, batch loss = 1.05 (44.7 examples/sec; 0.179 sec/batch; 15h:35m:33s remains)
INFO - root - 2017-12-03 08:22:06.938724: step 18640, loss = 581.97, batch loss = 1.18 (42.8 examples/sec; 0.187 sec/batch; 16h:18m:04s remains)
INFO - root - 2017-12-03 08:22:08.731046: step 18650, loss = 581.97, batch loss = 1.18 (45.4 examples/sec; 0.176 sec/batch; 15h:22m:01s remains)
INFO - root - 2017-12-03 08:22:10.554097: step 18660, loss = 581.98, batch loss = 1.19 (44.7 examples/sec; 0.179 sec/batch; 15h:35m:28s remains)
INFO - root - 2017-12-03 08:22:12.350649: step 18670, loss = 581.89, batch loss = 1.10 (44.3 examples/sec; 0.181 sec/batch; 15h:44m:50s remains)
INFO - root - 2017-12-03 08:22:14.147555: step 18680, loss = 581.92, batch loss = 1.13 (44.7 examples/sec; 0.179 sec/batch; 15h:36m:53s remains)
INFO - root - 2017-12-03 08:22:15.949216: step 18690, loss = 581.94, batch loss = 1.15 (43.9 examples/sec; 0.182 sec/batch; 15h:53m:51s remains)
INFO - root - 2017-12-03 08:22:17.719292: step 18700, loss = 581.82, batch loss = 1.03 (45.8 examples/sec; 0.175 sec/batch; 15h:12m:50s remains)
INFO - root - 2017-12-03 08:22:19.593674: step 18710, loss = 582.15, batch loss = 1.36 (45.6 examples/sec; 0.175 sec/batch; 15h:16m:57s remains)
INFO - root - 2017-12-03 08:22:21.404105: step 18720, loss = 582.11, batch loss = 1.32 (44.7 examples/sec; 0.179 sec/batch; 15h:36m:48s remains)
INFO - root - 2017-12-03 08:22:23.210239: step 18730, loss = 581.91, batch loss = 1.13 (44.6 examples/sec; 0.179 sec/batch; 15h:37m:26s remains)
INFO - root - 2017-12-03 08:22:24.996436: step 18740, loss = 582.17, batch loss = 1.38 (45.4 examples/sec; 0.176 sec/batch; 15h:22m:05s remains)
INFO - root - 2017-12-03 08:22:26.802916: step 18750, loss = 581.90, batch loss = 1.11 (43.3 examples/sec; 0.185 sec/batch; 16h:06m:26s remains)
INFO - root - 2017-12-03 08:22:28.608817: step 18760, loss = 581.87, batch loss = 1.09 (44.4 examples/sec; 0.180 sec/batch; 15h:43m:03s remains)
INFO - root - 2017-12-03 08:22:30.388869: step 18770, loss = 582.07, batch loss = 1.28 (43.6 examples/sec; 0.184 sec/batch; 15h:59m:43s remains)
INFO - root - 2017-12-03 08:22:32.172671: step 18780, loss = 581.90, batch loss = 1.12 (44.7 examples/sec; 0.179 sec/batch; 15h:35m:28s remains)
INFO - root - 2017-12-03 08:22:33.988077: step 18790, loss = 582.31, batch loss = 1.52 (45.4 examples/sec; 0.176 sec/batch; 15h:21m:42s remains)
INFO - root - 2017-12-03 08:22:35.766869: step 18800, loss = 582.19, batch loss = 1.40 (45.0 examples/sec; 0.178 sec/batch; 15h:29m:10s remains)
INFO - root - 2017-12-03 08:22:37.639148: step 18810, loss = 581.81, batch loss = 1.02 (45.1 examples/sec; 0.177 sec/batch; 15h:27m:55s remains)
INFO - root - 2017-12-03 08:22:39.454685: step 18820, loss = 582.06, batch loss = 1.27 (44.9 examples/sec; 0.178 sec/batch; 15h:30m:37s remains)
INFO - root - 2017-12-03 08:22:41.268630: step 18830, loss = 581.88, batch loss = 1.09 (44.0 examples/sec; 0.182 sec/batch; 15h:50m:01s remains)
INFO - root - 2017-12-03 08:22:43.076097: step 18840, loss = 581.85, batch loss = 1.07 (43.6 examples/sec; 0.183 sec/batch; 15h:58m:12s remains)
INFO - root - 2017-12-03 08:22:44.875353: step 18850, loss = 581.87, batch loss = 1.08 (45.6 examples/sec; 0.175 sec/batch; 15h:16m:43s remains)
INFO - root - 2017-12-03 08:22:46.657544: step 18860, loss = 582.13, batch loss = 1.34 (44.4 examples/sec; 0.180 sec/batch; 15h:42m:36s remains)
INFO - root - 2017-12-03 08:22:48.449785: step 18870, loss = 581.98, batch loss = 1.19 (45.7 examples/sec; 0.175 sec/batch; 15h:15m:41s remains)
INFO - root - 2017-12-03 08:22:50.260680: step 18880, loss = 581.77, batch loss = 0.99 (43.5 examples/sec; 0.184 sec/batch; 16h:01m:17s remains)
INFO - root - 2017-12-03 08:22:52.054386: step 18890, loss = 581.82, batch loss = 1.03 (45.6 examples/sec; 0.176 sec/batch; 15h:17m:49s remains)
INFO - root - 2017-12-03 08:22:53.870515: step 18900, loss = 582.12, batch loss = 1.34 (43.7 examples/sec; 0.183 sec/batch; 15h:55m:52s remains)
INFO - root - 2017-12-03 08:22:55.729832: step 18910, loss = 582.04, batch loss = 1.25 (45.2 examples/sec; 0.177 sec/batch; 15h:24m:35s remains)
INFO - root - 2017-12-03 08:22:57.533063: step 18920, loss = 582.13, batch loss = 1.34 (44.6 examples/sec; 0.179 sec/batch; 15h:37m:15s remains)
INFO - root - 2017-12-03 08:22:59.325307: step 18930, loss = 581.99, batch loss = 1.20 (44.8 examples/sec; 0.178 sec/batch; 15h:32m:46s remains)
INFO - root - 2017-12-03 08:23:01.104027: step 18940, loss = 581.85, batch loss = 1.06 (44.6 examples/sec; 0.179 sec/batch; 15h:37m:03s remains)
INFO - root - 2017-12-03 08:23:02.908394: step 18950, loss = 582.14, batch loss = 1.35 (44.3 examples/sec; 0.181 sec/batch; 15h:44m:24s remains)
INFO - root - 2017-12-03 08:23:04.735551: step 18960, loss = 581.92, batch loss = 1.13 (45.2 examples/sec; 0.177 sec/batch; 15h:25m:48s remains)
INFO - root - 2017-12-03 08:23:06.522791: step 18970, loss = 581.75, batch loss = 0.97 (45.0 examples/sec; 0.178 sec/batch; 15h:29m:09s remains)
INFO - root - 2017-12-03 08:23:08.323017: step 18980, loss = 581.82, batch loss = 1.03 (43.9 examples/sec; 0.182 sec/batch; 15h:52m:41s remains)
INFO - root - 2017-12-03 08:23:10.163572: step 18990, loss = 582.06, batch loss = 1.27 (43.2 examples/sec; 0.185 sec/batch; 16h:07m:09s remains)
INFO - root - 2017-12-03 08:23:11.952182: step 19000, loss = 582.12, batch loss = 1.34 (45.0 examples/sec; 0.178 sec/batch; 15h:28m:18s remains)
INFO - root - 2017-12-03 08:23:13.840119: step 19010, loss = 582.09, batch loss = 1.31 (44.2 examples/sec; 0.181 sec/batch; 15h:45m:28s remains)
INFO - root - 2017-12-03 08:23:15.637821: step 19020, loss = 582.09, batch loss = 1.30 (44.8 examples/sec; 0.179 sec/batch; 15h:33m:37s remains)
INFO - root - 2017-12-03 08:23:17.422404: step 19030, loss = 581.94, batch loss = 1.15 (44.0 examples/sec; 0.182 sec/batch; 15h:48m:57s remains)
INFO - root - 2017-12-03 08:23:19.206309: step 19040, loss = 582.30, batch loss = 1.51 (45.9 examples/sec; 0.174 sec/batch; 15h:10m:07s remains)
INFO - root - 2017-12-03 08:23:21.017026: step 19050, loss = 581.88, batch loss = 1.09 (44.0 examples/sec; 0.182 sec/batch; 15h:49m:37s remains)
INFO - root - 2017-12-03 08:23:22.813448: step 19060, loss = 582.06, batch loss = 1.27 (45.6 examples/sec; 0.175 sec/batch; 15h:15m:44s remains)
INFO - root - 2017-12-03 08:23:24.602143: step 19070, loss = 581.82, batch loss = 1.03 (45.6 examples/sec; 0.176 sec/batch; 15h:16m:48s remains)
INFO - root - 2017-12-03 08:23:26.381292: step 19080, loss = 582.10, batch loss = 1.32 (45.1 examples/sec; 0.177 sec/batch; 15h:25m:48s remains)
INFO - root - 2017-12-03 08:23:28.208807: step 19090, loss = 581.92, batch loss = 1.13 (46.2 examples/sec; 0.173 sec/batch; 15h:05m:05s remains)
INFO - root - 2017-12-03 08:23:29.997348: step 19100, loss = 582.06, batch loss = 1.28 (44.6 examples/sec; 0.180 sec/batch; 15h:37m:38s remains)
INFO - root - 2017-12-03 08:23:31.879711: step 19110, loss = 582.06, batch loss = 1.27 (44.3 examples/sec; 0.181 sec/batch; 15h:43m:10s remains)
INFO - root - 2017-12-03 08:23:33.672499: step 19120, loss = 582.05, batch loss = 1.27 (44.8 examples/sec; 0.179 sec/batch; 15h:32m:39s remains)
INFO - root - 2017-12-03 08:23:35.481695: step 19130, loss = 582.07, batch loss = 1.29 (43.8 examples/sec; 0.183 sec/batch; 15h:53m:17s remains)
INFO - root - 2017-12-03 08:23:37.271944: step 19140, loss = 581.87, batch loss = 1.08 (44.9 examples/sec; 0.178 sec/batch; 15h:30m:21s remains)
INFO - root - 2017-12-03 08:23:39.076354: step 19150, loss = 582.03, batch loss = 1.24 (45.3 examples/sec; 0.177 sec/batch; 15h:22m:35s remains)
INFO - root - 2017-12-03 08:23:40.862626: step 19160, loss = 582.01, batch loss = 1.23 (45.5 examples/sec; 0.176 sec/batch; 15h:17m:25s remains)
INFO - root - 2017-12-03 08:23:42.670079: step 19170, loss = 582.06, batch loss = 1.27 (44.3 examples/sec; 0.181 sec/batch; 15h:43m:23s remains)
INFO - root - 2017-12-03 08:23:44.485292: step 19180, loss = 582.10, batch loss = 1.31 (42.5 examples/sec; 0.188 sec/batch; 16h:23m:24s remains)
INFO - root - 2017-12-03 08:23:46.269438: step 19190, loss = 581.97, batch loss = 1.19 (44.6 examples/sec; 0.180 sec/batch; 15h:37m:28s remains)
INFO - root - 2017-12-03 08:23:48.075997: step 19200, loss = 581.94, batch loss = 1.15 (44.9 examples/sec; 0.178 sec/batch; 15h:29m:56s remains)
INFO - root - 2017-12-03 08:23:49.955174: step 19210, loss = 581.98, batch loss = 1.19 (44.0 examples/sec; 0.182 sec/batch; 15h:49m:54s remains)
INFO - root - 2017-12-03 08:23:51.740160: step 19220, loss = 582.06, batch loss = 1.28 (44.1 examples/sec; 0.181 sec/batch; 15h:46m:14s remains)
INFO - root - 2017-12-03 08:23:53.542616: step 19230, loss = 581.96, batch loss = 1.17 (44.4 examples/sec; 0.180 sec/batch; 15h:41m:40s remains)
INFO - root - 2017-12-03 08:23:55.370958: step 19240, loss = 582.01, batch loss = 1.22 (44.7 examples/sec; 0.179 sec/batch; 15h:34m:53s remains)
INFO - root - 2017-12-03 08:23:57.171970: step 19250, loss = 581.94, batch loss = 1.15 (40.8 examples/sec; 0.196 sec/batch; 17h:03m:47s remains)
INFO - root - 2017-12-03 08:23:58.974495: step 19260, loss = 581.94, batch loss = 1.15 (45.7 examples/sec; 0.175 sec/batch; 15h:13m:30s remains)
INFO - root - 2017-12-03 08:24:00.776164: step 19270, loss = 581.81, batch loss = 1.02 (43.8 examples/sec; 0.183 sec/batch; 15h:53m:28s remains)
INFO - root - 2017-12-03 08:24:02.571434: step 19280, loss = 582.20, batch loss = 1.41 (43.7 examples/sec; 0.183 sec/batch; 15h:54m:52s remains)
INFO - root - 2017-12-03 08:24:04.391027: step 19290, loss = 582.00, batch loss = 1.21 (45.3 examples/sec; 0.177 sec/batch; 15h:22m:10s remains)
INFO - root - 2017-12-03 08:24:06.185749: step 19300, loss = 581.99, batch loss = 1.21 (44.9 examples/sec; 0.178 sec/batch; 15h:29m:03s remains)
INFO - root - 2017-12-03 08:24:08.084693: step 19310, loss = 582.02, batch loss = 1.23 (44.1 examples/sec; 0.182 sec/batch; 15h:47m:24s remains)
INFO - root - 2017-12-03 08:24:09.892626: step 19320, loss = 582.10, batch loss = 1.31 (44.4 examples/sec; 0.180 sec/batch; 15h:41m:06s remains)
INFO - root - 2017-12-03 08:24:11.694261: step 19330, loss = 581.92, batch loss = 1.14 (46.3 examples/sec; 0.173 sec/batch; 15h:01m:14s remains)
INFO - root - 2017-12-03 08:24:13.492700: step 19340, loss = 581.91, batch loss = 1.12 (45.5 examples/sec; 0.176 sec/batch; 15h:16m:44s remains)
INFO - root - 2017-12-03 08:24:15.295791: step 19350, loss = 581.99, batch loss = 1.20 (45.6 examples/sec; 0.175 sec/batch; 15h:15m:06s remains)
INFO - root - 2017-12-03 08:24:17.085389: step 19360, loss = 581.94, batch loss = 1.15 (44.8 examples/sec; 0.178 sec/batch; 15h:31m:08s remains)
INFO - root - 2017-12-03 08:24:18.870236: step 19370, loss = 582.06, batch loss = 1.27 (45.8 examples/sec; 0.175 sec/batch; 15h:11m:14s remains)
INFO - root - 2017-12-03 08:24:20.681281: step 19380, loss = 582.15, batch loss = 1.37 (43.0 examples/sec; 0.186 sec/batch; 16h:10m:02s remains)
INFO - root - 2017-12-03 08:24:22.460488: step 19390, loss = 581.91, batch loss = 1.13 (44.8 examples/sec; 0.178 sec/batch; 15h:31m:26s remains)
INFO - root - 2017-12-03 08:24:24.266667: step 19400, loss = 582.24, batch loss = 1.46 (45.5 examples/sec; 0.176 sec/batch; 15h:18m:11s remains)
INFO - root - 2017-12-03 08:24:26.148233: step 19410, loss = 581.85, batch loss = 1.07 (45.2 examples/sec; 0.177 sec/batch; 15h:22m:43s remains)
INFO - root - 2017-12-03 08:24:27.943253: step 19420, loss = 581.88, batch loss = 1.09 (40.9 examples/sec; 0.196 sec/batch; 17h:00m:52s remains)
INFO - root - 2017-12-03 08:24:29.731053: step 19430, loss = 581.88, batch loss = 1.10 (45.4 examples/sec; 0.176 sec/batch; 15h:19m:44s remains)
INFO - root - 2017-12-03 08:24:31.514702: step 19440, loss = 581.89, batch loss = 1.11 (42.9 examples/sec; 0.186 sec/batch; 16h:13m:01s remains)
INFO - root - 2017-12-03 08:24:33.347433: step 19450, loss = 582.11, batch loss = 1.33 (45.4 examples/sec; 0.176 sec/batch; 15h:19m:31s remains)
INFO - root - 2017-12-03 08:24:35.151328: step 19460, loss = 582.07, batch loss = 1.28 (45.2 examples/sec; 0.177 sec/batch; 15h:22m:32s remains)
INFO - root - 2017-12-03 08:24:36.936235: step 19470, loss = 582.03, batch loss = 1.25 (43.9 examples/sec; 0.182 sec/batch; 15h:51m:20s remains)
INFO - root - 2017-12-03 08:24:38.747768: step 19480, loss = 582.10, batch loss = 1.31 (46.2 examples/sec; 0.173 sec/batch; 15h:03m:53s remains)
INFO - root - 2017-12-03 08:24:40.580538: step 19490, loss = 581.74, batch loss = 0.96 (44.3 examples/sec; 0.181 sec/batch; 15h:42m:58s remains)
INFO - root - 2017-12-03 08:24:42.359532: step 19500, loss = 581.96, batch loss = 1.17 (44.6 examples/sec; 0.180 sec/batch; 15h:36m:25s remains)
INFO - root - 2017-12-03 08:24:44.221562: step 19510, loss = 581.86, batch loss = 1.07 (44.8 examples/sec; 0.178 sec/batch; 15h:30m:58s remains)
INFO - root - 2017-12-03 08:24:46.023542: step 19520, loss = 581.82, batch loss = 1.03 (44.9 examples/sec; 0.178 sec/batch; 15h:28m:29s remains)
INFO - root - 2017-12-03 08:24:47.837495: step 19530, loss = 582.09, batch loss = 1.30 (43.3 examples/sec; 0.185 sec/batch; 16h:04m:29s remains)
INFO - root - 2017-12-03 08:24:49.644091: step 19540, loss = 581.90, batch loss = 1.11 (43.8 examples/sec; 0.183 sec/batch; 15h:52m:03s remains)
INFO - root - 2017-12-03 08:24:51.439223: step 19550, loss = 582.05, batch loss = 1.26 (44.5 examples/sec; 0.180 sec/batch; 15h:38m:35s remains)
INFO - root - 2017-12-03 08:24:53.222313: step 19560, loss = 581.94, batch loss = 1.15 (44.8 examples/sec; 0.179 sec/batch; 15h:32m:09s remains)
INFO - root - 2017-12-03 08:24:55.036310: step 19570, loss = 582.14, batch loss = 1.36 (43.7 examples/sec; 0.183 sec/batch; 15h:54m:45s remains)
INFO - root - 2017-12-03 08:24:56.814068: step 19580, loss = 581.89, batch loss = 1.10 (44.8 examples/sec; 0.179 sec/batch; 15h:31m:49s remains)
INFO - root - 2017-12-03 08:24:58.620806: step 19590, loss = 581.84, batch loss = 1.05 (44.2 examples/sec; 0.181 sec/batch; 15h:42m:54s remains)
INFO - root - 2017-12-03 08:25:00.410582: step 19600, loss = 581.84, batch loss = 1.05 (44.5 examples/sec; 0.180 sec/batch; 15h:37m:54s remains)
INFO - root - 2017-12-03 08:25:02.270851: step 19610, loss = 581.99, batch loss = 1.20 (42.6 examples/sec; 0.188 sec/batch; 16h:19m:22s remains)
INFO - root - 2017-12-03 08:25:04.065275: step 19620, loss = 581.97, batch loss = 1.18 (45.9 examples/sec; 0.174 sec/batch; 15h:09m:43s remains)
INFO - root - 2017-12-03 08:25:05.877813: step 19630, loss = 582.19, batch loss = 1.40 (43.6 examples/sec; 0.184 sec/batch; 15h:56m:56s remains)
INFO - root - 2017-12-03 08:25:07.666399: step 19640, loss = 582.06, batch loss = 1.27 (44.5 examples/sec; 0.180 sec/batch; 15h:36m:51s remains)
INFO - root - 2017-12-03 08:25:09.483554: step 19650, loss = 582.08, batch loss = 1.30 (43.1 examples/sec; 0.186 sec/batch; 16h:08m:54s remains)
INFO - root - 2017-12-03 08:25:11.276527: step 19660, loss = 581.99, batch loss = 1.21 (42.8 examples/sec; 0.187 sec/batch; 16h:15m:12s remains)
INFO - root - 2017-12-03 08:25:13.083099: step 19670, loss = 582.10, batch loss = 1.32 (44.6 examples/sec; 0.180 sec/batch; 15h:35m:56s remains)
INFO - root - 2017-12-03 08:25:14.906443: step 19680, loss = 581.94, batch loss = 1.15 (45.4 examples/sec; 0.176 sec/batch; 15h:19m:31s remains)
INFO - root - 2017-12-03 08:25:16.682458: step 19690, loss = 582.21, batch loss = 1.42 (45.0 examples/sec; 0.178 sec/batch; 15h:26m:19s remains)
INFO - root - 2017-12-03 08:25:18.501331: step 19700, loss = 582.02, batch loss = 1.23 (45.2 examples/sec; 0.177 sec/batch; 15h:22m:00s remains)
INFO - root - 2017-12-03 08:25:20.378194: step 19710, loss = 582.01, batch loss = 1.22 (43.8 examples/sec; 0.183 sec/batch; 15h:52m:07s remains)
INFO - root - 2017-12-03 08:25:22.201021: step 19720, loss = 581.97, batch loss = 1.18 (44.5 examples/sec; 0.180 sec/batch; 15h:36m:49s remains)
INFO - root - 2017-12-03 08:25:23.989018: step 19730, loss = 581.81, batch loss = 1.03 (44.3 examples/sec; 0.181 sec/batch; 15h:42m:08s remains)
INFO - root - 2017-12-03 08:25:25.782930: step 19740, loss = 582.00, batch loss = 1.21 (44.8 examples/sec; 0.178 sec/batch; 15h:30m:16s remains)
INFO - root - 2017-12-03 08:25:27.572203: step 19750, loss = 582.06, batch loss = 1.27 (44.0 examples/sec; 0.182 sec/batch; 15h:46m:51s remains)
INFO - root - 2017-12-03 08:25:29.367057: step 19760, loss = 582.03, batch loss = 1.24 (43.4 examples/sec; 0.184 sec/batch; 16h:00m:39s remains)
INFO - root - 2017-12-03 08:25:31.157942: step 19770, loss = 581.89, batch loss = 1.10 (44.0 examples/sec; 0.182 sec/batch; 15h:47m:48s remains)
INFO - root - 2017-12-03 08:25:32.955048: step 19780, loss = 581.86, batch loss = 1.07 (45.7 examples/sec; 0.175 sec/batch; 15h:11m:43s remains)
INFO - root - 2017-12-03 08:25:34.740721: step 19790, loss = 582.05, batch loss = 1.26 (44.8 examples/sec; 0.179 sec/batch; 15h:30m:53s remains)
INFO - root - 2017-12-03 08:25:36.541337: step 19800, loss = 581.87, batch loss = 1.08 (45.4 examples/sec; 0.176 sec/batch; 15h:19m:16s remains)
INFO - root - 2017-12-03 08:25:38.405117: step 19810, loss = 581.94, batch loss = 1.15 (43.3 examples/sec; 0.185 sec/batch; 16h:03m:54s remains)
INFO - root - 2017-12-03 08:25:40.221355: step 19820, loss = 581.86, batch loss = 1.07 (43.2 examples/sec; 0.185 sec/batch; 16h:04m:37s remains)
INFO - root - 2017-12-03 08:25:41.995180: step 19830, loss = 581.94, batch loss = 1.16 (45.3 examples/sec; 0.177 sec/batch; 15h:20m:12s remains)
INFO - root - 2017-12-03 08:25:43.802336: step 19840, loss = 582.16, batch loss = 1.37 (44.1 examples/sec; 0.181 sec/batch; 15h:45m:19s remains)
INFO - root - 2017-12-03 08:25:45.574744: step 19850, loss = 581.96, batch loss = 1.17 (44.5 examples/sec; 0.180 sec/batch; 15h:35m:45s remains)
INFO - root - 2017-12-03 08:25:47.386068: step 19860, loss = 581.95, batch loss = 1.16 (44.7 examples/sec; 0.179 sec/batch; 15h:32m:32s remains)
INFO - root - 2017-12-03 08:25:49.180971: step 19870, loss = 581.98, batch loss = 1.19 (44.4 examples/sec; 0.180 sec/batch; 15h:38m:44s remains)
INFO - root - 2017-12-03 08:25:50.967657: step 19880, loss = 581.98, batch loss = 1.19 (44.3 examples/sec; 0.180 sec/batch; 15h:40m:20s remains)
INFO - root - 2017-12-03 08:25:52.762112: step 19890, loss = 581.89, batch loss = 1.10 (44.6 examples/sec; 0.179 sec/batch; 15h:33m:52s remains)
INFO - root - 2017-12-03 08:25:54.569787: step 19900, loss = 581.84, batch loss = 1.06 (41.4 examples/sec; 0.193 sec/batch; 16h:46m:19s remains)
INFO - root - 2017-12-03 08:25:56.454358: step 19910, loss = 582.17, batch loss = 1.39 (43.9 examples/sec; 0.182 sec/batch; 15h:49m:29s remains)
INFO - root - 2017-12-03 08:25:58.264100: step 19920, loss = 582.08, batch loss = 1.29 (44.6 examples/sec; 0.179 sec/batch; 15h:34m:27s remains)
INFO - root - 2017-12-03 08:26:00.047324: step 19930, loss = 582.05, batch loss = 1.26 (45.5 examples/sec; 0.176 sec/batch; 15h:15m:50s remains)
INFO - root - 2017-12-03 08:26:01.860496: step 19940, loss = 581.86, batch loss = 1.07 (45.5 examples/sec; 0.176 sec/batch; 15h:15m:19s remains)
INFO - root - 2017-12-03 08:26:03.664847: step 19950, loss = 582.17, batch loss = 1.38 (45.1 examples/sec; 0.178 sec/batch; 15h:24m:38s remains)
INFO - root - 2017-12-03 08:26:05.454857: step 19960, loss = 582.08, batch loss = 1.29 (43.9 examples/sec; 0.182 sec/batch; 15h:48m:40s remains)
INFO - root - 2017-12-03 08:26:07.253828: step 19970, loss = 581.93, batch loss = 1.14 (42.9 examples/sec; 0.186 sec/batch; 16h:10m:28s remains)
INFO - root - 2017-12-03 08:26:09.061648: step 19980, loss = 581.85, batch loss = 1.07 (43.0 examples/sec; 0.186 sec/batch; 16h:08m:53s remains)
INFO - root - 2017-12-03 08:26:10.882891: step 19990, loss = 581.97, batch loss = 1.18 (45.2 examples/sec; 0.177 sec/batch; 15h:22m:39s remains)
INFO - root - 2017-12-03 08:26:12.667277: step 20000, loss = 581.88, batch loss = 1.09 (44.7 examples/sec; 0.179 sec/batch; 15h:32m:07s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-20000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-20000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-03 08:26:14.927295: step 20010, loss = 581.98, batch loss = 1.19 (45.5 examples/sec; 0.176 sec/batch; 15h:15m:35s remains)
INFO - root - 2017-12-03 08:26:16.716759: step 20020, loss = 581.94, batch loss = 1.16 (43.3 examples/sec; 0.185 sec/batch; 16h:01m:36s remains)
INFO - root - 2017-12-03 08:26:18.520340: step 20030, loss = 582.02, batch loss = 1.24 (45.5 examples/sec; 0.176 sec/batch; 15h:16m:35s remains)
INFO - root - 2017-12-03 08:26:20.342809: step 20040, loss = 581.93, batch loss = 1.15 (44.8 examples/sec; 0.178 sec/batch; 15h:29m:17s remains)
INFO - root - 2017-12-03 08:26:22.132436: step 20050, loss = 582.28, batch loss = 1.49 (44.3 examples/sec; 0.180 sec/batch; 15h:39m:56s remains)
INFO - root - 2017-12-03 08:26:23.949852: step 20060, loss = 581.93, batch loss = 1.15 (46.0 examples/sec; 0.174 sec/batch; 15h:06m:17s remains)
INFO - root - 2017-12-03 08:26:25.779738: step 20070, loss = 581.99, batch loss = 1.20 (44.5 examples/sec; 0.180 sec/batch; 15h:36m:49s remains)
INFO - root - 2017-12-03 08:26:27.560928: step 20080, loss = 582.01, batch loss = 1.23 (44.8 examples/sec; 0.179 sec/batch; 15h:30m:02s remains)
INFO - root - 2017-12-03 08:26:29.361371: step 20090, loss = 581.90, batch loss = 1.11 (44.1 examples/sec; 0.181 sec/batch; 15h:45m:01s remains)
INFO - root - 2017-12-03 08:26:31.151343: step 20100, loss = 581.92, batch loss = 1.14 (44.0 examples/sec; 0.182 sec/batch; 15h:45m:55s remains)
INFO - root - 2017-12-03 08:26:33.009736: step 20110, loss = 581.95, batch loss = 1.16 (44.2 examples/sec; 0.181 sec/batch; 15h:41m:32s remains)
INFO - root - 2017-12-03 08:26:34.817759: step 20120, loss = 582.04, batch loss = 1.25 (44.5 examples/sec; 0.180 sec/batch; 15h:35m:51s remains)
INFO - root - 2017-12-03 08:26:36.605086: step 20130, loss = 581.99, batch loss = 1.20 (44.5 examples/sec; 0.180 sec/batch; 15h:35m:33s remains)
INFO - root - 2017-12-03 08:26:38.395457: step 20140, loss = 581.86, batch loss = 1.08 (45.5 examples/sec; 0.176 sec/batch; 15h:15m:38s remains)
INFO - root - 2017-12-03 08:26:40.178841: step 20150, loss = 582.07, batch loss = 1.29 (45.3 examples/sec; 0.176 sec/batch; 15h:18m:45s remains)
INFO - root - 2017-12-03 08:26:41.978385: step 20160, loss = 581.80, batch loss = 1.02 (45.6 examples/sec; 0.175 sec/batch; 15h:13m:33s remains)
INFO - root - 2017-12-03 08:26:43.800942: step 20170, loss = 581.79, batch loss = 1.00 (44.9 examples/sec; 0.178 sec/batch; 15h:28m:14s remains)
INFO - root - 2017-12-03 08:26:45.587341: step 20180, loss = 581.91, batch loss = 1.12 (44.7 examples/sec; 0.179 sec/batch; 15h:31m:23s remains)
INFO - root - 2017-12-03 08:26:47.389469: step 20190, loss = 581.88, batch loss = 1.09 (44.6 examples/sec; 0.179 sec/batch; 15h:32m:54s remains)
INFO - root - 2017-12-03 08:26:49.200220: step 20200, loss = 582.03, batch loss = 1.25 (43.1 examples/sec; 0.185 sec/batch; 16h:05m:02s remains)
INFO - root - 2017-12-03 08:26:51.070010: step 20210, loss = 581.94, batch loss = 1.15 (44.1 examples/sec; 0.181 sec/batch; 15h:43m:14s remains)
INFO - root - 2017-12-03 08:26:52.868826: step 20220, loss = 581.98, batch loss = 1.19 (45.7 examples/sec; 0.175 sec/batch; 15h:11m:37s remains)
INFO - root - 2017-12-03 08:26:54.697534: step 20230, loss = 582.01, batch loss = 1.23 (43.9 examples/sec; 0.182 sec/batch; 15h:48m:56s remains)
INFO - root - 2017-12-03 08:26:56.497434: step 20240, loss = 581.77, batch loss = 0.98 (43.5 examples/sec; 0.184 sec/batch; 15h:57m:25s remains)
INFO - root - 2017-12-03 08:26:58.280849: step 20250, loss = 582.14, batch loss = 1.35 (44.7 examples/sec; 0.179 sec/batch; 15h:31m:32s remains)
INFO - root - 2017-12-03 08:27:00.093142: step 20260, loss = 581.92, batch loss = 1.14 (40.8 examples/sec; 0.196 sec/batch; 16h:59m:35s remains)
INFO - root - 2017-12-03 08:27:01.892601: step 20270, loss = 582.02, batch loss = 1.23 (44.7 examples/sec; 0.179 sec/batch; 15h:31m:40s remains)
INFO - root - 2017-12-03 08:27:03.696181: step 20280, loss = 582.09, batch loss = 1.30 (43.9 examples/sec; 0.182 sec/batch; 15h:49m:15s remains)
INFO - root - 2017-12-03 08:27:05.489905: step 20290, loss = 581.92, batch loss = 1.13 (44.8 examples/sec; 0.179 sec/batch; 15h:29m:39s remains)
INFO - root - 2017-12-03 08:27:07.284493: step 20300, loss = 582.19, batch loss = 1.40 (44.5 examples/sec; 0.180 sec/batch; 15h:35m:05s remains)
INFO - root - 2017-12-03 08:27:09.157342: step 20310, loss = 582.13, batch loss = 1.34 (45.3 examples/sec; 0.176 sec/batch; 15h:18m:09s remains)
INFO - root - 2017-12-03 08:27:10.987690: step 20320, loss = 581.99, batch loss = 1.20 (44.5 examples/sec; 0.180 sec/batch; 15h:35m:22s remains)
INFO - root - 2017-12-03 08:27:12.805784: step 20330, loss = 581.79, batch loss = 1.01 (42.7 examples/sec; 0.187 sec/batch; 16h:14m:05s remains)
INFO - root - 2017-12-03 08:27:14.608463: step 20340, loss = 581.86, batch loss = 1.08 (45.1 examples/sec; 0.177 sec/batch; 15h:22m:56s remains)
INFO - root - 2017-12-03 08:27:16.414823: step 20350, loss = 582.03, batch loss = 1.24 (43.8 examples/sec; 0.183 sec/batch; 15h:51m:15s remains)
INFO - root - 2017-12-03 08:27:18.202696: step 20360, loss = 581.91, batch loss = 1.12 (43.0 examples/sec; 0.186 sec/batch; 16h:07m:22s remains)
INFO - root - 2017-12-03 08:27:20.015445: step 20370, loss = 582.34, batch loss = 1.56 (44.7 examples/sec; 0.179 sec/batch; 15h:31m:24s remains)
INFO - root - 2017-12-03 08:27:21.808527: step 20380, loss = 581.90, batch loss = 1.11 (44.9 examples/sec; 0.178 sec/batch; 15h:27m:27s remains)
INFO - root - 2017-12-03 08:27:23.599673: step 20390, loss = 581.96, batch loss = 1.17 (44.9 examples/sec; 0.178 sec/batch; 15h:27m:09s remains)
INFO - root - 2017-12-03 08:27:25.423916: step 20400, loss = 581.92, batch loss = 1.13 (43.4 examples/sec; 0.184 sec/batch; 15h:59m:27s remains)
INFO - root - 2017-12-03 08:27:27.334779: step 20410, loss = 582.09, batch loss = 1.30 (43.7 examples/sec; 0.183 sec/batch; 15h:51m:53s remains)
INFO - root - 2017-12-03 08:27:29.149029: step 20420, loss = 582.06, batch loss = 1.27 (45.6 examples/sec; 0.175 sec/batch; 15h:12m:35s remains)
INFO - root - 2017-12-03 08:27:30.935650: step 20430, loss = 582.27, batch loss = 1.49 (45.7 examples/sec; 0.175 sec/batch; 15h:10m:16s remains)
INFO - root - 2017-12-03 08:27:32.732932: step 20440, loss = 581.91, batch loss = 1.13 (44.3 examples/sec; 0.181 sec/batch; 15h:39m:21s remains)
INFO - root - 2017-12-03 08:27:34.519527: step 20450, loss = 582.22, batch loss = 1.44 (44.3 examples/sec; 0.180 sec/batch; 15h:38m:40s remains)
INFO - root - 2017-12-03 08:27:36.314082: step 20460, loss = 581.85, batch loss = 1.07 (45.3 examples/sec; 0.176 sec/batch; 15h:17m:44s remains)
INFO - root - 2017-12-03 08:27:38.100783: step 20470, loss = 582.07, batch loss = 1.28 (45.1 examples/sec; 0.177 sec/batch; 15h:21m:54s remains)
INFO - root - 2017-12-03 08:27:39.886830: step 20480, loss = 581.97, batch loss = 1.18 (45.3 examples/sec; 0.177 sec/batch; 15h:18m:07s remains)
INFO - root - 2017-12-03 08:27:41.700009: step 20490, loss = 582.09, batch loss = 1.30 (44.9 examples/sec; 0.178 sec/batch; 15h:26m:49s remains)
INFO - root - 2017-12-03 08:27:43.498545: step 20500, loss = 581.80, batch loss = 1.01 (45.1 examples/sec; 0.178 sec/batch; 15h:23m:16s remains)
INFO - root - 2017-12-03 08:27:45.347299: step 20510, loss = 581.90, batch loss = 1.11 (45.7 examples/sec; 0.175 sec/batch; 15h:09m:20s remains)
INFO - root - 2017-12-03 08:27:47.144013: step 20520, loss = 582.10, batch loss = 1.32 (43.8 examples/sec; 0.182 sec/batch; 15h:48m:56s remains)
INFO - root - 2017-12-03 08:27:48.934813: step 20530, loss = 581.76, batch loss = 0.97 (45.0 examples/sec; 0.178 sec/batch; 15h:24m:01s remains)
INFO - root - 2017-12-03 08:27:50.723715: step 20540, loss = 581.91, batch loss = 1.12 (44.4 examples/sec; 0.180 sec/batch; 15h:37m:02s remains)
INFO - root - 2017-12-03 08:27:52.515943: step 20550, loss = 581.87, batch loss = 1.09 (45.8 examples/sec; 0.175 sec/batch; 15h:08m:43s remains)
INFO - root - 2017-12-03 08:27:54.341467: step 20560, loss = 582.05, batch loss = 1.27 (41.9 examples/sec; 0.191 sec/batch; 16h:32m:28s remains)
INFO - root - 2017-12-03 08:27:56.133904: step 20570, loss = 581.79, batch loss = 1.00 (45.5 examples/sec; 0.176 sec/batch; 15h:15m:00s remains)
INFO - root - 2017-12-03 08:27:57.931886: step 20580, loss = 581.94, batch loss = 1.16 (44.6 examples/sec; 0.179 sec/batch; 15h:32m:12s remains)
INFO - root - 2017-12-03 08:27:59.728764: step 20590, loss = 582.17, batch loss = 1.38 (43.9 examples/sec; 0.182 sec/batch; 15h:47m:09s remains)
INFO - root - 2017-12-03 08:28:01.520783: step 20600, loss = 582.09, batch loss = 1.30 (45.8 examples/sec; 0.175 sec/batch; 15h:08m:14s remains)
INFO - root - 2017-12-03 08:28:03.384074: step 20610, loss = 582.03, batch loss = 1.25 (45.1 examples/sec; 0.177 sec/batch; 15h:22m:11s remains)
INFO - root - 2017-12-03 08:28:05.167455: step 20620, loss = 581.92, batch loss = 1.13 (44.5 examples/sec; 0.180 sec/batch; 15h:35m:01s remains)
INFO - root - 2017-12-03 08:28:06.971790: step 20630, loss = 581.93, batch loss = 1.15 (45.1 examples/sec; 0.177 sec/batch; 15h:21m:22s remains)
INFO - root - 2017-12-03 08:28:08.772973: step 20640, loss = 582.03, batch loss = 1.24 (44.0 examples/sec; 0.182 sec/batch; 15h:44m:31s remains)
INFO - root - 2017-12-03 08:28:10.578854: step 20650, loss = 581.88, batch loss = 1.10 (44.6 examples/sec; 0.179 sec/batch; 15h:32m:21s remains)
INFO - root - 2017-12-03 08:28:12.369106: step 20660, loss = 582.15, batch loss = 1.36 (45.0 examples/sec; 0.178 sec/batch; 15h:24m:56s remains)
INFO - root - 2017-12-03 08:28:14.168325: step 20670, loss = 582.13, batch loss = 1.35 (43.5 examples/sec; 0.184 sec/batch; 15h:55m:42s remains)
INFO - root - 2017-12-03 08:28:15.960841: step 20680, loss = 581.89, batch loss = 1.10 (44.8 examples/sec; 0.178 sec/batch; 15h:27m:35s remains)
INFO - root - 2017-12-03 08:28:17.754541: step 20690, loss = 582.02, batch loss = 1.24 (44.8 examples/sec; 0.179 sec/batch; 15h:28m:45s remains)
INFO - root - 2017-12-03 08:28:19.538245: step 20700, loss = 582.04, batch loss = 1.25 (44.4 examples/sec; 0.180 sec/batch; 15h:36m:44s remains)
INFO - root - 2017-12-03 08:28:21.405355: step 20710, loss = 581.98, batch loss = 1.19 (45.9 examples/sec; 0.174 sec/batch; 15h:06m:36s remains)
INFO - root - 2017-12-03 08:28:23.197349: step 20720, loss = 581.88, batch loss = 1.10 (44.2 examples/sec; 0.181 sec/batch; 15h:39m:55s remains)
INFO - root - 2017-12-03 08:28:24.999990: step 20730, loss = 582.10, batch loss = 1.32 (44.0 examples/sec; 0.182 sec/batch; 15h:44m:58s remains)
INFO - root - 2017-12-03 08:28:26.780063: step 20740, loss = 581.95, batch loss = 1.16 (44.6 examples/sec; 0.179 sec/batch; 15h:32m:15s remains)
INFO - root - 2017-12-03 08:28:28.576568: step 20750, loss = 581.87, batch loss = 1.09 (43.7 examples/sec; 0.183 sec/batch; 15h:51m:29s remains)
INFO - root - 2017-12-03 08:28:30.352209: step 20760, loss = 582.20, batch loss = 1.41 (46.1 examples/sec; 0.174 sec/batch; 15h:02m:06s remains)
INFO - root - 2017-12-03 08:28:32.134206: step 20770, loss = 581.93, batch loss = 1.14 (44.6 examples/sec; 0.179 sec/batch; 15h:32m:10s remains)
INFO - root - 2017-12-03 08:28:33.930626: step 20780, loss = 582.08, batch loss = 1.29 (44.0 examples/sec; 0.182 sec/batch; 15h:43m:57s remains)
INFO - root - 2017-12-03 08:28:35.710573: step 20790, loss = 582.07, batch loss = 1.28 (45.1 examples/sec; 0.178 sec/batch; 15h:22m:20s remains)
INFO - root - 2017-12-03 08:28:37.501493: step 20800, loss = 581.89, batch loss = 1.10 (45.8 examples/sec; 0.175 sec/batch; 15h:07m:49s remains)
INFO - root - 2017-12-03 08:28:39.381488: step 20810, loss = 581.92, batch loss = 1.13 (44.2 examples/sec; 0.181 sec/batch; 15h:40m:00s remains)
INFO - root - 2017-12-03 08:28:41.177619: step 20820, loss = 582.04, batch loss = 1.25 (44.4 examples/sec; 0.180 sec/batch; 15h:36m:38s remains)
INFO - root - 2017-12-03 08:28:42.980438: step 20830, loss = 581.82, batch loss = 1.03 (44.1 examples/sec; 0.182 sec/batch; 15h:42m:52s remains)
INFO - root - 2017-12-03 08:28:44.769891: step 20840, loss = 581.97, batch loss = 1.18 (44.6 examples/sec; 0.179 sec/batch; 15h:32m:08s remains)
INFO - root - 2017-12-03 08:28:46.556435: step 20850, loss = 582.00, batch loss = 1.21 (44.7 examples/sec; 0.179 sec/batch; 15h:29m:17s remains)
INFO - root - 2017-12-03 08:28:48.356535: step 20860, loss = 581.92, batch loss = 1.13 (43.8 examples/sec; 0.183 sec/batch; 15h:49m:29s remains)
INFO - root - 2017-12-03 08:28:50.148290: step 20870, loss = 581.96, batch loss = 1.17 (44.4 examples/sec; 0.180 sec/batch; 15h:36m:26s remains)
INFO - root - 2017-12-03 08:28:51.934712: step 20880, loss = 581.87, batch loss = 1.09 (44.6 examples/sec; 0.180 sec/batch; 15h:32m:32s remains)
INFO - root - 2017-12-03 08:28:53.711289: step 20890, loss = 581.91, batch loss = 1.13 (44.3 examples/sec; 0.181 sec/batch; 15h:37m:37s remains)
INFO - root - 2017-12-03 08:28:55.502445: step 20900, loss = 582.05, batch loss = 1.27 (45.0 examples/sec; 0.178 sec/batch; 15h:23m:12s remains)
INFO - root - 2017-12-03 08:28:57.346607: step 20910, loss = 582.01, batch loss = 1.22 (44.8 examples/sec; 0.178 sec/batch; 15h:26m:33s remains)
INFO - root - 2017-12-03 08:28:59.150152: step 20920, loss = 582.02, batch loss = 1.23 (44.7 examples/sec; 0.179 sec/batch; 15h:29m:07s remains)
INFO - root - 2017-12-03 08:29:00.950508: step 20930, loss = 582.10, batch loss = 1.31 (44.1 examples/sec; 0.182 sec/batch; 15h:42m:43s remains)
INFO - root - 2017-12-03 08:29:02.762865: step 20940, loss = 582.01, batch loss = 1.22 (44.1 examples/sec; 0.182 sec/batch; 15h:42m:55s remains)
INFO - root - 2017-12-03 08:29:04.550612: step 20950, loss = 581.91, batch loss = 1.12 (45.5 examples/sec; 0.176 sec/batch; 15h:12m:15s remains)
INFO - root - 2017-12-03 08:29:06.363520: step 20960, loss = 582.01, batch loss = 1.22 (45.0 examples/sec; 0.178 sec/batch; 15h:22m:26s remains)
INFO - root - 2017-12-03 08:29:08.140900: step 20970, loss = 581.96, batch loss = 1.17 (45.8 examples/sec; 0.175 sec/batch; 15h:06m:14s remains)
INFO - root - 2017-12-03 08:29:09.951160: step 20980, loss = 581.98, batch loss = 1.19 (45.4 examples/sec; 0.176 sec/batch; 15h:14m:44s remains)
INFO - root - 2017-12-03 08:29:11.774257: step 20990, loss = 581.97, batch loss = 1.18 (44.2 examples/sec; 0.181 sec/batch; 15h:40m:42s remains)
INFO - root - 2017-12-03 08:29:13.560760: step 21000, loss = 581.95, batch loss = 1.16 (45.7 examples/sec; 0.175 sec/batch; 15h:09m:30s remains)
INFO - root - 2017-12-03 08:29:15.405388: step 21010, loss = 581.89, batch loss = 1.10 (44.2 examples/sec; 0.181 sec/batch; 15h:39m:45s remains)
INFO - root - 2017-12-03 08:29:17.192076: step 21020, loss = 581.99, batch loss = 1.21 (45.1 examples/sec; 0.178 sec/batch; 15h:21m:33s remains)
INFO - root - 2017-12-03 08:29:18.984797: step 21030, loss = 581.97, batch loss = 1.18 (45.5 examples/sec; 0.176 sec/batch; 15h:12m:46s remains)
INFO - root - 2017-12-03 08:29:20.770708: step 21040, loss = 581.94, batch loss = 1.16 (43.3 examples/sec; 0.185 sec/batch; 15h:58m:24s remains)
INFO - root - 2017-12-03 08:29:22.571898: step 21050, loss = 582.21, batch loss = 1.42 (44.8 examples/sec; 0.179 sec/batch; 15h:27m:09s remains)
INFO - root - 2017-12-03 08:29:24.357616: step 21060, loss = 582.19, batch loss = 1.41 (44.9 examples/sec; 0.178 sec/batch; 15h:24m:27s remains)
INFO - root - 2017-12-03 08:29:26.146019: step 21070, loss = 581.88, batch loss = 1.09 (44.9 examples/sec; 0.178 sec/batch; 15h:24m:19s remains)
INFO - root - 2017-12-03 08:29:27.934720: step 21080, loss = 581.91, batch loss = 1.12 (43.7 examples/sec; 0.183 sec/batch; 15h:49m:07s remains)
INFO - root - 2017-12-03 08:29:29.719827: step 21090, loss = 582.07, batch loss = 1.29 (44.4 examples/sec; 0.180 sec/batch; 15h:35m:35s remains)
INFO - root - 2017-12-03 08:29:31.513197: step 21100, loss = 581.98, batch loss = 1.20 (44.1 examples/sec; 0.181 sec/batch; 15h:40m:37s remains)
INFO - root - 2017-12-03 08:29:33.376080: step 21110, loss = 582.01, batch loss = 1.22 (42.6 examples/sec; 0.188 sec/batch; 16h:15m:05s remains)
INFO - root - 2017-12-03 08:29:35.149505: step 21120, loss = 581.92, batch loss = 1.13 (44.8 examples/sec; 0.178 sec/batch; 15h:25m:46s remains)
INFO - root - 2017-12-03 08:29:36.937047: step 21130, loss = 581.94, batch loss = 1.15 (43.7 examples/sec; 0.183 sec/batch; 15h:49m:49s remains)
INFO - root - 2017-12-03 08:29:38.720445: step 21140, loss = 582.19, batch loss = 1.40 (45.4 examples/sec; 0.176 sec/batch; 15h:15m:17s remains)
INFO - root - 2017-12-03 08:29:40.529971: step 21150, loss = 582.03, batch loss = 1.25 (42.9 examples/sec; 0.187 sec/batch; 16h:07m:50s remains)
INFO - root - 2017-12-03 08:29:42.317259: step 21160, loss = 581.89, batch loss = 1.11 (44.3 examples/sec; 0.181 sec/batch; 15h:37m:31s remains)
INFO - root - 2017-12-03 08:29:44.132062: step 21170, loss = 581.87, batch loss = 1.08 (44.4 examples/sec; 0.180 sec/batch; 15h:34m:55s remains)
INFO - root - 2017-12-03 08:29:45.908689: step 21180, loss = 582.15, batch loss = 1.36 (45.0 examples/sec; 0.178 sec/batch; 15h:23m:08s remains)
INFO - root - 2017-12-03 08:29:47.714257: step 21190, loss = 582.01, batch loss = 1.23 (43.9 examples/sec; 0.182 sec/batch; 15h:46m:32s remains)
INFO - root - 2017-12-03 08:29:49.502976: step 21200, loss = 582.07, batch loss = 1.28 (44.4 examples/sec; 0.180 sec/batch; 15h:34m:59s remains)
INFO - root - 2017-12-03 08:29:51.401564: step 21210, loss = 582.07, batch loss = 1.29 (44.4 examples/sec; 0.180 sec/batch; 15h:35m:22s remains)
INFO - root - 2017-12-03 08:29:53.193319: step 21220, loss = 582.07, batch loss = 1.29 (44.0 examples/sec; 0.182 sec/batch; 15h:42m:39s remains)
INFO - root - 2017-12-03 08:29:55.013925: step 21230, loss = 581.95, batch loss = 1.16 (45.8 examples/sec; 0.175 sec/batch; 15h:05m:22s remains)
INFO - root - 2017-12-03 08:29:56.813879: step 21240, loss = 582.09, batch loss = 1.30 (44.2 examples/sec; 0.181 sec/batch; 15h:39m:11s remains)
INFO - root - 2017-12-03 08:29:58.600045: step 21250, loss = 581.97, batch loss = 1.19 (45.0 examples/sec; 0.178 sec/batch; 15h:21m:50s remains)
INFO - root - 2017-12-03 08:30:00.426222: step 21260, loss = 581.91, batch loss = 1.12 (43.9 examples/sec; 0.182 sec/batch; 15h:46m:19s remains)
INFO - root - 2017-12-03 08:30:02.226109: step 21270, loss = 581.96, batch loss = 1.18 (42.0 examples/sec; 0.191 sec/batch; 16h:28m:31s remains)
INFO - root - 2017-12-03 08:30:04.035904: step 21280, loss = 582.06, batch loss = 1.27 (43.5 examples/sec; 0.184 sec/batch; 15h:54m:13s remains)
INFO - root - 2017-12-03 08:30:05.825089: step 21290, loss = 581.95, batch loss = 1.17 (43.7 examples/sec; 0.183 sec/batch; 15h:49m:20s remains)
INFO - root - 2017-12-03 08:30:07.625378: step 21300, loss = 581.99, batch loss = 1.20 (44.9 examples/sec; 0.178 sec/batch; 15h:24m:56s remains)
INFO - root - 2017-12-03 08:30:09.518443: step 21310, loss = 582.06, batch loss = 1.27 (44.6 examples/sec; 0.179 sec/batch; 15h:29m:30s remains)
INFO - root - 2017-12-03 08:30:11.358703: step 21320, loss = 581.95, batch loss = 1.17 (45.3 examples/sec; 0.177 sec/batch; 15h:16m:14s remains)
INFO - root - 2017-12-03 08:30:13.142591: step 21330, loss = 582.05, batch loss = 1.26 (45.1 examples/sec; 0.178 sec/batch; 15h:20m:51s remains)
INFO - root - 2017-12-03 08:30:14.937097: step 21340, loss = 581.92, batch loss = 1.13 (45.5 examples/sec; 0.176 sec/batch; 15h:12m:00s remains)
INFO - root - 2017-12-03 08:30:16.739514: step 21350, loss = 581.89, batch loss = 1.10 (44.1 examples/sec; 0.181 sec/batch; 15h:41m:01s remains)
INFO - root - 2017-12-03 08:30:18.527106: step 21360, loss = 582.05, batch loss = 1.27 (44.7 examples/sec; 0.179 sec/batch; 15h:29m:06s remains)
INFO - root - 2017-12-03 08:30:20.311001: step 21370, loss = 582.10, batch loss = 1.31 (44.2 examples/sec; 0.181 sec/batch; 15h:39m:16s remains)
INFO - root - 2017-12-03 08:30:22.109415: step 21380, loss = 581.84, batch loss = 1.05 (45.2 examples/sec; 0.177 sec/batch; 15h:16m:47s remains)
INFO - root - 2017-12-03 08:30:23.905345: step 21390, loss = 582.00, batch loss = 1.21 (45.5 examples/sec; 0.176 sec/batch; 15h:11m:48s remains)
INFO - root - 2017-12-03 08:30:25.731409: step 21400, loss = 581.99, batch loss = 1.20 (42.3 examples/sec; 0.189 sec/batch; 16h:21m:08s remains)
INFO - root - 2017-12-03 08:30:27.608179: step 21410, loss = 581.90, batch loss = 1.11 (43.3 examples/sec; 0.185 sec/batch; 15h:58m:09s remains)
INFO - root - 2017-12-03 08:30:29.396788: step 21420, loss = 581.84, batch loss = 1.05 (45.1 examples/sec; 0.177 sec/batch; 15h:19m:54s remains)
INFO - root - 2017-12-03 08:30:31.184869: step 21430, loss = 581.91, batch loss = 1.12 (45.0 examples/sec; 0.178 sec/batch; 15h:22m:34s remains)
INFO - root - 2017-12-03 08:30:32.966698: step 21440, loss = 582.00, batch loss = 1.22 (42.7 examples/sec; 0.187 sec/batch; 16h:10m:22s remains)
INFO - root - 2017-12-03 08:30:34.777889: step 21450, loss = 581.93, batch loss = 1.14 (45.6 examples/sec; 0.175 sec/batch; 15h:08m:43s remains)
INFO - root - 2017-12-03 08:30:36.567078: step 21460, loss = 581.85, batch loss = 1.06 (43.7 examples/sec; 0.183 sec/batch; 15h:49m:49s remains)
INFO - root - 2017-12-03 08:30:38.361110: step 21470, loss = 581.96, batch loss = 1.17 (44.4 examples/sec; 0.180 sec/batch; 15h:33m:31s remains)
INFO - root - 2017-12-03 08:30:40.154038: step 21480, loss = 582.04, batch loss = 1.25 (43.5 examples/sec; 0.184 sec/batch; 15h:52m:20s remains)
INFO - root - 2017-12-03 08:30:41.944274: step 21490, loss = 581.93, batch loss = 1.15 (43.8 examples/sec; 0.182 sec/batch; 15h:45m:44s remains)
INFO - root - 2017-12-03 08:30:43.762735: step 21500, loss = 582.10, batch loss = 1.31 (44.4 examples/sec; 0.180 sec/batch; 15h:33m:07s remains)
INFO - root - 2017-12-03 08:30:45.642405: step 21510, loss = 581.86, batch loss = 1.07 (44.7 examples/sec; 0.179 sec/batch; 15h:27m:13s remains)
INFO - root - 2017-12-03 08:30:47.427504: step 21520, loss = 581.88, batch loss = 1.09 (45.6 examples/sec; 0.175 sec/batch; 15h:09m:12s remains)
INFO - root - 2017-12-03 08:30:49.220009: step 21530, loss = 581.93, batch loss = 1.14 (45.4 examples/sec; 0.176 sec/batch; 15h:13m:21s remains)
INFO - root - 2017-12-03 08:30:50.993960: step 21540, loss = 581.90, batch loss = 1.12 (45.3 examples/sec; 0.177 sec/batch; 15h:16m:03s remains)
INFO - root - 2017-12-03 08:30:52.801239: step 21550, loss = 581.90, batch loss = 1.12 (43.2 examples/sec; 0.185 sec/batch; 16h:00m:40s remains)
INFO - root - 2017-12-03 08:30:54.584182: step 21560, loss = 581.91, batch loss = 1.12 (45.2 examples/sec; 0.177 sec/batch; 15h:16m:29s remains)
INFO - root - 2017-12-03 08:30:56.373306: step 21570, loss = 581.96, batch loss = 1.17 (46.1 examples/sec; 0.174 sec/batch; 14h:59m:21s remains)
INFO - root - 2017-12-03 08:30:58.163011: step 21580, loss = 582.03, batch loss = 1.24 (44.7 examples/sec; 0.179 sec/batch; 15h:27m:11s remains)
INFO - root - 2017-12-03 08:30:59.968016: step 21590, loss = 582.04, batch loss = 1.26 (45.0 examples/sec; 0.178 sec/batch; 15h:21m:32s remains)
INFO - root - 2017-12-03 08:31:01.760158: step 21600, loss = 581.92, batch loss = 1.13 (44.3 examples/sec; 0.181 sec/batch; 15h:36m:38s remains)
INFO - root - 2017-12-03 08:31:03.611675: step 21610, loss = 582.08, batch loss = 1.29 (43.9 examples/sec; 0.182 sec/batch; 15h:43m:41s remains)
INFO - root - 2017-12-03 08:31:05.401706: step 21620, loss = 581.96, batch loss = 1.17 (44.5 examples/sec; 0.180 sec/batch; 15h:32m:14s remains)
INFO - root - 2017-12-03 08:31:07.189801: step 21630, loss = 581.91, batch loss = 1.12 (44.4 examples/sec; 0.180 sec/batch; 15h:32m:54s remains)
INFO - root - 2017-12-03 08:31:08.982033: step 21640, loss = 581.90, batch loss = 1.11 (45.1 examples/sec; 0.178 sec/batch; 15h:20m:02s remains)
INFO - root - 2017-12-03 08:31:10.794695: step 21650, loss = 581.94, batch loss = 1.16 (45.1 examples/sec; 0.177 sec/batch; 15h:18m:47s remains)
INFO - root - 2017-12-03 08:31:12.609882: step 21660, loss = 582.02, batch loss = 1.23 (42.0 examples/sec; 0.190 sec/batch; 16h:26m:17s remains)
INFO - root - 2017-12-03 08:31:14.416235: step 21670, loss = 582.09, batch loss = 1.30 (44.1 examples/sec; 0.181 sec/batch; 15h:39m:30s remains)
INFO - root - 2017-12-03 08:31:16.215446: step 21680, loss = 581.97, batch loss = 1.18 (43.4 examples/sec; 0.184 sec/batch; 15h:54m:44s remains)
INFO - root - 2017-12-03 08:31:18.028818: step 21690, loss = 581.87, batch loss = 1.08 (43.2 examples/sec; 0.185 sec/batch; 15h:59m:55s remains)
INFO - root - 2017-12-03 08:31:19.815589: step 21700, loss = 581.98, batch loss = 1.20 (44.6 examples/sec; 0.179 sec/batch; 15h:29m:24s remains)
INFO - root - 2017-12-03 08:31:21.682237: step 21710, loss = 581.89, batch loss = 1.11 (45.2 examples/sec; 0.177 sec/batch; 15h:15m:58s remains)
INFO - root - 2017-12-03 08:31:23.467870: step 21720, loss = 582.01, batch loss = 1.23 (45.1 examples/sec; 0.178 sec/batch; 15h:19m:47s remains)
INFO - root - 2017-12-03 08:31:25.290311: step 21730, loss = 581.97, batch loss = 1.18 (45.0 examples/sec; 0.178 sec/batch; 15h:20m:01s remains)
INFO - root - 2017-12-03 08:31:27.095727: step 21740, loss = 581.90, batch loss = 1.11 (43.9 examples/sec; 0.182 sec/batch; 15h:42m:50s remains)
INFO - root - 2017-12-03 08:31:28.886470: step 21750, loss = 582.02, batch loss = 1.23 (45.5 examples/sec; 0.176 sec/batch; 15h:10m:36s remains)
INFO - root - 2017-12-03 08:31:30.674127: step 21760, loss = 582.05, batch loss = 1.26 (44.1 examples/sec; 0.181 sec/batch; 15h:38m:57s remains)
INFO - root - 2017-12-03 08:31:32.450154: step 21770, loss = 581.92, batch loss = 1.14 (45.5 examples/sec; 0.176 sec/batch; 15h:10m:41s remains)
INFO - root - 2017-12-03 08:31:34.255325: step 21780, loss = 581.93, batch loss = 1.14 (44.7 examples/sec; 0.179 sec/batch; 15h:26m:21s remains)
INFO - root - 2017-12-03 08:31:36.025984: step 21790, loss = 581.91, batch loss = 1.13 (44.7 examples/sec; 0.179 sec/batch; 15h:26m:28s remains)
INFO - root - 2017-12-03 08:31:37.820046: step 21800, loss = 582.10, batch loss = 1.32 (44.3 examples/sec; 0.181 sec/batch; 15h:34m:56s remains)
INFO - root - 2017-12-03 08:31:39.690596: step 21810, loss = 582.10, batch loss = 1.31 (44.5 examples/sec; 0.180 sec/batch; 15h:31m:22s remains)
INFO - root - 2017-12-03 08:31:41.495949: step 21820, loss = 581.92, batch loss = 1.13 (43.1 examples/sec; 0.186 sec/batch; 16h:01m:58s remains)
INFO - root - 2017-12-03 08:31:43.307106: step 21830, loss = 581.80, batch loss = 1.02 (43.3 examples/sec; 0.185 sec/batch; 15h:56m:22s remains)
INFO - root - 2017-12-03 08:31:45.120149: step 21840, loss = 582.00, batch loss = 1.21 (44.4 examples/sec; 0.180 sec/batch; 15h:33m:46s remains)
INFO - root - 2017-12-03 08:31:46.904093: step 21850, loss = 582.20, batch loss = 1.41 (44.2 examples/sec; 0.181 sec/batch; 15h:36m:48s remains)
INFO - root - 2017-12-03 08:31:48.700376: step 21860, loss = 581.83, batch loss = 1.04 (43.7 examples/sec; 0.183 sec/batch; 15h:47m:00s remains)
INFO - root - 2017-12-03 08:31:50.480418: step 21870, loss = 582.10, batch loss = 1.31 (44.6 examples/sec; 0.179 sec/batch; 15h:28m:10s remains)
INFO - root - 2017-12-03 08:31:52.280442: step 21880, loss = 582.01, batch loss = 1.23 (45.4 examples/sec; 0.176 sec/batch; 15h:11m:48s remains)
INFO - root - 2017-12-03 08:31:54.081975: step 21890, loss = 581.96, batch loss = 1.17 (43.0 examples/sec; 0.186 sec/batch; 16h:03m:18s remains)
INFO - root - 2017-12-03 08:31:55.897220: step 21900, loss = 581.78, batch loss = 0.99 (45.4 examples/sec; 0.176 sec/batch; 15h:12m:40s remains)
INFO - root - 2017-12-03 08:31:57.773635: step 21910, loss = 582.01, batch loss = 1.22 (44.6 examples/sec; 0.179 sec/batch; 15h:28m:15s remains)
INFO - root - 2017-12-03 08:31:59.565526: step 21920, loss = 581.91, batch loss = 1.12 (42.4 examples/sec; 0.189 sec/batch; 16h:17m:30s remains)
INFO - root - 2017-12-03 08:32:01.346303: step 21930, loss = 581.97, batch loss = 1.18 (44.7 examples/sec; 0.179 sec/batch; 15h:26m:15s remains)
INFO - root - 2017-12-03 08:32:03.149810: step 21940, loss = 582.04, batch loss = 1.25 (44.1 examples/sec; 0.181 sec/batch; 15h:38m:05s remains)
INFO - root - 2017-12-03 08:32:04.936887: step 21950, loss = 581.91, batch loss = 1.12 (43.5 examples/sec; 0.184 sec/batch; 15h:51m:37s remains)
INFO - root - 2017-12-03 08:32:06.759702: step 21960, loss = 581.97, batch loss = 1.18 (44.8 examples/sec; 0.178 sec/batch; 15h:23m:16s remains)
INFO - root - 2017-12-03 08:32:08.594270: step 21970, loss = 582.03, batch loss = 1.24 (42.6 examples/sec; 0.188 sec/batch; 16h:12m:45s remains)
INFO - root - 2017-12-03 08:32:10.383583: step 21980, loss = 581.93, batch loss = 1.14 (44.4 examples/sec; 0.180 sec/batch; 15h:32m:01s remains)
INFO - root - 2017-12-03 08:32:12.170613: step 21990, loss = 581.87, batch loss = 1.08 (44.8 examples/sec; 0.179 sec/batch; 15h:23m:52s remains)
INFO - root - 2017-12-03 08:32:13.966310: step 22000, loss = 582.02, batch loss = 1.23 (44.6 examples/sec; 0.179 sec/batch; 15h:27m:54s remains)
INFO - root - 2017-12-03 08:32:15.864386: step 22010, loss = 581.93, batch loss = 1.14 (43.8 examples/sec; 0.183 sec/batch; 15h:45m:43s remains)
INFO - root - 2017-12-03 08:32:17.652184: step 22020, loss = 582.10, batch loss = 1.32 (45.0 examples/sec; 0.178 sec/batch; 15h:20m:20s remains)
INFO - root - 2017-12-03 08:32:19.466552: step 22030, loss = 581.88, batch loss = 1.10 (43.8 examples/sec; 0.183 sec/batch; 15h:45m:44s remains)
INFO - root - 2017-12-03 08:32:21.275488: step 22040, loss = 582.11, batch loss = 1.32 (41.0 examples/sec; 0.195 sec/batch; 16h:49m:33s remains)
INFO - root - 2017-12-03 08:32:23.063632: step 22050, loss = 581.76, batch loss = 0.97 (45.7 examples/sec; 0.175 sec/batch; 15h:05m:19s remains)
INFO - root - 2017-12-03 08:32:24.864717: step 22060, loss = 582.00, batch loss = 1.21 (44.0 examples/sec; 0.182 sec/batch; 15h:41m:20s remains)
INFO - root - 2017-12-03 08:32:26.655204: step 22070, loss = 582.02, batch loss = 1.23 (45.3 examples/sec; 0.177 sec/batch; 15h:14m:15s remains)
INFO - root - 2017-12-03 08:32:28.476112: step 22080, loss = 581.78, batch loss = 1.00 (44.8 examples/sec; 0.179 sec/batch; 15h:24m:43s remains)
INFO - root - 2017-12-03 08:32:30.253904: step 22090, loss = 582.05, batch loss = 1.27 (43.4 examples/sec; 0.184 sec/batch; 15h:52m:37s remains)
INFO - root - 2017-12-03 08:32:32.045973: step 22100, loss = 582.00, batch loss = 1.21 (45.2 examples/sec; 0.177 sec/batch; 15h:16m:17s remains)
INFO - root - 2017-12-03 08:32:33.914344: step 22110, loss = 581.92, batch loss = 1.13 (44.9 examples/sec; 0.178 sec/batch; 15h:21m:36s remains)
INFO - root - 2017-12-03 08:32:35.691270: step 22120, loss = 581.89, batch loss = 1.11 (43.9 examples/sec; 0.182 sec/batch; 15h:42m:13s remains)
INFO - root - 2017-12-03 08:32:37.485245: step 22130, loss = 582.11, batch loss = 1.32 (44.6 examples/sec; 0.179 sec/batch; 15h:27m:57s remains)
INFO - root - 2017-12-03 08:32:39.264582: step 22140, loss = 582.03, batch loss = 1.24 (43.4 examples/sec; 0.184 sec/batch; 15h:54m:11s remains)
INFO - root - 2017-12-03 08:32:41.109599: step 22150, loss = 582.03, batch loss = 1.24 (44.7 examples/sec; 0.179 sec/batch; 15h:25m:01s remains)
INFO - root - 2017-12-03 08:32:42.913489: step 22160, loss = 582.15, batch loss = 1.36 (43.4 examples/sec; 0.184 sec/batch; 15h:53m:20s remains)
INFO - root - 2017-12-03 08:32:44.703644: step 22170, loss = 582.03, batch loss = 1.24 (43.4 examples/sec; 0.184 sec/batch; 15h:53m:59s remains)
INFO - root - 2017-12-03 08:32:46.537659: step 22180, loss = 581.87, batch loss = 1.08 (38.4 examples/sec; 0.208 sec/batch; 17h:56m:19s remains)
INFO - root - 2017-12-03 08:32:48.323145: step 22190, loss = 581.92, batch loss = 1.13 (44.4 examples/sec; 0.180 sec/batch; 15h:32m:06s remains)
INFO - root - 2017-12-03 08:32:50.102103: step 22200, loss = 582.02, batch loss = 1.24 (45.9 examples/sec; 0.174 sec/batch; 15h:01m:13s remains)
INFO - root - 2017-12-03 08:32:51.947256: step 22210, loss = 581.96, batch loss = 1.18 (45.2 examples/sec; 0.177 sec/batch; 15h:16m:00s remains)
INFO - root - 2017-12-03 08:32:53.741371: step 22220, loss = 581.95, batch loss = 1.16 (45.3 examples/sec; 0.177 sec/batch; 15h:13m:48s remains)
INFO - root - 2017-12-03 08:32:55.520444: step 22230, loss = 581.92, batch loss = 1.13 (45.8 examples/sec; 0.175 sec/batch; 15h:02m:36s remains)
INFO - root - 2017-12-03 08:32:57.318024: step 22240, loss = 581.93, batch loss = 1.14 (43.1 examples/sec; 0.186 sec/batch; 16h:00m:31s remains)
INFO - root - 2017-12-03 08:32:59.114068: step 22250, loss = 582.18, batch loss = 1.39 (45.0 examples/sec; 0.178 sec/batch; 15h:19m:28s remains)
INFO - root - 2017-12-03 08:33:00.904355: step 22260, loss = 581.86, batch loss = 1.07 (45.2 examples/sec; 0.177 sec/batch; 15h:15m:12s remains)
INFO - root - 2017-12-03 08:33:02.700413: step 22270, loss = 581.96, batch loss = 1.17 (45.2 examples/sec; 0.177 sec/batch; 15h:14m:59s remains)
INFO - root - 2017-12-03 08:33:04.498840: step 22280, loss = 581.91, batch loss = 1.13 (44.6 examples/sec; 0.179 sec/batch; 15h:27m:29s remains)
INFO - root - 2017-12-03 08:33:06.283214: step 22290, loss = 581.94, batch loss = 1.15 (44.9 examples/sec; 0.178 sec/batch; 15h:20m:13s remains)
INFO - root - 2017-12-03 08:33:08.083833: step 22300, loss = 581.90, batch loss = 1.11 (45.0 examples/sec; 0.178 sec/batch; 15h:19m:51s remains)
INFO - root - 2017-12-03 08:33:09.964828: step 22310, loss = 582.05, batch loss = 1.26 (44.2 examples/sec; 0.181 sec/batch; 15h:35m:59s remains)
INFO - root - 2017-12-03 08:33:11.755032: step 22320, loss = 582.00, batch loss = 1.21 (45.2 examples/sec; 0.177 sec/batch; 15h:15m:27s remains)
INFO - root - 2017-12-03 08:33:13.550705: step 22330, loss = 582.06, batch loss = 1.27 (45.8 examples/sec; 0.175 sec/batch; 15h:03m:31s remains)
INFO - root - 2017-12-03 08:33:15.344242: step 22340, loss = 581.87, batch loss = 1.09 (44.6 examples/sec; 0.179 sec/batch; 15h:27m:36s remains)
INFO - root - 2017-12-03 08:33:17.135478: step 22350, loss = 581.98, batch loss = 1.20 (45.0 examples/sec; 0.178 sec/batch; 15h:19m:25s remains)
INFO - root - 2017-12-03 08:33:18.960815: step 22360, loss = 581.95, batch loss = 1.17 (40.8 examples/sec; 0.196 sec/batch; 16h:52m:28s remains)
INFO - root - 2017-12-03 08:33:20.752852: step 22370, loss = 581.92, batch loss = 1.13 (45.3 examples/sec; 0.177 sec/batch; 15h:13m:45s remains)
INFO - root - 2017-12-03 08:33:22.554144: step 22380, loss = 582.15, batch loss = 1.37 (45.1 examples/sec; 0.177 sec/batch; 15h:16m:30s remains)
INFO - root - 2017-12-03 08:33:24.374064: step 22390, loss = 582.03, batch loss = 1.25 (42.9 examples/sec; 0.186 sec/batch; 16h:03m:06s remains)
INFO - root - 2017-12-03 08:33:26.163689: step 22400, loss = 582.06, batch loss = 1.27 (43.8 examples/sec; 0.183 sec/batch; 15h:43m:44s remains)
INFO - root - 2017-12-03 08:33:28.095153: step 22410, loss = 581.92, batch loss = 1.13 (43.2 examples/sec; 0.185 sec/batch; 15h:57m:04s remains)
INFO - root - 2017-12-03 08:33:29.894944: step 22420, loss = 582.03, batch loss = 1.24 (44.5 examples/sec; 0.180 sec/batch; 15h:29m:51s remains)
INFO - root - 2017-12-03 08:33:31.714856: step 22430, loss = 581.89, batch loss = 1.10 (45.1 examples/sec; 0.177 sec/batch; 15h:15m:44s remains)
INFO - root - 2017-12-03 08:33:33.515291: step 22440, loss = 581.84, batch loss = 1.05 (44.7 examples/sec; 0.179 sec/batch; 15h:24m:30s remains)
INFO - root - 2017-12-03 08:33:35.309651: step 22450, loss = 582.13, batch loss = 1.34 (44.8 examples/sec; 0.178 sec/batch; 15h:21m:57s remains)
INFO - root - 2017-12-03 08:33:37.127204: step 22460, loss = 581.96, batch loss = 1.17 (43.6 examples/sec; 0.183 sec/batch; 15h:47m:24s remains)
INFO - root - 2017-12-03 08:33:38.914090: step 22470, loss = 582.09, batch loss = 1.30 (44.0 examples/sec; 0.182 sec/batch; 15h:38m:42s remains)
INFO - root - 2017-12-03 08:33:40.744177: step 22480, loss = 581.89, batch loss = 1.10 (44.3 examples/sec; 0.181 sec/batch; 15h:33m:05s remains)
INFO - root - 2017-12-03 08:33:42.566997: step 22490, loss = 582.04, batch loss = 1.25 (43.3 examples/sec; 0.185 sec/batch; 15h:54m:10s remains)
INFO - root - 2017-12-03 08:33:44.379072: step 22500, loss = 582.05, batch loss = 1.26 (43.6 examples/sec; 0.183 sec/batch; 15h:48m:02s remains)
INFO - root - 2017-12-03 08:33:46.224321: step 22510, loss = 582.06, batch loss = 1.27 (43.5 examples/sec; 0.184 sec/batch; 15h:50m:07s remains)
INFO - root - 2017-12-03 08:33:48.039191: step 22520, loss = 581.95, batch loss = 1.16 (44.7 examples/sec; 0.179 sec/batch; 15h:24m:53s remains)
INFO - root - 2017-12-03 08:33:49.825032: step 22530, loss = 581.85, batch loss = 1.07 (44.3 examples/sec; 0.181 sec/batch; 15h:33m:01s remains)
INFO - root - 2017-12-03 08:33:51.613680: step 22540, loss = 581.85, batch loss = 1.07 (44.6 examples/sec; 0.179 sec/batch; 15h:26m:59s remains)
INFO - root - 2017-12-03 08:33:53.417846: step 22550, loss = 581.97, batch loss = 1.18 (43.5 examples/sec; 0.184 sec/batch; 15h:50m:28s remains)
INFO - root - 2017-12-03 08:33:55.217175: step 22560, loss = 582.07, batch loss = 1.28 (42.3 examples/sec; 0.189 sec/batch; 16h:17m:02s remains)
INFO - root - 2017-12-03 08:33:57.028515: step 22570, loss = 582.14, batch loss = 1.35 (45.7 examples/sec; 0.175 sec/batch; 15h:04m:35s remains)
INFO - root - 2017-12-03 08:33:58.816946: step 22580, loss = 582.04, batch loss = 1.25 (43.6 examples/sec; 0.184 sec/batch; 15h:48m:40s remains)
INFO - root - 2017-12-03 08:34:00.620434: step 22590, loss = 581.81, batch loss = 1.03 (44.7 examples/sec; 0.179 sec/batch; 15h:24m:54s remains)
INFO - root - 2017-12-03 08:34:02.402034: step 22600, loss = 582.00, batch loss = 1.21 (44.4 examples/sec; 0.180 sec/batch; 15h:29m:37s remains)
INFO - root - 2017-12-03 08:34:04.257873: step 22610, loss = 582.18, batch loss = 1.40 (45.0 examples/sec; 0.178 sec/batch; 15h:18m:55s remains)
INFO - root - 2017-12-03 08:34:06.049135: step 22620, loss = 581.83, batch loss = 1.04 (45.6 examples/sec; 0.175 sec/batch; 15h:05m:37s remains)
INFO - root - 2017-12-03 08:34:07.845241: step 22630, loss = 581.99, batch loss = 1.20 (43.4 examples/sec; 0.184 sec/batch; 15h:52m:00s remains)
INFO - root - 2017-12-03 08:34:09.630782: step 22640, loss = 581.86, batch loss = 1.07 (45.4 examples/sec; 0.176 sec/batch; 15h:09m:38s remains)
INFO - root - 2017-12-03 08:34:11.435560: step 22650, loss = 581.92, batch loss = 1.13 (44.3 examples/sec; 0.180 sec/batch; 15h:31m:33s remains)
INFO - root - 2017-12-03 08:34:13.226062: step 22660, loss = 582.02, batch loss = 1.23 (45.3 examples/sec; 0.176 sec/batch; 15h:10m:59s remains)
INFO - root - 2017-12-03 08:34:15.039611: step 22670, loss = 581.80, batch loss = 1.01 (44.3 examples/sec; 0.181 sec/batch; 15h:33m:28s remains)
INFO - root - 2017-12-03 08:34:16.816139: step 22680, loss = 581.88, batch loss = 1.09 (45.9 examples/sec; 0.174 sec/batch; 14h:59m:03s remains)
INFO - root - 2017-12-03 08:34:18.607503: step 22690, loss = 582.07, batch loss = 1.28 (44.9 examples/sec; 0.178 sec/batch; 15h:20m:28s remains)
INFO - root - 2017-12-03 08:34:20.389060: step 22700, loss = 582.13, batch loss = 1.34 (45.0 examples/sec; 0.178 sec/batch; 15h:17m:42s remains)
INFO - root - 2017-12-03 08:34:22.281885: step 22710, loss = 582.01, batch loss = 1.22 (43.0 examples/sec; 0.186 sec/batch; 15h:59m:41s remains)
INFO - root - 2017-12-03 08:34:24.097883: step 22720, loss = 581.98, batch loss = 1.20 (41.1 examples/sec; 0.195 sec/batch; 16h:46m:09s remains)
INFO - root - 2017-12-03 08:34:25.912148: step 22730, loss = 582.02, batch loss = 1.23 (45.5 examples/sec; 0.176 sec/batch; 15h:07m:41s remains)
INFO - root - 2017-12-03 08:34:27.719749: step 22740, loss = 581.80, batch loss = 1.01 (43.1 examples/sec; 0.186 sec/batch; 15h:57m:49s remains)
INFO - root - 2017-12-03 08:34:29.507439: step 22750, loss = 581.96, batch loss = 1.17 (45.8 examples/sec; 0.175 sec/batch; 15h:02m:02s remains)
INFO - root - 2017-12-03 08:34:31.318624: step 22760, loss = 582.08, batch loss = 1.29 (44.3 examples/sec; 0.181 sec/batch; 15h:32m:47s remains)
INFO - root - 2017-12-03 08:34:33.103076: step 22770, loss = 581.92, batch loss = 1.13 (44.9 examples/sec; 0.178 sec/batch; 15h:20m:17s remains)
INFO - root - 2017-12-03 08:34:34.883822: step 22780, loss = 582.04, batch loss = 1.26 (45.5 examples/sec; 0.176 sec/batch; 15h:07m:50s remains)
INFO - root - 2017-12-03 08:34:36.665837: step 22790, loss = 581.84, batch loss = 1.06 (44.6 examples/sec; 0.179 sec/batch; 15h:25m:55s remains)
INFO - root - 2017-12-03 08:34:38.469264: step 22800, loss = 582.04, batch loss = 1.25 (44.8 examples/sec; 0.179 sec/batch; 15h:21m:41s remains)
INFO - root - 2017-12-03 08:34:40.368576: step 22810, loss = 581.96, batch loss = 1.17 (43.9 examples/sec; 0.182 sec/batch; 15h:41m:03s remains)
INFO - root - 2017-12-03 08:34:42.169470: step 22820, loss = 582.05, batch loss = 1.27 (44.7 examples/sec; 0.179 sec/batch; 15h:23m:31s remains)
INFO - root - 2017-12-03 08:34:43.975142: step 22830, loss = 581.93, batch loss = 1.15 (45.4 examples/sec; 0.176 sec/batch; 15h:09m:58s remains)
INFO - root - 2017-12-03 08:34:45.776437: step 22840, loss = 582.03, batch loss = 1.25 (44.8 examples/sec; 0.178 sec/batch; 15h:21m:00s remains)
INFO - root - 2017-12-03 08:34:47.565097: step 22850, loss = 582.01, batch loss = 1.22 (44.1 examples/sec; 0.181 sec/batch; 15h:36m:03s remains)
INFO - root - 2017-12-03 08:34:49.366414: step 22860, loss = 581.90, batch loss = 1.12 (45.5 examples/sec; 0.176 sec/batch; 15h:07m:54s remains)
INFO - root - 2017-12-03 08:34:51.171440: step 22870, loss = 581.94, batch loss = 1.15 (44.8 examples/sec; 0.178 sec/batch; 15h:21m:02s remains)
INFO - root - 2017-12-03 08:34:52.953447: step 22880, loss = 581.98, batch loss = 1.19 (45.0 examples/sec; 0.178 sec/batch; 15h:17m:12s remains)
INFO - root - 2017-12-03 08:34:54.758606: step 22890, loss = 582.01, batch loss = 1.22 (44.1 examples/sec; 0.181 sec/batch; 15h:35m:08s remains)
INFO - root - 2017-12-03 08:34:56.533863: step 22900, loss = 582.04, batch loss = 1.25 (45.5 examples/sec; 0.176 sec/batch; 15h:07m:12s remains)
INFO - root - 2017-12-03 08:34:58.393453: step 22910, loss = 582.04, batch loss = 1.26 (45.7 examples/sec; 0.175 sec/batch; 15h:03m:32s remains)
INFO - root - 2017-12-03 08:35:00.175632: step 22920, loss = 581.98, batch loss = 1.20 (44.5 examples/sec; 0.180 sec/batch; 15h:27m:21s remains)
INFO - root - 2017-12-03 08:35:01.985554: step 22930, loss = 581.98, batch loss = 1.19 (44.8 examples/sec; 0.179 sec/batch; 15h:22m:10s remains)
INFO - root - 2017-12-03 08:35:03.806042: step 22940, loss = 582.00, batch loss = 1.21 (44.3 examples/sec; 0.180 sec/batch; 15h:30m:56s remains)
INFO - root - 2017-12-03 08:35:05.593312: step 22950, loss = 581.95, batch loss = 1.17 (44.9 examples/sec; 0.178 sec/batch; 15h:19m:52s remains)
INFO - root - 2017-12-03 08:35:07.388926: step 22960, loss = 581.83, batch loss = 1.04 (43.9 examples/sec; 0.182 sec/batch; 15h:39m:36s remains)
INFO - root - 2017-12-03 08:35:09.181036: step 22970, loss = 582.01, batch loss = 1.22 (44.4 examples/sec; 0.180 sec/batch; 15h:29m:41s remains)
INFO - root - 2017-12-03 08:35:10.978480: step 22980, loss = 581.96, batch loss = 1.17 (45.1 examples/sec; 0.177 sec/batch; 15h:15m:33s remains)
INFO - root - 2017-12-03 08:35:12.774523: step 22990, loss = 582.01, batch loss = 1.22 (44.4 examples/sec; 0.180 sec/batch; 15h:28m:36s remains)
INFO - root - 2017-12-03 08:35:14.569264: step 23000, loss = 581.95, batch loss = 1.16 (41.9 examples/sec; 0.191 sec/batch; 16h:24m:23s remains)
INFO - root - 2017-12-03 08:35:16.413676: step 23010, loss = 582.04, batch loss = 1.25 (45.5 examples/sec; 0.176 sec/batch; 15h:07m:16s remains)
INFO - root - 2017-12-03 08:35:18.204965: step 23020, loss = 582.12, batch loss = 1.33 (44.2 examples/sec; 0.181 sec/batch; 15h:33m:50s remains)
INFO - root - 2017-12-03 08:35:20.009816: step 23030, loss = 581.88, batch loss = 1.10 (45.1 examples/sec; 0.177 sec/batch; 15h:14m:21s remains)
INFO - root - 2017-12-03 08:35:21.807934: step 23040, loss = 581.96, batch loss = 1.17 (45.4 examples/sec; 0.176 sec/batch; 15h:08m:46s remains)
INFO - root - 2017-12-03 08:35:23.583597: step 23050, loss = 581.96, batch loss = 1.17 (44.4 examples/sec; 0.180 sec/batch; 15h:28m:37s remains)
INFO - root - 2017-12-03 08:35:25.409181: step 23060, loss = 581.93, batch loss = 1.15 (45.2 examples/sec; 0.177 sec/batch; 15h:13m:39s remains)
INFO - root - 2017-12-03 08:35:27.202007: step 23070, loss = 582.00, batch loss = 1.21 (44.6 examples/sec; 0.179 sec/batch; 15h:25m:27s remains)
INFO - root - 2017-12-03 08:35:28.964836: step 23080, loss = 581.82, batch loss = 1.03 (45.0 examples/sec; 0.178 sec/batch; 15h:16m:05s remains)
INFO - root - 2017-12-03 08:35:30.757203: step 23090, loss = 581.93, batch loss = 1.15 (43.1 examples/sec; 0.186 sec/batch; 15h:56m:52s remains)
INFO - root - 2017-12-03 08:35:32.560731: step 23100, loss = 581.84, batch loss = 1.05 (44.8 examples/sec; 0.179 sec/batch; 15h:21m:08s remains)
INFO - root - 2017-12-03 08:35:34.424594: step 23110, loss = 582.11, batch loss = 1.32 (44.9 examples/sec; 0.178 sec/batch; 15h:19m:08s remains)
INFO - root - 2017-12-03 08:35:36.335279: step 23120, loss = 581.92, batch loss = 1.13 (44.8 examples/sec; 0.179 sec/batch; 15h:21m:33s remains)
INFO - root - 2017-12-03 08:35:38.126250: step 23130, loss = 581.98, batch loss = 1.20 (44.9 examples/sec; 0.178 sec/batch; 15h:17m:48s remains)
INFO - root - 2017-12-03 08:35:39.905082: step 23140, loss = 581.89, batch loss = 1.10 (44.8 examples/sec; 0.179 sec/batch; 15h:21m:38s remains)
INFO - root - 2017-12-03 08:35:41.721552: step 23150, loss = 582.21, batch loss = 1.43 (45.2 examples/sec; 0.177 sec/batch; 15h:12m:13s remains)
INFO - root - 2017-12-03 08:35:43.527660: step 23160, loss = 581.75, batch loss = 0.96 (43.8 examples/sec; 0.182 sec/batch; 15h:40m:40s remains)
INFO - root - 2017-12-03 08:35:45.338990: step 23170, loss = 581.83, batch loss = 1.04 (45.2 examples/sec; 0.177 sec/batch; 15h:12m:28s remains)
INFO - root - 2017-12-03 08:35:47.144602: step 23180, loss = 581.93, batch loss = 1.14 (43.8 examples/sec; 0.183 sec/batch; 15h:42m:23s remains)
INFO - root - 2017-12-03 08:35:48.936020: step 23190, loss = 581.96, batch loss = 1.18 (43.9 examples/sec; 0.182 sec/batch; 15h:40m:13s remains)
INFO - root - 2017-12-03 08:35:50.724069: step 23200, loss = 582.05, batch loss = 1.26 (45.3 examples/sec; 0.177 sec/batch; 15h:10m:05s remains)
INFO - root - 2017-12-03 08:35:52.590936: step 23210, loss = 582.16, batch loss = 1.37 (42.7 examples/sec; 0.187 sec/batch; 16h:06m:29s remains)
INFO - root - 2017-12-03 08:35:54.392096: step 23220, loss = 581.92, batch loss = 1.13 (45.0 examples/sec; 0.178 sec/batch; 15h:15m:57s remains)
INFO - root - 2017-12-03 08:35:56.192962: step 23230, loss = 582.05, batch loss = 1.27 (44.5 examples/sec; 0.180 sec/batch; 15h:27m:13s remains)
INFO - root - 2017-12-03 08:35:58.002624: step 23240, loss = 582.08, batch loss = 1.30 (43.8 examples/sec; 0.183 sec/batch; 15h:41m:17s remains)
INFO - root - 2017-12-03 08:35:59.797446: step 23250, loss = 582.32, batch loss = 1.53 (43.9 examples/sec; 0.182 sec/batch; 15h:40m:15s remains)
INFO - root - 2017-12-03 08:36:01.581363: step 23260, loss = 582.15, batch loss = 1.36 (45.6 examples/sec; 0.175 sec/batch; 15h:03m:47s remains)
INFO - root - 2017-12-03 08:36:03.390455: step 23270, loss = 581.90, batch loss = 1.11 (43.5 examples/sec; 0.184 sec/batch; 15h:47m:08s remains)
INFO - root - 2017-12-03 08:36:05.200799: step 23280, loss = 582.10, batch loss = 1.32 (44.3 examples/sec; 0.180 sec/batch; 15h:30m:01s remains)
INFO - root - 2017-12-03 08:36:07.014309: step 23290, loss = 582.00, batch loss = 1.21 (44.5 examples/sec; 0.180 sec/batch; 15h:25m:29s remains)
INFO - root - 2017-12-03 08:36:08.833636: step 23300, loss = 582.05, batch loss = 1.26 (42.2 examples/sec; 0.189 sec/batch; 16h:16m:09s remains)
INFO - root - 2017-12-03 08:36:10.826424: step 23310, loss = 582.01, batch loss = 1.22 (44.1 examples/sec; 0.182 sec/batch; 15h:35m:32s remains)
INFO - root - 2017-12-03 08:36:12.635588: step 23320, loss = 582.01, batch loss = 1.22 (46.3 examples/sec; 0.173 sec/batch; 14h:50m:11s remains)
INFO - root - 2017-12-03 08:36:14.448792: step 23330, loss = 581.80, batch loss = 1.02 (43.5 examples/sec; 0.184 sec/batch; 15h:48m:03s remains)
INFO - root - 2017-12-03 08:36:16.255097: step 23340, loss = 582.07, batch loss = 1.28 (45.2 examples/sec; 0.177 sec/batch; 15h:11m:32s remains)
INFO - root - 2017-12-03 08:36:18.070728: step 23350, loss = 582.01, batch loss = 1.22 (43.4 examples/sec; 0.184 sec/batch; 15h:49m:49s remains)
INFO - root - 2017-12-03 08:36:19.868205: step 23360, loss = 581.91, batch loss = 1.12 (42.5 examples/sec; 0.188 sec/batch; 16h:08m:48s remains)
INFO - root - 2017-12-03 08:36:21.675352: step 23370, loss = 581.93, batch loss = 1.14 (44.6 examples/sec; 0.179 sec/batch; 15h:24m:36s remains)
INFO - root - 2017-12-03 08:36:23.493068: step 23380, loss = 581.89, batch loss = 1.10 (44.7 examples/sec; 0.179 sec/batch; 15h:22m:13s remains)
INFO - root - 2017-12-03 08:36:25.302466: step 23390, loss = 582.04, batch loss = 1.26 (43.9 examples/sec; 0.182 sec/batch; 15h:38m:56s remains)
INFO - root - 2017-12-03 08:36:27.117723: step 23400, loss = 581.84, batch loss = 1.05 (43.0 examples/sec; 0.186 sec/batch; 15h:57m:57s remains)
