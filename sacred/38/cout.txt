INFO - Siam-FC - Running command 'main'
INFO - Siam-FC - Started run with ID "38"
INFO - root - preproces -- siamese_fc_color
WARNING - root - root is not explicitly specified, using default value: None
INFO - root - For training, we use instance size 255 - 2 * 8 ...
WARNING - root - init_method is not explicitly specified, using default value: None
sdiufhasudf Tensor("siamese_fc/conv5/split:0", shape=(8, 8, 8, 192), dtype=float32)
sdfah Tensor("siamese_fc/conv5/def/offset2/BiasAdd:0", shape=(8, 8, 8, 72), dtype=float32)
Tensor("siamese_fc/conv5/def/transpose:0", shape=(8, 192, 8, 8), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(128, 192, 3, 3) dtype=float32_ref> Tensor("siamese_fc/conv5/def/transpose_1:0", shape=(8, 72, 8, 8), dtype=float32)
ddd Tensor("siamese_fc/conv5/def/b1/transpose:0", shape=(8, 6, 6, 128), dtype=float32)
sdiufhasudf Tensor("siamese_fc_1/conv5/split:0", shape=(8, 22, 22, 192), dtype=float32)
sdfah Tensor("siamese_fc_1/conv5/def/offset2/BiasAdd:0", shape=(8, 22, 22, 72), dtype=float32)
Tensor("siamese_fc_1/conv5/def/transpose:0", shape=(8, 192, 22, 22), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(128, 192, 3, 3) dtype=float32_ref> Tensor("siamese_fc_1/conv5/def/transpose_1:0", shape=(8, 72, 22, 22), dtype=float32)
ddd Tensor("siamese_fc_1/conv5/def/b1/transpose:0", shape=(8, 20, 20, 128), dtype=float32)
INFO - root - Model moving average is disabled since decay factor is 0
2017-12-03 06:33:57.175205: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-03 06:33:57.175246: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-03 06:33:57.175252: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-03 06:33:57.175256: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-03 06:33:57.175261: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-03 06:33:57.759400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 5791:00:00.0
Total memory: 11.17GiB
Free memory: 11.11GiB
2017-12-03 06:33:57.759440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-12-03 06:33:57.759447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-12-03 06:33:57.759455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 5791:00:00.0)
INFO:tensorflow:Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO - tensorflow - Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO - root - Starting threads 0 ...

INFO - root - training for 332500 steps
INFO - root - 2017-12-03 06:34:00.695461: step 0, loss = 1.10, batch loss = 1.00 (3.6 examples/sec; 2.248 sec/batch; 207h:36m:36s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-03 06:34:03.158150: step 10, loss = 0.98, batch loss = 0.88 (44.3 examples/sec; 0.181 sec/batch; 16h:40m:45s remains)
INFO - root - 2017-12-03 06:34:04.952019: step 20, loss = 1.28, batch loss = 1.18 (45.9 examples/sec; 0.174 sec/batch; 16h:06m:31s remains)
INFO - root - 2017-12-03 06:34:06.733576: step 30, loss = 0.99, batch loss = 0.88 (45.1 examples/sec; 0.177 sec/batch; 16h:21m:58s remains)
INFO - root - 2017-12-03 06:34:08.519957: step 40, loss = 1.11, batch loss = 1.01 (44.4 examples/sec; 0.180 sec/batch; 16h:38m:06s remains)
INFO - root - 2017-12-03 06:34:10.331575: step 50, loss = 0.97, batch loss = 0.86 (43.6 examples/sec; 0.183 sec/batch; 16h:55m:41s remains)
INFO - root - 2017-12-03 06:34:12.115509: step 60, loss = 1.29, batch loss = 1.17 (44.4 examples/sec; 0.180 sec/batch; 16h:38m:21s remains)
INFO - root - 2017-12-03 06:34:13.911364: step 70, loss = 1.00, batch loss = 0.88 (43.8 examples/sec; 0.183 sec/batch; 16h:51m:27s remains)
INFO - root - 2017-12-03 06:34:15.681131: step 80, loss = 1.10, batch loss = 0.98 (44.7 examples/sec; 0.179 sec/batch; 16h:31m:33s remains)
INFO - root - 2017-12-03 06:34:17.486162: step 90, loss = 1.01, batch loss = 0.84 (44.4 examples/sec; 0.180 sec/batch; 16h:37m:37s remains)
INFO - root - 2017-12-03 06:34:19.249932: step 100, loss = 2.14, batch loss = 1.62 (43.3 examples/sec; 0.185 sec/batch; 17h:03m:03s remains)
INFO - root - 2017-12-03 06:34:21.098072: step 110, loss = 1961.66, batch loss = 1720.78 (44.7 examples/sec; 0.179 sec/batch; 16h:31m:26s remains)
INFO - root - 2017-12-03 06:34:22.821969: step 120, loss = nan, batch loss = 2.22 (46.9 examples/sec; 0.171 sec/batch; 15h:44m:44s remains)
INFO - root - 2017-12-03 06:34:24.522311: step 130, loss = nan, batch loss = 2.22 (47.1 examples/sec; 0.170 sec/batch; 15h:41m:03s remains)
INFO - root - 2017-12-03 06:34:26.220400: step 140, loss = nan, batch loss = 2.22 (47.3 examples/sec; 0.169 sec/batch; 15h:36m:18s remains)
