INFO - Siam-FC - Running command 'main'
INFO - Siam-FC - Started run with ID "131"
INFO - root - Creating training directory: /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-2-conv2-adm-0.001
INFO - root - preproces -- siamese_fc_color
WARNING - root - root is not explicitly specified, using default value: None
INFO - root - For training, we use instance size 255 - 2 * 8 ...
WARNING - root - init_method is not explicitly specified, using default value: None
sdiufhasudf Tensor("siamese_fc/conv2/split:0", shape=(8, 29, 29, 48), dtype=float32)
Tensor("siamese_fc/conv2/def/transpose:0", shape=(8, 48, 29, 29), dtype=float32) <tf.Variable 'siamese_fc/conv2/def/b1/weights:0' shape=(128, 48, 5, 5) dtype=float32_ref> Tensor("siamese_fc/conv2/def/transpose_1:0", shape=(8, 200, 29, 29), dtype=float32)
Tensor("siamese_fc/conv2/def/transpose_2:0", shape=(8, 48, 29, 29), dtype=float32) <tf.Variable 'siamese_fc/conv2/def/b2/weights:0' shape=(128, 48, 5, 5) dtype=float32_ref> Tensor("siamese_fc/conv2/def/transpose_3:0", shape=(8, 200, 29, 29), dtype=float32)
sdiufhasudf Tensor("siamese_fc_1/conv2/split:0", shape=(8, 57, 57, 48), dtype=float32)
Tensor("siamese_fc_1/conv2/def/transpose:0", shape=(8, 48, 57, 57), dtype=float32) <tf.Variable 'siamese_fc/conv2/def/b1/weights:0' shape=(128, 48, 5, 5) dtype=float32_ref> Tensor("siamese_fc_1/conv2/def/transpose_1:0", shape=(8, 200, 57, 57), dtype=float32)
Tensor("siamese_fc_1/conv2/def/transpose_2:0", shape=(8, 48, 57, 57), dtype=float32) <tf.Variable 'siamese_fc/conv2/def/b2/weights:0' shape=(128, 48, 5, 5) dtype=float32_ref> Tensor("siamese_fc_1/conv2/def/transpose_3:0", shape=(8, 200, 57, 57), dtype=float32)
INFO - root - Model moving average is disabled since decay factor is 0
2017-12-07 03:11:31.931266: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-07 03:11:31.931305: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-07 03:11:31.931312: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-07 03:11:31.931319: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-07 03:11:31.931322: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-07 03:11:32.324540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 5791:00:00.0
Total memory: 11.17GiB
Free memory: 6.38GiB
2017-12-07 03:11:32.324579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-12-07 03:11:32.324586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-12-07 03:11:32.324594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 5791:00:00.0)
INFO:tensorflow:Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO - tensorflow - Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO - root - Starting threads 0 ...

INFO - root - training for 332500 steps
Tensor("detection/add:0", shape=(8, 15, 15), dtype=float32)
[<tf.Variable 'siamese_fc/conv1/weights:0' shape=(11, 11, 3, 96) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv1/BatchNorm/gamma:0' shape=(96,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv1/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv1/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv3/weights:0' shape=(3, 3, 256, 384) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv3/BatchNorm/gamma:0' shape=(384,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv3/BatchNorm/moving_mean:0' shape=(384,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv3/BatchNorm/moving_variance:0' shape=(384,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b1/weights:0' shape=(3, 3, 192, 192) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b1/BatchNorm/gamma:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b1/BatchNorm/moving_mean:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b1/BatchNorm/moving_variance:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b2/weights:0' shape=(3, 3, 192, 192) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b2/BatchNorm/gamma:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b2/BatchNorm/moving_mean:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b2/BatchNorm/moving_variance:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv5/b1/weights:0' shape=(3, 3, 192, 128) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv5/b1/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv5/b2/weights:0' shape=(3, 3, 192, 128) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv5/b2/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'detection/biases:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'global_step:0' shape=() dtype=int32_ref>]
INFO - root - 2017-12-07 03:11:42.430653: step 0, loss = 0.67, batch loss = 0.60 (1.1 examples/sec; 7.518 sec/batch; 694h:22m:45s remains)
2017-12-07 03:11:43.482205: I tensorflow/core/kernels/logging_ops.cc:79] [[[-2.9742088 -2.9655232 -3.0734317 -3.2468534 -3.3613365 -3.4464331 -3.4937916 -3.4528494 -3.387619 -3.30472 -3.1673632 -3.0816576 -2.9738295 -2.8472874 -2.8079581][-3.0063481 -3.0173235 -3.1966467 -3.372685 -3.4144607 -3.4690518 -3.5052354 -3.4035635 -3.2882473 -3.1771531 -2.9739318 -2.8696818 -2.8169529 -2.7497954 -2.7775731][-2.9858785 -3.0713029 -3.3393459 -3.4718938 -3.3772855 -3.3485103 -3.2867193 -3.0712123 -2.9486189 -2.8721502 -2.6585088 -2.5988467 -2.654119 -2.6655173 -2.7660751][-3.0035613 -3.2537036 -3.6421881 -3.7248106 -3.4771256 -3.28826 -3.0133779 -2.6812959 -2.6468997 -2.6938815 -2.5112555 -2.4981155 -2.6179028 -2.6488547 -2.7821279][-3.1781816 -3.5784519 -4.0122995 -3.9851422 -3.5502992 -3.0979667 -2.49005 -2.0210164 -2.16371 -2.4279046 -2.3804212 -2.4976788 -2.678771 -2.6967311 -2.8296585][-3.3966632 -3.793489 -4.1138673 -3.9019625 -3.2466404 -2.4449627 -1.3793809 -0.69542718 -1.0356266 -1.6221354 -1.8876786 -2.2934651 -2.6098711 -2.6714306 -2.847245][-3.4742692 -3.7333021 -3.8608599 -3.4661169 -2.6338782 -1.5644977 -0.18654251 0.58131218 -0.039308548 -0.96757627 -1.5912127 -2.2702227 -2.6325207 -2.6769872 -2.8779454][-3.3396373 -3.4969988 -3.5046949 -3.043889 -2.2333436 -1.1812174 0.092233181 0.60216856 -0.26916695 -1.3395202 -2.1074779 -2.7929688 -2.9715436 -2.8675871 -3.0237947][-3.2509041 -3.3952971 -3.3559866 -2.9236808 -2.2730119 -1.418721 -0.53388691 -0.39259005 -1.2518382 -2.1451821 -2.791975 -3.2949581 -3.2455289 -3.0262754 -3.1635883][-3.4060638 -3.5464904 -3.4252512 -3.0033157 -2.4822898 -1.8279431 -1.3228588 -1.4134052 -2.0902503 -2.6938307 -3.139164 -3.478878 -3.3252516 -3.0861554 -3.2269642][-3.5492811 -3.6539822 -3.4555492 -3.0794683 -2.7000113 -2.2657194 -2.0975828 -2.320904 -2.7714672 -3.0946784 -3.305635 -3.4993563 -3.3114948 -3.081461 -3.2284956][-3.5041454 -3.5224874 -3.3282082 -3.1191707 -2.97575 -2.8021235 -2.8789392 -3.1227572 -3.3623526 -3.448401 -3.4380007 -3.513593 -3.3175554 -3.091289 -3.2257473][-3.4932673 -3.4280419 -3.2971678 -3.273813 -3.3167334 -3.2836037 -3.4177935 -3.5804391 -3.6497407 -3.585474 -3.4573979 -3.5013895 -3.3436174 -3.1284447 -3.2404151][-3.6540332 -3.5750728 -3.5168619 -3.5857227 -3.6778288 -3.6444957 -3.7135534 -3.7472944 -3.6727219 -3.5424836 -3.4051828 -3.4733465 -3.3764288 -3.1645436 -3.2420831][-3.9165783 -3.8309388 -3.8078556 -3.8897028 -3.959214 -3.8986762 -3.9349003 -3.9081995 -3.7587504 -3.6269257 -3.5069175 -3.5437753 -3.4476337 -3.2001116 -3.2221828]]...]
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-2-conv2-adm-0.001/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-2-conv2-adm-0.001/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-07 03:11:55.344100: step 10, loss = 0.73, batch loss = 0.65 (6.5 examples/sec; 1.222 sec/batch; 112h:53m:52s remains)
INFO - root - 2017-12-07 03:12:06.722821: step 20, loss = 0.71, batch loss = 0.63 (7.1 examples/sec; 1.130 sec/batch; 104h:20m:14s remains)
INFO - root - 2017-12-07 03:12:21.138257: step 30, loss = 0.70, batch loss = 0.62 (6.5 examples/sec; 1.224 sec/batch; 113h:00m:30s remains)
INFO - root - 2017-12-07 03:12:36.253307: step 40, loss = 0.81, batch loss = 0.74 (5.3 examples/sec; 1.505 sec/batch; 138h:59m:58s remains)
INFO - root - 2017-12-07 03:12:51.132339: step 50, loss = 0.86, batch loss = 0.78 (5.8 examples/sec; 1.374 sec/batch; 126h:55m:11s remains)
INFO - root - 2017-12-07 03:13:08.787099: step 60, loss = 0.97, batch loss = 0.89 (5.2 examples/sec; 1.548 sec/batch; 142h:58m:54s remains)
INFO - root - 2017-12-07 03:13:23.624508: step 70, loss = 0.80, batch loss = 0.73 (5.4 examples/sec; 1.471 sec/batch; 135h:51m:04s remains)
INFO - root - 2017-12-07 03:13:40.481607: step 80, loss = 0.74, batch loss = 0.66 (2.3 examples/sec; 3.465 sec/batch; 319h:58m:23s remains)
INFO - root - 2017-12-07 03:14:00.769267: step 90, loss = 0.94, batch loss = 0.86 (5.3 examples/sec; 1.518 sec/batch; 140h:11m:17s remains)
INFO - root - 2017-12-07 03:18:51.370800: step 100, loss = 0.90, batch loss = 0.82 (5.1 examples/sec; 1.560 sec/batch; 143h:59m:42s remains)
2017-12-07 03:18:52.444912: I tensorflow/core/kernels/logging_ops.cc:79] [[[-2.6205618 -2.4837589 -2.4995179 -2.634825 -2.6477833 -2.5898294 -2.6839836 -2.7290652 -2.5750496 -2.4948361 -2.5012898 -2.4569545 -2.4508057 -2.5118418 -2.5058613][-2.6709213 -2.5160475 -2.4635229 -2.5407577 -2.5461257 -2.541553 -2.6844587 -2.7044082 -2.5279517 -2.4941251 -2.5439427 -2.5154757 -2.5548973 -2.6380548 -2.6065853][-2.7447515 -2.6075623 -2.538857 -2.5971541 -2.6088114 -2.6308181 -2.7591062 -2.7286487 -2.5474317 -2.5599945 -2.623724 -2.577879 -2.6464686 -2.7606621 -2.7253971][-2.7802262 -2.6530714 -2.5708795 -2.5892649 -2.5881333 -2.625932 -2.7305443 -2.6690803 -2.5168905 -2.5833364 -2.6580958 -2.6044269 -2.7031169 -2.8615294 -2.845737][-2.775001 -2.6401696 -2.5519404 -2.5468259 -2.5413418 -2.5984111 -2.6833901 -2.5772145 -2.4319644 -2.5248413 -2.607904 -2.5647824 -2.6946411 -2.9087546 -2.9455657][-2.7874994 -2.6495576 -2.5452988 -2.5221715 -2.5283475 -2.5987029 -2.6445494 -2.4625378 -2.294533 -2.3985934 -2.5068331 -2.5020339 -2.6639352 -2.9068763 -2.9867849][-2.8000884 -2.6872475 -2.5826149 -2.5594006 -2.5811439 -2.6423235 -2.6358075 -2.3826342 -2.1750121 -2.2829237 -2.4406157 -2.5064445 -2.6824069 -2.8942437 -2.9757061][-2.7817087 -2.7047868 -2.6272287 -2.6289957 -2.661293 -2.6920135 -2.6479506 -2.3950369 -2.1532338 -2.190913 -2.3302908 -2.4416218 -2.6191642 -2.7894695 -2.8890553][-2.7725313 -2.7371645 -2.7049134 -2.7330446 -2.7566962 -2.7344995 -2.6763194 -2.4914932 -2.2624786 -2.2032971 -2.254199 -2.3370574 -2.4902062 -2.6399641 -2.7789431][-2.7983651 -2.7966077 -2.8097715 -2.8661764 -2.8794169 -2.8019452 -2.7272062 -2.6206145 -2.4272478 -2.2843552 -2.2367005 -2.2632284 -2.3686745 -2.5212035 -2.7088404][-2.8188143 -2.8283229 -2.8652115 -2.9321897 -2.9261475 -2.8019233 -2.7031069 -2.6529284 -2.5139813 -2.3517048 -2.2694879 -2.2638941 -2.3089683 -2.4275677 -2.62579][-2.7964478 -2.7763977 -2.8074193 -2.8789091 -2.8560903 -2.7040706 -2.5964725 -2.5962491 -2.5289435 -2.3963501 -2.3205945 -2.3078187 -2.2999568 -2.3542409 -2.5337491][-2.775197 -2.7094474 -2.7024155 -2.755547 -2.7374387 -2.6164594 -2.543901 -2.5996518 -2.5914812 -2.4695549 -2.3659773 -2.3101454 -2.2519734 -2.2624309 -2.4298863][-2.7930236 -2.7118063 -2.6769 -2.7016425 -2.6961007 -2.6417785 -2.6309011 -2.7174408 -2.7333264 -2.6176622 -2.4898639 -2.3974204 -2.3314717 -2.3523378 -2.5169864][-2.834321 -2.7784939 -2.7560272 -2.7821989 -2.8021536 -2.8069484 -2.83673 -2.9038255 -2.896908 -2.7851081 -2.6687341 -2.5920513 -2.5562105 -2.5872416 -2.7223172]]...]
INFO - root - 2017-12-07 03:19:07.948228: step 110, loss = 1.12, batch loss = 1.04 (3.2 examples/sec; 2.508 sec/batch; 231h:32m:40s remains)
INFO - root - 2017-12-07 03:19:23.361938: step 120, loss = 0.77, batch loss = 0.70 (5.6 examples/sec; 1.416 sec/batch; 130h:46m:18s remains)
INFO - root - 2017-12-07 03:19:40.764813: step 130, loss = 0.84, batch loss = 0.76 (5.6 examples/sec; 1.417 sec/batch; 130h:50m:09s remains)
INFO - root - 2017-12-07 03:19:56.854830: step 140, loss = 0.78, batch loss = 0.71 (5.6 examples/sec; 1.436 sec/batch; 132h:33m:10s remains)
INFO - root - 2017-12-07 03:20:13.449305: step 150, loss = 1.07, batch loss = 1.00 (5.5 examples/sec; 1.461 sec/batch; 134h:55m:04s remains)
