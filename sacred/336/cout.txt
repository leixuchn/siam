INFO - Siam-FC - Running command 'main'
INFO - Siam-FC - Started run with ID "336"
INFO - root - preproces -- siamese_fc_color
WARNING - root - root is not explicitly specified, using default value: None
/home/v-chaoqw/MYSFC-ORI/workspace/train_imdb.pickle
INFO - root - For training, we use instance size 255 - 2 * 8 ...
WARNING - root - init_method is not explicitly specified, using default value: None
INFO - root - preproces -- None
WARNING - root - root is not explicitly specified, using default value: None
INFO - root - For training, we use instance size 255 - 2 * 8 ...
WARNING - root - init_method is not explicitly specified, using default value: None
2017-12-16 14:42:20.950156: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-16 14:42:20.950195: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-16 14:42:20.950201: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-16 14:42:20.950206: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-16 14:42:20.950209: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-16 14:42:22.144458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 6bee:00:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2017-12-16 14:42:22.144495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-12-16 14:42:22.144502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-12-16 14:42:22.144514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 6bee:00:00.0)
INFO - root - Restore from last checkpoint: /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO:tensorflow:Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO - tensorflow - Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO - root - Starting threads 0 ...

INFO - root - Starting threads 0 ...

INFO - root - training for 332500 steps
inputs Tensor("train/batch:0", shape=(8, 127, 127, 3), dtype=float32, device=/device:CPU:0)
conv1 Tensor("train/siamese_fc/pool1/MaxPool:0", shape=(8, 29, 29, 96), dtype=float32)
net Tensor("train/siamese_fc/conv4/concat:0", shape=(8, 8, 8, 384), dtype=float32)
Tensor("train/siamese_fc/conv5/def/transpose:0", shape=(8, 384, 8, 8), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(256, 384, 3, 3) dtype=float32_ref> Tensor("train/siamese_fc/conv5/def/transpose_1:0", shape=(8, 18, 8, 8), dtype=float32)
inputs Tensor("train/batch:1", shape=(8, 239, 239, 3), dtype=float32, device=/device:CPU:0)
conv1 Tensor("train/siamese_fc_1/pool1/MaxPool:0", shape=(8, 57, 57, 96), dtype=float32)
net Tensor("train/siamese_fc_1/conv4/concat:0", shape=(8, 22, 22, 384), dtype=float32)
Tensor("train/siamese_fc_1/conv5/def/transpose:0", shape=(8, 384, 22, 22), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(256, 384, 3, 3) dtype=float32_ref> Tensor("train/siamese_fc_1/conv5/def/transpose_1:0", shape=(8, 18, 22, 22), dtype=float32)
/home/v-chaoqw/MYSFC-ORI/workspace/val_imdb.pickle
inputs Tensor("val/batch:0", shape=(8, 127, 127, 3), dtype=float32, device=/device:CPU:0)
conv1 Tensor("val/siamese_fc/pool1/MaxPool:0", shape=(8, 29, 29, 96), dtype=float32)
net Tensor("val/siamese_fc/conv4/concat:0", shape=(8, 8, 8, 384), dtype=float32)
Tensor("val/siamese_fc/conv5/def/transpose:0", shape=(8, 384, 8, 8), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(256, 384, 3, 3) dtype=float32_ref> Tensor("val/siamese_fc/conv5/def/transpose_1:0", shape=(8, 18, 8, 8), dtype=float32)
inputs Tensor("val/batch:1", shape=(8, 239, 239, 3), dtype=float32, device=/device:CPU:0)
conv1 Tensor("val/siamese_fc_1/pool1/MaxPool:0", shape=(8, 57, 57, 96), dtype=float32)
net Tensor("val/siamese_fc_1/conv4/concat:0", shape=(8, 22, 22, 384), dtype=float32)
Tensor("val/siamese_fc_1/conv5/def/transpose:0", shape=(8, 384, 22, 22), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(256, 384, 3, 3) dtype=float32_ref> Tensor("val/siamese_fc_1/conv5/def/transpose_1:0", shape=(8, 18, 22, 22), dtype=float32)
INFO - root - 2017-12-16 14:42:29.197870: step 0, loss = 2.28, batch loss = 2.23 (1.6 examples/sec; 4.958 sec/batch; 457h:53m:56s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 14:42:33.101386: step 10, loss = 1.75, batch loss = 1.69 (29.4 examples/sec; 0.272 sec/batch; 25h:07m:07s remains)
INFO - root - 2017-12-16 14:42:35.469764: step 20, loss = 0.49, batch loss = 0.43 (30.9 examples/sec; 0.259 sec/batch; 23h:52m:53s remains)
INFO - root - 2017-12-16 14:42:37.716153: step 30, loss = 0.87, batch loss = 0.80 (37.0 examples/sec; 0.216 sec/batch; 19h:56m:48s remains)
INFO - root - 2017-12-16 14:42:39.978796: step 40, loss = 0.93, batch loss = 0.86 (36.2 examples/sec; 0.221 sec/batch; 20h:23m:32s remains)
INFO - root - 2017-12-16 14:42:42.308452: step 50, loss = 1.26, batch loss = 1.16 (35.8 examples/sec; 0.224 sec/batch; 20h:38m:26s remains)
INFO - root - 2017-12-16 14:42:44.552528: step 60, loss = 0.90, batch loss = 0.76 (35.5 examples/sec; 0.225 sec/batch; 20h:47m:10s remains)
INFO - root - 2017-12-16 14:42:46.857493: step 70, loss = 1.01, batch loss = 0.83 (35.9 examples/sec; 0.223 sec/batch; 20h:35m:51s remains)
INFO - root - 2017-12-16 14:42:49.114689: step 80, loss = 1.14, batch loss = 0.93 (36.6 examples/sec; 0.219 sec/batch; 20h:12m:13s remains)
INFO - root - 2017-12-16 14:42:51.380882: step 90, loss = 1.10, batch loss = 0.87 (35.8 examples/sec; 0.223 sec/batch; 20h:37m:39s remains)
INFO - root - 2017-12-16 14:42:53.630556: step 100, loss = 0.93, batch loss = 0.69 (34.3 examples/sec; 0.233 sec/batch; 21h:30m:30s remains)
INFO - root - 2017-12-16 14:42:56.038976: step 110, loss = 0.91, batch loss = 0.65 (36.6 examples/sec; 0.218 sec/batch; 20h:10m:02s remains)
INFO - root - 2017-12-16 14:42:58.295786: step 120, loss = 1.03, batch loss = 0.74 (36.7 examples/sec; 0.218 sec/batch; 20h:08m:05s remains)
INFO - root - 2017-12-16 14:43:00.566216: step 130, loss = 1.04, batch loss = 0.71 (33.3 examples/sec; 0.240 sec/batch; 22h:09m:01s remains)
INFO - root - 2017-12-16 14:43:02.815853: step 140, loss = 1.09, batch loss = 0.73 (36.6 examples/sec; 0.218 sec/batch; 20h:10m:00s remains)
INFO - root - 2017-12-16 14:43:05.037615: step 150, loss = 0.99, batch loss = 0.62 (35.9 examples/sec; 0.223 sec/batch; 20h:33m:22s remains)
INFO - root - 2017-12-16 14:43:07.237655: step 160, loss = 1.14, batch loss = 0.77 (36.7 examples/sec; 0.218 sec/batch; 20h:07m:07s remains)
INFO - root - 2017-12-16 14:43:09.479331: step 170, loss = 1.12, batch loss = 0.73 (36.5 examples/sec; 0.219 sec/batch; 20h:12m:45s remains)
INFO - root - 2017-12-16 14:43:11.714963: step 180, loss = 1.16, batch loss = 0.75 (36.6 examples/sec; 0.219 sec/batch; 20h:12m:12s remains)
INFO - root - 2017-12-16 14:43:13.974546: step 190, loss = 1.09, batch loss = 0.68 (35.2 examples/sec; 0.227 sec/batch; 20h:57m:39s remains)
INFO - root - 2017-12-16 14:43:16.220389: step 200, loss = 1.15, batch loss = 0.73 (35.8 examples/sec; 0.223 sec/batch; 20h:35m:57s remains)
INFO - root - 2017-12-16 14:43:18.583995: step 210, loss = 1.09, batch loss = 0.66 (36.9 examples/sec; 0.217 sec/batch; 20h:01m:23s remains)
INFO - root - 2017-12-16 14:43:20.801436: step 220, loss = 1.15, batch loss = 0.70 (35.1 examples/sec; 0.228 sec/batch; 21h:00m:49s remains)
INFO - root - 2017-12-16 14:43:23.027777: step 230, loss = 1.23, batch loss = 0.76 (35.2 examples/sec; 0.228 sec/batch; 21h:00m:19s remains)
INFO - root - 2017-12-16 14:43:25.265792: step 240, loss = 1.12, batch loss = 0.64 (35.6 examples/sec; 0.225 sec/batch; 20h:44m:38s remains)
INFO - root - 2017-12-16 14:43:27.491977: step 250, loss = 1.15, batch loss = 0.66 (35.5 examples/sec; 0.225 sec/batch; 20h:47m:54s remains)
INFO - root - 2017-12-16 14:43:29.723989: step 260, loss = 1.18, batch loss = 0.67 (36.1 examples/sec; 0.222 sec/batch; 20h:27m:04s remains)
INFO - root - 2017-12-16 14:43:31.952673: step 270, loss = 1.12, batch loss = 0.60 (36.7 examples/sec; 0.218 sec/batch; 20h:06m:02s remains)
INFO - root - 2017-12-16 14:43:34.169001: step 280, loss = 1.14, batch loss = 0.62 (35.5 examples/sec; 0.225 sec/batch; 20h:46m:30s remains)
INFO - root - 2017-12-16 14:43:36.380341: step 290, loss = 1.10, batch loss = 0.57 (36.5 examples/sec; 0.219 sec/batch; 20h:13m:08s remains)
INFO - root - 2017-12-16 14:43:38.612085: step 300, loss = 1.15, batch loss = 0.63 (36.4 examples/sec; 0.220 sec/batch; 20h:16m:44s remains)
INFO - root - 2017-12-16 14:43:40.976274: step 310, loss = 1.13, batch loss = 0.60 (36.9 examples/sec; 0.217 sec/batch; 20h:00m:05s remains)
INFO - root - 2017-12-16 14:43:43.247178: step 320, loss = 1.06, batch loss = 0.53 (34.1 examples/sec; 0.235 sec/batch; 21h:40m:26s remains)
INFO - root - 2017-12-16 14:43:45.474142: step 330, loss = 1.09, batch loss = 0.57 (35.5 examples/sec; 0.225 sec/batch; 20h:47m:49s remains)
INFO - root - 2017-12-16 14:43:47.727233: step 340, loss = 1.02, batch loss = 0.50 (36.5 examples/sec; 0.219 sec/batch; 20h:15m:00s remains)
INFO - root - 2017-12-16 14:43:50.009075: step 350, loss = 1.03, batch loss = 0.50 (34.4 examples/sec; 0.232 sec/batch; 21h:26m:37s remains)
INFO - root - 2017-12-16 14:43:52.245892: step 360, loss = 1.01, batch loss = 0.49 (34.9 examples/sec; 0.229 sec/batch; 21h:10m:01s remains)
INFO - root - 2017-12-16 14:43:54.477133: step 370, loss = 1.02, batch loss = 0.50 (36.4 examples/sec; 0.220 sec/batch; 20h:18m:06s remains)
INFO - root - 2017-12-16 14:43:56.752703: step 380, loss = 1.08, batch loss = 0.56 (36.9 examples/sec; 0.217 sec/batch; 19h:58m:44s remains)
INFO - root - 2017-12-16 14:43:58.959587: step 390, loss = 1.00, batch loss = 0.48 (36.7 examples/sec; 0.218 sec/batch; 20h:05m:02s remains)
INFO - root - 2017-12-16 14:44:01.227762: step 400, loss = 1.17, batch loss = 0.65 (36.4 examples/sec; 0.220 sec/batch; 20h:16m:42s remains)
INFO - root - 2017-12-16 14:44:03.569103: step 410, loss = 1.08, batch loss = 0.56 (37.0 examples/sec; 0.216 sec/batch; 19h:57m:39s remains)
INFO - root - 2017-12-16 14:44:05.789919: step 420, loss = 1.06, batch loss = 0.54 (35.7 examples/sec; 0.224 sec/batch; 20h:39m:10s remains)
INFO - root - 2017-12-16 14:44:08.018091: step 430, loss = 1.28, batch loss = 0.76 (35.3 examples/sec; 0.226 sec/batch; 20h:52m:56s remains)
INFO - root - 2017-12-16 14:44:10.295355: step 440, loss = 1.13, batch loss = 0.61 (35.5 examples/sec; 0.226 sec/batch; 20h:48m:53s remains)
INFO - root - 2017-12-16 14:44:12.524408: step 450, loss = 1.08, batch loss = 0.56 (35.7 examples/sec; 0.224 sec/batch; 20h:39m:25s remains)
INFO - root - 2017-12-16 14:44:14.737622: step 460, loss = 1.07, batch loss = 0.55 (36.7 examples/sec; 0.218 sec/batch; 20h:06m:55s remains)
INFO - root - 2017-12-16 14:44:16.975117: step 470, loss = 1.15, batch loss = 0.63 (35.7 examples/sec; 0.224 sec/batch; 20h:38m:38s remains)
INFO - root - 2017-12-16 14:44:19.199684: step 480, loss = 1.12, batch loss = 0.60 (35.4 examples/sec; 0.226 sec/batch; 20h:49m:39s remains)
INFO - root - 2017-12-16 14:44:21.396601: step 490, loss = 1.17, batch loss = 0.66 (36.9 examples/sec; 0.217 sec/batch; 20h:00m:35s remains)
INFO - root - 2017-12-16 14:44:23.617729: step 500, loss = 1.20, batch loss = 0.68 (36.7 examples/sec; 0.218 sec/batch; 20h:05m:53s remains)
INFO - root - 2017-12-16 14:44:25.967335: step 510, loss = 1.19, batch loss = 0.67 (35.8 examples/sec; 0.224 sec/batch; 20h:37m:35s remains)
INFO - root - 2017-12-16 14:44:28.199895: step 520, loss = 1.30, batch loss = 0.79 (37.2 examples/sec; 0.215 sec/batch; 19h:49m:04s remains)
INFO - root - 2017-12-16 14:44:30.445641: step 530, loss = 1.12, batch loss = 0.60 (35.2 examples/sec; 0.227 sec/batch; 20h:56m:16s remains)
INFO - root - 2017-12-16 14:44:32.698552: step 540, loss = 1.23, batch loss = 0.72 (34.1 examples/sec; 0.235 sec/batch; 21h:39m:25s remains)
INFO - root - 2017-12-16 14:44:34.918059: step 550, loss = 1.14, batch loss = 0.63 (35.5 examples/sec; 0.225 sec/batch; 20h:45m:02s remains)
INFO - root - 2017-12-16 14:44:37.102384: step 560, loss = 1.18, batch loss = 0.66 (35.2 examples/sec; 0.227 sec/batch; 20h:55m:46s remains)
INFO - root - 2017-12-16 14:44:39.332765: step 570, loss = 1.14, batch loss = 0.63 (37.1 examples/sec; 0.215 sec/batch; 19h:51m:50s remains)
INFO - root - 2017-12-16 14:44:41.591745: step 580, loss = 1.33, batch loss = 0.81 (34.5 examples/sec; 0.232 sec/batch; 21h:23m:03s remains)
INFO - root - 2017-12-16 14:44:43.790443: step 590, loss = 1.16, batch loss = 0.65 (36.5 examples/sec; 0.219 sec/batch; 20h:11m:37s remains)
INFO - root - 2017-12-16 14:44:46.023235: step 600, loss = 1.43, batch loss = 0.92 (37.3 examples/sec; 0.214 sec/batch; 19h:45m:47s remains)
INFO - root - 2017-12-16 14:44:48.434023: step 610, loss = 1.25, batch loss = 0.74 (34.8 examples/sec; 0.230 sec/batch; 21h:11m:37s remains)
INFO - root - 2017-12-16 14:44:50.673022: step 620, loss = 1.07, batch loss = 0.56 (36.1 examples/sec; 0.221 sec/batch; 20h:25m:00s remains)
INFO - root - 2017-12-16 14:44:52.927890: step 630, loss = 1.11, batch loss = 0.60 (34.1 examples/sec; 0.235 sec/batch; 21h:39m:23s remains)
INFO - root - 2017-12-16 14:44:55.176954: step 640, loss = 1.03, batch loss = 0.52 (34.8 examples/sec; 0.230 sec/batch; 21h:10m:25s remains)
INFO - root - 2017-12-16 14:44:57.404560: step 650, loss = 1.11, batch loss = 0.60 (34.7 examples/sec; 0.231 sec/batch; 21h:15m:04s remains)
INFO - root - 2017-12-16 14:44:59.653681: step 660, loss = 1.10, batch loss = 0.59 (35.1 examples/sec; 0.228 sec/batch; 21h:00m:30s remains)
INFO - root - 2017-12-16 14:45:01.871669: step 670, loss = 0.98, batch loss = 0.47 (35.2 examples/sec; 0.227 sec/batch; 20h:55m:54s remains)
INFO - root - 2017-12-16 14:45:04.069178: step 680, loss = 1.05, batch loss = 0.54 (35.7 examples/sec; 0.224 sec/batch; 20h:38m:09s remains)
INFO - root - 2017-12-16 14:45:06.299127: step 690, loss = 0.97, batch loss = 0.46 (35.2 examples/sec; 0.227 sec/batch; 20h:55m:29s remains)
INFO - root - 2017-12-16 14:45:08.547809: step 700, loss = 1.04, batch loss = 0.53 (36.1 examples/sec; 0.221 sec/batch; 20h:24m:34s remains)
INFO - root - 2017-12-16 14:45:10.914710: step 710, loss = 0.97, batch loss = 0.47 (35.0 examples/sec; 0.229 sec/batch; 21h:04m:17s remains)
INFO - root - 2017-12-16 14:45:13.174066: step 720, loss = 0.98, batch loss = 0.47 (34.9 examples/sec; 0.229 sec/batch; 21h:05m:58s remains)
INFO - root - 2017-12-16 14:45:15.393531: step 730, loss = 0.99, batch loss = 0.48 (35.2 examples/sec; 0.227 sec/batch; 20h:55m:10s remains)
INFO - root - 2017-12-16 14:45:17.606919: step 740, loss = 0.95, batch loss = 0.45 (36.2 examples/sec; 0.221 sec/batch; 20h:22m:36s remains)
INFO - root - 2017-12-16 14:45:19.842400: step 750, loss = 0.98, batch loss = 0.47 (35.0 examples/sec; 0.228 sec/batch; 21h:02m:33s remains)
INFO - root - 2017-12-16 14:45:22.119761: step 760, loss = 1.02, batch loss = 0.52 (36.3 examples/sec; 0.221 sec/batch; 20h:19m:39s remains)
INFO - root - 2017-12-16 14:45:24.345181: step 770, loss = 0.98, batch loss = 0.47 (36.9 examples/sec; 0.217 sec/batch; 19h:59m:47s remains)
INFO - root - 2017-12-16 14:45:26.624523: step 780, loss = 1.02, batch loss = 0.52 (35.6 examples/sec; 0.225 sec/batch; 20h:42m:16s remains)
INFO - root - 2017-12-16 14:45:28.844202: step 790, loss = 0.94, batch loss = 0.44 (36.6 examples/sec; 0.219 sec/batch; 20h:08m:49s remains)
INFO - root - 2017-12-16 14:45:31.042365: step 800, loss = 0.95, batch loss = 0.45 (36.3 examples/sec; 0.221 sec/batch; 20h:19m:06s remains)
INFO - root - 2017-12-16 14:45:33.425819: step 810, loss = 1.02, batch loss = 0.51 (35.9 examples/sec; 0.223 sec/batch; 20h:30m:47s remains)
INFO - root - 2017-12-16 14:45:35.657065: step 820, loss = 1.08, batch loss = 0.58 (36.7 examples/sec; 0.218 sec/batch; 20h:04m:50s remains)
INFO - root - 2017-12-16 14:45:37.912438: step 830, loss = 1.05, batch loss = 0.55 (33.8 examples/sec; 0.237 sec/batch; 21h:48m:02s remains)
INFO - root - 2017-12-16 14:45:40.134496: step 840, loss = 1.01, batch loss = 0.51 (36.2 examples/sec; 0.221 sec/batch; 20h:23m:02s remains)
INFO - root - 2017-12-16 14:45:42.350223: step 850, loss = 0.95, batch loss = 0.45 (36.1 examples/sec; 0.222 sec/batch; 20h:24m:30s remains)
INFO - root - 2017-12-16 14:45:44.564838: step 860, loss = 0.92, batch loss = 0.42 (35.9 examples/sec; 0.223 sec/batch; 20h:32m:19s remains)
INFO - root - 2017-12-16 14:45:46.781135: step 870, loss = 0.99, batch loss = 0.49 (36.5 examples/sec; 0.219 sec/batch; 20h:12m:46s remains)
INFO - root - 2017-12-16 14:45:49.018372: step 880, loss = 1.02, batch loss = 0.52 (35.4 examples/sec; 0.226 sec/batch; 20h:47m:17s remains)
INFO - root - 2017-12-16 14:45:51.243138: step 890, loss = 1.01, batch loss = 0.51 (35.2 examples/sec; 0.227 sec/batch; 20h:54m:55s remains)
INFO - root - 2017-12-16 14:45:53.481153: step 900, loss = 0.90, batch loss = 0.40 (35.5 examples/sec; 0.225 sec/batch; 20h:44m:31s remains)
INFO - root - 2017-12-16 14:45:55.860152: step 910, loss = 0.95, batch loss = 0.46 (37.1 examples/sec; 0.216 sec/batch; 19h:52m:26s remains)
INFO - root - 2017-12-16 14:45:58.058157: step 920, loss = 0.93, batch loss = 0.43 (37.1 examples/sec; 0.215 sec/batch; 19h:50m:37s remains)
INFO - root - 2017-12-16 14:46:00.307757: step 930, loss = 0.97, batch loss = 0.47 (35.6 examples/sec; 0.225 sec/batch; 20h:40m:45s remains)
INFO - root - 2017-12-16 14:46:02.521509: step 940, loss = 0.97, batch loss = 0.48 (37.4 examples/sec; 0.214 sec/batch; 19h:42m:29s remains)
INFO - root - 2017-12-16 14:46:04.743317: step 950, loss = 1.02, batch loss = 0.52 (36.4 examples/sec; 0.220 sec/batch; 20h:14m:34s remains)
INFO - root - 2017-12-16 14:46:06.943022: step 960, loss = 0.97, batch loss = 0.47 (36.4 examples/sec; 0.220 sec/batch; 20h:13m:15s remains)
INFO - root - 2017-12-16 14:46:09.226062: step 970, loss = 0.93, batch loss = 0.44 (33.6 examples/sec; 0.238 sec/batch; 21h:53m:58s remains)
INFO - root - 2017-12-16 14:46:11.443958: step 980, loss = 1.00, batch loss = 0.51 (38.3 examples/sec; 0.209 sec/batch; 19h:14m:24s remains)
INFO - root - 2017-12-16 14:46:13.648202: step 990, loss = 0.97, batch loss = 0.48 (36.8 examples/sec; 0.217 sec/batch; 20h:01m:09s remains)
INFO - root - 2017-12-16 14:46:15.867838: step 1000, loss = 0.97, batch loss = 0.47 (37.8 examples/sec; 0.212 sec/batch; 19h:30m:03s remains)
INFO - root - 2017-12-16 14:46:18.233251: step 1010, loss = 1.01, batch loss = 0.52 (36.1 examples/sec; 0.222 sec/batch; 20h:25m:39s remains)
INFO - root - 2017-12-16 14:46:20.469081: step 1020, loss = 0.89, batch loss = 0.40 (36.4 examples/sec; 0.220 sec/batch; 20h:15m:45s remains)
INFO - root - 2017-12-16 14:46:22.703352: step 1030, loss = 1.03, batch loss = 0.54 (35.7 examples/sec; 0.224 sec/batch; 20h:39m:13s remains)
INFO - root - 2017-12-16 14:46:24.938715: step 1040, loss = 0.94, batch loss = 0.45 (36.2 examples/sec; 0.221 sec/batch; 20h:19m:15s remains)
INFO - root - 2017-12-16 14:46:27.196536: step 1050, loss = 0.97, batch loss = 0.48 (35.1 examples/sec; 0.228 sec/batch; 20h:57m:21s remains)
INFO - root - 2017-12-16 14:46:29.386486: step 1060, loss = 0.98, batch loss = 0.49 (36.4 examples/sec; 0.220 sec/batch; 20h:15m:28s remains)
INFO - root - 2017-12-16 14:46:31.646280: step 1070, loss = 0.97, batch loss = 0.48 (34.5 examples/sec; 0.232 sec/batch; 21h:20m:59s remains)
INFO - root - 2017-12-16 14:46:33.876588: step 1080, loss = 1.00, batch loss = 0.51 (36.4 examples/sec; 0.220 sec/batch; 20h:15m:21s remains)
INFO - root - 2017-12-16 14:46:36.098120: step 1090, loss = 0.93, batch loss = 0.45 (36.6 examples/sec; 0.218 sec/batch; 20h:06m:13s remains)
INFO - root - 2017-12-16 14:46:38.318689: step 1100, loss = 0.97, batch loss = 0.49 (34.9 examples/sec; 0.229 sec/batch; 21h:07m:06s remains)
INFO - root - 2017-12-16 14:46:40.707102: step 1110, loss = 1.02, batch loss = 0.53 (35.1 examples/sec; 0.228 sec/batch; 20h:59m:48s remains)
INFO - root - 2017-12-16 14:46:42.933254: step 1120, loss = 1.04, batch loss = 0.55 (34.5 examples/sec; 0.232 sec/batch; 21h:19m:57s remains)
INFO - root - 2017-12-16 14:46:45.148161: step 1130, loss = 0.95, batch loss = 0.46 (36.9 examples/sec; 0.217 sec/batch; 19h:57m:20s remains)
INFO - root - 2017-12-16 14:46:47.383238: step 1140, loss = 1.09, batch loss = 0.61 (35.0 examples/sec; 0.229 sec/batch; 21h:02m:11s remains)
INFO - root - 2017-12-16 14:46:49.578986: step 1150, loss = 0.93, batch loss = 0.44 (37.0 examples/sec; 0.216 sec/batch; 19h:53m:41s remains)
INFO - root - 2017-12-16 14:46:51.767961: step 1160, loss = 0.97, batch loss = 0.49 (36.2 examples/sec; 0.221 sec/batch; 20h:19m:52s remains)
INFO - root - 2017-12-16 14:46:53.969358: step 1170, loss = 0.95, batch loss = 0.47 (36.9 examples/sec; 0.217 sec/batch; 19h:55m:49s remains)
INFO - root - 2017-12-16 14:46:56.168630: step 1180, loss = 0.96, batch loss = 0.48 (36.0 examples/sec; 0.222 sec/batch; 20h:27m:52s remains)
INFO - root - 2017-12-16 14:46:58.363338: step 1190, loss = 0.91, batch loss = 0.43 (37.2 examples/sec; 0.215 sec/batch; 19h:46m:02s remains)
INFO - root - 2017-12-16 14:47:00.557055: step 1200, loss = 0.99, batch loss = 0.51 (36.4 examples/sec; 0.220 sec/batch; 20h:14m:20s remains)
INFO - root - 2017-12-16 14:47:02.919632: step 1210, loss = 1.05, batch loss = 0.57 (36.0 examples/sec; 0.222 sec/batch; 20h:27m:41s remains)
INFO - root - 2017-12-16 14:47:05.146881: step 1220, loss = 0.92, batch loss = 0.44 (37.0 examples/sec; 0.216 sec/batch; 19h:53m:57s remains)
INFO - root - 2017-12-16 14:47:07.371417: step 1230, loss = 0.98, batch loss = 0.50 (33.4 examples/sec; 0.240 sec/batch; 22h:02m:33s remains)
INFO - root - 2017-12-16 14:47:09.608855: step 1240, loss = 1.01, batch loss = 0.53 (37.3 examples/sec; 0.214 sec/batch; 19h:44m:05s remains)
INFO - root - 2017-12-16 14:47:11.828166: step 1250, loss = 0.93, batch loss = 0.45 (35.9 examples/sec; 0.223 sec/batch; 20h:29m:10s remains)
INFO - root - 2017-12-16 14:47:14.052965: step 1260, loss = 0.98, batch loss = 0.50 (34.2 examples/sec; 0.234 sec/batch; 21h:29m:48s remains)
INFO - root - 2017-12-16 14:47:16.280027: step 1270, loss = 0.95, batch loss = 0.47 (35.8 examples/sec; 0.224 sec/batch; 20h:34m:31s remains)
INFO - root - 2017-12-16 14:47:18.503356: step 1280, loss = 0.97, batch loss = 0.49 (36.1 examples/sec; 0.221 sec/batch; 20h:21m:42s remains)
INFO - root - 2017-12-16 14:47:20.710494: step 1290, loss = 0.93, batch loss = 0.45 (34.0 examples/sec; 0.235 sec/batch; 21h:37m:36s remains)
INFO - root - 2017-12-16 14:47:22.961280: step 1300, loss = 0.89, batch loss = 0.41 (34.2 examples/sec; 0.234 sec/batch; 21h:31m:05s remains)
INFO - root - 2017-12-16 14:47:25.330508: step 1310, loss = 0.97, batch loss = 0.50 (36.5 examples/sec; 0.219 sec/batch; 20h:09m:07s remains)
INFO - root - 2017-12-16 14:47:27.549931: step 1320, loss = 0.89, batch loss = 0.42 (36.7 examples/sec; 0.218 sec/batch; 20h:04m:07s remains)
INFO - root - 2017-12-16 14:47:29.804034: step 1330, loss = 0.91, batch loss = 0.43 (36.9 examples/sec; 0.217 sec/batch; 19h:55m:10s remains)
INFO - root - 2017-12-16 14:47:32.032845: step 1340, loss = 0.91, batch loss = 0.43 (36.3 examples/sec; 0.220 sec/batch; 20h:14m:59s remains)
INFO - root - 2017-12-16 14:47:34.260364: step 1350, loss = 1.02, batch loss = 0.54 (35.0 examples/sec; 0.228 sec/batch; 21h:00m:18s remains)
INFO - root - 2017-12-16 14:47:36.505350: step 1360, loss = 0.97, batch loss = 0.50 (35.9 examples/sec; 0.223 sec/batch; 20h:29m:54s remains)
INFO - root - 2017-12-16 14:47:38.719652: step 1370, loss = 0.93, batch loss = 0.46 (37.3 examples/sec; 0.215 sec/batch; 19h:44m:04s remains)
INFO - root - 2017-12-16 14:47:40.926366: step 1380, loss = 0.89, batch loss = 0.42 (34.8 examples/sec; 0.230 sec/batch; 21h:08m:00s remains)
INFO - root - 2017-12-16 14:47:43.153800: step 1390, loss = 0.99, batch loss = 0.52 (36.6 examples/sec; 0.218 sec/batch; 20h:05m:25s remains)
INFO - root - 2017-12-16 14:47:45.372710: step 1400, loss = 0.93, batch loss = 0.45 (36.6 examples/sec; 0.219 sec/batch; 20h:06m:38s remains)
INFO - root - 2017-12-16 14:47:47.867273: step 1410, loss = 0.86, batch loss = 0.39 (36.6 examples/sec; 0.218 sec/batch; 20h:05m:12s remains)
INFO - root - 2017-12-16 14:47:50.066516: step 1420, loss = 0.96, batch loss = 0.49 (37.0 examples/sec; 0.216 sec/batch; 19h:54m:02s remains)
INFO - root - 2017-12-16 14:47:52.273561: step 1430, loss = 0.96, batch loss = 0.49 (35.3 examples/sec; 0.227 sec/batch; 20h:51m:39s remains)
INFO - root - 2017-12-16 14:47:54.632526: step 1440, loss = 0.90, batch loss = 0.43 (34.0 examples/sec; 0.235 sec/batch; 21h:38m:47s remains)
INFO - root - 2017-12-16 14:47:56.817762: step 1450, loss = 0.98, batch loss = 0.51 (36.1 examples/sec; 0.222 sec/batch; 20h:23m:42s remains)
INFO - root - 2017-12-16 14:47:59.073134: step 1460, loss = 0.93, batch loss = 0.46 (36.7 examples/sec; 0.218 sec/batch; 20h:02m:50s remains)
INFO - root - 2017-12-16 14:48:01.289549: step 1470, loss = 0.99, batch loss = 0.52 (37.0 examples/sec; 0.216 sec/batch; 19h:52m:48s remains)
INFO - root - 2017-12-16 14:48:03.488542: step 1480, loss = 1.04, batch loss = 0.57 (34.9 examples/sec; 0.229 sec/batch; 21h:05m:51s remains)
INFO - root - 2017-12-16 14:48:05.724576: step 1490, loss = 0.91, batch loss = 0.44 (35.9 examples/sec; 0.223 sec/batch; 20h:30m:49s remains)
INFO - root - 2017-12-16 14:48:07.948047: step 1500, loss = 0.94, batch loss = 0.47 (36.8 examples/sec; 0.218 sec/batch; 20h:00m:34s remains)
INFO - root - 2017-12-16 14:48:10.288836: step 1510, loss = 0.88, batch loss = 0.41 (35.1 examples/sec; 0.228 sec/batch; 20h:58m:16s remains)
INFO - root - 2017-12-16 14:48:12.505759: step 1520, loss = 0.97, batch loss = 0.50 (36.5 examples/sec; 0.219 sec/batch; 20h:09m:12s remains)
INFO - root - 2017-12-16 14:48:14.712302: step 1530, loss = 0.91, batch loss = 0.45 (35.2 examples/sec; 0.227 sec/batch; 20h:54m:15s remains)
INFO - root - 2017-12-16 14:48:16.922167: step 1540, loss = 0.94, batch loss = 0.47 (37.7 examples/sec; 0.212 sec/batch; 19h:30m:41s remains)
INFO - root - 2017-12-16 14:48:19.139939: step 1550, loss = 0.85, batch loss = 0.38 (37.0 examples/sec; 0.216 sec/batch; 19h:51m:18s remains)
INFO - root - 2017-12-16 14:48:21.324865: step 1560, loss = 0.92, batch loss = 0.45 (36.8 examples/sec; 0.217 sec/batch; 19h:57m:42s remains)
INFO - root - 2017-12-16 14:48:23.546744: step 1570, loss = 0.88, batch loss = 0.42 (35.6 examples/sec; 0.225 sec/batch; 20h:38m:54s remains)
INFO - root - 2017-12-16 14:48:25.756357: step 1580, loss = 0.93, batch loss = 0.47 (35.5 examples/sec; 0.226 sec/batch; 20h:44m:30s remains)
INFO - root - 2017-12-16 14:48:27.989825: step 1590, loss = 0.96, batch loss = 0.50 (35.4 examples/sec; 0.226 sec/batch; 20h:47m:31s remains)
INFO - root - 2017-12-16 14:48:30.241539: step 1600, loss = 0.92, batch loss = 0.46 (35.5 examples/sec; 0.225 sec/batch; 20h:42m:10s remains)
INFO - root - 2017-12-16 14:48:32.636448: step 1610, loss = 0.91, batch loss = 0.45 (34.6 examples/sec; 0.232 sec/batch; 21h:16m:45s remains)
INFO - root - 2017-12-16 14:48:34.875921: step 1620, loss = 0.96, batch loss = 0.49 (36.7 examples/sec; 0.218 sec/batch; 20h:03m:20s remains)
INFO - root - 2017-12-16 14:48:37.105372: step 1630, loss = 0.91, batch loss = 0.44 (35.2 examples/sec; 0.227 sec/batch; 20h:52m:13s remains)
INFO - root - 2017-12-16 14:48:39.362989: step 1640, loss = 0.91, batch loss = 0.45 (36.0 examples/sec; 0.222 sec/batch; 20h:26m:35s remains)
INFO - root - 2017-12-16 14:48:41.611916: step 1650, loss = 0.93, batch loss = 0.47 (33.6 examples/sec; 0.238 sec/batch; 21h:53m:45s remains)
INFO - root - 2017-12-16 14:48:43.826702: step 1660, loss = 0.89, batch loss = 0.43 (35.8 examples/sec; 0.223 sec/batch; 20h:31m:36s remains)
INFO - root - 2017-12-16 14:48:46.013346: step 1670, loss = 0.93, batch loss = 0.47 (36.1 examples/sec; 0.221 sec/batch; 20h:20m:25s remains)
INFO - root - 2017-12-16 14:48:48.226188: step 1680, loss = 0.93, batch loss = 0.47 (35.9 examples/sec; 0.223 sec/batch; 20h:27m:38s remains)
INFO - root - 2017-12-16 14:48:50.472138: step 1690, loss = 0.95, batch loss = 0.49 (35.7 examples/sec; 0.224 sec/batch; 20h:37m:08s remains)
INFO - root - 2017-12-16 14:48:52.647700: step 1700, loss = 0.98, batch loss = 0.52 (37.4 examples/sec; 0.214 sec/batch; 19h:38m:26s remains)
INFO - root - 2017-12-16 14:48:54.993159: step 1710, loss = 0.92, batch loss = 0.46 (36.2 examples/sec; 0.221 sec/batch; 20h:18m:58s remains)
INFO - root - 2017-12-16 14:48:57.237665: step 1720, loss = 0.86, batch loss = 0.41 (35.9 examples/sec; 0.223 sec/batch; 20h:29m:57s remains)
INFO - root - 2017-12-16 14:48:59.416537: step 1730, loss = 0.85, batch loss = 0.40 (37.4 examples/sec; 0.214 sec/batch; 19h:39m:08s remains)
INFO - root - 2017-12-16 14:49:01.594585: step 1740, loss = 0.94, batch loss = 0.48 (36.2 examples/sec; 0.221 sec/batch; 20h:18m:47s remains)
INFO - root - 2017-12-16 14:49:03.800440: step 1750, loss = 0.93, batch loss = 0.48 (37.2 examples/sec; 0.215 sec/batch; 19h:45m:39s remains)
INFO - root - 2017-12-16 14:49:06.007850: step 1760, loss = 0.87, batch loss = 0.42 (36.3 examples/sec; 0.220 sec/batch; 20h:15m:27s remains)
INFO - root - 2017-12-16 14:49:08.228968: step 1770, loss = 0.84, batch loss = 0.39 (35.8 examples/sec; 0.223 sec/batch; 20h:30m:56s remains)
INFO - root - 2017-12-16 14:49:10.423167: step 1780, loss = 0.92, batch loss = 0.47 (34.9 examples/sec; 0.230 sec/batch; 21h:05m:08s remains)
INFO - root - 2017-12-16 14:49:12.637717: step 1790, loss = 0.92, batch loss = 0.46 (36.5 examples/sec; 0.219 sec/batch; 20h:06m:27s remains)
INFO - root - 2017-12-16 14:49:14.847294: step 1800, loss = 0.94, batch loss = 0.49 (35.5 examples/sec; 0.225 sec/batch; 20h:41m:29s remains)
INFO - root - 2017-12-16 14:49:17.184899: step 1810, loss = 0.97, batch loss = 0.51 (36.7 examples/sec; 0.218 sec/batch; 20h:00m:04s remains)
INFO - root - 2017-12-16 14:49:19.388120: step 1820, loss = 0.90, batch loss = 0.45 (36.6 examples/sec; 0.219 sec/batch; 20h:05m:10s remains)
INFO - root - 2017-12-16 14:49:21.663510: step 1830, loss = 0.82, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 19h:54m:02s remains)
INFO - root - 2017-12-16 14:49:23.870233: step 1840, loss = 0.90, batch loss = 0.45 (36.5 examples/sec; 0.219 sec/batch; 20h:08m:31s remains)
INFO - root - 2017-12-16 14:49:26.094617: step 1850, loss = 0.85, batch loss = 0.40 (35.8 examples/sec; 0.223 sec/batch; 20h:31m:28s remains)
INFO - root - 2017-12-16 14:49:28.330094: step 1860, loss = 0.94, batch loss = 0.49 (36.7 examples/sec; 0.218 sec/batch; 20h:01m:54s remains)
INFO - root - 2017-12-16 14:49:30.555730: step 1870, loss = 0.90, batch loss = 0.45 (36.2 examples/sec; 0.221 sec/batch; 20h:16m:43s remains)
INFO - root - 2017-12-16 14:49:32.772363: step 1880, loss = 0.94, batch loss = 0.49 (36.2 examples/sec; 0.221 sec/batch; 20h:17m:26s remains)
INFO - root - 2017-12-16 14:49:35.018268: step 1890, loss = 0.96, batch loss = 0.51 (34.1 examples/sec; 0.234 sec/batch; 21h:31m:04s remains)
INFO - root - 2017-12-16 14:49:37.215373: step 1900, loss = 0.94, batch loss = 0.49 (36.1 examples/sec; 0.222 sec/batch; 20h:21m:42s remains)
INFO - root - 2017-12-16 14:49:39.577164: step 1910, loss = 0.84, batch loss = 0.39 (35.9 examples/sec; 0.223 sec/batch; 20h:26m:20s remains)
INFO - root - 2017-12-16 14:49:41.772006: step 1920, loss = 0.88, batch loss = 0.43 (36.0 examples/sec; 0.222 sec/batch; 20h:25m:04s remains)
INFO - root - 2017-12-16 14:49:44.007766: step 1930, loss = 0.97, batch loss = 0.52 (36.8 examples/sec; 0.217 sec/batch; 19h:56m:31s remains)
INFO - root - 2017-12-16 14:49:46.213150: step 1940, loss = 0.89, batch loss = 0.44 (37.0 examples/sec; 0.216 sec/batch; 19h:51m:50s remains)
INFO - root - 2017-12-16 14:49:48.421664: step 1950, loss = 1.00, batch loss = 0.55 (36.6 examples/sec; 0.219 sec/batch; 20h:04m:07s remains)
INFO - root - 2017-12-16 14:49:50.638602: step 1960, loss = 1.01, batch loss = 0.57 (36.2 examples/sec; 0.221 sec/batch; 20h:18m:51s remains)
INFO - root - 2017-12-16 14:49:52.859540: step 1970, loss = 1.00, batch loss = 0.55 (35.6 examples/sec; 0.225 sec/batch; 20h:37m:44s remains)
INFO - root - 2017-12-16 14:49:55.081348: step 1980, loss = 0.91, batch loss = 0.47 (35.0 examples/sec; 0.228 sec/batch; 20h:58m:29s remains)
INFO - root - 2017-12-16 14:49:57.272827: step 1990, loss = 0.94, batch loss = 0.49 (36.5 examples/sec; 0.219 sec/batch; 20h:08m:11s remains)
INFO - root - 2017-12-16 14:49:59.454299: step 2000, loss = 0.95, batch loss = 0.50 (36.2 examples/sec; 0.221 sec/batch; 20h:17m:41s remains)
INFO - root - 2017-12-16 14:50:01.804874: step 2010, loss = 0.95, batch loss = 0.51 (35.1 examples/sec; 0.228 sec/batch; 20h:54m:49s remains)
INFO - root - 2017-12-16 14:50:04.031665: step 2020, loss = 0.90, batch loss = 0.46 (34.6 examples/sec; 0.231 sec/batch; 21h:14m:14s remains)
INFO - root - 2017-12-16 14:50:06.232121: step 2030, loss = 0.91, batch loss = 0.47 (36.4 examples/sec; 0.220 sec/batch; 20h:09m:16s remains)
INFO - root - 2017-12-16 14:50:08.463967: step 2040, loss = 0.87, batch loss = 0.43 (36.4 examples/sec; 0.220 sec/batch; 20h:11m:46s remains)
INFO - root - 2017-12-16 14:50:10.643799: step 2050, loss = 1.00, batch loss = 0.56 (37.0 examples/sec; 0.216 sec/batch; 19h:51m:58s remains)
INFO - root - 2017-12-16 14:50:12.860861: step 2060, loss = 0.94, batch loss = 0.49 (36.5 examples/sec; 0.219 sec/batch; 20h:08m:24s remains)
INFO - root - 2017-12-16 14:50:15.044701: step 2070, loss = 0.96, batch loss = 0.51 (36.1 examples/sec; 0.221 sec/batch; 20h:19m:27s remains)
INFO - root - 2017-12-16 14:50:17.247861: step 2080, loss = 0.96, batch loss = 0.52 (34.0 examples/sec; 0.235 sec/batch; 21h:33m:55s remains)
INFO - root - 2017-12-16 14:50:19.465093: step 2090, loss = 0.91, batch loss = 0.47 (37.3 examples/sec; 0.215 sec/batch; 19h:42m:14s remains)
INFO - root - 2017-12-16 14:50:21.674819: step 2100, loss = 0.95, batch loss = 0.51 (33.9 examples/sec; 0.236 sec/batch; 21h:38m:42s remains)
INFO - root - 2017-12-16 14:50:24.000023: step 2110, loss = 0.94, batch loss = 0.50 (36.4 examples/sec; 0.220 sec/batch; 20h:11m:32s remains)
INFO - root - 2017-12-16 14:50:26.189416: step 2120, loss = 0.98, batch loss = 0.54 (36.6 examples/sec; 0.219 sec/batch; 20h:03m:26s remains)
INFO - root - 2017-12-16 14:50:28.411627: step 2130, loss = 0.90, batch loss = 0.46 (36.3 examples/sec; 0.220 sec/batch; 20h:12m:16s remains)
INFO - root - 2017-12-16 14:50:30.649141: step 2140, loss = 0.94, batch loss = 0.50 (37.6 examples/sec; 0.213 sec/batch; 19h:30m:14s remains)
INFO - root - 2017-12-16 14:50:32.847941: step 2150, loss = 0.90, batch loss = 0.47 (35.9 examples/sec; 0.223 sec/batch; 20h:26m:20s remains)
INFO - root - 2017-12-16 14:50:35.035357: step 2160, loss = 0.90, batch loss = 0.46 (37.4 examples/sec; 0.214 sec/batch; 19h:36m:22s remains)
INFO - root - 2017-12-16 14:50:37.238552: step 2170, loss = 0.93, batch loss = 0.49 (37.1 examples/sec; 0.216 sec/batch; 19h:48m:40s remains)
INFO - root - 2017-12-16 14:50:39.425099: step 2180, loss = 0.92, batch loss = 0.48 (37.4 examples/sec; 0.214 sec/batch; 19h:37m:18s remains)
INFO - root - 2017-12-16 14:50:41.621986: step 2190, loss = 0.99, batch loss = 0.56 (36.7 examples/sec; 0.218 sec/batch; 19h:58m:29s remains)
INFO - root - 2017-12-16 14:50:43.842572: step 2200, loss = 0.95, batch loss = 0.52 (36.4 examples/sec; 0.220 sec/batch; 20h:08m:21s remains)
INFO - root - 2017-12-16 14:50:46.209176: step 2210, loss = 0.87, batch loss = 0.43 (35.5 examples/sec; 0.226 sec/batch; 20h:42m:10s remains)
INFO - root - 2017-12-16 14:50:48.435585: step 2220, loss = 0.91, batch loss = 0.48 (35.6 examples/sec; 0.225 sec/batch; 20h:37m:35s remains)
INFO - root - 2017-12-16 14:50:50.668734: step 2230, loss = 0.93, batch loss = 0.50 (34.9 examples/sec; 0.229 sec/batch; 21h:02m:59s remains)
INFO - root - 2017-12-16 14:50:52.873491: step 2240, loss = 0.99, batch loss = 0.56 (36.5 examples/sec; 0.219 sec/batch; 20h:05m:14s remains)
INFO - root - 2017-12-16 14:50:55.062678: step 2250, loss = 0.93, batch loss = 0.50 (36.3 examples/sec; 0.220 sec/batch; 20h:11m:46s remains)
INFO - root - 2017-12-16 14:50:57.258307: step 2260, loss = 0.94, batch loss = 0.51 (37.2 examples/sec; 0.215 sec/batch; 19h:42m:28s remains)
INFO - root - 2017-12-16 14:50:59.458210: step 2270, loss = 0.92, batch loss = 0.49 (35.8 examples/sec; 0.223 sec/batch; 20h:29m:09s remains)
INFO - root - 2017-12-16 14:51:01.650198: step 2280, loss = 0.87, batch loss = 0.44 (36.9 examples/sec; 0.217 sec/batch; 19h:53m:52s remains)
INFO - root - 2017-12-16 14:51:03.853699: step 2290, loss = 0.91, batch loss = 0.48 (35.5 examples/sec; 0.225 sec/batch; 20h:38m:35s remains)
INFO - root - 2017-12-16 14:51:06.049143: step 2300, loss = 0.99, batch loss = 0.56 (36.5 examples/sec; 0.219 sec/batch; 20h:04m:50s remains)
INFO - root - 2017-12-16 14:51:08.392635: step 2310, loss = 0.90, batch loss = 0.47 (36.6 examples/sec; 0.219 sec/batch; 20h:03m:26s remains)
INFO - root - 2017-12-16 14:51:10.601823: step 2320, loss = 0.91, batch loss = 0.48 (35.9 examples/sec; 0.223 sec/batch; 20h:25m:37s remains)
INFO - root - 2017-12-16 14:51:12.771391: step 2330, loss = 0.89, batch loss = 0.46 (37.3 examples/sec; 0.215 sec/batch; 19h:40m:48s remains)
INFO - root - 2017-12-16 14:51:15.033970: step 2340, loss = 0.97, batch loss = 0.54 (36.3 examples/sec; 0.221 sec/batch; 20h:14m:04s remains)
INFO - root - 2017-12-16 14:51:17.253731: step 2350, loss = 0.93, batch loss = 0.50 (35.8 examples/sec; 0.224 sec/batch; 20h:31m:04s remains)
INFO - root - 2017-12-16 14:51:19.466972: step 2360, loss = 0.91, batch loss = 0.49 (37.6 examples/sec; 0.213 sec/batch; 19h:29m:44s remains)
INFO - root - 2017-12-16 14:51:21.655154: step 2370, loss = 0.93, batch loss = 0.50 (37.0 examples/sec; 0.216 sec/batch; 19h:50m:46s remains)
INFO - root - 2017-12-16 14:51:23.941213: step 2380, loss = 1.00, batch loss = 0.57 (34.8 examples/sec; 0.230 sec/batch; 21h:05m:26s remains)
INFO - root - 2017-12-16 14:51:26.162226: step 2390, loss = 0.93, batch loss = 0.50 (34.9 examples/sec; 0.229 sec/batch; 21h:00m:39s remains)
INFO - root - 2017-12-16 14:51:28.373892: step 2400, loss = 0.94, batch loss = 0.51 (36.9 examples/sec; 0.217 sec/batch; 19h:51m:33s remains)
INFO - root - 2017-12-16 14:51:30.703703: step 2410, loss = 0.90, batch loss = 0.47 (36.5 examples/sec; 0.219 sec/batch; 20h:04m:49s remains)
INFO - root - 2017-12-16 14:51:32.881709: step 2420, loss = 0.93, batch loss = 0.51 (37.2 examples/sec; 0.215 sec/batch; 19h:44m:13s remains)
INFO - root - 2017-12-16 14:51:35.077485: step 2430, loss = 0.97, batch loss = 0.55 (36.8 examples/sec; 0.217 sec/batch; 19h:54m:28s remains)
INFO - root - 2017-12-16 14:51:37.278240: step 2440, loss = 1.00, batch loss = 0.57 (36.0 examples/sec; 0.222 sec/batch; 20h:23m:12s remains)
INFO - root - 2017-12-16 14:51:39.528639: step 2450, loss = 0.97, batch loss = 0.54 (36.6 examples/sec; 0.219 sec/batch; 20h:03m:39s remains)
INFO - root - 2017-12-16 14:51:41.728164: step 2460, loss = 0.87, batch loss = 0.45 (35.6 examples/sec; 0.225 sec/batch; 20h:36m:23s remains)
INFO - root - 2017-12-16 14:51:43.944634: step 2470, loss = 0.93, batch loss = 0.50 (37.1 examples/sec; 0.216 sec/batch; 19h:46m:01s remains)
INFO - root - 2017-12-16 14:51:46.170883: step 2480, loss = 0.95, batch loss = 0.52 (36.4 examples/sec; 0.220 sec/batch; 20h:07m:50s remains)
INFO - root - 2017-12-16 14:51:48.342231: step 2490, loss = 0.96, batch loss = 0.54 (36.7 examples/sec; 0.218 sec/batch; 19h:59m:17s remains)
INFO - root - 2017-12-16 14:51:50.539786: step 2500, loss = 0.90, batch loss = 0.48 (36.1 examples/sec; 0.222 sec/batch; 20h:19m:48s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-2500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-2500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 14:51:53.414355: step 2510, loss = 0.94, batch loss = 0.52 (35.7 examples/sec; 0.224 sec/batch; 20h:31m:05s remains)
INFO - root - 2017-12-16 14:51:55.604069: step 2520, loss = 0.88, batch loss = 0.46 (37.7 examples/sec; 0.212 sec/batch; 19h:25m:38s remains)
INFO - root - 2017-12-16 14:51:57.803410: step 2530, loss = 0.91, batch loss = 0.49 (35.0 examples/sec; 0.228 sec/batch; 20h:56m:08s remains)
INFO - root - 2017-12-16 14:52:00.011095: step 2540, loss = 0.93, batch loss = 0.51 (35.3 examples/sec; 0.226 sec/batch; 20h:45m:10s remains)
INFO - root - 2017-12-16 14:52:02.237150: step 2550, loss = 0.97, batch loss = 0.55 (35.4 examples/sec; 0.226 sec/batch; 20h:41m:04s remains)
INFO - root - 2017-12-16 14:52:04.483269: step 2560, loss = 0.95, batch loss = 0.53 (36.4 examples/sec; 0.220 sec/batch; 20h:07m:24s remains)
INFO - root - 2017-12-16 14:52:06.661422: step 2570, loss = 0.86, batch loss = 0.44 (37.9 examples/sec; 0.211 sec/batch; 19h:20m:18s remains)
INFO - root - 2017-12-16 14:52:08.883229: step 2580, loss = 0.86, batch loss = 0.44 (35.9 examples/sec; 0.223 sec/batch; 20h:24m:19s remains)
INFO - root - 2017-12-16 14:52:11.103245: step 2590, loss = 0.90, batch loss = 0.49 (36.6 examples/sec; 0.218 sec/batch; 20h:00m:57s remains)
INFO - root - 2017-12-16 14:52:13.304410: step 2600, loss = 0.87, batch loss = 0.45 (36.5 examples/sec; 0.219 sec/batch; 20h:05m:21s remains)
INFO - root - 2017-12-16 14:52:15.616019: step 2610, loss = 0.93, batch loss = 0.51 (37.3 examples/sec; 0.214 sec/batch; 19h:39m:20s remains)
INFO - root - 2017-12-16 14:52:17.816875: step 2620, loss = 0.94, batch loss = 0.52 (38.0 examples/sec; 0.211 sec/batch; 19h:17m:34s remains)
INFO - root - 2017-12-16 14:52:20.030329: step 2630, loss = 0.96, batch loss = 0.54 (37.4 examples/sec; 0.214 sec/batch; 19h:36m:59s remains)
INFO - root - 2017-12-16 14:52:22.246604: step 2640, loss = 0.82, batch loss = 0.41 (36.3 examples/sec; 0.221 sec/batch; 20h:12m:16s remains)
INFO - root - 2017-12-16 14:52:24.465232: step 2650, loss = 0.89, batch loss = 0.47 (37.0 examples/sec; 0.216 sec/batch; 19h:47m:35s remains)
INFO - root - 2017-12-16 14:52:26.704118: step 2660, loss = 0.95, batch loss = 0.54 (35.4 examples/sec; 0.226 sec/batch; 20h:41m:10s remains)
INFO - root - 2017-12-16 14:52:28.913195: step 2670, loss = 0.91, batch loss = 0.50 (37.1 examples/sec; 0.216 sec/batch; 19h:46m:01s remains)
INFO - root - 2017-12-16 14:52:31.108707: step 2680, loss = 0.87, batch loss = 0.46 (36.4 examples/sec; 0.220 sec/batch; 20h:07m:26s remains)
INFO - root - 2017-12-16 14:52:33.294909: step 2690, loss = 0.91, batch loss = 0.50 (36.5 examples/sec; 0.219 sec/batch; 20h:05m:08s remains)
INFO - root - 2017-12-16 14:52:35.472735: step 2700, loss = 0.84, batch loss = 0.43 (37.3 examples/sec; 0.214 sec/batch; 19h:38m:40s remains)
INFO - root - 2017-12-16 14:52:37.864569: step 2710, loss = 1.00, batch loss = 0.59 (35.0 examples/sec; 0.229 sec/batch; 20h:56m:13s remains)
INFO - root - 2017-12-16 14:52:40.058061: step 2720, loss = 0.91, batch loss = 0.50 (35.9 examples/sec; 0.223 sec/batch; 20h:23m:37s remains)
INFO - root - 2017-12-16 14:52:42.251889: step 2730, loss = 0.91, batch loss = 0.50 (37.5 examples/sec; 0.213 sec/batch; 19h:32m:10s remains)
INFO - root - 2017-12-16 14:52:44.421345: step 2740, loss = 0.84, batch loss = 0.43 (36.4 examples/sec; 0.220 sec/batch; 20h:07m:42s remains)
INFO - root - 2017-12-16 14:52:46.606483: step 2750, loss = 0.88, batch loss = 0.47 (38.1 examples/sec; 0.210 sec/batch; 19h:15m:13s remains)
INFO - root - 2017-12-16 14:52:48.838558: step 2760, loss = 0.87, batch loss = 0.46 (35.6 examples/sec; 0.225 sec/batch; 20h:36m:22s remains)
INFO - root - 2017-12-16 14:52:51.057916: step 2770, loss = 0.82, batch loss = 0.41 (37.0 examples/sec; 0.216 sec/batch; 19h:47m:33s remains)
INFO - root - 2017-12-16 14:52:53.299427: step 2780, loss = 0.87, batch loss = 0.45 (34.7 examples/sec; 0.230 sec/batch; 21h:06m:34s remains)
INFO - root - 2017-12-16 14:52:55.529158: step 2790, loss = 0.84, batch loss = 0.43 (36.2 examples/sec; 0.221 sec/batch; 20h:12m:47s remains)
INFO - root - 2017-12-16 14:52:57.779744: step 2800, loss = 0.91, batch loss = 0.50 (37.2 examples/sec; 0.215 sec/batch; 19h:42m:27s remains)
INFO - root - 2017-12-16 14:53:00.134534: step 2810, loss = 0.90, batch loss = 0.49 (32.3 examples/sec; 0.247 sec/batch; 22h:39m:27s remains)
INFO - root - 2017-12-16 14:53:02.348903: step 2820, loss = 0.84, batch loss = 0.43 (35.5 examples/sec; 0.225 sec/batch; 20h:37m:06s remains)
INFO - root - 2017-12-16 14:53:04.566529: step 2830, loss = 0.93, batch loss = 0.52 (34.8 examples/sec; 0.230 sec/batch; 21h:01m:39s remains)
INFO - root - 2017-12-16 14:53:06.725396: step 2840, loss = 0.88, batch loss = 0.48 (37.6 examples/sec; 0.213 sec/batch; 19h:29m:34s remains)
INFO - root - 2017-12-16 14:53:08.977597: step 2850, loss = 0.95, batch loss = 0.54 (35.6 examples/sec; 0.225 sec/batch; 20h:35m:37s remains)
INFO - root - 2017-12-16 14:53:11.221801: step 2860, loss = 0.93, batch loss = 0.52 (35.5 examples/sec; 0.226 sec/batch; 20h:39m:18s remains)
INFO - root - 2017-12-16 14:53:13.405543: step 2870, loss = 1.00, batch loss = 0.60 (37.7 examples/sec; 0.212 sec/batch; 19h:24m:39s remains)
INFO - root - 2017-12-16 14:53:15.612882: step 2880, loss = 0.90, batch loss = 0.50 (36.1 examples/sec; 0.222 sec/batch; 20h:18m:51s remains)
INFO - root - 2017-12-16 14:53:17.835151: step 2890, loss = 0.91, batch loss = 0.50 (36.4 examples/sec; 0.220 sec/batch; 20h:06m:49s remains)
INFO - root - 2017-12-16 14:53:20.048401: step 2900, loss = 0.84, batch loss = 0.43 (35.7 examples/sec; 0.224 sec/batch; 20h:29m:52s remains)
INFO - root - 2017-12-16 14:53:22.425798: step 2910, loss = 0.95, batch loss = 0.54 (35.7 examples/sec; 0.224 sec/batch; 20h:32m:14s remains)
INFO - root - 2017-12-16 14:53:24.659976: step 2920, loss = 0.91, batch loss = 0.50 (35.8 examples/sec; 0.223 sec/batch; 20h:27m:24s remains)
INFO - root - 2017-12-16 14:53:26.868623: step 2930, loss = 0.89, batch loss = 0.48 (36.2 examples/sec; 0.221 sec/batch; 20h:12m:33s remains)
INFO - root - 2017-12-16 14:53:29.097644: step 2940, loss = 0.89, batch loss = 0.49 (37.7 examples/sec; 0.212 sec/batch; 19h:25m:52s remains)
INFO - root - 2017-12-16 14:53:31.318392: step 2950, loss = 0.89, batch loss = 0.49 (34.6 examples/sec; 0.231 sec/batch; 21h:09m:18s remains)
INFO - root - 2017-12-16 14:53:33.526290: step 2960, loss = 0.87, batch loss = 0.47 (36.5 examples/sec; 0.219 sec/batch; 20h:04m:35s remains)
INFO - root - 2017-12-16 14:53:35.754409: step 2970, loss = 0.86, batch loss = 0.45 (36.8 examples/sec; 0.217 sec/batch; 19h:53m:31s remains)
INFO - root - 2017-12-16 14:53:37.966670: step 2980, loss = 0.89, batch loss = 0.49 (35.7 examples/sec; 0.224 sec/batch; 20h:30m:46s remains)
INFO - root - 2017-12-16 14:53:40.201238: step 2990, loss = 0.84, batch loss = 0.44 (35.9 examples/sec; 0.223 sec/batch; 20h:23m:07s remains)
INFO - root - 2017-12-16 14:53:42.394004: step 3000, loss = 0.95, batch loss = 0.55 (35.9 examples/sec; 0.223 sec/batch; 20h:22m:10s remains)
INFO - root - 2017-12-16 14:53:44.732192: step 3010, loss = 0.85, batch loss = 0.45 (37.3 examples/sec; 0.214 sec/batch; 19h:37m:33s remains)
INFO - root - 2017-12-16 14:53:46.953158: step 3020, loss = 0.87, batch loss = 0.47 (36.2 examples/sec; 0.221 sec/batch; 20h:13m:04s remains)
INFO - root - 2017-12-16 14:53:49.166027: step 3030, loss = 0.84, batch loss = 0.44 (35.9 examples/sec; 0.223 sec/batch; 20h:22m:11s remains)
INFO - root - 2017-12-16 14:53:51.380754: step 3040, loss = 0.87, batch loss = 0.47 (35.5 examples/sec; 0.226 sec/batch; 20h:38m:33s remains)
INFO - root - 2017-12-16 14:53:53.629792: step 3050, loss = 0.83, batch loss = 0.43 (35.0 examples/sec; 0.229 sec/batch; 20h:55m:33s remains)
INFO - root - 2017-12-16 14:53:55.835427: step 3060, loss = 0.91, batch loss = 0.51 (38.0 examples/sec; 0.211 sec/batch; 19h:17m:05s remains)
INFO - root - 2017-12-16 14:53:58.026657: step 3070, loss = 0.86, batch loss = 0.46 (36.9 examples/sec; 0.217 sec/batch; 19h:49m:50s remains)
INFO - root - 2017-12-16 14:54:00.226003: step 3080, loss = 0.94, batch loss = 0.54 (36.9 examples/sec; 0.217 sec/batch; 19h:51m:49s remains)
INFO - root - 2017-12-16 14:54:02.410633: step 3090, loss = 0.90, batch loss = 0.50 (38.0 examples/sec; 0.211 sec/batch; 19h:16m:01s remains)
INFO - root - 2017-12-16 14:54:04.631617: step 3100, loss = 0.88, batch loss = 0.48 (37.4 examples/sec; 0.214 sec/batch; 19h:34m:00s remains)
INFO - root - 2017-12-16 14:54:07.027168: step 3110, loss = 0.85, batch loss = 0.45 (36.2 examples/sec; 0.221 sec/batch; 20h:13m:03s remains)
INFO - root - 2017-12-16 14:54:09.217843: step 3120, loss = 0.87, batch loss = 0.47 (37.0 examples/sec; 0.216 sec/batch; 19h:45m:21s remains)
INFO - root - 2017-12-16 14:54:11.433318: step 3130, loss = 0.87, batch loss = 0.47 (36.0 examples/sec; 0.222 sec/batch; 20h:19m:08s remains)
INFO - root - 2017-12-16 14:54:13.667901: step 3140, loss = 0.91, batch loss = 0.51 (36.5 examples/sec; 0.219 sec/batch; 20h:02m:34s remains)
INFO - root - 2017-12-16 14:54:15.862117: step 3150, loss = 0.85, batch loss = 0.45 (36.8 examples/sec; 0.217 sec/batch; 19h:51m:41s remains)
INFO - root - 2017-12-16 14:54:18.061822: step 3160, loss = 0.93, batch loss = 0.53 (35.1 examples/sec; 0.228 sec/batch; 20h:50m:22s remains)
INFO - root - 2017-12-16 14:54:20.271006: step 3170, loss = 0.94, batch loss = 0.54 (35.1 examples/sec; 0.228 sec/batch; 20h:51m:20s remains)
INFO - root - 2017-12-16 14:54:22.490283: step 3180, loss = 0.90, batch loss = 0.51 (34.8 examples/sec; 0.230 sec/batch; 21h:00m:22s remains)
INFO - root - 2017-12-16 14:54:24.674486: step 3190, loss = 0.77, batch loss = 0.38 (36.9 examples/sec; 0.217 sec/batch; 19h:50m:58s remains)
INFO - root - 2017-12-16 14:54:26.860870: step 3200, loss = 0.87, batch loss = 0.48 (34.8 examples/sec; 0.230 sec/batch; 21h:01m:07s remains)
INFO - root - 2017-12-16 14:54:29.188519: step 3210, loss = 0.89, batch loss = 0.50 (35.8 examples/sec; 0.223 sec/batch; 20h:26m:13s remains)
INFO - root - 2017-12-16 14:54:31.412407: step 3220, loss = 0.87, batch loss = 0.48 (34.9 examples/sec; 0.229 sec/batch; 20h:57m:39s remains)
INFO - root - 2017-12-16 14:54:33.615235: step 3230, loss = 0.95, batch loss = 0.56 (35.3 examples/sec; 0.226 sec/batch; 20h:42m:04s remains)
INFO - root - 2017-12-16 14:54:35.830493: step 3240, loss = 0.83, batch loss = 0.43 (35.6 examples/sec; 0.225 sec/batch; 20h:33m:08s remains)
INFO - root - 2017-12-16 14:54:38.036369: step 3250, loss = 0.94, batch loss = 0.54 (37.6 examples/sec; 0.213 sec/batch; 19h:27m:41s remains)
INFO - root - 2017-12-16 14:54:40.277789: step 3260, loss = 1.00, batch loss = 0.61 (35.5 examples/sec; 0.225 sec/batch; 20h:36m:18s remains)
INFO - root - 2017-12-16 14:54:42.445807: step 3270, loss = 0.87, batch loss = 0.48 (36.2 examples/sec; 0.221 sec/batch; 20h:12m:45s remains)
INFO - root - 2017-12-16 14:54:44.637660: step 3280, loss = 0.93, batch loss = 0.54 (36.9 examples/sec; 0.217 sec/batch; 19h:48m:19s remains)
INFO - root - 2017-12-16 14:54:46.870216: step 3290, loss = 0.93, batch loss = 0.54 (35.4 examples/sec; 0.226 sec/batch; 20h:41m:26s remains)
INFO - root - 2017-12-16 14:54:49.062316: step 3300, loss = 0.90, batch loss = 0.51 (37.0 examples/sec; 0.216 sec/batch; 19h:45m:17s remains)
INFO - root - 2017-12-16 14:54:51.385182: step 3310, loss = 0.84, batch loss = 0.45 (36.4 examples/sec; 0.220 sec/batch; 20h:07m:07s remains)
INFO - root - 2017-12-16 14:54:53.665596: step 3320, loss = 0.94, batch loss = 0.55 (35.5 examples/sec; 0.225 sec/batch; 20h:35m:57s remains)
INFO - root - 2017-12-16 14:54:55.904829: step 3330, loss = 0.82, batch loss = 0.43 (34.6 examples/sec; 0.231 sec/batch; 21h:08m:43s remains)
INFO - root - 2017-12-16 14:54:58.145824: step 3340, loss = 0.91, batch loss = 0.52 (36.7 examples/sec; 0.218 sec/batch; 19h:56m:20s remains)
INFO - root - 2017-12-16 14:55:00.349590: step 3350, loss = 0.92, batch loss = 0.53 (35.8 examples/sec; 0.224 sec/batch; 20h:26m:28s remains)
INFO - root - 2017-12-16 14:55:02.546857: step 3360, loss = 0.89, batch loss = 0.50 (36.5 examples/sec; 0.219 sec/batch; 20h:02m:20s remains)
INFO - root - 2017-12-16 14:55:04.768045: step 3370, loss = 0.87, batch loss = 0.48 (36.8 examples/sec; 0.218 sec/batch; 19h:54m:02s remains)
INFO - root - 2017-12-16 14:55:06.963542: step 3380, loss = 0.82, batch loss = 0.44 (34.3 examples/sec; 0.233 sec/batch; 21h:18m:17s remains)
INFO - root - 2017-12-16 14:55:09.220911: step 3390, loss = 0.79, batch loss = 0.40 (37.0 examples/sec; 0.216 sec/batch; 19h:44m:54s remains)
INFO - root - 2017-12-16 14:55:11.458557: step 3400, loss = 0.89, batch loss = 0.50 (36.1 examples/sec; 0.222 sec/batch; 20h:16m:47s remains)
INFO - root - 2017-12-16 14:55:13.844181: step 3410, loss = 0.81, batch loss = 0.42 (33.8 examples/sec; 0.237 sec/batch; 21h:39m:20s remains)
INFO - root - 2017-12-16 14:55:16.099973: step 3420, loss = 0.84, batch loss = 0.46 (34.4 examples/sec; 0.233 sec/batch; 21h:16m:04s remains)
INFO - root - 2017-12-16 14:55:18.320794: step 3430, loss = 0.90, batch loss = 0.51 (36.9 examples/sec; 0.217 sec/batch; 19h:50m:25s remains)
INFO - root - 2017-12-16 14:55:20.532329: step 3440, loss = 0.84, batch loss = 0.46 (36.7 examples/sec; 0.218 sec/batch; 19h:56m:36s remains)
INFO - root - 2017-12-16 14:55:22.771561: step 3450, loss = 0.95, batch loss = 0.56 (35.8 examples/sec; 0.224 sec/batch; 20h:26m:24s remains)
INFO - root - 2017-12-16 14:55:25.016912: step 3460, loss = 0.89, batch loss = 0.50 (36.0 examples/sec; 0.222 sec/batch; 20h:17m:55s remains)
INFO - root - 2017-12-16 14:55:27.274814: step 3470, loss = 0.90, batch loss = 0.52 (37.1 examples/sec; 0.216 sec/batch; 19h:41m:47s remains)
INFO - root - 2017-12-16 14:55:29.499910: step 3480, loss = 0.91, batch loss = 0.52 (35.7 examples/sec; 0.224 sec/batch; 20h:27m:20s remains)
INFO - root - 2017-12-16 14:55:31.702699: step 3490, loss = 0.94, batch loss = 0.56 (37.2 examples/sec; 0.215 sec/batch; 19h:38m:32s remains)
INFO - root - 2017-12-16 14:55:33.939268: step 3500, loss = 0.94, batch loss = 0.55 (35.4 examples/sec; 0.226 sec/batch; 20h:40m:03s remains)
INFO - root - 2017-12-16 14:55:36.271426: step 3510, loss = 0.91, batch loss = 0.53 (37.8 examples/sec; 0.212 sec/batch; 19h:21m:53s remains)
INFO - root - 2017-12-16 14:55:38.515707: step 3520, loss = 0.84, batch loss = 0.46 (34.8 examples/sec; 0.230 sec/batch; 21h:02m:10s remains)
INFO - root - 2017-12-16 14:55:40.753008: step 3530, loss = 0.93, batch loss = 0.54 (36.2 examples/sec; 0.221 sec/batch; 20h:11m:54s remains)
INFO - root - 2017-12-16 14:55:42.987096: step 3540, loss = 0.86, batch loss = 0.48 (34.5 examples/sec; 0.232 sec/batch; 21h:10m:58s remains)
INFO - root - 2017-12-16 14:55:45.200137: step 3550, loss = 0.85, batch loss = 0.47 (35.5 examples/sec; 0.225 sec/batch; 20h:35m:08s remains)
INFO - root - 2017-12-16 14:55:47.388721: step 3560, loss = 0.89, batch loss = 0.51 (35.5 examples/sec; 0.225 sec/batch; 20h:35m:31s remains)
INFO - root - 2017-12-16 14:55:49.599364: step 3570, loss = 0.88, batch loss = 0.50 (37.5 examples/sec; 0.214 sec/batch; 19h:30m:35s remains)
INFO - root - 2017-12-16 14:55:51.784351: step 3580, loss = 0.87, batch loss = 0.49 (36.5 examples/sec; 0.219 sec/batch; 20h:02m:42s remains)
INFO - root - 2017-12-16 14:55:54.021234: step 3590, loss = 0.91, batch loss = 0.53 (36.6 examples/sec; 0.219 sec/batch; 19h:58m:33s remains)
INFO - root - 2017-12-16 14:55:56.214208: step 3600, loss = 0.97, batch loss = 0.59 (36.6 examples/sec; 0.218 sec/batch; 19h:57m:12s remains)
INFO - root - 2017-12-16 14:55:58.552921: step 3610, loss = 0.98, batch loss = 0.60 (34.5 examples/sec; 0.232 sec/batch; 21h:10m:17s remains)
INFO - root - 2017-12-16 14:56:00.778737: step 3620, loss = 0.88, batch loss = 0.50 (35.2 examples/sec; 0.227 sec/batch; 20h:44m:30s remains)
INFO - root - 2017-12-16 14:56:03.050191: step 3630, loss = 0.94, batch loss = 0.56 (35.5 examples/sec; 0.226 sec/batch; 20h:36m:14s remains)
INFO - root - 2017-12-16 14:56:05.232896: step 3640, loss = 0.87, batch loss = 0.49 (37.8 examples/sec; 0.212 sec/batch; 19h:19m:58s remains)
INFO - root - 2017-12-16 14:56:07.450861: step 3650, loss = 0.93, batch loss = 0.56 (34.9 examples/sec; 0.229 sec/batch; 20h:56m:18s remains)
INFO - root - 2017-12-16 14:56:09.637280: step 3660, loss = 0.96, batch loss = 0.58 (36.4 examples/sec; 0.220 sec/batch; 20h:03m:43s remains)
INFO - root - 2017-12-16 14:56:11.849064: step 3670, loss = 0.92, batch loss = 0.54 (37.1 examples/sec; 0.215 sec/batch; 19h:40m:29s remains)
INFO - root - 2017-12-16 14:56:14.057822: step 3680, loss = 0.90, batch loss = 0.52 (37.3 examples/sec; 0.214 sec/batch; 19h:34m:10s remains)
INFO - root - 2017-12-16 14:56:16.291453: step 3690, loss = 0.88, batch loss = 0.50 (36.1 examples/sec; 0.222 sec/batch; 20h:14m:07s remains)
INFO - root - 2017-12-16 14:56:18.468952: step 3700, loss = 0.93, batch loss = 0.55 (38.1 examples/sec; 0.210 sec/batch; 19h:10m:52s remains)
INFO - root - 2017-12-16 14:56:20.771395: step 3710, loss = 0.97, batch loss = 0.60 (35.7 examples/sec; 0.224 sec/batch; 20h:28m:32s remains)
INFO - root - 2017-12-16 14:56:22.995055: step 3720, loss = 0.94, batch loss = 0.56 (35.9 examples/sec; 0.223 sec/batch; 20h:20m:09s remains)
INFO - root - 2017-12-16 14:56:25.205179: step 3730, loss = 0.91, batch loss = 0.53 (36.5 examples/sec; 0.219 sec/batch; 20h:02m:30s remains)
INFO - root - 2017-12-16 14:56:27.432284: step 3740, loss = 0.93, batch loss = 0.56 (36.2 examples/sec; 0.221 sec/batch; 20h:10m:46s remains)
INFO - root - 2017-12-16 14:56:29.677234: step 3750, loss = 0.85, batch loss = 0.48 (35.7 examples/sec; 0.224 sec/batch; 20h:29m:17s remains)
INFO - root - 2017-12-16 14:56:31.861442: step 3760, loss = 0.90, batch loss = 0.53 (37.2 examples/sec; 0.215 sec/batch; 19h:39m:13s remains)
INFO - root - 2017-12-16 14:56:34.088239: step 3770, loss = 0.88, batch loss = 0.50 (35.2 examples/sec; 0.228 sec/batch; 20h:46m:52s remains)
INFO - root - 2017-12-16 14:56:36.297162: step 3780, loss = 0.88, batch loss = 0.51 (36.7 examples/sec; 0.218 sec/batch; 19h:55m:39s remains)
INFO - root - 2017-12-16 14:56:38.468759: step 3790, loss = 0.95, batch loss = 0.57 (36.9 examples/sec; 0.217 sec/batch; 19h:48m:21s remains)
INFO - root - 2017-12-16 14:56:40.689713: step 3800, loss = 0.93, batch loss = 0.56 (34.8 examples/sec; 0.230 sec/batch; 20h:57m:58s remains)
INFO - root - 2017-12-16 14:56:43.008942: step 3810, loss = 0.83, batch loss = 0.46 (37.2 examples/sec; 0.215 sec/batch; 19h:37m:19s remains)
INFO - root - 2017-12-16 14:56:45.214286: step 3820, loss = 0.93, batch loss = 0.56 (36.8 examples/sec; 0.217 sec/batch; 19h:49m:46s remains)
INFO - root - 2017-12-16 14:56:47.434159: step 3830, loss = 0.84, batch loss = 0.47 (34.3 examples/sec; 0.233 sec/batch; 21h:16m:54s remains)
INFO - root - 2017-12-16 14:56:49.615755: step 3840, loss = 0.87, batch loss = 0.50 (37.2 examples/sec; 0.215 sec/batch; 19h:37m:10s remains)
INFO - root - 2017-12-16 14:56:51.840580: step 3850, loss = 0.85, batch loss = 0.48 (36.9 examples/sec; 0.217 sec/batch; 19h:48m:19s remains)
INFO - root - 2017-12-16 14:56:54.033916: step 3860, loss = 0.90, batch loss = 0.53 (38.0 examples/sec; 0.210 sec/batch; 19h:12m:45s remains)
INFO - root - 2017-12-16 14:56:56.266615: step 3870, loss = 0.86, batch loss = 0.49 (35.5 examples/sec; 0.225 sec/batch; 20h:32m:51s remains)
INFO - root - 2017-12-16 14:56:58.504333: step 3880, loss = 0.85, batch loss = 0.48 (35.8 examples/sec; 0.223 sec/batch; 20h:23m:47s remains)
INFO - root - 2017-12-16 14:57:00.708751: step 3890, loss = 0.92, batch loss = 0.55 (36.2 examples/sec; 0.221 sec/batch; 20h:09m:18s remains)
INFO - root - 2017-12-16 14:57:02.908827: step 3900, loss = 0.94, batch loss = 0.58 (36.4 examples/sec; 0.220 sec/batch; 20h:02m:59s remains)
INFO - root - 2017-12-16 14:57:05.285484: step 3910, loss = 0.81, batch loss = 0.44 (36.5 examples/sec; 0.219 sec/batch; 19h:58m:56s remains)
INFO - root - 2017-12-16 14:57:07.506051: step 3920, loss = 0.85, batch loss = 0.49 (36.2 examples/sec; 0.221 sec/batch; 20h:10m:41s remains)
INFO - root - 2017-12-16 14:57:09.783166: step 3930, loss = 0.91, batch loss = 0.54 (37.1 examples/sec; 0.216 sec/batch; 19h:41m:37s remains)
INFO - root - 2017-12-16 14:57:11.986759: step 3940, loss = 0.81, batch loss = 0.44 (37.4 examples/sec; 0.214 sec/batch; 19h:29m:59s remains)
INFO - root - 2017-12-16 14:57:14.207053: step 3950, loss = 0.90, batch loss = 0.53 (36.1 examples/sec; 0.222 sec/batch; 20h:13m:35s remains)
INFO - root - 2017-12-16 14:57:16.425056: step 3960, loss = 0.82, batch loss = 0.46 (37.4 examples/sec; 0.214 sec/batch; 19h:32m:41s remains)
INFO - root - 2017-12-16 14:57:18.614882: step 3970, loss = 0.94, batch loss = 0.58 (36.6 examples/sec; 0.218 sec/batch; 19h:56m:10s remains)
INFO - root - 2017-12-16 14:57:20.831747: step 3980, loss = 0.84, batch loss = 0.48 (35.7 examples/sec; 0.224 sec/batch; 20h:28m:37s remains)
INFO - root - 2017-12-16 14:57:23.061023: step 3990, loss = 0.76, batch loss = 0.40 (34.6 examples/sec; 0.231 sec/batch; 21h:06m:52s remains)
INFO - root - 2017-12-16 14:57:25.335833: step 4000, loss = 0.86, batch loss = 0.49 (33.7 examples/sec; 0.238 sec/batch; 21h:41m:04s remains)
INFO - root - 2017-12-16 14:57:27.733238: step 4010, loss = 0.78, batch loss = 0.42 (35.1 examples/sec; 0.228 sec/batch; 20h:48m:42s remains)
INFO - root - 2017-12-16 14:57:29.928156: step 4020, loss = 0.84, batch loss = 0.48 (35.3 examples/sec; 0.227 sec/batch; 20h:40m:50s remains)
INFO - root - 2017-12-16 14:57:32.140266: step 4030, loss = 0.86, batch loss = 0.49 (36.5 examples/sec; 0.219 sec/batch; 19h:59m:46s remains)
INFO - root - 2017-12-16 14:57:34.355150: step 4040, loss = 0.86, batch loss = 0.50 (37.6 examples/sec; 0.213 sec/batch; 19h:25m:33s remains)
INFO - root - 2017-12-16 14:57:36.562722: step 4050, loss = 0.86, batch loss = 0.50 (37.2 examples/sec; 0.215 sec/batch; 19h:38m:27s remains)
INFO - root - 2017-12-16 14:57:38.788153: step 4060, loss = 0.85, batch loss = 0.49 (36.8 examples/sec; 0.217 sec/batch; 19h:48m:33s remains)
INFO - root - 2017-12-16 14:57:41.002685: step 4070, loss = 0.84, batch loss = 0.48 (37.5 examples/sec; 0.213 sec/batch; 19h:26m:27s remains)
INFO - root - 2017-12-16 14:57:43.249067: step 4080, loss = 0.81, batch loss = 0.45 (33.0 examples/sec; 0.242 sec/batch; 22h:06m:32s remains)
INFO - root - 2017-12-16 14:57:45.474010: step 4090, loss = 0.80, batch loss = 0.44 (36.2 examples/sec; 0.221 sec/batch; 20h:09m:30s remains)
INFO - root - 2017-12-16 14:57:47.691865: step 4100, loss = 0.80, batch loss = 0.44 (35.3 examples/sec; 0.226 sec/batch; 20h:39m:17s remains)
INFO - root - 2017-12-16 14:57:50.097341: step 4110, loss = 0.80, batch loss = 0.44 (34.3 examples/sec; 0.233 sec/batch; 21h:16m:26s remains)
INFO - root - 2017-12-16 14:57:52.288646: step 4120, loss = 0.81, batch loss = 0.45 (35.8 examples/sec; 0.223 sec/batch; 20h:23m:10s remains)
INFO - root - 2017-12-16 14:57:54.499475: step 4130, loss = 0.87, batch loss = 0.51 (37.3 examples/sec; 0.215 sec/batch; 19h:34m:31s remains)
INFO - root - 2017-12-16 14:57:56.686388: step 4140, loss = 0.94, batch loss = 0.59 (37.0 examples/sec; 0.216 sec/batch; 19h:43m:55s remains)
INFO - root - 2017-12-16 14:57:58.886251: step 4150, loss = 0.93, batch loss = 0.57 (35.8 examples/sec; 0.223 sec/batch; 20h:21m:38s remains)
INFO - root - 2017-12-16 14:58:01.134401: step 4160, loss = 0.83, batch loss = 0.47 (34.8 examples/sec; 0.230 sec/batch; 20h:58m:15s remains)
INFO - root - 2017-12-16 14:58:03.359736: step 4170, loss = 0.75, batch loss = 0.39 (35.4 examples/sec; 0.226 sec/batch; 20h:38m:00s remains)
INFO - root - 2017-12-16 14:58:05.543513: step 4180, loss = 0.81, batch loss = 0.45 (37.2 examples/sec; 0.215 sec/batch; 19h:35m:18s remains)
INFO - root - 2017-12-16 14:58:07.756367: step 4190, loss = 0.83, batch loss = 0.47 (36.5 examples/sec; 0.219 sec/batch; 19h:59m:16s remains)
INFO - root - 2017-12-16 14:58:09.963967: step 4200, loss = 0.88, batch loss = 0.53 (36.3 examples/sec; 0.220 sec/batch; 20h:05m:51s remains)
INFO - root - 2017-12-16 14:58:12.268420: step 4210, loss = 0.88, batch loss = 0.53 (36.8 examples/sec; 0.218 sec/batch; 19h:50m:26s remains)
INFO - root - 2017-12-16 14:58:14.477642: step 4220, loss = 0.84, batch loss = 0.49 (36.8 examples/sec; 0.217 sec/batch; 19h:48m:23s remains)
INFO - root - 2017-12-16 14:58:16.701395: step 4230, loss = 0.86, batch loss = 0.50 (36.7 examples/sec; 0.218 sec/batch; 19h:51m:45s remains)
INFO - root - 2017-12-16 14:58:18.892533: step 4240, loss = 0.96, batch loss = 0.60 (36.5 examples/sec; 0.219 sec/batch; 19h:58m:38s remains)
INFO - root - 2017-12-16 14:58:21.176861: step 4250, loss = 0.89, batch loss = 0.54 (35.0 examples/sec; 0.228 sec/batch; 20h:49m:10s remains)
INFO - root - 2017-12-16 14:58:23.409341: step 4260, loss = 0.94, batch loss = 0.59 (34.9 examples/sec; 0.229 sec/batch; 20h:54m:03s remains)
INFO - root - 2017-12-16 14:58:25.622474: step 4270, loss = 0.91, batch loss = 0.56 (35.0 examples/sec; 0.229 sec/batch; 20h:50m:05s remains)
INFO - root - 2017-12-16 14:58:27.849002: step 4280, loss = 0.90, batch loss = 0.55 (36.5 examples/sec; 0.219 sec/batch; 20h:00m:20s remains)
INFO - root - 2017-12-16 14:58:30.115254: step 4290, loss = 0.79, batch loss = 0.44 (34.7 examples/sec; 0.231 sec/batch; 21h:01m:59s remains)
INFO - root - 2017-12-16 14:58:32.371404: step 4300, loss = 0.93, batch loss = 0.58 (36.1 examples/sec; 0.222 sec/batch; 20h:12m:11s remains)
INFO - root - 2017-12-16 14:58:34.835937: step 4310, loss = 0.78, batch loss = 0.42 (34.7 examples/sec; 0.230 sec/batch; 20h:59m:35s remains)
INFO - root - 2017-12-16 14:58:37.055139: step 4320, loss = 0.80, batch loss = 0.44 (35.0 examples/sec; 0.229 sec/batch; 20h:51m:41s remains)
INFO - root - 2017-12-16 14:58:39.283943: step 4330, loss = 0.82, batch loss = 0.47 (37.4 examples/sec; 0.214 sec/batch; 19h:29m:08s remains)
INFO - root - 2017-12-16 14:58:41.493371: step 4340, loss = 0.84, batch loss = 0.49 (35.2 examples/sec; 0.227 sec/batch; 20h:43m:26s remains)
INFO - root - 2017-12-16 14:58:43.695794: step 4350, loss = 0.84, batch loss = 0.49 (35.3 examples/sec; 0.227 sec/batch; 20h:39m:12s remains)
INFO - root - 2017-12-16 14:58:45.925021: step 4360, loss = 0.91, batch loss = 0.56 (34.5 examples/sec; 0.232 sec/batch; 21h:09m:34s remains)
INFO - root - 2017-12-16 14:58:48.142781: step 4370, loss = 0.85, batch loss = 0.50 (35.9 examples/sec; 0.223 sec/batch; 20h:17m:43s remains)
INFO - root - 2017-12-16 14:58:50.364552: step 4380, loss = 0.84, batch loss = 0.49 (36.4 examples/sec; 0.220 sec/batch; 20h:02m:29s remains)
INFO - root - 2017-12-16 14:58:52.552582: step 4390, loss = 0.82, batch loss = 0.47 (37.9 examples/sec; 0.211 sec/batch; 19h:12m:57s remains)
INFO - root - 2017-12-16 14:58:54.735245: step 4400, loss = 0.80, batch loss = 0.45 (36.7 examples/sec; 0.218 sec/batch; 19h:53m:06s remains)
INFO - root - 2017-12-16 14:58:57.092438: step 4410, loss = 0.82, batch loss = 0.47 (36.7 examples/sec; 0.218 sec/batch; 19h:51m:13s remains)
INFO - root - 2017-12-16 14:58:59.340049: step 4420, loss = 0.74, batch loss = 0.39 (34.7 examples/sec; 0.231 sec/batch; 21h:02m:02s remains)
INFO - root - 2017-12-16 14:59:01.580640: step 4430, loss = 0.81, batch loss = 0.47 (34.3 examples/sec; 0.233 sec/batch; 21h:13m:29s remains)
INFO - root - 2017-12-16 14:59:03.809000: step 4440, loss = 0.84, batch loss = 0.49 (36.5 examples/sec; 0.219 sec/batch; 19h:58m:35s remains)
INFO - root - 2017-12-16 14:59:06.038556: step 4450, loss = 0.84, batch loss = 0.49 (34.8 examples/sec; 0.230 sec/batch; 20h:55m:35s remains)
INFO - root - 2017-12-16 14:59:08.299428: step 4460, loss = 0.85, batch loss = 0.50 (36.3 examples/sec; 0.220 sec/batch; 20h:03m:41s remains)
INFO - root - 2017-12-16 14:59:10.562834: step 4470, loss = 0.78, batch loss = 0.43 (35.8 examples/sec; 0.224 sec/batch; 20h:23m:01s remains)
INFO - root - 2017-12-16 14:59:12.794796: step 4480, loss = 0.84, batch loss = 0.49 (36.3 examples/sec; 0.220 sec/batch; 20h:04m:16s remains)
INFO - root - 2017-12-16 14:59:15.040764: step 4490, loss = 0.83, batch loss = 0.49 (36.2 examples/sec; 0.221 sec/batch; 20h:08m:32s remains)
INFO - root - 2017-12-16 14:59:17.240564: step 4500, loss = 0.85, batch loss = 0.51 (37.4 examples/sec; 0.214 sec/batch; 19h:27m:54s remains)
INFO - root - 2017-12-16 14:59:19.634013: step 4510, loss = 0.79, batch loss = 0.45 (36.8 examples/sec; 0.217 sec/batch; 19h:47m:39s remains)
INFO - root - 2017-12-16 14:59:21.846226: step 4520, loss = 0.82, batch loss = 0.48 (35.6 examples/sec; 0.225 sec/batch; 20h:30m:02s remains)
INFO - root - 2017-12-16 14:59:24.040170: step 4530, loss = 0.80, batch loss = 0.46 (37.3 examples/sec; 0.215 sec/batch; 19h:32m:36s remains)
INFO - root - 2017-12-16 14:59:26.206950: step 4540, loss = 0.80, batch loss = 0.45 (37.5 examples/sec; 0.213 sec/batch; 19h:26m:14s remains)
INFO - root - 2017-12-16 14:59:28.444008: step 4550, loss = 0.82, batch loss = 0.48 (34.7 examples/sec; 0.230 sec/batch; 20h:59m:12s remains)
INFO - root - 2017-12-16 14:59:30.659958: step 4560, loss = 0.78, batch loss = 0.44 (37.2 examples/sec; 0.215 sec/batch; 19h:35m:17s remains)
INFO - root - 2017-12-16 14:59:32.885777: step 4570, loss = 0.74, batch loss = 0.40 (36.6 examples/sec; 0.219 sec/batch; 19h:54m:27s remains)
INFO - root - 2017-12-16 14:59:35.109515: step 4580, loss = 0.79, batch loss = 0.45 (36.5 examples/sec; 0.219 sec/batch; 19h:58m:30s remains)
INFO - root - 2017-12-16 14:59:37.346426: step 4590, loss = 0.75, batch loss = 0.41 (36.0 examples/sec; 0.222 sec/batch; 20h:13m:10s remains)
INFO - root - 2017-12-16 14:59:39.567480: step 4600, loss = 0.91, batch loss = 0.57 (36.9 examples/sec; 0.217 sec/batch; 19h:43m:55s remains)
INFO - root - 2017-12-16 14:59:41.943089: step 4610, loss = 0.81, batch loss = 0.46 (36.4 examples/sec; 0.220 sec/batch; 19h:59m:38s remains)
INFO - root - 2017-12-16 14:59:44.154989: step 4620, loss = 0.80, batch loss = 0.45 (36.4 examples/sec; 0.220 sec/batch; 20h:02m:02s remains)
INFO - root - 2017-12-16 14:59:46.383576: step 4630, loss = 0.80, batch loss = 0.46 (35.4 examples/sec; 0.226 sec/batch; 20h:35m:25s remains)
INFO - root - 2017-12-16 14:59:48.574992: step 4640, loss = 0.80, batch loss = 0.46 (37.6 examples/sec; 0.213 sec/batch; 19h:22m:11s remains)
INFO - root - 2017-12-16 14:59:50.789233: step 4650, loss = 0.78, batch loss = 0.43 (35.8 examples/sec; 0.224 sec/batch; 20h:21m:57s remains)
INFO - root - 2017-12-16 14:59:53.041619: step 4660, loss = 0.82, batch loss = 0.48 (35.4 examples/sec; 0.226 sec/batch; 20h:34m:07s remains)
INFO - root - 2017-12-16 14:59:55.262915: step 4670, loss = 0.83, batch loss = 0.49 (37.0 examples/sec; 0.216 sec/batch; 19h:42m:03s remains)
INFO - root - 2017-12-16 14:59:57.473688: step 4680, loss = 0.78, batch loss = 0.44 (36.3 examples/sec; 0.220 sec/batch; 20h:02m:57s remains)
INFO - root - 2017-12-16 14:59:59.658698: step 4690, loss = 0.77, batch loss = 0.43 (37.3 examples/sec; 0.215 sec/batch; 19h:32m:23s remains)
INFO - root - 2017-12-16 15:00:01.899534: step 4700, loss = 0.86, batch loss = 0.52 (37.2 examples/sec; 0.215 sec/batch; 19h:35m:27s remains)
INFO - root - 2017-12-16 15:00:04.250162: step 4710, loss = 0.83, batch loss = 0.49 (35.9 examples/sec; 0.223 sec/batch; 20h:16m:53s remains)
INFO - root - 2017-12-16 15:00:06.449949: step 4720, loss = 0.75, batch loss = 0.41 (36.2 examples/sec; 0.221 sec/batch; 20h:05m:43s remains)
INFO - root - 2017-12-16 15:00:08.707591: step 4730, loss = 0.80, batch loss = 0.46 (34.3 examples/sec; 0.233 sec/batch; 21h:13m:57s remains)
INFO - root - 2017-12-16 15:00:10.944633: step 4740, loss = 0.78, batch loss = 0.44 (36.3 examples/sec; 0.220 sec/batch; 20h:02m:23s remains)
INFO - root - 2017-12-16 15:00:13.169100: step 4750, loss = 0.83, batch loss = 0.49 (37.8 examples/sec; 0.212 sec/batch; 19h:17m:00s remains)
INFO - root - 2017-12-16 15:00:15.396843: step 4760, loss = 0.86, batch loss = 0.52 (34.0 examples/sec; 0.235 sec/batch; 21h:26m:00s remains)
INFO - root - 2017-12-16 15:00:17.640571: step 4770, loss = 0.75, batch loss = 0.42 (35.2 examples/sec; 0.227 sec/batch; 20h:40m:28s remains)
INFO - root - 2017-12-16 15:00:19.877572: step 4780, loss = 0.97, batch loss = 0.64 (36.5 examples/sec; 0.219 sec/batch; 19h:57m:48s remains)
INFO - root - 2017-12-16 15:00:22.082748: step 4790, loss = 0.79, batch loss = 0.46 (36.7 examples/sec; 0.218 sec/batch; 19h:51m:08s remains)
INFO - root - 2017-12-16 15:00:24.303828: step 4800, loss = 0.85, batch loss = 0.51 (37.2 examples/sec; 0.215 sec/batch; 19h:35m:34s remains)
INFO - root - 2017-12-16 15:00:26.705623: step 4810, loss = 0.80, batch loss = 0.47 (34.4 examples/sec; 0.233 sec/batch; 21h:11m:08s remains)
INFO - root - 2017-12-16 15:00:28.920238: step 4820, loss = 0.82, batch loss = 0.49 (36.7 examples/sec; 0.218 sec/batch; 19h:51m:33s remains)
INFO - root - 2017-12-16 15:00:31.136774: step 4830, loss = 0.81, batch loss = 0.47 (36.3 examples/sec; 0.220 sec/batch; 20h:02m:36s remains)
INFO - root - 2017-12-16 15:00:33.369499: step 4840, loss = 0.79, batch loss = 0.46 (36.0 examples/sec; 0.222 sec/batch; 20h:14m:23s remains)
INFO - root - 2017-12-16 15:00:35.569476: step 4850, loss = 0.75, batch loss = 0.41 (34.7 examples/sec; 0.231 sec/batch; 20h:59m:04s remains)
INFO - root - 2017-12-16 15:00:37.778735: step 4860, loss = 0.85, batch loss = 0.52 (36.7 examples/sec; 0.218 sec/batch; 19h:51m:25s remains)
INFO - root - 2017-12-16 15:00:39.978751: step 4870, loss = 0.82, batch loss = 0.49 (36.3 examples/sec; 0.221 sec/batch; 20h:04m:26s remains)
INFO - root - 2017-12-16 15:00:42.219692: step 4880, loss = 0.76, batch loss = 0.42 (34.6 examples/sec; 0.231 sec/batch; 21h:02m:59s remains)
INFO - root - 2017-12-16 15:00:44.419714: step 4890, loss = 0.80, batch loss = 0.47 (36.5 examples/sec; 0.219 sec/batch; 19h:57m:33s remains)
INFO - root - 2017-12-16 15:00:46.654961: step 4900, loss = 0.72, batch loss = 0.39 (36.6 examples/sec; 0.219 sec/batch; 19h:53m:52s remains)
INFO - root - 2017-12-16 15:00:49.000174: step 4910, loss = 0.77, batch loss = 0.44 (36.6 examples/sec; 0.218 sec/batch; 19h:52m:14s remains)
INFO - root - 2017-12-16 15:00:51.261077: step 4920, loss = 0.81, batch loss = 0.48 (35.0 examples/sec; 0.229 sec/batch; 20h:48m:58s remains)
INFO - root - 2017-12-16 15:00:53.489058: step 4930, loss = 0.75, batch loss = 0.42 (36.4 examples/sec; 0.220 sec/batch; 20h:01m:04s remains)
INFO - root - 2017-12-16 15:00:55.723239: step 4940, loss = 0.80, batch loss = 0.47 (35.3 examples/sec; 0.227 sec/batch; 20h:36m:51s remains)
INFO - root - 2017-12-16 15:00:57.919830: step 4950, loss = 0.78, batch loss = 0.45 (34.6 examples/sec; 0.231 sec/batch; 21h:00m:25s remains)
INFO - root - 2017-12-16 15:01:00.138808: step 4960, loss = 0.83, batch loss = 0.50 (36.6 examples/sec; 0.219 sec/batch; 19h:52m:51s remains)
INFO - root - 2017-12-16 15:01:02.358346: step 4970, loss = 0.74, batch loss = 0.41 (37.0 examples/sec; 0.216 sec/batch; 19h:40m:15s remains)
INFO - root - 2017-12-16 15:01:04.595444: step 4980, loss = 0.83, batch loss = 0.50 (35.1 examples/sec; 0.228 sec/batch; 20h:43m:09s remains)
INFO - root - 2017-12-16 15:01:06.838695: step 4990, loss = 0.84, batch loss = 0.51 (34.7 examples/sec; 0.231 sec/batch; 20h:59m:19s remains)
INFO - root - 2017-12-16 15:01:09.058645: step 5000, loss = 0.77, batch loss = 0.44 (35.6 examples/sec; 0.225 sec/batch; 20h:26m:04s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-5000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-5000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 15:01:12.151330: step 5010, loss = 0.78, batch loss = 0.45 (35.9 examples/sec; 0.223 sec/batch; 20h:17m:49s remains)
INFO - root - 2017-12-16 15:01:14.360969: step 5020, loss = 0.88, batch loss = 0.55 (37.2 examples/sec; 0.215 sec/batch; 19h:34m:52s remains)
INFO - root - 2017-12-16 15:01:16.581103: step 5030, loss = 0.81, batch loss = 0.49 (36.1 examples/sec; 0.221 sec/batch; 20h:08m:28s remains)
INFO - root - 2017-12-16 15:01:18.796729: step 5040, loss = 0.85, batch loss = 0.52 (34.9 examples/sec; 0.229 sec/batch; 20h:50m:18s remains)
INFO - root - 2017-12-16 15:01:21.030518: step 5050, loss = 0.77, batch loss = 0.45 (34.5 examples/sec; 0.232 sec/batch; 21h:04m:38s remains)
INFO - root - 2017-12-16 15:01:23.276989: step 5060, loss = 0.75, batch loss = 0.42 (36.6 examples/sec; 0.219 sec/batch; 19h:53m:28s remains)
INFO - root - 2017-12-16 15:01:25.514921: step 5070, loss = 0.79, batch loss = 0.46 (36.1 examples/sec; 0.222 sec/batch; 20h:10m:09s remains)
INFO - root - 2017-12-16 15:01:27.693105: step 5080, loss = 0.73, batch loss = 0.40 (36.8 examples/sec; 0.217 sec/batch; 19h:46m:31s remains)
INFO - root - 2017-12-16 15:01:29.917497: step 5090, loss = 0.75, batch loss = 0.42 (35.5 examples/sec; 0.225 sec/batch; 20h:28m:15s remains)
INFO - root - 2017-12-16 15:01:32.141914: step 5100, loss = 0.76, batch loss = 0.43 (36.3 examples/sec; 0.220 sec/batch; 20h:03m:02s remains)
INFO - root - 2017-12-16 15:01:34.500958: step 5110, loss = 0.83, batch loss = 0.50 (36.5 examples/sec; 0.219 sec/batch; 19h:55m:29s remains)
INFO - root - 2017-12-16 15:01:36.678635: step 5120, loss = 0.84, batch loss = 0.51 (36.9 examples/sec; 0.217 sec/batch; 19h:41m:31s remains)
INFO - root - 2017-12-16 15:01:38.875269: step 5130, loss = 0.76, batch loss = 0.44 (35.8 examples/sec; 0.223 sec/batch; 20h:18m:47s remains)
INFO - root - 2017-12-16 15:01:41.093583: step 5140, loss = 0.78, batch loss = 0.46 (34.4 examples/sec; 0.233 sec/batch; 21h:09m:52s remains)
INFO - root - 2017-12-16 15:01:43.323843: step 5150, loss = 0.76, batch loss = 0.44 (36.0 examples/sec; 0.222 sec/batch; 20h:12m:48s remains)
INFO - root - 2017-12-16 15:01:45.556170: step 5160, loss = 0.85, batch loss = 0.53 (37.4 examples/sec; 0.214 sec/batch; 19h:26m:33s remains)
INFO - root - 2017-12-16 15:01:47.814376: step 5170, loss = 0.78, batch loss = 0.46 (35.2 examples/sec; 0.227 sec/batch; 20h:38m:29s remains)
INFO - root - 2017-12-16 15:01:50.021266: step 5180, loss = 0.80, batch loss = 0.47 (36.3 examples/sec; 0.220 sec/batch; 20h:02m:43s remains)
INFO - root - 2017-12-16 15:01:52.262820: step 5190, loss = 0.86, batch loss = 0.54 (36.6 examples/sec; 0.218 sec/batch; 19h:51m:42s remains)
INFO - root - 2017-12-16 15:01:54.474341: step 5200, loss = 0.84, batch loss = 0.52 (36.0 examples/sec; 0.222 sec/batch; 20h:12m:18s remains)
INFO - root - 2017-12-16 15:01:56.844750: step 5210, loss = 0.78, batch loss = 0.45 (36.7 examples/sec; 0.218 sec/batch; 19h:49m:04s remains)
INFO - root - 2017-12-16 15:01:59.046322: step 5220, loss = 0.84, batch loss = 0.52 (37.4 examples/sec; 0.214 sec/batch; 19h:27m:16s remains)
INFO - root - 2017-12-16 15:02:01.258585: step 5230, loss = 0.79, batch loss = 0.47 (36.2 examples/sec; 0.221 sec/batch; 20h:05m:08s remains)
INFO - root - 2017-12-16 15:02:03.504118: step 5240, loss = 0.78, batch loss = 0.46 (35.2 examples/sec; 0.227 sec/batch; 20h:39m:24s remains)
INFO - root - 2017-12-16 15:02:05.684611: step 5250, loss = 0.77, batch loss = 0.45 (37.1 examples/sec; 0.216 sec/batch; 19h:37m:17s remains)
INFO - root - 2017-12-16 15:02:07.880700: step 5260, loss = 0.79, batch loss = 0.47 (37.6 examples/sec; 0.213 sec/batch; 19h:21m:31s remains)
INFO - root - 2017-12-16 15:02:10.122210: step 5270, loss = 0.84, batch loss = 0.52 (35.9 examples/sec; 0.223 sec/batch; 20h:16m:51s remains)
INFO - root - 2017-12-16 15:02:12.356384: step 5280, loss = 0.78, batch loss = 0.46 (36.2 examples/sec; 0.221 sec/batch; 20h:06m:21s remains)
INFO - root - 2017-12-16 15:02:14.538340: step 5290, loss = 0.77, batch loss = 0.45 (37.2 examples/sec; 0.215 sec/batch; 19h:31m:27s remains)
INFO - root - 2017-12-16 15:02:16.783330: step 5300, loss = 0.85, batch loss = 0.53 (35.0 examples/sec; 0.229 sec/batch; 20h:46m:24s remains)
INFO - root - 2017-12-16 15:02:19.121837: step 5310, loss = 0.80, batch loss = 0.48 (36.6 examples/sec; 0.219 sec/batch; 19h:52m:29s remains)
INFO - root - 2017-12-16 15:02:21.354502: step 5320, loss = 0.76, batch loss = 0.44 (35.2 examples/sec; 0.227 sec/batch; 20h:38m:27s remains)
INFO - root - 2017-12-16 15:02:23.594633: step 5330, loss = 0.90, batch loss = 0.58 (34.3 examples/sec; 0.234 sec/batch; 21h:13m:18s remains)
INFO - root - 2017-12-16 15:02:25.864957: step 5340, loss = 0.85, batch loss = 0.53 (35.5 examples/sec; 0.225 sec/batch; 20h:28m:24s remains)
INFO - root - 2017-12-16 15:02:28.098906: step 5350, loss = 0.86, batch loss = 0.54 (36.0 examples/sec; 0.222 sec/batch; 20h:10m:04s remains)
INFO - root - 2017-12-16 15:02:30.309021: step 5360, loss = 0.75, batch loss = 0.44 (36.8 examples/sec; 0.218 sec/batch; 19h:45m:54s remains)
INFO - root - 2017-12-16 15:02:32.498456: step 5370, loss = 0.72, batch loss = 0.41 (36.8 examples/sec; 0.218 sec/batch; 19h:46m:16s remains)
INFO - root - 2017-12-16 15:02:34.705247: step 5380, loss = 0.81, batch loss = 0.49 (37.1 examples/sec; 0.216 sec/batch; 19h:36m:15s remains)
INFO - root - 2017-12-16 15:02:36.931172: step 5390, loss = 0.82, batch loss = 0.50 (35.4 examples/sec; 0.226 sec/batch; 20h:30m:47s remains)
INFO - root - 2017-12-16 15:02:39.150654: step 5400, loss = 0.76, batch loss = 0.45 (35.2 examples/sec; 0.227 sec/batch; 20h:38m:07s remains)
INFO - root - 2017-12-16 15:02:41.487147: step 5410, loss = 0.79, batch loss = 0.47 (35.0 examples/sec; 0.229 sec/batch; 20h:45m:57s remains)
INFO - root - 2017-12-16 15:02:43.723410: step 5420, loss = 0.79, batch loss = 0.47 (35.6 examples/sec; 0.225 sec/batch; 20h:26m:37s remains)
INFO - root - 2017-12-16 15:02:45.947172: step 5430, loss = 0.77, batch loss = 0.46 (35.8 examples/sec; 0.224 sec/batch; 20h:19m:20s remains)
INFO - root - 2017-12-16 15:02:48.219947: step 5440, loss = 0.76, batch loss = 0.45 (34.5 examples/sec; 0.232 sec/batch; 21h:05m:07s remains)
INFO - root - 2017-12-16 15:02:50.430669: step 5450, loss = 0.85, batch loss = 0.53 (36.7 examples/sec; 0.218 sec/batch; 19h:49m:01s remains)
INFO - root - 2017-12-16 15:02:52.638186: step 5460, loss = 0.87, batch loss = 0.55 (37.0 examples/sec; 0.216 sec/batch; 19h:39m:07s remains)
INFO - root - 2017-12-16 15:02:54.914070: step 5470, loss = 0.80, batch loss = 0.48 (36.0 examples/sec; 0.222 sec/batch; 20h:10m:58s remains)
INFO - root - 2017-12-16 15:02:57.123921: step 5480, loss = 0.78, batch loss = 0.47 (35.9 examples/sec; 0.223 sec/batch; 20h:13m:26s remains)
INFO - root - 2017-12-16 15:02:59.351342: step 5490, loss = 0.76, batch loss = 0.45 (36.3 examples/sec; 0.220 sec/batch; 20h:01m:38s remains)
INFO - root - 2017-12-16 15:03:01.585288: step 5500, loss = 0.77, batch loss = 0.46 (35.1 examples/sec; 0.228 sec/batch; 20h:40m:50s remains)
INFO - root - 2017-12-16 15:03:03.962553: step 5510, loss = 0.87, batch loss = 0.55 (37.2 examples/sec; 0.215 sec/batch; 19h:31m:01s remains)
INFO - root - 2017-12-16 15:03:06.177453: step 5520, loss = 0.73, batch loss = 0.41 (37.1 examples/sec; 0.216 sec/batch; 19h:36m:38s remains)
INFO - root - 2017-12-16 15:03:08.403210: step 5530, loss = 0.81, batch loss = 0.50 (35.7 examples/sec; 0.224 sec/batch; 20h:20m:08s remains)
INFO - root - 2017-12-16 15:03:10.676325: step 5540, loss = 0.80, batch loss = 0.49 (34.7 examples/sec; 0.231 sec/batch; 20h:56m:32s remains)
INFO - root - 2017-12-16 15:03:12.914476: step 5550, loss = 0.79, batch loss = 0.47 (35.9 examples/sec; 0.223 sec/batch; 20h:14m:40s remains)
INFO - root - 2017-12-16 15:03:15.155998: step 5560, loss = 0.79, batch loss = 0.48 (37.3 examples/sec; 0.215 sec/batch; 19h:29m:26s remains)
INFO - root - 2017-12-16 15:03:17.375744: step 5570, loss = 0.75, batch loss = 0.44 (36.3 examples/sec; 0.221 sec/batch; 20h:02m:16s remains)
INFO - root - 2017-12-16 15:03:19.596333: step 5580, loss = 0.81, batch loss = 0.50 (36.8 examples/sec; 0.218 sec/batch; 19h:45m:12s remains)
INFO - root - 2017-12-16 15:03:21.830748: step 5590, loss = 0.87, batch loss = 0.55 (36.0 examples/sec; 0.222 sec/batch; 20h:09m:55s remains)
INFO - root - 2017-12-16 15:03:24.040812: step 5600, loss = 0.79, batch loss = 0.48 (36.3 examples/sec; 0.220 sec/batch; 20h:01m:00s remains)
INFO - root - 2017-12-16 15:03:26.365833: step 5610, loss = 0.72, batch loss = 0.41 (37.6 examples/sec; 0.213 sec/batch; 19h:19m:31s remains)
INFO - root - 2017-12-16 15:03:28.548503: step 5620, loss = 0.77, batch loss = 0.46 (35.7 examples/sec; 0.224 sec/batch; 20h:21m:49s remains)
INFO - root - 2017-12-16 15:03:30.737421: step 5630, loss = 0.79, batch loss = 0.48 (36.5 examples/sec; 0.219 sec/batch; 19h:52m:39s remains)
INFO - root - 2017-12-16 15:03:32.936685: step 5640, loss = 0.79, batch loss = 0.48 (35.0 examples/sec; 0.228 sec/batch; 20h:43m:28s remains)
INFO - root - 2017-12-16 15:03:35.168521: step 5650, loss = 0.77, batch loss = 0.46 (36.6 examples/sec; 0.218 sec/batch; 19h:49m:13s remains)
INFO - root - 2017-12-16 15:03:37.384892: step 5660, loss = 0.85, batch loss = 0.54 (35.7 examples/sec; 0.224 sec/batch; 20h:21m:27s remains)
INFO - root - 2017-12-16 15:03:39.597499: step 5670, loss = 0.74, batch loss = 0.43 (36.4 examples/sec; 0.220 sec/batch; 19h:58m:29s remains)
INFO - root - 2017-12-16 15:03:41.830210: step 5680, loss = 0.81, batch loss = 0.50 (34.7 examples/sec; 0.231 sec/batch; 20h:57m:27s remains)
INFO - root - 2017-12-16 15:03:44.043911: step 5690, loss = 0.87, batch loss = 0.56 (35.5 examples/sec; 0.225 sec/batch; 20h:27m:16s remains)
INFO - root - 2017-12-16 15:03:46.259615: step 5700, loss = 0.77, batch loss = 0.46 (36.4 examples/sec; 0.220 sec/batch; 19h:57m:45s remains)
INFO - root - 2017-12-16 15:03:48.602012: step 5710, loss = 0.71, batch loss = 0.40 (36.2 examples/sec; 0.221 sec/batch; 20h:02m:53s remains)
INFO - root - 2017-12-16 15:03:50.812362: step 5720, loss = 0.72, batch loss = 0.41 (36.3 examples/sec; 0.221 sec/batch; 20h:01m:33s remains)
INFO - root - 2017-12-16 15:03:53.013378: step 5730, loss = 0.78, batch loss = 0.47 (36.7 examples/sec; 0.218 sec/batch; 19h:48m:29s remains)
INFO - root - 2017-12-16 15:03:55.218703: step 5740, loss = 0.81, batch loss = 0.50 (36.9 examples/sec; 0.217 sec/batch; 19h:39m:14s remains)
INFO - root - 2017-12-16 15:03:57.441227: step 5750, loss = 0.90, batch loss = 0.59 (36.6 examples/sec; 0.218 sec/batch; 19h:49m:32s remains)
INFO - root - 2017-12-16 15:03:59.653518: step 5760, loss = 0.76, batch loss = 0.46 (37.0 examples/sec; 0.216 sec/batch; 19h:36m:45s remains)
INFO - root - 2017-12-16 15:04:01.842986: step 5770, loss = 0.77, batch loss = 0.47 (35.9 examples/sec; 0.223 sec/batch; 20h:13m:41s remains)
INFO - root - 2017-12-16 15:04:04.075891: step 5780, loss = 0.80, batch loss = 0.49 (35.3 examples/sec; 0.227 sec/batch; 20h:34m:25s remains)
INFO - root - 2017-12-16 15:04:06.321164: step 5790, loss = 0.77, batch loss = 0.46 (32.8 examples/sec; 0.244 sec/batch; 22h:07m:33s remains)
INFO - root - 2017-12-16 15:04:08.502168: step 5800, loss = 0.79, batch loss = 0.49 (37.8 examples/sec; 0.211 sec/batch; 19h:10m:56s remains)
INFO - root - 2017-12-16 15:04:10.884019: step 5810, loss = 0.76, batch loss = 0.45 (35.8 examples/sec; 0.224 sec/batch; 20h:17m:35s remains)
INFO - root - 2017-12-16 15:04:13.106253: step 5820, loss = 0.80, batch loss = 0.49 (36.4 examples/sec; 0.220 sec/batch; 19h:57m:08s remains)
INFO - root - 2017-12-16 15:04:15.275512: step 5830, loss = 0.74, batch loss = 0.44 (35.8 examples/sec; 0.223 sec/batch; 20h:16m:29s remains)
INFO - root - 2017-12-16 15:04:17.492624: step 5840, loss = 0.83, batch loss = 0.53 (36.3 examples/sec; 0.220 sec/batch; 19h:58m:57s remains)
INFO - root - 2017-12-16 15:04:19.715362: step 5850, loss = 0.77, batch loss = 0.47 (35.7 examples/sec; 0.224 sec/batch; 20h:21m:32s remains)
INFO - root - 2017-12-16 15:04:21.890470: step 5860, loss = 0.82, batch loss = 0.52 (37.2 examples/sec; 0.215 sec/batch; 19h:29m:32s remains)
INFO - root - 2017-12-16 15:04:24.088388: step 5870, loss = 0.76, batch loss = 0.45 (37.7 examples/sec; 0.212 sec/batch; 19h:14m:09s remains)
INFO - root - 2017-12-16 15:04:26.263114: step 5880, loss = 0.78, batch loss = 0.47 (37.0 examples/sec; 0.216 sec/batch; 19h:37m:51s remains)
INFO - root - 2017-12-16 15:04:28.462673: step 5890, loss = 0.78, batch loss = 0.48 (34.9 examples/sec; 0.229 sec/batch; 20h:48m:55s remains)
INFO - root - 2017-12-16 15:04:30.637548: step 5900, loss = 0.83, batch loss = 0.53 (37.7 examples/sec; 0.212 sec/batch; 19h:15m:56s remains)
INFO - root - 2017-12-16 15:04:32.984424: step 5910, loss = 0.72, batch loss = 0.42 (36.7 examples/sec; 0.218 sec/batch; 19h:47m:45s remains)
INFO - root - 2017-12-16 15:04:35.155965: step 5920, loss = 0.75, batch loss = 0.45 (37.0 examples/sec; 0.216 sec/batch; 19h:38m:18s remains)
INFO - root - 2017-12-16 15:04:37.323111: step 5930, loss = 0.76, batch loss = 0.46 (36.7 examples/sec; 0.218 sec/batch; 19h:47m:24s remains)
INFO - root - 2017-12-16 15:04:39.527971: step 5940, loss = 0.76, batch loss = 0.46 (37.6 examples/sec; 0.213 sec/batch; 19h:17m:28s remains)
INFO - root - 2017-12-16 15:04:41.741614: step 5950, loss = 0.71, batch loss = 0.41 (36.8 examples/sec; 0.217 sec/batch; 19h:42m:58s remains)
INFO - root - 2017-12-16 15:04:43.919489: step 5960, loss = 0.73, batch loss = 0.43 (35.9 examples/sec; 0.223 sec/batch; 20h:12m:58s remains)
INFO - root - 2017-12-16 15:04:46.132144: step 5970, loss = 0.74, batch loss = 0.44 (34.8 examples/sec; 0.230 sec/batch; 20h:51m:47s remains)
INFO - root - 2017-12-16 15:04:48.339541: step 5980, loss = 0.74, batch loss = 0.45 (35.9 examples/sec; 0.223 sec/batch; 20h:13m:02s remains)
INFO - root - 2017-12-16 15:04:50.546102: step 5990, loss = 0.73, batch loss = 0.43 (35.4 examples/sec; 0.226 sec/batch; 20h:29m:49s remains)
INFO - root - 2017-12-16 15:04:52.757935: step 6000, loss = 0.74, batch loss = 0.45 (35.2 examples/sec; 0.228 sec/batch; 20h:38m:00s remains)
INFO - root - 2017-12-16 15:04:55.107749: step 6010, loss = 0.75, batch loss = 0.46 (36.5 examples/sec; 0.219 sec/batch; 19h:52m:09s remains)
INFO - root - 2017-12-16 15:04:57.308214: step 6020, loss = 0.80, batch loss = 0.50 (36.4 examples/sec; 0.220 sec/batch; 19h:55m:06s remains)
INFO - root - 2017-12-16 15:04:59.499274: step 6030, loss = 0.72, batch loss = 0.43 (35.8 examples/sec; 0.223 sec/batch; 20h:14m:40s remains)
INFO - root - 2017-12-16 15:05:01.666251: step 6040, loss = 0.72, batch loss = 0.43 (37.5 examples/sec; 0.213 sec/batch; 19h:19m:13s remains)
INFO - root - 2017-12-16 15:05:03.865645: step 6050, loss = 0.77, batch loss = 0.48 (35.6 examples/sec; 0.225 sec/batch; 20h:21m:59s remains)
INFO - root - 2017-12-16 15:05:06.120127: step 6060, loss = 0.66, batch loss = 0.37 (35.7 examples/sec; 0.224 sec/batch; 20h:20m:42s remains)
INFO - root - 2017-12-16 15:05:08.330000: step 6070, loss = 0.73, batch loss = 0.43 (36.8 examples/sec; 0.217 sec/batch; 19h:42m:48s remains)
INFO - root - 2017-12-16 15:05:10.520631: step 6080, loss = 0.77, batch loss = 0.48 (36.7 examples/sec; 0.218 sec/batch; 19h:46m:19s remains)
INFO - root - 2017-12-16 15:05:12.751150: step 6090, loss = 0.76, batch loss = 0.46 (36.7 examples/sec; 0.218 sec/batch; 19h:45m:51s remains)
INFO - root - 2017-12-16 15:05:14.946043: step 6100, loss = 0.74, batch loss = 0.45 (35.3 examples/sec; 0.227 sec/batch; 20h:33m:10s remains)
INFO - root - 2017-12-16 15:05:17.273806: step 6110, loss = 0.86, batch loss = 0.56 (35.7 examples/sec; 0.224 sec/batch; 20h:19m:52s remains)
INFO - root - 2017-12-16 15:05:19.455801: step 6120, loss = 0.84, batch loss = 0.55 (37.4 examples/sec; 0.214 sec/batch; 19h:23m:36s remains)
INFO - root - 2017-12-16 15:05:21.672536: step 6130, loss = 0.79, batch loss = 0.49 (37.0 examples/sec; 0.216 sec/batch; 19h:35m:50s remains)
INFO - root - 2017-12-16 15:05:23.897095: step 6140, loss = 0.76, batch loss = 0.47 (35.8 examples/sec; 0.223 sec/batch; 20h:15m:12s remains)
INFO - root - 2017-12-16 15:05:26.125175: step 6150, loss = 0.72, batch loss = 0.43 (36.5 examples/sec; 0.219 sec/batch; 19h:51m:23s remains)
INFO - root - 2017-12-16 15:05:28.372450: step 6160, loss = 0.75, batch loss = 0.45 (36.2 examples/sec; 0.221 sec/batch; 20h:03m:26s remains)
INFO - root - 2017-12-16 15:05:30.542915: step 6170, loss = 0.77, batch loss = 0.48 (37.1 examples/sec; 0.216 sec/batch; 19h:33m:43s remains)
INFO - root - 2017-12-16 15:05:32.724412: step 6180, loss = 0.79, batch loss = 0.50 (37.2 examples/sec; 0.215 sec/batch; 19h:29m:55s remains)
INFO - root - 2017-12-16 15:05:34.958431: step 6190, loss = 0.73, batch loss = 0.44 (36.3 examples/sec; 0.220 sec/batch; 19h:58m:30s remains)
INFO - root - 2017-12-16 15:05:37.132040: step 6200, loss = 0.74, batch loss = 0.45 (36.7 examples/sec; 0.218 sec/batch; 19h:43m:58s remains)
INFO - root - 2017-12-16 15:05:39.494208: step 6210, loss = 0.74, batch loss = 0.45 (35.6 examples/sec; 0.225 sec/batch; 20h:23m:45s remains)
INFO - root - 2017-12-16 15:05:41.664262: step 6220, loss = 0.80, batch loss = 0.50 (36.6 examples/sec; 0.218 sec/batch; 19h:47m:07s remains)
INFO - root - 2017-12-16 15:05:43.829858: step 6230, loss = 0.72, batch loss = 0.43 (36.6 examples/sec; 0.218 sec/batch; 19h:47m:28s remains)
INFO - root - 2017-12-16 15:05:46.036238: step 6240, loss = 0.71, batch loss = 0.42 (37.1 examples/sec; 0.216 sec/batch; 19h:31m:53s remains)
INFO - root - 2017-12-16 15:05:48.269416: step 6250, loss = 0.72, batch loss = 0.43 (35.0 examples/sec; 0.229 sec/batch; 20h:43m:44s remains)
INFO - root - 2017-12-16 15:05:50.447894: step 6260, loss = 0.76, batch loss = 0.47 (37.3 examples/sec; 0.215 sec/batch; 19h:27m:05s remains)
INFO - root - 2017-12-16 15:05:52.625766: step 6270, loss = 0.72, batch loss = 0.43 (36.4 examples/sec; 0.220 sec/batch; 19h:54m:33s remains)
INFO - root - 2017-12-16 15:05:54.822905: step 6280, loss = 0.70, batch loss = 0.41 (36.3 examples/sec; 0.220 sec/batch; 19h:56m:59s remains)
INFO - root - 2017-12-16 15:05:57.006676: step 6290, loss = 0.70, batch loss = 0.41 (36.4 examples/sec; 0.220 sec/batch; 19h:53m:58s remains)
INFO - root - 2017-12-16 15:05:59.181586: step 6300, loss = 0.73, batch loss = 0.44 (37.6 examples/sec; 0.213 sec/batch; 19h:18m:02s remains)
INFO - root - 2017-12-16 15:06:01.502768: step 6310, loss = 0.73, batch loss = 0.45 (37.0 examples/sec; 0.216 sec/batch; 19h:34m:18s remains)
INFO - root - 2017-12-16 15:06:03.723989: step 6320, loss = 0.78, batch loss = 0.49 (36.4 examples/sec; 0.220 sec/batch; 19h:55m:58s remains)
INFO - root - 2017-12-16 15:06:05.925023: step 6330, loss = 0.76, batch loss = 0.47 (36.9 examples/sec; 0.217 sec/batch; 19h:38m:08s remains)
INFO - root - 2017-12-16 15:06:08.182519: step 6340, loss = 0.78, batch loss = 0.50 (35.5 examples/sec; 0.226 sec/batch; 20h:25m:54s remains)
INFO - root - 2017-12-16 15:06:10.365981: step 6350, loss = 0.77, batch loss = 0.48 (35.8 examples/sec; 0.224 sec/batch; 20h:15m:19s remains)
INFO - root - 2017-12-16 15:06:12.622430: step 6360, loss = 0.75, batch loss = 0.47 (36.1 examples/sec; 0.221 sec/batch; 20h:03m:11s remains)
INFO - root - 2017-12-16 15:06:14.828533: step 6370, loss = 0.75, batch loss = 0.46 (36.2 examples/sec; 0.221 sec/batch; 20h:02m:47s remains)
INFO - root - 2017-12-16 15:06:17.048614: step 6380, loss = 0.72, batch loss = 0.43 (37.3 examples/sec; 0.215 sec/batch; 19h:26m:31s remains)
INFO - root - 2017-12-16 15:06:19.260340: step 6390, loss = 0.83, batch loss = 0.55 (33.4 examples/sec; 0.239 sec/batch; 21h:40m:45s remains)
INFO - root - 2017-12-16 15:06:21.475823: step 6400, loss = 0.73, batch loss = 0.45 (36.7 examples/sec; 0.218 sec/batch; 19h:44m:25s remains)
INFO - root - 2017-12-16 15:06:23.804118: step 6410, loss = 0.80, batch loss = 0.51 (37.1 examples/sec; 0.216 sec/batch; 19h:31m:21s remains)
INFO - root - 2017-12-16 15:06:26.035119: step 6420, loss = 0.73, batch loss = 0.44 (34.7 examples/sec; 0.231 sec/batch; 20h:52m:48s remains)
INFO - root - 2017-12-16 15:06:28.261194: step 6430, loss = 0.70, batch loss = 0.42 (34.8 examples/sec; 0.230 sec/batch; 20h:50m:46s remains)
INFO - root - 2017-12-16 15:06:30.436020: step 6440, loss = 0.75, batch loss = 0.46 (37.1 examples/sec; 0.215 sec/batch; 19h:30m:41s remains)
INFO - root - 2017-12-16 15:06:32.637816: step 6450, loss = 0.80, batch loss = 0.51 (37.2 examples/sec; 0.215 sec/batch; 19h:30m:12s remains)
INFO - root - 2017-12-16 15:06:34.854014: step 6460, loss = 0.67, batch loss = 0.38 (36.9 examples/sec; 0.217 sec/batch; 19h:36m:36s remains)
INFO - root - 2017-12-16 15:06:37.094147: step 6470, loss = 0.69, batch loss = 0.41 (35.4 examples/sec; 0.226 sec/batch; 20h:28m:18s remains)
INFO - root - 2017-12-16 15:06:39.353490: step 6480, loss = 0.77, batch loss = 0.49 (35.9 examples/sec; 0.223 sec/batch; 20h:10m:37s remains)
INFO - root - 2017-12-16 15:06:41.575362: step 6490, loss = 0.70, batch loss = 0.41 (36.6 examples/sec; 0.218 sec/batch; 19h:46m:58s remains)
INFO - root - 2017-12-16 15:06:43.770927: step 6500, loss = 0.77, batch loss = 0.49 (37.8 examples/sec; 0.212 sec/batch; 19h:10m:43s remains)
INFO - root - 2017-12-16 15:06:46.122764: step 6510, loss = 0.80, batch loss = 0.52 (37.7 examples/sec; 0.212 sec/batch; 19h:11m:59s remains)
INFO - root - 2017-12-16 15:06:48.350629: step 6520, loss = 0.82, batch loss = 0.54 (35.0 examples/sec; 0.228 sec/batch; 20h:41m:04s remains)
INFO - root - 2017-12-16 15:06:50.565167: step 6530, loss = 0.71, batch loss = 0.42 (35.8 examples/sec; 0.224 sec/batch; 20h:15m:34s remains)
INFO - root - 2017-12-16 15:06:52.748463: step 6540, loss = 0.79, batch loss = 0.51 (37.2 examples/sec; 0.215 sec/batch; 19h:28m:35s remains)
INFO - root - 2017-12-16 15:06:54.990499: step 6550, loss = 0.77, batch loss = 0.48 (35.7 examples/sec; 0.224 sec/batch; 20h:17m:51s remains)
INFO - root - 2017-12-16 15:06:57.209112: step 6560, loss = 0.79, batch loss = 0.51 (37.4 examples/sec; 0.214 sec/batch; 19h:22m:56s remains)
INFO - root - 2017-12-16 15:06:59.409691: step 6570, loss = 0.70, batch loss = 0.42 (37.4 examples/sec; 0.214 sec/batch; 19h:22m:57s remains)
INFO - root - 2017-12-16 15:07:01.589048: step 6580, loss = 0.70, batch loss = 0.42 (36.7 examples/sec; 0.218 sec/batch; 19h:43m:39s remains)
INFO - root - 2017-12-16 15:07:03.801127: step 6590, loss = 0.77, batch loss = 0.49 (37.7 examples/sec; 0.212 sec/batch; 19h:12m:14s remains)
INFO - root - 2017-12-16 15:07:05.997967: step 6600, loss = 0.65, batch loss = 0.37 (38.7 examples/sec; 0.207 sec/batch; 18h:44m:04s remains)
INFO - root - 2017-12-16 15:07:08.329555: step 6610, loss = 0.76, batch loss = 0.48 (35.6 examples/sec; 0.225 sec/batch; 20h:19m:29s remains)
INFO - root - 2017-12-16 15:07:10.514361: step 6620, loss = 0.81, batch loss = 0.53 (37.0 examples/sec; 0.216 sec/batch; 19h:35m:13s remains)
INFO - root - 2017-12-16 15:07:12.705807: step 6630, loss = 0.70, batch loss = 0.42 (37.1 examples/sec; 0.216 sec/batch; 19h:31m:33s remains)
INFO - root - 2017-12-16 15:07:14.881743: step 6640, loss = 0.67, batch loss = 0.39 (35.9 examples/sec; 0.223 sec/batch; 20h:09m:01s remains)
INFO - root - 2017-12-16 15:07:17.123103: step 6650, loss = 0.68, batch loss = 0.40 (35.9 examples/sec; 0.223 sec/batch; 20h:10m:38s remains)
INFO - root - 2017-12-16 15:07:19.312576: step 6660, loss = 0.71, batch loss = 0.43 (37.5 examples/sec; 0.213 sec/batch; 19h:17m:07s remains)
INFO - root - 2017-12-16 15:07:21.501810: step 6670, loss = 0.74, batch loss = 0.46 (37.2 examples/sec; 0.215 sec/batch; 19h:28m:15s remains)
INFO - root - 2017-12-16 15:07:23.747039: step 6680, loss = 0.76, batch loss = 0.48 (34.9 examples/sec; 0.229 sec/batch; 20h:43m:41s remains)
INFO - root - 2017-12-16 15:07:25.946622: step 6690, loss = 0.70, batch loss = 0.43 (37.5 examples/sec; 0.213 sec/batch; 19h:16m:57s remains)
INFO - root - 2017-12-16 15:07:28.187243: step 6700, loss = 0.80, batch loss = 0.52 (36.3 examples/sec; 0.220 sec/batch; 19h:55m:57s remains)
INFO - root - 2017-12-16 15:07:30.598160: step 6710, loss = 0.74, batch loss = 0.46 (36.5 examples/sec; 0.219 sec/batch; 19h:49m:15s remains)
INFO - root - 2017-12-16 15:07:32.788514: step 6720, loss = 0.73, batch loss = 0.46 (37.0 examples/sec; 0.216 sec/batch; 19h:32m:56s remains)
INFO - root - 2017-12-16 15:07:35.032349: step 6730, loss = 0.78, batch loss = 0.51 (36.0 examples/sec; 0.222 sec/batch; 20h:07m:14s remains)
INFO - root - 2017-12-16 15:07:37.232448: step 6740, loss = 0.76, batch loss = 0.48 (36.2 examples/sec; 0.221 sec/batch; 19h:58m:19s remains)
INFO - root - 2017-12-16 15:07:39.423778: step 6750, loss = 0.75, batch loss = 0.47 (37.6 examples/sec; 0.213 sec/batch; 19h:14m:20s remains)
INFO - root - 2017-12-16 15:07:41.631576: step 6760, loss = 0.64, batch loss = 0.36 (34.5 examples/sec; 0.232 sec/batch; 20h:57m:38s remains)
INFO - root - 2017-12-16 15:07:43.832123: step 6770, loss = 0.70, batch loss = 0.42 (36.5 examples/sec; 0.219 sec/batch; 19h:48m:57s remains)
INFO - root - 2017-12-16 15:07:46.030184: step 6780, loss = 0.65, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 19h:58m:57s remains)
INFO - root - 2017-12-16 15:07:48.216504: step 6790, loss = 0.82, batch loss = 0.54 (36.5 examples/sec; 0.219 sec/batch; 19h:49m:53s remains)
INFO - root - 2017-12-16 15:07:50.441344: step 6800, loss = 0.72, batch loss = 0.44 (37.2 examples/sec; 0.215 sec/batch; 19h:28m:16s remains)
INFO - root - 2017-12-16 15:07:52.800007: step 6810, loss = 0.74, batch loss = 0.47 (35.1 examples/sec; 0.228 sec/batch; 20h:37m:08s remains)
INFO - root - 2017-12-16 15:07:55.003468: step 6820, loss = 0.71, batch loss = 0.44 (37.0 examples/sec; 0.216 sec/batch; 19h:33m:25s remains)
INFO - root - 2017-12-16 15:07:57.226514: step 6830, loss = 0.66, batch loss = 0.38 (37.3 examples/sec; 0.215 sec/batch; 19h:24m:57s remains)
INFO - root - 2017-12-16 15:07:59.413702: step 6840, loss = 0.68, batch loss = 0.40 (37.3 examples/sec; 0.214 sec/batch; 19h:24m:02s remains)
INFO - root - 2017-12-16 15:08:01.645978: step 6850, loss = 0.84, batch loss = 0.57 (37.2 examples/sec; 0.215 sec/batch; 19h:27m:21s remains)
INFO - root - 2017-12-16 15:08:03.863748: step 6860, loss = 0.76, batch loss = 0.48 (35.4 examples/sec; 0.226 sec/batch; 20h:24m:58s remains)
INFO - root - 2017-12-16 15:08:06.081914: step 6870, loss = 0.69, batch loss = 0.42 (37.5 examples/sec; 0.213 sec/batch; 19h:18m:33s remains)
INFO - root - 2017-12-16 15:08:08.307816: step 6880, loss = 0.74, batch loss = 0.47 (35.1 examples/sec; 0.228 sec/batch; 20h:35m:28s remains)
INFO - root - 2017-12-16 15:08:10.472616: step 6890, loss = 0.70, batch loss = 0.43 (36.9 examples/sec; 0.217 sec/batch; 19h:36m:03s remains)
INFO - root - 2017-12-16 15:08:12.691114: step 6900, loss = 0.72, batch loss = 0.45 (36.4 examples/sec; 0.220 sec/batch; 19h:52m:36s remains)
INFO - root - 2017-12-16 15:08:15.034975: step 6910, loss = 0.67, batch loss = 0.40 (36.3 examples/sec; 0.220 sec/batch; 19h:56m:01s remains)
INFO - root - 2017-12-16 15:08:17.243693: step 6920, loss = 0.66, batch loss = 0.39 (37.0 examples/sec; 0.216 sec/batch; 19h:34m:27s remains)
INFO - root - 2017-12-16 15:08:19.411886: step 6930, loss = 0.63, batch loss = 0.36 (37.8 examples/sec; 0.211 sec/batch; 19h:07m:25s remains)
INFO - root - 2017-12-16 15:08:21.591142: step 6940, loss = 0.72, batch loss = 0.44 (37.0 examples/sec; 0.216 sec/batch; 19h:32m:19s remains)
INFO - root - 2017-12-16 15:08:23.827273: step 6950, loss = 0.70, batch loss = 0.43 (37.0 examples/sec; 0.216 sec/batch; 19h:32m:37s remains)
INFO - root - 2017-12-16 15:08:26.083480: step 6960, loss = 0.60, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 20h:19m:12s remains)
INFO - root - 2017-12-16 15:08:28.317013: step 6970, loss = 0.80, batch loss = 0.53 (34.4 examples/sec; 0.232 sec/batch; 21h:00m:03s remains)
INFO - root - 2017-12-16 15:08:30.521392: step 6980, loss = 0.71, batch loss = 0.44 (35.6 examples/sec; 0.225 sec/batch; 20h:19m:15s remains)
INFO - root - 2017-12-16 15:08:32.756186: step 6990, loss = 0.70, batch loss = 0.43 (35.2 examples/sec; 0.227 sec/batch; 20h:31m:35s remains)
INFO - root - 2017-12-16 15:08:34.985883: step 7000, loss = 0.76, batch loss = 0.49 (35.9 examples/sec; 0.223 sec/batch; 20h:09m:59s remains)
INFO - root - 2017-12-16 15:08:37.307546: step 7010, loss = 0.67, batch loss = 0.40 (35.9 examples/sec; 0.223 sec/batch; 20h:10m:25s remains)
INFO - root - 2017-12-16 15:08:39.542281: step 7020, loss = 0.70, batch loss = 0.43 (36.3 examples/sec; 0.220 sec/batch; 19h:55m:41s remains)
INFO - root - 2017-12-16 15:08:41.721129: step 7030, loss = 0.76, batch loss = 0.49 (37.4 examples/sec; 0.214 sec/batch; 19h:21m:37s remains)
INFO - root - 2017-12-16 15:08:43.912239: step 7040, loss = 0.71, batch loss = 0.44 (36.4 examples/sec; 0.220 sec/batch; 19h:51m:02s remains)
INFO - root - 2017-12-16 15:08:46.106799: step 7050, loss = 0.73, batch loss = 0.47 (37.1 examples/sec; 0.216 sec/batch; 19h:30m:07s remains)
INFO - root - 2017-12-16 15:08:48.340603: step 7060, loss = 0.71, batch loss = 0.44 (36.4 examples/sec; 0.220 sec/batch; 19h:51m:12s remains)
INFO - root - 2017-12-16 15:08:50.548279: step 7070, loss = 0.70, batch loss = 0.43 (35.9 examples/sec; 0.223 sec/batch; 20h:07m:40s remains)
INFO - root - 2017-12-16 15:08:52.813047: step 7080, loss = 0.78, batch loss = 0.51 (33.5 examples/sec; 0.239 sec/batch; 21h:34m:00s remains)
INFO - root - 2017-12-16 15:08:55.012065: step 7090, loss = 0.67, batch loss = 0.40 (36.4 examples/sec; 0.220 sec/batch; 19h:52m:41s remains)
INFO - root - 2017-12-16 15:08:57.205446: step 7100, loss = 0.71, batch loss = 0.44 (35.1 examples/sec; 0.228 sec/batch; 20h:34m:32s remains)
INFO - root - 2017-12-16 15:08:59.512323: step 7110, loss = 0.73, batch loss = 0.47 (37.8 examples/sec; 0.212 sec/batch; 19h:07m:30s remains)
INFO - root - 2017-12-16 15:09:01.750010: step 7120, loss = 0.72, batch loss = 0.45 (37.1 examples/sec; 0.216 sec/batch; 19h:30m:33s remains)
INFO - root - 2017-12-16 15:09:03.942044: step 7130, loss = 0.69, batch loss = 0.42 (36.8 examples/sec; 0.218 sec/batch; 19h:39m:42s remains)
INFO - root - 2017-12-16 15:09:06.149961: step 7140, loss = 0.72, batch loss = 0.45 (36.1 examples/sec; 0.222 sec/batch; 20h:02m:27s remains)
INFO - root - 2017-12-16 15:09:08.380825: step 7150, loss = 0.81, batch loss = 0.55 (36.5 examples/sec; 0.219 sec/batch; 19h:49m:55s remains)
INFO - root - 2017-12-16 15:09:10.584472: step 7160, loss = 0.67, batch loss = 0.41 (36.2 examples/sec; 0.221 sec/batch; 19h:58m:13s remains)
INFO - root - 2017-12-16 15:09:12.790459: step 7170, loss = 0.73, batch loss = 0.46 (37.7 examples/sec; 0.212 sec/batch; 19h:09m:51s remains)
INFO - root - 2017-12-16 15:09:15.020551: step 7180, loss = 0.68, batch loss = 0.42 (36.0 examples/sec; 0.222 sec/batch; 20h:05m:06s remains)
INFO - root - 2017-12-16 15:09:17.221928: step 7190, loss = 0.72, batch loss = 0.45 (35.4 examples/sec; 0.226 sec/batch; 20h:26m:28s remains)
INFO - root - 2017-12-16 15:09:19.451669: step 7200, loss = 0.69, batch loss = 0.42 (34.4 examples/sec; 0.233 sec/batch; 21h:01m:28s remains)
INFO - root - 2017-12-16 15:09:21.831353: step 7210, loss = 0.67, batch loss = 0.41 (36.2 examples/sec; 0.221 sec/batch; 19h:57m:22s remains)
INFO - root - 2017-12-16 15:09:24.078609: step 7220, loss = 0.71, batch loss = 0.44 (35.9 examples/sec; 0.223 sec/batch; 20h:09m:02s remains)
INFO - root - 2017-12-16 15:09:26.271732: step 7230, loss = 0.74, batch loss = 0.47 (36.3 examples/sec; 0.220 sec/batch; 19h:55m:21s remains)
INFO - root - 2017-12-16 15:09:28.469436: step 7240, loss = 0.77, batch loss = 0.50 (37.7 examples/sec; 0.212 sec/batch; 19h:09m:35s remains)
INFO - root - 2017-12-16 15:09:30.661303: step 7250, loss = 0.69, batch loss = 0.43 (37.3 examples/sec; 0.215 sec/batch; 19h:23m:01s remains)
INFO - root - 2017-12-16 15:09:32.863949: step 7260, loss = 0.75, batch loss = 0.49 (35.8 examples/sec; 0.223 sec/batch; 20h:10m:48s remains)
INFO - root - 2017-12-16 15:09:35.075945: step 7270, loss = 0.69, batch loss = 0.43 (35.2 examples/sec; 0.227 sec/batch; 20h:30m:48s remains)
INFO - root - 2017-12-16 15:09:37.256567: step 7280, loss = 0.72, batch loss = 0.46 (36.4 examples/sec; 0.220 sec/batch; 19h:51m:59s remains)
INFO - root - 2017-12-16 15:09:39.447720: step 7290, loss = 0.68, batch loss = 0.41 (37.8 examples/sec; 0.212 sec/batch; 19h:08m:37s remains)
INFO - root - 2017-12-16 15:09:41.629625: step 7300, loss = 0.72, batch loss = 0.45 (36.9 examples/sec; 0.217 sec/batch; 19h:36m:35s remains)
INFO - root - 2017-12-16 15:09:43.982296: step 7310, loss = 0.81, batch loss = 0.55 (35.2 examples/sec; 0.227 sec/batch; 20h:32m:00s remains)
INFO - root - 2017-12-16 15:09:46.217017: step 7320, loss = 0.70, batch loss = 0.44 (35.8 examples/sec; 0.224 sec/batch; 20h:12m:08s remains)
INFO - root - 2017-12-16 15:09:48.416078: step 7330, loss = 0.72, batch loss = 0.46 (35.9 examples/sec; 0.223 sec/batch; 20h:08m:12s remains)
INFO - root - 2017-12-16 15:09:50.613584: step 7340, loss = 0.74, batch loss = 0.48 (35.5 examples/sec; 0.225 sec/batch; 20h:21m:29s remains)
INFO - root - 2017-12-16 15:09:52.811138: step 7350, loss = 0.69, batch loss = 0.43 (35.5 examples/sec; 0.225 sec/batch; 20h:20m:42s remains)
INFO - root - 2017-12-16 15:09:54.993442: step 7360, loss = 0.71, batch loss = 0.45 (36.2 examples/sec; 0.221 sec/batch; 19h:56m:16s remains)
INFO - root - 2017-12-16 15:09:57.207382: step 7370, loss = 0.73, batch loss = 0.47 (35.9 examples/sec; 0.223 sec/batch; 20h:06m:26s remains)
INFO - root - 2017-12-16 15:09:59.433361: step 7380, loss = 0.67, batch loss = 0.41 (35.2 examples/sec; 0.227 sec/batch; 20h:30m:39s remains)
INFO - root - 2017-12-16 15:10:01.664823: step 7390, loss = 0.77, batch loss = 0.51 (37.0 examples/sec; 0.216 sec/batch; 19h:32m:26s remains)
INFO - root - 2017-12-16 15:10:03.865022: step 7400, loss = 0.70, batch loss = 0.44 (36.7 examples/sec; 0.218 sec/batch; 19h:42m:18s remains)
INFO - root - 2017-12-16 15:10:06.239549: step 7410, loss = 0.70, batch loss = 0.44 (36.0 examples/sec; 0.222 sec/batch; 20h:05m:31s remains)
INFO - root - 2017-12-16 15:10:08.451274: step 7420, loss = 0.64, batch loss = 0.39 (35.8 examples/sec; 0.223 sec/batch; 20h:10m:55s remains)
INFO - root - 2017-12-16 15:10:10.681249: step 7430, loss = 0.75, batch loss = 0.49 (35.5 examples/sec; 0.226 sec/batch; 20h:22m:05s remains)
INFO - root - 2017-12-16 15:10:12.865726: step 7440, loss = 0.71, batch loss = 0.45 (37.1 examples/sec; 0.216 sec/batch; 19h:28m:46s remains)
INFO - root - 2017-12-16 15:10:15.064184: step 7450, loss = 0.80, batch loss = 0.54 (36.6 examples/sec; 0.218 sec/batch; 19h:42m:59s remains)
INFO - root - 2017-12-16 15:10:17.275765: step 7460, loss = 0.72, batch loss = 0.47 (36.5 examples/sec; 0.219 sec/batch; 19h:48m:58s remains)
INFO - root - 2017-12-16 15:10:19.499893: step 7470, loss = 0.60, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 19h:36m:23s remains)
INFO - root - 2017-12-16 15:10:21.709035: step 7480, loss = 0.75, batch loss = 0.49 (36.1 examples/sec; 0.222 sec/batch; 20h:01m:36s remains)
INFO - root - 2017-12-16 15:10:23.958997: step 7490, loss = 0.72, batch loss = 0.46 (35.9 examples/sec; 0.223 sec/batch; 20h:05m:50s remains)
INFO - root - 2017-12-16 15:10:26.138012: step 7500, loss = 0.68, batch loss = 0.42 (37.1 examples/sec; 0.216 sec/batch; 19h:28m:09s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-7500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-7500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 15:10:28.974004: step 7510, loss = 0.72, batch loss = 0.47 (35.7 examples/sec; 0.224 sec/batch; 20h:13m:57s remains)
INFO - root - 2017-12-16 15:10:31.211868: step 7520, loss = 0.68, batch loss = 0.43 (36.4 examples/sec; 0.220 sec/batch; 19h:48m:59s remains)
INFO - root - 2017-12-16 15:10:33.406531: step 7530, loss = 0.59, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 20h:31m:42s remains)
INFO - root - 2017-12-16 15:10:35.587840: step 7540, loss = 0.69, batch loss = 0.44 (35.2 examples/sec; 0.227 sec/batch; 20h:31m:38s remains)
INFO - root - 2017-12-16 15:10:37.801304: step 7550, loss = 0.59, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 20h:13m:24s remains)
INFO - root - 2017-12-16 15:10:40.020014: step 7560, loss = 0.69, batch loss = 0.44 (36.8 examples/sec; 0.218 sec/batch; 19h:38m:40s remains)
INFO - root - 2017-12-16 15:10:42.234103: step 7570, loss = 0.69, batch loss = 0.44 (37.6 examples/sec; 0.213 sec/batch; 19h:11m:37s remains)
INFO - root - 2017-12-16 15:10:44.475911: step 7580, loss = 0.72, batch loss = 0.47 (36.2 examples/sec; 0.221 sec/batch; 19h:57m:01s remains)
INFO - root - 2017-12-16 15:10:46.686119: step 7590, loss = 0.71, batch loss = 0.46 (35.1 examples/sec; 0.228 sec/batch; 20h:32m:59s remains)
INFO - root - 2017-12-16 15:10:48.908748: step 7600, loss = 0.72, batch loss = 0.46 (36.3 examples/sec; 0.220 sec/batch; 19h:51m:48s remains)
INFO - root - 2017-12-16 15:10:51.239769: step 7610, loss = 0.73, batch loss = 0.47 (34.1 examples/sec; 0.235 sec/batch; 21h:11m:07s remains)
INFO - root - 2017-12-16 15:10:53.454004: step 7620, loss = 0.63, batch loss = 0.37 (36.9 examples/sec; 0.217 sec/batch; 19h:33m:49s remains)
INFO - root - 2017-12-16 15:10:55.664991: step 7630, loss = 0.70, batch loss = 0.44 (35.3 examples/sec; 0.226 sec/batch; 20h:26m:13s remains)
INFO - root - 2017-12-16 15:10:57.870090: step 7640, loss = 0.69, batch loss = 0.43 (35.4 examples/sec; 0.226 sec/batch; 20h:24m:57s remains)
INFO - root - 2017-12-16 15:11:00.073568: step 7650, loss = 0.69, batch loss = 0.44 (37.4 examples/sec; 0.214 sec/batch; 19h:17m:06s remains)
INFO - root - 2017-12-16 15:11:02.274892: step 7660, loss = 0.71, batch loss = 0.46 (35.7 examples/sec; 0.224 sec/batch; 20h:12m:34s remains)
INFO - root - 2017-12-16 15:11:04.467875: step 7670, loss = 0.72, batch loss = 0.47 (36.0 examples/sec; 0.222 sec/batch; 20h:01m:49s remains)
INFO - root - 2017-12-16 15:11:06.656621: step 7680, loss = 0.71, batch loss = 0.46 (36.5 examples/sec; 0.219 sec/batch; 19h:45m:27s remains)
INFO - root - 2017-12-16 15:11:08.941703: step 7690, loss = 0.64, batch loss = 0.39 (34.3 examples/sec; 0.233 sec/batch; 21h:02m:16s remains)
INFO - root - 2017-12-16 15:11:11.170945: step 7700, loss = 0.75, batch loss = 0.50 (36.1 examples/sec; 0.222 sec/batch; 20h:01m:04s remains)
INFO - root - 2017-12-16 15:11:13.537893: step 7710, loss = 0.72, batch loss = 0.47 (37.9 examples/sec; 0.211 sec/batch; 19h:03m:46s remains)
INFO - root - 2017-12-16 15:11:15.732029: step 7720, loss = 0.75, batch loss = 0.49 (36.7 examples/sec; 0.218 sec/batch; 19h:39m:12s remains)
INFO - root - 2017-12-16 15:11:17.970501: step 7730, loss = 0.71, batch loss = 0.45 (34.2 examples/sec; 0.234 sec/batch; 21h:04m:26s remains)
INFO - root - 2017-12-16 15:11:20.161840: step 7740, loss = 0.77, batch loss = 0.52 (37.4 examples/sec; 0.214 sec/batch; 19h:19m:00s remains)
INFO - root - 2017-12-16 15:11:22.391471: step 7750, loss = 0.75, batch loss = 0.50 (34.5 examples/sec; 0.232 sec/batch; 20h:54m:45s remains)
INFO - root - 2017-12-16 15:11:24.632085: step 7760, loss = 0.68, batch loss = 0.43 (34.5 examples/sec; 0.232 sec/batch; 20h:54m:10s remains)
INFO - root - 2017-12-16 15:11:26.792462: step 7770, loss = 0.69, batch loss = 0.44 (35.5 examples/sec; 0.226 sec/batch; 20h:20m:45s remains)
INFO - root - 2017-12-16 15:11:29.007110: step 7780, loss = 0.69, batch loss = 0.44 (35.7 examples/sec; 0.224 sec/batch; 20h:13m:01s remains)
INFO - root - 2017-12-16 15:11:31.217726: step 7790, loss = 0.65, batch loss = 0.40 (37.4 examples/sec; 0.214 sec/batch; 19h:16m:26s remains)
INFO - root - 2017-12-16 15:11:33.427187: step 7800, loss = 0.70, batch loss = 0.45 (37.2 examples/sec; 0.215 sec/batch; 19h:24m:02s remains)
INFO - root - 2017-12-16 15:11:35.781020: step 7810, loss = 0.69, batch loss = 0.44 (35.7 examples/sec; 0.224 sec/batch; 20h:11m:26s remains)
INFO - root - 2017-12-16 15:11:37.972839: step 7820, loss = 0.72, batch loss = 0.47 (36.1 examples/sec; 0.222 sec/batch; 19h:58m:54s remains)
INFO - root - 2017-12-16 15:11:40.146417: step 7830, loss = 0.70, batch loss = 0.46 (38.1 examples/sec; 0.210 sec/batch; 18h:56m:25s remains)
INFO - root - 2017-12-16 15:11:42.372481: step 7840, loss = 0.65, batch loss = 0.40 (35.6 examples/sec; 0.224 sec/batch; 20h:14m:27s remains)
INFO - root - 2017-12-16 15:11:44.568425: step 7850, loss = 0.70, batch loss = 0.45 (36.7 examples/sec; 0.218 sec/batch; 19h:41m:01s remains)
INFO - root - 2017-12-16 15:11:46.802769: step 7860, loss = 0.67, batch loss = 0.42 (36.9 examples/sec; 0.217 sec/batch; 19h:31m:55s remains)
INFO - root - 2017-12-16 15:11:49.026400: step 7870, loss = 0.70, batch loss = 0.45 (35.2 examples/sec; 0.227 sec/batch; 20h:30m:10s remains)
INFO - root - 2017-12-16 15:11:51.244016: step 7880, loss = 0.74, batch loss = 0.49 (36.2 examples/sec; 0.221 sec/batch; 19h:54m:01s remains)
INFO - root - 2017-12-16 15:11:53.477649: step 7890, loss = 0.71, batch loss = 0.46 (34.4 examples/sec; 0.233 sec/batch; 20h:58m:54s remains)
INFO - root - 2017-12-16 15:11:55.687796: step 7900, loss = 0.64, batch loss = 0.39 (36.2 examples/sec; 0.221 sec/batch; 19h:56m:12s remains)
INFO - root - 2017-12-16 15:11:58.028779: step 7910, loss = 0.66, batch loss = 0.41 (36.7 examples/sec; 0.218 sec/batch; 19h:37m:56s remains)
INFO - root - 2017-12-16 15:12:00.213835: step 7920, loss = 0.70, batch loss = 0.45 (37.2 examples/sec; 0.215 sec/batch; 19h:24m:48s remains)
INFO - root - 2017-12-16 15:12:02.468141: step 7930, loss = 0.69, batch loss = 0.45 (33.9 examples/sec; 0.236 sec/batch; 21h:14m:43s remains)
INFO - root - 2017-12-16 15:12:04.683102: step 7940, loss = 0.67, batch loss = 0.42 (35.0 examples/sec; 0.229 sec/batch; 20h:36m:06s remains)
INFO - root - 2017-12-16 15:12:06.910562: step 7950, loss = 0.68, batch loss = 0.43 (36.7 examples/sec; 0.218 sec/batch; 19h:38m:59s remains)
INFO - root - 2017-12-16 15:12:09.155720: step 7960, loss = 0.63, batch loss = 0.38 (35.2 examples/sec; 0.227 sec/batch; 20h:30m:09s remains)
INFO - root - 2017-12-16 15:12:11.339698: step 7970, loss = 0.75, batch loss = 0.50 (37.1 examples/sec; 0.215 sec/batch; 19h:25m:30s remains)
INFO - root - 2017-12-16 15:12:13.593574: step 7980, loss = 0.73, batch loss = 0.48 (35.8 examples/sec; 0.224 sec/batch; 20h:09m:21s remains)
INFO - root - 2017-12-16 15:12:15.802765: step 7990, loss = 0.61, batch loss = 0.37 (37.3 examples/sec; 0.214 sec/batch; 19h:18m:42s remains)
INFO - root - 2017-12-16 15:12:17.985589: step 8000, loss = 0.58, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 19h:39m:29s remains)
INFO - root - 2017-12-16 15:12:20.354155: step 8010, loss = 0.74, batch loss = 0.50 (34.9 examples/sec; 0.229 sec/batch; 20h:38m:34s remains)
INFO - root - 2017-12-16 15:12:22.548771: step 8020, loss = 0.65, batch loss = 0.40 (36.1 examples/sec; 0.222 sec/batch; 19h:58m:36s remains)
INFO - root - 2017-12-16 15:12:24.782310: step 8030, loss = 0.68, batch loss = 0.43 (37.2 examples/sec; 0.215 sec/batch; 19h:21m:26s remains)
INFO - root - 2017-12-16 15:12:27.019273: step 8040, loss = 0.70, batch loss = 0.46 (35.8 examples/sec; 0.224 sec/batch; 20h:08m:41s remains)
INFO - root - 2017-12-16 15:12:29.255844: step 8050, loss = 0.66, batch loss = 0.42 (34.1 examples/sec; 0.234 sec/batch; 21h:07m:44s remains)
INFO - root - 2017-12-16 15:12:31.477722: step 8060, loss = 0.60, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 19h:44m:15s remains)
INFO - root - 2017-12-16 15:12:33.717192: step 8070, loss = 0.66, batch loss = 0.42 (36.4 examples/sec; 0.220 sec/batch; 19h:48m:02s remains)
INFO - root - 2017-12-16 15:12:35.937878: step 8080, loss = 0.78, batch loss = 0.54 (36.8 examples/sec; 0.218 sec/batch; 19h:36m:57s remains)
INFO - root - 2017-12-16 15:12:38.144646: step 8090, loss = 0.70, batch loss = 0.46 (35.7 examples/sec; 0.224 sec/batch; 20h:12m:28s remains)
INFO - root - 2017-12-16 15:12:40.383780: step 8100, loss = 0.69, batch loss = 0.45 (35.2 examples/sec; 0.227 sec/batch; 20h:27m:21s remains)
INFO - root - 2017-12-16 15:12:42.731225: step 8110, loss = 0.67, batch loss = 0.43 (36.9 examples/sec; 0.217 sec/batch; 19h:31m:09s remains)
INFO - root - 2017-12-16 15:12:44.969367: step 8120, loss = 0.71, batch loss = 0.47 (35.9 examples/sec; 0.223 sec/batch; 20h:03m:05s remains)
INFO - root - 2017-12-16 15:12:47.198007: step 8130, loss = 0.66, batch loss = 0.41 (35.0 examples/sec; 0.229 sec/batch; 20h:36m:14s remains)
INFO - root - 2017-12-16 15:12:49.404812: step 8140, loss = 0.65, batch loss = 0.41 (36.1 examples/sec; 0.222 sec/batch; 19h:57m:50s remains)
INFO - root - 2017-12-16 15:12:51.653125: step 8150, loss = 0.66, batch loss = 0.42 (34.4 examples/sec; 0.232 sec/batch; 20h:55m:51s remains)
INFO - root - 2017-12-16 15:12:53.845462: step 8160, loss = 0.64, batch loss = 0.40 (36.8 examples/sec; 0.218 sec/batch; 19h:36m:07s remains)
INFO - root - 2017-12-16 15:12:56.044866: step 8170, loss = 0.73, batch loss = 0.49 (37.2 examples/sec; 0.215 sec/batch; 19h:21m:13s remains)
INFO - root - 2017-12-16 15:12:58.215374: step 8180, loss = 0.66, batch loss = 0.42 (37.6 examples/sec; 0.213 sec/batch; 19h:10m:41s remains)
INFO - root - 2017-12-16 15:13:00.427790: step 8190, loss = 0.62, batch loss = 0.38 (35.7 examples/sec; 0.224 sec/batch; 20h:12m:49s remains)
INFO - root - 2017-12-16 15:13:02.654138: step 8200, loss = 0.65, batch loss = 0.41 (35.7 examples/sec; 0.224 sec/batch; 20h:11m:06s remains)
INFO - root - 2017-12-16 15:13:04.988034: step 8210, loss = 0.66, batch loss = 0.42 (36.0 examples/sec; 0.222 sec/batch; 20h:01m:37s remains)
INFO - root - 2017-12-16 15:13:07.241009: step 8220, loss = 0.67, batch loss = 0.43 (35.7 examples/sec; 0.224 sec/batch; 20h:11m:38s remains)
INFO - root - 2017-12-16 15:13:09.475690: step 8230, loss = 0.68, batch loss = 0.44 (36.4 examples/sec; 0.220 sec/batch; 19h:47m:55s remains)
INFO - root - 2017-12-16 15:13:11.693648: step 8240, loss = 0.62, batch loss = 0.38 (34.6 examples/sec; 0.231 sec/batch; 20h:50m:34s remains)
INFO - root - 2017-12-16 15:13:13.944066: step 8250, loss = 0.64, batch loss = 0.41 (36.1 examples/sec; 0.222 sec/batch; 19h:58m:12s remains)
INFO - root - 2017-12-16 15:13:16.169091: step 8260, loss = 0.65, batch loss = 0.41 (36.1 examples/sec; 0.222 sec/batch; 19h:59m:09s remains)
INFO - root - 2017-12-16 15:13:18.417111: step 8270, loss = 0.63, batch loss = 0.39 (36.5 examples/sec; 0.219 sec/batch; 19h:44m:13s remains)
INFO - root - 2017-12-16 15:13:20.627263: step 8280, loss = 0.59, batch loss = 0.35 (34.8 examples/sec; 0.230 sec/batch; 20h:41m:15s remains)
INFO - root - 2017-12-16 15:13:22.827222: step 8290, loss = 0.62, batch loss = 0.38 (36.1 examples/sec; 0.222 sec/batch; 19h:57m:33s remains)
INFO - root - 2017-12-16 15:13:25.055481: step 8300, loss = 0.74, batch loss = 0.50 (36.0 examples/sec; 0.222 sec/batch; 20h:01m:34s remains)
INFO - root - 2017-12-16 15:13:27.413541: step 8310, loss = 0.64, batch loss = 0.41 (36.4 examples/sec; 0.220 sec/batch; 19h:46m:45s remains)
INFO - root - 2017-12-16 15:13:29.647255: step 8320, loss = 0.63, batch loss = 0.39 (36.2 examples/sec; 0.221 sec/batch; 19h:54m:58s remains)
INFO - root - 2017-12-16 15:13:31.847354: step 8330, loss = 0.72, batch loss = 0.48 (34.9 examples/sec; 0.229 sec/batch; 20h:36m:53s remains)
INFO - root - 2017-12-16 15:13:34.047602: step 8340, loss = 0.63, batch loss = 0.40 (35.7 examples/sec; 0.224 sec/batch; 20h:11m:29s remains)
INFO - root - 2017-12-16 15:13:36.266632: step 8350, loss = 0.61, batch loss = 0.38 (35.1 examples/sec; 0.228 sec/batch; 20h:30m:14s remains)
INFO - root - 2017-12-16 15:13:38.474226: step 8360, loss = 0.70, batch loss = 0.46 (36.6 examples/sec; 0.219 sec/batch; 19h:42m:24s remains)
INFO - root - 2017-12-16 15:13:40.657447: step 8370, loss = 0.71, batch loss = 0.47 (37.3 examples/sec; 0.215 sec/batch; 19h:19m:27s remains)
INFO - root - 2017-12-16 15:13:42.896792: step 8380, loss = 0.63, batch loss = 0.40 (37.2 examples/sec; 0.215 sec/batch; 19h:21m:44s remains)
INFO - root - 2017-12-16 15:13:45.127898: step 8390, loss = 0.61, batch loss = 0.38 (32.1 examples/sec; 0.249 sec/batch; 22h:25m:48s remains)
INFO - root - 2017-12-16 15:13:47.323349: step 8400, loss = 0.70, batch loss = 0.47 (34.8 examples/sec; 0.230 sec/batch; 20h:42m:04s remains)
INFO - root - 2017-12-16 15:13:49.677870: step 8410, loss = 0.66, batch loss = 0.43 (36.3 examples/sec; 0.220 sec/batch; 19h:49m:08s remains)
INFO - root - 2017-12-16 15:13:51.873558: step 8420, loss = 0.69, batch loss = 0.46 (35.4 examples/sec; 0.226 sec/batch; 20h:20m:40s remains)
INFO - root - 2017-12-16 15:13:54.075568: step 8430, loss = 0.64, batch loss = 0.41 (37.0 examples/sec; 0.216 sec/batch; 19h:27m:07s remains)
INFO - root - 2017-12-16 15:13:56.305305: step 8440, loss = 0.66, batch loss = 0.42 (35.4 examples/sec; 0.226 sec/batch; 20h:19m:31s remains)
INFO - root - 2017-12-16 15:13:58.542713: step 8450, loss = 0.60, batch loss = 0.37 (36.0 examples/sec; 0.222 sec/batch; 20h:01m:37s remains)
INFO - root - 2017-12-16 15:14:00.769213: step 8460, loss = 0.58, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 19h:43m:48s remains)
INFO - root - 2017-12-16 15:14:03.011676: step 8470, loss = 0.71, batch loss = 0.48 (34.6 examples/sec; 0.231 sec/batch; 20h:49m:11s remains)
INFO - root - 2017-12-16 15:14:05.196137: step 8480, loss = 0.57, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 20h:02m:10s remains)
INFO - root - 2017-12-16 15:14:07.396405: step 8490, loss = 0.64, batch loss = 0.40 (33.1 examples/sec; 0.242 sec/batch; 21h:44m:47s remains)
INFO - root - 2017-12-16 15:14:09.653906: step 8500, loss = 0.70, batch loss = 0.47 (36.0 examples/sec; 0.222 sec/batch; 20h:01m:19s remains)
INFO - root - 2017-12-16 15:14:12.035095: step 8510, loss = 0.62, batch loss = 0.39 (36.2 examples/sec; 0.221 sec/batch; 19h:53m:57s remains)
INFO - root - 2017-12-16 15:14:14.274292: step 8520, loss = 0.61, batch loss = 0.38 (36.6 examples/sec; 0.219 sec/batch; 19h:40m:55s remains)
INFO - root - 2017-12-16 15:14:16.462529: step 8530, loss = 0.67, batch loss = 0.44 (36.2 examples/sec; 0.221 sec/batch; 19h:52m:42s remains)
INFO - root - 2017-12-16 15:14:18.648919: step 8540, loss = 0.59, batch loss = 0.36 (37.3 examples/sec; 0.215 sec/batch; 19h:19m:01s remains)
INFO - root - 2017-12-16 15:14:20.872989: step 8550, loss = 0.67, batch loss = 0.44 (35.0 examples/sec; 0.228 sec/batch; 20h:32m:31s remains)
INFO - root - 2017-12-16 15:14:23.073159: step 8560, loss = 0.66, batch loss = 0.43 (36.1 examples/sec; 0.222 sec/batch; 19h:56m:03s remains)
INFO - root - 2017-12-16 15:14:25.272118: step 8570, loss = 0.60, batch loss = 0.37 (36.1 examples/sec; 0.222 sec/batch; 19h:55m:52s remains)
INFO - root - 2017-12-16 15:14:27.451464: step 8580, loss = 0.62, batch loss = 0.39 (37.2 examples/sec; 0.215 sec/batch; 19h:20m:18s remains)
INFO - root - 2017-12-16 15:14:29.661248: step 8590, loss = 0.59, batch loss = 0.36 (37.8 examples/sec; 0.212 sec/batch; 19h:03m:27s remains)
INFO - root - 2017-12-16 15:14:31.858622: step 8600, loss = 0.61, batch loss = 0.38 (37.0 examples/sec; 0.216 sec/batch; 19h:27m:32s remains)
INFO - root - 2017-12-16 15:14:34.203317: step 8610, loss = 0.61, batch loss = 0.38 (35.5 examples/sec; 0.225 sec/batch; 20h:16m:30s remains)
INFO - root - 2017-12-16 15:14:36.425542: step 8620, loss = 0.57, batch loss = 0.34 (37.8 examples/sec; 0.212 sec/batch; 19h:02m:31s remains)
INFO - root - 2017-12-16 15:14:38.643899: step 8630, loss = 0.59, batch loss = 0.36 (35.1 examples/sec; 0.228 sec/batch; 20h:29m:22s remains)
INFO - root - 2017-12-16 15:14:40.846569: step 8640, loss = 0.62, batch loss = 0.39 (36.5 examples/sec; 0.219 sec/batch; 19h:42m:40s remains)
INFO - root - 2017-12-16 15:14:43.065203: step 8650, loss = 0.58, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 19h:45m:35s remains)
INFO - root - 2017-12-16 15:14:45.316428: step 8660, loss = 0.65, batch loss = 0.42 (35.7 examples/sec; 0.224 sec/batch; 20h:08m:11s remains)
INFO - root - 2017-12-16 15:14:47.533743: step 8670, loss = 0.73, batch loss = 0.50 (36.8 examples/sec; 0.217 sec/batch; 19h:32m:58s remains)
INFO - root - 2017-12-16 15:14:49.811467: step 8680, loss = 0.64, batch loss = 0.41 (30.6 examples/sec; 0.261 sec/batch; 23h:29m:44s remains)
INFO - root - 2017-12-16 15:14:52.028820: step 8690, loss = 0.59, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 19h:43m:02s remains)
INFO - root - 2017-12-16 15:14:54.268955: step 8700, loss = 0.56, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 19h:49m:04s remains)
INFO - root - 2017-12-16 15:14:56.634300: step 8710, loss = 0.61, batch loss = 0.38 (37.4 examples/sec; 0.214 sec/batch; 19h:13m:31s remains)
INFO - root - 2017-12-16 15:14:58.851751: step 8720, loss = 0.67, batch loss = 0.44 (36.1 examples/sec; 0.222 sec/batch; 19h:55m:49s remains)
INFO - root - 2017-12-16 15:15:01.087203: step 8730, loss = 0.64, batch loss = 0.41 (35.6 examples/sec; 0.225 sec/batch; 20h:12m:09s remains)
INFO - root - 2017-12-16 15:15:03.314401: step 8740, loss = 0.76, batch loss = 0.54 (35.0 examples/sec; 0.228 sec/batch; 20h:31m:52s remains)
INFO - root - 2017-12-16 15:15:05.540075: step 8750, loss = 0.69, batch loss = 0.47 (33.6 examples/sec; 0.238 sec/batch; 21h:24m:30s remains)
INFO - root - 2017-12-16 15:15:07.754685: step 8760, loss = 0.65, batch loss = 0.42 (36.2 examples/sec; 0.221 sec/batch; 19h:51m:14s remains)
INFO - root - 2017-12-16 15:15:09.958697: step 8770, loss = 0.63, batch loss = 0.40 (36.6 examples/sec; 0.218 sec/batch; 19h:38m:26s remains)
INFO - root - 2017-12-16 15:15:12.142255: step 8780, loss = 0.65, batch loss = 0.43 (36.7 examples/sec; 0.218 sec/batch; 19h:35m:23s remains)
INFO - root - 2017-12-16 15:15:14.319388: step 8790, loss = 0.60, batch loss = 0.38 (35.5 examples/sec; 0.225 sec/batch; 20h:14m:28s remains)
INFO - root - 2017-12-16 15:15:16.546515: step 8800, loss = 0.65, batch loss = 0.43 (35.7 examples/sec; 0.224 sec/batch; 20h:09m:40s remains)
INFO - root - 2017-12-16 15:15:18.915318: step 8810, loss = 0.65, batch loss = 0.43 (36.7 examples/sec; 0.218 sec/batch; 19h:35m:55s remains)
INFO - root - 2017-12-16 15:15:21.094219: step 8820, loss = 0.59, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 20h:09m:51s remains)
INFO - root - 2017-12-16 15:15:23.302439: step 8830, loss = 0.59, batch loss = 0.36 (37.5 examples/sec; 0.214 sec/batch; 19h:11m:49s remains)
INFO - root - 2017-12-16 15:15:25.552373: step 8840, loss = 0.62, batch loss = 0.40 (35.3 examples/sec; 0.227 sec/batch; 20h:22m:26s remains)
INFO - root - 2017-12-16 15:15:27.750779: step 8850, loss = 0.65, batch loss = 0.42 (36.5 examples/sec; 0.219 sec/batch; 19h:42m:51s remains)
INFO - root - 2017-12-16 15:15:30.004029: step 8860, loss = 0.66, batch loss = 0.44 (37.1 examples/sec; 0.216 sec/batch; 19h:24m:16s remains)
INFO - root - 2017-12-16 15:15:32.247327: step 8870, loss = 0.71, batch loss = 0.48 (33.4 examples/sec; 0.240 sec/batch; 21h:31m:52s remains)
INFO - root - 2017-12-16 15:15:34.487053: step 8880, loss = 0.61, batch loss = 0.39 (36.6 examples/sec; 0.219 sec/batch; 19h:39m:01s remains)
INFO - root - 2017-12-16 15:15:36.680080: step 8890, loss = 0.59, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 19h:46m:40s remains)
INFO - root - 2017-12-16 15:15:38.919653: step 8900, loss = 0.76, batch loss = 0.54 (36.0 examples/sec; 0.222 sec/batch; 19h:59m:02s remains)
INFO - root - 2017-12-16 15:15:41.253491: step 8910, loss = 0.74, batch loss = 0.51 (37.0 examples/sec; 0.216 sec/batch; 19h:26m:43s remains)
INFO - root - 2017-12-16 15:15:43.413869: step 8920, loss = 0.56, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 20h:21m:44s remains)
INFO - root - 2017-12-16 15:15:45.647898: step 8930, loss = 0.55, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 19h:31m:01s remains)
INFO - root - 2017-12-16 15:15:47.846189: step 8940, loss = 0.73, batch loss = 0.51 (34.7 examples/sec; 0.231 sec/batch; 20h:44m:28s remains)
INFO - root - 2017-12-16 15:15:50.040200: step 8950, loss = 0.62, batch loss = 0.40 (36.8 examples/sec; 0.217 sec/batch; 19h:30m:49s remains)
INFO - root - 2017-12-16 15:15:52.267979: step 8960, loss = 0.57, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 19h:25m:47s remains)
INFO - root - 2017-12-16 15:15:54.464135: step 8970, loss = 0.62, batch loss = 0.40 (36.7 examples/sec; 0.218 sec/batch; 19h:34m:40s remains)
INFO - root - 2017-12-16 15:15:56.715977: step 8980, loss = 0.78, batch loss = 0.56 (35.7 examples/sec; 0.224 sec/batch; 20h:09m:20s remains)
INFO - root - 2017-12-16 15:15:58.929292: step 8990, loss = 0.71, batch loss = 0.49 (35.0 examples/sec; 0.228 sec/batch; 20h:30m:54s remains)
INFO - root - 2017-12-16 15:16:01.143772: step 9000, loss = 0.56, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 19h:56m:38s remains)
INFO - root - 2017-12-16 15:16:03.537957: step 9010, loss = 0.57, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 19h:51m:51s remains)
INFO - root - 2017-12-16 15:16:05.726614: step 9020, loss = 0.61, batch loss = 0.39 (36.5 examples/sec; 0.219 sec/batch; 19h:43m:11s remains)
INFO - root - 2017-12-16 15:16:07.968471: step 9030, loss = 0.61, batch loss = 0.39 (35.3 examples/sec; 0.227 sec/batch; 20h:23m:17s remains)
INFO - root - 2017-12-16 15:16:10.176273: step 9040, loss = 0.66, batch loss = 0.44 (36.3 examples/sec; 0.220 sec/batch; 19h:46m:30s remains)
INFO - root - 2017-12-16 15:16:12.387323: step 9050, loss = 0.65, batch loss = 0.43 (35.5 examples/sec; 0.225 sec/batch; 20h:13m:52s remains)
INFO - root - 2017-12-16 15:16:14.610742: step 9060, loss = 0.58, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 19h:46m:41s remains)
INFO - root - 2017-12-16 15:16:16.857133: step 9070, loss = 0.70, batch loss = 0.48 (37.1 examples/sec; 0.215 sec/batch; 19h:20m:52s remains)
INFO - root - 2017-12-16 15:16:19.086663: step 9080, loss = 0.58, batch loss = 0.36 (36.2 examples/sec; 0.221 sec/batch; 19h:51m:16s remains)
INFO - root - 2017-12-16 15:16:21.304477: step 9090, loss = 0.63, batch loss = 0.41 (36.0 examples/sec; 0.223 sec/batch; 19h:59m:22s remains)
INFO - root - 2017-12-16 15:16:23.525188: step 9100, loss = 0.65, batch loss = 0.43 (36.4 examples/sec; 0.220 sec/batch; 19h:45m:04s remains)
INFO - root - 2017-12-16 15:16:25.902181: step 9110, loss = 0.63, batch loss = 0.41 (37.4 examples/sec; 0.214 sec/batch; 19h:11m:43s remains)
INFO - root - 2017-12-16 15:16:28.103250: step 9120, loss = 0.64, batch loss = 0.42 (35.0 examples/sec; 0.229 sec/batch; 20h:33m:41s remains)
INFO - root - 2017-12-16 15:16:30.323511: step 9130, loss = 0.68, batch loss = 0.46 (36.8 examples/sec; 0.218 sec/batch; 19h:32m:24s remains)
INFO - root - 2017-12-16 15:16:32.501669: step 9140, loss = 0.64, batch loss = 0.42 (35.5 examples/sec; 0.226 sec/batch; 20h:15m:47s remains)
INFO - root - 2017-12-16 15:16:34.750652: step 9150, loss = 0.66, batch loss = 0.44 (37.2 examples/sec; 0.215 sec/batch; 19h:18m:02s remains)
INFO - root - 2017-12-16 15:16:36.957036: step 9160, loss = 0.63, batch loss = 0.41 (37.4 examples/sec; 0.214 sec/batch; 19h:13m:54s remains)
INFO - root - 2017-12-16 15:16:39.177491: step 9170, loss = 0.56, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 19h:40m:18s remains)
INFO - root - 2017-12-16 15:16:41.384229: step 9180, loss = 0.53, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 19h:25m:11s remains)
INFO - root - 2017-12-16 15:16:43.640134: step 9190, loss = 0.53, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 19h:49m:56s remains)
INFO - root - 2017-12-16 15:16:45.865206: step 9200, loss = 0.55, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 19h:49m:13s remains)
INFO - root - 2017-12-16 15:16:48.214310: step 9210, loss = 0.59, batch loss = 0.38 (36.0 examples/sec; 0.222 sec/batch; 19h:57m:41s remains)
INFO - root - 2017-12-16 15:16:50.428993: step 9220, loss = 0.67, batch loss = 0.45 (37.6 examples/sec; 0.213 sec/batch; 19h:07m:28s remains)
INFO - root - 2017-12-16 15:16:52.672655: step 9230, loss = 0.58, batch loss = 0.36 (35.1 examples/sec; 0.228 sec/batch; 20h:29m:07s remains)
INFO - root - 2017-12-16 15:16:54.905586: step 9240, loss = 0.61, batch loss = 0.39 (35.1 examples/sec; 0.228 sec/batch; 20h:28m:44s remains)
INFO - root - 2017-12-16 15:16:57.140278: step 9250, loss = 0.63, batch loss = 0.42 (35.1 examples/sec; 0.228 sec/batch; 20h:29m:23s remains)
INFO - root - 2017-12-16 15:16:59.357519: step 9260, loss = 0.60, batch loss = 0.38 (37.0 examples/sec; 0.216 sec/batch; 19h:26m:19s remains)
INFO - root - 2017-12-16 15:17:01.556530: step 9270, loss = 0.51, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 19h:27m:41s remains)
INFO - root - 2017-12-16 15:17:03.783550: step 9280, loss = 0.60, batch loss = 0.39 (36.7 examples/sec; 0.218 sec/batch; 19h:35m:33s remains)
INFO - root - 2017-12-16 15:17:06.020594: step 9290, loss = 0.58, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 19h:41m:35s remains)
INFO - root - 2017-12-16 15:17:08.261379: step 9300, loss = 0.57, batch loss = 0.35 (34.6 examples/sec; 0.231 sec/batch; 20h:46m:12s remains)
INFO - root - 2017-12-16 15:17:10.634073: step 9310, loss = 0.65, batch loss = 0.43 (34.3 examples/sec; 0.233 sec/batch; 20h:56m:51s remains)
INFO - root - 2017-12-16 15:17:12.840284: step 9320, loss = 0.57, batch loss = 0.36 (37.1 examples/sec; 0.216 sec/batch; 19h:22m:36s remains)
INFO - root - 2017-12-16 15:17:15.058474: step 9330, loss = 0.56, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 19h:19m:21s remains)
INFO - root - 2017-12-16 15:17:17.299229: step 9340, loss = 0.62, batch loss = 0.41 (36.1 examples/sec; 0.222 sec/batch; 19h:54m:25s remains)
INFO - root - 2017-12-16 15:17:19.525207: step 9350, loss = 0.63, batch loss = 0.41 (36.7 examples/sec; 0.218 sec/batch; 19h:32m:43s remains)
INFO - root - 2017-12-16 15:17:21.757186: step 9360, loss = 0.59, batch loss = 0.38 (36.1 examples/sec; 0.222 sec/batch; 19h:54m:15s remains)
INFO - root - 2017-12-16 15:17:23.989260: step 9370, loss = 0.65, batch loss = 0.43 (35.3 examples/sec; 0.227 sec/batch; 20h:20m:02s remains)
INFO - root - 2017-12-16 15:17:26.227019: step 9380, loss = 0.59, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 19h:40m:20s remains)
INFO - root - 2017-12-16 15:17:28.438173: step 9390, loss = 0.59, batch loss = 0.38 (36.6 examples/sec; 0.219 sec/batch; 19h:38m:03s remains)
INFO - root - 2017-12-16 15:17:30.685768: step 9400, loss = 0.55, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 20h:06m:17s remains)
INFO - root - 2017-12-16 15:17:33.017879: step 9410, loss = 0.60, batch loss = 0.39 (37.3 examples/sec; 0.214 sec/batch; 19h:14m:37s remains)
INFO - root - 2017-12-16 15:17:35.264827: step 9420, loss = 0.63, batch loss = 0.42 (36.3 examples/sec; 0.221 sec/batch; 19h:48m:13s remains)
INFO - root - 2017-12-16 15:17:37.477884: step 9430, loss = 0.62, batch loss = 0.41 (35.5 examples/sec; 0.225 sec/batch; 20h:12m:15s remains)
INFO - root - 2017-12-16 15:17:39.682531: step 9440, loss = 0.61, batch loss = 0.40 (36.9 examples/sec; 0.217 sec/batch; 19h:25m:59s remains)
INFO - root - 2017-12-16 15:17:41.914691: step 9450, loss = 0.69, batch loss = 0.48 (35.2 examples/sec; 0.227 sec/batch; 20h:23m:48s remains)
INFO - root - 2017-12-16 15:17:44.134244: step 9460, loss = 0.57, batch loss = 0.36 (37.2 examples/sec; 0.215 sec/batch; 19h:19m:05s remains)
INFO - root - 2017-12-16 15:17:46.367648: step 9470, loss = 0.63, batch loss = 0.42 (36.6 examples/sec; 0.219 sec/batch; 19h:36m:39s remains)
INFO - root - 2017-12-16 15:17:48.575094: step 9480, loss = 0.57, batch loss = 0.36 (35.4 examples/sec; 0.226 sec/batch; 20h:17m:55s remains)
INFO - root - 2017-12-16 15:17:50.785245: step 9490, loss = 0.63, batch loss = 0.42 (35.8 examples/sec; 0.224 sec/batch; 20h:03m:56s remains)
INFO - root - 2017-12-16 15:17:53.005373: step 9500, loss = 0.64, batch loss = 0.43 (35.1 examples/sec; 0.228 sec/batch; 20h:26m:15s remains)
INFO - root - 2017-12-16 15:17:55.409941: step 9510, loss = 0.67, batch loss = 0.46 (37.2 examples/sec; 0.215 sec/batch; 19h:17m:30s remains)
INFO - root - 2017-12-16 15:17:57.619191: step 9520, loss = 0.62, batch loss = 0.41 (36.0 examples/sec; 0.222 sec/batch; 19h:55m:06s remains)
INFO - root - 2017-12-16 15:17:59.843672: step 9530, loss = 0.62, batch loss = 0.41 (37.4 examples/sec; 0.214 sec/batch; 19h:12m:08s remains)
INFO - root - 2017-12-16 15:18:02.082419: step 9540, loss = 0.61, batch loss = 0.40 (34.1 examples/sec; 0.235 sec/batch; 21h:04m:00s remains)
INFO - root - 2017-12-16 15:18:04.352291: step 9550, loss = 0.66, batch loss = 0.45 (37.0 examples/sec; 0.216 sec/batch; 19h:23m:01s remains)
INFO - root - 2017-12-16 15:18:06.555342: step 9560, loss = 0.56, batch loss = 0.35 (36.6 examples/sec; 0.219 sec/batch; 19h:37m:14s remains)
INFO - root - 2017-12-16 15:18:08.796814: step 9570, loss = 0.62, batch loss = 0.41 (37.0 examples/sec; 0.216 sec/batch; 19h:23m:00s remains)
INFO - root - 2017-12-16 15:18:11.015507: step 9580, loss = 0.68, batch loss = 0.47 (36.3 examples/sec; 0.220 sec/batch; 19h:45m:29s remains)
INFO - root - 2017-12-16 15:18:13.203962: step 9590, loss = 0.58, batch loss = 0.37 (36.6 examples/sec; 0.219 sec/batch; 19h:36m:31s remains)
INFO - root - 2017-12-16 15:18:15.409882: step 9600, loss = 0.58, batch loss = 0.37 (35.2 examples/sec; 0.227 sec/batch; 20h:22m:47s remains)
INFO - root - 2017-12-16 15:18:17.756700: step 9610, loss = 0.63, batch loss = 0.42 (33.9 examples/sec; 0.236 sec/batch; 21h:09m:36s remains)
INFO - root - 2017-12-16 15:18:19.993403: step 9620, loss = 0.63, batch loss = 0.42 (36.4 examples/sec; 0.220 sec/batch; 19h:43m:13s remains)
INFO - root - 2017-12-16 15:18:22.200137: step 9630, loss = 0.67, batch loss = 0.47 (36.3 examples/sec; 0.221 sec/batch; 19h:46m:55s remains)
INFO - root - 2017-12-16 15:18:24.390523: step 9640, loss = 0.65, batch loss = 0.44 (37.3 examples/sec; 0.214 sec/batch; 19h:13m:09s remains)
INFO - root - 2017-12-16 15:18:26.590284: step 9650, loss = 0.60, batch loss = 0.39 (36.1 examples/sec; 0.222 sec/batch; 19h:52m:09s remains)
INFO - root - 2017-12-16 15:18:28.792227: step 9660, loss = 0.56, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 19h:30m:11s remains)
INFO - root - 2017-12-16 15:18:31.038880: step 9670, loss = 0.64, batch loss = 0.43 (35.1 examples/sec; 0.228 sec/batch; 20h:25m:51s remains)
INFO - root - 2017-12-16 15:18:33.291127: step 9680, loss = 0.62, batch loss = 0.42 (36.7 examples/sec; 0.218 sec/batch; 19h:32m:59s remains)
INFO - root - 2017-12-16 15:18:35.535960: step 9690, loss = 0.55, batch loss = 0.34 (34.2 examples/sec; 0.234 sec/batch; 21h:00m:14s remains)
INFO - root - 2017-12-16 15:18:37.741500: step 9700, loss = 0.70, batch loss = 0.50 (36.4 examples/sec; 0.220 sec/batch; 19h:41m:57s remains)
INFO - root - 2017-12-16 15:18:40.091352: step 9710, loss = 0.59, batch loss = 0.39 (35.3 examples/sec; 0.227 sec/batch; 20h:20m:15s remains)
INFO - root - 2017-12-16 15:18:42.278587: step 9720, loss = 0.71, batch loss = 0.50 (36.7 examples/sec; 0.218 sec/batch; 19h:33m:58s remains)
INFO - root - 2017-12-16 15:18:44.506393: step 9730, loss = 0.58, batch loss = 0.38 (35.2 examples/sec; 0.227 sec/batch; 20h:22m:48s remains)
INFO - root - 2017-12-16 15:18:46.723041: step 9740, loss = 0.62, batch loss = 0.42 (35.6 examples/sec; 0.225 sec/batch; 20h:10m:09s remains)
INFO - root - 2017-12-16 15:18:48.964390: step 9750, loss = 0.59, batch loss = 0.39 (36.4 examples/sec; 0.220 sec/batch; 19h:43m:07s remains)
INFO - root - 2017-12-16 15:18:51.197509: step 9760, loss = 0.59, batch loss = 0.39 (36.3 examples/sec; 0.220 sec/batch; 19h:45m:18s remains)
INFO - root - 2017-12-16 15:18:53.457657: step 9770, loss = 0.58, batch loss = 0.38 (34.9 examples/sec; 0.229 sec/batch; 20h:32m:20s remains)
INFO - root - 2017-12-16 15:18:55.700495: step 9780, loss = 0.65, batch loss = 0.45 (35.9 examples/sec; 0.223 sec/batch; 19h:57m:10s remains)
INFO - root - 2017-12-16 15:18:57.932781: step 9790, loss = 0.57, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 19h:37m:29s remains)
INFO - root - 2017-12-16 15:19:00.136219: step 9800, loss = 0.61, batch loss = 0.41 (36.6 examples/sec; 0.219 sec/batch; 19h:35m:14s remains)
INFO - root - 2017-12-16 15:19:02.483016: step 9810, loss = 0.63, batch loss = 0.42 (36.2 examples/sec; 0.221 sec/batch; 19h:48m:59s remains)
INFO - root - 2017-12-16 15:19:04.681346: step 9820, loss = 0.61, batch loss = 0.41 (36.8 examples/sec; 0.218 sec/batch; 19h:30m:32s remains)
INFO - root - 2017-12-16 15:19:06.870145: step 9830, loss = 0.56, batch loss = 0.35 (37.4 examples/sec; 0.214 sec/batch; 19h:10m:30s remains)
INFO - root - 2017-12-16 15:19:09.101106: step 9840, loss = 0.54, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 19h:31m:38s remains)
INFO - root - 2017-12-16 15:19:11.314722: step 9850, loss = 0.49, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 19h:12m:38s remains)
INFO - root - 2017-12-16 15:19:13.548757: step 9860, loss = 0.61, batch loss = 0.41 (35.5 examples/sec; 0.225 sec/batch; 20h:10m:25s remains)
INFO - root - 2017-12-16 15:19:15.779254: step 9870, loss = 0.60, batch loss = 0.40 (36.4 examples/sec; 0.220 sec/batch; 19h:41m:24s remains)
INFO - root - 2017-12-16 15:19:18.030141: step 9880, loss = 0.53, batch loss = 0.33 (34.2 examples/sec; 0.234 sec/batch; 20h:59m:10s remains)
INFO - root - 2017-12-16 15:19:20.238326: step 9890, loss = 0.62, batch loss = 0.42 (35.8 examples/sec; 0.224 sec/batch; 20h:03m:05s remains)
INFO - root - 2017-12-16 15:19:22.418383: step 9900, loss = 0.59, batch loss = 0.39 (37.4 examples/sec; 0.214 sec/batch; 19h:09m:30s remains)
INFO - root - 2017-12-16 15:19:24.765645: step 9910, loss = 0.60, batch loss = 0.39 (36.6 examples/sec; 0.218 sec/batch; 19h:34m:42s remains)
INFO - root - 2017-12-16 15:19:26.975403: step 9920, loss = 0.64, batch loss = 0.44 (37.0 examples/sec; 0.216 sec/batch; 19h:21m:11s remains)
INFO - root - 2017-12-16 15:19:29.181601: step 9930, loss = 0.54, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 20h:04m:58s remains)
INFO - root - 2017-12-16 15:19:31.397696: step 9940, loss = 0.54, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 19h:29m:27s remains)
INFO - root - 2017-12-16 15:19:33.609507: step 9950, loss = 0.59, batch loss = 0.39 (36.3 examples/sec; 0.220 sec/batch; 19h:44m:50s remains)
INFO - root - 2017-12-16 15:19:35.807221: step 9960, loss = 0.61, batch loss = 0.41 (35.9 examples/sec; 0.223 sec/batch; 19h:57m:18s remains)
INFO - root - 2017-12-16 15:19:38.037855: step 9970, loss = 0.54, batch loss = 0.34 (37.7 examples/sec; 0.212 sec/batch; 19h:02m:00s remains)
INFO - root - 2017-12-16 15:19:40.244506: step 9980, loss = 0.51, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 19h:48m:08s remains)
INFO - root - 2017-12-16 15:19:42.452608: step 9990, loss = 0.52, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 19h:15m:07s remains)
INFO - root - 2017-12-16 15:19:44.707672: step 10000, loss = 0.54, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 20h:05m:51s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-10000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-10000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 15:19:47.551926: step 10010, loss = 0.71, batch loss = 0.51 (35.3 examples/sec; 0.227 sec/batch; 20h:19m:14s remains)
INFO - root - 2017-12-16 15:19:49.770217: step 10020, loss = 0.54, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 20h:09m:33s remains)
INFO - root - 2017-12-16 15:19:51.996413: step 10030, loss = 0.60, batch loss = 0.40 (34.7 examples/sec; 0.230 sec/batch; 20h:37m:36s remains)
INFO - root - 2017-12-16 15:19:54.214412: step 10040, loss = 0.58, batch loss = 0.38 (36.3 examples/sec; 0.220 sec/batch; 19h:44m:56s remains)
INFO - root - 2017-12-16 15:19:56.468460: step 10050, loss = 0.57, batch loss = 0.37 (33.8 examples/sec; 0.236 sec/batch; 21h:10m:26s remains)
INFO - root - 2017-12-16 15:19:58.671422: step 10060, loss = 0.55, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 19h:33m:02s remains)
INFO - root - 2017-12-16 15:20:00.888885: step 10070, loss = 0.58, batch loss = 0.38 (35.3 examples/sec; 0.227 sec/batch; 20h:17m:45s remains)
INFO - root - 2017-12-16 15:20:03.117573: step 10080, loss = 0.63, batch loss = 0.43 (35.7 examples/sec; 0.224 sec/batch; 20h:03m:29s remains)
INFO - root - 2017-12-16 15:20:05.370361: step 10090, loss = 0.52, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 19h:38m:35s remains)
INFO - root - 2017-12-16 15:20:07.609436: step 10100, loss = 0.57, batch loss = 0.37 (37.3 examples/sec; 0.214 sec/batch; 19h:11m:58s remains)
INFO - root - 2017-12-16 15:20:10.007336: step 10110, loss = 0.55, batch loss = 0.35 (35.1 examples/sec; 0.228 sec/batch; 20h:23m:55s remains)
INFO - root - 2017-12-16 15:20:12.239893: step 10120, loss = 0.52, batch loss = 0.33 (33.1 examples/sec; 0.242 sec/batch; 21h:37m:48s remains)
INFO - root - 2017-12-16 15:20:14.477906: step 10130, loss = 0.63, batch loss = 0.43 (35.1 examples/sec; 0.228 sec/batch; 20h:23m:51s remains)
INFO - root - 2017-12-16 15:20:16.703870: step 10140, loss = 0.57, batch loss = 0.37 (35.6 examples/sec; 0.225 sec/batch; 20h:08m:12s remains)
INFO - root - 2017-12-16 15:20:18.905885: step 10150, loss = 0.62, batch loss = 0.42 (36.2 examples/sec; 0.221 sec/batch; 19h:48m:19s remains)
INFO - root - 2017-12-16 15:20:21.110506: step 10160, loss = 0.58, batch loss = 0.38 (37.4 examples/sec; 0.214 sec/batch; 19h:08m:33s remains)
INFO - root - 2017-12-16 15:20:23.325803: step 10170, loss = 0.55, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 19h:20m:38s remains)
INFO - root - 2017-12-16 15:20:25.568879: step 10180, loss = 0.56, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 19h:35m:19s remains)
INFO - root - 2017-12-16 15:20:27.754729: step 10190, loss = 0.49, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 19h:40m:22s remains)
INFO - root - 2017-12-16 15:20:29.998949: step 10200, loss = 0.60, batch loss = 0.40 (34.4 examples/sec; 0.233 sec/batch; 20h:50m:05s remains)
INFO - root - 2017-12-16 15:20:32.388850: step 10210, loss = 0.62, batch loss = 0.42 (35.2 examples/sec; 0.227 sec/batch; 20h:21m:34s remains)
INFO - root - 2017-12-16 15:20:34.594607: step 10220, loss = 0.59, batch loss = 0.39 (36.0 examples/sec; 0.222 sec/batch; 19h:53m:07s remains)
INFO - root - 2017-12-16 15:20:36.812469: step 10230, loss = 0.55, batch loss = 0.35 (34.2 examples/sec; 0.234 sec/batch; 20h:54m:42s remains)
INFO - root - 2017-12-16 15:20:39.107712: step 10240, loss = 0.63, batch loss = 0.43 (36.5 examples/sec; 0.219 sec/batch; 19h:38m:00s remains)
INFO - root - 2017-12-16 15:20:41.411168: step 10250, loss = 0.65, batch loss = 0.45 (35.9 examples/sec; 0.223 sec/batch; 19h:58m:19s remains)
INFO - root - 2017-12-16 15:20:43.637882: step 10260, loss = 0.60, batch loss = 0.40 (33.4 examples/sec; 0.239 sec/batch; 21h:26m:02s remains)
INFO - root - 2017-12-16 15:20:45.841356: step 10270, loss = 0.54, batch loss = 0.34 (36.6 examples/sec; 0.218 sec/batch; 19h:33m:24s remains)
INFO - root - 2017-12-16 15:20:48.061680: step 10280, loss = 0.51, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 19h:51m:23s remains)
INFO - root - 2017-12-16 15:20:50.287447: step 10290, loss = 0.68, batch loss = 0.48 (34.8 examples/sec; 0.230 sec/batch; 20h:32m:59s remains)
INFO - root - 2017-12-16 15:20:52.460817: step 10300, loss = 0.58, batch loss = 0.38 (37.8 examples/sec; 0.212 sec/batch; 18h:56m:01s remains)
INFO - root - 2017-12-16 15:20:54.805653: step 10310, loss = 0.64, batch loss = 0.44 (35.1 examples/sec; 0.228 sec/batch; 20h:23m:39s remains)
INFO - root - 2017-12-16 15:20:56.995904: step 10320, loss = 0.53, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 19h:54m:08s remains)
INFO - root - 2017-12-16 15:20:59.216801: step 10330, loss = 0.53, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 19h:39m:06s remains)
INFO - root - 2017-12-16 15:21:01.496504: step 10340, loss = 0.54, batch loss = 0.34 (35.5 examples/sec; 0.226 sec/batch; 20h:11m:19s remains)
INFO - root - 2017-12-16 15:21:03.740005: step 10350, loss = 0.54, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 19h:38m:53s remains)
INFO - root - 2017-12-16 15:21:05.953065: step 10360, loss = 0.48, batch loss = 0.29 (34.3 examples/sec; 0.233 sec/batch; 20h:51m:13s remains)
INFO - root - 2017-12-16 15:21:08.179454: step 10370, loss = 0.64, batch loss = 0.44 (36.8 examples/sec; 0.217 sec/batch; 19h:26m:15s remains)
INFO - root - 2017-12-16 15:21:10.402438: step 10380, loss = 0.58, batch loss = 0.38 (36.1 examples/sec; 0.221 sec/batch; 19h:48m:57s remains)
INFO - root - 2017-12-16 15:21:12.648654: step 10390, loss = 0.55, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 19h:55m:37s remains)
INFO - root - 2017-12-16 15:21:14.914078: step 10400, loss = 0.52, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 19h:56m:25s remains)
INFO - root - 2017-12-16 15:21:17.230245: step 10410, loss = 0.48, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 19h:08m:32s remains)
INFO - root - 2017-12-16 15:21:19.458932: step 10420, loss = 0.51, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 20h:33m:31s remains)
INFO - root - 2017-12-16 15:21:21.652764: step 10430, loss = 0.57, batch loss = 0.37 (37.0 examples/sec; 0.216 sec/batch; 19h:22m:01s remains)
INFO - root - 2017-12-16 15:21:23.896565: step 10440, loss = 0.60, batch loss = 0.40 (35.5 examples/sec; 0.226 sec/batch; 20h:10m:47s remains)
INFO - root - 2017-12-16 15:21:26.100448: step 10450, loss = 0.60, batch loss = 0.41 (36.4 examples/sec; 0.220 sec/batch; 19h:40m:06s remains)
INFO - root - 2017-12-16 15:21:28.324850: step 10460, loss = 0.63, batch loss = 0.43 (36.6 examples/sec; 0.218 sec/batch; 19h:32m:35s remains)
INFO - root - 2017-12-16 15:21:30.558254: step 10470, loss = 0.56, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 19h:36m:57s remains)
INFO - root - 2017-12-16 15:21:32.789750: step 10480, loss = 0.56, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 19h:34m:33s remains)
INFO - root - 2017-12-16 15:21:35.013499: step 10490, loss = 0.61, batch loss = 0.41 (35.5 examples/sec; 0.225 sec/batch; 20h:07m:57s remains)
INFO - root - 2017-12-16 15:21:37.251895: step 10500, loss = 0.60, batch loss = 0.40 (35.7 examples/sec; 0.224 sec/batch; 20h:01m:43s remains)
INFO - root - 2017-12-16 15:21:39.629457: step 10510, loss = 0.56, batch loss = 0.36 (36.2 examples/sec; 0.221 sec/batch; 19h:44m:42s remains)
INFO - root - 2017-12-16 15:21:41.851334: step 10520, loss = 0.57, batch loss = 0.38 (36.2 examples/sec; 0.221 sec/batch; 19h:46m:34s remains)
INFO - root - 2017-12-16 15:21:44.058449: step 10530, loss = 0.61, batch loss = 0.41 (36.4 examples/sec; 0.220 sec/batch; 19h:38m:25s remains)
INFO - root - 2017-12-16 15:21:46.317599: step 10540, loss = 0.54, batch loss = 0.34 (33.9 examples/sec; 0.236 sec/batch; 21h:04m:27s remains)
INFO - root - 2017-12-16 15:21:48.544097: step 10550, loss = 0.52, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 20h:02m:04s remains)
INFO - root - 2017-12-16 15:21:50.748517: step 10560, loss = 0.50, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 19h:32m:06s remains)
INFO - root - 2017-12-16 15:21:52.974469: step 10570, loss = 0.51, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 20h:32m:07s remains)
INFO - root - 2017-12-16 15:21:55.247027: step 10580, loss = 0.53, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 19h:38m:43s remains)
INFO - root - 2017-12-16 15:21:57.486699: step 10590, loss = 0.55, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 19h:53m:40s remains)
INFO - root - 2017-12-16 15:21:59.686274: step 10600, loss = 0.57, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 19h:42m:43s remains)
INFO - root - 2017-12-16 15:22:02.020370: step 10610, loss = 0.61, batch loss = 0.41 (36.9 examples/sec; 0.217 sec/batch; 19h:22m:13s remains)
INFO - root - 2017-12-16 15:22:04.289459: step 10620, loss = 0.60, batch loss = 0.40 (34.7 examples/sec; 0.230 sec/batch; 20h:36m:26s remains)
INFO - root - 2017-12-16 15:22:06.501895: step 10630, loss = 0.62, batch loss = 0.42 (36.3 examples/sec; 0.221 sec/batch; 19h:43m:43s remains)
INFO - root - 2017-12-16 15:22:08.703002: step 10640, loss = 0.56, batch loss = 0.37 (36.7 examples/sec; 0.218 sec/batch; 19h:27m:45s remains)
INFO - root - 2017-12-16 15:22:10.912805: step 10650, loss = 0.52, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 19h:36m:55s remains)
INFO - root - 2017-12-16 15:22:13.109226: step 10660, loss = 0.55, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 19h:41m:02s remains)
INFO - root - 2017-12-16 15:22:15.310963: step 10670, loss = 0.62, batch loss = 0.43 (37.1 examples/sec; 0.216 sec/batch; 19h:17m:19s remains)
INFO - root - 2017-12-16 15:22:17.587871: step 10680, loss = 0.59, batch loss = 0.40 (35.8 examples/sec; 0.224 sec/batch; 20h:00m:10s remains)
INFO - root - 2017-12-16 15:22:19.820661: step 10690, loss = 0.66, batch loss = 0.46 (35.3 examples/sec; 0.227 sec/batch; 20h:15m:18s remains)
INFO - root - 2017-12-16 15:22:22.008830: step 10700, loss = 0.59, batch loss = 0.39 (37.7 examples/sec; 0.212 sec/batch; 18h:57m:16s remains)
INFO - root - 2017-12-16 15:22:24.316344: step 10710, loss = 0.68, batch loss = 0.48 (36.3 examples/sec; 0.220 sec/batch; 19h:40m:24s remains)
INFO - root - 2017-12-16 15:22:26.521861: step 10720, loss = 0.58, batch loss = 0.38 (37.1 examples/sec; 0.216 sec/batch; 19h:17m:27s remains)
INFO - root - 2017-12-16 15:22:28.737850: step 10730, loss = 0.62, batch loss = 0.42 (35.6 examples/sec; 0.225 sec/batch; 20h:06m:47s remains)
INFO - root - 2017-12-16 15:22:30.927004: step 10740, loss = 0.50, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 19h:23m:55s remains)
INFO - root - 2017-12-16 15:22:33.113382: step 10750, loss = 0.54, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 19h:24m:21s remains)
INFO - root - 2017-12-16 15:22:35.304341: step 10760, loss = 0.57, batch loss = 0.38 (35.3 examples/sec; 0.226 sec/batch; 20h:13m:40s remains)
INFO - root - 2017-12-16 15:22:37.489769: step 10770, loss = 0.57, batch loss = 0.38 (36.3 examples/sec; 0.220 sec/batch; 19h:42m:19s remains)
INFO - root - 2017-12-16 15:22:39.793027: step 10780, loss = 0.58, batch loss = 0.38 (37.0 examples/sec; 0.216 sec/batch; 19h:20m:51s remains)
INFO - root - 2017-12-16 15:22:41.986868: step 10790, loss = 0.49, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 19h:34m:57s remains)
INFO - root - 2017-12-16 15:22:44.206467: step 10800, loss = 0.49, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 19h:01m:22s remains)
INFO - root - 2017-12-16 15:22:46.566753: step 10810, loss = 0.58, batch loss = 0.38 (37.0 examples/sec; 0.216 sec/batch; 19h:19m:46s remains)
INFO - root - 2017-12-16 15:22:48.747616: step 10820, loss = 0.56, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 19h:29m:25s remains)
INFO - root - 2017-12-16 15:22:50.975041: step 10830, loss = 0.63, batch loss = 0.43 (36.5 examples/sec; 0.219 sec/batch; 19h:34m:42s remains)
INFO - root - 2017-12-16 15:22:53.197000: step 10840, loss = 0.61, batch loss = 0.41 (37.4 examples/sec; 0.214 sec/batch; 19h:05m:35s remains)
INFO - root - 2017-12-16 15:22:55.415478: step 10850, loss = 0.64, batch loss = 0.44 (37.3 examples/sec; 0.214 sec/batch; 19h:09m:00s remains)
INFO - root - 2017-12-16 15:22:57.603948: step 10860, loss = 0.58, batch loss = 0.39 (36.8 examples/sec; 0.217 sec/batch; 19h:24m:06s remains)
INFO - root - 2017-12-16 15:22:59.815581: step 10870, loss = 0.60, batch loss = 0.41 (36.5 examples/sec; 0.219 sec/batch; 19h:35m:40s remains)
INFO - root - 2017-12-16 15:23:02.029160: step 10880, loss = 0.49, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 19h:22m:05s remains)
INFO - root - 2017-12-16 15:23:04.209006: step 10890, loss = 0.53, batch loss = 0.33 (37.3 examples/sec; 0.214 sec/batch; 19h:08m:14s remains)
INFO - root - 2017-12-16 15:23:06.424135: step 10900, loss = 0.53, batch loss = 0.33 (36.6 examples/sec; 0.218 sec/batch; 19h:30m:34s remains)
INFO - root - 2017-12-16 15:23:08.781211: step 10910, loss = 0.63, batch loss = 0.44 (36.9 examples/sec; 0.217 sec/batch; 19h:21m:28s remains)
INFO - root - 2017-12-16 15:23:10.993763: step 10920, loss = 0.68, batch loss = 0.48 (34.6 examples/sec; 0.231 sec/batch; 20h:37m:35s remains)
INFO - root - 2017-12-16 15:23:13.169138: step 10930, loss = 0.57, batch loss = 0.37 (35.4 examples/sec; 0.226 sec/batch; 20h:10m:27s remains)
INFO - root - 2017-12-16 15:23:15.413777: step 10940, loss = 0.66, batch loss = 0.46 (35.8 examples/sec; 0.224 sec/batch; 19h:58m:52s remains)
INFO - root - 2017-12-16 15:23:17.621708: step 10950, loss = 0.59, batch loss = 0.40 (34.5 examples/sec; 0.232 sec/batch; 20h:42m:15s remains)
INFO - root - 2017-12-16 15:23:19.814562: step 10960, loss = 0.55, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 19h:19m:51s remains)
INFO - root - 2017-12-16 15:23:22.009565: step 10970, loss = 0.60, batch loss = 0.41 (35.5 examples/sec; 0.225 sec/batch; 20h:07m:00s remains)
INFO - root - 2017-12-16 15:23:24.230438: step 10980, loss = 0.57, batch loss = 0.37 (37.3 examples/sec; 0.215 sec/batch; 19h:10m:18s remains)
INFO - root - 2017-12-16 15:23:26.441814: step 10990, loss = 0.54, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 20h:02m:13s remains)
INFO - root - 2017-12-16 15:23:28.646697: step 11000, loss = 0.57, batch loss = 0.37 (37.6 examples/sec; 0.213 sec/batch; 19h:01m:06s remains)
INFO - root - 2017-12-16 15:23:30.980134: step 11010, loss = 0.63, batch loss = 0.43 (34.5 examples/sec; 0.232 sec/batch; 20h:41m:53s remains)
INFO - root - 2017-12-16 15:23:33.200841: step 11020, loss = 0.56, batch loss = 0.36 (37.0 examples/sec; 0.216 sec/batch; 19h:18m:07s remains)
INFO - root - 2017-12-16 15:23:35.386871: step 11030, loss = 0.49, batch loss = 0.29 (38.0 examples/sec; 0.211 sec/batch; 18h:48m:53s remains)
INFO - root - 2017-12-16 15:23:37.592485: step 11040, loss = 0.54, batch loss = 0.34 (37.1 examples/sec; 0.215 sec/batch; 19h:14m:04s remains)
INFO - root - 2017-12-16 15:23:39.776179: step 11050, loss = 0.56, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 19h:31m:07s remains)
INFO - root - 2017-12-16 15:23:41.989436: step 11060, loss = 0.57, batch loss = 0.37 (36.6 examples/sec; 0.218 sec/batch; 19h:29m:46s remains)
INFO - root - 2017-12-16 15:23:44.185073: step 11070, loss = 0.61, batch loss = 0.42 (37.6 examples/sec; 0.213 sec/batch; 18h:59m:16s remains)
INFO - root - 2017-12-16 15:23:46.346295: step 11080, loss = 0.60, batch loss = 0.41 (36.6 examples/sec; 0.218 sec/batch; 19h:30m:05s remains)
INFO - root - 2017-12-16 15:23:48.564078: step 11090, loss = 0.51, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 19h:43m:40s remains)
INFO - root - 2017-12-16 15:23:50.763686: step 11100, loss = 0.57, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 19h:33m:26s remains)
INFO - root - 2017-12-16 15:23:53.154552: step 11110, loss = 0.55, batch loss = 0.35 (35.5 examples/sec; 0.225 sec/batch; 20h:05m:50s remains)
INFO - root - 2017-12-16 15:23:55.373638: step 11120, loss = 0.66, batch loss = 0.47 (34.7 examples/sec; 0.231 sec/batch; 20h:35m:50s remains)
INFO - root - 2017-12-16 15:23:57.618061: step 11130, loss = 0.53, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 19h:18m:30s remains)
INFO - root - 2017-12-16 15:23:59.857361: step 11140, loss = 0.61, batch loss = 0.41 (35.9 examples/sec; 0.223 sec/batch; 19h:53m:33s remains)
INFO - root - 2017-12-16 15:24:02.081781: step 11150, loss = 0.56, batch loss = 0.36 (35.3 examples/sec; 0.227 sec/batch; 20h:15m:25s remains)
INFO - root - 2017-12-16 15:24:04.294367: step 11160, loss = 0.50, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 19h:50m:11s remains)
INFO - root - 2017-12-16 15:24:06.523947: step 11170, loss = 0.46, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 19h:57m:25s remains)
INFO - root - 2017-12-16 15:24:08.767122: step 11180, loss = 0.50, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 19h:28m:45s remains)
INFO - root - 2017-12-16 15:24:10.986726: step 11190, loss = 0.58, batch loss = 0.38 (35.5 examples/sec; 0.225 sec/batch; 20h:06m:12s remains)
INFO - root - 2017-12-16 15:24:13.173935: step 11200, loss = 0.50, batch loss = 0.30 (34.0 examples/sec; 0.235 sec/batch; 21h:00m:23s remains)
INFO - root - 2017-12-16 15:24:15.521965: step 11210, loss = 0.58, batch loss = 0.38 (35.5 examples/sec; 0.225 sec/batch; 20h:07m:22s remains)
INFO - root - 2017-12-16 15:24:17.735385: step 11220, loss = 0.52, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 19h:32m:08s remains)
INFO - root - 2017-12-16 15:24:19.945295: step 11230, loss = 0.60, batch loss = 0.41 (35.4 examples/sec; 0.226 sec/batch; 20h:10m:59s remains)
INFO - root - 2017-12-16 15:24:22.110635: step 11240, loss = 0.54, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 19h:10m:16s remains)
INFO - root - 2017-12-16 15:24:24.307061: step 11250, loss = 0.54, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 19h:24m:09s remains)
INFO - root - 2017-12-16 15:24:26.519547: step 11260, loss = 0.51, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 19h:19m:11s remains)
INFO - root - 2017-12-16 15:24:28.697804: step 11270, loss = 0.54, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 19h:26m:33s remains)
INFO - root - 2017-12-16 15:24:30.864731: step 11280, loss = 0.61, batch loss = 0.41 (36.3 examples/sec; 0.220 sec/batch; 19h:40m:14s remains)
INFO - root - 2017-12-16 15:24:33.073078: step 11290, loss = 0.57, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 19h:35m:50s remains)
INFO - root - 2017-12-16 15:24:35.295941: step 11300, loss = 0.53, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 19h:37m:36s remains)
INFO - root - 2017-12-16 15:24:37.575918: step 11310, loss = 0.62, batch loss = 0.42 (36.7 examples/sec; 0.218 sec/batch; 19h:27m:50s remains)
INFO - root - 2017-12-16 15:24:39.773826: step 11320, loss = 0.54, batch loss = 0.35 (37.5 examples/sec; 0.213 sec/batch; 19h:00m:54s remains)
INFO - root - 2017-12-16 15:24:41.968212: step 11330, loss = 0.60, batch loss = 0.40 (37.4 examples/sec; 0.214 sec/batch; 19h:03m:58s remains)
INFO - root - 2017-12-16 15:24:44.176259: step 11340, loss = 0.60, batch loss = 0.40 (37.6 examples/sec; 0.213 sec/batch; 18h:57m:53s remains)
INFO - root - 2017-12-16 15:24:46.368566: step 11350, loss = 0.49, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 19h:39m:29s remains)
INFO - root - 2017-12-16 15:24:48.594736: step 11360, loss = 0.58, batch loss = 0.38 (35.2 examples/sec; 0.227 sec/batch; 20h:15m:16s remains)
INFO - root - 2017-12-16 15:24:50.784775: step 11370, loss = 0.55, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 19h:10m:27s remains)
INFO - root - 2017-12-16 15:24:52.969375: step 11380, loss = 0.56, batch loss = 0.36 (37.8 examples/sec; 0.212 sec/batch; 18h:53m:14s remains)
INFO - root - 2017-12-16 15:24:55.179957: step 11390, loss = 0.54, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 19h:59m:45s remains)
INFO - root - 2017-12-16 15:24:57.421841: step 11400, loss = 0.53, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 20h:29m:57s remains)
INFO - root - 2017-12-16 15:24:59.761427: step 11410, loss = 0.54, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 19h:23m:46s remains)
INFO - root - 2017-12-16 15:25:01.969095: step 11420, loss = 0.59, batch loss = 0.40 (36.3 examples/sec; 0.220 sec/batch; 19h:39m:08s remains)
INFO - root - 2017-12-16 15:25:04.201889: step 11430, loss = 0.50, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 19h:25m:15s remains)
INFO - root - 2017-12-16 15:25:06.425029: step 11440, loss = 0.59, batch loss = 0.40 (35.9 examples/sec; 0.223 sec/batch; 19h:51m:20s remains)
INFO - root - 2017-12-16 15:25:08.688659: step 11450, loss = 0.53, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 20h:31m:26s remains)
INFO - root - 2017-12-16 15:25:10.899213: step 11460, loss = 0.47, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 19h:43m:15s remains)
INFO - root - 2017-12-16 15:25:13.081102: step 11470, loss = 0.50, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 19h:17m:12s remains)
INFO - root - 2017-12-16 15:25:15.257614: step 11480, loss = 0.53, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 19h:32m:04s remains)
INFO - root - 2017-12-16 15:25:17.465963: step 11490, loss = 0.56, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 19h:59m:15s remains)
INFO - root - 2017-12-16 15:25:19.655464: step 11500, loss = 0.59, batch loss = 0.39 (37.4 examples/sec; 0.214 sec/batch; 19h:05m:39s remains)
INFO - root - 2017-12-16 15:25:22.022369: step 11510, loss = 0.57, batch loss = 0.38 (35.0 examples/sec; 0.229 sec/batch; 20h:22m:43s remains)
INFO - root - 2017-12-16 15:25:24.267689: step 11520, loss = 0.49, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 19h:37m:46s remains)
INFO - root - 2017-12-16 15:25:26.463689: step 11530, loss = 0.51, batch loss = 0.31 (38.0 examples/sec; 0.211 sec/batch; 18h:46m:39s remains)
INFO - root - 2017-12-16 15:25:28.628438: step 11540, loss = 0.61, batch loss = 0.41 (37.7 examples/sec; 0.212 sec/batch; 18h:54m:26s remains)
INFO - root - 2017-12-16 15:25:30.849382: step 11550, loss = 0.51, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 19h:36m:43s remains)
INFO - root - 2017-12-16 15:25:33.032785: step 11560, loss = 0.63, batch loss = 0.43 (36.1 examples/sec; 0.222 sec/batch; 19h:45m:05s remains)
INFO - root - 2017-12-16 15:25:35.263341: step 11570, loss = 0.49, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 19h:26m:49s remains)
INFO - root - 2017-12-16 15:25:37.507924: step 11580, loss = 0.57, batch loss = 0.38 (35.7 examples/sec; 0.224 sec/batch; 20h:00m:07s remains)
INFO - root - 2017-12-16 15:25:39.748320: step 11590, loss = 0.54, batch loss = 0.34 (34.5 examples/sec; 0.232 sec/batch; 20h:41m:15s remains)
INFO - root - 2017-12-16 15:25:41.960340: step 11600, loss = 0.52, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 19h:39m:58s remains)
INFO - root - 2017-12-16 15:25:44.275359: step 11610, loss = 0.53, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 20h:01m:06s remains)
INFO - root - 2017-12-16 15:25:46.482717: step 11620, loss = 0.51, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 19h:21m:36s remains)
INFO - root - 2017-12-16 15:25:48.668783: step 11630, loss = 0.52, batch loss = 0.33 (35.1 examples/sec; 0.228 sec/batch; 20h:17m:44s remains)
INFO - root - 2017-12-16 15:25:50.857299: step 11640, loss = 0.55, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 19h:26m:08s remains)
INFO - root - 2017-12-16 15:25:53.079862: step 11650, loss = 0.56, batch loss = 0.37 (36.7 examples/sec; 0.218 sec/batch; 19h:25m:54s remains)
INFO - root - 2017-12-16 15:25:55.240320: step 11660, loss = 0.53, batch loss = 0.34 (37.1 examples/sec; 0.216 sec/batch; 19h:13m:51s remains)
INFO - root - 2017-12-16 15:25:57.458585: step 11670, loss = 0.51, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 20h:15m:58s remains)
INFO - root - 2017-12-16 15:25:59.688233: step 11680, loss = 0.49, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 19h:56m:03s remains)
INFO - root - 2017-12-16 15:26:01.885419: step 11690, loss = 0.59, batch loss = 0.39 (36.5 examples/sec; 0.219 sec/batch; 19h:33m:18s remains)
INFO - root - 2017-12-16 15:26:04.084110: step 11700, loss = 0.52, batch loss = 0.33 (35.0 examples/sec; 0.229 sec/batch; 20h:23m:48s remains)
INFO - root - 2017-12-16 15:26:06.418740: step 11710, loss = 0.57, batch loss = 0.37 (36.3 examples/sec; 0.221 sec/batch; 19h:39m:20s remains)
INFO - root - 2017-12-16 15:26:08.667310: step 11720, loss = 0.59, batch loss = 0.39 (35.8 examples/sec; 0.224 sec/batch; 19h:55m:08s remains)
INFO - root - 2017-12-16 15:26:10.869367: step 11730, loss = 0.60, batch loss = 0.40 (36.5 examples/sec; 0.219 sec/batch; 19h:30m:49s remains)
INFO - root - 2017-12-16 15:26:13.092281: step 11740, loss = 0.59, batch loss = 0.39 (37.4 examples/sec; 0.214 sec/batch; 19h:03m:53s remains)
INFO - root - 2017-12-16 15:26:15.298025: step 11750, loss = 0.52, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 19h:10m:53s remains)
INFO - root - 2017-12-16 15:26:17.486383: step 11760, loss = 0.55, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 19h:32m:52s remains)
INFO - root - 2017-12-16 15:26:19.657907: step 11770, loss = 0.53, batch loss = 0.33 (37.6 examples/sec; 0.213 sec/batch; 18h:57m:43s remains)
INFO - root - 2017-12-16 15:26:21.836106: step 11780, loss = 0.54, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 19h:50m:04s remains)
INFO - root - 2017-12-16 15:26:24.066822: step 11790, loss = 0.62, batch loss = 0.42 (35.2 examples/sec; 0.227 sec/batch; 20h:15m:44s remains)
INFO - root - 2017-12-16 15:26:26.280331: step 11800, loss = 0.52, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 19h:24m:56s remains)
INFO - root - 2017-12-16 15:26:28.630770: step 11810, loss = 0.48, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 20h:06m:34s remains)
INFO - root - 2017-12-16 15:26:30.829399: step 11820, loss = 0.51, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 20h:07m:00s remains)
INFO - root - 2017-12-16 15:26:33.014516: step 11830, loss = 0.57, batch loss = 0.37 (36.9 examples/sec; 0.217 sec/batch; 19h:17m:11s remains)
INFO - root - 2017-12-16 15:26:35.206994: step 11840, loss = 0.50, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 19h:29m:45s remains)
INFO - root - 2017-12-16 15:26:37.406397: step 11850, loss = 0.55, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 20h:02m:17s remains)
INFO - root - 2017-12-16 15:26:39.648532: step 11860, loss = 0.59, batch loss = 0.40 (36.7 examples/sec; 0.218 sec/batch; 19h:24m:39s remains)
INFO - root - 2017-12-16 15:26:41.855953: step 11870, loss = 0.56, batch loss = 0.36 (35.6 examples/sec; 0.225 sec/batch; 20h:02m:20s remains)
INFO - root - 2017-12-16 15:26:44.065276: step 11880, loss = 0.61, batch loss = 0.41 (37.0 examples/sec; 0.216 sec/batch; 19h:14m:43s remains)
INFO - root - 2017-12-16 15:26:46.259381: step 11890, loss = 0.56, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 19h:25m:38s remains)
INFO - root - 2017-12-16 15:26:48.467462: step 11900, loss = 0.56, batch loss = 0.37 (35.6 examples/sec; 0.225 sec/batch; 20h:01m:39s remains)
INFO - root - 2017-12-16 15:26:50.871066: step 11910, loss = 0.52, batch loss = 0.32 (33.1 examples/sec; 0.242 sec/batch; 21h:33m:05s remains)
INFO - root - 2017-12-16 15:26:53.079639: step 11920, loss = 0.58, batch loss = 0.39 (37.5 examples/sec; 0.214 sec/batch; 19h:00m:57s remains)
INFO - root - 2017-12-16 15:26:55.262149: step 11930, loss = 0.49, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 19h:50m:43s remains)
INFO - root - 2017-12-16 15:26:57.492111: step 11940, loss = 0.57, batch loss = 0.38 (35.2 examples/sec; 0.227 sec/batch; 20h:14m:44s remains)
INFO - root - 2017-12-16 15:26:59.698062: step 11950, loss = 0.49, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 19h:51m:56s remains)
INFO - root - 2017-12-16 15:27:01.890214: step 11960, loss = 0.56, batch loss = 0.37 (37.2 examples/sec; 0.215 sec/batch; 19h:09m:30s remains)
INFO - root - 2017-12-16 15:27:04.097124: step 11970, loss = 0.64, batch loss = 0.44 (36.2 examples/sec; 0.221 sec/batch; 19h:41m:55s remains)
INFO - root - 2017-12-16 15:27:06.327383: step 11980, loss = 0.58, batch loss = 0.38 (36.3 examples/sec; 0.220 sec/batch; 19h:36m:40s remains)
INFO - root - 2017-12-16 15:27:08.557486: step 11990, loss = 0.58, batch loss = 0.39 (35.3 examples/sec; 0.227 sec/batch; 20h:11m:57s remains)
INFO - root - 2017-12-16 15:27:10.771415: step 12000, loss = 0.52, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 20h:03m:05s remains)
INFO - root - 2017-12-16 15:27:13.125063: step 12010, loss = 0.63, batch loss = 0.44 (35.4 examples/sec; 0.226 sec/batch; 20h:06m:08s remains)
INFO - root - 2017-12-16 15:27:15.332860: step 12020, loss = 0.54, batch loss = 0.35 (35.3 examples/sec; 0.226 sec/batch; 20h:09m:34s remains)
INFO - root - 2017-12-16 15:27:17.555956: step 12030, loss = 0.50, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 19h:45m:49s remains)
INFO - root - 2017-12-16 15:27:19.787556: step 12040, loss = 0.55, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 19h:51m:16s remains)
INFO - root - 2017-12-16 15:27:21.999696: step 12050, loss = 0.49, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 19h:37m:06s remains)
INFO - root - 2017-12-16 15:27:24.239238: step 12060, loss = 0.54, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 19h:21m:21s remains)
INFO - root - 2017-12-16 15:27:26.450650: step 12070, loss = 0.55, batch loss = 0.36 (35.3 examples/sec; 0.227 sec/batch; 20h:10m:23s remains)
INFO - root - 2017-12-16 15:27:28.658328: step 12080, loss = 0.55, batch loss = 0.35 (38.2 examples/sec; 0.209 sec/batch; 18h:37m:53s remains)
INFO - root - 2017-12-16 15:27:30.822950: step 12090, loss = 0.52, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 19h:26m:30s remains)
INFO - root - 2017-12-16 15:27:33.064503: step 12100, loss = 0.59, batch loss = 0.40 (34.7 examples/sec; 0.230 sec/batch; 20h:29m:50s remains)
INFO - root - 2017-12-16 15:27:35.438782: step 12110, loss = 0.53, batch loss = 0.33 (36.3 examples/sec; 0.221 sec/batch; 19h:38m:06s remains)
INFO - root - 2017-12-16 15:27:37.629362: step 12120, loss = 0.59, batch loss = 0.39 (36.9 examples/sec; 0.217 sec/batch; 19h:16m:54s remains)
INFO - root - 2017-12-16 15:27:39.861954: step 12130, loss = 0.61, batch loss = 0.42 (36.0 examples/sec; 0.222 sec/batch; 19h:46m:30s remains)
INFO - root - 2017-12-16 15:27:42.080703: step 12140, loss = 0.59, batch loss = 0.39 (35.4 examples/sec; 0.226 sec/batch; 20h:06m:15s remains)
INFO - root - 2017-12-16 15:27:44.258118: step 12150, loss = 0.56, batch loss = 0.37 (36.0 examples/sec; 0.222 sec/batch; 19h:47m:12s remains)
INFO - root - 2017-12-16 15:27:46.481154: step 12160, loss = 0.53, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 20h:02m:39s remains)
INFO - root - 2017-12-16 15:27:48.669193: step 12170, loss = 0.60, batch loss = 0.40 (36.2 examples/sec; 0.221 sec/batch; 19h:39m:46s remains)
INFO - root - 2017-12-16 15:27:50.887309: step 12180, loss = 0.58, batch loss = 0.39 (35.0 examples/sec; 0.228 sec/batch; 20h:19m:01s remains)
INFO - root - 2017-12-16 15:27:53.106145: step 12190, loss = 0.64, batch loss = 0.44 (35.5 examples/sec; 0.226 sec/batch; 20h:04m:14s remains)
INFO - root - 2017-12-16 15:27:55.323001: step 12200, loss = 0.57, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 19h:38m:19s remains)
INFO - root - 2017-12-16 15:27:57.660241: step 12210, loss = 0.58, batch loss = 0.39 (36.6 examples/sec; 0.218 sec/batch; 19h:25m:44s remains)
INFO - root - 2017-12-16 15:27:59.878059: step 12220, loss = 0.52, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 19h:37m:07s remains)
INFO - root - 2017-12-16 15:28:02.065337: step 12230, loss = 0.59, batch loss = 0.39 (37.0 examples/sec; 0.216 sec/batch; 19h:13m:33s remains)
INFO - root - 2017-12-16 15:28:04.274138: step 12240, loss = 0.58, batch loss = 0.39 (35.6 examples/sec; 0.225 sec/batch; 19h:58m:22s remains)
INFO - root - 2017-12-16 15:28:06.501018: step 12250, loss = 0.57, batch loss = 0.37 (37.2 examples/sec; 0.215 sec/batch; 19h:07m:35s remains)
INFO - root - 2017-12-16 15:28:08.749754: step 12260, loss = 0.52, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 19h:13m:20s remains)
INFO - root - 2017-12-16 15:28:10.971192: step 12270, loss = 0.55, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 19h:35m:49s remains)
INFO - root - 2017-12-16 15:28:13.173096: step 12280, loss = 0.58, batch loss = 0.38 (35.6 examples/sec; 0.225 sec/batch; 20h:00m:42s remains)
INFO - root - 2017-12-16 15:28:15.426388: step 12290, loss = 0.56, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 19h:40m:24s remains)
INFO - root - 2017-12-16 15:28:17.601454: step 12300, loss = 0.57, batch loss = 0.37 (37.3 examples/sec; 0.215 sec/batch; 19h:06m:07s remains)
INFO - root - 2017-12-16 15:28:19.967701: step 12310, loss = 0.54, batch loss = 0.34 (37.7 examples/sec; 0.212 sec/batch; 18h:53m:23s remains)
INFO - root - 2017-12-16 15:28:22.191277: step 12320, loss = 0.61, batch loss = 0.42 (36.2 examples/sec; 0.221 sec/batch; 19h:39m:26s remains)
INFO - root - 2017-12-16 15:28:24.417545: step 12330, loss = 0.52, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 20h:00m:24s remains)
INFO - root - 2017-12-16 15:28:26.617285: step 12340, loss = 0.54, batch loss = 0.35 (37.1 examples/sec; 0.216 sec/batch; 19h:10m:46s remains)
INFO - root - 2017-12-16 15:28:28.825662: step 12350, loss = 0.50, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 19h:08m:05s remains)
INFO - root - 2017-12-16 15:28:31.041793: step 12360, loss = 0.59, batch loss = 0.39 (37.2 examples/sec; 0.215 sec/batch; 19h:08m:25s remains)
INFO - root - 2017-12-16 15:28:33.255154: step 12370, loss = 0.58, batch loss = 0.38 (36.3 examples/sec; 0.220 sec/batch; 19h:34m:34s remains)
INFO - root - 2017-12-16 15:28:35.474938: step 12380, loss = 0.56, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 19h:49m:24s remains)
INFO - root - 2017-12-16 15:28:37.726681: step 12390, loss = 0.58, batch loss = 0.39 (35.5 examples/sec; 0.225 sec/batch; 20h:02m:35s remains)
INFO - root - 2017-12-16 15:28:39.934462: step 12400, loss = 0.48, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 19h:19m:24s remains)
INFO - root - 2017-12-16 15:28:42.258375: step 12410, loss = 0.61, batch loss = 0.42 (36.9 examples/sec; 0.217 sec/batch; 19h:17m:21s remains)
INFO - root - 2017-12-16 15:28:44.472704: step 12420, loss = 0.53, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 19h:30m:17s remains)
INFO - root - 2017-12-16 15:28:46.655639: step 12430, loss = 0.62, batch loss = 0.42 (37.4 examples/sec; 0.214 sec/batch; 19h:02m:29s remains)
INFO - root - 2017-12-16 15:28:48.868702: step 12440, loss = 0.56, batch loss = 0.37 (37.3 examples/sec; 0.215 sec/batch; 19h:04m:46s remains)
INFO - root - 2017-12-16 15:28:51.080268: step 12450, loss = 0.60, batch loss = 0.40 (35.3 examples/sec; 0.226 sec/batch; 20h:07m:41s remains)
INFO - root - 2017-12-16 15:28:53.279830: step 12460, loss = 0.53, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 19h:26m:21s remains)
INFO - root - 2017-12-16 15:28:55.495685: step 12470, loss = 0.54, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 19h:50m:20s remains)
INFO - root - 2017-12-16 15:28:57.725840: step 12480, loss = 0.61, batch loss = 0.42 (34.8 examples/sec; 0.230 sec/batch; 20h:26m:26s remains)
INFO - root - 2017-12-16 15:28:59.905202: step 12490, loss = 0.51, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 19h:44m:51s remains)
INFO - root - 2017-12-16 15:29:02.111082: step 12500, loss = 0.52, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 19h:42m:21s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-12500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-12500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 15:29:05.080614: step 12510, loss = 0.52, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 19h:12m:01s remains)
INFO - root - 2017-12-16 15:29:07.280239: step 12520, loss = 0.60, batch loss = 0.40 (36.0 examples/sec; 0.222 sec/batch; 19h:44m:08s remains)
INFO - root - 2017-12-16 15:29:09.482736: step 12530, loss = 0.53, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 19h:16m:21s remains)
INFO - root - 2017-12-16 15:29:11.710136: step 12540, loss = 0.55, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 19h:49m:49s remains)
INFO - root - 2017-12-16 15:29:13.933235: step 12550, loss = 0.65, batch loss = 0.46 (37.1 examples/sec; 0.215 sec/batch; 19h:08m:47s remains)
INFO - root - 2017-12-16 15:29:16.159555: step 12560, loss = 0.58, batch loss = 0.39 (36.5 examples/sec; 0.219 sec/batch; 19h:29m:22s remains)
INFO - root - 2017-12-16 15:29:18.395326: step 12570, loss = 0.61, batch loss = 0.41 (34.9 examples/sec; 0.229 sec/batch; 20h:23m:00s remains)
INFO - root - 2017-12-16 15:29:20.602650: step 12580, loss = 0.53, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 19h:52m:14s remains)
INFO - root - 2017-12-16 15:29:22.828778: step 12590, loss = 0.61, batch loss = 0.41 (37.2 examples/sec; 0.215 sec/batch; 19h:06m:36s remains)
INFO - root - 2017-12-16 15:29:25.054753: step 12600, loss = 0.52, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 20h:04m:07s remains)
INFO - root - 2017-12-16 15:29:27.375432: step 12610, loss = 0.57, batch loss = 0.38 (37.0 examples/sec; 0.216 sec/batch; 19h:14m:12s remains)
INFO - root - 2017-12-16 15:29:29.563885: step 12620, loss = 0.60, batch loss = 0.40 (34.8 examples/sec; 0.230 sec/batch; 20h:26m:32s remains)
INFO - root - 2017-12-16 15:29:31.746463: step 12630, loss = 0.53, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 19h:06m:35s remains)
INFO - root - 2017-12-16 15:29:33.951236: step 12640, loss = 0.60, batch loss = 0.41 (37.3 examples/sec; 0.215 sec/batch; 19h:03m:31s remains)
INFO - root - 2017-12-16 15:29:36.185401: step 12650, loss = 0.54, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 20h:09m:13s remains)
INFO - root - 2017-12-16 15:29:38.396205: step 12660, loss = 0.56, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 19h:21m:25s remains)
INFO - root - 2017-12-16 15:29:40.600871: step 12670, loss = 0.52, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 19h:27m:00s remains)
INFO - root - 2017-12-16 15:29:42.825407: step 12680, loss = 0.58, batch loss = 0.38 (36.8 examples/sec; 0.217 sec/batch; 19h:18m:17s remains)
INFO - root - 2017-12-16 15:29:45.020270: step 12690, loss = 0.53, batch loss = 0.34 (34.1 examples/sec; 0.235 sec/batch; 20h:50m:42s remains)
INFO - root - 2017-12-16 15:29:47.212803: step 12700, loss = 0.53, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 19h:23m:13s remains)
INFO - root - 2017-12-16 15:29:49.584550: step 12710, loss = 0.55, batch loss = 0.35 (35.5 examples/sec; 0.225 sec/batch; 19h:59m:40s remains)
INFO - root - 2017-12-16 15:29:51.766051: step 12720, loss = 0.58, batch loss = 0.39 (37.7 examples/sec; 0.212 sec/batch; 18h:50m:39s remains)
INFO - root - 2017-12-16 15:29:53.982376: step 12730, loss = 0.61, batch loss = 0.41 (34.8 examples/sec; 0.230 sec/batch; 20h:24m:17s remains)
INFO - root - 2017-12-16 15:29:56.180056: step 12740, loss = 0.48, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 19h:47m:16s remains)
INFO - root - 2017-12-16 15:29:58.402587: step 12750, loss = 0.57, batch loss = 0.37 (34.8 examples/sec; 0.230 sec/batch; 20h:23m:52s remains)
INFO - root - 2017-12-16 15:30:00.605548: step 12760, loss = 0.61, batch loss = 0.42 (36.9 examples/sec; 0.217 sec/batch; 19h:16m:42s remains)
INFO - root - 2017-12-16 15:30:02.801828: step 12770, loss = 0.57, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 19h:38m:14s remains)
INFO - root - 2017-12-16 15:30:05.025117: step 12780, loss = 0.59, batch loss = 0.40 (36.0 examples/sec; 0.222 sec/batch; 19h:42m:34s remains)
INFO - root - 2017-12-16 15:30:07.239560: step 12790, loss = 0.59, batch loss = 0.40 (37.5 examples/sec; 0.213 sec/batch; 18h:55m:54s remains)
INFO - root - 2017-12-16 15:30:09.470735: step 12800, loss = 0.50, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 19h:32m:56s remains)
INFO - root - 2017-12-16 15:30:11.860026: step 12810, loss = 0.53, batch loss = 0.34 (32.4 examples/sec; 0.247 sec/batch; 21h:57m:26s remains)
INFO - root - 2017-12-16 15:30:14.077903: step 12820, loss = 0.52, batch loss = 0.33 (35.3 examples/sec; 0.226 sec/batch; 20h:05m:58s remains)
INFO - root - 2017-12-16 15:30:16.273226: step 12830, loss = 0.63, batch loss = 0.44 (36.3 examples/sec; 0.220 sec/batch; 19h:33m:16s remains)
INFO - root - 2017-12-16 15:30:18.459465: step 12840, loss = 0.55, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 19h:19m:54s remains)
INFO - root - 2017-12-16 15:30:20.661698: step 12850, loss = 0.53, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 19h:36m:45s remains)
INFO - root - 2017-12-16 15:30:22.846777: step 12860, loss = 0.57, batch loss = 0.37 (36.8 examples/sec; 0.217 sec/batch; 19h:17m:11s remains)
INFO - root - 2017-12-16 15:30:25.036511: step 12870, loss = 0.60, batch loss = 0.40 (36.0 examples/sec; 0.222 sec/batch; 19h:42m:34s remains)
INFO - root - 2017-12-16 15:30:27.239348: step 12880, loss = 0.51, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 20h:08m:52s remains)
INFO - root - 2017-12-16 15:30:29.471130: step 12890, loss = 0.66, batch loss = 0.47 (36.4 examples/sec; 0.220 sec/batch; 19h:29m:54s remains)
INFO - root - 2017-12-16 15:30:31.684878: step 12900, loss = 0.59, batch loss = 0.39 (37.6 examples/sec; 0.213 sec/batch; 18h:53m:58s remains)
INFO - root - 2017-12-16 15:30:34.035713: step 12910, loss = 0.58, batch loss = 0.39 (35.5 examples/sec; 0.225 sec/batch; 20h:00m:15s remains)
INFO - root - 2017-12-16 15:30:36.222855: step 12920, loss = 0.52, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 20h:11m:35s remains)
INFO - root - 2017-12-16 15:30:38.438752: step 12930, loss = 0.54, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 19h:52m:33s remains)
INFO - root - 2017-12-16 15:30:40.654569: step 12940, loss = 0.64, batch loss = 0.45 (35.9 examples/sec; 0.223 sec/batch; 19h:45m:46s remains)
INFO - root - 2017-12-16 15:30:42.848688: step 12950, loss = 0.55, batch loss = 0.36 (37.0 examples/sec; 0.216 sec/batch; 19h:10m:57s remains)
INFO - root - 2017-12-16 15:30:45.069350: step 12960, loss = 0.53, batch loss = 0.33 (35.6 examples/sec; 0.224 sec/batch; 19h:55m:30s remains)
INFO - root - 2017-12-16 15:30:47.300453: step 12970, loss = 0.56, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 19h:20m:53s remains)
INFO - root - 2017-12-16 15:30:49.480452: step 12980, loss = 0.52, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 19h:27m:32s remains)
INFO - root - 2017-12-16 15:30:51.693699: step 12990, loss = 0.55, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 19h:31m:16s remains)
INFO - root - 2017-12-16 15:30:53.926413: step 13000, loss = 0.56, batch loss = 0.37 (35.8 examples/sec; 0.224 sec/batch; 19h:51m:26s remains)
INFO - root - 2017-12-16 15:30:56.269879: step 13010, loss = 0.64, batch loss = 0.45 (37.0 examples/sec; 0.216 sec/batch; 19h:11m:56s remains)
INFO - root - 2017-12-16 15:30:58.422071: step 13020, loss = 0.51, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 19h:40m:05s remains)
INFO - root - 2017-12-16 15:31:00.630601: step 13030, loss = 0.57, batch loss = 0.38 (37.1 examples/sec; 0.215 sec/batch; 19h:07m:17s remains)
INFO - root - 2017-12-16 15:31:02.841820: step 13040, loss = 0.53, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 19h:28m:15s remains)
INFO - root - 2017-12-16 15:31:05.061549: step 13050, loss = 0.52, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 19h:18m:32s remains)
INFO - root - 2017-12-16 15:31:07.258663: step 13060, loss = 0.52, batch loss = 0.33 (34.2 examples/sec; 0.234 sec/batch; 20h:45m:50s remains)
INFO - root - 2017-12-16 15:31:09.488554: step 13070, loss = 0.57, batch loss = 0.38 (36.0 examples/sec; 0.222 sec/batch; 19h:41m:59s remains)
INFO - root - 2017-12-16 15:31:11.719650: step 13080, loss = 0.50, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 19h:45m:45s remains)
INFO - root - 2017-12-16 15:31:13.970684: step 13090, loss = 0.62, batch loss = 0.43 (37.3 examples/sec; 0.215 sec/batch; 19h:02m:42s remains)
INFO - root - 2017-12-16 15:31:16.200058: step 13100, loss = 0.61, batch loss = 0.41 (35.6 examples/sec; 0.225 sec/batch; 19h:55m:38s remains)
INFO - root - 2017-12-16 15:31:18.519801: step 13110, loss = 0.49, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 20h:00m:12s remains)
INFO - root - 2017-12-16 15:31:20.713973: step 13120, loss = 0.70, batch loss = 0.51 (37.2 examples/sec; 0.215 sec/batch; 19h:05m:56s remains)
INFO - root - 2017-12-16 15:31:22.948920: step 13130, loss = 0.61, batch loss = 0.42 (34.4 examples/sec; 0.233 sec/batch; 20h:37m:54s remains)
INFO - root - 2017-12-16 15:31:25.195489: step 13140, loss = 0.55, batch loss = 0.35 (35.3 examples/sec; 0.227 sec/batch; 20h:07m:30s remains)
INFO - root - 2017-12-16 15:31:27.423842: step 13150, loss = 0.57, batch loss = 0.38 (35.5 examples/sec; 0.225 sec/batch; 19h:58m:56s remains)
INFO - root - 2017-12-16 15:31:29.657506: step 13160, loss = 0.51, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 18h:59m:04s remains)
INFO - root - 2017-12-16 15:31:31.857424: step 13170, loss = 0.62, batch loss = 0.43 (37.9 examples/sec; 0.211 sec/batch; 18h:44m:26s remains)
INFO - root - 2017-12-16 15:31:34.063004: step 13180, loss = 0.52, batch loss = 0.33 (37.5 examples/sec; 0.213 sec/batch; 18h:54m:29s remains)
INFO - root - 2017-12-16 15:31:36.295928: step 13190, loss = 0.67, batch loss = 0.47 (35.7 examples/sec; 0.224 sec/batch; 19h:52m:40s remains)
INFO - root - 2017-12-16 15:31:38.498231: step 13200, loss = 0.56, batch loss = 0.37 (35.2 examples/sec; 0.227 sec/batch; 20h:08m:59s remains)
INFO - root - 2017-12-16 15:31:40.866475: step 13210, loss = 0.48, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 19h:43m:10s remains)
INFO - root - 2017-12-16 15:31:43.084095: step 13220, loss = 0.55, batch loss = 0.36 (37.6 examples/sec; 0.213 sec/batch; 18h:53m:32s remains)
INFO - root - 2017-12-16 15:31:45.297705: step 13230, loss = 0.52, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 19h:24m:44s remains)
INFO - root - 2017-12-16 15:31:47.542229: step 13240, loss = 0.50, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 19h:31m:52s remains)
INFO - root - 2017-12-16 15:31:49.761504: step 13250, loss = 0.54, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 19h:51m:12s remains)
INFO - root - 2017-12-16 15:31:51.999600: step 13260, loss = 0.55, batch loss = 0.36 (35.3 examples/sec; 0.226 sec/batch; 20h:04m:56s remains)
INFO - root - 2017-12-16 15:31:54.231724: step 13270, loss = 0.48, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 19h:17m:37s remains)
INFO - root - 2017-12-16 15:31:56.447865: step 13280, loss = 0.52, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 19h:16m:53s remains)
INFO - root - 2017-12-16 15:31:58.649732: step 13290, loss = 0.56, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 19h:31m:44s remains)
INFO - root - 2017-12-16 15:32:00.841405: step 13300, loss = 0.57, batch loss = 0.38 (36.2 examples/sec; 0.221 sec/batch; 19h:37m:01s remains)
INFO - root - 2017-12-16 15:32:03.184016: step 13310, loss = 0.57, batch loss = 0.38 (36.5 examples/sec; 0.219 sec/batch; 19h:26m:05s remains)
INFO - root - 2017-12-16 15:32:05.398129: step 13320, loss = 0.54, batch loss = 0.35 (37.3 examples/sec; 0.214 sec/batch; 18h:59m:29s remains)
INFO - root - 2017-12-16 15:32:07.585747: step 13330, loss = 0.50, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 19h:19m:09s remains)
INFO - root - 2017-12-16 15:32:09.872670: step 13340, loss = 0.49, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 19h:27m:57s remains)
INFO - root - 2017-12-16 15:32:12.072852: step 13350, loss = 0.51, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 19h:14m:00s remains)
INFO - root - 2017-12-16 15:32:14.277620: step 13360, loss = 0.60, batch loss = 0.41 (36.7 examples/sec; 0.218 sec/batch; 19h:20m:19s remains)
INFO - root - 2017-12-16 15:32:16.515527: step 13370, loss = 0.46, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 20h:22m:37s remains)
INFO - root - 2017-12-16 15:32:18.727015: step 13380, loss = 0.55, batch loss = 0.36 (36.0 examples/sec; 0.222 sec/batch; 19h:40m:36s remains)
INFO - root - 2017-12-16 15:32:20.920212: step 13390, loss = 0.52, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 20h:02m:04s remains)
INFO - root - 2017-12-16 15:32:23.166665: step 13400, loss = 0.54, batch loss = 0.35 (34.4 examples/sec; 0.233 sec/batch; 20h:38m:25s remains)
INFO - root - 2017-12-16 15:32:25.524629: step 13410, loss = 0.51, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 19h:11m:32s remains)
INFO - root - 2017-12-16 15:32:27.714929: step 13420, loss = 0.52, batch loss = 0.33 (37.3 examples/sec; 0.215 sec/batch; 19h:01m:37s remains)
INFO - root - 2017-12-16 15:32:29.932885: step 13430, loss = 0.52, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 19h:56m:26s remains)
INFO - root - 2017-12-16 15:32:32.138373: step 13440, loss = 0.55, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 19h:03m:23s remains)
INFO - root - 2017-12-16 15:32:34.363091: step 13450, loss = 0.57, batch loss = 0.37 (35.8 examples/sec; 0.223 sec/batch; 19h:47m:29s remains)
INFO - root - 2017-12-16 15:32:36.615224: step 13460, loss = 0.52, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 19h:36m:12s remains)
INFO - root - 2017-12-16 15:32:38.825120: step 13470, loss = 0.46, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 19h:30m:11s remains)
INFO - root - 2017-12-16 15:32:41.002160: step 13480, loss = 0.59, batch loss = 0.39 (36.2 examples/sec; 0.221 sec/batch; 19h:33m:41s remains)
INFO - root - 2017-12-16 15:32:43.199862: step 13490, loss = 0.47, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 19h:15m:54s remains)
INFO - root - 2017-12-16 15:32:45.408796: step 13500, loss = 0.53, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 19h:23m:59s remains)
INFO - root - 2017-12-16 15:32:47.744131: step 13510, loss = 0.52, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 19h:41m:33s remains)
INFO - root - 2017-12-16 15:32:49.930640: step 13520, loss = 0.62, batch loss = 0.42 (37.9 examples/sec; 0.211 sec/batch; 18h:42m:31s remains)
INFO - root - 2017-12-16 15:32:52.168066: step 13530, loss = 0.51, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 19h:14m:55s remains)
INFO - root - 2017-12-16 15:32:54.432294: step 13540, loss = 0.50, batch loss = 0.31 (33.7 examples/sec; 0.237 sec/batch; 21h:02m:10s remains)
INFO - root - 2017-12-16 15:32:56.641387: step 13550, loss = 0.55, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 19h:40m:47s remains)
INFO - root - 2017-12-16 15:32:58.900866: step 13560, loss = 0.52, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 19h:23m:58s remains)
INFO - root - 2017-12-16 15:33:01.101813: step 13570, loss = 0.54, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 19h:45m:20s remains)
INFO - root - 2017-12-16 15:33:03.290369: step 13580, loss = 0.62, batch loss = 0.43 (36.2 examples/sec; 0.221 sec/batch; 19h:33m:04s remains)
INFO - root - 2017-12-16 15:33:05.550323: step 13590, loss = 0.59, batch loss = 0.40 (35.2 examples/sec; 0.227 sec/batch; 20h:07m:00s remains)
INFO - root - 2017-12-16 15:33:07.792057: step 13600, loss = 0.55, batch loss = 0.36 (35.2 examples/sec; 0.227 sec/batch; 20h:07m:01s remains)
INFO - root - 2017-12-16 15:33:10.140547: step 13610, loss = 0.51, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 19h:50m:33s remains)
INFO - root - 2017-12-16 15:33:12.368981: step 13620, loss = 0.65, batch loss = 0.46 (36.4 examples/sec; 0.220 sec/batch; 19h:27m:52s remains)
INFO - root - 2017-12-16 15:33:14.599076: step 13630, loss = 0.52, batch loss = 0.33 (35.2 examples/sec; 0.227 sec/batch; 20h:07m:03s remains)
INFO - root - 2017-12-16 15:33:16.830145: step 13640, loss = 0.62, batch loss = 0.43 (36.7 examples/sec; 0.218 sec/batch; 19h:19m:52s remains)
INFO - root - 2017-12-16 15:33:19.082099: step 13650, loss = 0.55, batch loss = 0.36 (35.1 examples/sec; 0.228 sec/batch; 20h:11m:17s remains)
INFO - root - 2017-12-16 15:33:21.306555: step 13660, loss = 0.52, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 19h:11m:48s remains)
INFO - root - 2017-12-16 15:33:23.544347: step 13670, loss = 0.52, batch loss = 0.33 (36.3 examples/sec; 0.221 sec/batch; 19h:32m:21s remains)
INFO - root - 2017-12-16 15:33:25.736667: step 13680, loss = 0.57, batch loss = 0.37 (35.1 examples/sec; 0.228 sec/batch; 20h:10m:59s remains)
INFO - root - 2017-12-16 15:33:27.985232: step 13690, loss = 0.57, batch loss = 0.38 (35.4 examples/sec; 0.226 sec/batch; 20h:01m:23s remains)
INFO - root - 2017-12-16 15:33:30.197046: step 13700, loss = 0.56, batch loss = 0.37 (35.6 examples/sec; 0.225 sec/batch; 19h:52m:54s remains)
INFO - root - 2017-12-16 15:33:32.552855: step 13710, loss = 0.55, batch loss = 0.36 (35.8 examples/sec; 0.223 sec/batch; 19h:47m:19s remains)
INFO - root - 2017-12-16 15:33:34.776202: step 13720, loss = 0.49, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 19h:16m:45s remains)
INFO - root - 2017-12-16 15:33:37.029093: step 13730, loss = 0.48, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 19h:20m:00s remains)
INFO - root - 2017-12-16 15:33:39.253729: step 13740, loss = 0.53, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 19h:11m:13s remains)
INFO - root - 2017-12-16 15:33:41.458858: step 13750, loss = 0.52, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 19h:01m:57s remains)
INFO - root - 2017-12-16 15:33:43.671232: step 13760, loss = 0.52, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 18h:57m:33s remains)
INFO - root - 2017-12-16 15:33:45.900376: step 13770, loss = 0.54, batch loss = 0.35 (33.9 examples/sec; 0.236 sec/batch; 20h:52m:01s remains)
INFO - root - 2017-12-16 15:33:48.077726: step 13780, loss = 0.54, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 19h:14m:16s remains)
INFO - root - 2017-12-16 15:33:50.291654: step 13790, loss = 0.54, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 19h:34m:07s remains)
INFO - root - 2017-12-16 15:33:52.509848: step 13800, loss = 0.50, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 19h:48m:49s remains)
INFO - root - 2017-12-16 15:33:54.905517: step 13810, loss = 0.54, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 19h:34m:28s remains)
INFO - root - 2017-12-16 15:33:57.116047: step 13820, loss = 0.58, batch loss = 0.39 (35.8 examples/sec; 0.223 sec/batch; 19h:45m:35s remains)
INFO - root - 2017-12-16 15:33:59.351028: step 13830, loss = 0.52, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 19h:10m:06s remains)
INFO - root - 2017-12-16 15:34:01.537228: step 13840, loss = 0.53, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 19h:15m:16s remains)
INFO - root - 2017-12-16 15:34:03.750208: step 13850, loss = 0.53, batch loss = 0.33 (37.5 examples/sec; 0.213 sec/batch; 18h:53m:22s remains)
INFO - root - 2017-12-16 15:34:06.023674: step 13860, loss = 0.49, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 19h:28m:55s remains)
INFO - root - 2017-12-16 15:34:08.195379: step 13870, loss = 0.58, batch loss = 0.39 (35.5 examples/sec; 0.226 sec/batch; 19h:58m:11s remains)
INFO - root - 2017-12-16 15:34:10.457702: step 13880, loss = 0.52, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 19h:30m:05s remains)
INFO - root - 2017-12-16 15:34:12.698092: step 13890, loss = 0.49, batch loss = 0.30 (31.7 examples/sec; 0.252 sec/batch; 22h:20m:29s remains)
INFO - root - 2017-12-16 15:34:14.917776: step 13900, loss = 0.55, batch loss = 0.36 (34.3 examples/sec; 0.233 sec/batch; 20h:37m:23s remains)
INFO - root - 2017-12-16 15:34:17.262495: step 13910, loss = 0.66, batch loss = 0.46 (36.0 examples/sec; 0.222 sec/batch; 19h:40m:39s remains)
INFO - root - 2017-12-16 15:34:19.524682: step 13920, loss = 0.52, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 20h:19m:46s remains)
INFO - root - 2017-12-16 15:34:21.790675: step 13930, loss = 0.59, batch loss = 0.40 (36.1 examples/sec; 0.222 sec/batch; 19h:37m:48s remains)
INFO - root - 2017-12-16 15:34:24.000684: step 13940, loss = 0.61, batch loss = 0.42 (36.8 examples/sec; 0.217 sec/batch; 19h:13m:21s remains)
INFO - root - 2017-12-16 15:34:26.208324: step 13950, loss = 0.59, batch loss = 0.40 (34.9 examples/sec; 0.229 sec/batch; 20h:16m:25s remains)
INFO - root - 2017-12-16 15:34:28.435033: step 13960, loss = 0.51, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 20h:08m:57s remains)
INFO - root - 2017-12-16 15:34:30.652156: step 13970, loss = 0.65, batch loss = 0.46 (36.0 examples/sec; 0.222 sec/batch; 19h:40m:11s remains)
INFO - root - 2017-12-16 15:34:32.895130: step 13980, loss = 0.48, batch loss = 0.29 (36.4 examples/sec; 0.219 sec/batch; 19h:25m:14s remains)
INFO - root - 2017-12-16 15:34:35.100318: step 13990, loss = 0.59, batch loss = 0.40 (38.7 examples/sec; 0.207 sec/batch; 18h:18m:35s remains)
INFO - root - 2017-12-16 15:34:37.337581: step 14000, loss = 0.50, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 19h:46m:41s remains)
INFO - root - 2017-12-16 15:34:39.714143: step 14010, loss = 0.57, batch loss = 0.37 (35.8 examples/sec; 0.224 sec/batch; 19h:46m:45s remains)
INFO - root - 2017-12-16 15:34:41.951020: step 14020, loss = 0.55, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 19h:23m:36s remains)
INFO - root - 2017-12-16 15:34:44.177350: step 14030, loss = 0.60, batch loss = 0.41 (36.2 examples/sec; 0.221 sec/batch; 19h:32m:11s remains)
INFO - root - 2017-12-16 15:34:46.371560: step 14040, loss = 0.58, batch loss = 0.39 (35.5 examples/sec; 0.225 sec/batch; 19h:54m:31s remains)
INFO - root - 2017-12-16 15:34:48.569993: step 14050, loss = 0.60, batch loss = 0.41 (36.3 examples/sec; 0.221 sec/batch; 19h:30m:35s remains)
INFO - root - 2017-12-16 15:34:50.771521: step 14060, loss = 0.52, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 19h:02m:34s remains)
INFO - root - 2017-12-16 15:34:52.968387: step 14070, loss = 0.60, batch loss = 0.41 (35.1 examples/sec; 0.228 sec/batch; 20h:08m:07s remains)
INFO - root - 2017-12-16 15:34:55.148571: step 14080, loss = 0.50, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 18h:52m:30s remains)
INFO - root - 2017-12-16 15:34:57.364522: step 14090, loss = 0.51, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 20h:17m:01s remains)
INFO - root - 2017-12-16 15:34:59.593527: step 14100, loss = 0.52, batch loss = 0.33 (34.0 examples/sec; 0.236 sec/batch; 20h:49m:47s remains)
INFO - root - 2017-12-16 15:35:01.949093: step 14110, loss = 0.52, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 19h:54m:01s remains)
INFO - root - 2017-12-16 15:35:04.178092: step 14120, loss = 0.58, batch loss = 0.39 (37.0 examples/sec; 0.216 sec/batch; 19h:06m:02s remains)
INFO - root - 2017-12-16 15:35:06.401649: step 14130, loss = 0.56, batch loss = 0.37 (35.3 examples/sec; 0.227 sec/batch; 20h:01m:59s remains)
INFO - root - 2017-12-16 15:35:08.634189: step 14140, loss = 0.57, batch loss = 0.38 (35.8 examples/sec; 0.224 sec/batch; 19h:47m:21s remains)
INFO - root - 2017-12-16 15:35:10.838795: step 14150, loss = 0.54, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 19h:07m:53s remains)
INFO - root - 2017-12-16 15:35:13.019419: step 14160, loss = 0.48, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 19h:27m:37s remains)
INFO - root - 2017-12-16 15:35:15.255951: step 14170, loss = 0.62, batch loss = 0.42 (37.2 examples/sec; 0.215 sec/batch; 19h:00m:14s remains)
INFO - root - 2017-12-16 15:35:17.471643: step 14180, loss = 0.55, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 19h:50m:04s remains)
INFO - root - 2017-12-16 15:35:19.662383: step 14190, loss = 0.59, batch loss = 0.40 (35.9 examples/sec; 0.223 sec/batch; 19h:41m:23s remains)
INFO - root - 2017-12-16 15:35:21.856342: step 14200, loss = 0.60, batch loss = 0.41 (37.1 examples/sec; 0.215 sec/batch; 19h:02m:58s remains)
INFO - root - 2017-12-16 15:35:24.228232: step 14210, loss = 0.49, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 19h:05m:02s remains)
INFO - root - 2017-12-16 15:35:26.435015: step 14220, loss = 0.49, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 18h:58m:14s remains)
INFO - root - 2017-12-16 15:35:28.624627: step 14230, loss = 0.53, batch loss = 0.34 (37.5 examples/sec; 0.213 sec/batch; 18h:51m:38s remains)
INFO - root - 2017-12-16 15:35:30.835829: step 14240, loss = 0.56, batch loss = 0.37 (37.5 examples/sec; 0.213 sec/batch; 18h:51m:28s remains)
INFO - root - 2017-12-16 15:35:33.039841: step 14250, loss = 0.51, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 19h:25m:22s remains)
INFO - root - 2017-12-16 15:35:35.239722: step 14260, loss = 0.58, batch loss = 0.39 (37.1 examples/sec; 0.216 sec/batch; 19h:03m:58s remains)
INFO - root - 2017-12-16 15:35:37.463326: step 14270, loss = 0.61, batch loss = 0.42 (36.1 examples/sec; 0.222 sec/batch; 19h:35m:45s remains)
INFO - root - 2017-12-16 15:35:39.710115: step 14280, loss = 0.51, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 19h:22m:21s remains)
INFO - root - 2017-12-16 15:35:41.931341: step 14290, loss = 0.52, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 19h:25m:01s remains)
INFO - root - 2017-12-16 15:35:44.130211: step 14300, loss = 0.57, batch loss = 0.38 (36.6 examples/sec; 0.218 sec/batch; 19h:18m:03s remains)
INFO - root - 2017-12-16 15:35:46.452302: step 14310, loss = 0.57, batch loss = 0.38 (37.1 examples/sec; 0.216 sec/batch; 19h:03m:03s remains)
INFO - root - 2017-12-16 15:35:48.655526: step 14320, loss = 0.55, batch loss = 0.36 (35.8 examples/sec; 0.223 sec/batch; 19h:44m:06s remains)
INFO - root - 2017-12-16 15:35:50.867818: step 14330, loss = 0.57, batch loss = 0.38 (36.9 examples/sec; 0.217 sec/batch; 19h:10m:13s remains)
INFO - root - 2017-12-16 15:35:53.060325: step 14340, loss = 0.49, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 19h:24m:18s remains)
INFO - root - 2017-12-16 15:35:55.279814: step 14350, loss = 0.53, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 19h:30m:58s remains)
INFO - root - 2017-12-16 15:35:57.532818: step 14360, loss = 0.62, batch loss = 0.43 (36.1 examples/sec; 0.222 sec/batch; 19h:36m:07s remains)
INFO - root - 2017-12-16 15:35:59.765025: step 14370, loss = 0.51, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 19h:23m:02s remains)
INFO - root - 2017-12-16 15:36:02.009542: step 14380, loss = 0.54, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 19h:35m:57s remains)
INFO - root - 2017-12-16 15:36:04.197752: step 14390, loss = 0.62, batch loss = 0.42 (36.1 examples/sec; 0.222 sec/batch; 19h:35m:43s remains)
INFO - root - 2017-12-16 15:36:06.463094: step 14400, loss = 0.59, batch loss = 0.40 (36.6 examples/sec; 0.219 sec/batch; 19h:19m:51s remains)
INFO - root - 2017-12-16 15:36:08.827906: step 14410, loss = 0.47, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 19h:40m:56s remains)
INFO - root - 2017-12-16 15:36:11.054066: step 14420, loss = 0.63, batch loss = 0.44 (37.6 examples/sec; 0.213 sec/batch; 18h:47m:06s remains)
INFO - root - 2017-12-16 15:36:13.330671: step 14430, loss = 0.54, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 19h:32m:04s remains)
INFO - root - 2017-12-16 15:36:15.564409: step 14440, loss = 0.57, batch loss = 0.38 (35.2 examples/sec; 0.227 sec/batch; 20h:04m:29s remains)
INFO - root - 2017-12-16 15:36:17.809710: step 14450, loss = 0.55, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 19h:40m:22s remains)
INFO - root - 2017-12-16 15:36:20.004936: step 14460, loss = 0.62, batch loss = 0.43 (37.0 examples/sec; 0.216 sec/batch; 19h:05m:28s remains)
INFO - root - 2017-12-16 15:36:22.243657: step 14470, loss = 0.52, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 19h:33m:58s remains)
INFO - root - 2017-12-16 15:36:24.505552: step 14480, loss = 0.49, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 19h:46m:20s remains)
INFO - root - 2017-12-16 15:36:26.742491: step 14490, loss = 0.54, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 19h:36m:48s remains)
INFO - root - 2017-12-16 15:36:29.008171: step 14500, loss = 0.61, batch loss = 0.42 (35.0 examples/sec; 0.228 sec/batch; 20h:10m:50s remains)
INFO - root - 2017-12-16 15:36:31.324088: step 14510, loss = 0.57, batch loss = 0.38 (36.2 examples/sec; 0.221 sec/batch; 19h:30m:42s remains)
INFO - root - 2017-12-16 15:36:33.557491: step 14520, loss = 0.51, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 19h:51m:56s remains)
INFO - root - 2017-12-16 15:36:35.802229: step 14530, loss = 0.53, batch loss = 0.34 (36.1 examples/sec; 0.221 sec/batch; 19h:32m:47s remains)
INFO - root - 2017-12-16 15:36:38.027613: step 14540, loss = 0.60, batch loss = 0.41 (36.0 examples/sec; 0.222 sec/batch; 19h:36m:00s remains)
INFO - root - 2017-12-16 15:36:40.251798: step 14550, loss = 0.53, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 19h:14m:22s remains)
INFO - root - 2017-12-16 15:36:42.455912: step 14560, loss = 0.54, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 19h:38m:48s remains)
INFO - root - 2017-12-16 15:36:44.670140: step 14570, loss = 0.57, batch loss = 0.38 (36.6 examples/sec; 0.219 sec/batch; 19h:18m:17s remains)
INFO - root - 2017-12-16 15:36:46.861070: step 14580, loss = 0.58, batch loss = 0.39 (36.8 examples/sec; 0.217 sec/batch; 19h:12m:03s remains)
INFO - root - 2017-12-16 15:36:49.107882: step 14590, loss = 0.50, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 20h:19m:08s remains)
INFO - root - 2017-12-16 15:36:51.305759: step 14600, loss = 0.49, batch loss = 0.30 (34.7 examples/sec; 0.230 sec/batch; 20h:20m:12s remains)
INFO - root - 2017-12-16 15:36:53.640542: step 14610, loss = 0.58, batch loss = 0.39 (37.0 examples/sec; 0.216 sec/batch; 19h:04m:52s remains)
INFO - root - 2017-12-16 15:36:55.842489: step 14620, loss = 0.50, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 19h:41m:16s remains)
INFO - root - 2017-12-16 15:36:58.140582: step 14630, loss = 0.54, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 19h:50m:01s remains)
INFO - root - 2017-12-16 15:37:00.352839: step 14640, loss = 0.52, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 19h:41m:01s remains)
INFO - root - 2017-12-16 15:37:02.586011: step 14650, loss = 0.51, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 19h:13m:01s remains)
INFO - root - 2017-12-16 15:37:04.886243: step 14660, loss = 0.59, batch loss = 0.40 (36.1 examples/sec; 0.222 sec/batch; 19h:35m:03s remains)
INFO - root - 2017-12-16 15:37:07.099221: step 14670, loss = 0.52, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 19h:00m:41s remains)
INFO - root - 2017-12-16 15:37:09.307271: step 14680, loss = 0.52, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 19h:44m:27s remains)
INFO - root - 2017-12-16 15:37:11.539000: step 14690, loss = 0.48, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 20h:03m:23s remains)
INFO - root - 2017-12-16 15:37:13.751428: step 14700, loss = 0.57, batch loss = 0.38 (36.5 examples/sec; 0.219 sec/batch; 19h:19m:20s remains)
INFO - root - 2017-12-16 15:37:16.114601: step 14710, loss = 0.57, batch loss = 0.38 (35.5 examples/sec; 0.225 sec/batch; 19h:52m:35s remains)
INFO - root - 2017-12-16 15:37:18.322606: step 14720, loss = 0.54, batch loss = 0.35 (33.8 examples/sec; 0.236 sec/batch; 20h:51m:44s remains)
INFO - root - 2017-12-16 15:37:20.571504: step 14730, loss = 0.52, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 19h:40m:57s remains)
INFO - root - 2017-12-16 15:37:22.791743: step 14740, loss = 0.55, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 19h:08m:23s remains)
INFO - root - 2017-12-16 15:37:25.035816: step 14750, loss = 0.52, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 19h:37m:54s remains)
INFO - root - 2017-12-16 15:37:27.308646: step 14760, loss = 0.52, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 19h:42m:03s remains)
INFO - root - 2017-12-16 15:37:29.535376: step 14770, loss = 0.58, batch loss = 0.39 (35.4 examples/sec; 0.226 sec/batch; 19h:55m:48s remains)
INFO - root - 2017-12-16 15:37:31.776135: step 14780, loss = 0.56, batch loss = 0.37 (35.7 examples/sec; 0.224 sec/batch; 19h:46m:14s remains)
INFO - root - 2017-12-16 15:37:33.973812: step 14790, loss = 0.62, batch loss = 0.43 (35.9 examples/sec; 0.223 sec/batch; 19h:38m:47s remains)
INFO - root - 2017-12-16 15:37:36.196023: step 14800, loss = 0.59, batch loss = 0.40 (34.1 examples/sec; 0.234 sec/batch; 20h:41m:00s remains)
INFO - root - 2017-12-16 15:37:38.547056: step 14810, loss = 0.55, batch loss = 0.36 (35.0 examples/sec; 0.228 sec/batch; 20h:08m:35s remains)
INFO - root - 2017-12-16 15:37:40.765928: step 14820, loss = 0.55, batch loss = 0.36 (36.1 examples/sec; 0.221 sec/batch; 19h:32m:29s remains)
INFO - root - 2017-12-16 15:37:42.961318: step 14830, loss = 0.51, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 18h:54m:22s remains)
INFO - root - 2017-12-16 15:37:45.193454: step 14840, loss = 0.51, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 19h:11m:05s remains)
INFO - root - 2017-12-16 15:37:47.422872: step 14850, loss = 0.58, batch loss = 0.39 (36.2 examples/sec; 0.221 sec/batch; 19h:30m:09s remains)
INFO - root - 2017-12-16 15:37:49.640972: step 14860, loss = 0.57, batch loss = 0.38 (33.9 examples/sec; 0.236 sec/batch; 20h:48m:51s remains)
INFO - root - 2017-12-16 15:37:51.854383: step 14870, loss = 0.61, batch loss = 0.42 (35.6 examples/sec; 0.225 sec/batch; 19h:50m:06s remains)
INFO - root - 2017-12-16 15:37:54.093264: step 14880, loss = 0.58, batch loss = 0.39 (35.0 examples/sec; 0.228 sec/batch; 20h:08m:32s remains)
INFO - root - 2017-12-16 15:37:56.294724: step 14890, loss = 0.56, batch loss = 0.37 (37.3 examples/sec; 0.215 sec/batch; 18h:55m:30s remains)
INFO - root - 2017-12-16 15:37:58.524974: step 14900, loss = 0.53, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 19h:06m:41s remains)
INFO - root - 2017-12-16 15:38:00.852610: step 14910, loss = 0.54, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 19h:18m:42s remains)
INFO - root - 2017-12-16 15:38:03.089023: step 14920, loss = 0.51, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 19h:25m:07s remains)
INFO - root - 2017-12-16 15:38:05.325002: step 14930, loss = 0.51, batch loss = 0.31 (35.6 examples/sec; 0.224 sec/batch; 19h:47m:55s remains)
INFO - root - 2017-12-16 15:38:07.576028: step 14940, loss = 0.56, batch loss = 0.37 (33.3 examples/sec; 0.240 sec/batch; 21h:10m:36s remains)
INFO - root - 2017-12-16 15:38:09.790983: step 14950, loss = 0.53, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 19h:49m:33s remains)
INFO - root - 2017-12-16 15:38:12.056385: step 14960, loss = 0.61, batch loss = 0.42 (36.1 examples/sec; 0.222 sec/batch; 19h:32m:33s remains)
INFO - root - 2017-12-16 15:38:14.276620: step 14970, loss = 0.49, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 19h:27m:40s remains)
INFO - root - 2017-12-16 15:38:16.473791: step 14980, loss = 0.48, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 19h:02m:43s remains)
INFO - root - 2017-12-16 15:38:18.708920: step 14990, loss = 0.61, batch loss = 0.42 (32.4 examples/sec; 0.247 sec/batch; 21h:45m:26s remains)
INFO - root - 2017-12-16 15:38:20.962967: step 15000, loss = 0.58, batch loss = 0.39 (35.3 examples/sec; 0.227 sec/batch; 20h:00m:53s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-15000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-15000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 15:38:23.819393: step 15010, loss = 0.57, batch loss = 0.38 (36.0 examples/sec; 0.222 sec/batch; 19h:35m:38s remains)
INFO - root - 2017-12-16 15:38:26.034090: step 15020, loss = 0.47, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 19h:36m:13s remains)
INFO - root - 2017-12-16 15:38:28.262748: step 15030, loss = 0.54, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 19h:39m:10s remains)
INFO - root - 2017-12-16 15:38:30.505098: step 15040, loss = 0.50, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 19h:52m:03s remains)
INFO - root - 2017-12-16 15:38:32.732843: step 15050, loss = 0.53, batch loss = 0.34 (34.3 examples/sec; 0.233 sec/batch; 20h:32m:35s remains)
INFO - root - 2017-12-16 15:38:34.954049: step 15060, loss = 0.50, batch loss = 0.31 (35.5 examples/sec; 0.226 sec/batch; 19h:53m:29s remains)
INFO - root - 2017-12-16 15:38:37.197031: step 15070, loss = 0.56, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 19h:25m:42s remains)
INFO - root - 2017-12-16 15:38:39.446298: step 15080, loss = 0.51, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 19h:18m:52s remains)
INFO - root - 2017-12-16 15:38:41.625281: step 15090, loss = 0.56, batch loss = 0.37 (37.1 examples/sec; 0.216 sec/batch; 19h:01m:07s remains)
INFO - root - 2017-12-16 15:38:43.883190: step 15100, loss = 0.60, batch loss = 0.41 (37.0 examples/sec; 0.216 sec/batch; 19h:04m:47s remains)
INFO - root - 2017-12-16 15:38:46.208554: step 15110, loss = 0.66, batch loss = 0.47 (36.8 examples/sec; 0.218 sec/batch; 19h:10m:47s remains)
INFO - root - 2017-12-16 15:38:48.421573: step 15120, loss = 0.54, batch loss = 0.35 (35.1 examples/sec; 0.228 sec/batch; 20h:04m:17s remains)
INFO - root - 2017-12-16 15:38:50.628796: step 15130, loss = 0.58, batch loss = 0.39 (36.9 examples/sec; 0.217 sec/batch; 19h:05m:50s remains)
INFO - root - 2017-12-16 15:38:52.867939: step 15140, loss = 0.54, batch loss = 0.35 (37.4 examples/sec; 0.214 sec/batch; 18h:51m:43s remains)
INFO - root - 2017-12-16 15:38:55.100736: step 15150, loss = 0.50, batch loss = 0.31 (37.1 examples/sec; 0.215 sec/batch; 18h:59m:16s remains)
INFO - root - 2017-12-16 15:38:57.319075: step 15160, loss = 0.49, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 19h:02m:19s remains)
INFO - root - 2017-12-16 15:38:59.520820: step 15170, loss = 0.46, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 19h:14m:55s remains)
INFO - root - 2017-12-16 15:39:01.742538: step 15180, loss = 0.50, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 19h:33m:27s remains)
INFO - root - 2017-12-16 15:39:04.007974: step 15190, loss = 0.53, batch loss = 0.34 (35.0 examples/sec; 0.229 sec/batch; 20h:09m:31s remains)
INFO - root - 2017-12-16 15:39:06.226574: step 15200, loss = 0.58, batch loss = 0.39 (37.4 examples/sec; 0.214 sec/batch; 18h:50m:38s remains)
INFO - root - 2017-12-16 15:39:08.620860: step 15210, loss = 0.50, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 19h:34m:44s remains)
INFO - root - 2017-12-16 15:39:10.835122: step 15220, loss = 0.52, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 19h:56m:05s remains)
INFO - root - 2017-12-16 15:39:13.045373: step 15230, loss = 0.57, batch loss = 0.38 (36.0 examples/sec; 0.222 sec/batch; 19h:34m:05s remains)
INFO - root - 2017-12-16 15:39:15.239414: step 15240, loss = 0.53, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 19h:18m:40s remains)
INFO - root - 2017-12-16 15:39:17.470353: step 15250, loss = 0.59, batch loss = 0.40 (34.4 examples/sec; 0.232 sec/batch; 20h:27m:55s remains)
INFO - root - 2017-12-16 15:39:19.650603: step 15260, loss = 0.53, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 19h:48m:17s remains)
INFO - root - 2017-12-16 15:39:21.842655: step 15270, loss = 0.53, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 19h:06m:39s remains)
INFO - root - 2017-12-16 15:39:24.105580: step 15280, loss = 0.53, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 19h:39m:33s remains)
INFO - root - 2017-12-16 15:39:26.321546: step 15290, loss = 0.56, batch loss = 0.37 (36.0 examples/sec; 0.222 sec/batch; 19h:34m:05s remains)
INFO - root - 2017-12-16 15:39:28.496801: step 15300, loss = 0.56, batch loss = 0.37 (35.8 examples/sec; 0.223 sec/batch; 19h:39m:53s remains)
INFO - root - 2017-12-16 15:39:30.871535: step 15310, loss = 0.48, batch loss = 0.29 (34.6 examples/sec; 0.231 sec/batch; 20h:20m:58s remains)
INFO - root - 2017-12-16 15:39:33.138352: step 15320, loss = 0.51, batch loss = 0.32 (34.6 examples/sec; 0.231 sec/batch; 20h:23m:21s remains)
INFO - root - 2017-12-16 15:39:35.348010: step 15330, loss = 0.60, batch loss = 0.41 (36.2 examples/sec; 0.221 sec/batch; 19h:28m:22s remains)
INFO - root - 2017-12-16 15:39:37.545184: step 15340, loss = 0.57, batch loss = 0.38 (34.6 examples/sec; 0.231 sec/batch; 20h:23m:07s remains)
INFO - root - 2017-12-16 15:39:39.802543: step 15350, loss = 0.54, batch loss = 0.35 (35.0 examples/sec; 0.229 sec/batch; 20h:07m:50s remains)
INFO - root - 2017-12-16 15:39:42.045236: step 15360, loss = 0.51, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 19h:30m:29s remains)
INFO - root - 2017-12-16 15:39:44.302288: step 15370, loss = 0.49, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 19h:32m:27s remains)
INFO - root - 2017-12-16 15:39:46.486316: step 15380, loss = 0.55, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 19h:39m:11s remains)
INFO - root - 2017-12-16 15:39:48.711115: step 15390, loss = 0.54, batch loss = 0.35 (37.7 examples/sec; 0.212 sec/batch; 18h:40m:53s remains)
INFO - root - 2017-12-16 15:39:50.943039: step 15400, loss = 0.58, batch loss = 0.39 (34.0 examples/sec; 0.235 sec/batch; 20h:42m:43s remains)
INFO - root - 2017-12-16 15:39:53.309355: step 15410, loss = 0.50, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 19h:29m:30s remains)
INFO - root - 2017-12-16 15:39:55.524632: step 15420, loss = 0.53, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 19h:30m:50s remains)
INFO - root - 2017-12-16 15:39:57.736176: step 15430, loss = 0.51, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 19h:29m:42s remains)
INFO - root - 2017-12-16 15:39:59.959748: step 15440, loss = 0.57, batch loss = 0.38 (36.6 examples/sec; 0.218 sec/batch; 19h:14m:00s remains)
INFO - root - 2017-12-16 15:40:02.201650: step 15450, loss = 0.47, batch loss = 0.28 (34.5 examples/sec; 0.232 sec/batch; 20h:24m:37s remains)
INFO - root - 2017-12-16 15:40:04.398898: step 15460, loss = 0.49, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 18h:51m:42s remains)
INFO - root - 2017-12-16 15:40:06.639023: step 15470, loss = 0.48, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 19h:31m:17s remains)
INFO - root - 2017-12-16 15:40:08.895793: step 15480, loss = 0.60, batch loss = 0.41 (35.3 examples/sec; 0.227 sec/batch; 19h:56m:53s remains)
INFO - root - 2017-12-16 15:40:11.125280: step 15490, loss = 0.50, batch loss = 0.32 (34.2 examples/sec; 0.234 sec/batch; 20h:34m:53s remains)
INFO - root - 2017-12-16 15:40:13.350733: step 15500, loss = 0.56, batch loss = 0.37 (36.9 examples/sec; 0.217 sec/batch; 19h:05m:02s remains)
INFO - root - 2017-12-16 15:40:15.700117: step 15510, loss = 0.50, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 19h:31m:32s remains)
INFO - root - 2017-12-16 15:40:17.903174: step 15520, loss = 0.56, batch loss = 0.37 (36.1 examples/sec; 0.221 sec/batch; 19h:29m:53s remains)
INFO - root - 2017-12-16 15:40:20.127539: step 15530, loss = 0.53, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 19h:54m:04s remains)
INFO - root - 2017-12-16 15:40:22.357190: step 15540, loss = 0.56, batch loss = 0.37 (34.7 examples/sec; 0.231 sec/batch; 20h:17m:50s remains)
INFO - root - 2017-12-16 15:40:24.569438: step 15550, loss = 0.50, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 19h:09m:15s remains)
INFO - root - 2017-12-16 15:40:26.775731: step 15560, loss = 0.54, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 19h:12m:45s remains)
INFO - root - 2017-12-16 15:40:28.968718: step 15570, loss = 0.67, batch loss = 0.48 (36.6 examples/sec; 0.218 sec/batch; 19h:13m:50s remains)
INFO - root - 2017-12-16 15:40:31.221519: step 15580, loss = 0.54, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 19h:25m:53s remains)
INFO - root - 2017-12-16 15:40:33.463974: step 15590, loss = 0.55, batch loss = 0.36 (35.8 examples/sec; 0.223 sec/batch; 19h:40m:21s remains)
INFO - root - 2017-12-16 15:40:35.660708: step 15600, loss = 0.54, batch loss = 0.35 (34.5 examples/sec; 0.232 sec/batch; 20h:24m:37s remains)
INFO - root - 2017-12-16 15:40:38.027912: step 15610, loss = 0.48, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 20h:34m:39s remains)
INFO - root - 2017-12-16 15:40:40.230989: step 15620, loss = 0.53, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 19h:09m:09s remains)
INFO - root - 2017-12-16 15:40:42.449597: step 15630, loss = 0.58, batch loss = 0.39 (35.5 examples/sec; 0.226 sec/batch; 19h:51m:36s remains)
INFO - root - 2017-12-16 15:40:44.668794: step 15640, loss = 0.53, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 19h:50m:05s remains)
INFO - root - 2017-12-16 15:40:46.869561: step 15650, loss = 0.53, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 19h:30m:30s remains)
INFO - root - 2017-12-16 15:40:49.080863: step 15660, loss = 0.47, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 19h:10m:51s remains)
INFO - root - 2017-12-16 15:40:51.336094: step 15670, loss = 0.51, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 20h:02m:25s remains)
INFO - root - 2017-12-16 15:40:53.567233: step 15680, loss = 0.48, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 19h:50m:42s remains)
INFO - root - 2017-12-16 15:40:55.807380: step 15690, loss = 0.47, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 19h:48m:38s remains)
INFO - root - 2017-12-16 15:40:58.026263: step 15700, loss = 0.54, batch loss = 0.35 (35.5 examples/sec; 0.226 sec/batch; 19h:51m:11s remains)
INFO - root - 2017-12-16 15:41:00.392006: step 15710, loss = 0.53, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 19h:40m:51s remains)
INFO - root - 2017-12-16 15:41:02.609624: step 15720, loss = 0.48, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 19h:52m:50s remains)
INFO - root - 2017-12-16 15:41:04.818717: step 15730, loss = 0.50, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 19h:29m:07s remains)
INFO - root - 2017-12-16 15:41:07.025934: step 15740, loss = 0.50, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 19h:33m:37s remains)
INFO - root - 2017-12-16 15:41:09.291216: step 15750, loss = 0.47, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 20h:00m:11s remains)
INFO - root - 2017-12-16 15:41:11.531769: step 15760, loss = 0.53, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 19h:33m:55s remains)
INFO - root - 2017-12-16 15:41:13.799761: step 15770, loss = 0.58, batch loss = 0.40 (33.5 examples/sec; 0.239 sec/batch; 21h:00m:50s remains)
INFO - root - 2017-12-16 15:41:16.005256: step 15780, loss = 0.60, batch loss = 0.42 (36.5 examples/sec; 0.219 sec/batch; 19h:15m:29s remains)
INFO - root - 2017-12-16 15:41:18.215970: step 15790, loss = 0.55, batch loss = 0.36 (37.0 examples/sec; 0.216 sec/batch; 19h:01m:48s remains)
INFO - root - 2017-12-16 15:41:20.444855: step 15800, loss = 0.47, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 19h:21m:00s remains)
INFO - root - 2017-12-16 15:41:22.768632: step 15810, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 19h:56m:53s remains)
INFO - root - 2017-12-16 15:41:24.994868: step 15820, loss = 0.55, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 19h:37m:37s remains)
INFO - root - 2017-12-16 15:41:27.225819: step 15830, loss = 0.49, batch loss = 0.30 (33.7 examples/sec; 0.237 sec/batch; 20h:52m:53s remains)
INFO - root - 2017-12-16 15:41:29.452675: step 15840, loss = 0.56, batch loss = 0.37 (34.8 examples/sec; 0.230 sec/batch; 20h:12m:07s remains)
INFO - root - 2017-12-16 15:41:31.655328: step 15850, loss = 0.50, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 19h:00m:12s remains)
INFO - root - 2017-12-16 15:41:33.882872: step 15860, loss = 0.49, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 19h:40m:59s remains)
INFO - root - 2017-12-16 15:41:36.081059: step 15870, loss = 0.59, batch loss = 0.40 (37.1 examples/sec; 0.216 sec/batch; 18h:57m:34s remains)
INFO - root - 2017-12-16 15:41:38.361529: step 15880, loss = 0.53, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 19h:40m:02s remains)
INFO - root - 2017-12-16 15:41:40.580827: step 15890, loss = 0.57, batch loss = 0.38 (35.6 examples/sec; 0.224 sec/batch; 19h:44m:28s remains)
INFO - root - 2017-12-16 15:41:42.763773: step 15900, loss = 0.46, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 19h:47m:31s remains)
INFO - root - 2017-12-16 15:41:45.100097: step 15910, loss = 0.50, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 18h:59m:46s remains)
INFO - root - 2017-12-16 15:41:47.325383: step 15920, loss = 0.46, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 19h:17m:55s remains)
INFO - root - 2017-12-16 15:41:49.552810: step 15930, loss = 0.51, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 19h:25m:58s remains)
INFO - root - 2017-12-16 15:41:51.791146: step 15940, loss = 0.56, batch loss = 0.38 (37.8 examples/sec; 0.211 sec/batch; 18h:35m:16s remains)
INFO - root - 2017-12-16 15:41:54.033146: step 15950, loss = 0.60, batch loss = 0.41 (35.0 examples/sec; 0.229 sec/batch; 20h:06m:20s remains)
INFO - root - 2017-12-16 15:41:56.277982: step 15960, loss = 0.51, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 19h:32m:58s remains)
INFO - root - 2017-12-16 15:41:58.544771: step 15970, loss = 0.51, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 19h:08m:02s remains)
INFO - root - 2017-12-16 15:42:00.786155: step 15980, loss = 0.53, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 18h:49m:17s remains)
INFO - root - 2017-12-16 15:42:02.977651: step 15990, loss = 0.54, batch loss = 0.35 (35.6 examples/sec; 0.224 sec/batch; 19h:44m:04s remains)
INFO - root - 2017-12-16 15:42:05.155659: step 16000, loss = 0.59, batch loss = 0.40 (36.9 examples/sec; 0.217 sec/batch; 19h:04m:39s remains)
INFO - root - 2017-12-16 15:42:07.480316: step 16010, loss = 0.51, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 19h:52m:22s remains)
INFO - root - 2017-12-16 15:42:09.695199: step 16020, loss = 0.48, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 19h:46m:07s remains)
INFO - root - 2017-12-16 15:42:11.942510: step 16030, loss = 0.49, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 19h:19m:46s remains)
INFO - root - 2017-12-16 15:42:14.165489: step 16040, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 19h:21m:20s remains)
INFO - root - 2017-12-16 15:42:16.361757: step 16050, loss = 0.53, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 19h:38m:17s remains)
INFO - root - 2017-12-16 15:42:18.589017: step 16060, loss = 0.52, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 19h:38m:23s remains)
INFO - root - 2017-12-16 15:42:20.801873: step 16070, loss = 0.53, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 19h:32m:54s remains)
INFO - root - 2017-12-16 15:42:23.044508: step 16080, loss = 0.57, batch loss = 0.39 (37.2 examples/sec; 0.215 sec/batch; 18h:53m:54s remains)
INFO - root - 2017-12-16 15:42:25.263318: step 16090, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 19h:03m:30s remains)
INFO - root - 2017-12-16 15:42:27.515512: step 16100, loss = 0.52, batch loss = 0.33 (35.0 examples/sec; 0.228 sec/batch; 20h:03m:57s remains)
INFO - root - 2017-12-16 15:42:29.833718: step 16110, loss = 0.53, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 19h:19m:38s remains)
INFO - root - 2017-12-16 15:42:32.029438: step 16120, loss = 0.55, batch loss = 0.36 (35.4 examples/sec; 0.226 sec/batch; 19h:51m:19s remains)
INFO - root - 2017-12-16 15:42:34.249201: step 16130, loss = 0.55, batch loss = 0.36 (34.1 examples/sec; 0.235 sec/batch; 20h:37m:17s remains)
INFO - root - 2017-12-16 15:42:36.453530: step 16140, loss = 0.46, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 19h:02m:41s remains)
INFO - root - 2017-12-16 15:42:38.644529: step 16150, loss = 0.53, batch loss = 0.34 (34.7 examples/sec; 0.230 sec/batch; 20h:14m:32s remains)
INFO - root - 2017-12-16 15:42:40.874533: step 16160, loss = 0.52, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 19h:05m:07s remains)
INFO - root - 2017-12-16 15:42:43.087939: step 16170, loss = 0.54, batch loss = 0.36 (35.3 examples/sec; 0.227 sec/batch; 19h:55m:44s remains)
INFO - root - 2017-12-16 15:42:45.337347: step 16180, loss = 0.53, batch loss = 0.35 (34.2 examples/sec; 0.234 sec/batch; 20h:34m:56s remains)
INFO - root - 2017-12-16 15:42:47.543067: step 16190, loss = 0.47, batch loss = 0.29 (34.4 examples/sec; 0.232 sec/batch; 20h:25m:23s remains)
INFO - root - 2017-12-16 15:42:49.751584: step 16200, loss = 0.59, batch loss = 0.40 (35.6 examples/sec; 0.224 sec/batch; 19h:43m:28s remains)
INFO - root - 2017-12-16 15:42:52.099538: step 16210, loss = 0.50, batch loss = 0.31 (35.3 examples/sec; 0.226 sec/batch; 19h:53m:49s remains)
INFO - root - 2017-12-16 15:42:54.336193: step 16220, loss = 0.54, batch loss = 0.35 (33.6 examples/sec; 0.238 sec/batch; 20h:54m:13s remains)
INFO - root - 2017-12-16 15:42:56.558333: step 16230, loss = 0.48, batch loss = 0.30 (33.8 examples/sec; 0.237 sec/batch; 20h:48m:50s remains)
INFO - root - 2017-12-16 15:42:58.762524: step 16240, loss = 0.53, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 19h:03m:04s remains)
INFO - root - 2017-12-16 15:43:01.009446: step 16250, loss = 0.56, batch loss = 0.37 (35.3 examples/sec; 0.227 sec/batch; 19h:54m:07s remains)
INFO - root - 2017-12-16 15:43:03.212609: step 16260, loss = 0.50, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 18h:38m:10s remains)
INFO - root - 2017-12-16 15:43:05.472173: step 16270, loss = 0.54, batch loss = 0.35 (35.2 examples/sec; 0.227 sec/batch; 19h:57m:40s remains)
INFO - root - 2017-12-16 15:43:07.691118: step 16280, loss = 0.53, batch loss = 0.35 (34.8 examples/sec; 0.230 sec/batch; 20h:11m:23s remains)
INFO - root - 2017-12-16 15:43:09.926946: step 16290, loss = 0.49, batch loss = 0.30 (35.8 examples/sec; 0.224 sec/batch; 19h:38m:37s remains)
INFO - root - 2017-12-16 15:43:12.165357: step 16300, loss = 0.52, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 20h:02m:47s remains)
INFO - root - 2017-12-16 15:43:14.511922: step 16310, loss = 0.60, batch loss = 0.42 (34.6 examples/sec; 0.231 sec/batch; 20h:18m:53s remains)
INFO - root - 2017-12-16 15:43:16.694869: step 16320, loss = 0.52, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 19h:13m:31s remains)
INFO - root - 2017-12-16 15:43:18.897967: step 16330, loss = 0.50, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 19h:15m:51s remains)
INFO - root - 2017-12-16 15:43:21.129782: step 16340, loss = 0.57, batch loss = 0.38 (35.3 examples/sec; 0.226 sec/batch; 19h:52m:39s remains)
INFO - root - 2017-12-16 15:43:23.355881: step 16350, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 19h:36m:49s remains)
INFO - root - 2017-12-16 15:43:25.554183: step 16360, loss = 0.55, batch loss = 0.37 (37.1 examples/sec; 0.216 sec/batch; 18h:57m:00s remains)
INFO - root - 2017-12-16 15:43:27.796357: step 16370, loss = 0.50, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 19h:05m:31s remains)
INFO - root - 2017-12-16 15:43:30.006671: step 16380, loss = 0.47, batch loss = 0.28 (37.5 examples/sec; 0.214 sec/batch; 18h:45m:11s remains)
INFO - root - 2017-12-16 15:43:32.198907: step 16390, loss = 0.51, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 19h:14m:53s remains)
INFO - root - 2017-12-16 15:43:34.427699: step 16400, loss = 0.50, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 19h:54m:57s remains)
INFO - root - 2017-12-16 15:43:36.761929: step 16410, loss = 0.49, batch loss = 0.31 (37.8 examples/sec; 0.212 sec/batch; 18h:36m:23s remains)
INFO - root - 2017-12-16 15:43:38.961231: step 16420, loss = 0.57, batch loss = 0.38 (36.1 examples/sec; 0.222 sec/batch; 19h:26m:57s remains)
INFO - root - 2017-12-16 15:43:41.188579: step 16430, loss = 0.56, batch loss = 0.37 (35.3 examples/sec; 0.227 sec/batch; 19h:54m:23s remains)
INFO - root - 2017-12-16 15:43:43.449239: step 16440, loss = 0.48, batch loss = 0.29 (34.0 examples/sec; 0.235 sec/batch; 20h:38m:37s remains)
INFO - root - 2017-12-16 15:43:45.700224: step 16450, loss = 0.58, batch loss = 0.39 (36.7 examples/sec; 0.218 sec/batch; 19h:07m:35s remains)
INFO - root - 2017-12-16 15:43:47.915096: step 16460, loss = 0.53, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 19h:26m:58s remains)
INFO - root - 2017-12-16 15:43:50.148552: step 16470, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 19h:16m:16s remains)
INFO - root - 2017-12-16 15:43:52.385148: step 16480, loss = 0.58, batch loss = 0.39 (36.2 examples/sec; 0.221 sec/batch; 19h:24m:43s remains)
INFO - root - 2017-12-16 15:43:54.593382: step 16490, loss = 0.54, batch loss = 0.35 (37.1 examples/sec; 0.216 sec/batch; 18h:56m:39s remains)
INFO - root - 2017-12-16 15:43:56.786034: step 16500, loss = 0.54, batch loss = 0.35 (36.1 examples/sec; 0.221 sec/batch; 19h:25m:59s remains)
INFO - root - 2017-12-16 15:43:59.119528: step 16510, loss = 0.51, batch loss = 0.33 (34.0 examples/sec; 0.236 sec/batch; 20h:40m:25s remains)
INFO - root - 2017-12-16 15:44:01.338944: step 16520, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 19h:57m:31s remains)
INFO - root - 2017-12-16 15:44:03.563309: step 16530, loss = 0.49, batch loss = 0.30 (35.0 examples/sec; 0.229 sec/batch; 20h:05m:06s remains)
INFO - root - 2017-12-16 15:44:05.789943: step 16540, loss = 0.50, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 19h:08m:34s remains)
INFO - root - 2017-12-16 15:44:07.998894: step 16550, loss = 0.53, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 19h:32m:45s remains)
INFO - root - 2017-12-16 15:44:10.218308: step 16560, loss = 0.53, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 19h:20m:30s remains)
INFO - root - 2017-12-16 15:44:12.429712: step 16570, loss = 0.54, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 19h:03m:34s remains)
INFO - root - 2017-12-16 15:44:14.698837: step 16580, loss = 0.57, batch loss = 0.38 (37.5 examples/sec; 0.213 sec/batch; 18h:44m:02s remains)
INFO - root - 2017-12-16 15:44:16.892832: step 16590, loss = 0.54, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 19h:17m:34s remains)
INFO - root - 2017-12-16 15:44:19.113865: step 16600, loss = 0.55, batch loss = 0.36 (36.4 examples/sec; 0.220 sec/batch; 19h:18m:27s remains)
INFO - root - 2017-12-16 15:44:21.439321: step 16610, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 19h:48m:19s remains)
INFO - root - 2017-12-16 15:44:23.705072: step 16620, loss = 0.53, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 19h:18m:08s remains)
INFO - root - 2017-12-16 15:44:25.950224: step 16630, loss = 0.53, batch loss = 0.34 (34.1 examples/sec; 0.234 sec/batch; 20h:34m:13s remains)
INFO - root - 2017-12-16 15:44:28.194078: step 16640, loss = 0.50, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 19h:48m:21s remains)
INFO - root - 2017-12-16 15:44:30.429575: step 16650, loss = 0.58, batch loss = 0.40 (33.7 examples/sec; 0.238 sec/batch; 20h:50m:46s remains)
INFO - root - 2017-12-16 15:44:32.632766: step 16660, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 19h:20m:08s remains)
INFO - root - 2017-12-16 15:44:34.856350: step 16670, loss = 0.57, batch loss = 0.38 (37.6 examples/sec; 0.213 sec/batch; 18h:38m:50s remains)
INFO - root - 2017-12-16 15:44:37.065607: step 16680, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 19h:41m:51s remains)
INFO - root - 2017-12-16 15:44:39.337952: step 16690, loss = 0.44, batch loss = 0.25 (34.9 examples/sec; 0.229 sec/batch; 20h:07m:17s remains)
INFO - root - 2017-12-16 15:44:41.543465: step 16700, loss = 0.56, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 19h:19m:00s remains)
INFO - root - 2017-12-16 15:44:43.886646: step 16710, loss = 0.49, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 19h:07m:22s remains)
INFO - root - 2017-12-16 15:44:46.097994: step 16720, loss = 0.56, batch loss = 0.37 (34.4 examples/sec; 0.233 sec/batch; 20h:24m:40s remains)
INFO - root - 2017-12-16 15:44:48.295036: step 16730, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 19h:11m:39s remains)
INFO - root - 2017-12-16 15:44:50.519939: step 16740, loss = 0.59, batch loss = 0.40 (34.2 examples/sec; 0.234 sec/batch; 20h:29m:50s remains)
INFO - root - 2017-12-16 15:44:52.742407: step 16750, loss = 0.47, batch loss = 0.29 (33.5 examples/sec; 0.239 sec/batch; 20h:56m:36s remains)
INFO - root - 2017-12-16 15:44:54.950377: step 16760, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 19h:45m:31s remains)
INFO - root - 2017-12-16 15:44:57.143327: step 16770, loss = 0.53, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 19h:37m:49s remains)
INFO - root - 2017-12-16 15:44:59.408969: step 16780, loss = 0.55, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 19h:39m:54s remains)
INFO - root - 2017-12-16 15:45:01.606428: step 16790, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 18h:45m:43s remains)
INFO - root - 2017-12-16 15:45:03.828624: step 16800, loss = 0.49, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 19h:35m:47s remains)
INFO - root - 2017-12-16 15:45:06.199765: step 16810, loss = 0.50, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 19h:36m:36s remains)
INFO - root - 2017-12-16 15:45:08.426613: step 16820, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 18h:49m:04s remains)
INFO - root - 2017-12-16 15:45:10.636920: step 16830, loss = 0.58, batch loss = 0.40 (36.2 examples/sec; 0.221 sec/batch; 19h:21m:12s remains)
INFO - root - 2017-12-16 15:45:12.818238: step 16840, loss = 0.62, batch loss = 0.44 (37.5 examples/sec; 0.213 sec/batch; 18h:43m:06s remains)
INFO - root - 2017-12-16 15:45:15.023837: step 16850, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 18h:54m:14s remains)
INFO - root - 2017-12-16 15:45:17.270337: step 16860, loss = 0.57, batch loss = 0.38 (35.8 examples/sec; 0.223 sec/batch; 19h:34m:37s remains)
INFO - root - 2017-12-16 15:45:19.467940: step 16870, loss = 0.59, batch loss = 0.40 (35.6 examples/sec; 0.225 sec/batch; 19h:43m:32s remains)
INFO - root - 2017-12-16 15:45:21.708862: step 16880, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 19h:43m:09s remains)
INFO - root - 2017-12-16 15:45:23.964164: step 16890, loss = 0.57, batch loss = 0.38 (36.0 examples/sec; 0.222 sec/batch; 19h:28m:58s remains)
INFO - root - 2017-12-16 15:45:26.149868: step 16900, loss = 0.47, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 19h:20m:50s remains)
INFO - root - 2017-12-16 15:45:28.529484: step 16910, loss = 0.55, batch loss = 0.37 (36.3 examples/sec; 0.221 sec/batch; 19h:19m:55s remains)
INFO - root - 2017-12-16 15:45:30.753432: step 16920, loss = 0.49, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 19h:11m:50s remains)
INFO - root - 2017-12-16 15:45:32.945062: step 16930, loss = 0.54, batch loss = 0.35 (37.8 examples/sec; 0.212 sec/batch; 18h:33m:58s remains)
INFO - root - 2017-12-16 15:45:35.159115: step 16940, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 19h:02m:15s remains)
INFO - root - 2017-12-16 15:45:37.374961: step 16950, loss = 0.50, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 19h:28m:42s remains)
INFO - root - 2017-12-16 15:45:39.635661: step 16960, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.228 sec/batch; 20h:00m:34s remains)
INFO - root - 2017-12-16 15:45:41.869097: step 16970, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 19h:17m:43s remains)
INFO - root - 2017-12-16 15:45:44.083379: step 16980, loss = 0.48, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 19h:42m:10s remains)
INFO - root - 2017-12-16 15:45:46.294051: step 16990, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 19h:29m:28s remains)
INFO - root - 2017-12-16 15:45:48.487961: step 17000, loss = 0.50, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 18h:48m:27s remains)
INFO - root - 2017-12-16 15:45:50.837746: step 17010, loss = 0.51, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 19h:03m:27s remains)
INFO - root - 2017-12-16 15:45:53.052662: step 17020, loss = 0.55, batch loss = 0.36 (35.5 examples/sec; 0.225 sec/batch; 19h:43m:56s remains)
INFO - root - 2017-12-16 15:45:55.280060: step 17030, loss = 0.51, batch loss = 0.32 (34.3 examples/sec; 0.233 sec/batch; 20h:27m:29s remains)
INFO - root - 2017-12-16 15:45:57.514551: step 17040, loss = 0.55, batch loss = 0.37 (35.8 examples/sec; 0.223 sec/batch; 19h:34m:00s remains)
INFO - root - 2017-12-16 15:45:59.709067: step 17050, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 19h:06m:53s remains)
INFO - root - 2017-12-16 15:46:01.945226: step 17060, loss = 0.48, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 19h:44m:48s remains)
INFO - root - 2017-12-16 15:46:04.205621: step 17070, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 19h:51m:26s remains)
INFO - root - 2017-12-16 15:46:06.415402: step 17080, loss = 0.55, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 19h:13m:14s remains)
INFO - root - 2017-12-16 15:46:08.667362: step 17090, loss = 0.51, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 19h:22m:56s remains)
INFO - root - 2017-12-16 15:46:10.912346: step 17100, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 19h:39m:14s remains)
INFO - root - 2017-12-16 15:46:13.264710: step 17110, loss = 0.49, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 20h:06m:14s remains)
INFO - root - 2017-12-16 15:46:15.448934: step 17120, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 19h:40m:32s remains)
INFO - root - 2017-12-16 15:46:17.656011: step 17130, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 19h:16m:05s remains)
INFO - root - 2017-12-16 15:46:19.861599: step 17140, loss = 0.63, batch loss = 0.44 (37.1 examples/sec; 0.216 sec/batch; 18h:54m:19s remains)
INFO - root - 2017-12-16 15:46:22.073083: step 17150, loss = 0.52, batch loss = 0.33 (34.7 examples/sec; 0.230 sec/batch; 20h:10m:07s remains)
INFO - root - 2017-12-16 15:46:24.294281: step 17160, loss = 0.57, batch loss = 0.39 (37.0 examples/sec; 0.216 sec/batch; 18h:57m:43s remains)
INFO - root - 2017-12-16 15:46:26.569030: step 17170, loss = 0.50, batch loss = 0.31 (33.3 examples/sec; 0.240 sec/batch; 21h:02m:31s remains)
INFO - root - 2017-12-16 15:46:28.822754: step 17180, loss = 0.53, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 19h:28m:43s remains)
INFO - root - 2017-12-16 15:46:31.020153: step 17190, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 19h:03m:39s remains)
INFO - root - 2017-12-16 15:46:33.240859: step 17200, loss = 0.53, batch loss = 0.35 (35.0 examples/sec; 0.228 sec/batch; 20h:00m:24s remains)
INFO - root - 2017-12-16 15:46:35.629436: step 17210, loss = 0.50, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 19h:08m:35s remains)
INFO - root - 2017-12-16 15:46:37.878849: step 17220, loss = 0.69, batch loss = 0.50 (36.1 examples/sec; 0.221 sec/batch; 19h:23m:14s remains)
INFO - root - 2017-12-16 15:46:40.117659: step 17230, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 19h:53m:33s remains)
INFO - root - 2017-12-16 15:46:42.352713: step 17240, loss = 0.49, batch loss = 0.30 (33.6 examples/sec; 0.238 sec/batch; 20h:49m:23s remains)
INFO - root - 2017-12-16 15:46:44.580263: step 17250, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 19h:45m:01s remains)
INFO - root - 2017-12-16 15:46:46.796877: step 17260, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 18h:56m:29s remains)
INFO - root - 2017-12-16 15:46:48.998505: step 17270, loss = 0.49, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 19h:36m:21s remains)
INFO - root - 2017-12-16 15:46:51.245780: step 17280, loss = 0.56, batch loss = 0.38 (36.9 examples/sec; 0.217 sec/batch; 19h:00m:16s remains)
INFO - root - 2017-12-16 15:46:53.498275: step 17290, loss = 0.49, batch loss = 0.31 (33.5 examples/sec; 0.239 sec/batch; 20h:56m:14s remains)
INFO - root - 2017-12-16 15:46:55.723025: step 17300, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 19h:20m:14s remains)
INFO - root - 2017-12-16 15:46:58.027387: step 17310, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 19h:31m:52s remains)
INFO - root - 2017-12-16 15:47:00.263092: step 17320, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 19h:38m:03s remains)
INFO - root - 2017-12-16 15:47:02.482243: step 17330, loss = 0.52, batch loss = 0.34 (37.3 examples/sec; 0.214 sec/batch; 18h:45m:20s remains)
INFO - root - 2017-12-16 15:47:04.717341: step 17340, loss = 0.63, batch loss = 0.44 (36.1 examples/sec; 0.222 sec/batch; 19h:24m:22s remains)
INFO - root - 2017-12-16 15:47:06.955404: step 17350, loss = 0.57, batch loss = 0.39 (34.3 examples/sec; 0.233 sec/batch; 20h:25m:54s remains)
INFO - root - 2017-12-16 15:47:09.208349: step 17360, loss = 0.48, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 19h:35m:33s remains)
INFO - root - 2017-12-16 15:47:11.420938: step 17370, loss = 0.55, batch loss = 0.36 (36.1 examples/sec; 0.222 sec/batch; 19h:25m:08s remains)
INFO - root - 2017-12-16 15:47:13.660797: step 17380, loss = 0.46, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 20h:02m:26s remains)
INFO - root - 2017-12-16 15:47:15.886297: step 17390, loss = 0.58, batch loss = 0.40 (36.5 examples/sec; 0.219 sec/batch; 19h:11m:41s remains)
INFO - root - 2017-12-16 15:47:18.140639: step 17400, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 19h:08m:42s remains)
INFO - root - 2017-12-16 15:47:20.479957: step 17410, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 19h:15m:18s remains)
INFO - root - 2017-12-16 15:47:22.723396: step 17420, loss = 0.57, batch loss = 0.39 (33.4 examples/sec; 0.239 sec/batch; 20h:56m:03s remains)
INFO - root - 2017-12-16 15:47:24.950504: step 17430, loss = 0.48, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 19h:50m:00s remains)
INFO - root - 2017-12-16 15:47:27.174635: step 17440, loss = 0.52, batch loss = 0.34 (34.0 examples/sec; 0.235 sec/batch; 20h:34m:41s remains)
INFO - root - 2017-12-16 15:47:29.374599: step 17450, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.218 sec/batch; 19h:07m:16s remains)
INFO - root - 2017-12-16 15:47:31.608922: step 17460, loss = 0.57, batch loss = 0.39 (35.9 examples/sec; 0.223 sec/batch; 19h:29m:19s remains)
INFO - root - 2017-12-16 15:47:33.853419: step 17470, loss = 0.49, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 18h:53m:55s remains)
INFO - root - 2017-12-16 15:47:36.043915: step 17480, loss = 0.56, batch loss = 0.38 (35.9 examples/sec; 0.223 sec/batch; 19h:28m:59s remains)
INFO - root - 2017-12-16 15:47:38.259633: step 17490, loss = 0.51, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 19h:27m:02s remains)
INFO - root - 2017-12-16 15:47:40.466032: step 17500, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 19h:07m:35s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-17500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-17500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 15:47:43.581517: step 17510, loss = 0.49, batch loss = 0.30 (34.7 examples/sec; 0.230 sec/batch; 20h:09m:19s remains)
INFO - root - 2017-12-16 15:47:45.752145: step 17520, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 19h:04m:01s remains)
INFO - root - 2017-12-16 15:47:47.996350: step 17530, loss = 0.54, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 19h:34m:49s remains)
INFO - root - 2017-12-16 15:47:50.185479: step 17540, loss = 0.49, batch loss = 0.30 (38.1 examples/sec; 0.210 sec/batch; 18h:21m:45s remains)
INFO - root - 2017-12-16 15:47:52.429014: step 17550, loss = 0.55, batch loss = 0.36 (34.4 examples/sec; 0.233 sec/batch; 20h:20m:53s remains)
INFO - root - 2017-12-16 15:47:54.650097: step 17560, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 19h:14m:39s remains)
INFO - root - 2017-12-16 15:47:56.882631: step 17570, loss = 0.57, batch loss = 0.39 (35.9 examples/sec; 0.223 sec/batch; 19h:28m:13s remains)
INFO - root - 2017-12-16 15:47:59.086554: step 17580, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 19h:28m:44s remains)
INFO - root - 2017-12-16 15:48:01.294729: step 17590, loss = 0.55, batch loss = 0.36 (35.3 examples/sec; 0.227 sec/batch; 19h:50m:41s remains)
INFO - root - 2017-12-16 15:48:03.514764: step 17600, loss = 0.65, batch loss = 0.47 (36.8 examples/sec; 0.218 sec/batch; 19h:02m:00s remains)
INFO - root - 2017-12-16 15:48:05.879074: step 17610, loss = 0.56, batch loss = 0.38 (37.4 examples/sec; 0.214 sec/batch; 18h:43m:19s remains)
INFO - root - 2017-12-16 15:48:08.072887: step 17620, loss = 0.46, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 19h:20m:36s remains)
INFO - root - 2017-12-16 15:48:10.269341: step 17630, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 18h:46m:36s remains)
INFO - root - 2017-12-16 15:48:12.491641: step 17640, loss = 0.51, batch loss = 0.32 (35.3 examples/sec; 0.226 sec/batch; 19h:48m:09s remains)
INFO - root - 2017-12-16 15:48:14.692238: step 17650, loss = 0.53, batch loss = 0.35 (38.3 examples/sec; 0.209 sec/batch; 18h:15m:57s remains)
INFO - root - 2017-12-16 15:48:16.906284: step 17660, loss = 0.49, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 19h:02m:44s remains)
INFO - root - 2017-12-16 15:48:19.116238: step 17670, loss = 0.48, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 18h:32m:09s remains)
INFO - root - 2017-12-16 15:48:21.345523: step 17680, loss = 0.48, batch loss = 0.29 (38.0 examples/sec; 0.210 sec/batch; 18h:23m:49s remains)
INFO - root - 2017-12-16 15:48:23.588106: step 17690, loss = 0.57, batch loss = 0.38 (35.5 examples/sec; 0.225 sec/batch; 19h:42m:36s remains)
INFO - root - 2017-12-16 15:48:25.759103: step 17700, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 18h:56m:47s remains)
INFO - root - 2017-12-16 15:48:28.135644: step 17710, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 19h:04m:41s remains)
INFO - root - 2017-12-16 15:48:30.380648: step 17720, loss = 0.60, batch loss = 0.42 (35.6 examples/sec; 0.225 sec/batch; 19h:39m:05s remains)
INFO - root - 2017-12-16 15:48:32.596578: step 17730, loss = 0.61, batch loss = 0.43 (36.7 examples/sec; 0.218 sec/batch; 19h:02m:31s remains)
INFO - root - 2017-12-16 15:48:34.773235: step 17740, loss = 0.55, batch loss = 0.36 (36.8 examples/sec; 0.217 sec/batch; 19h:00m:57s remains)
INFO - root - 2017-12-16 15:48:36.981812: step 17750, loss = 0.51, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 19h:03m:53s remains)
INFO - root - 2017-12-16 15:48:39.180863: step 17760, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 19h:00m:44s remains)
INFO - root - 2017-12-16 15:48:41.368441: step 17770, loss = 0.52, batch loss = 0.34 (37.7 examples/sec; 0.212 sec/batch; 18h:32m:04s remains)
INFO - root - 2017-12-16 15:48:43.575375: step 17780, loss = 0.45, batch loss = 0.27 (37.6 examples/sec; 0.213 sec/batch; 18h:37m:05s remains)
INFO - root - 2017-12-16 15:48:45.841765: step 17790, loss = 0.54, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 19h:28m:21s remains)
INFO - root - 2017-12-16 15:48:48.038160: step 17800, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 18h:50m:37s remains)
INFO - root - 2017-12-16 15:48:50.406967: step 17810, loss = 0.45, batch loss = 0.26 (34.5 examples/sec; 0.232 sec/batch; 20h:17m:51s remains)
INFO - root - 2017-12-16 15:48:52.649104: step 17820, loss = 0.47, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 19h:18m:07s remains)
INFO - root - 2017-12-16 15:48:54.861273: step 17830, loss = 0.54, batch loss = 0.35 (38.1 examples/sec; 0.210 sec/batch; 18h:22m:00s remains)
INFO - root - 2017-12-16 15:48:57.038370: step 17840, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 19h:38m:17s remains)
INFO - root - 2017-12-16 15:48:59.243031: step 17850, loss = 0.52, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 19h:04m:15s remains)
INFO - root - 2017-12-16 15:49:01.444164: step 17860, loss = 0.48, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 18h:54m:58s remains)
INFO - root - 2017-12-16 15:49:03.649011: step 17870, loss = 0.58, batch loss = 0.39 (36.0 examples/sec; 0.222 sec/batch; 19h:25m:57s remains)
INFO - root - 2017-12-16 15:49:05.872103: step 17880, loss = 0.56, batch loss = 0.38 (37.0 examples/sec; 0.216 sec/batch; 18h:53m:42s remains)
INFO - root - 2017-12-16 15:49:08.060955: step 17890, loss = 0.60, batch loss = 0.41 (36.8 examples/sec; 0.217 sec/batch; 18h:59m:26s remains)
INFO - root - 2017-12-16 15:49:10.283637: step 17900, loss = 0.50, batch loss = 0.32 (37.5 examples/sec; 0.214 sec/batch; 18h:39m:52s remains)
INFO - root - 2017-12-16 15:49:12.604054: step 17910, loss = 0.53, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 19h:01m:23s remains)
INFO - root - 2017-12-16 15:49:14.796644: step 17920, loss = 0.55, batch loss = 0.37 (34.4 examples/sec; 0.233 sec/batch; 20h:20m:52s remains)
INFO - root - 2017-12-16 15:49:17.024584: step 17930, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 19h:15m:25s remains)
INFO - root - 2017-12-16 15:49:19.233691: step 17940, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 19h:15m:59s remains)
INFO - root - 2017-12-16 15:49:21.432806: step 17950, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 19h:17m:12s remains)
INFO - root - 2017-12-16 15:49:23.654268: step 17960, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 19h:02m:37s remains)
INFO - root - 2017-12-16 15:49:25.843939: step 17970, loss = 0.46, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 19h:17m:49s remains)
INFO - root - 2017-12-16 15:49:28.019947: step 17980, loss = 0.58, batch loss = 0.39 (36.0 examples/sec; 0.222 sec/batch; 19h:24m:31s remains)
INFO - root - 2017-12-16 15:49:30.190405: step 17990, loss = 0.56, batch loss = 0.37 (35.4 examples/sec; 0.226 sec/batch; 19h:44m:21s remains)
INFO - root - 2017-12-16 15:49:32.396096: step 18000, loss = 0.54, batch loss = 0.35 (36.8 examples/sec; 0.218 sec/batch; 19h:00m:50s remains)
INFO - root - 2017-12-16 15:49:34.712670: step 18010, loss = 0.52, batch loss = 0.33 (37.3 examples/sec; 0.214 sec/batch; 18h:43m:04s remains)
INFO - root - 2017-12-16 15:49:36.941652: step 18020, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 19h:29m:44s remains)
INFO - root - 2017-12-16 15:49:39.176731: step 18030, loss = 0.49, batch loss = 0.31 (37.8 examples/sec; 0.212 sec/batch; 18h:30m:42s remains)
INFO - root - 2017-12-16 15:49:41.416436: step 18040, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 20h:14m:47s remains)
INFO - root - 2017-12-16 15:49:43.615498: step 18050, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 19h:22m:33s remains)
INFO - root - 2017-12-16 15:49:45.808020: step 18060, loss = 0.48, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 18h:57m:08s remains)
INFO - root - 2017-12-16 15:49:48.027692: step 18070, loss = 0.51, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 19h:33m:14s remains)
INFO - root - 2017-12-16 15:49:50.233873: step 18080, loss = 0.54, batch loss = 0.36 (34.6 examples/sec; 0.231 sec/batch; 20h:10m:17s remains)
INFO - root - 2017-12-16 15:49:52.449830: step 18090, loss = 0.44, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 18h:40m:40s remains)
INFO - root - 2017-12-16 15:49:54.670072: step 18100, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 19h:08m:04s remains)
INFO - root - 2017-12-16 15:49:56.980473: step 18110, loss = 0.50, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 19h:06m:39s remains)
INFO - root - 2017-12-16 15:49:59.176360: step 18120, loss = 0.56, batch loss = 0.38 (36.6 examples/sec; 0.219 sec/batch; 19h:05m:43s remains)
INFO - root - 2017-12-16 15:50:01.416159: step 18130, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 19h:54m:15s remains)
INFO - root - 2017-12-16 15:50:03.634141: step 18140, loss = 0.52, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 19h:02m:16s remains)
INFO - root - 2017-12-16 15:50:05.812067: step 18150, loss = 0.57, batch loss = 0.39 (37.5 examples/sec; 0.213 sec/batch; 18h:38m:11s remains)
INFO - root - 2017-12-16 15:50:08.038230: step 18160, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.215 sec/batch; 18h:48m:52s remains)
INFO - root - 2017-12-16 15:50:10.220038: step 18170, loss = 0.59, batch loss = 0.40 (36.3 examples/sec; 0.220 sec/batch; 19h:14m:56s remains)
INFO - root - 2017-12-16 15:50:12.413864: step 18180, loss = 0.54, batch loss = 0.35 (37.9 examples/sec; 0.211 sec/batch; 18h:26m:01s remains)
INFO - root - 2017-12-16 15:50:14.613867: step 18190, loss = 0.58, batch loss = 0.40 (35.5 examples/sec; 0.225 sec/batch; 19h:39m:31s remains)
INFO - root - 2017-12-16 15:50:16.846884: step 18200, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 18h:41m:10s remains)
INFO - root - 2017-12-16 15:50:19.234316: step 18210, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.221 sec/batch; 19h:20m:08s remains)
INFO - root - 2017-12-16 15:50:21.484349: step 18220, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 19h:26m:07s remains)
INFO - root - 2017-12-16 15:50:23.710702: step 18230, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 19h:08m:38s remains)
INFO - root - 2017-12-16 15:50:25.905414: step 18240, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 19h:29m:58s remains)
INFO - root - 2017-12-16 15:50:28.145964: step 18250, loss = 0.47, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 19h:48m:32s remains)
INFO - root - 2017-12-16 15:50:30.364106: step 18260, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 19h:32m:48s remains)
INFO - root - 2017-12-16 15:50:32.599823: step 18270, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.233 sec/batch; 20h:18m:56s remains)
INFO - root - 2017-12-16 15:50:34.797005: step 18280, loss = 0.48, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 18h:37m:11s remains)
INFO - root - 2017-12-16 15:50:37.016718: step 18290, loss = 0.56, batch loss = 0.37 (35.9 examples/sec; 0.223 sec/batch; 19h:27m:52s remains)
INFO - root - 2017-12-16 15:50:39.293909: step 18300, loss = 0.53, batch loss = 0.34 (34.3 examples/sec; 0.233 sec/batch; 20h:19m:58s remains)
INFO - root - 2017-12-16 15:50:41.615029: step 18310, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 18h:44m:20s remains)
INFO - root - 2017-12-16 15:50:43.794014: step 18320, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 19h:05m:41s remains)
INFO - root - 2017-12-16 15:50:46.008202: step 18330, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 19h:22m:40s remains)
INFO - root - 2017-12-16 15:50:48.182925: step 18340, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 19h:07m:01s remains)
INFO - root - 2017-12-16 15:50:50.409295: step 18350, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 19h:51m:08s remains)
INFO - root - 2017-12-16 15:50:52.631104: step 18360, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 19h:00m:28s remains)
INFO - root - 2017-12-16 15:50:54.853340: step 18370, loss = 0.50, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 18h:40m:48s remains)
INFO - root - 2017-12-16 15:50:57.031299: step 18380, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 19h:16m:14s remains)
INFO - root - 2017-12-16 15:50:59.252566: step 18390, loss = 0.51, batch loss = 0.33 (31.1 examples/sec; 0.257 sec/batch; 22h:25m:22s remains)
INFO - root - 2017-12-16 15:51:01.494311: step 18400, loss = 0.54, batch loss = 0.35 (35.8 examples/sec; 0.223 sec/batch; 19h:29m:51s remains)
INFO - root - 2017-12-16 15:51:03.846014: step 18410, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 19h:01m:00s remains)
INFO - root - 2017-12-16 15:51:06.038966: step 18420, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 19h:17m:48s remains)
INFO - root - 2017-12-16 15:51:08.247795: step 18430, loss = 0.48, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 18h:59m:56s remains)
INFO - root - 2017-12-16 15:51:10.506909: step 18440, loss = 0.52, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 19h:48m:47s remains)
INFO - root - 2017-12-16 15:51:12.706057: step 18450, loss = 0.52, batch loss = 0.34 (37.7 examples/sec; 0.212 sec/batch; 18h:29m:57s remains)
INFO - root - 2017-12-16 15:51:14.911456: step 18460, loss = 0.50, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 19h:13m:53s remains)
INFO - root - 2017-12-16 15:51:17.156936: step 18470, loss = 0.56, batch loss = 0.38 (36.2 examples/sec; 0.221 sec/batch; 19h:16m:09s remains)
INFO - root - 2017-12-16 15:51:19.344441: step 18480, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 18h:41m:00s remains)
INFO - root - 2017-12-16 15:51:21.550226: step 18490, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 19h:29m:41s remains)
INFO - root - 2017-12-16 15:51:23.777418: step 18500, loss = 0.48, batch loss = 0.29 (34.7 examples/sec; 0.231 sec/batch; 20h:07m:14s remains)
INFO - root - 2017-12-16 15:51:26.133146: step 18510, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 19h:05m:52s remains)
INFO - root - 2017-12-16 15:51:28.347460: step 18520, loss = 0.56, batch loss = 0.37 (35.7 examples/sec; 0.224 sec/batch; 19h:33m:03s remains)
INFO - root - 2017-12-16 15:51:30.551081: step 18530, loss = 0.54, batch loss = 0.36 (37.1 examples/sec; 0.216 sec/batch; 18h:48m:45s remains)
INFO - root - 2017-12-16 15:51:32.741627: step 18540, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 19h:00m:02s remains)
INFO - root - 2017-12-16 15:51:34.970501: step 18550, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 19h:25m:56s remains)
INFO - root - 2017-12-16 15:51:37.151618: step 18560, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 19h:04m:53s remains)
INFO - root - 2017-12-16 15:51:39.377930: step 18570, loss = 0.59, batch loss = 0.41 (36.6 examples/sec; 0.218 sec/batch; 19h:02m:27s remains)
INFO - root - 2017-12-16 15:51:41.598618: step 18580, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 18h:59m:34s remains)
INFO - root - 2017-12-16 15:51:43.778604: step 18590, loss = 0.55, batch loss = 0.37 (36.1 examples/sec; 0.222 sec/batch; 19h:19m:15s remains)
INFO - root - 2017-12-16 15:51:45.952285: step 18600, loss = 0.56, batch loss = 0.38 (37.1 examples/sec; 0.216 sec/batch; 18h:49m:06s remains)
INFO - root - 2017-12-16 15:51:48.332635: step 18610, loss = 0.52, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 20h:01m:17s remains)
INFO - root - 2017-12-16 15:51:50.528350: step 18620, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 19h:05m:32s remains)
INFO - root - 2017-12-16 15:51:52.740892: step 18630, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 19h:10m:31s remains)
INFO - root - 2017-12-16 15:51:54.936356: step 18640, loss = 0.53, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 18h:53m:53s remains)
INFO - root - 2017-12-16 15:51:57.186729: step 18650, loss = 0.49, batch loss = 0.31 (34.2 examples/sec; 0.234 sec/batch; 20h:24m:01s remains)
INFO - root - 2017-12-16 15:51:59.429794: step 18660, loss = 0.52, batch loss = 0.34 (34.8 examples/sec; 0.230 sec/batch; 20h:01m:54s remains)
INFO - root - 2017-12-16 15:52:01.662583: step 18670, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 19h:00m:05s remains)
INFO - root - 2017-12-16 15:52:03.878424: step 18680, loss = 0.42, batch loss = 0.24 (35.9 examples/sec; 0.223 sec/batch; 19h:25m:14s remains)
INFO - root - 2017-12-16 15:52:06.095918: step 18690, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 19h:05m:07s remains)
INFO - root - 2017-12-16 15:52:08.306587: step 18700, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 18h:59m:40s remains)
INFO - root - 2017-12-16 15:52:10.670334: step 18710, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 18h:49m:02s remains)
INFO - root - 2017-12-16 15:52:12.918198: step 18720, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.212 sec/batch; 18h:31m:15s remains)
INFO - root - 2017-12-16 15:52:15.133341: step 18730, loss = 0.52, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 19h:16m:22s remains)
INFO - root - 2017-12-16 15:52:17.347489: step 18740, loss = 0.49, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 19h:10m:18s remains)
INFO - root - 2017-12-16 15:52:19.583199: step 18750, loss = 0.50, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 19h:47m:38s remains)
INFO - root - 2017-12-16 15:52:21.803910: step 18760, loss = 0.53, batch loss = 0.35 (35.8 examples/sec; 0.223 sec/batch; 19h:27m:57s remains)
INFO - root - 2017-12-16 15:52:24.005361: step 18770, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 19h:14m:19s remains)
INFO - root - 2017-12-16 15:52:26.223115: step 18780, loss = 0.52, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 19h:36m:52s remains)
INFO - root - 2017-12-16 15:52:28.410599: step 18790, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 19h:03m:42s remains)
INFO - root - 2017-12-16 15:52:30.602455: step 18800, loss = 0.49, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 18h:47m:21s remains)
INFO - root - 2017-12-16 15:52:32.962161: step 18810, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 19h:19m:22s remains)
INFO - root - 2017-12-16 15:52:35.142905: step 18820, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 18h:52m:45s remains)
INFO - root - 2017-12-16 15:52:37.357039: step 18830, loss = 0.57, batch loss = 0.38 (36.4 examples/sec; 0.220 sec/batch; 19h:09m:24s remains)
INFO - root - 2017-12-16 15:52:39.585707: step 18840, loss = 0.58, batch loss = 0.40 (35.6 examples/sec; 0.224 sec/batch; 19h:33m:16s remains)
INFO - root - 2017-12-16 15:52:41.795347: step 18850, loss = 0.56, batch loss = 0.37 (35.5 examples/sec; 0.225 sec/batch; 19h:38m:25s remains)
INFO - root - 2017-12-16 15:52:43.999133: step 18860, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 19h:03m:23s remains)
INFO - root - 2017-12-16 15:52:46.184304: step 18870, loss = 0.45, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 19h:35m:14s remains)
INFO - root - 2017-12-16 15:52:48.445248: step 18880, loss = 0.50, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 19h:57m:13s remains)
INFO - root - 2017-12-16 15:52:50.665527: step 18890, loss = 0.42, batch loss = 0.24 (35.9 examples/sec; 0.223 sec/batch; 19h:25m:14s remains)
INFO - root - 2017-12-16 15:52:52.893687: step 18900, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 18h:46m:40s remains)
INFO - root - 2017-12-16 15:52:55.258310: step 18910, loss = 0.49, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 19h:16m:48s remains)
INFO - root - 2017-12-16 15:52:57.488623: step 18920, loss = 0.55, batch loss = 0.37 (37.2 examples/sec; 0.215 sec/batch; 18h:44m:31s remains)
INFO - root - 2017-12-16 15:52:59.716115: step 18930, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 18h:59m:24s remains)
INFO - root - 2017-12-16 15:53:01.924497: step 18940, loss = 0.51, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 18h:50m:32s remains)
INFO - root - 2017-12-16 15:53:04.136749: step 18950, loss = 0.47, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 19h:17m:57s remains)
INFO - root - 2017-12-16 15:53:06.389090: step 18960, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 19h:24m:38s remains)
INFO - root - 2017-12-16 15:53:08.598342: step 18970, loss = 0.48, batch loss = 0.30 (37.9 examples/sec; 0.211 sec/batch; 18h:21m:45s remains)
INFO - root - 2017-12-16 15:53:10.834400: step 18980, loss = 0.41, batch loss = 0.22 (35.7 examples/sec; 0.224 sec/batch; 19h:31m:11s remains)
INFO - root - 2017-12-16 15:53:13.058082: step 18990, loss = 0.55, batch loss = 0.37 (37.2 examples/sec; 0.215 sec/batch; 18h:43m:14s remains)
INFO - root - 2017-12-16 15:53:15.288812: step 19000, loss = 0.58, batch loss = 0.39 (35.0 examples/sec; 0.228 sec/batch; 19h:53m:14s remains)
INFO - root - 2017-12-16 15:53:17.615346: step 19010, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 19h:41m:53s remains)
INFO - root - 2017-12-16 15:53:19.819788: step 19020, loss = 0.48, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 19h:17m:29s remains)
INFO - root - 2017-12-16 15:53:22.025781: step 19030, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 18h:47m:24s remains)
INFO - root - 2017-12-16 15:53:24.244667: step 19040, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 19h:34m:24s remains)
INFO - root - 2017-12-16 15:53:26.471331: step 19050, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 19h:23m:47s remains)
INFO - root - 2017-12-16 15:53:28.683647: step 19060, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.228 sec/batch; 19h:53m:35s remains)
INFO - root - 2017-12-16 15:53:30.899268: step 19070, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 19h:18m:16s remains)
INFO - root - 2017-12-16 15:53:33.127289: step 19080, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 19h:35m:15s remains)
INFO - root - 2017-12-16 15:53:35.380453: step 19090, loss = 0.47, batch loss = 0.28 (33.1 examples/sec; 0.242 sec/batch; 21h:01m:51s remains)
INFO - root - 2017-12-16 15:53:37.610532: step 19100, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 19h:20m:59s remains)
INFO - root - 2017-12-16 15:53:39.957295: step 19110, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 20h:11m:00s remains)
INFO - root - 2017-12-16 15:53:42.148377: step 19120, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 18h:57m:38s remains)
INFO - root - 2017-12-16 15:53:44.352045: step 19130, loss = 0.67, batch loss = 0.49 (36.4 examples/sec; 0.220 sec/batch; 19h:08m:18s remains)
INFO - root - 2017-12-16 15:53:46.581311: step 19140, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.231 sec/batch; 20h:05m:46s remains)
INFO - root - 2017-12-16 15:53:48.794999: step 19150, loss = 0.51, batch loss = 0.32 (34.6 examples/sec; 0.231 sec/batch; 20h:08m:46s remains)
INFO - root - 2017-12-16 15:53:51.042467: step 19160, loss = 0.51, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 19h:57m:58s remains)
INFO - root - 2017-12-16 15:53:53.257397: step 19170, loss = 0.55, batch loss = 0.37 (36.7 examples/sec; 0.218 sec/batch; 18h:58m:32s remains)
INFO - root - 2017-12-16 15:53:55.481140: step 19180, loss = 0.46, batch loss = 0.27 (33.9 examples/sec; 0.236 sec/batch; 20h:34m:02s remains)
INFO - root - 2017-12-16 15:53:57.666629: step 19190, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 18h:33m:51s remains)
INFO - root - 2017-12-16 15:53:59.883666: step 19200, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 18h:46m:52s remains)
INFO - root - 2017-12-16 15:54:02.213462: step 19210, loss = 0.55, batch loss = 0.37 (36.1 examples/sec; 0.222 sec/batch; 19h:18m:20s remains)
INFO - root - 2017-12-16 15:54:04.404864: step 19220, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.221 sec/batch; 19h:16m:16s remains)
INFO - root - 2017-12-16 15:54:06.603927: step 19230, loss = 0.48, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 18h:58m:06s remains)
INFO - root - 2017-12-16 15:54:08.841148: step 19240, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 19h:38m:37s remains)
INFO - root - 2017-12-16 15:54:11.097577: step 19250, loss = 0.48, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 19h:36m:16s remains)
INFO - root - 2017-12-16 15:54:13.303002: step 19260, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 19h:28m:58s remains)
INFO - root - 2017-12-16 15:54:15.528416: step 19270, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 18h:53m:04s remains)
INFO - root - 2017-12-16 15:54:17.758677: step 19280, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 18h:55m:06s remains)
INFO - root - 2017-12-16 15:54:19.960668: step 19290, loss = 0.51, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 19h:10m:23s remains)
INFO - root - 2017-12-16 15:54:22.183741: step 19300, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 19h:44m:27s remains)
INFO - root - 2017-12-16 15:54:24.561763: step 19310, loss = 0.59, batch loss = 0.41 (35.5 examples/sec; 0.225 sec/batch; 19h:34m:56s remains)
INFO - root - 2017-12-16 15:54:26.743562: step 19320, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 18h:54m:35s remains)
INFO - root - 2017-12-16 15:54:28.977562: step 19330, loss = 0.51, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 18h:52m:04s remains)
INFO - root - 2017-12-16 15:54:31.251728: step 19340, loss = 0.55, batch loss = 0.37 (34.3 examples/sec; 0.234 sec/batch; 20h:18m:56s remains)
INFO - root - 2017-12-16 15:54:33.477923: step 19350, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 18h:40m:14s remains)
INFO - root - 2017-12-16 15:54:35.665282: step 19360, loss = 0.43, batch loss = 0.24 (37.0 examples/sec; 0.216 sec/batch; 18h:47m:43s remains)
INFO - root - 2017-12-16 15:54:37.850600: step 19370, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 19h:07m:59s remains)
INFO - root - 2017-12-16 15:54:40.075425: step 19380, loss = 0.48, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 19h:33m:09s remains)
INFO - root - 2017-12-16 15:54:42.321654: step 19390, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 19h:17m:20s remains)
INFO - root - 2017-12-16 15:54:44.594428: step 19400, loss = 0.49, batch loss = 0.30 (34.2 examples/sec; 0.234 sec/batch; 20h:21m:20s remains)
INFO - root - 2017-12-16 15:54:46.998518: step 19410, loss = 0.49, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 18h:54m:10s remains)
INFO - root - 2017-12-16 15:54:49.213555: step 19420, loss = 0.56, batch loss = 0.38 (34.6 examples/sec; 0.231 sec/batch; 20h:05m:19s remains)
INFO - root - 2017-12-16 15:54:51.490770: step 19430, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 19h:43m:02s remains)
INFO - root - 2017-12-16 15:54:53.752969: step 19440, loss = 0.52, batch loss = 0.33 (34.6 examples/sec; 0.231 sec/batch; 20h:07m:18s remains)
INFO - root - 2017-12-16 15:54:55.955985: step 19450, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 19h:20m:26s remains)
INFO - root - 2017-12-16 15:54:58.198740: step 19460, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 19h:15m:16s remains)
INFO - root - 2017-12-16 15:55:00.451524: step 19470, loss = 0.55, batch loss = 0.37 (34.9 examples/sec; 0.229 sec/batch; 19h:54m:33s remains)
INFO - root - 2017-12-16 15:55:02.663587: step 19480, loss = 0.56, batch loss = 0.38 (38.2 examples/sec; 0.210 sec/batch; 18h:13m:33s remains)
INFO - root - 2017-12-16 15:55:04.845722: step 19490, loss = 0.44, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 19h:02m:16s remains)
INFO - root - 2017-12-16 15:55:07.097435: step 19500, loss = 0.56, batch loss = 0.38 (35.0 examples/sec; 0.228 sec/batch; 19h:50m:59s remains)
INFO - root - 2017-12-16 15:55:09.497669: step 19510, loss = 0.47, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 19h:22m:34s remains)
INFO - root - 2017-12-16 15:55:11.675627: step 19520, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 19h:39m:59s remains)
INFO - root - 2017-12-16 15:55:13.896836: step 19530, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 19h:04m:14s remains)
INFO - root - 2017-12-16 15:55:16.118689: step 19540, loss = 0.49, batch loss = 0.31 (37.8 examples/sec; 0.212 sec/batch; 18h:24m:00s remains)
INFO - root - 2017-12-16 15:55:18.300171: step 19550, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 18h:38m:37s remains)
INFO - root - 2017-12-16 15:55:20.528171: step 19560, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.226 sec/batch; 19h:36m:33s remains)
INFO - root - 2017-12-16 15:55:22.800173: step 19570, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 20h:00m:33s remains)
INFO - root - 2017-12-16 15:55:24.998270: step 19580, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 19h:03m:37s remains)
INFO - root - 2017-12-16 15:55:27.180005: step 19590, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 18h:41m:48s remains)
INFO - root - 2017-12-16 15:55:29.406519: step 19600, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 19h:11m:47s remains)
INFO - root - 2017-12-16 15:55:31.778850: step 19610, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 18h:26m:37s remains)
INFO - root - 2017-12-16 15:55:33.976454: step 19620, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 19h:05m:23s remains)
INFO - root - 2017-12-16 15:55:36.212246: step 19630, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 19h:08m:39s remains)
INFO - root - 2017-12-16 15:55:38.414399: step 19640, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 18h:46m:21s remains)
INFO - root - 2017-12-16 15:55:40.621407: step 19650, loss = 0.45, batch loss = 0.27 (38.2 examples/sec; 0.209 sec/batch; 18h:11m:44s remains)
INFO - root - 2017-12-16 15:55:42.841464: step 19660, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.226 sec/batch; 19h:40m:30s remains)
INFO - root - 2017-12-16 15:55:45.056624: step 19670, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 18h:46m:07s remains)
INFO - root - 2017-12-16 15:55:47.282198: step 19680, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 19h:22m:08s remains)
INFO - root - 2017-12-16 15:55:49.514956: step 19690, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 19h:37m:31s remains)
INFO - root - 2017-12-16 15:55:51.748851: step 19700, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 19h:20m:19s remains)
INFO - root - 2017-12-16 15:55:54.117224: step 19710, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 19h:17m:45s remains)
INFO - root - 2017-12-16 15:55:56.349890: step 19720, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 18h:57m:45s remains)
INFO - root - 2017-12-16 15:55:58.595158: step 19730, loss = 0.42, batch loss = 0.24 (35.1 examples/sec; 0.228 sec/batch; 19h:48m:01s remains)
INFO - root - 2017-12-16 15:56:00.773155: step 19740, loss = 0.47, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 18h:50m:56s remains)
INFO - root - 2017-12-16 15:56:03.018353: step 19750, loss = 0.53, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 19h:16m:35s remains)
INFO - root - 2017-12-16 15:56:05.217531: step 19760, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 19h:22m:00s remains)
INFO - root - 2017-12-16 15:56:07.469723: step 19770, loss = 0.56, batch loss = 0.38 (34.4 examples/sec; 0.232 sec/batch; 20h:11m:26s remains)
INFO - root - 2017-12-16 15:56:09.769513: step 19780, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 19h:11m:59s remains)
INFO - root - 2017-12-16 15:56:11.983224: step 19790, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 19h:00m:37s remains)
INFO - root - 2017-12-16 15:56:14.191490: step 19800, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 19h:13m:43s remains)
INFO - root - 2017-12-16 15:56:16.509358: step 19810, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 19h:22m:51s remains)
INFO - root - 2017-12-16 15:56:18.696443: step 19820, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 19h:15m:42s remains)
INFO - root - 2017-12-16 15:56:20.901247: step 19830, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 18h:44m:40s remains)
INFO - root - 2017-12-16 15:56:23.103631: step 19840, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 19h:19m:43s remains)
INFO - root - 2017-12-16 15:56:25.308667: step 19850, loss = 0.53, batch loss = 0.35 (35.4 examples/sec; 0.226 sec/batch; 19h:36m:41s remains)
INFO - root - 2017-12-16 15:56:27.496301: step 19860, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 18h:53m:56s remains)
INFO - root - 2017-12-16 15:56:29.734574: step 19870, loss = 0.47, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 20h:17m:06s remains)
INFO - root - 2017-12-16 15:56:31.952387: step 19880, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 18h:51m:48s remains)
INFO - root - 2017-12-16 15:56:34.172895: step 19890, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 19h:21m:44s remains)
INFO - root - 2017-12-16 15:56:36.412355: step 19900, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 18h:42m:16s remains)
INFO - root - 2017-12-16 15:56:38.718701: step 19910, loss = 0.49, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 18h:40m:28s remains)
INFO - root - 2017-12-16 15:56:40.926085: step 19920, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 19h:20m:00s remains)
INFO - root - 2017-12-16 15:56:43.159030: step 19930, loss = 0.42, batch loss = 0.24 (35.3 examples/sec; 0.226 sec/batch; 19h:39m:32s remains)
INFO - root - 2017-12-16 15:56:45.367040: step 19940, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 18h:34m:18s remains)
INFO - root - 2017-12-16 15:56:47.562361: step 19950, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 18h:55m:31s remains)
INFO - root - 2017-12-16 15:56:49.819312: step 19960, loss = 0.53, batch loss = 0.35 (35.0 examples/sec; 0.229 sec/batch; 19h:51m:10s remains)
INFO - root - 2017-12-16 15:56:52.072299: step 19970, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.226 sec/batch; 19h:38m:52s remains)
INFO - root - 2017-12-16 15:56:54.296280: step 19980, loss = 0.46, batch loss = 0.27 (38.3 examples/sec; 0.209 sec/batch; 18h:07m:51s remains)
INFO - root - 2017-12-16 15:56:56.541810: step 19990, loss = 0.55, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 19h:12m:36s remains)
INFO - root - 2017-12-16 15:56:58.773202: step 20000, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 19h:18m:18s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-20000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-20000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 15:57:01.607615: step 20010, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 18h:37m:40s remains)
INFO - root - 2017-12-16 15:57:03.818456: step 20020, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 18h:47m:51s remains)
INFO - root - 2017-12-16 15:57:06.070928: step 20030, loss = 0.54, batch loss = 0.36 (34.5 examples/sec; 0.232 sec/batch; 20h:08m:47s remains)
INFO - root - 2017-12-16 15:57:08.314886: step 20040, loss = 0.54, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 19h:05m:33s remains)
INFO - root - 2017-12-16 15:57:10.538763: step 20050, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 19h:11m:00s remains)
INFO - root - 2017-12-16 15:57:12.741528: step 20060, loss = 0.54, batch loss = 0.36 (37.6 examples/sec; 0.213 sec/batch; 18h:27m:55s remains)
INFO - root - 2017-12-16 15:57:14.962749: step 20070, loss = 0.55, batch loss = 0.37 (35.7 examples/sec; 0.224 sec/batch; 19h:28m:21s remains)
INFO - root - 2017-12-16 15:57:17.192166: step 20080, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 19h:24m:42s remains)
INFO - root - 2017-12-16 15:57:19.415311: step 20090, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 19h:08m:14s remains)
INFO - root - 2017-12-16 15:57:21.638575: step 20100, loss = 0.47, batch loss = 0.29 (38.2 examples/sec; 0.210 sec/batch; 18h:11m:29s remains)
INFO - root - 2017-12-16 15:57:23.974053: step 20110, loss = 0.50, batch loss = 0.32 (37.7 examples/sec; 0.212 sec/batch; 18h:26m:17s remains)
INFO - root - 2017-12-16 15:57:26.183092: step 20120, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 19h:28m:16s remains)
INFO - root - 2017-12-16 15:57:28.415399: step 20130, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 18h:34m:28s remains)
INFO - root - 2017-12-16 15:57:30.642430: step 20140, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.224 sec/batch; 19h:28m:27s remains)
INFO - root - 2017-12-16 15:57:32.907828: step 20150, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 19h:02m:06s remains)
INFO - root - 2017-12-16 15:57:35.132574: step 20160, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 19h:26m:53s remains)
INFO - root - 2017-12-16 15:57:37.332655: step 20170, loss = 0.48, batch loss = 0.30 (33.9 examples/sec; 0.236 sec/batch; 20h:27m:10s remains)
INFO - root - 2017-12-16 15:57:39.531706: step 20180, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 19h:34m:40s remains)
INFO - root - 2017-12-16 15:57:41.723195: step 20190, loss = 0.55, batch loss = 0.37 (36.7 examples/sec; 0.218 sec/batch; 18h:55m:57s remains)
INFO - root - 2017-12-16 15:57:43.924477: step 20200, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 19h:12m:12s remains)
INFO - root - 2017-12-16 15:57:46.258597: step 20210, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 18h:47m:05s remains)
INFO - root - 2017-12-16 15:57:48.483163: step 20220, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 19h:50m:16s remains)
INFO - root - 2017-12-16 15:57:50.679154: step 20230, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 18h:42m:49s remains)
INFO - root - 2017-12-16 15:57:52.918770: step 20240, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 19h:25m:11s remains)
INFO - root - 2017-12-16 15:57:55.113222: step 20250, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 18h:53m:52s remains)
INFO - root - 2017-12-16 15:57:57.351383: step 20260, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 18h:47m:26s remains)
INFO - root - 2017-12-16 15:57:59.618923: step 20270, loss = 0.51, batch loss = 0.33 (37.9 examples/sec; 0.211 sec/batch; 18h:18m:27s remains)
INFO - root - 2017-12-16 15:58:01.826350: step 20280, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 19h:10m:19s remains)
INFO - root - 2017-12-16 15:58:04.078651: step 20290, loss = 0.52, batch loss = 0.34 (33.7 examples/sec; 0.238 sec/batch; 20h:35m:57s remains)
INFO - root - 2017-12-16 15:58:06.294632: step 20300, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 18h:47m:10s remains)
INFO - root - 2017-12-16 15:58:08.696249: step 20310, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 20h:00m:58s remains)
INFO - root - 2017-12-16 15:58:10.919749: step 20320, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 19h:28m:35s remains)
INFO - root - 2017-12-16 15:58:13.138277: step 20330, loss = 0.55, batch loss = 0.37 (36.8 examples/sec; 0.217 sec/batch; 18h:51m:03s remains)
INFO - root - 2017-12-16 15:58:15.407585: step 20340, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.229 sec/batch; 19h:49m:10s remains)
INFO - root - 2017-12-16 15:58:17.632135: step 20350, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 19h:30m:19s remains)
INFO - root - 2017-12-16 15:58:19.854005: step 20360, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.230 sec/batch; 19h:58m:02s remains)
INFO - root - 2017-12-16 15:58:22.064867: step 20370, loss = 0.48, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 19h:02m:37s remains)
INFO - root - 2017-12-16 15:58:24.304016: step 20380, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.221 sec/batch; 19h:11m:43s remains)
INFO - root - 2017-12-16 15:58:26.512546: step 20390, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 19h:45m:46s remains)
INFO - root - 2017-12-16 15:58:28.689122: step 20400, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 19h:12m:59s remains)
INFO - root - 2017-12-16 15:58:31.018875: step 20410, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 18h:33m:56s remains)
INFO - root - 2017-12-16 15:58:33.231481: step 20420, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 18h:56m:39s remains)
INFO - root - 2017-12-16 15:58:35.447325: step 20430, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 19h:40m:27s remains)
INFO - root - 2017-12-16 15:58:37.638373: step 20440, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 18h:40m:36s remains)
INFO - root - 2017-12-16 15:58:39.876027: step 20450, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.224 sec/batch; 19h:27m:18s remains)
INFO - root - 2017-12-16 15:58:42.108925: step 20460, loss = 0.46, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 19h:20m:30s remains)
INFO - root - 2017-12-16 15:58:44.363577: step 20470, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 18h:44m:28s remains)
INFO - root - 2017-12-16 15:58:46.595735: step 20480, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 19h:29m:15s remains)
INFO - root - 2017-12-16 15:58:48.855342: step 20490, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 19h:12m:15s remains)
INFO - root - 2017-12-16 15:58:51.061717: step 20500, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 19h:24m:58s remains)
INFO - root - 2017-12-16 15:58:53.423139: step 20510, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 19h:30m:52s remains)
INFO - root - 2017-12-16 15:58:55.662602: step 20520, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 19h:28m:39s remains)
INFO - root - 2017-12-16 15:58:57.888931: step 20530, loss = 0.48, batch loss = 0.30 (33.4 examples/sec; 0.239 sec/batch; 20h:45m:14s remains)
INFO - root - 2017-12-16 15:59:00.092569: step 20540, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 19h:13m:08s remains)
INFO - root - 2017-12-16 15:59:02.335722: step 20550, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 19h:04m:05s remains)
INFO - root - 2017-12-16 15:59:04.577447: step 20560, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 18h:47m:21s remains)
INFO - root - 2017-12-16 15:59:06.766667: step 20570, loss = 0.54, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 18h:58m:05s remains)
INFO - root - 2017-12-16 15:59:09.031555: step 20580, loss = 0.44, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 19h:31m:39s remains)
INFO - root - 2017-12-16 15:59:11.196939: step 20590, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 18h:52m:15s remains)
INFO - root - 2017-12-16 15:59:13.408976: step 20600, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 18h:50m:22s remains)
INFO - root - 2017-12-16 15:59:15.767967: step 20610, loss = 0.59, batch loss = 0.41 (36.9 examples/sec; 0.217 sec/batch; 18h:48m:00s remains)
INFO - root - 2017-12-16 15:59:18.017449: step 20620, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 19h:35m:40s remains)
INFO - root - 2017-12-16 15:59:20.212949: step 20630, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 19h:37m:38s remains)
INFO - root - 2017-12-16 15:59:22.469783: step 20640, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 18h:59m:28s remains)
INFO - root - 2017-12-16 15:59:24.709767: step 20650, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 19h:17m:46s remains)
INFO - root - 2017-12-16 15:59:26.961000: step 20660, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 20h:05m:01s remains)
INFO - root - 2017-12-16 15:59:29.214887: step 20670, loss = 0.48, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 19h:32m:35s remains)
INFO - root - 2017-12-16 15:59:31.444814: step 20680, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 18h:54m:53s remains)
INFO - root - 2017-12-16 15:59:33.629125: step 20690, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 19h:09m:09s remains)
INFO - root - 2017-12-16 15:59:35.861444: step 20700, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 18h:54m:56s remains)
INFO - root - 2017-12-16 15:59:38.209594: step 20710, loss = 0.42, batch loss = 0.24 (36.8 examples/sec; 0.217 sec/batch; 18h:49m:30s remains)
INFO - root - 2017-12-16 15:59:40.439688: step 20720, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 18h:44m:24s remains)
INFO - root - 2017-12-16 15:59:42.630199: step 20730, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 18h:47m:19s remains)
INFO - root - 2017-12-16 15:59:44.873191: step 20740, loss = 0.45, batch loss = 0.27 (34.8 examples/sec; 0.230 sec/batch; 19h:53m:53s remains)
INFO - root - 2017-12-16 15:59:47.067911: step 20750, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 19h:03m:58s remains)
INFO - root - 2017-12-16 15:59:49.295266: step 20760, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 19h:12m:33s remains)
INFO - root - 2017-12-16 15:59:51.568146: step 20770, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 19h:24m:11s remains)
INFO - root - 2017-12-16 15:59:53.805354: step 20780, loss = 0.46, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 18h:30m:51s remains)
INFO - root - 2017-12-16 15:59:56.028891: step 20790, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 19h:22m:54s remains)
INFO - root - 2017-12-16 15:59:58.247787: step 20800, loss = 0.53, batch loss = 0.35 (34.6 examples/sec; 0.231 sec/batch; 20h:00m:29s remains)
INFO - root - 2017-12-16 16:00:00.606389: step 20810, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 19h:07m:21s remains)
INFO - root - 2017-12-16 16:00:02.835191: step 20820, loss = 0.49, batch loss = 0.31 (34.7 examples/sec; 0.230 sec/batch; 19h:57m:20s remains)
INFO - root - 2017-12-16 16:00:05.087034: step 20830, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 19h:43m:43s remains)
INFO - root - 2017-12-16 16:00:07.308743: step 20840, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 19h:09m:15s remains)
INFO - root - 2017-12-16 16:00:09.542249: step 20850, loss = 0.45, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 19h:30m:31s remains)
INFO - root - 2017-12-16 16:00:11.750886: step 20860, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 18h:56m:18s remains)
INFO - root - 2017-12-16 16:00:13.967776: step 20870, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 19h:18m:37s remains)
INFO - root - 2017-12-16 16:00:16.177269: step 20880, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 19h:28m:23s remains)
INFO - root - 2017-12-16 16:00:18.389376: step 20890, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 18h:41m:19s remains)
INFO - root - 2017-12-16 16:00:20.606620: step 20900, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 18h:58m:38s remains)
INFO - root - 2017-12-16 16:00:22.965020: step 20910, loss = 0.48, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 19h:47m:59s remains)
INFO - root - 2017-12-16 16:00:25.183017: step 20920, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 19h:18m:27s remains)
INFO - root - 2017-12-16 16:00:27.381914: step 20930, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 19h:05m:50s remains)
INFO - root - 2017-12-16 16:00:29.596480: step 20940, loss = 0.55, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 18h:56m:08s remains)
INFO - root - 2017-12-16 16:00:31.850121: step 20950, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 18h:51m:27s remains)
INFO - root - 2017-12-16 16:00:34.084082: step 20960, loss = 0.51, batch loss = 0.32 (34.9 examples/sec; 0.230 sec/batch; 19h:51m:45s remains)
INFO - root - 2017-12-16 16:00:36.296364: step 20970, loss = 0.53, batch loss = 0.35 (35.3 examples/sec; 0.226 sec/batch; 19h:35m:12s remains)
INFO - root - 2017-12-16 16:00:38.521646: step 20980, loss = 0.48, batch loss = 0.29 (33.7 examples/sec; 0.237 sec/batch; 20h:30m:42s remains)
INFO - root - 2017-12-16 16:00:40.745825: step 20990, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 19h:06m:50s remains)
INFO - root - 2017-12-16 16:00:42.969258: step 21000, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 19h:37m:31s remains)
INFO - root - 2017-12-16 16:00:45.329934: step 21010, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 18h:35m:53s remains)
INFO - root - 2017-12-16 16:00:47.538279: step 21020, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 19h:02m:15s remains)
INFO - root - 2017-12-16 16:00:49.793396: step 21030, loss = 0.56, batch loss = 0.38 (35.9 examples/sec; 0.223 sec/batch; 19h:15m:57s remains)
INFO - root - 2017-12-16 16:00:52.025705: step 21040, loss = 0.55, batch loss = 0.36 (35.2 examples/sec; 0.227 sec/batch; 19h:39m:12s remains)
INFO - root - 2017-12-16 16:00:54.241349: step 21050, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 19h:16m:03s remains)
INFO - root - 2017-12-16 16:00:56.463251: step 21060, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 18h:41m:43s remains)
INFO - root - 2017-12-16 16:00:58.700494: step 21070, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.223 sec/batch; 19h:18m:47s remains)
INFO - root - 2017-12-16 16:01:00.905030: step 21080, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 19h:09m:04s remains)
INFO - root - 2017-12-16 16:01:03.160098: step 21090, loss = 0.47, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 19h:07m:00s remains)
INFO - root - 2017-12-16 16:01:05.334281: step 21100, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 18h:43m:59s remains)
INFO - root - 2017-12-16 16:01:07.623251: step 21110, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 18h:35m:33s remains)
INFO - root - 2017-12-16 16:01:09.856567: step 21120, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 19h:50m:33s remains)
INFO - root - 2017-12-16 16:01:12.013193: step 21130, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 19h:05m:53s remains)
INFO - root - 2017-12-16 16:01:14.240844: step 21140, loss = 0.51, batch loss = 0.33 (35.2 examples/sec; 0.227 sec/batch; 19h:38m:18s remains)
INFO - root - 2017-12-16 16:01:16.434099: step 21150, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 19h:31m:55s remains)
INFO - root - 2017-12-16 16:01:18.630878: step 21160, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.221 sec/batch; 19h:05m:08s remains)
INFO - root - 2017-12-16 16:01:20.839858: step 21170, loss = 0.54, batch loss = 0.36 (37.9 examples/sec; 0.211 sec/batch; 18h:14m:33s remains)
INFO - root - 2017-12-16 16:01:23.038145: step 21180, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 19h:30m:16s remains)
INFO - root - 2017-12-16 16:01:25.243530: step 21190, loss = 0.47, batch loss = 0.29 (34.0 examples/sec; 0.235 sec/batch; 20h:20m:58s remains)
INFO - root - 2017-12-16 16:01:27.471144: step 21200, loss = 0.47, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 19h:52m:22s remains)
INFO - root - 2017-12-16 16:01:29.773479: step 21210, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 18h:42m:24s remains)
INFO - root - 2017-12-16 16:01:31.970896: step 21220, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 18h:56m:09s remains)
INFO - root - 2017-12-16 16:01:34.154933: step 21230, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 19h:07m:58s remains)
INFO - root - 2017-12-16 16:01:36.394917: step 21240, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 18h:33m:27s remains)
INFO - root - 2017-12-16 16:01:38.579601: step 21250, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.230 sec/batch; 19h:55m:17s remains)
INFO - root - 2017-12-16 16:01:40.810317: step 21260, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 19h:00m:45s remains)
INFO - root - 2017-12-16 16:01:43.033126: step 21270, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 19h:18m:29s remains)
INFO - root - 2017-12-16 16:01:45.230216: step 21280, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 20h:02m:36s remains)
INFO - root - 2017-12-16 16:01:47.440492: step 21290, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 19h:11m:39s remains)
INFO - root - 2017-12-16 16:01:49.657784: step 21300, loss = 0.48, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 18h:57m:43s remains)
INFO - root - 2017-12-16 16:01:51.987883: step 21310, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 18h:45m:55s remains)
INFO - root - 2017-12-16 16:01:54.156948: step 21320, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 18h:32m:45s remains)
INFO - root - 2017-12-16 16:01:56.376948: step 21330, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 18h:44m:35s remains)
INFO - root - 2017-12-16 16:01:58.555244: step 21340, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 18h:32m:51s remains)
INFO - root - 2017-12-16 16:02:00.726687: step 21350, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 19h:07m:04s remains)
INFO - root - 2017-12-16 16:02:02.914137: step 21360, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 18h:47m:14s remains)
INFO - root - 2017-12-16 16:02:05.105753: step 21370, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 18h:39m:59s remains)
INFO - root - 2017-12-16 16:02:07.286349: step 21380, loss = 0.48, batch loss = 0.30 (38.5 examples/sec; 0.208 sec/batch; 17h:56m:24s remains)
INFO - root - 2017-12-16 16:02:09.464589: step 21390, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 18h:42m:32s remains)
INFO - root - 2017-12-16 16:02:11.657164: step 21400, loss = 0.42, batch loss = 0.24 (37.4 examples/sec; 0.214 sec/batch; 18h:29m:49s remains)
INFO - root - 2017-12-16 16:02:14.019525: step 21410, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 19h:02m:19s remains)
INFO - root - 2017-12-16 16:02:16.259337: step 21420, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 18h:47m:43s remains)
INFO - root - 2017-12-16 16:02:18.436287: step 21430, loss = 0.51, batch loss = 0.33 (37.7 examples/sec; 0.212 sec/batch; 18h:20m:22s remains)
INFO - root - 2017-12-16 16:02:20.653571: step 21440, loss = 0.56, batch loss = 0.38 (37.3 examples/sec; 0.215 sec/batch; 18h:32m:09s remains)
INFO - root - 2017-12-16 16:02:22.897006: step 21450, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 18h:42m:42s remains)
INFO - root - 2017-12-16 16:02:25.098254: step 21460, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 18h:51m:21s remains)
INFO - root - 2017-12-16 16:02:27.336637: step 21470, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 19h:37m:59s remains)
INFO - root - 2017-12-16 16:02:29.518613: step 21480, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 19h:18m:35s remains)
INFO - root - 2017-12-16 16:02:31.685686: step 21490, loss = 0.49, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 18h:39m:24s remains)
INFO - root - 2017-12-16 16:02:33.868686: step 21500, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 19h:25m:21s remains)
INFO - root - 2017-12-16 16:02:36.198933: step 21510, loss = 0.50, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 19h:28m:33s remains)
INFO - root - 2017-12-16 16:02:38.425847: step 21520, loss = 0.47, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 19h:45m:31s remains)
INFO - root - 2017-12-16 16:02:40.665578: step 21530, loss = 0.45, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 19h:51m:59s remains)
INFO - root - 2017-12-16 16:02:42.830210: step 21540, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 19h:27m:06s remains)
INFO - root - 2017-12-16 16:02:45.030780: step 21550, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 18h:50m:17s remains)
INFO - root - 2017-12-16 16:02:47.254579: step 21560, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 19h:08m:04s remains)
INFO - root - 2017-12-16 16:02:49.461765: step 21570, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 18h:42m:09s remains)
INFO - root - 2017-12-16 16:02:51.678048: step 21580, loss = 0.54, batch loss = 0.36 (35.4 examples/sec; 0.226 sec/batch; 19h:32m:41s remains)
INFO - root - 2017-12-16 16:02:53.905404: step 21590, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 19h:15m:42s remains)
INFO - root - 2017-12-16 16:02:56.146057: step 21600, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 19h:22m:18s remains)
INFO - root - 2017-12-16 16:02:58.469966: step 21610, loss = 0.45, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 18h:36m:48s remains)
INFO - root - 2017-12-16 16:03:00.670771: step 21620, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 18h:40m:40s remains)
INFO - root - 2017-12-16 16:03:02.920648: step 21630, loss = 0.43, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 19h:33m:58s remains)
INFO - root - 2017-12-16 16:03:05.145106: step 21640, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 19h:58m:34s remains)
INFO - root - 2017-12-16 16:03:07.353828: step 21650, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 19h:09m:58s remains)
INFO - root - 2017-12-16 16:03:09.574893: step 21660, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 19h:44m:06s remains)
INFO - root - 2017-12-16 16:03:11.798164: step 21670, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 18h:46m:23s remains)
INFO - root - 2017-12-16 16:03:14.011845: step 21680, loss = 0.50, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 18h:58m:40s remains)
INFO - root - 2017-12-16 16:03:16.240256: step 21690, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 18h:52m:28s remains)
INFO - root - 2017-12-16 16:03:18.449800: step 21700, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 19h:30m:55s remains)
INFO - root - 2017-12-16 16:03:20.782458: step 21710, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 18h:42m:13s remains)
INFO - root - 2017-12-16 16:03:23.036900: step 21720, loss = 0.49, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 19h:29m:56s remains)
INFO - root - 2017-12-16 16:03:25.222502: step 21730, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 19h:01m:36s remains)
INFO - root - 2017-12-16 16:03:27.406936: step 21740, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.215 sec/batch; 18h:35m:26s remains)
INFO - root - 2017-12-16 16:03:29.621053: step 21750, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 18h:58m:26s remains)
INFO - root - 2017-12-16 16:03:31.856060: step 21760, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 20h:01m:50s remains)
INFO - root - 2017-12-16 16:03:34.053513: step 21770, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 18h:58m:49s remains)
INFO - root - 2017-12-16 16:03:36.233717: step 21780, loss = 0.44, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 18h:22m:30s remains)
INFO - root - 2017-12-16 16:03:38.459621: step 21790, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 19h:36m:18s remains)
INFO - root - 2017-12-16 16:03:40.670314: step 21800, loss = 0.54, batch loss = 0.36 (35.1 examples/sec; 0.228 sec/batch; 19h:38m:54s remains)
INFO - root - 2017-12-16 16:03:43.037703: step 21810, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 18h:52m:37s remains)
INFO - root - 2017-12-16 16:03:45.256184: step 21820, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.218 sec/batch; 18h:50m:40s remains)
INFO - root - 2017-12-16 16:03:47.487844: step 21830, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 19h:03m:50s remains)
INFO - root - 2017-12-16 16:03:49.700272: step 21840, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 19h:47m:12s remains)
INFO - root - 2017-12-16 16:03:51.899948: step 21850, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 18h:58m:15s remains)
INFO - root - 2017-12-16 16:03:54.129082: step 21860, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 18h:40m:16s remains)
INFO - root - 2017-12-16 16:03:56.329052: step 21870, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 18h:33m:14s remains)
INFO - root - 2017-12-16 16:03:58.547227: step 21880, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 19h:19m:33s remains)
INFO - root - 2017-12-16 16:04:00.775490: step 21890, loss = 0.51, batch loss = 0.33 (34.5 examples/sec; 0.232 sec/batch; 20h:01m:25s remains)
INFO - root - 2017-12-16 16:04:02.990462: step 21900, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 18h:37m:18s remains)
INFO - root - 2017-12-16 16:04:05.360260: step 21910, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 18h:51m:12s remains)
INFO - root - 2017-12-16 16:04:07.553832: step 21920, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 19h:16m:12s remains)
INFO - root - 2017-12-16 16:04:09.784353: step 21930, loss = 0.45, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 18h:21m:36s remains)
INFO - root - 2017-12-16 16:04:11.962869: step 21940, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 18h:54m:10s remains)
INFO - root - 2017-12-16 16:04:14.166820: step 21950, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 19h:14m:05s remains)
INFO - root - 2017-12-16 16:04:16.363749: step 21960, loss = 0.57, batch loss = 0.39 (36.0 examples/sec; 0.222 sec/batch; 19h:09m:12s remains)
INFO - root - 2017-12-16 16:04:18.569574: step 21970, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 18h:59m:06s remains)
INFO - root - 2017-12-16 16:04:20.781377: step 21980, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 19h:01m:58s remains)
INFO - root - 2017-12-16 16:04:23.025286: step 21990, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 19h:51m:06s remains)
INFO - root - 2017-12-16 16:04:25.191748: step 22000, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 18h:31m:51s remains)
INFO - root - 2017-12-16 16:04:27.546800: step 22010, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 18h:56m:15s remains)
INFO - root - 2017-12-16 16:04:29.789940: step 22020, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 19h:26m:20s remains)
INFO - root - 2017-12-16 16:04:31.966851: step 22030, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 18h:36m:19s remains)
INFO - root - 2017-12-16 16:04:34.176762: step 22040, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 18h:52m:54s remains)
INFO - root - 2017-12-16 16:04:36.458798: step 22050, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 19h:22m:52s remains)
INFO - root - 2017-12-16 16:04:38.678638: step 22060, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 19h:12m:23s remains)
INFO - root - 2017-12-16 16:04:40.906592: step 22070, loss = 0.63, batch loss = 0.45 (36.0 examples/sec; 0.222 sec/batch; 19h:10m:43s remains)
INFO - root - 2017-12-16 16:04:43.121537: step 22080, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 18h:39m:28s remains)
INFO - root - 2017-12-16 16:04:45.288644: step 22090, loss = 0.47, batch loss = 0.29 (38.3 examples/sec; 0.209 sec/batch; 18h:01m:44s remains)
INFO - root - 2017-12-16 16:04:47.481497: step 22100, loss = 0.46, batch loss = 0.28 (34.5 examples/sec; 0.232 sec/batch; 19h:58m:17s remains)
INFO - root - 2017-12-16 16:04:49.841870: step 22110, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 18h:32m:15s remains)
INFO - root - 2017-12-16 16:04:52.048210: step 22120, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 19h:58m:24s remains)
INFO - root - 2017-12-16 16:04:54.298087: step 22130, loss = 0.45, batch loss = 0.27 (38.0 examples/sec; 0.211 sec/batch; 18h:09m:34s remains)
INFO - root - 2017-12-16 16:04:56.500492: step 22140, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 19h:08m:35s remains)
INFO - root - 2017-12-16 16:04:58.701883: step 22150, loss = 0.49, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 18h:17m:44s remains)
INFO - root - 2017-12-16 16:05:00.893741: step 22160, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 18h:56m:54s remains)
INFO - root - 2017-12-16 16:05:03.093491: step 22170, loss = 0.60, batch loss = 0.42 (36.4 examples/sec; 0.220 sec/batch; 18h:55m:26s remains)
INFO - root - 2017-12-16 16:05:05.312510: step 22180, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 19h:03m:36s remains)
INFO - root - 2017-12-16 16:05:07.516924: step 22190, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 19h:22m:46s remains)
INFO - root - 2017-12-16 16:05:09.706492: step 22200, loss = 0.49, batch loss = 0.31 (37.9 examples/sec; 0.211 sec/batch; 18h:11m:05s remains)
INFO - root - 2017-12-16 16:05:12.064205: step 22210, loss = 0.59, batch loss = 0.41 (35.8 examples/sec; 0.223 sec/batch; 19h:14m:42s remains)
INFO - root - 2017-12-16 16:05:14.276266: step 22220, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 19h:10m:37s remains)
INFO - root - 2017-12-16 16:05:16.482832: step 22230, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 19h:27m:00s remains)
INFO - root - 2017-12-16 16:05:18.699408: step 22240, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 18h:39m:14s remains)
INFO - root - 2017-12-16 16:05:20.947024: step 22250, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 18h:43m:26s remains)
INFO - root - 2017-12-16 16:05:23.158664: step 22260, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 19h:12m:54s remains)
INFO - root - 2017-12-16 16:05:25.361559: step 22270, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 19h:07m:50s remains)
INFO - root - 2017-12-16 16:05:27.562522: step 22280, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 18h:47m:52s remains)
INFO - root - 2017-12-16 16:05:29.797462: step 22290, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 18h:32m:04s remains)
INFO - root - 2017-12-16 16:05:31.992595: step 22300, loss = 0.56, batch loss = 0.38 (34.9 examples/sec; 0.229 sec/batch; 19h:45m:28s remains)
INFO - root - 2017-12-16 16:05:34.322958: step 22310, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 19h:21m:10s remains)
INFO - root - 2017-12-16 16:05:36.533761: step 22320, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 18h:50m:00s remains)
INFO - root - 2017-12-16 16:05:38.711703: step 22330, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 18h:44m:11s remains)
INFO - root - 2017-12-16 16:05:40.912206: step 22340, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 18h:30m:22s remains)
INFO - root - 2017-12-16 16:05:43.096781: step 22350, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 18h:36m:26s remains)
INFO - root - 2017-12-16 16:05:45.301156: step 22360, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 18h:32m:44s remains)
INFO - root - 2017-12-16 16:05:47.510858: step 22370, loss = 0.51, batch loss = 0.33 (34.5 examples/sec; 0.232 sec/batch; 19h:57m:26s remains)
INFO - root - 2017-12-16 16:05:49.693135: step 22380, loss = 0.47, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 18h:42m:42s remains)
INFO - root - 2017-12-16 16:05:51.904605: step 22390, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 19h:56m:52s remains)
INFO - root - 2017-12-16 16:05:54.098270: step 22400, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 19h:27m:29s remains)
INFO - root - 2017-12-16 16:05:56.441210: step 22410, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 18h:59m:56s remains)
INFO - root - 2017-12-16 16:05:58.629714: step 22420, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.215 sec/batch; 18h:33m:25s remains)
INFO - root - 2017-12-16 16:06:00.840776: step 22430, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.221 sec/batch; 19h:03m:43s remains)
INFO - root - 2017-12-16 16:06:03.043401: step 22440, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 18h:37m:02s remains)
INFO - root - 2017-12-16 16:06:05.251588: step 22450, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 19h:14m:19s remains)
INFO - root - 2017-12-16 16:06:07.458748: step 22460, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 18h:57m:21s remains)
INFO - root - 2017-12-16 16:06:09.674355: step 22470, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 18h:51m:42s remains)
INFO - root - 2017-12-16 16:06:11.864912: step 22480, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 18h:47m:09s remains)
INFO - root - 2017-12-16 16:06:14.078234: step 22490, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 18h:37m:07s remains)
INFO - root - 2017-12-16 16:06:16.287981: step 22500, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 18h:40m:37s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-22500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-22500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 16:06:19.108192: step 22510, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 19h:11m:39s remains)
INFO - root - 2017-12-16 16:06:21.298623: step 22520, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.224 sec/batch; 19h:19m:32s remains)
INFO - root - 2017-12-16 16:06:23.561251: step 22530, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.231 sec/batch; 19h:51m:44s remains)
INFO - root - 2017-12-16 16:06:25.741111: step 22540, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 18h:13m:52s remains)
INFO - root - 2017-12-16 16:06:27.941329: step 22550, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 19h:22m:58s remains)
INFO - root - 2017-12-16 16:06:30.142842: step 22560, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 19h:03m:54s remains)
INFO - root - 2017-12-16 16:06:32.412545: step 22570, loss = 0.48, batch loss = 0.30 (32.7 examples/sec; 0.245 sec/batch; 21h:04m:11s remains)
INFO - root - 2017-12-16 16:06:34.638540: step 22580, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 18h:53m:54s remains)
INFO - root - 2017-12-16 16:06:36.903790: step 22590, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 19h:32m:03s remains)
INFO - root - 2017-12-16 16:06:39.103149: step 22600, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 18h:46m:15s remains)
INFO - root - 2017-12-16 16:06:41.432257: step 22610, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 18h:36m:36s remains)
INFO - root - 2017-12-16 16:06:43.607052: step 22620, loss = 0.57, batch loss = 0.38 (35.1 examples/sec; 0.228 sec/batch; 19h:37m:04s remains)
INFO - root - 2017-12-16 16:06:45.844014: step 22630, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 18h:41m:02s remains)
INFO - root - 2017-12-16 16:06:48.035986: step 22640, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 18h:44m:14s remains)
INFO - root - 2017-12-16 16:06:50.266191: step 22650, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.230 sec/batch; 19h:45m:22s remains)
INFO - root - 2017-12-16 16:06:52.459095: step 22660, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 19h:48m:02s remains)
INFO - root - 2017-12-16 16:06:54.662017: step 22670, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 18h:57m:23s remains)
INFO - root - 2017-12-16 16:06:56.853710: step 22680, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 18h:47m:35s remains)
INFO - root - 2017-12-16 16:06:59.073698: step 22690, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 18h:49m:15s remains)
INFO - root - 2017-12-16 16:07:01.275572: step 22700, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 18h:55m:36s remains)
INFO - root - 2017-12-16 16:07:03.647267: step 22710, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 19h:33m:24s remains)
INFO - root - 2017-12-16 16:07:05.856387: step 22720, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 18h:56m:20s remains)
INFO - root - 2017-12-16 16:07:08.056845: step 22730, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 19h:07m:32s remains)
INFO - root - 2017-12-16 16:07:10.287352: step 22740, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 19h:35m:05s remains)
INFO - root - 2017-12-16 16:07:12.490850: step 22750, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 18h:42m:15s remains)
INFO - root - 2017-12-16 16:07:14.665164: step 22760, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 18h:32m:48s remains)
INFO - root - 2017-12-16 16:07:16.895748: step 22770, loss = 0.54, batch loss = 0.36 (36.1 examples/sec; 0.222 sec/batch; 19h:04m:50s remains)
INFO - root - 2017-12-16 16:07:19.087317: step 22780, loss = 0.59, batch loss = 0.41 (36.7 examples/sec; 0.218 sec/batch; 18h:44m:46s remains)
INFO - root - 2017-12-16 16:07:21.281808: step 22790, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 18h:54m:15s remains)
INFO - root - 2017-12-16 16:07:23.491912: step 22800, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 19h:11m:40s remains)
INFO - root - 2017-12-16 16:07:25.847120: step 22810, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 18h:34m:31s remains)
INFO - root - 2017-12-16 16:07:28.087536: step 22820, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 19h:03m:06s remains)
INFO - root - 2017-12-16 16:07:30.316470: step 22830, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 18h:47m:03s remains)
INFO - root - 2017-12-16 16:07:32.502863: step 22840, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 18h:48m:31s remains)
INFO - root - 2017-12-16 16:07:34.729703: step 22850, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.221 sec/batch; 18h:58m:23s remains)
INFO - root - 2017-12-16 16:07:36.970436: step 22860, loss = 0.49, batch loss = 0.31 (33.2 examples/sec; 0.241 sec/batch; 20h:41m:48s remains)
INFO - root - 2017-12-16 16:07:39.210392: step 22870, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 19h:03m:59s remains)
INFO - root - 2017-12-16 16:07:41.450164: step 22880, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 19h:42m:41s remains)
INFO - root - 2017-12-16 16:07:43.632920: step 22890, loss = 0.49, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 18h:16m:08s remains)
INFO - root - 2017-12-16 16:07:45.834188: step 22900, loss = 0.43, batch loss = 0.25 (34.4 examples/sec; 0.232 sec/batch; 19h:59m:27s remains)
INFO - root - 2017-12-16 16:07:48.194202: step 22910, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 18h:31m:18s remains)
INFO - root - 2017-12-16 16:07:50.438423: step 22920, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 19h:10m:00s remains)
INFO - root - 2017-12-16 16:07:52.663213: step 22930, loss = 0.55, batch loss = 0.37 (35.9 examples/sec; 0.223 sec/batch; 19h:10m:48s remains)
INFO - root - 2017-12-16 16:07:54.871722: step 22940, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 19h:18m:20s remains)
INFO - root - 2017-12-16 16:07:57.059491: step 22950, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 18h:18m:55s remains)
INFO - root - 2017-12-16 16:07:59.279367: step 22960, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 19h:00m:38s remains)
INFO - root - 2017-12-16 16:08:01.490563: step 22970, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 18h:56m:16s remains)
INFO - root - 2017-12-16 16:08:03.710774: step 22980, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 18h:44m:23s remains)
INFO - root - 2017-12-16 16:08:05.926198: step 22990, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 18h:45m:13s remains)
INFO - root - 2017-12-16 16:08:08.147445: step 23000, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 18h:39m:25s remains)
INFO - root - 2017-12-16 16:08:10.528168: step 23010, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 18h:48m:48s remains)
INFO - root - 2017-12-16 16:08:12.739215: step 23020, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 18h:54m:33s remains)
INFO - root - 2017-12-16 16:08:14.983744: step 23030, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 18h:56m:14s remains)
INFO - root - 2017-12-16 16:08:17.180175: step 23040, loss = 0.54, batch loss = 0.36 (34.6 examples/sec; 0.231 sec/batch; 19h:51m:10s remains)
INFO - root - 2017-12-16 16:08:19.374299: step 23050, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 18h:56m:08s remains)
INFO - root - 2017-12-16 16:08:21.575542: step 23060, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 19h:18m:18s remains)
INFO - root - 2017-12-16 16:08:23.788031: step 23070, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 18h:56m:15s remains)
INFO - root - 2017-12-16 16:08:25.975909: step 23080, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 18h:52m:26s remains)
INFO - root - 2017-12-16 16:08:28.167079: step 23090, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 18h:54m:08s remains)
INFO - root - 2017-12-16 16:08:30.350294: step 23100, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 18h:37m:52s remains)
INFO - root - 2017-12-16 16:08:32.706646: step 23110, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 18h:53m:05s remains)
INFO - root - 2017-12-16 16:08:34.901820: step 23120, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 19h:29m:10s remains)
INFO - root - 2017-12-16 16:08:37.152667: step 23130, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 18h:40m:19s remains)
INFO - root - 2017-12-16 16:08:39.390131: step 23140, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 18h:38m:29s remains)
INFO - root - 2017-12-16 16:08:41.623591: step 23150, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 18h:54m:07s remains)
INFO - root - 2017-12-16 16:08:43.843267: step 23160, loss = 0.55, batch loss = 0.37 (36.9 examples/sec; 0.217 sec/batch; 18h:37m:49s remains)
INFO - root - 2017-12-16 16:08:46.051952: step 23170, loss = 0.54, batch loss = 0.36 (37.3 examples/sec; 0.215 sec/batch; 18h:26m:14s remains)
INFO - root - 2017-12-16 16:08:48.293800: step 23180, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 19h:18m:44s remains)
INFO - root - 2017-12-16 16:08:50.500137: step 23190, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 19h:04m:23s remains)
INFO - root - 2017-12-16 16:08:52.722286: step 23200, loss = 0.56, batch loss = 0.38 (36.9 examples/sec; 0.217 sec/batch; 18h:39m:07s remains)
INFO - root - 2017-12-16 16:08:55.082031: step 23210, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 18h:47m:16s remains)
INFO - root - 2017-12-16 16:08:57.342913: step 23220, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 19h:03m:25s remains)
INFO - root - 2017-12-16 16:08:59.558041: step 23230, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 19h:17m:24s remains)
INFO - root - 2017-12-16 16:09:01.730429: step 23240, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 19h:05m:01s remains)
INFO - root - 2017-12-16 16:09:03.962001: step 23250, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 19h:14m:39s remains)
INFO - root - 2017-12-16 16:09:06.185125: step 23260, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 18h:30m:19s remains)
INFO - root - 2017-12-16 16:09:08.407690: step 23270, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 18h:27m:12s remains)
INFO - root - 2017-12-16 16:09:10.591081: step 23280, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 19h:01m:32s remains)
INFO - root - 2017-12-16 16:09:12.793273: step 23290, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 19h:17m:47s remains)
INFO - root - 2017-12-16 16:09:15.011475: step 23300, loss = 0.55, batch loss = 0.37 (36.9 examples/sec; 0.217 sec/batch; 18h:38m:30s remains)
INFO - root - 2017-12-16 16:09:17.389936: step 23310, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 18h:46m:42s remains)
INFO - root - 2017-12-16 16:09:19.609433: step 23320, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 18h:28m:47s remains)
INFO - root - 2017-12-16 16:09:21.779268: step 23330, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 18h:37m:21s remains)
INFO - root - 2017-12-16 16:09:23.997600: step 23340, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 18h:42m:08s remains)
INFO - root - 2017-12-16 16:09:26.204188: step 23350, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 18h:19m:16s remains)
INFO - root - 2017-12-16 16:09:28.414065: step 23360, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 18h:42m:28s remains)
INFO - root - 2017-12-16 16:09:30.619331: step 23370, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 18h:36m:21s remains)
INFO - root - 2017-12-16 16:09:32.845745: step 23380, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 19h:31m:38s remains)
INFO - root - 2017-12-16 16:09:35.081854: step 23390, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 18h:52m:59s remains)
INFO - root - 2017-12-16 16:09:37.276394: step 23400, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.216 sec/batch; 18h:31m:32s remains)
INFO - root - 2017-12-16 16:09:39.650503: step 23410, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 18h:47m:57s remains)
INFO - root - 2017-12-16 16:09:41.880641: step 23420, loss = 0.58, batch loss = 0.39 (37.3 examples/sec; 0.215 sec/batch; 18h:25m:19s remains)
INFO - root - 2017-12-16 16:09:44.119669: step 23430, loss = 0.56, batch loss = 0.38 (35.2 examples/sec; 0.227 sec/batch; 19h:29m:06s remains)
INFO - root - 2017-12-16 16:09:46.328659: step 23440, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 18h:25m:51s remains)
INFO - root - 2017-12-16 16:09:48.524677: step 23450, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 18h:58m:13s remains)
INFO - root - 2017-12-16 16:09:50.740810: step 23460, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 18h:35m:34s remains)
INFO - root - 2017-12-16 16:09:52.965540: step 23470, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 19h:21m:24s remains)
INFO - root - 2017-12-16 16:09:55.178122: step 23480, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 18h:47m:14s remains)
INFO - root - 2017-12-16 16:09:57.385260: step 23490, loss = 0.52, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 19h:30m:45s remains)
INFO - root - 2017-12-16 16:09:59.625610: step 23500, loss = 0.49, batch loss = 0.31 (34.4 examples/sec; 0.232 sec/batch; 19h:57m:09s remains)
INFO - root - 2017-12-16 16:10:01.986178: step 23510, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 18h:37m:38s remains)
INFO - root - 2017-12-16 16:10:04.169228: step 23520, loss = 0.44, batch loss = 0.26 (37.7 examples/sec; 0.212 sec/batch; 18h:13m:40s remains)
INFO - root - 2017-12-16 16:10:06.423483: step 23530, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 19h:12m:29s remains)
INFO - root - 2017-12-16 16:10:08.700539: step 23540, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 19h:35m:23s remains)
INFO - root - 2017-12-16 16:10:10.951210: step 23550, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 18h:56m:02s remains)
INFO - root - 2017-12-16 16:10:13.156949: step 23560, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 18h:32m:10s remains)
INFO - root - 2017-12-16 16:10:15.324844: step 23570, loss = 0.55, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 18h:51m:00s remains)
INFO - root - 2017-12-16 16:10:17.544094: step 23580, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 18h:48m:31s remains)
INFO - root - 2017-12-16 16:10:19.738442: step 23590, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 18h:18m:18s remains)
INFO - root - 2017-12-16 16:10:21.941633: step 23600, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 19h:14m:45s remains)
INFO - root - 2017-12-16 16:10:24.284985: step 23610, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 19h:05m:42s remains)
INFO - root - 2017-12-16 16:10:26.493258: step 23620, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 19h:11m:50s remains)
INFO - root - 2017-12-16 16:10:28.758200: step 23630, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 18h:58m:16s remains)
INFO - root - 2017-12-16 16:10:30.982369: step 23640, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 19h:36m:15s remains)
INFO - root - 2017-12-16 16:10:33.233058: step 23650, loss = 0.53, batch loss = 0.35 (35.2 examples/sec; 0.227 sec/batch; 19h:29m:18s remains)
INFO - root - 2017-12-16 16:10:35.420676: step 23660, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 18h:29m:19s remains)
INFO - root - 2017-12-16 16:10:37.601743: step 23670, loss = 0.42, batch loss = 0.24 (36.3 examples/sec; 0.220 sec/batch; 18h:52m:48s remains)
INFO - root - 2017-12-16 16:10:39.829932: step 23680, loss = 0.44, batch loss = 0.26 (34.5 examples/sec; 0.232 sec/batch; 19h:52m:32s remains)
INFO - root - 2017-12-16 16:10:42.034344: step 23690, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 18h:45m:49s remains)
INFO - root - 2017-12-16 16:10:44.233529: step 23700, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 19h:09m:47s remains)
INFO - root - 2017-12-16 16:10:46.561094: step 23710, loss = 0.51, batch loss = 0.33 (37.7 examples/sec; 0.212 sec/batch; 18h:11m:00s remains)
INFO - root - 2017-12-16 16:10:48.767241: step 23720, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 18h:27m:59s remains)
INFO - root - 2017-12-16 16:10:50.980131: step 23730, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 18h:29m:10s remains)
INFO - root - 2017-12-16 16:10:53.222447: step 23740, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 18h:38m:30s remains)
INFO - root - 2017-12-16 16:10:55.417225: step 23750, loss = 0.53, batch loss = 0.35 (37.6 examples/sec; 0.213 sec/batch; 18h:14m:03s remains)
INFO - root - 2017-12-16 16:10:57.647427: step 23760, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 18h:28m:53s remains)
INFO - root - 2017-12-16 16:10:59.850104: step 23770, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 18h:26m:34s remains)
INFO - root - 2017-12-16 16:11:02.082174: step 23780, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 19h:18m:22s remains)
INFO - root - 2017-12-16 16:11:04.271001: step 23790, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 18h:36m:44s remains)
INFO - root - 2017-12-16 16:11:06.505638: step 23800, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 19h:20m:50s remains)
INFO - root - 2017-12-16 16:11:08.902653: step 23810, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 19h:22m:49s remains)
INFO - root - 2017-12-16 16:11:11.086521: step 23820, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 18h:11m:51s remains)
INFO - root - 2017-12-16 16:11:13.291309: step 23830, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 18h:27m:30s remains)
INFO - root - 2017-12-16 16:11:15.505632: step 23840, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 18h:50m:09s remains)
INFO - root - 2017-12-16 16:11:17.719154: step 23850, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 19h:18m:23s remains)
INFO - root - 2017-12-16 16:11:19.919531: step 23860, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 19h:18m:09s remains)
INFO - root - 2017-12-16 16:11:22.124152: step 23870, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 18h:18m:08s remains)
INFO - root - 2017-12-16 16:11:24.370056: step 23880, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 18h:29m:56s remains)
INFO - root - 2017-12-16 16:11:26.583300: step 23890, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 18h:50m:15s remains)
INFO - root - 2017-12-16 16:11:28.811111: step 23900, loss = 0.53, batch loss = 0.35 (33.9 examples/sec; 0.236 sec/batch; 20h:12m:11s remains)
INFO - root - 2017-12-16 16:11:31.127872: step 23910, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 18h:47m:56s remains)
INFO - root - 2017-12-16 16:11:33.337295: step 23920, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 18h:46m:56s remains)
INFO - root - 2017-12-16 16:11:35.572545: step 23930, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 19h:09m:32s remains)
INFO - root - 2017-12-16 16:11:37.813782: step 23940, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 19h:13m:38s remains)
INFO - root - 2017-12-16 16:11:40.038574: step 23950, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 18h:56m:55s remains)
INFO - root - 2017-12-16 16:11:42.231484: step 23960, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 19h:22m:11s remains)
INFO - root - 2017-12-16 16:11:44.480764: step 23970, loss = 0.42, batch loss = 0.24 (37.3 examples/sec; 0.214 sec/batch; 18h:22m:37s remains)
INFO - root - 2017-12-16 16:11:46.663375: step 23980, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 19h:18m:31s remains)
INFO - root - 2017-12-16 16:11:48.899329: step 23990, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 18h:58m:53s remains)
INFO - root - 2017-12-16 16:11:51.117130: step 24000, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.231 sec/batch; 19h:49m:08s remains)
INFO - root - 2017-12-16 16:11:53.495442: step 24010, loss = 0.51, batch loss = 0.33 (37.8 examples/sec; 0.212 sec/batch; 18h:07m:33s remains)
INFO - root - 2017-12-16 16:11:55.724201: step 24020, loss = 0.52, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 18h:20m:44s remains)
INFO - root - 2017-12-16 16:11:57.934655: step 24030, loss = 0.50, batch loss = 0.32 (34.3 examples/sec; 0.233 sec/batch; 19h:58m:18s remains)
INFO - root - 2017-12-16 16:12:00.150841: step 24040, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 19h:15m:06s remains)
INFO - root - 2017-12-16 16:12:02.437161: step 24050, loss = 0.53, batch loss = 0.35 (35.8 examples/sec; 0.223 sec/batch; 19h:07m:39s remains)
INFO - root - 2017-12-16 16:12:04.674302: step 24060, loss = 0.45, batch loss = 0.27 (34.0 examples/sec; 0.235 sec/batch; 20h:09m:14s remains)
INFO - root - 2017-12-16 16:12:06.917069: step 24070, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 19h:25m:31s remains)
INFO - root - 2017-12-16 16:12:09.182964: step 24080, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.226 sec/batch; 19h:23m:27s remains)
INFO - root - 2017-12-16 16:12:11.407618: step 24090, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 18h:46m:31s remains)
INFO - root - 2017-12-16 16:12:13.617888: step 24100, loss = 0.49, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 18h:09m:46s remains)
INFO - root - 2017-12-16 16:12:15.926997: step 24110, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 18h:30m:06s remains)
INFO - root - 2017-12-16 16:12:18.167226: step 24120, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 19h:43m:06s remains)
INFO - root - 2017-12-16 16:12:20.413929: step 24130, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 19h:08m:10s remains)
INFO - root - 2017-12-16 16:12:22.598817: step 24140, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 19h:11m:19s remains)
INFO - root - 2017-12-16 16:12:24.827889: step 24150, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 18h:46m:31s remains)
INFO - root - 2017-12-16 16:12:27.089536: step 24160, loss = 0.50, batch loss = 0.32 (34.7 examples/sec; 0.230 sec/batch; 19h:43m:18s remains)
INFO - root - 2017-12-16 16:12:29.319327: step 24170, loss = 0.43, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 19h:25m:53s remains)
INFO - root - 2017-12-16 16:12:31.584780: step 24180, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 18h:39m:07s remains)
INFO - root - 2017-12-16 16:12:33.806624: step 24190, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 19h:00m:03s remains)
INFO - root - 2017-12-16 16:12:36.038361: step 24200, loss = 0.49, batch loss = 0.31 (38.0 examples/sec; 0.211 sec/batch; 18h:02m:40s remains)
INFO - root - 2017-12-16 16:12:38.428267: step 24210, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 18h:22m:34s remains)
INFO - root - 2017-12-16 16:12:40.679467: step 24220, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 18h:58m:21s remains)
INFO - root - 2017-12-16 16:12:42.947980: step 24230, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 18h:58m:31s remains)
INFO - root - 2017-12-16 16:12:45.182443: step 24240, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 19h:09m:01s remains)
INFO - root - 2017-12-16 16:12:47.379343: step 24250, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 18h:21m:16s remains)
INFO - root - 2017-12-16 16:12:49.607516: step 24260, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 18h:45m:22s remains)
INFO - root - 2017-12-16 16:12:51.839286: step 24270, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 18h:58m:39s remains)
INFO - root - 2017-12-16 16:12:54.056393: step 24280, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 18h:55m:23s remains)
INFO - root - 2017-12-16 16:12:56.277006: step 24290, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 18h:41m:54s remains)
INFO - root - 2017-12-16 16:12:58.470002: step 24300, loss = 0.55, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 18h:52m:21s remains)
INFO - root - 2017-12-16 16:13:00.843868: step 24310, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 18h:35m:23s remains)
INFO - root - 2017-12-16 16:13:03.041973: step 24320, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 18h:31m:44s remains)
INFO - root - 2017-12-16 16:13:05.249947: step 24330, loss = 0.55, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 18h:55m:20s remains)
INFO - root - 2017-12-16 16:13:07.457026: step 24340, loss = 0.52, batch loss = 0.34 (37.3 examples/sec; 0.214 sec/batch; 18h:20m:38s remains)
INFO - root - 2017-12-16 16:13:09.708567: step 24350, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 18h:37m:37s remains)
INFO - root - 2017-12-16 16:13:11.897678: step 24360, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 18h:35m:31s remains)
INFO - root - 2017-12-16 16:13:14.104006: step 24370, loss = 0.53, batch loss = 0.35 (34.4 examples/sec; 0.233 sec/batch; 19h:55m:02s remains)
INFO - root - 2017-12-16 16:13:16.324618: step 24380, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 18h:53m:40s remains)
INFO - root - 2017-12-16 16:13:18.578351: step 24390, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 19h:24m:07s remains)
INFO - root - 2017-12-16 16:13:20.799534: step 24400, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 19h:27m:52s remains)
INFO - root - 2017-12-16 16:13:23.139971: step 24410, loss = 0.53, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 19h:10m:43s remains)
INFO - root - 2017-12-16 16:13:25.353405: step 24420, loss = 0.54, batch loss = 0.36 (37.0 examples/sec; 0.216 sec/batch; 18h:28m:48s remains)
INFO - root - 2017-12-16 16:13:27.563070: step 24430, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 18h:38m:14s remains)
INFO - root - 2017-12-16 16:13:29.784735: step 24440, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 18h:27m:33s remains)
INFO - root - 2017-12-16 16:13:31.990957: step 24450, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 18h:34m:28s remains)
INFO - root - 2017-12-16 16:13:34.236802: step 24460, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 18h:28m:22s remains)
INFO - root - 2017-12-16 16:13:36.458944: step 24470, loss = 0.49, batch loss = 0.31 (33.2 examples/sec; 0.241 sec/batch; 20h:38m:22s remains)
INFO - root - 2017-12-16 16:13:38.676651: step 24480, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 18h:40m:26s remains)
INFO - root - 2017-12-16 16:13:40.889376: step 24490, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 18h:17m:02s remains)
INFO - root - 2017-12-16 16:13:43.110095: step 24500, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 19h:18m:39s remains)
INFO - root - 2017-12-16 16:13:45.497110: step 24510, loss = 0.51, batch loss = 0.33 (34.1 examples/sec; 0.234 sec/batch; 20h:03m:31s remains)
INFO - root - 2017-12-16 16:13:47.717842: step 24520, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 19h:04m:00s remains)
INFO - root - 2017-12-16 16:13:49.919576: step 24530, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.224 sec/batch; 19h:11m:56s remains)
INFO - root - 2017-12-16 16:13:52.121326: step 24540, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 18h:18m:51s remains)
INFO - root - 2017-12-16 16:13:54.336364: step 24550, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.228 sec/batch; 19h:31m:57s remains)
INFO - root - 2017-12-16 16:13:56.535177: step 24560, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 18h:39m:44s remains)
INFO - root - 2017-12-16 16:13:58.759978: step 24570, loss = 0.48, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 18h:56m:26s remains)
INFO - root - 2017-12-16 16:14:00.985670: step 24580, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 19h:02m:45s remains)
INFO - root - 2017-12-16 16:14:03.225772: step 24590, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 19h:13m:22s remains)
INFO - root - 2017-12-16 16:14:05.458711: step 24600, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 19h:06m:22s remains)
INFO - root - 2017-12-16 16:14:07.847375: step 24610, loss = 0.44, batch loss = 0.26 (35.0 examples/sec; 0.228 sec/batch; 19h:32m:27s remains)
INFO - root - 2017-12-16 16:14:10.076860: step 24620, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 18h:35m:32s remains)
INFO - root - 2017-12-16 16:14:12.301439: step 24630, loss = 0.49, batch loss = 0.31 (34.0 examples/sec; 0.235 sec/batch; 20h:05m:40s remains)
INFO - root - 2017-12-16 16:14:14.534512: step 24640, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 18h:18m:22s remains)
INFO - root - 2017-12-16 16:14:16.792953: step 24650, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 19h:18m:38s remains)
INFO - root - 2017-12-16 16:14:19.004135: step 24660, loss = 0.53, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 19h:10m:37s remains)
INFO - root - 2017-12-16 16:14:21.239027: step 24670, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 18h:45m:07s remains)
INFO - root - 2017-12-16 16:14:23.508224: step 24680, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 18h:56m:07s remains)
INFO - root - 2017-12-16 16:14:25.742660: step 24690, loss = 0.54, batch loss = 0.36 (33.3 examples/sec; 0.240 sec/batch; 20h:31m:32s remains)
INFO - root - 2017-12-16 16:14:27.987886: step 24700, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 18h:19m:02s remains)
INFO - root - 2017-12-16 16:14:30.356167: step 24710, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 19h:05m:16s remains)
INFO - root - 2017-12-16 16:14:32.607884: step 24720, loss = 0.53, batch loss = 0.35 (35.0 examples/sec; 0.229 sec/batch; 19h:32m:42s remains)
INFO - root - 2017-12-16 16:14:34.791678: step 24730, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 18h:42m:48s remains)
INFO - root - 2017-12-16 16:14:36.970709: step 24740, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 18h:37m:23s remains)
INFO - root - 2017-12-16 16:14:39.196338: step 24750, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 18h:21m:00s remains)
INFO - root - 2017-12-16 16:14:41.456321: step 24760, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 19h:01m:45s remains)
INFO - root - 2017-12-16 16:14:43.647677: step 24770, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 18h:48m:00s remains)
INFO - root - 2017-12-16 16:14:45.905035: step 24780, loss = 0.52, batch loss = 0.34 (34.4 examples/sec; 0.233 sec/batch; 19h:52m:51s remains)
INFO - root - 2017-12-16 16:14:48.109799: step 24790, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 18h:39m:30s remains)
INFO - root - 2017-12-16 16:14:50.330791: step 24800, loss = 0.57, batch loss = 0.39 (36.1 examples/sec; 0.221 sec/batch; 18h:55m:11s remains)
INFO - root - 2017-12-16 16:14:52.700737: step 24810, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 19h:47m:44s remains)
INFO - root - 2017-12-16 16:14:54.931661: step 24820, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.230 sec/batch; 19h:41m:42s remains)
INFO - root - 2017-12-16 16:14:57.179745: step 24830, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 19h:19m:35s remains)
INFO - root - 2017-12-16 16:14:59.397009: step 24840, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 18h:32m:34s remains)
INFO - root - 2017-12-16 16:15:01.653487: step 24850, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 19h:14m:25s remains)
INFO - root - 2017-12-16 16:15:03.873048: step 24860, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 18h:32m:20s remains)
INFO - root - 2017-12-16 16:15:06.073218: step 24870, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 18h:15m:57s remains)
INFO - root - 2017-12-16 16:15:08.295799: step 24880, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 18h:44m:59s remains)
INFO - root - 2017-12-16 16:15:10.520471: step 24890, loss = 0.49, batch loss = 0.31 (34.3 examples/sec; 0.233 sec/batch; 19h:56m:40s remains)
INFO - root - 2017-12-16 16:15:12.755386: step 24900, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 18h:56m:19s remains)
INFO - root - 2017-12-16 16:15:15.106402: step 24910, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 18h:32m:16s remains)
INFO - root - 2017-12-16 16:15:17.310128: step 24920, loss = 0.53, batch loss = 0.35 (35.5 examples/sec; 0.226 sec/batch; 19h:16m:12s remains)
INFO - root - 2017-12-16 16:15:19.508512: step 24930, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 19h:27m:15s remains)
INFO - root - 2017-12-16 16:15:21.732046: step 24940, loss = 0.53, batch loss = 0.35 (37.1 examples/sec; 0.216 sec/batch; 18h:25m:14s remains)
INFO - root - 2017-12-16 16:15:23.951938: step 24950, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 18h:18m:40s remains)
INFO - root - 2017-12-16 16:15:26.189274: step 24960, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 18h:54m:53s remains)
INFO - root - 2017-12-16 16:15:28.422356: step 24970, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 18h:40m:12s remains)
INFO - root - 2017-12-16 16:15:30.629560: step 24980, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 19h:13m:39s remains)
INFO - root - 2017-12-16 16:15:32.839061: step 24990, loss = 0.56, batch loss = 0.38 (36.1 examples/sec; 0.222 sec/batch; 18h:55m:37s remains)
INFO - root - 2017-12-16 16:15:35.066193: step 25000, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 18h:43m:23s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-25000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-25000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 16:15:38.056592: step 25010, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 18h:25m:22s remains)
INFO - root - 2017-12-16 16:15:40.294849: step 25020, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 19h:09m:30s remains)
INFO - root - 2017-12-16 16:15:42.494487: step 25030, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 18h:58m:07s remains)
INFO - root - 2017-12-16 16:15:44.713941: step 25040, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 18h:54m:30s remains)
INFO - root - 2017-12-16 16:15:46.926177: step 25050, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 19h:09m:18s remains)
INFO - root - 2017-12-16 16:15:49.118554: step 25060, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 18h:42m:38s remains)
INFO - root - 2017-12-16 16:15:51.337804: step 25070, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 19h:10m:22s remains)
INFO - root - 2017-12-16 16:15:53.642417: step 25080, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 19h:23m:52s remains)
INFO - root - 2017-12-16 16:15:55.846649: step 25090, loss = 0.53, batch loss = 0.35 (34.9 examples/sec; 0.229 sec/batch; 19h:33m:00s remains)
INFO - root - 2017-12-16 16:15:58.069584: step 25100, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.232 sec/batch; 19h:50m:04s remains)
INFO - root - 2017-12-16 16:16:00.448177: step 25110, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 19h:36m:07s remains)
INFO - root - 2017-12-16 16:16:02.656083: step 25120, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 18h:37m:12s remains)
INFO - root - 2017-12-16 16:16:04.922917: step 25130, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 19h:04m:09s remains)
INFO - root - 2017-12-16 16:16:07.129741: step 25140, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 18h:32m:00s remains)
INFO - root - 2017-12-16 16:16:09.410418: step 25150, loss = 0.51, batch loss = 0.33 (34.1 examples/sec; 0.235 sec/batch; 20h:03m:05s remains)
INFO - root - 2017-12-16 16:16:11.663230: step 25160, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 18h:48m:43s remains)
INFO - root - 2017-12-16 16:16:13.922804: step 25170, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 19h:14m:19s remains)
INFO - root - 2017-12-16 16:16:16.113108: step 25180, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 18h:52m:01s remains)
INFO - root - 2017-12-16 16:16:18.336248: step 25190, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 18h:42m:27s remains)
INFO - root - 2017-12-16 16:16:20.550345: step 25200, loss = 0.54, batch loss = 0.36 (36.8 examples/sec; 0.217 sec/batch; 18h:32m:35s remains)
INFO - root - 2017-12-16 16:16:22.903807: step 25210, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 19h:02m:36s remains)
INFO - root - 2017-12-16 16:16:25.095052: step 25220, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 18h:41m:13s remains)
INFO - root - 2017-12-16 16:16:27.313792: step 25230, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.217 sec/batch; 18h:28m:44s remains)
INFO - root - 2017-12-16 16:16:29.503753: step 25240, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 18h:46m:08s remains)
INFO - root - 2017-12-16 16:16:31.706580: step 25250, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.215 sec/batch; 18h:22m:49s remains)
INFO - root - 2017-12-16 16:16:33.962801: step 25260, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 19h:20m:16s remains)
INFO - root - 2017-12-16 16:16:36.167502: step 25270, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.221 sec/batch; 18h:53m:58s remains)
INFO - root - 2017-12-16 16:16:38.412576: step 25280, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 19h:21m:30s remains)
INFO - root - 2017-12-16 16:16:40.618858: step 25290, loss = 0.54, batch loss = 0.36 (37.4 examples/sec; 0.214 sec/batch; 18h:15m:15s remains)
INFO - root - 2017-12-16 16:16:42.855247: step 25300, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 18h:30m:23s remains)
INFO - root - 2017-12-16 16:16:45.198279: step 25310, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 18h:59m:01s remains)
INFO - root - 2017-12-16 16:16:47.388599: step 25320, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 18h:52m:07s remains)
INFO - root - 2017-12-16 16:16:49.598965: step 25330, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 18h:45m:18s remains)
INFO - root - 2017-12-16 16:16:51.805882: step 25340, loss = 0.52, batch loss = 0.34 (37.7 examples/sec; 0.212 sec/batch; 18h:06m:49s remains)
INFO - root - 2017-12-16 16:16:54.047088: step 25350, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 18h:44m:24s remains)
INFO - root - 2017-12-16 16:16:56.229659: step 25360, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 18h:33m:02s remains)
INFO - root - 2017-12-16 16:16:58.437139: step 25370, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 18h:59m:48s remains)
INFO - root - 2017-12-16 16:17:00.660100: step 25380, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 18h:03m:12s remains)
INFO - root - 2017-12-16 16:17:02.897571: step 25390, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 18h:42m:11s remains)
INFO - root - 2017-12-16 16:17:05.093540: step 25400, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 19h:46m:25s remains)
INFO - root - 2017-12-16 16:17:07.482997: step 25410, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 19h:15m:07s remains)
INFO - root - 2017-12-16 16:17:09.699928: step 25420, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 19h:02m:50s remains)
INFO - root - 2017-12-16 16:17:11.931521: step 25430, loss = 0.50, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 19h:38m:06s remains)
INFO - root - 2017-12-16 16:17:14.131781: step 25440, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 18h:41m:26s remains)
INFO - root - 2017-12-16 16:17:16.362537: step 25450, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 18h:56m:54s remains)
INFO - root - 2017-12-16 16:17:18.569588: step 25460, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 18h:28m:36s remains)
INFO - root - 2017-12-16 16:17:20.806173: step 25470, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 19h:36m:48s remains)
INFO - root - 2017-12-16 16:17:23.013409: step 25480, loss = 0.61, batch loss = 0.43 (36.8 examples/sec; 0.218 sec/batch; 18h:33m:40s remains)
INFO - root - 2017-12-16 16:17:25.249257: step 25490, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 19h:04m:27s remains)
INFO - root - 2017-12-16 16:17:27.489473: step 25500, loss = 0.59, batch loss = 0.41 (36.8 examples/sec; 0.217 sec/batch; 18h:31m:37s remains)
INFO - root - 2017-12-16 16:17:29.874064: step 25510, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 18h:32m:38s remains)
INFO - root - 2017-12-16 16:17:32.058242: step 25520, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 19h:06m:06s remains)
INFO - root - 2017-12-16 16:17:34.270253: step 25530, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 19h:00m:21s remains)
INFO - root - 2017-12-16 16:17:36.485959: step 25540, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 18h:44m:46s remains)
INFO - root - 2017-12-16 16:17:38.729518: step 25550, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 19h:18m:42s remains)
INFO - root - 2017-12-16 16:17:40.946227: step 25560, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 19h:18m:58s remains)
INFO - root - 2017-12-16 16:17:43.151485: step 25570, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 19h:26m:54s remains)
INFO - root - 2017-12-16 16:17:45.355435: step 25580, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.219 sec/batch; 18h:42m:48s remains)
INFO - root - 2017-12-16 16:17:47.571167: step 25590, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 18h:35m:23s remains)
INFO - root - 2017-12-16 16:17:49.788787: step 25600, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 19h:35m:55s remains)
INFO - root - 2017-12-16 16:17:52.124560: step 25610, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.215 sec/batch; 18h:22m:02s remains)
INFO - root - 2017-12-16 16:17:54.347929: step 25620, loss = 0.53, batch loss = 0.35 (35.5 examples/sec; 0.225 sec/batch; 19h:12m:00s remains)
INFO - root - 2017-12-16 16:17:56.568764: step 25630, loss = 0.50, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 19h:31m:00s remains)
INFO - root - 2017-12-16 16:17:58.826372: step 25640, loss = 0.57, batch loss = 0.39 (34.8 examples/sec; 0.230 sec/batch; 19h:36m:43s remains)
INFO - root - 2017-12-16 16:18:01.050024: step 25650, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 18h:26m:00s remains)
INFO - root - 2017-12-16 16:18:03.253046: step 25660, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 18h:57m:28s remains)
INFO - root - 2017-12-16 16:18:05.506775: step 25670, loss = 0.53, batch loss = 0.35 (33.3 examples/sec; 0.240 sec/batch; 20h:29m:39s remains)
INFO - root - 2017-12-16 16:18:07.733754: step 25680, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 18h:46m:33s remains)
INFO - root - 2017-12-16 16:18:09.972251: step 25690, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 18h:45m:51s remains)
INFO - root - 2017-12-16 16:18:12.197058: step 25700, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 18h:59m:50s remains)
INFO - root - 2017-12-16 16:18:14.538045: step 25710, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 19h:34m:45s remains)
INFO - root - 2017-12-16 16:18:16.769080: step 25720, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 18h:48m:08s remains)
INFO - root - 2017-12-16 16:18:18.962740: step 25730, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 18h:33m:41s remains)
INFO - root - 2017-12-16 16:18:21.191438: step 25740, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 18h:58m:26s remains)
INFO - root - 2017-12-16 16:18:23.419240: step 25750, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 19h:10m:57s remains)
INFO - root - 2017-12-16 16:18:25.616250: step 25760, loss = 0.53, batch loss = 0.35 (37.9 examples/sec; 0.211 sec/batch; 17h:59m:00s remains)
INFO - root - 2017-12-16 16:18:27.850908: step 25770, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 19h:20m:39s remains)
INFO - root - 2017-12-16 16:18:30.035084: step 25780, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 18h:43m:22s remains)
INFO - root - 2017-12-16 16:18:32.276005: step 25790, loss = 0.56, batch loss = 0.38 (36.1 examples/sec; 0.222 sec/batch; 18h:53m:35s remains)
INFO - root - 2017-12-16 16:18:34.452101: step 25800, loss = 0.53, batch loss = 0.35 (37.4 examples/sec; 0.214 sec/batch; 18h:12m:55s remains)
INFO - root - 2017-12-16 16:18:36.781831: step 25810, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 18h:39m:38s remains)
INFO - root - 2017-12-16 16:18:38.996054: step 25820, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.232 sec/batch; 19h:47m:06s remains)
INFO - root - 2017-12-16 16:18:41.253736: step 25830, loss = 0.53, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 18h:28m:03s remains)
INFO - root - 2017-12-16 16:18:43.477713: step 25840, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 18h:35m:34s remains)
INFO - root - 2017-12-16 16:18:45.715114: step 25850, loss = 0.58, batch loss = 0.40 (37.3 examples/sec; 0.214 sec/batch; 18h:15m:42s remains)
INFO - root - 2017-12-16 16:18:47.953511: step 25860, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 19h:05m:47s remains)
INFO - root - 2017-12-16 16:18:50.129844: step 25870, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 18h:20m:20s remains)
INFO - root - 2017-12-16 16:18:52.390465: step 25880, loss = 0.44, batch loss = 0.26 (33.6 examples/sec; 0.238 sec/batch; 20h:18m:08s remains)
INFO - root - 2017-12-16 16:18:54.640860: step 25890, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 19h:21m:09s remains)
INFO - root - 2017-12-16 16:18:56.894241: step 25900, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 19h:05m:03s remains)
INFO - root - 2017-12-16 16:18:59.230415: step 25910, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 19h:02m:12s remains)
INFO - root - 2017-12-16 16:19:01.487047: step 25920, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 18h:46m:37s remains)
INFO - root - 2017-12-16 16:19:03.683272: step 25930, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 18h:34m:18s remains)
INFO - root - 2017-12-16 16:19:05.902658: step 25940, loss = 0.54, batch loss = 0.36 (36.2 examples/sec; 0.221 sec/batch; 18h:49m:20s remains)
INFO - root - 2017-12-16 16:19:08.180412: step 25950, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 19h:32m:07s remains)
INFO - root - 2017-12-16 16:19:10.411125: step 25960, loss = 0.53, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 19h:04m:41s remains)
INFO - root - 2017-12-16 16:19:12.650587: step 25970, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 18h:49m:29s remains)
INFO - root - 2017-12-16 16:19:14.832356: step 25980, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 18h:49m:17s remains)
INFO - root - 2017-12-16 16:19:17.100746: step 25990, loss = 0.53, batch loss = 0.35 (34.5 examples/sec; 0.232 sec/batch; 19h:44m:35s remains)
INFO - root - 2017-12-16 16:19:19.307100: step 26000, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 18h:22m:55s remains)
INFO - root - 2017-12-16 16:19:21.629137: step 26010, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 18h:21m:50s remains)
INFO - root - 2017-12-16 16:19:23.857709: step 26020, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 19h:29m:24s remains)
INFO - root - 2017-12-16 16:19:26.097701: step 26030, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 18h:49m:36s remains)
INFO - root - 2017-12-16 16:19:28.338239: step 26040, loss = 0.57, batch loss = 0.39 (35.0 examples/sec; 0.229 sec/batch; 19h:27m:26s remains)
INFO - root - 2017-12-16 16:19:30.534138: step 26050, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 19h:21m:46s remains)
INFO - root - 2017-12-16 16:19:32.734950: step 26060, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 19h:18m:29s remains)
INFO - root - 2017-12-16 16:19:34.925993: step 26070, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 18h:17m:29s remains)
INFO - root - 2017-12-16 16:19:37.166703: step 26080, loss = 0.47, batch loss = 0.29 (34.3 examples/sec; 0.233 sec/batch; 19h:49m:32s remains)
INFO - root - 2017-12-16 16:19:39.389228: step 26090, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 19h:08m:18s remains)
INFO - root - 2017-12-16 16:19:41.562340: step 26100, loss = 0.51, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 18h:39m:43s remains)
INFO - root - 2017-12-16 16:19:43.943390: step 26110, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 18h:47m:37s remains)
INFO - root - 2017-12-16 16:19:46.169172: step 26120, loss = 0.51, batch loss = 0.33 (34.9 examples/sec; 0.229 sec/batch; 19h:30m:38s remains)
INFO - root - 2017-12-16 16:19:48.409232: step 26130, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 18h:54m:59s remains)
INFO - root - 2017-12-16 16:19:50.648245: step 26140, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 18h:53m:51s remains)
INFO - root - 2017-12-16 16:19:52.859243: step 26150, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 19h:04m:08s remains)
INFO - root - 2017-12-16 16:19:55.110526: step 26160, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 18h:33m:32s remains)
INFO - root - 2017-12-16 16:19:57.337892: step 26170, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 19h:09m:04s remains)
INFO - root - 2017-12-16 16:19:59.536558: step 26180, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 18h:22m:51s remains)
INFO - root - 2017-12-16 16:20:01.767923: step 26190, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 18h:59m:57s remains)
INFO - root - 2017-12-16 16:20:03.968866: step 26200, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 18h:52m:13s remains)
INFO - root - 2017-12-16 16:20:06.287152: step 26210, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 18h:58m:38s remains)
INFO - root - 2017-12-16 16:20:08.529813: step 26220, loss = 0.44, batch loss = 0.26 (34.5 examples/sec; 0.232 sec/batch; 19h:42m:49s remains)
INFO - root - 2017-12-16 16:20:10.776643: step 26230, loss = 0.57, batch loss = 0.39 (36.0 examples/sec; 0.222 sec/batch; 18h:54m:30s remains)
INFO - root - 2017-12-16 16:20:12.992849: step 26240, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 19h:02m:06s remains)
INFO - root - 2017-12-16 16:20:15.207293: step 26250, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 19h:02m:42s remains)
INFO - root - 2017-12-16 16:20:17.443117: step 26260, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 18h:33m:56s remains)
INFO - root - 2017-12-16 16:20:19.638958: step 26270, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 18h:52m:43s remains)
INFO - root - 2017-12-16 16:20:21.884115: step 26280, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 18h:58m:18s remains)
INFO - root - 2017-12-16 16:20:24.114726: step 26290, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 18h:54m:35s remains)
INFO - root - 2017-12-16 16:20:26.331961: step 26300, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 19h:07m:20s remains)
INFO - root - 2017-12-16 16:20:28.686660: step 26310, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 19h:00m:27s remains)
INFO - root - 2017-12-16 16:20:30.912843: step 26320, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 19h:21m:31s remains)
INFO - root - 2017-12-16 16:20:33.152175: step 26330, loss = 0.51, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 19h:20m:37s remains)
INFO - root - 2017-12-16 16:20:35.360720: step 26340, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 19h:06m:49s remains)
INFO - root - 2017-12-16 16:20:37.571117: step 26350, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 19h:40m:12s remains)
INFO - root - 2017-12-16 16:20:39.792614: step 26360, loss = 0.45, batch loss = 0.27 (33.8 examples/sec; 0.237 sec/batch; 20h:08m:26s remains)
INFO - root - 2017-12-16 16:20:42.050261: step 26370, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 18h:43m:24s remains)
INFO - root - 2017-12-16 16:20:44.254721: step 26380, loss = 0.59, batch loss = 0.41 (36.5 examples/sec; 0.219 sec/batch; 18h:37m:27s remains)
INFO - root - 2017-12-16 16:20:46.464343: step 26390, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 18h:26m:01s remains)
INFO - root - 2017-12-16 16:20:48.649625: step 26400, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 18h:23m:41s remains)
INFO - root - 2017-12-16 16:20:50.961875: step 26410, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 18h:28m:41s remains)
INFO - root - 2017-12-16 16:20:53.234134: step 26420, loss = 0.49, batch loss = 0.31 (34.0 examples/sec; 0.235 sec/batch; 20h:00m:14s remains)
INFO - root - 2017-12-16 16:20:55.481935: step 26430, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 18h:46m:51s remains)
INFO - root - 2017-12-16 16:20:57.699679: step 26440, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 18h:46m:05s remains)
INFO - root - 2017-12-16 16:20:59.922333: step 26450, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 18h:56m:48s remains)
INFO - root - 2017-12-16 16:21:02.152389: step 26460, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 18h:23m:19s remains)
INFO - root - 2017-12-16 16:21:04.340908: step 26470, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 18h:47m:39s remains)
INFO - root - 2017-12-16 16:21:06.574793: step 26480, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 18h:57m:41s remains)
INFO - root - 2017-12-16 16:21:08.819433: step 26490, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 18h:38m:37s remains)
INFO - root - 2017-12-16 16:21:11.030816: step 26500, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 18h:32m:06s remains)
INFO - root - 2017-12-16 16:21:13.383346: step 26510, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 19h:25m:45s remains)
INFO - root - 2017-12-16 16:21:15.579122: step 26520, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 18h:25m:26s remains)
INFO - root - 2017-12-16 16:21:17.797797: step 26530, loss = 0.47, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 18h:54m:25s remains)
INFO - root - 2017-12-16 16:21:20.034978: step 26540, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 18h:58m:32s remains)
INFO - root - 2017-12-16 16:21:22.246171: step 26550, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 18h:30m:46s remains)
INFO - root - 2017-12-16 16:21:24.456666: step 26560, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 18h:31m:02s remains)
INFO - root - 2017-12-16 16:21:26.679820: step 26570, loss = 0.44, batch loss = 0.26 (39.5 examples/sec; 0.203 sec/batch; 17h:12m:31s remains)
INFO - root - 2017-12-16 16:21:28.884435: step 26580, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 18h:38m:04s remains)
INFO - root - 2017-12-16 16:21:31.087796: step 26590, loss = 0.44, batch loss = 0.26 (34.2 examples/sec; 0.234 sec/batch; 19h:51m:38s remains)
INFO - root - 2017-12-16 16:21:33.283783: step 26600, loss = 0.54, batch loss = 0.36 (37.0 examples/sec; 0.216 sec/batch; 18h:21m:48s remains)
INFO - root - 2017-12-16 16:21:35.625241: step 26610, loss = 0.51, batch loss = 0.33 (34.3 examples/sec; 0.233 sec/batch; 19h:48m:33s remains)
INFO - root - 2017-12-16 16:21:37.848544: step 26620, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.216 sec/batch; 18h:20m:41s remains)
INFO - root - 2017-12-16 16:21:40.061514: step 26630, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 18h:52m:09s remains)
INFO - root - 2017-12-16 16:21:42.280573: step 26640, loss = 0.41, batch loss = 0.23 (35.9 examples/sec; 0.223 sec/batch; 18h:56m:21s remains)
INFO - root - 2017-12-16 16:21:44.497144: step 26650, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 18h:41m:18s remains)
INFO - root - 2017-12-16 16:21:46.724379: step 26660, loss = 0.57, batch loss = 0.39 (36.8 examples/sec; 0.217 sec/batch; 18h:27m:56s remains)
INFO - root - 2017-12-16 16:21:48.962950: step 26670, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 18h:29m:13s remains)
INFO - root - 2017-12-16 16:21:51.166840: step 26680, loss = 0.44, batch loss = 0.26 (37.7 examples/sec; 0.212 sec/batch; 18h:00m:33s remains)
INFO - root - 2017-12-16 16:21:53.379874: step 26690, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 18h:23m:03s remains)
INFO - root - 2017-12-16 16:21:55.593410: step 26700, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 18h:44m:27s remains)
INFO - root - 2017-12-16 16:21:57.926562: step 26710, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 18h:27m:59s remains)
INFO - root - 2017-12-16 16:22:00.121004: step 26720, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 18h:33m:07s remains)
INFO - root - 2017-12-16 16:22:02.357826: step 26730, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 18h:37m:05s remains)
INFO - root - 2017-12-16 16:22:04.579169: step 26740, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 18h:19m:57s remains)
INFO - root - 2017-12-16 16:22:06.823319: step 26750, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.223 sec/batch; 18h:53m:55s remains)
INFO - root - 2017-12-16 16:22:09.094322: step 26760, loss = 0.45, batch loss = 0.27 (34.6 examples/sec; 0.231 sec/batch; 19h:39m:34s remains)
INFO - root - 2017-12-16 16:22:11.280472: step 26770, loss = 0.43, batch loss = 0.25 (38.0 examples/sec; 0.211 sec/batch; 17h:53m:59s remains)
INFO - root - 2017-12-16 16:22:13.476121: step 26780, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 18h:41m:54s remains)
INFO - root - 2017-12-16 16:22:15.718530: step 26790, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 19h:28m:34s remains)
INFO - root - 2017-12-16 16:22:17.933002: step 26800, loss = 0.52, batch loss = 0.34 (34.6 examples/sec; 0.231 sec/batch; 19h:39m:19s remains)
INFO - root - 2017-12-16 16:22:20.277537: step 26810, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 18h:29m:04s remains)
INFO - root - 2017-12-16 16:22:22.491813: step 26820, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 18h:42m:36s remains)
INFO - root - 2017-12-16 16:22:24.700221: step 26830, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 18h:19m:49s remains)
INFO - root - 2017-12-16 16:22:26.970856: step 26840, loss = 0.47, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 18h:53m:57s remains)
INFO - root - 2017-12-16 16:22:29.195918: step 26850, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 19h:31m:24s remains)
INFO - root - 2017-12-16 16:22:31.412017: step 26860, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 18h:50m:13s remains)
INFO - root - 2017-12-16 16:22:33.609835: step 26870, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 18h:58m:11s remains)
INFO - root - 2017-12-16 16:22:35.800368: step 26880, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 18h:15m:49s remains)
INFO - root - 2017-12-16 16:22:38.019755: step 26890, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 19h:11m:35s remains)
INFO - root - 2017-12-16 16:22:40.227793: step 26900, loss = 0.51, batch loss = 0.33 (37.6 examples/sec; 0.213 sec/batch; 18h:02m:29s remains)
INFO - root - 2017-12-16 16:22:42.577344: step 26910, loss = 0.42, batch loss = 0.24 (36.1 examples/sec; 0.222 sec/batch; 18h:49m:55s remains)
INFO - root - 2017-12-16 16:22:44.778134: step 26920, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 18h:08m:48s remains)
INFO - root - 2017-12-16 16:22:47.026803: step 26930, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 19h:14m:11s remains)
INFO - root - 2017-12-16 16:22:49.281852: step 26940, loss = 0.55, batch loss = 0.37 (35.9 examples/sec; 0.223 sec/batch; 18h:56m:10s remains)
INFO - root - 2017-12-16 16:22:51.500782: step 26950, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 18h:34m:27s remains)
INFO - root - 2017-12-16 16:22:53.708432: step 26960, loss = 0.43, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 19h:15m:19s remains)
INFO - root - 2017-12-16 16:22:55.923369: step 26970, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 18h:23m:44s remains)
INFO - root - 2017-12-16 16:22:58.153610: step 26980, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.211 sec/batch; 17h:56m:32s remains)
INFO - root - 2017-12-16 16:23:00.383033: step 26990, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 18h:42m:45s remains)
INFO - root - 2017-12-16 16:23:02.588440: step 27000, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 19h:18m:10s remains)
INFO - root - 2017-12-16 16:23:04.934902: step 27010, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 18h:22m:31s remains)
INFO - root - 2017-12-16 16:23:07.172211: step 27020, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 18h:47m:51s remains)
INFO - root - 2017-12-16 16:23:09.386775: step 27030, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 18h:33m:50s remains)
INFO - root - 2017-12-16 16:23:11.578194: step 27040, loss = 0.58, batch loss = 0.40 (36.7 examples/sec; 0.218 sec/batch; 18h:28m:16s remains)
INFO - root - 2017-12-16 16:23:13.818633: step 27050, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 19h:15m:16s remains)
INFO - root - 2017-12-16 16:23:16.091711: step 27060, loss = 0.45, batch loss = 0.27 (34.7 examples/sec; 0.231 sec/batch; 19h:35m:06s remains)
INFO - root - 2017-12-16 16:23:18.328240: step 27070, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 18h:47m:47s remains)
INFO - root - 2017-12-16 16:23:20.526067: step 27080, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 18h:30m:34s remains)
INFO - root - 2017-12-16 16:23:22.730381: step 27090, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 18h:27m:29s remains)
INFO - root - 2017-12-16 16:23:24.959439: step 27100, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 18h:48m:23s remains)
INFO - root - 2017-12-16 16:23:27.329569: step 27110, loss = 0.56, batch loss = 0.38 (36.4 examples/sec; 0.220 sec/batch; 18h:38m:08s remains)
INFO - root - 2017-12-16 16:23:29.530183: step 27120, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 18h:13m:15s remains)
INFO - root - 2017-12-16 16:23:31.764999: step 27130, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 19h:28m:48s remains)
INFO - root - 2017-12-16 16:23:34.003808: step 27140, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 19h:14m:26s remains)
INFO - root - 2017-12-16 16:23:36.246513: step 27150, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 19h:05m:38s remains)
INFO - root - 2017-12-16 16:23:38.434778: step 27160, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 18h:36m:41s remains)
INFO - root - 2017-12-16 16:23:40.724572: step 27170, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 19h:13m:07s remains)
INFO - root - 2017-12-16 16:23:42.979310: step 27180, loss = 0.53, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 18h:59m:55s remains)
INFO - root - 2017-12-16 16:23:45.222415: step 27190, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 18h:55m:44s remains)
INFO - root - 2017-12-16 16:23:47.449587: step 27200, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 19h:20m:40s remains)
INFO - root - 2017-12-16 16:23:49.775789: step 27210, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 18h:31m:00s remains)
INFO - root - 2017-12-16 16:23:52.020035: step 27220, loss = 0.52, batch loss = 0.34 (34.3 examples/sec; 0.233 sec/batch; 19h:45m:56s remains)
INFO - root - 2017-12-16 16:23:54.249858: step 27230, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 19h:09m:51s remains)
INFO - root - 2017-12-16 16:23:56.461382: step 27240, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 18h:53m:45s remains)
INFO - root - 2017-12-16 16:23:58.686545: step 27250, loss = 0.56, batch loss = 0.39 (35.4 examples/sec; 0.226 sec/batch; 19h:11m:19s remains)
INFO - root - 2017-12-16 16:24:00.938974: step 27260, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 19h:39m:22s remains)
INFO - root - 2017-12-16 16:24:03.176644: step 27270, loss = 0.52, batch loss = 0.34 (34.1 examples/sec; 0.235 sec/batch; 19h:53m:10s remains)
INFO - root - 2017-12-16 16:24:05.412297: step 27280, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.223 sec/batch; 18h:51m:54s remains)
INFO - root - 2017-12-16 16:24:07.651424: step 27290, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.231 sec/batch; 19h:33m:26s remains)
INFO - root - 2017-12-16 16:24:09.889964: step 27300, loss = 0.56, batch loss = 0.38 (36.0 examples/sec; 0.222 sec/batch; 18h:50m:38s remains)
INFO - root - 2017-12-16 16:24:12.243891: step 27310, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 19h:01m:16s remains)
INFO - root - 2017-12-16 16:24:14.491560: step 27320, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 19h:04m:18s remains)
INFO - root - 2017-12-16 16:24:16.734922: step 27330, loss = 0.48, batch loss = 0.30 (34.7 examples/sec; 0.231 sec/batch; 19h:33m:49s remains)
INFO - root - 2017-12-16 16:24:18.985207: step 27340, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 19h:03m:34s remains)
INFO - root - 2017-12-16 16:24:21.230771: step 27350, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 18h:26m:59s remains)
INFO - root - 2017-12-16 16:24:23.448325: step 27360, loss = 0.47, batch loss = 0.29 (33.8 examples/sec; 0.237 sec/batch; 20h:02m:57s remains)
INFO - root - 2017-12-16 16:24:25.697188: step 27370, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 19h:26m:38s remains)
INFO - root - 2017-12-16 16:24:27.885645: step 27380, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 18h:34m:34s remains)
INFO - root - 2017-12-16 16:24:30.089918: step 27390, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.221 sec/batch; 18h:41m:29s remains)
INFO - root - 2017-12-16 16:24:32.310282: step 27400, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 18h:01m:05s remains)
INFO - root - 2017-12-16 16:24:34.640305: step 27410, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 18h:17m:58s remains)
INFO - root - 2017-12-16 16:24:36.852854: step 27420, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 18h:58m:58s remains)
INFO - root - 2017-12-16 16:24:39.049560: step 27430, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 18h:27m:08s remains)
INFO - root - 2017-12-16 16:24:41.281166: step 27440, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 18h:46m:48s remains)
INFO - root - 2017-12-16 16:24:43.495460: step 27450, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 19h:03m:21s remains)
INFO - root - 2017-12-16 16:24:45.704853: step 27460, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.218 sec/batch; 18h:29m:44s remains)
INFO - root - 2017-12-16 16:24:47.937185: step 27470, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 19h:10m:28s remains)
INFO - root - 2017-12-16 16:24:50.157795: step 27480, loss = 0.46, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 18h:22m:20s remains)
INFO - root - 2017-12-16 16:24:52.344244: step 27490, loss = 0.43, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 18h:06m:34s remains)
INFO - root - 2017-12-16 16:24:54.571474: step 27500, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 19h:11m:48s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-27500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-27500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 16:24:57.381364: step 27510, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 18h:16m:37s remains)
INFO - root - 2017-12-16 16:24:59.589667: step 27520, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.214 sec/batch; 18h:05m:40s remains)
INFO - root - 2017-12-16 16:25:01.804176: step 27530, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 18h:59m:50s remains)
INFO - root - 2017-12-16 16:25:04.048707: step 27540, loss = 0.53, batch loss = 0.35 (35.3 examples/sec; 0.227 sec/batch; 19h:12m:26s remains)
INFO - root - 2017-12-16 16:25:06.296769: step 27550, loss = 0.50, batch loss = 0.32 (34.1 examples/sec; 0.234 sec/batch; 19h:50m:39s remains)
INFO - root - 2017-12-16 16:25:08.544870: step 27560, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 18h:26m:36s remains)
INFO - root - 2017-12-16 16:25:10.747921: step 27570, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 18h:58m:13s remains)
INFO - root - 2017-12-16 16:25:12.983870: step 27580, loss = 0.55, batch loss = 0.37 (36.9 examples/sec; 0.217 sec/batch; 18h:20m:53s remains)
INFO - root - 2017-12-16 16:25:15.188021: step 27590, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 18h:53m:29s remains)
INFO - root - 2017-12-16 16:25:17.377427: step 27600, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 18h:37m:07s remains)
INFO - root - 2017-12-16 16:25:19.688627: step 27610, loss = 0.51, batch loss = 0.33 (37.5 examples/sec; 0.214 sec/batch; 18h:04m:54s remains)
INFO - root - 2017-12-16 16:25:21.878208: step 27620, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 18h:23m:44s remains)
INFO - root - 2017-12-16 16:25:24.085666: step 27630, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 18h:22m:02s remains)
INFO - root - 2017-12-16 16:25:26.330995: step 27640, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 18h:54m:58s remains)
INFO - root - 2017-12-16 16:25:28.515926: step 27650, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 18h:18m:24s remains)
INFO - root - 2017-12-16 16:25:30.684479: step 27660, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 18h:31m:32s remains)
INFO - root - 2017-12-16 16:25:32.864075: step 27670, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 18h:41m:19s remains)
INFO - root - 2017-12-16 16:25:35.066500: step 27680, loss = 0.64, batch loss = 0.47 (35.8 examples/sec; 0.224 sec/batch; 18h:56m:42s remains)
INFO - root - 2017-12-16 16:25:37.282863: step 27690, loss = 0.40, batch loss = 0.23 (35.6 examples/sec; 0.225 sec/batch; 19h:01m:07s remains)
INFO - root - 2017-12-16 16:25:39.494932: step 27700, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 18h:32m:01s remains)
INFO - root - 2017-12-16 16:25:41.789269: step 27710, loss = 0.48, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 18h:43m:34s remains)
INFO - root - 2017-12-16 16:25:43.984753: step 27720, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 18h:31m:06s remains)
INFO - root - 2017-12-16 16:25:46.197236: step 27730, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 19h:14m:31s remains)
INFO - root - 2017-12-16 16:25:48.433218: step 27740, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 18h:51m:27s remains)
INFO - root - 2017-12-16 16:25:50.663222: step 27750, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 18h:20m:07s remains)
INFO - root - 2017-12-16 16:25:52.870064: step 27760, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 18h:16m:06s remains)
INFO - root - 2017-12-16 16:25:55.068650: step 27770, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 18h:08m:28s remains)
INFO - root - 2017-12-16 16:25:57.291977: step 27780, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 19h:07m:13s remains)
INFO - root - 2017-12-16 16:25:59.503628: step 27790, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 18h:23m:22s remains)
INFO - root - 2017-12-16 16:26:01.720357: step 27800, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 18h:46m:16s remains)
INFO - root - 2017-12-16 16:26:04.060714: step 27810, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 18h:43m:44s remains)
INFO - root - 2017-12-16 16:26:06.266088: step 27820, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 18h:52m:46s remains)
INFO - root - 2017-12-16 16:26:08.500434: step 27830, loss = 0.47, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 18h:28m:16s remains)
INFO - root - 2017-12-16 16:26:10.731009: step 27840, loss = 0.45, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 18h:31m:33s remains)
INFO - root - 2017-12-16 16:26:12.962859: step 27850, loss = 0.54, batch loss = 0.36 (34.6 examples/sec; 0.231 sec/batch; 19h:32m:32s remains)
INFO - root - 2017-12-16 16:26:15.157679: step 27860, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 18h:23m:28s remains)
INFO - root - 2017-12-16 16:26:17.341128: step 27870, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 19h:27m:06s remains)
INFO - root - 2017-12-16 16:26:19.564998: step 27880, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 18h:24m:11s remains)
INFO - root - 2017-12-16 16:26:21.805852: step 27890, loss = 0.48, batch loss = 0.30 (34.0 examples/sec; 0.235 sec/batch; 19h:54m:11s remains)
INFO - root - 2017-12-16 16:26:24.034287: step 27900, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 18h:01m:58s remains)
INFO - root - 2017-12-16 16:26:26.375343: step 27910, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 18h:38m:59s remains)
INFO - root - 2017-12-16 16:26:28.565793: step 27920, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 18h:49m:00s remains)
INFO - root - 2017-12-16 16:26:30.737642: step 27930, loss = 0.55, batch loss = 0.37 (36.9 examples/sec; 0.217 sec/batch; 18h:19m:47s remains)
INFO - root - 2017-12-16 16:26:32.914169: step 27940, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 18h:37m:39s remains)
INFO - root - 2017-12-16 16:26:35.111083: step 27950, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 18h:31m:33s remains)
INFO - root - 2017-12-16 16:26:37.287714: step 27960, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 18h:39m:20s remains)
INFO - root - 2017-12-16 16:26:39.497786: step 27970, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 18h:07m:42s remains)
INFO - root - 2017-12-16 16:26:41.697318: step 27980, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 18h:34m:02s remains)
INFO - root - 2017-12-16 16:26:43.900588: step 27990, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 18h:46m:53s remains)
INFO - root - 2017-12-16 16:26:46.104900: step 28000, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.218 sec/batch; 18h:28m:28s remains)
INFO - root - 2017-12-16 16:26:48.412313: step 28010, loss = 0.52, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 18h:05m:52s remains)
INFO - root - 2017-12-16 16:26:50.576837: step 28020, loss = 0.42, batch loss = 0.24 (37.0 examples/sec; 0.216 sec/batch; 18h:16m:36s remains)
INFO - root - 2017-12-16 16:26:52.753331: step 28030, loss = 0.48, batch loss = 0.30 (38.5 examples/sec; 0.208 sec/batch; 17h:35m:18s remains)
INFO - root - 2017-12-16 16:26:54.948130: step 28040, loss = 0.55, batch loss = 0.37 (36.7 examples/sec; 0.218 sec/batch; 18h:24m:47s remains)
INFO - root - 2017-12-16 16:26:57.156134: step 28050, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 18h:27m:26s remains)
INFO - root - 2017-12-16 16:26:59.353388: step 28060, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 18h:46m:15s remains)
INFO - root - 2017-12-16 16:27:01.573318: step 28070, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 18h:43m:24s remains)
INFO - root - 2017-12-16 16:27:03.758022: step 28080, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 19h:00m:42s remains)
INFO - root - 2017-12-16 16:27:05.948867: step 28090, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 18h:47m:57s remains)
INFO - root - 2017-12-16 16:27:08.168554: step 28100, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 18h:44m:31s remains)
INFO - root - 2017-12-16 16:27:10.519895: step 28110, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 18h:19m:43s remains)
INFO - root - 2017-12-16 16:27:12.737005: step 28120, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 18h:50m:01s remains)
INFO - root - 2017-12-16 16:27:14.951720: step 28130, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 18h:32m:12s remains)
INFO - root - 2017-12-16 16:27:17.155716: step 28140, loss = 0.47, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 18h:40m:16s remains)
INFO - root - 2017-12-16 16:27:19.391278: step 28150, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 18h:53m:27s remains)
INFO - root - 2017-12-16 16:27:21.590098: step 28160, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 18h:26m:04s remains)
INFO - root - 2017-12-16 16:27:23.795323: step 28170, loss = 0.53, batch loss = 0.35 (33.6 examples/sec; 0.238 sec/batch; 20h:07m:05s remains)
INFO - root - 2017-12-16 16:27:26.014833: step 28180, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 18h:31m:22s remains)
INFO - root - 2017-12-16 16:27:28.210095: step 28190, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 18h:34m:00s remains)
INFO - root - 2017-12-16 16:27:30.393127: step 28200, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 18h:11m:11s remains)
INFO - root - 2017-12-16 16:27:32.723642: step 28210, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 19h:07m:16s remains)
INFO - root - 2017-12-16 16:27:34.923752: step 28220, loss = 0.55, batch loss = 0.37 (37.3 examples/sec; 0.214 sec/batch; 18h:07m:33s remains)
INFO - root - 2017-12-16 16:27:37.134247: step 28230, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 18h:34m:16s remains)
INFO - root - 2017-12-16 16:27:39.380521: step 28240, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 18h:26m:38s remains)
INFO - root - 2017-12-16 16:27:41.588120: step 28250, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 19h:24m:14s remains)
INFO - root - 2017-12-16 16:27:43.761683: step 28260, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 18h:26m:46s remains)
INFO - root - 2017-12-16 16:27:45.950953: step 28270, loss = 0.56, batch loss = 0.38 (35.4 examples/sec; 0.226 sec/batch; 19h:04m:31s remains)
INFO - root - 2017-12-16 16:27:48.178260: step 28280, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 18h:21m:01s remains)
INFO - root - 2017-12-16 16:27:50.401705: step 28290, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 19h:31m:48s remains)
INFO - root - 2017-12-16 16:27:52.597067: step 28300, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 18h:14m:44s remains)
INFO - root - 2017-12-16 16:27:54.960802: step 28310, loss = 0.47, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 18h:12m:04s remains)
INFO - root - 2017-12-16 16:27:57.152413: step 28320, loss = 0.58, batch loss = 0.40 (36.9 examples/sec; 0.217 sec/batch; 18h:19m:36s remains)
INFO - root - 2017-12-16 16:27:59.354550: step 28330, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 18h:33m:04s remains)
INFO - root - 2017-12-16 16:28:01.536946: step 28340, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 18h:48m:59s remains)
INFO - root - 2017-12-16 16:28:03.752470: step 28350, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 18h:21m:02s remains)
INFO - root - 2017-12-16 16:28:05.974478: step 28360, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 19h:12m:45s remains)
INFO - root - 2017-12-16 16:28:08.179611: step 28370, loss = 0.49, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 18h:39m:19s remains)
INFO - root - 2017-12-16 16:28:10.434513: step 28380, loss = 0.50, batch loss = 0.32 (34.7 examples/sec; 0.231 sec/batch; 19h:28m:40s remains)
INFO - root - 2017-12-16 16:28:12.644740: step 28390, loss = 0.50, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 18h:30m:37s remains)
INFO - root - 2017-12-16 16:28:14.806352: step 28400, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 18h:06m:14s remains)
INFO - root - 2017-12-16 16:28:17.142358: step 28410, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 18h:34m:39s remains)
INFO - root - 2017-12-16 16:28:19.333093: step 28420, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 18h:19m:36s remains)
INFO - root - 2017-12-16 16:28:21.562455: step 28430, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 18h:20m:16s remains)
INFO - root - 2017-12-16 16:28:23.807841: step 28440, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 18h:46m:28s remains)
INFO - root - 2017-12-16 16:28:26.071412: step 28450, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 19h:14m:13s remains)
INFO - root - 2017-12-16 16:28:28.292527: step 28460, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 18h:26m:21s remains)
INFO - root - 2017-12-16 16:28:30.487840: step 28470, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 19h:03m:18s remains)
INFO - root - 2017-12-16 16:28:32.709198: step 28480, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 18h:31m:33s remains)
INFO - root - 2017-12-16 16:28:34.914558: step 28490, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 18h:25m:28s remains)
INFO - root - 2017-12-16 16:28:37.121028: step 28500, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 18h:15m:50s remains)
INFO - root - 2017-12-16 16:28:39.472972: step 28510, loss = 0.45, batch loss = 0.27 (34.2 examples/sec; 0.234 sec/batch; 19h:46m:04s remains)
INFO - root - 2017-12-16 16:28:41.682425: step 28520, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 18h:49m:38s remains)
INFO - root - 2017-12-16 16:28:43.928699: step 28530, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 18h:38m:22s remains)
INFO - root - 2017-12-16 16:28:46.149892: step 28540, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 18h:40m:35s remains)
INFO - root - 2017-12-16 16:28:48.353914: step 28550, loss = 0.48, batch loss = 0.30 (34.2 examples/sec; 0.234 sec/batch; 19h:44m:28s remains)
INFO - root - 2017-12-16 16:28:50.567036: step 28560, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 18h:45m:35s remains)
INFO - root - 2017-12-16 16:28:52.777617: step 28570, loss = 0.51, batch loss = 0.33 (35.0 examples/sec; 0.229 sec/batch; 19h:17m:41s remains)
INFO - root - 2017-12-16 16:28:55.006183: step 28580, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 18h:32m:01s remains)
INFO - root - 2017-12-16 16:28:57.218902: step 28590, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 18h:53m:47s remains)
INFO - root - 2017-12-16 16:28:59.457546: step 28600, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.214 sec/batch; 18h:06m:09s remains)
INFO - root - 2017-12-16 16:29:01.821547: step 28610, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 18h:45m:48s remains)
INFO - root - 2017-12-16 16:29:04.031703: step 28620, loss = 0.53, batch loss = 0.35 (35.1 examples/sec; 0.228 sec/batch; 19h:15m:52s remains)
INFO - root - 2017-12-16 16:29:06.230351: step 28630, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 18h:25m:29s remains)
INFO - root - 2017-12-16 16:29:08.440852: step 28640, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 18h:28m:31s remains)
INFO - root - 2017-12-16 16:29:10.664531: step 28650, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 18h:16m:50s remains)
INFO - root - 2017-12-16 16:29:12.893569: step 28660, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 18h:44m:11s remains)
INFO - root - 2017-12-16 16:29:15.110353: step 28670, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 18h:04m:41s remains)
INFO - root - 2017-12-16 16:29:17.290946: step 28680, loss = 0.44, batch loss = 0.26 (38.2 examples/sec; 0.209 sec/batch; 17h:39m:54s remains)
INFO - root - 2017-12-16 16:29:19.478171: step 28690, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 18h:31m:49s remains)
INFO - root - 2017-12-16 16:29:21.699246: step 28700, loss = 0.57, batch loss = 0.39 (35.5 examples/sec; 0.226 sec/batch; 19h:01m:59s remains)
INFO - root - 2017-12-16 16:29:24.063132: step 28710, loss = 0.43, batch loss = 0.25 (34.4 examples/sec; 0.232 sec/batch; 19h:36m:56s remains)
INFO - root - 2017-12-16 16:29:26.247249: step 28720, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 18h:38m:58s remains)
INFO - root - 2017-12-16 16:29:28.433613: step 28730, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 18h:12m:04s remains)
INFO - root - 2017-12-16 16:29:30.646693: step 28740, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 18h:03m:35s remains)
INFO - root - 2017-12-16 16:29:32.896942: step 28750, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 18h:49m:02s remains)
INFO - root - 2017-12-16 16:29:35.126095: step 28760, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 19h:24m:24s remains)
INFO - root - 2017-12-16 16:29:37.341011: step 28770, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 18h:42m:38s remains)
INFO - root - 2017-12-16 16:29:39.576420: step 28780, loss = 0.43, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 19h:07m:29s remains)
INFO - root - 2017-12-16 16:29:41.790779: step 28790, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 18h:44m:26s remains)
INFO - root - 2017-12-16 16:29:43.999708: step 28800, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 18h:55m:30s remains)
INFO - root - 2017-12-16 16:29:46.343031: step 28810, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 18h:34m:24s remains)
INFO - root - 2017-12-16 16:29:48.519771: step 28820, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 18h:41m:41s remains)
INFO - root - 2017-12-16 16:29:50.743601: step 28830, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 18h:40m:08s remains)
INFO - root - 2017-12-16 16:29:52.972523: step 28840, loss = 0.42, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 18h:39m:00s remains)
INFO - root - 2017-12-16 16:29:55.195333: step 28850, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 18h:44m:52s remains)
INFO - root - 2017-12-16 16:29:57.445004: step 28860, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 18h:42m:28s remains)
INFO - root - 2017-12-16 16:29:59.671248: step 28870, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 18h:18m:33s remains)
INFO - root - 2017-12-16 16:30:01.883782: step 28880, loss = 0.50, batch loss = 0.32 (34.4 examples/sec; 0.232 sec/batch; 19h:36m:15s remains)
INFO - root - 2017-12-16 16:30:04.094846: step 28890, loss = 0.47, batch loss = 0.29 (33.8 examples/sec; 0.237 sec/batch; 19h:58m:51s remains)
INFO - root - 2017-12-16 16:30:06.320018: step 28900, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 18h:17m:39s remains)
INFO - root - 2017-12-16 16:30:08.671790: step 28910, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 19h:10m:51s remains)
INFO - root - 2017-12-16 16:30:10.882522: step 28920, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 18h:52m:18s remains)
INFO - root - 2017-12-16 16:30:13.071332: step 28930, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 19h:14m:07s remains)
INFO - root - 2017-12-16 16:30:15.309130: step 28940, loss = 0.55, batch loss = 0.37 (36.1 examples/sec; 0.221 sec/batch; 18h:40m:35s remains)
INFO - root - 2017-12-16 16:30:17.523078: step 28950, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 18h:28m:45s remains)
INFO - root - 2017-12-16 16:30:19.737394: step 28960, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 18h:49m:25s remains)
INFO - root - 2017-12-16 16:30:21.955293: step 28970, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 18h:29m:56s remains)
INFO - root - 2017-12-16 16:30:24.249167: step 28980, loss = 0.54, batch loss = 0.36 (35.4 examples/sec; 0.226 sec/batch; 19h:01m:45s remains)
INFO - root - 2017-12-16 16:30:26.450745: step 28990, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 18h:04m:19s remains)
INFO - root - 2017-12-16 16:30:28.677271: step 29000, loss = 0.42, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 18h:21m:59s remains)
INFO - root - 2017-12-16 16:30:31.030367: step 29010, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 19h:14m:17s remains)
INFO - root - 2017-12-16 16:30:33.264930: step 29020, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 18h:45m:57s remains)
INFO - root - 2017-12-16 16:30:35.478822: step 29030, loss = 0.45, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 18h:31m:40s remains)
INFO - root - 2017-12-16 16:30:37.711299: step 29040, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 18h:31m:45s remains)
INFO - root - 2017-12-16 16:30:39.956858: step 29050, loss = 0.61, batch loss = 0.43 (36.2 examples/sec; 0.221 sec/batch; 18h:36m:44s remains)
INFO - root - 2017-12-16 16:30:42.152928: step 29060, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 18h:41m:25s remains)
INFO - root - 2017-12-16 16:30:44.384613: step 29070, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 18h:06m:47s remains)
INFO - root - 2017-12-16 16:30:46.651581: step 29080, loss = 0.53, batch loss = 0.35 (34.5 examples/sec; 0.232 sec/batch; 19h:34m:04s remains)
INFO - root - 2017-12-16 16:30:48.857335: step 29090, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 18h:30m:30s remains)
INFO - root - 2017-12-16 16:30:51.043243: step 29100, loss = 0.57, batch loss = 0.39 (35.8 examples/sec; 0.224 sec/batch; 18h:50m:35s remains)
INFO - root - 2017-12-16 16:30:53.395219: step 29110, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 18h:31m:37s remains)
INFO - root - 2017-12-16 16:30:55.650035: step 29120, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 18h:09m:13s remains)
INFO - root - 2017-12-16 16:30:57.891570: step 29130, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 19h:21m:44s remains)
INFO - root - 2017-12-16 16:31:00.093197: step 29140, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 19h:02m:03s remains)
INFO - root - 2017-12-16 16:31:02.319950: step 29150, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.219 sec/batch; 18h:29m:42s remains)
INFO - root - 2017-12-16 16:31:04.547743: step 29160, loss = 0.44, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 18h:49m:37s remains)
INFO - root - 2017-12-16 16:31:06.784106: step 29170, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 18h:59m:30s remains)
INFO - root - 2017-12-16 16:31:09.034918: step 29180, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 18h:59m:03s remains)
INFO - root - 2017-12-16 16:31:11.234091: step 29190, loss = 0.54, batch loss = 0.36 (37.4 examples/sec; 0.214 sec/batch; 18h:02m:15s remains)
INFO - root - 2017-12-16 16:31:13.461888: step 29200, loss = 0.53, batch loss = 0.35 (37.1 examples/sec; 0.215 sec/batch; 18h:08m:36s remains)
INFO - root - 2017-12-16 16:31:15.798615: step 29210, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 18h:03m:23s remains)
INFO - root - 2017-12-16 16:31:18.002101: step 29220, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 18h:32m:18s remains)
INFO - root - 2017-12-16 16:31:20.208229: step 29230, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 18h:27m:27s remains)
INFO - root - 2017-12-16 16:31:22.448468: step 29240, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 18h:36m:39s remains)
INFO - root - 2017-12-16 16:31:24.720361: step 29250, loss = 0.43, batch loss = 0.25 (33.9 examples/sec; 0.236 sec/batch; 19h:51m:02s remains)
INFO - root - 2017-12-16 16:31:26.915851: step 29260, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 18h:22m:15s remains)
INFO - root - 2017-12-16 16:31:29.157101: step 29270, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 18h:39m:35s remains)
INFO - root - 2017-12-16 16:31:31.381783: step 29280, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 18h:31m:05s remains)
INFO - root - 2017-12-16 16:31:33.606502: step 29290, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 19h:03m:04s remains)
INFO - root - 2017-12-16 16:31:35.823120: step 29300, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 18h:00m:47s remains)
INFO - root - 2017-12-16 16:31:38.126372: step 29310, loss = 0.56, batch loss = 0.38 (37.6 examples/sec; 0.213 sec/batch; 17h:54m:04s remains)
INFO - root - 2017-12-16 16:31:40.332763: step 29320, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 18h:51m:12s remains)
INFO - root - 2017-12-16 16:31:42.582141: step 29330, loss = 0.55, batch loss = 0.37 (34.7 examples/sec; 0.230 sec/batch; 19h:24m:01s remains)
INFO - root - 2017-12-16 16:31:44.811205: step 29340, loss = 0.49, batch loss = 0.31 (33.6 examples/sec; 0.238 sec/batch; 20h:03m:11s remains)
INFO - root - 2017-12-16 16:31:47.031607: step 29350, loss = 0.57, batch loss = 0.39 (34.2 examples/sec; 0.234 sec/batch; 19h:41m:17s remains)
INFO - root - 2017-12-16 16:31:49.236932: step 29360, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 18h:12m:48s remains)
INFO - root - 2017-12-16 16:31:51.453533: step 29370, loss = 0.52, batch loss = 0.35 (37.6 examples/sec; 0.213 sec/batch; 17h:55m:18s remains)
INFO - root - 2017-12-16 16:31:53.661826: step 29380, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 19h:00m:39s remains)
INFO - root - 2017-12-16 16:31:55.876788: step 29390, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 18h:57m:54s remains)
INFO - root - 2017-12-16 16:31:58.044543: step 29400, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 18h:52m:27s remains)
INFO - root - 2017-12-16 16:32:00.353500: step 29410, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 17h:52m:37s remains)
INFO - root - 2017-12-16 16:32:02.547743: step 29420, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 18h:20m:37s remains)
INFO - root - 2017-12-16 16:32:04.769985: step 29430, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 18h:18m:14s remains)
INFO - root - 2017-12-16 16:32:06.984919: step 29440, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 18h:49m:53s remains)
INFO - root - 2017-12-16 16:32:09.212299: step 29450, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 18h:20m:36s remains)
INFO - root - 2017-12-16 16:32:11.401703: step 29460, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 18h:33m:51s remains)
INFO - root - 2017-12-16 16:32:13.609661: step 29470, loss = 0.44, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 18h:18m:24s remains)
INFO - root - 2017-12-16 16:32:15.893791: step 29480, loss = 0.58, batch loss = 0.40 (36.3 examples/sec; 0.220 sec/batch; 18h:32m:49s remains)
INFO - root - 2017-12-16 16:32:18.122351: step 29490, loss = 0.46, batch loss = 0.28 (34.2 examples/sec; 0.234 sec/batch; 19h:40m:40s remains)
INFO - root - 2017-12-16 16:32:20.314916: step 29500, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 18h:14m:01s remains)
INFO - root - 2017-12-16 16:32:22.673244: step 29510, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 18h:21m:38s remains)
INFO - root - 2017-12-16 16:32:24.870136: step 29520, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 19h:03m:25s remains)
INFO - root - 2017-12-16 16:32:27.106369: step 29530, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 18h:12m:27s remains)
INFO - root - 2017-12-16 16:32:29.331353: step 29540, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 19h:10m:23s remains)
INFO - root - 2017-12-16 16:32:31.556350: step 29550, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 18h:23m:33s remains)
INFO - root - 2017-12-16 16:32:33.786123: step 29560, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 18h:41m:48s remains)
INFO - root - 2017-12-16 16:32:36.031295: step 29570, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 18h:49m:33s remains)
INFO - root - 2017-12-16 16:32:38.267404: step 29580, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 18h:49m:55s remains)
INFO - root - 2017-12-16 16:32:40.481119: step 29590, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 18h:18m:37s remains)
INFO - root - 2017-12-16 16:32:42.677578: step 29600, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 19h:15m:57s remains)
INFO - root - 2017-12-16 16:32:45.022345: step 29610, loss = 0.46, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 18h:00m:59s remains)
INFO - root - 2017-12-16 16:32:47.207245: step 29620, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 18h:27m:47s remains)
INFO - root - 2017-12-16 16:32:49.435167: step 29630, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 18h:40m:21s remains)
INFO - root - 2017-12-16 16:32:51.648231: step 29640, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 18h:17m:33s remains)
INFO - root - 2017-12-16 16:32:53.878734: step 29650, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 18h:37m:04s remains)
INFO - root - 2017-12-16 16:32:56.125420: step 29660, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 18h:51m:36s remains)
INFO - root - 2017-12-16 16:32:58.393380: step 29670, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 18h:21m:02s remains)
INFO - root - 2017-12-16 16:33:00.628645: step 29680, loss = 0.44, batch loss = 0.26 (34.6 examples/sec; 0.231 sec/batch; 19h:25m:27s remains)
INFO - root - 2017-12-16 16:33:02.854444: step 29690, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 18h:10m:12s remains)
INFO - root - 2017-12-16 16:33:05.041959: step 29700, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 18h:45m:31s remains)
INFO - root - 2017-12-16 16:33:07.452627: step 29710, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 18h:33m:20s remains)
INFO - root - 2017-12-16 16:33:09.737372: step 29720, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 19h:05m:25s remains)
INFO - root - 2017-12-16 16:33:11.936038: step 29730, loss = 0.43, batch loss = 0.25 (34.8 examples/sec; 0.230 sec/batch; 19h:20m:40s remains)
INFO - root - 2017-12-16 16:33:14.151791: step 29740, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 19h:04m:18s remains)
INFO - root - 2017-12-16 16:33:16.363505: step 29750, loss = 0.53, batch loss = 0.35 (34.3 examples/sec; 0.233 sec/batch; 19h:37m:47s remains)
INFO - root - 2017-12-16 16:33:18.591662: step 29760, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 19h:13m:28s remains)
INFO - root - 2017-12-16 16:33:20.805742: step 29770, loss = 0.48, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 19h:01m:26s remains)
INFO - root - 2017-12-16 16:33:23.044527: step 29780, loss = 0.48, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 18h:25m:25s remains)
INFO - root - 2017-12-16 16:33:25.270439: step 29790, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 18h:27m:26s remains)
INFO - root - 2017-12-16 16:33:27.473221: step 29800, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 18h:15m:52s remains)
INFO - root - 2017-12-16 16:33:29.872292: step 29810, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 19h:10m:12s remains)
INFO - root - 2017-12-16 16:33:32.084396: step 29820, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 18h:25m:49s remains)
INFO - root - 2017-12-16 16:33:34.318586: step 29830, loss = 0.48, batch loss = 0.31 (34.6 examples/sec; 0.231 sec/batch; 19h:27m:00s remains)
INFO - root - 2017-12-16 16:33:36.571375: step 29840, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 18h:58m:19s remains)
INFO - root - 2017-12-16 16:33:38.809042: step 29850, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 18h:31m:18s remains)
INFO - root - 2017-12-16 16:33:40.996041: step 29860, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 18h:23m:13s remains)
INFO - root - 2017-12-16 16:33:43.202308: step 29870, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 18h:14m:10s remains)
INFO - root - 2017-12-16 16:33:45.441550: step 29880, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 18h:00m:48s remains)
INFO - root - 2017-12-16 16:33:47.693308: step 29890, loss = 0.52, batch loss = 0.34 (33.7 examples/sec; 0.237 sec/batch; 19h:57m:19s remains)
INFO - root - 2017-12-16 16:33:49.892814: step 29900, loss = 0.49, batch loss = 0.31 (34.1 examples/sec; 0.234 sec/batch; 19h:41m:33s remains)
INFO - root - 2017-12-16 16:33:52.232839: step 29910, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 18h:37m:28s remains)
INFO - root - 2017-12-16 16:33:54.468364: step 29920, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 18h:40m:26s remains)
INFO - root - 2017-12-16 16:33:56.677602: step 29930, loss = 0.53, batch loss = 0.35 (35.5 examples/sec; 0.225 sec/batch; 18h:55m:59s remains)
INFO - root - 2017-12-16 16:33:58.896415: step 29940, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 19h:29m:40s remains)
INFO - root - 2017-12-16 16:34:01.131577: step 29950, loss = 0.48, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 19h:10m:31s remains)
INFO - root - 2017-12-16 16:34:03.374394: step 29960, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 18h:27m:30s remains)
INFO - root - 2017-12-16 16:34:05.610012: step 29970, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 18h:17m:25s remains)
INFO - root - 2017-12-16 16:34:07.792272: step 29980, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 18h:17m:38s remains)
INFO - root - 2017-12-16 16:34:10.064102: step 29990, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 18h:18m:59s remains)
INFO - root - 2017-12-16 16:34:12.311866: step 30000, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 18h:18m:33s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-30000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-30000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 16:34:15.418012: step 30010, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 18h:33m:42s remains)
INFO - root - 2017-12-16 16:34:17.615911: step 30020, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 19h:15m:38s remains)
INFO - root - 2017-12-16 16:34:19.844885: step 30030, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 18h:37m:54s remains)
INFO - root - 2017-12-16 16:34:22.075162: step 30040, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 18h:34m:15s remains)
INFO - root - 2017-12-16 16:34:24.332264: step 30050, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 18h:46m:10s remains)
INFO - root - 2017-12-16 16:34:26.546784: step 30060, loss = 0.58, batch loss = 0.41 (36.5 examples/sec; 0.219 sec/batch; 18h:25m:16s remains)
INFO - root - 2017-12-16 16:34:28.797507: step 30070, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 18h:10m:43s remains)
INFO - root - 2017-12-16 16:34:31.025684: step 30080, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 18h:20m:29s remains)
INFO - root - 2017-12-16 16:34:33.277679: step 30090, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 18h:35m:57s remains)
INFO - root - 2017-12-16 16:34:35.513343: step 30100, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 18h:40m:08s remains)
INFO - root - 2017-12-16 16:34:37.858817: step 30110, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 18h:38m:29s remains)
INFO - root - 2017-12-16 16:34:40.054304: step 30120, loss = 0.49, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 18h:31m:27s remains)
INFO - root - 2017-12-16 16:34:42.271440: step 30130, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 18h:09m:20s remains)
INFO - root - 2017-12-16 16:34:44.509454: step 30140, loss = 0.45, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 19h:00m:00s remains)
INFO - root - 2017-12-16 16:34:46.719496: step 30150, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 18h:04m:29s remains)
INFO - root - 2017-12-16 16:34:48.943763: step 30160, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 18h:50m:20s remains)
INFO - root - 2017-12-16 16:34:51.146601: step 30170, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.232 sec/batch; 19h:30m:49s remains)
INFO - root - 2017-12-16 16:34:53.388911: step 30180, loss = 0.42, batch loss = 0.24 (36.1 examples/sec; 0.222 sec/batch; 18h:36m:31s remains)
INFO - root - 2017-12-16 16:34:55.602648: step 30190, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 18h:39m:22s remains)
INFO - root - 2017-12-16 16:34:57.835860: step 30200, loss = 0.51, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 19h:05m:22s remains)
INFO - root - 2017-12-16 16:35:00.227430: step 30210, loss = 0.41, batch loss = 0.24 (33.7 examples/sec; 0.238 sec/batch; 19h:57m:43s remains)
INFO - root - 2017-12-16 16:35:02.495470: step 30220, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 17h:55m:14s remains)
INFO - root - 2017-12-16 16:35:04.724097: step 30230, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 18h:18m:51s remains)
INFO - root - 2017-12-16 16:35:06.927711: step 30240, loss = 0.43, batch loss = 0.25 (34.8 examples/sec; 0.230 sec/batch; 19h:18m:10s remains)
INFO - root - 2017-12-16 16:35:09.183154: step 30250, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 18h:44m:00s remains)
INFO - root - 2017-12-16 16:35:11.391794: step 30260, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 18h:54m:48s remains)
INFO - root - 2017-12-16 16:35:13.611175: step 30270, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 18h:18m:29s remains)
INFO - root - 2017-12-16 16:35:15.834221: step 30280, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 18h:56m:30s remains)
INFO - root - 2017-12-16 16:35:18.072813: step 30290, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 18h:39m:27s remains)
INFO - root - 2017-12-16 16:35:20.275910: step 30300, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 18h:25m:00s remains)
INFO - root - 2017-12-16 16:35:22.639566: step 30310, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 19h:11m:52s remains)
INFO - root - 2017-12-16 16:35:24.878289: step 30320, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 18h:24m:00s remains)
INFO - root - 2017-12-16 16:35:27.123953: step 30330, loss = 0.51, batch loss = 0.33 (32.9 examples/sec; 0.243 sec/batch; 20h:23m:14s remains)
INFO - root - 2017-12-16 16:35:29.322516: step 30340, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 18h:09m:42s remains)
INFO - root - 2017-12-16 16:35:31.577321: step 30350, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 18h:16m:39s remains)
INFO - root - 2017-12-16 16:35:33.822701: step 30360, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 18h:42m:57s remains)
INFO - root - 2017-12-16 16:35:36.065180: step 30370, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 18h:34m:21s remains)
INFO - root - 2017-12-16 16:35:38.313076: step 30380, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 19h:24m:58s remains)
INFO - root - 2017-12-16 16:35:40.550756: step 30390, loss = 0.53, batch loss = 0.35 (34.8 examples/sec; 0.230 sec/batch; 19h:15m:54s remains)
INFO - root - 2017-12-16 16:35:42.785865: step 30400, loss = 0.49, batch loss = 0.31 (33.0 examples/sec; 0.243 sec/batch; 20h:22m:05s remains)
INFO - root - 2017-12-16 16:35:45.153577: step 30410, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 18h:31m:52s remains)
INFO - root - 2017-12-16 16:35:47.359267: step 30420, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 17h:58m:14s remains)
INFO - root - 2017-12-16 16:35:49.606286: step 30430, loss = 0.58, batch loss = 0.40 (35.9 examples/sec; 0.223 sec/batch; 18h:42m:50s remains)
INFO - root - 2017-12-16 16:35:51.821046: step 30440, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 18h:22m:53s remains)
INFO - root - 2017-12-16 16:35:54.053682: step 30450, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 18h:46m:02s remains)
INFO - root - 2017-12-16 16:35:56.285023: step 30460, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 18h:10m:20s remains)
INFO - root - 2017-12-16 16:35:58.468073: step 30470, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.221 sec/batch; 18h:34m:27s remains)
INFO - root - 2017-12-16 16:36:00.676621: step 30480, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 18h:04m:49s remains)
INFO - root - 2017-12-16 16:36:02.871861: step 30490, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.221 sec/batch; 18h:30m:18s remains)
INFO - root - 2017-12-16 16:36:05.095954: step 30500, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 18h:14m:06s remains)
INFO - root - 2017-12-16 16:36:07.401635: step 30510, loss = 0.50, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 18h:12m:32s remains)
INFO - root - 2017-12-16 16:36:09.613108: step 30520, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 18h:34m:21s remains)
INFO - root - 2017-12-16 16:36:11.807972: step 30530, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 18h:12m:49s remains)
INFO - root - 2017-12-16 16:36:14.004486: step 30540, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 18h:28m:02s remains)
INFO - root - 2017-12-16 16:36:16.237288: step 30550, loss = 0.44, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 18h:51m:19s remains)
INFO - root - 2017-12-16 16:36:18.448071: step 30560, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 18h:20m:24s remains)
INFO - root - 2017-12-16 16:36:20.652905: step 30570, loss = 0.47, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 18h:21m:51s remains)
INFO - root - 2017-12-16 16:36:22.842548: step 30580, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 18h:44m:01s remains)
INFO - root - 2017-12-16 16:36:25.077638: step 30590, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 18h:45m:43s remains)
INFO - root - 2017-12-16 16:36:27.278225: step 30600, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 18h:12m:24s remains)
INFO - root - 2017-12-16 16:36:29.619398: step 30610, loss = 0.47, batch loss = 0.29 (38.5 examples/sec; 0.208 sec/batch; 17h:24m:11s remains)
INFO - root - 2017-12-16 16:36:31.827136: step 30620, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 17h:59m:05s remains)
INFO - root - 2017-12-16 16:36:34.029042: step 30630, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 18h:35m:48s remains)
INFO - root - 2017-12-16 16:36:36.223153: step 30640, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 18h:17m:19s remains)
INFO - root - 2017-12-16 16:36:38.440658: step 30650, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 18h:20m:50s remains)
INFO - root - 2017-12-16 16:36:40.622001: step 30660, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.224 sec/batch; 18h:49m:05s remains)
INFO - root - 2017-12-16 16:36:42.863717: step 30670, loss = 0.44, batch loss = 0.26 (33.7 examples/sec; 0.237 sec/batch; 19h:54m:12s remains)
INFO - root - 2017-12-16 16:36:45.095891: step 30680, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 18h:20m:14s remains)
INFO - root - 2017-12-16 16:36:47.265383: step 30690, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 18h:39m:12s remains)
INFO - root - 2017-12-16 16:36:49.479156: step 30700, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 18h:43m:33s remains)
INFO - root - 2017-12-16 16:36:51.796186: step 30710, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 18h:09m:11s remains)
INFO - root - 2017-12-16 16:36:54.035743: step 30720, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 18h:23m:08s remains)
INFO - root - 2017-12-16 16:36:56.254613: step 30730, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 18h:01m:34s remains)
INFO - root - 2017-12-16 16:36:58.446908: step 30740, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 19h:05m:31s remains)
INFO - root - 2017-12-16 16:37:00.660154: step 30750, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 18h:16m:47s remains)
INFO - root - 2017-12-16 16:37:02.857839: step 30760, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 17h:58m:57s remains)
INFO - root - 2017-12-16 16:37:05.033900: step 30770, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 18h:37m:45s remains)
INFO - root - 2017-12-16 16:37:07.230075: step 30780, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 18h:38m:44s remains)
INFO - root - 2017-12-16 16:37:09.420593: step 30790, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 18h:38m:33s remains)
INFO - root - 2017-12-16 16:37:11.590176: step 30800, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 18h:21m:42s remains)
INFO - root - 2017-12-16 16:37:13.916648: step 30810, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 18h:56m:44s remains)
INFO - root - 2017-12-16 16:37:16.136061: step 30820, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 18h:18m:16s remains)
INFO - root - 2017-12-16 16:37:18.303454: step 30830, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 17h:54m:18s remains)
INFO - root - 2017-12-16 16:37:20.473803: step 30840, loss = 0.42, batch loss = 0.25 (37.6 examples/sec; 0.213 sec/batch; 17h:50m:04s remains)
INFO - root - 2017-12-16 16:37:22.669141: step 30850, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 18h:10m:25s remains)
INFO - root - 2017-12-16 16:37:24.886841: step 30860, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 18h:29m:38s remains)
INFO - root - 2017-12-16 16:37:27.094734: step 30870, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 18h:42m:51s remains)
INFO - root - 2017-12-16 16:37:29.285371: step 30880, loss = 0.49, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 18h:09m:57s remains)
INFO - root - 2017-12-16 16:37:31.484246: step 30890, loss = 0.57, batch loss = 0.39 (36.6 examples/sec; 0.219 sec/batch; 18h:19m:16s remains)
INFO - root - 2017-12-16 16:37:33.704701: step 30900, loss = 0.46, batch loss = 0.28 (33.1 examples/sec; 0.242 sec/batch; 20h:15m:29s remains)
INFO - root - 2017-12-16 16:37:36.074212: step 30910, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 18h:46m:13s remains)
INFO - root - 2017-12-16 16:37:38.309848: step 30920, loss = 0.49, batch loss = 0.32 (35.0 examples/sec; 0.229 sec/batch; 19h:10m:14s remains)
INFO - root - 2017-12-16 16:37:40.519948: step 30930, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 18h:45m:18s remains)
INFO - root - 2017-12-16 16:37:42.688066: step 30940, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 18h:26m:11s remains)
INFO - root - 2017-12-16 16:37:44.931790: step 30950, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 18h:10m:38s remains)
INFO - root - 2017-12-16 16:37:47.122995: step 30960, loss = 0.43, batch loss = 0.25 (37.9 examples/sec; 0.211 sec/batch; 17h:41m:34s remains)
INFO - root - 2017-12-16 16:37:49.303537: step 30970, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 18h:09m:04s remains)
INFO - root - 2017-12-16 16:37:51.497780: step 30980, loss = 0.54, batch loss = 0.37 (36.7 examples/sec; 0.218 sec/batch; 18h:16m:01s remains)
INFO - root - 2017-12-16 16:37:53.728512: step 30990, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 18h:28m:38s remains)
INFO - root - 2017-12-16 16:37:55.924670: step 31000, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 18h:24m:38s remains)
INFO - root - 2017-12-16 16:37:58.286960: step 31010, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 18h:48m:59s remains)
INFO - root - 2017-12-16 16:38:00.486701: step 31020, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 18h:25m:23s remains)
INFO - root - 2017-12-16 16:38:02.664601: step 31030, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 18h:52m:59s remains)
INFO - root - 2017-12-16 16:38:04.880492: step 31040, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 18h:15m:43s remains)
INFO - root - 2017-12-16 16:38:07.072361: step 31050, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 18h:12m:23s remains)
INFO - root - 2017-12-16 16:38:09.260650: step 31060, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 18h:11m:50s remains)
INFO - root - 2017-12-16 16:38:11.424318: step 31070, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 17h:57m:50s remains)
INFO - root - 2017-12-16 16:38:13.644391: step 31080, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 18h:06m:45s remains)
INFO - root - 2017-12-16 16:38:15.850916: step 31090, loss = 0.42, batch loss = 0.24 (37.0 examples/sec; 0.216 sec/batch; 18h:06m:47s remains)
INFO - root - 2017-12-16 16:38:18.044898: step 31100, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 19h:01m:51s remains)
INFO - root - 2017-12-16 16:38:20.344247: step 31110, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 18h:09m:11s remains)
INFO - root - 2017-12-16 16:38:22.508154: step 31120, loss = 0.50, batch loss = 0.32 (38.4 examples/sec; 0.208 sec/batch; 17h:25m:55s remains)
INFO - root - 2017-12-16 16:38:24.723329: step 31130, loss = 0.48, batch loss = 0.30 (34.7 examples/sec; 0.231 sec/batch; 19h:19m:14s remains)
INFO - root - 2017-12-16 16:38:26.922444: step 31140, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 19h:24m:00s remains)
INFO - root - 2017-12-16 16:38:29.161784: step 31150, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 18h:21m:19s remains)
INFO - root - 2017-12-16 16:38:31.355709: step 31160, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 18h:11m:51s remains)
INFO - root - 2017-12-16 16:38:33.578822: step 31170, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 19h:02m:08s remains)
INFO - root - 2017-12-16 16:38:35.789178: step 31180, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 18h:00m:46s remains)
INFO - root - 2017-12-16 16:38:38.011645: step 31190, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 18h:06m:19s remains)
INFO - root - 2017-12-16 16:38:40.208892: step 31200, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 19h:03m:32s remains)
INFO - root - 2017-12-16 16:38:42.544572: step 31210, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 19h:05m:14s remains)
INFO - root - 2017-12-16 16:38:44.744400: step 31220, loss = 0.56, batch loss = 0.38 (36.7 examples/sec; 0.218 sec/batch; 18h:13m:52s remains)
INFO - root - 2017-12-16 16:38:46.963652: step 31230, loss = 0.56, batch loss = 0.38 (36.1 examples/sec; 0.222 sec/batch; 18h:33m:06s remains)
INFO - root - 2017-12-16 16:38:49.183013: step 31240, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 17h:51m:28s remains)
INFO - root - 2017-12-16 16:38:51.418715: step 31250, loss = 0.45, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 18h:24m:16s remains)
INFO - root - 2017-12-16 16:38:53.680067: step 31260, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.216 sec/batch; 18h:03m:44s remains)
INFO - root - 2017-12-16 16:38:55.914672: step 31270, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 18h:43m:18s remains)
INFO - root - 2017-12-16 16:38:58.124229: step 31280, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 18h:47m:16s remains)
INFO - root - 2017-12-16 16:39:00.350067: step 31290, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 18h:02m:35s remains)
INFO - root - 2017-12-16 16:39:02.597520: step 31300, loss = 0.54, batch loss = 0.36 (37.2 examples/sec; 0.215 sec/batch; 18h:00m:18s remains)
INFO - root - 2017-12-16 16:39:05.004049: step 31310, loss = 0.51, batch loss = 0.33 (34.2 examples/sec; 0.234 sec/batch; 19h:34m:20s remains)
INFO - root - 2017-12-16 16:39:07.203037: step 31320, loss = 0.46, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 18h:07m:56s remains)
INFO - root - 2017-12-16 16:39:09.435475: step 31330, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 18h:21m:08s remains)
INFO - root - 2017-12-16 16:39:11.635108: step 31340, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 18h:04m:57s remains)
INFO - root - 2017-12-16 16:39:13.819653: step 31350, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 17h:55m:44s remains)
INFO - root - 2017-12-16 16:39:15.992274: step 31360, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 18h:09m:10s remains)
INFO - root - 2017-12-16 16:39:18.203284: step 31370, loss = 0.42, batch loss = 0.24 (36.6 examples/sec; 0.218 sec/batch; 18h:16m:03s remains)
INFO - root - 2017-12-16 16:39:20.395174: step 31380, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 18h:44m:22s remains)
INFO - root - 2017-12-16 16:39:22.596298: step 31390, loss = 0.57, batch loss = 0.39 (36.0 examples/sec; 0.222 sec/batch; 18h:35m:31s remains)
INFO - root - 2017-12-16 16:39:24.809955: step 31400, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 18h:08m:21s remains)
INFO - root - 2017-12-16 16:39:27.124574: step 31410, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 18h:21m:33s remains)
INFO - root - 2017-12-16 16:39:29.378745: step 31420, loss = 0.50, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 19h:08m:45s remains)
INFO - root - 2017-12-16 16:39:31.582913: step 31430, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 18h:07m:24s remains)
INFO - root - 2017-12-16 16:39:33.809260: step 31440, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 18h:25m:52s remains)
INFO - root - 2017-12-16 16:39:36.035349: step 31450, loss = 0.57, batch loss = 0.39 (35.5 examples/sec; 0.225 sec/batch; 18h:49m:33s remains)
INFO - root - 2017-12-16 16:39:38.210587: step 31460, loss = 0.50, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 18h:20m:07s remains)
INFO - root - 2017-12-16 16:39:40.418803: step 31470, loss = 0.52, batch loss = 0.34 (37.9 examples/sec; 0.211 sec/batch; 17h:38m:31s remains)
INFO - root - 2017-12-16 16:39:42.668808: step 31480, loss = 0.57, batch loss = 0.39 (35.8 examples/sec; 0.223 sec/batch; 18h:40m:10s remains)
INFO - root - 2017-12-16 16:39:44.865143: step 31490, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 18h:04m:44s remains)
INFO - root - 2017-12-16 16:39:47.078417: step 31500, loss = 0.44, batch loss = 0.26 (35.0 examples/sec; 0.229 sec/batch; 19h:06m:39s remains)
INFO - root - 2017-12-16 16:39:49.492053: step 31510, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 19h:11m:06s remains)
INFO - root - 2017-12-16 16:39:51.726227: step 31520, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 18h:42m:57s remains)
INFO - root - 2017-12-16 16:39:53.941722: step 31530, loss = 0.44, batch loss = 0.26 (34.5 examples/sec; 0.232 sec/batch; 19h:23m:04s remains)
INFO - root - 2017-12-16 16:39:56.138805: step 31540, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 18h:24m:02s remains)
INFO - root - 2017-12-16 16:39:58.367398: step 31550, loss = 0.55, batch loss = 0.37 (36.9 examples/sec; 0.217 sec/batch; 18h:06m:32s remains)
INFO - root - 2017-12-16 16:40:00.604896: step 31560, loss = 0.45, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 18h:06m:06s remains)
INFO - root - 2017-12-16 16:40:02.815322: step 31570, loss = 0.45, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 18h:15m:24s remains)
INFO - root - 2017-12-16 16:40:05.027943: step 31580, loss = 0.53, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 18h:14m:14s remains)
INFO - root - 2017-12-16 16:40:07.261138: step 31590, loss = 0.55, batch loss = 0.37 (34.0 examples/sec; 0.236 sec/batch; 19h:41m:29s remains)
INFO - root - 2017-12-16 16:40:09.519878: step 31600, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 18h:18m:27s remains)
INFO - root - 2017-12-16 16:40:11.883485: step 31610, loss = 0.48, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 18h:02m:48s remains)
INFO - root - 2017-12-16 16:40:14.109148: step 31620, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 18h:17m:28s remains)
INFO - root - 2017-12-16 16:40:16.311293: step 31630, loss = 0.51, batch loss = 0.33 (35.1 examples/sec; 0.228 sec/batch; 19h:03m:46s remains)
INFO - root - 2017-12-16 16:40:18.538961: step 31640, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 17h:59m:44s remains)
INFO - root - 2017-12-16 16:40:20.737783: step 31650, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 18h:34m:43s remains)
INFO - root - 2017-12-16 16:40:22.934148: step 31660, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 18h:23m:52s remains)
INFO - root - 2017-12-16 16:40:25.164057: step 31670, loss = 0.47, batch loss = 0.29 (33.8 examples/sec; 0.236 sec/batch; 19h:45m:32s remains)
INFO - root - 2017-12-16 16:40:27.390191: step 31680, loss = 0.58, batch loss = 0.40 (35.6 examples/sec; 0.224 sec/batch; 18h:45m:17s remains)
INFO - root - 2017-12-16 16:40:29.585663: step 31690, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 19h:08m:44s remains)
INFO - root - 2017-12-16 16:40:31.791807: step 31700, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 18h:33m:08s remains)
INFO - root - 2017-12-16 16:40:34.162379: step 31710, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 18h:19m:02s remains)
INFO - root - 2017-12-16 16:40:36.351310: step 31720, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 18h:30m:36s remains)
INFO - root - 2017-12-16 16:40:38.599920: step 31730, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 18h:05m:27s remains)
INFO - root - 2017-12-16 16:40:40.832364: step 31740, loss = 0.47, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 18h:25m:38s remains)
INFO - root - 2017-12-16 16:40:43.066010: step 31750, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 18h:32m:25s remains)
INFO - root - 2017-12-16 16:40:45.265032: step 31760, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 18h:17m:31s remains)
INFO - root - 2017-12-16 16:40:47.491771: step 31770, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 18h:20m:21s remains)
INFO - root - 2017-12-16 16:40:49.703204: step 31780, loss = 0.55, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 18h:27m:01s remains)
INFO - root - 2017-12-16 16:40:51.910803: step 31790, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.217 sec/batch; 18h:05m:06s remains)
INFO - root - 2017-12-16 16:40:54.105057: step 31800, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 18h:38m:36s remains)
INFO - root - 2017-12-16 16:40:56.440210: step 31810, loss = 0.59, batch loss = 0.41 (36.8 examples/sec; 0.217 sec/batch; 18h:09m:59s remains)
INFO - root - 2017-12-16 16:40:58.627445: step 31820, loss = 0.48, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 18h:29m:11s remains)
INFO - root - 2017-12-16 16:41:00.835037: step 31830, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 18h:41m:30s remains)
INFO - root - 2017-12-16 16:41:03.044839: step 31840, loss = 0.44, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 18h:37m:28s remains)
INFO - root - 2017-12-16 16:41:05.298709: step 31850, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 18h:50m:54s remains)
INFO - root - 2017-12-16 16:41:07.496580: step 31860, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 18h:27m:34s remains)
INFO - root - 2017-12-16 16:41:09.668031: step 31870, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 18h:22m:23s remains)
INFO - root - 2017-12-16 16:41:11.900170: step 31880, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 18h:54m:01s remains)
INFO - root - 2017-12-16 16:41:14.120734: step 31890, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 18h:32m:22s remains)
INFO - root - 2017-12-16 16:41:16.341608: step 31900, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 18h:41m:37s remains)
INFO - root - 2017-12-16 16:41:18.692979: step 31910, loss = 0.57, batch loss = 0.39 (35.4 examples/sec; 0.226 sec/batch; 18h:53m:02s remains)
INFO - root - 2017-12-16 16:41:20.914181: step 31920, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 18h:18m:13s remains)
INFO - root - 2017-12-16 16:41:23.130455: step 31930, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 18h:25m:14s remains)
INFO - root - 2017-12-16 16:41:25.330227: step 31940, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 18h:46m:43s remains)
INFO - root - 2017-12-16 16:41:27.557334: step 31950, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 18h:32m:11s remains)
INFO - root - 2017-12-16 16:41:29.728386: step 31960, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 18h:06m:15s remains)
INFO - root - 2017-12-16 16:41:31.954493: step 31970, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 18h:21m:01s remains)
INFO - root - 2017-12-16 16:41:34.177888: step 31980, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 18h:26m:26s remains)
INFO - root - 2017-12-16 16:41:36.428503: step 31990, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 18h:40m:40s remains)
INFO - root - 2017-12-16 16:41:38.654138: step 32000, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 18h:25m:35s remains)
INFO - root - 2017-12-16 16:41:41.042507: step 32010, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 18h:49m:11s remains)
INFO - root - 2017-12-16 16:41:43.279863: step 32020, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 18h:18m:46s remains)
INFO - root - 2017-12-16 16:41:45.482068: step 32030, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 18h:56m:06s remains)
INFO - root - 2017-12-16 16:41:47.645797: step 32040, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 18h:06m:58s remains)
INFO - root - 2017-12-16 16:41:49.879572: step 32050, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 18h:25m:05s remains)
INFO - root - 2017-12-16 16:41:52.093723: step 32060, loss = 0.58, batch loss = 0.40 (35.0 examples/sec; 0.228 sec/batch; 19h:02m:54s remains)
INFO - root - 2017-12-16 16:41:54.316211: step 32070, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 18h:21m:34s remains)
INFO - root - 2017-12-16 16:41:56.535804: step 32080, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 18h:51m:25s remains)
INFO - root - 2017-12-16 16:41:58.717518: step 32090, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 17h:59m:12s remains)
INFO - root - 2017-12-16 16:42:00.920505: step 32100, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 18h:29m:36s remains)
INFO - root - 2017-12-16 16:42:03.285904: step 32110, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 18h:56m:56s remains)
INFO - root - 2017-12-16 16:42:05.506691: step 32120, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 18h:17m:34s remains)
INFO - root - 2017-12-16 16:42:07.699974: step 32130, loss = 0.58, batch loss = 0.40 (37.5 examples/sec; 0.213 sec/batch; 17h:48m:23s remains)
INFO - root - 2017-12-16 16:42:09.906576: step 32140, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 18h:34m:57s remains)
INFO - root - 2017-12-16 16:42:12.128377: step 32150, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.230 sec/batch; 19h:12m:45s remains)
INFO - root - 2017-12-16 16:42:14.344837: step 32160, loss = 0.48, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 18h:35m:58s remains)
INFO - root - 2017-12-16 16:42:16.548259: step 32170, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 18h:13m:31s remains)
INFO - root - 2017-12-16 16:42:18.784284: step 32180, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 18h:31m:16s remains)
INFO - root - 2017-12-16 16:42:21.006223: step 32190, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 18h:53m:07s remains)
INFO - root - 2017-12-16 16:42:23.233000: step 32200, loss = 0.57, batch loss = 0.39 (37.3 examples/sec; 0.215 sec/batch; 17h:53m:42s remains)
INFO - root - 2017-12-16 16:42:25.603231: step 32210, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 18h:04m:10s remains)
INFO - root - 2017-12-16 16:42:27.847787: step 32220, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 18h:36m:48s remains)
INFO - root - 2017-12-16 16:42:30.053631: step 32230, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 18h:33m:56s remains)
INFO - root - 2017-12-16 16:42:32.260319: step 32240, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 18h:21m:22s remains)
INFO - root - 2017-12-16 16:42:34.481978: step 32250, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 18h:35m:24s remains)
INFO - root - 2017-12-16 16:42:36.686649: step 32260, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 17h:53m:25s remains)
INFO - root - 2017-12-16 16:42:38.953195: step 32270, loss = 0.44, batch loss = 0.27 (35.3 examples/sec; 0.226 sec/batch; 18h:52m:53s remains)
INFO - root - 2017-12-16 16:42:41.176475: step 32280, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 18h:32m:09s remains)
INFO - root - 2017-12-16 16:42:43.412049: step 32290, loss = 0.45, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 17h:59m:56s remains)
INFO - root - 2017-12-16 16:42:45.676931: step 32300, loss = 0.48, batch loss = 0.30 (34.1 examples/sec; 0.235 sec/batch; 19h:34m:57s remains)
INFO - root - 2017-12-16 16:42:48.038792: step 32310, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 18h:26m:08s remains)
INFO - root - 2017-12-16 16:42:50.247897: step 32320, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 18h:30m:20s remains)
INFO - root - 2017-12-16 16:42:52.474325: step 32330, loss = 0.46, batch loss = 0.28 (33.5 examples/sec; 0.239 sec/batch; 19h:53m:38s remains)
INFO - root - 2017-12-16 16:42:54.718243: step 32340, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 18h:32m:46s remains)
INFO - root - 2017-12-16 16:42:56.927905: step 32350, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 18h:07m:16s remains)
INFO - root - 2017-12-16 16:42:59.122347: step 32360, loss = 0.48, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 18h:12m:08s remains)
INFO - root - 2017-12-16 16:43:01.374225: step 32370, loss = 0.59, batch loss = 0.41 (35.6 examples/sec; 0.224 sec/batch; 18h:42m:52s remains)
INFO - root - 2017-12-16 16:43:03.599351: step 32380, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 18h:47m:03s remains)
INFO - root - 2017-12-16 16:43:05.779155: step 32390, loss = 0.48, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 18h:31m:19s remains)
INFO - root - 2017-12-16 16:43:08.007179: step 32400, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 18h:54m:15s remains)
INFO - root - 2017-12-16 16:43:10.356007: step 32410, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 17h:57m:54s remains)
INFO - root - 2017-12-16 16:43:12.563574: step 32420, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 18h:13m:59s remains)
INFO - root - 2017-12-16 16:43:14.793840: step 32430, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 18h:08m:29s remains)
INFO - root - 2017-12-16 16:43:17.027657: step 32440, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 18h:09m:15s remains)
INFO - root - 2017-12-16 16:43:19.250620: step 32450, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 18h:22m:45s remains)
INFO - root - 2017-12-16 16:43:21.436521: step 32460, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 18h:04m:31s remains)
INFO - root - 2017-12-16 16:43:23.667856: step 32470, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 18h:40m:14s remains)
INFO - root - 2017-12-16 16:43:25.904784: step 32480, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 18h:13m:11s remains)
INFO - root - 2017-12-16 16:43:28.133149: step 32490, loss = 0.52, batch loss = 0.34 (37.6 examples/sec; 0.213 sec/batch; 17h:43m:28s remains)
INFO - root - 2017-12-16 16:43:30.352153: step 32500, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 18h:41m:13s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-32500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-32500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 16:43:33.142228: step 32510, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 18h:50m:30s remains)
INFO - root - 2017-12-16 16:43:35.330041: step 32520, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 18h:48m:29s remains)
INFO - root - 2017-12-16 16:43:37.513156: step 32530, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 17h:45m:01s remains)
INFO - root - 2017-12-16 16:43:39.763998: step 32540, loss = 0.47, batch loss = 0.29 (33.3 examples/sec; 0.240 sec/batch; 20h:01m:23s remains)
INFO - root - 2017-12-16 16:43:41.980250: step 32550, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 18h:08m:36s remains)
INFO - root - 2017-12-16 16:43:44.208644: step 32560, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 18h:02m:27s remains)
INFO - root - 2017-12-16 16:43:46.454338: step 32570, loss = 0.47, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 18h:13m:33s remains)
INFO - root - 2017-12-16 16:43:48.687108: step 32580, loss = 0.50, batch loss = 0.32 (34.6 examples/sec; 0.232 sec/batch; 19h:17m:14s remains)
INFO - root - 2017-12-16 16:43:50.896196: step 32590, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 18h:32m:27s remains)
INFO - root - 2017-12-16 16:43:53.097271: step 32600, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 18h:23m:15s remains)
INFO - root - 2017-12-16 16:43:55.511554: step 32610, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.231 sec/batch; 19h:13m:33s remains)
INFO - root - 2017-12-16 16:43:57.794482: step 32620, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 18h:06m:10s remains)
INFO - root - 2017-12-16 16:44:00.013172: step 32630, loss = 0.42, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 18h:40m:47s remains)
INFO - root - 2017-12-16 16:44:02.233285: step 32640, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 18h:18m:29s remains)
INFO - root - 2017-12-16 16:44:04.402686: step 32650, loss = 0.57, batch loss = 0.39 (37.8 examples/sec; 0.212 sec/batch; 17h:37m:21s remains)
INFO - root - 2017-12-16 16:44:06.635685: step 32660, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 18h:18m:03s remains)
INFO - root - 2017-12-16 16:44:08.836680: step 32670, loss = 0.48, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 17h:39m:32s remains)
INFO - root - 2017-12-16 16:44:11.025577: step 32680, loss = 0.46, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 19h:02m:01s remains)
INFO - root - 2017-12-16 16:44:13.260478: step 32690, loss = 0.45, batch loss = 0.27 (34.1 examples/sec; 0.235 sec/batch; 19h:31m:59s remains)
INFO - root - 2017-12-16 16:44:15.448700: step 32700, loss = 0.49, batch loss = 0.31 (37.9 examples/sec; 0.211 sec/batch; 17h:34m:50s remains)
INFO - root - 2017-12-16 16:44:17.757689: step 32710, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 18h:00m:58s remains)
INFO - root - 2017-12-16 16:44:20.002106: step 32720, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 18h:45m:26s remains)
INFO - root - 2017-12-16 16:44:22.207535: step 32730, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 17h:56m:17s remains)
INFO - root - 2017-12-16 16:44:24.441706: step 32740, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 18h:06m:29s remains)
INFO - root - 2017-12-16 16:44:26.671516: step 32750, loss = 0.48, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 18h:21m:04s remains)
INFO - root - 2017-12-16 16:44:28.873486: step 32760, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 18h:38m:15s remains)
INFO - root - 2017-12-16 16:44:31.127880: step 32770, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.233 sec/batch; 19h:22m:29s remains)
INFO - root - 2017-12-16 16:44:33.331726: step 32780, loss = 0.58, batch loss = 0.40 (37.4 examples/sec; 0.214 sec/batch; 17h:47m:21s remains)
INFO - root - 2017-12-16 16:44:35.552795: step 32790, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 18h:53m:05s remains)
INFO - root - 2017-12-16 16:44:37.797549: step 32800, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 18h:23m:48s remains)
INFO - root - 2017-12-16 16:44:40.144455: step 32810, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 18h:13m:56s remains)
INFO - root - 2017-12-16 16:44:42.371787: step 32820, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 18h:04m:05s remains)
INFO - root - 2017-12-16 16:44:44.580993: step 32830, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.221 sec/batch; 18h:21m:50s remains)
INFO - root - 2017-12-16 16:44:46.805774: step 32840, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 18h:02m:01s remains)
INFO - root - 2017-12-16 16:44:49.036811: step 32850, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.229 sec/batch; 19h:03m:01s remains)
INFO - root - 2017-12-16 16:44:51.267317: step 32860, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 18h:52m:46s remains)
INFO - root - 2017-12-16 16:44:53.483517: step 32870, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 18h:49m:46s remains)
INFO - root - 2017-12-16 16:44:55.748129: step 32880, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 18h:31m:31s remains)
INFO - root - 2017-12-16 16:44:57.988348: step 32890, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 18h:35m:18s remains)
INFO - root - 2017-12-16 16:45:00.214695: step 32900, loss = 0.42, batch loss = 0.24 (37.2 examples/sec; 0.215 sec/batch; 17h:52m:56s remains)
INFO - root - 2017-12-16 16:45:02.564193: step 32910, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 18h:21m:56s remains)
INFO - root - 2017-12-16 16:45:04.818976: step 32920, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 19h:06m:24s remains)
INFO - root - 2017-12-16 16:45:07.152515: step 32930, loss = 0.51, batch loss = 0.34 (35.0 examples/sec; 0.229 sec/batch; 19h:02m:16s remains)
INFO - root - 2017-12-16 16:45:09.391765: step 32940, loss = 0.42, batch loss = 0.24 (34.9 examples/sec; 0.229 sec/batch; 19h:03m:53s remains)
INFO - root - 2017-12-16 16:45:11.562566: step 32950, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 17h:57m:20s remains)
INFO - root - 2017-12-16 16:45:13.775189: step 32960, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 17h:58m:47s remains)
INFO - root - 2017-12-16 16:45:15.997223: step 32970, loss = 0.45, batch loss = 0.27 (38.2 examples/sec; 0.209 sec/batch; 17h:25m:20s remains)
INFO - root - 2017-12-16 16:45:18.259854: step 32980, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 18h:06m:14s remains)
INFO - root - 2017-12-16 16:45:20.454394: step 32990, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 17h:42m:16s remains)
INFO - root - 2017-12-16 16:45:22.707307: step 33000, loss = 0.47, batch loss = 0.29 (34.3 examples/sec; 0.233 sec/batch; 19h:25m:15s remains)
INFO - root - 2017-12-16 16:45:25.093197: step 33010, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.221 sec/batch; 18h:25m:31s remains)
INFO - root - 2017-12-16 16:45:27.317750: step 33020, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 18h:35m:03s remains)
INFO - root - 2017-12-16 16:45:29.525965: step 33030, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 18h:01m:41s remains)
INFO - root - 2017-12-16 16:45:31.755082: step 33040, loss = 0.42, batch loss = 0.24 (35.3 examples/sec; 0.227 sec/batch; 18h:50m:38s remains)
INFO - root - 2017-12-16 16:45:33.962826: step 33050, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 17h:49m:20s remains)
INFO - root - 2017-12-16 16:45:36.189355: step 33060, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 18h:35m:36s remains)
INFO - root - 2017-12-16 16:45:38.400853: step 33070, loss = 0.50, batch loss = 0.32 (33.8 examples/sec; 0.236 sec/batch; 19h:39m:41s remains)
INFO - root - 2017-12-16 16:45:40.661009: step 33080, loss = 0.54, batch loss = 0.36 (36.4 examples/sec; 0.220 sec/batch; 18h:17m:19s remains)
INFO - root - 2017-12-16 16:45:42.883584: step 33090, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.219 sec/batch; 18h:15m:14s remains)
INFO - root - 2017-12-16 16:45:45.130426: step 33100, loss = 0.44, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 18h:54m:51s remains)
INFO - root - 2017-12-16 16:45:47.484959: step 33110, loss = 0.46, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 17h:35m:32s remains)
INFO - root - 2017-12-16 16:45:49.686727: step 33120, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 18h:30m:51s remains)
INFO - root - 2017-12-16 16:45:51.942038: step 33130, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 17h:47m:11s remains)
INFO - root - 2017-12-16 16:45:54.182260: step 33140, loss = 0.49, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 18h:30m:20s remains)
INFO - root - 2017-12-16 16:45:56.411197: step 33150, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 18h:17m:10s remains)
INFO - root - 2017-12-16 16:45:58.612393: step 33160, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 18h:22m:05s remains)
INFO - root - 2017-12-16 16:46:00.867882: step 33170, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 18h:57m:29s remains)
INFO - root - 2017-12-16 16:46:03.148464: step 33180, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 18h:38m:19s remains)
INFO - root - 2017-12-16 16:46:05.356519: step 33190, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 18h:44m:23s remains)
INFO - root - 2017-12-16 16:46:07.581455: step 33200, loss = 0.42, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 18h:23m:07s remains)
INFO - root - 2017-12-16 16:46:09.913776: step 33210, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 18h:10m:53s remains)
INFO - root - 2017-12-16 16:46:12.100255: step 33220, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 17h:57m:27s remains)
INFO - root - 2017-12-16 16:46:14.323817: step 33230, loss = 0.54, batch loss = 0.36 (36.1 examples/sec; 0.221 sec/batch; 18h:24m:45s remains)
INFO - root - 2017-12-16 16:46:16.580708: step 33240, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 18h:37m:08s remains)
INFO - root - 2017-12-16 16:46:18.793009: step 33250, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 18h:36m:46s remains)
INFO - root - 2017-12-16 16:46:21.017680: step 33260, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 18h:28m:39s remains)
INFO - root - 2017-12-16 16:46:23.224019: step 33270, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 18h:19m:03s remains)
INFO - root - 2017-12-16 16:46:25.496606: step 33280, loss = 0.51, batch loss = 0.33 (35.1 examples/sec; 0.228 sec/batch; 18h:56m:23s remains)
INFO - root - 2017-12-16 16:46:27.709776: step 33290, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 18h:55m:11s remains)
INFO - root - 2017-12-16 16:46:29.936183: step 33300, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 19h:04m:18s remains)
INFO - root - 2017-12-16 16:46:32.338975: step 33310, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 18h:06m:45s remains)
INFO - root - 2017-12-16 16:46:34.554466: step 33320, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 18h:42m:06s remains)
INFO - root - 2017-12-16 16:46:36.764291: step 33330, loss = 0.44, batch loss = 0.26 (34.6 examples/sec; 0.232 sec/batch; 19h:14m:20s remains)
INFO - root - 2017-12-16 16:46:39.003625: step 33340, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 18h:32m:12s remains)
INFO - root - 2017-12-16 16:46:41.233108: step 33350, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 18h:37m:33s remains)
INFO - root - 2017-12-16 16:46:43.447106: step 33360, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 17h:47m:31s remains)
INFO - root - 2017-12-16 16:46:45.649841: step 33370, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 18h:21m:12s remains)
INFO - root - 2017-12-16 16:46:47.868499: step 33380, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 18h:20m:57s remains)
INFO - root - 2017-12-16 16:46:50.073235: step 33390, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 18h:20m:51s remains)
INFO - root - 2017-12-16 16:46:52.300896: step 33400, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 18h:05m:50s remains)
INFO - root - 2017-12-16 16:46:54.644887: step 33410, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.218 sec/batch; 18h:08m:23s remains)
INFO - root - 2017-12-16 16:46:56.864481: step 33420, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 17h:59m:42s remains)
INFO - root - 2017-12-16 16:46:59.080066: step 33430, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 18h:33m:29s remains)
INFO - root - 2017-12-16 16:47:01.259107: step 33440, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 17h:56m:13s remains)
INFO - root - 2017-12-16 16:47:03.488300: step 33450, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 18h:27m:58s remains)
INFO - root - 2017-12-16 16:47:05.699024: step 33460, loss = 0.55, batch loss = 0.37 (35.7 examples/sec; 0.224 sec/batch; 18h:37m:15s remains)
INFO - root - 2017-12-16 16:47:07.929829: step 33470, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 18h:21m:14s remains)
INFO - root - 2017-12-16 16:47:10.151964: step 33480, loss = 0.53, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 18h:37m:09s remains)
INFO - root - 2017-12-16 16:47:12.374395: step 33490, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 18h:14m:36s remains)
INFO - root - 2017-12-16 16:47:14.602573: step 33500, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 18h:21m:57s remains)
INFO - root - 2017-12-16 16:47:16.919894: step 33510, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 18h:26m:17s remains)
INFO - root - 2017-12-16 16:47:19.136682: step 33520, loss = 0.46, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 18h:14m:10s remains)
INFO - root - 2017-12-16 16:47:21.371208: step 33530, loss = 0.53, batch loss = 0.35 (34.3 examples/sec; 0.233 sec/batch; 19h:22m:00s remains)
INFO - root - 2017-12-16 16:47:23.574046: step 33540, loss = 0.47, batch loss = 0.29 (38.4 examples/sec; 0.208 sec/batch; 17h:17m:39s remains)
INFO - root - 2017-12-16 16:47:25.798351: step 33550, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 18h:11m:50s remains)
INFO - root - 2017-12-16 16:47:28.014414: step 33560, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 18h:48m:26s remains)
INFO - root - 2017-12-16 16:47:30.240147: step 33570, loss = 0.56, batch loss = 0.38 (35.7 examples/sec; 0.224 sec/batch; 18h:36m:54s remains)
INFO - root - 2017-12-16 16:47:32.467316: step 33580, loss = 0.55, batch loss = 0.37 (37.8 examples/sec; 0.212 sec/batch; 17h:34m:35s remains)
INFO - root - 2017-12-16 16:47:34.717351: step 33590, loss = 0.50, batch loss = 0.33 (36.3 examples/sec; 0.221 sec/batch; 18h:19m:11s remains)
INFO - root - 2017-12-16 16:47:36.997100: step 33600, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 18h:58m:34s remains)
INFO - root - 2017-12-16 16:47:39.369895: step 33610, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 18h:17m:19s remains)
INFO - root - 2017-12-16 16:47:41.593753: step 33620, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 17h:56m:29s remains)
INFO - root - 2017-12-16 16:47:43.804702: step 33630, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 18h:35m:41s remains)
INFO - root - 2017-12-16 16:47:46.010460: step 33640, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 18h:49m:41s remains)
INFO - root - 2017-12-16 16:47:48.225360: step 33650, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 18h:34m:14s remains)
INFO - root - 2017-12-16 16:47:50.421074: step 33660, loss = 0.54, batch loss = 0.36 (35.3 examples/sec; 0.227 sec/batch; 18h:49m:27s remains)
INFO - root - 2017-12-16 16:47:52.630556: step 33670, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 18h:51m:14s remains)
INFO - root - 2017-12-16 16:47:54.884846: step 33680, loss = 0.45, batch loss = 0.27 (33.4 examples/sec; 0.239 sec/batch; 19h:51m:38s remains)
INFO - root - 2017-12-16 16:47:57.065873: step 33690, loss = 0.54, batch loss = 0.36 (36.1 examples/sec; 0.222 sec/batch; 18h:25m:02s remains)
INFO - root - 2017-12-16 16:47:59.268366: step 33700, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 18h:26m:44s remains)
INFO - root - 2017-12-16 16:48:01.637167: step 33710, loss = 0.43, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 18h:56m:34s remains)
INFO - root - 2017-12-16 16:48:03.837794: step 33720, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 18h:45m:38s remains)
INFO - root - 2017-12-16 16:48:06.052155: step 33730, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 18h:05m:27s remains)
INFO - root - 2017-12-16 16:48:08.271919: step 33740, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 18h:35m:38s remains)
INFO - root - 2017-12-16 16:48:10.508869: step 33750, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 18h:40m:00s remains)
INFO - root - 2017-12-16 16:48:12.775115: step 33760, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 18h:11m:53s remains)
INFO - root - 2017-12-16 16:48:14.991991: step 33770, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 18h:45m:04s remains)
INFO - root - 2017-12-16 16:48:17.210472: step 33780, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 18h:03m:54s remains)
INFO - root - 2017-12-16 16:48:19.415069: step 33790, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 17h:40m:57s remains)
INFO - root - 2017-12-16 16:48:21.603863: step 33800, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.221 sec/batch; 18h:22m:30s remains)
INFO - root - 2017-12-16 16:48:23.959616: step 33810, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 18h:18m:16s remains)
INFO - root - 2017-12-16 16:48:26.190709: step 33820, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.215 sec/batch; 17h:48m:09s remains)
INFO - root - 2017-12-16 16:48:28.421754: step 33830, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 18h:13m:09s remains)
INFO - root - 2017-12-16 16:48:30.608638: step 33840, loss = 0.43, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 18h:23m:11s remains)
INFO - root - 2017-12-16 16:48:32.836740: step 33850, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 18h:41m:15s remains)
INFO - root - 2017-12-16 16:48:35.020450: step 33860, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 18h:28m:16s remains)
INFO - root - 2017-12-16 16:48:37.229470: step 33870, loss = 0.46, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 18h:44m:15s remains)
INFO - root - 2017-12-16 16:48:39.422979: step 33880, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 18h:09m:49s remains)
INFO - root - 2017-12-16 16:48:41.660479: step 33890, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 18h:03m:17s remains)
INFO - root - 2017-12-16 16:48:43.886832: step 33900, loss = 0.56, batch loss = 0.38 (36.8 examples/sec; 0.218 sec/batch; 18h:03m:11s remains)
INFO - root - 2017-12-16 16:48:46.254359: step 33910, loss = 0.49, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 18h:48m:01s remains)
INFO - root - 2017-12-16 16:48:48.469448: step 33920, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 17h:59m:29s remains)
INFO - root - 2017-12-16 16:48:50.665568: step 33930, loss = 0.48, batch loss = 0.31 (34.4 examples/sec; 0.233 sec/batch; 19h:18m:31s remains)
INFO - root - 2017-12-16 16:48:52.906148: step 33940, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 19h:02m:51s remains)
INFO - root - 2017-12-16 16:48:55.138651: step 33950, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 18h:00m:31s remains)
INFO - root - 2017-12-16 16:48:57.345118: step 33960, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 18h:20m:40s remains)
INFO - root - 2017-12-16 16:48:59.589416: step 33970, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 18h:19m:01s remains)
INFO - root - 2017-12-16 16:49:01.805348: step 33980, loss = 0.44, batch loss = 0.27 (35.3 examples/sec; 0.226 sec/batch; 18h:46m:41s remains)
INFO - root - 2017-12-16 16:49:04.028972: step 33990, loss = 0.47, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 18h:39m:40s remains)
INFO - root - 2017-12-16 16:49:06.221204: step 34000, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 18h:07m:03s remains)
INFO - root - 2017-12-16 16:49:08.560987: step 34010, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 18h:34m:40s remains)
INFO - root - 2017-12-16 16:49:10.769989: step 34020, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 18h:45m:39s remains)
INFO - root - 2017-12-16 16:49:13.011824: step 34030, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 18h:29m:43s remains)
INFO - root - 2017-12-16 16:49:15.230480: step 34040, loss = 0.57, batch loss = 0.39 (36.8 examples/sec; 0.217 sec/batch; 17h:59m:59s remains)
INFO - root - 2017-12-16 16:49:17.470380: step 34050, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 18h:33m:32s remains)
INFO - root - 2017-12-16 16:49:19.703353: step 34060, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 18h:05m:10s remains)
INFO - root - 2017-12-16 16:49:21.921836: step 34070, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 18h:05m:07s remains)
INFO - root - 2017-12-16 16:49:24.145129: step 34080, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.228 sec/batch; 18h:51m:57s remains)
INFO - root - 2017-12-16 16:49:26.395143: step 34090, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.228 sec/batch; 18h:51m:49s remains)
INFO - root - 2017-12-16 16:49:28.613363: step 34100, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 18h:03m:44s remains)
INFO - root - 2017-12-16 16:49:30.959045: step 34110, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 17h:58m:25s remains)
INFO - root - 2017-12-16 16:49:33.182486: step 34120, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 18h:18m:44s remains)
INFO - root - 2017-12-16 16:49:35.406462: step 34130, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 18h:07m:14s remains)
INFO - root - 2017-12-16 16:49:37.612966: step 34140, loss = 0.50, batch loss = 0.32 (35.0 examples/sec; 0.228 sec/batch; 18h:55m:37s remains)
INFO - root - 2017-12-16 16:49:39.850207: step 34150, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 18h:42m:17s remains)
INFO - root - 2017-12-16 16:49:42.059554: step 34160, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 17h:52m:41s remains)
INFO - root - 2017-12-16 16:49:44.285069: step 34170, loss = 0.48, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 18h:49m:09s remains)
INFO - root - 2017-12-16 16:49:46.480362: step 34180, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 18h:27m:39s remains)
INFO - root - 2017-12-16 16:49:48.679091: step 34190, loss = 0.52, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 17h:42m:45s remains)
INFO - root - 2017-12-16 16:49:50.859055: step 34200, loss = 0.42, batch loss = 0.24 (36.0 examples/sec; 0.222 sec/batch; 18h:24m:22s remains)
INFO - root - 2017-12-16 16:49:53.257917: step 34210, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 18h:09m:13s remains)
INFO - root - 2017-12-16 16:49:55.484342: step 34220, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 18h:02m:44s remains)
INFO - root - 2017-12-16 16:49:57.741423: step 34230, loss = 0.45, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 18h:56m:22s remains)
INFO - root - 2017-12-16 16:49:59.967003: step 34240, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 17h:51m:05s remains)
INFO - root - 2017-12-16 16:50:02.185427: step 34250, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 18h:15m:20s remains)
INFO - root - 2017-12-16 16:50:04.431793: step 34260, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 18h:27m:50s remains)
INFO - root - 2017-12-16 16:50:06.659024: step 34270, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 17h:54m:32s remains)
INFO - root - 2017-12-16 16:50:08.884710: step 34280, loss = 0.52, batch loss = 0.34 (37.5 examples/sec; 0.213 sec/batch; 17h:40m:19s remains)
INFO - root - 2017-12-16 16:50:11.148033: step 34290, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 18h:35m:14s remains)
INFO - root - 2017-12-16 16:50:13.370978: step 34300, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.226 sec/batch; 18h:40m:46s remains)
INFO - root - 2017-12-16 16:50:15.670122: step 34310, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 18h:09m:08s remains)
INFO - root - 2017-12-16 16:50:17.902665: step 34320, loss = 0.44, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 18h:09m:09s remains)
INFO - root - 2017-12-16 16:50:20.102232: step 34330, loss = 0.55, batch loss = 0.37 (35.7 examples/sec; 0.224 sec/batch; 18h:32m:22s remains)
INFO - root - 2017-12-16 16:50:22.327248: step 34340, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 18h:18m:37s remains)
INFO - root - 2017-12-16 16:50:24.577836: step 34350, loss = 0.41, batch loss = 0.23 (36.3 examples/sec; 0.221 sec/batch; 18h:16m:27s remains)
INFO - root - 2017-12-16 16:50:26.826268: step 34360, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 18h:08m:47s remains)
INFO - root - 2017-12-16 16:50:29.039125: step 34370, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 18h:12m:56s remains)
INFO - root - 2017-12-16 16:50:31.260511: step 34380, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 18h:38m:04s remains)
INFO - root - 2017-12-16 16:50:33.471863: step 34390, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 18h:02m:35s remains)
INFO - root - 2017-12-16 16:50:35.773503: step 34400, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 18h:47m:31s remains)
INFO - root - 2017-12-16 16:50:38.153972: step 34410, loss = 0.46, batch loss = 0.28 (34.1 examples/sec; 0.235 sec/batch; 19h:26m:06s remains)
INFO - root - 2017-12-16 16:50:40.388676: step 34420, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 18h:19m:24s remains)
INFO - root - 2017-12-16 16:50:42.629272: step 34430, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 18h:59m:02s remains)
INFO - root - 2017-12-16 16:50:44.871847: step 34440, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 18h:07m:10s remains)
INFO - root - 2017-12-16 16:50:47.115699: step 34450, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 17h:57m:02s remains)
INFO - root - 2017-12-16 16:50:49.360022: step 34460, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 18h:19m:04s remains)
INFO - root - 2017-12-16 16:50:51.609588: step 34470, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 18h:41m:11s remains)
INFO - root - 2017-12-16 16:50:53.839929: step 34480, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 18h:59m:53s remains)
INFO - root - 2017-12-16 16:50:56.045312: step 34490, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 18h:17m:53s remains)
INFO - root - 2017-12-16 16:50:58.282218: step 34500, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 17h:58m:01s remains)
INFO - root - 2017-12-16 16:51:00.609994: step 34510, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 17h:57m:11s remains)
INFO - root - 2017-12-16 16:51:02.827173: step 34520, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 18h:39m:50s remains)
INFO - root - 2017-12-16 16:51:05.076384: step 34530, loss = 0.44, batch loss = 0.26 (34.0 examples/sec; 0.235 sec/batch; 19h:28m:20s remains)
INFO - root - 2017-12-16 16:51:07.320552: step 34540, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 17h:59m:19s remains)
INFO - root - 2017-12-16 16:51:09.525434: step 34550, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 17h:53m:14s remains)
INFO - root - 2017-12-16 16:51:11.765164: step 34560, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 18h:28m:54s remains)
INFO - root - 2017-12-16 16:51:13.989384: step 34570, loss = 0.43, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 18h:14m:44s remains)
INFO - root - 2017-12-16 16:51:16.204894: step 34580, loss = 0.42, batch loss = 0.24 (36.0 examples/sec; 0.222 sec/batch; 18h:23m:16s remains)
INFO - root - 2017-12-16 16:51:18.394169: step 34590, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 18h:13m:06s remains)
INFO - root - 2017-12-16 16:51:20.609177: step 34600, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 18h:25m:21s remains)
INFO - root - 2017-12-16 16:51:22.938007: step 34610, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 18h:08m:55s remains)
INFO - root - 2017-12-16 16:51:25.157214: step 34620, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 18h:38m:50s remains)
INFO - root - 2017-12-16 16:51:27.383685: step 34630, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 18h:37m:21s remains)
INFO - root - 2017-12-16 16:51:29.610929: step 34640, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 18h:08m:46s remains)
INFO - root - 2017-12-16 16:51:31.828590: step 34650, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 18h:58m:35s remains)
INFO - root - 2017-12-16 16:51:34.047750: step 34660, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 18h:00m:38s remains)
INFO - root - 2017-12-16 16:51:36.253195: step 34670, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.221 sec/batch; 18h:18m:42s remains)
INFO - root - 2017-12-16 16:51:38.497567: step 34680, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 18h:11m:15s remains)
INFO - root - 2017-12-16 16:51:40.683589: step 34690, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 18h:15m:34s remains)
INFO - root - 2017-12-16 16:51:42.884564: step 34700, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 18h:37m:08s remains)
INFO - root - 2017-12-16 16:51:45.244962: step 34710, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 18h:02m:50s remains)
INFO - root - 2017-12-16 16:51:47.498022: step 34720, loss = 0.48, batch loss = 0.31 (35.0 examples/sec; 0.229 sec/batch; 18h:54m:08s remains)
INFO - root - 2017-12-16 16:51:49.724550: step 34730, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 18h:10m:12s remains)
INFO - root - 2017-12-16 16:51:51.966025: step 34740, loss = 0.45, batch loss = 0.27 (33.5 examples/sec; 0.239 sec/batch; 19h:43m:45s remains)
INFO - root - 2017-12-16 16:51:54.146233: step 34750, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 17h:56m:48s remains)
INFO - root - 2017-12-16 16:51:56.383125: step 34760, loss = 0.50, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 19h:01m:45s remains)
INFO - root - 2017-12-16 16:51:58.631115: step 34770, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 18h:38m:01s remains)
INFO - root - 2017-12-16 16:52:00.857866: step 34780, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 17h:52m:50s remains)
INFO - root - 2017-12-16 16:52:03.101706: step 34790, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 18h:31m:53s remains)
INFO - root - 2017-12-16 16:52:05.324809: step 34800, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 18h:25m:54s remains)
INFO - root - 2017-12-16 16:52:07.708511: step 34810, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 18h:50m:24s remains)
INFO - root - 2017-12-16 16:52:09.942138: step 34820, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 17h:56m:35s remains)
INFO - root - 2017-12-16 16:52:12.137518: step 34830, loss = 0.46, batch loss = 0.28 (37.7 examples/sec; 0.212 sec/batch; 17h:34m:05s remains)
INFO - root - 2017-12-16 16:52:14.328714: step 34840, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 18h:29m:42s remains)
INFO - root - 2017-12-16 16:52:16.544718: step 34850, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 17h:58m:26s remains)
INFO - root - 2017-12-16 16:52:18.754506: step 34860, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 18h:53m:09s remains)
INFO - root - 2017-12-16 16:52:21.040189: step 34870, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 18h:53m:37s remains)
INFO - root - 2017-12-16 16:52:23.276370: step 34880, loss = 0.47, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 18h:21m:29s remains)
INFO - root - 2017-12-16 16:52:25.521472: step 34890, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 18h:38m:08s remains)
INFO - root - 2017-12-16 16:52:27.745163: step 34900, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 17h:54m:09s remains)
INFO - root - 2017-12-16 16:52:30.106782: step 34910, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 18h:24m:08s remains)
INFO - root - 2017-12-16 16:52:32.339808: step 34920, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 18h:25m:29s remains)
INFO - root - 2017-12-16 16:52:34.532115: step 34930, loss = 0.58, batch loss = 0.40 (36.8 examples/sec; 0.218 sec/batch; 17h:58m:50s remains)
INFO - root - 2017-12-16 16:52:36.706460: step 34940, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 18h:03m:05s remains)
INFO - root - 2017-12-16 16:52:38.914886: step 34950, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.223 sec/batch; 18h:23m:33s remains)
INFO - root - 2017-12-16 16:52:41.108270: step 34960, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 18h:11m:11s remains)
INFO - root - 2017-12-16 16:52:43.341709: step 34970, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 18h:11m:52s remains)
INFO - root - 2017-12-16 16:52:45.530657: step 34980, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 17h:37m:13s remains)
INFO - root - 2017-12-16 16:52:47.776000: step 34990, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.230 sec/batch; 19h:01m:58s remains)
INFO - root - 2017-12-16 16:52:50.055718: step 35000, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 19h:08m:41s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-35000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-35000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 16:52:53.067491: step 35010, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 18h:31m:49s remains)
INFO - root - 2017-12-16 16:52:55.350599: step 35020, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 18h:03m:53s remains)
INFO - root - 2017-12-16 16:52:57.586395: step 35030, loss = 0.48, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 18h:00m:31s remains)
INFO - root - 2017-12-16 16:52:59.824233: step 35040, loss = 0.57, batch loss = 0.39 (36.9 examples/sec; 0.217 sec/batch; 17h:55m:03s remains)
INFO - root - 2017-12-16 16:53:02.038137: step 35050, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 17h:51m:56s remains)
INFO - root - 2017-12-16 16:53:04.276970: step 35060, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.226 sec/batch; 18h:41m:55s remains)
INFO - root - 2017-12-16 16:53:06.485787: step 35070, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.230 sec/batch; 19h:01m:56s remains)
INFO - root - 2017-12-16 16:53:08.696419: step 35080, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 18h:37m:57s remains)
INFO - root - 2017-12-16 16:53:10.923201: step 35090, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 17h:39m:17s remains)
INFO - root - 2017-12-16 16:53:13.164919: step 35100, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 18h:03m:25s remains)
INFO - root - 2017-12-16 16:53:15.486913: step 35110, loss = 0.57, batch loss = 0.39 (37.1 examples/sec; 0.216 sec/batch; 17h:49m:01s remains)
INFO - root - 2017-12-16 16:53:17.699118: step 35120, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 18h:33m:15s remains)
INFO - root - 2017-12-16 16:53:19.944879: step 35130, loss = 0.43, batch loss = 0.25 (34.4 examples/sec; 0.233 sec/batch; 19h:14m:01s remains)
INFO - root - 2017-12-16 16:53:22.183785: step 35140, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 19h:09m:21s remains)
INFO - root - 2017-12-16 16:53:24.442283: step 35150, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 18h:57m:44s remains)
INFO - root - 2017-12-16 16:53:26.637086: step 35160, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 17h:57m:34s remains)
INFO - root - 2017-12-16 16:53:28.868279: step 35170, loss = 0.49, batch loss = 0.31 (34.5 examples/sec; 0.232 sec/batch; 19h:09m:31s remains)
INFO - root - 2017-12-16 16:53:31.059863: step 35180, loss = 0.48, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 18h:22m:55s remains)
INFO - root - 2017-12-16 16:53:33.315515: step 35190, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 18h:22m:21s remains)
INFO - root - 2017-12-16 16:53:35.530476: step 35200, loss = 0.43, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 18h:44m:11s remains)
INFO - root - 2017-12-16 16:53:37.887576: step 35210, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 18h:11m:23s remains)
INFO - root - 2017-12-16 16:53:40.084236: step 35220, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 18h:22m:40s remains)
INFO - root - 2017-12-16 16:53:42.281578: step 35230, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 18h:15m:33s remains)
INFO - root - 2017-12-16 16:53:44.506492: step 35240, loss = 0.43, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 18h:31m:45s remains)
INFO - root - 2017-12-16 16:53:46.750138: step 35250, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 18h:49m:58s remains)
INFO - root - 2017-12-16 16:53:48.931695: step 35260, loss = 0.59, batch loss = 0.41 (36.8 examples/sec; 0.217 sec/batch; 17h:56m:48s remains)
INFO - root - 2017-12-16 16:53:51.127557: step 35270, loss = 0.49, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 18h:32m:45s remains)
INFO - root - 2017-12-16 16:53:53.348033: step 35280, loss = 0.59, batch loss = 0.41 (35.4 examples/sec; 0.226 sec/batch; 18h:38m:18s remains)
INFO - root - 2017-12-16 16:53:55.563141: step 35290, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 18h:27m:37s remains)
INFO - root - 2017-12-16 16:53:57.773828: step 35300, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 17h:50m:43s remains)
INFO - root - 2017-12-16 16:54:00.159470: step 35310, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 18h:51m:24s remains)
INFO - root - 2017-12-16 16:54:02.350913: step 35320, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 18h:00m:16s remains)
INFO - root - 2017-12-16 16:54:04.572421: step 35330, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 18h:17m:51s remains)
INFO - root - 2017-12-16 16:54:06.839017: step 35340, loss = 0.50, batch loss = 0.33 (35.1 examples/sec; 0.228 sec/batch; 18h:49m:50s remains)
INFO - root - 2017-12-16 16:54:09.077023: step 35350, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 17h:59m:33s remains)
INFO - root - 2017-12-16 16:54:11.290805: step 35360, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 18h:15m:39s remains)
INFO - root - 2017-12-16 16:54:13.503363: step 35370, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 18h:17m:42s remains)
INFO - root - 2017-12-16 16:54:15.775227: step 35380, loss = 0.44, batch loss = 0.27 (34.8 examples/sec; 0.230 sec/batch; 18h:59m:01s remains)
INFO - root - 2017-12-16 16:54:17.980359: step 35390, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 18h:00m:19s remains)
INFO - root - 2017-12-16 16:54:20.239360: step 35400, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 18h:48m:26s remains)
INFO - root - 2017-12-16 16:54:22.595111: step 35410, loss = 0.52, batch loss = 0.34 (34.8 examples/sec; 0.230 sec/batch; 18h:59m:28s remains)
INFO - root - 2017-12-16 16:54:24.810203: step 35420, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 18h:16m:36s remains)
INFO - root - 2017-12-16 16:54:27.029796: step 35430, loss = 0.43, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 17h:56m:09s remains)
INFO - root - 2017-12-16 16:54:29.281236: step 35440, loss = 0.49, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 18h:44m:13s remains)
INFO - root - 2017-12-16 16:54:31.517443: step 35450, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 18h:08m:22s remains)
INFO - root - 2017-12-16 16:54:33.744879: step 35460, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 18h:26m:46s remains)
INFO - root - 2017-12-16 16:54:35.953844: step 35470, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 18h:10m:45s remains)
INFO - root - 2017-12-16 16:54:38.155822: step 35480, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 18h:48m:57s remains)
INFO - root - 2017-12-16 16:54:40.382256: step 35490, loss = 0.53, batch loss = 0.35 (34.2 examples/sec; 0.234 sec/batch; 19h:19m:24s remains)
INFO - root - 2017-12-16 16:54:42.584609: step 35500, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 18h:19m:21s remains)
INFO - root - 2017-12-16 16:54:44.897060: step 35510, loss = 0.48, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 17h:38m:05s remains)
INFO - root - 2017-12-16 16:54:47.113084: step 35520, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 18h:10m:41s remains)
INFO - root - 2017-12-16 16:54:49.342461: step 35530, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 17h:42m:45s remains)
INFO - root - 2017-12-16 16:54:51.563473: step 35540, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 17h:47m:10s remains)
INFO - root - 2017-12-16 16:54:53.785307: step 35550, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.224 sec/batch; 18h:31m:00s remains)
INFO - root - 2017-12-16 16:54:55.997780: step 35560, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 18h:18m:06s remains)
INFO - root - 2017-12-16 16:54:58.249361: step 35570, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 18h:41m:48s remains)
INFO - root - 2017-12-16 16:55:00.471930: step 35580, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 18h:17m:44s remains)
INFO - root - 2017-12-16 16:55:02.704428: step 35590, loss = 0.45, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 18h:47m:02s remains)
INFO - root - 2017-12-16 16:55:04.947980: step 35600, loss = 0.51, batch loss = 0.34 (35.0 examples/sec; 0.228 sec/batch; 18h:50m:14s remains)
INFO - root - 2017-12-16 16:55:07.309010: step 35610, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 18h:51m:47s remains)
INFO - root - 2017-12-16 16:55:09.521445: step 35620, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 18h:06m:59s remains)
INFO - root - 2017-12-16 16:55:11.730544: step 35630, loss = 0.57, batch loss = 0.39 (36.3 examples/sec; 0.220 sec/batch; 18h:09m:24s remains)
INFO - root - 2017-12-16 16:55:13.963857: step 35640, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 17h:41m:48s remains)
INFO - root - 2017-12-16 16:55:16.162166: step 35650, loss = 0.44, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 18h:37m:31s remains)
INFO - root - 2017-12-16 16:55:18.372193: step 35660, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 18h:04m:08s remains)
INFO - root - 2017-12-16 16:55:20.639185: step 35670, loss = 0.50, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 17h:56m:00s remains)
INFO - root - 2017-12-16 16:55:22.838961: step 35680, loss = 0.60, batch loss = 0.42 (36.1 examples/sec; 0.221 sec/batch; 18h:15m:10s remains)
INFO - root - 2017-12-16 16:55:25.059915: step 35690, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.226 sec/batch; 18h:36m:17s remains)
INFO - root - 2017-12-16 16:55:27.299461: step 35700, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 18h:25m:08s remains)
INFO - root - 2017-12-16 16:55:29.690736: step 35710, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 17h:48m:32s remains)
INFO - root - 2017-12-16 16:55:31.900172: step 35720, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 18h:19m:31s remains)
INFO - root - 2017-12-16 16:55:34.119987: step 35730, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 18h:10m:27s remains)
INFO - root - 2017-12-16 16:55:36.331758: step 35740, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 18h:42m:21s remains)
INFO - root - 2017-12-16 16:55:38.562191: step 35750, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 17h:28m:49s remains)
INFO - root - 2017-12-16 16:55:40.798229: step 35760, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 18h:22m:37s remains)
INFO - root - 2017-12-16 16:55:43.023909: step 35770, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 18h:24m:18s remains)
INFO - root - 2017-12-16 16:55:45.218864: step 35780, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 18h:12m:52s remains)
INFO - root - 2017-12-16 16:55:47.419336: step 35790, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 17h:57m:40s remains)
INFO - root - 2017-12-16 16:55:49.657860: step 35800, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 18h:11m:38s remains)
INFO - root - 2017-12-16 16:55:52.027013: step 35810, loss = 0.46, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 17h:43m:12s remains)
INFO - root - 2017-12-16 16:55:54.258895: step 35820, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 18h:42m:43s remains)
INFO - root - 2017-12-16 16:55:56.449848: step 35830, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 18h:03m:33s remains)
INFO - root - 2017-12-16 16:55:58.676408: step 35840, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 17h:54m:24s remains)
INFO - root - 2017-12-16 16:56:00.898661: step 35850, loss = 0.46, batch loss = 0.28 (34.4 examples/sec; 0.232 sec/batch; 19h:08m:21s remains)
INFO - root - 2017-12-16 16:56:03.118922: step 35860, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 18h:25m:57s remains)
INFO - root - 2017-12-16 16:56:05.342409: step 35870, loss = 0.56, batch loss = 0.38 (36.4 examples/sec; 0.220 sec/batch; 18h:05m:19s remains)
INFO - root - 2017-12-16 16:56:07.554468: step 35880, loss = 0.48, batch loss = 0.30 (33.7 examples/sec; 0.237 sec/batch; 19h:33m:13s remains)
INFO - root - 2017-12-16 16:56:09.792639: step 35890, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 17h:38m:28s remains)
INFO - root - 2017-12-16 16:56:11.964405: step 35900, loss = 0.55, batch loss = 0.37 (36.7 examples/sec; 0.218 sec/batch; 17h:58m:12s remains)
INFO - root - 2017-12-16 16:56:14.324313: step 35910, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 18h:47m:41s remains)
INFO - root - 2017-12-16 16:56:16.534104: step 35920, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 17h:51m:03s remains)
INFO - root - 2017-12-16 16:56:18.719951: step 35930, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 17h:50m:17s remains)
INFO - root - 2017-12-16 16:56:20.922872: step 35940, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 18h:10m:58s remains)
INFO - root - 2017-12-16 16:56:23.140822: step 35950, loss = 0.49, batch loss = 0.31 (33.0 examples/sec; 0.243 sec/batch; 19h:59m:17s remains)
INFO - root - 2017-12-16 16:56:25.412537: step 35960, loss = 0.42, batch loss = 0.25 (35.3 examples/sec; 0.226 sec/batch; 18h:39m:06s remains)
INFO - root - 2017-12-16 16:56:27.562285: step 35970, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 17h:59m:54s remains)
INFO - root - 2017-12-16 16:56:29.745516: step 35980, loss = 0.59, batch loss = 0.41 (35.8 examples/sec; 0.224 sec/batch; 18h:24m:49s remains)
INFO - root - 2017-12-16 16:56:31.963730: step 35990, loss = 0.56, batch loss = 0.38 (36.2 examples/sec; 0.221 sec/batch; 18h:11m:50s remains)
INFO - root - 2017-12-16 16:56:34.168858: step 36000, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 18h:19m:42s remains)
INFO - root - 2017-12-16 16:56:36.524271: step 36010, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 17h:50m:17s remains)
INFO - root - 2017-12-16 16:56:38.785408: step 36020, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 19h:06m:54s remains)
INFO - root - 2017-12-16 16:56:41.010530: step 36030, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 17h:42m:25s remains)
INFO - root - 2017-12-16 16:56:43.219063: step 36040, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 18h:16m:35s remains)
INFO - root - 2017-12-16 16:56:45.436878: step 36050, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 18h:22m:40s remains)
INFO - root - 2017-12-16 16:56:47.708616: step 36060, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 18h:13m:42s remains)
INFO - root - 2017-12-16 16:56:49.930575: step 36070, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 18h:01m:41s remains)
INFO - root - 2017-12-16 16:56:52.163456: step 36080, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 18h:43m:10s remains)
INFO - root - 2017-12-16 16:56:54.374697: step 36090, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 18h:16m:12s remains)
INFO - root - 2017-12-16 16:56:56.580624: step 36100, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 18h:01m:16s remains)
INFO - root - 2017-12-16 16:56:58.896344: step 36110, loss = 0.41, batch loss = 0.23 (36.3 examples/sec; 0.221 sec/batch; 18h:09m:55s remains)
INFO - root - 2017-12-16 16:57:01.109573: step 36120, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 18h:50m:40s remains)
INFO - root - 2017-12-16 16:57:03.287468: step 36130, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 18h:50m:26s remains)
INFO - root - 2017-12-16 16:57:05.468363: step 36140, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 17h:53m:03s remains)
INFO - root - 2017-12-16 16:57:07.701083: step 36150, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.230 sec/batch; 18h:57m:46s remains)
INFO - root - 2017-12-16 16:57:09.902864: step 36160, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.215 sec/batch; 17h:43m:36s remains)
INFO - root - 2017-12-16 16:57:12.069993: step 36170, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 17h:33m:03s remains)
INFO - root - 2017-12-16 16:57:14.254634: step 36180, loss = 0.51, batch loss = 0.33 (37.8 examples/sec; 0.212 sec/batch; 17h:26m:00s remains)
INFO - root - 2017-12-16 16:57:16.435590: step 36190, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 18h:54m:13s remains)
INFO - root - 2017-12-16 16:57:18.648161: step 36200, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.229 sec/batch; 18h:49m:18s remains)
INFO - root - 2017-12-16 16:57:20.984407: step 36210, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 18h:12m:39s remains)
INFO - root - 2017-12-16 16:57:23.174831: step 36220, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 17h:45m:23s remains)
INFO - root - 2017-12-16 16:57:25.374457: step 36230, loss = 0.55, batch loss = 0.38 (35.5 examples/sec; 0.225 sec/batch; 18h:32m:07s remains)
INFO - root - 2017-12-16 16:57:27.591182: step 36240, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 17h:37m:52s remains)
INFO - root - 2017-12-16 16:57:29.827333: step 36250, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 17h:51m:32s remains)
INFO - root - 2017-12-16 16:57:32.035129: step 36260, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 18h:11m:44s remains)
INFO - root - 2017-12-16 16:57:34.201572: step 36270, loss = 0.48, batch loss = 0.31 (37.5 examples/sec; 0.214 sec/batch; 17h:34m:17s remains)
INFO - root - 2017-12-16 16:57:36.413069: step 36280, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 17h:53m:02s remains)
INFO - root - 2017-12-16 16:57:38.638673: step 36290, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 18h:01m:40s remains)
INFO - root - 2017-12-16 16:57:40.833269: step 36300, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 17h:57m:35s remains)
INFO - root - 2017-12-16 16:57:43.171153: step 36310, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 17h:40m:08s remains)
INFO - root - 2017-12-16 16:57:45.369157: step 36320, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 17h:25m:40s remains)
INFO - root - 2017-12-16 16:57:47.575775: step 36330, loss = 0.51, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 18h:14m:00s remains)
INFO - root - 2017-12-16 16:57:49.817042: step 36340, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 18h:25m:22s remains)
INFO - root - 2017-12-16 16:57:52.063114: step 36350, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 18h:29m:42s remains)
INFO - root - 2017-12-16 16:57:54.264009: step 36360, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 18h:24m:07s remains)
INFO - root - 2017-12-16 16:57:56.502483: step 36370, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.221 sec/batch; 18h:08m:22s remains)
INFO - root - 2017-12-16 16:57:58.734138: step 36380, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 17h:42m:13s remains)
INFO - root - 2017-12-16 16:58:00.942099: step 36390, loss = 0.43, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 18h:29m:05s remains)
INFO - root - 2017-12-16 16:58:03.179815: step 36400, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 17h:57m:58s remains)
INFO - root - 2017-12-16 16:58:05.515684: step 36410, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 18h:40m:59s remains)
INFO - root - 2017-12-16 16:58:07.742408: step 36420, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 18h:18m:12s remains)
INFO - root - 2017-12-16 16:58:09.992109: step 36430, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 17h:56m:53s remains)
INFO - root - 2017-12-16 16:58:12.237172: step 36440, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 18h:45m:22s remains)
INFO - root - 2017-12-16 16:58:14.481918: step 36450, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 18h:40m:46s remains)
INFO - root - 2017-12-16 16:58:16.703034: step 36460, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.226 sec/batch; 18h:37m:06s remains)
INFO - root - 2017-12-16 16:58:18.961085: step 36470, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 18h:20m:58s remains)
INFO - root - 2017-12-16 16:58:21.159514: step 36480, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 18h:03m:33s remains)
INFO - root - 2017-12-16 16:58:23.358265: step 36490, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 18h:45m:42s remains)
INFO - root - 2017-12-16 16:58:25.576124: step 36500, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 18h:20m:16s remains)
INFO - root - 2017-12-16 16:58:27.913446: step 36510, loss = 0.52, batch loss = 0.34 (37.6 examples/sec; 0.213 sec/batch; 17h:28m:35s remains)
INFO - root - 2017-12-16 16:58:30.085891: step 36520, loss = 0.46, batch loss = 0.28 (38.3 examples/sec; 0.209 sec/batch; 17h:10m:04s remains)
INFO - root - 2017-12-16 16:58:32.265708: step 36530, loss = 0.53, batch loss = 0.35 (34.3 examples/sec; 0.233 sec/batch; 19h:11m:07s remains)
INFO - root - 2017-12-16 16:58:34.471346: step 36540, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 17h:48m:08s remains)
INFO - root - 2017-12-16 16:58:36.704098: step 36550, loss = 0.54, batch loss = 0.36 (33.1 examples/sec; 0.242 sec/batch; 19h:52m:41s remains)
INFO - root - 2017-12-16 16:58:38.950075: step 36560, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 18h:16m:00s remains)
INFO - root - 2017-12-16 16:58:41.172793: step 36570, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 17h:41m:32s remains)
INFO - root - 2017-12-16 16:58:43.348491: step 36580, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.216 sec/batch; 17h:43m:16s remains)
INFO - root - 2017-12-16 16:58:45.540246: step 36590, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.223 sec/batch; 18h:17m:23s remains)
INFO - root - 2017-12-16 16:58:47.738496: step 36600, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 18h:14m:21s remains)
INFO - root - 2017-12-16 16:58:50.044894: step 36610, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 17h:49m:24s remains)
INFO - root - 2017-12-16 16:58:52.256327: step 36620, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 18h:00m:39s remains)
INFO - root - 2017-12-16 16:58:54.440017: step 36630, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 17h:30m:49s remains)
INFO - root - 2017-12-16 16:58:56.661801: step 36640, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 17h:44m:34s remains)
INFO - root - 2017-12-16 16:58:58.858750: step 36650, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 17h:58m:34s remains)
INFO - root - 2017-12-16 16:59:01.063038: step 36660, loss = 0.53, batch loss = 0.35 (37.5 examples/sec; 0.213 sec/batch; 17h:32m:03s remains)
INFO - root - 2017-12-16 16:59:03.317169: step 36670, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 17h:26m:13s remains)
INFO - root - 2017-12-16 16:59:05.532570: step 36680, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 17h:53m:52s remains)
INFO - root - 2017-12-16 16:59:07.766071: step 36690, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 18h:13m:59s remains)
INFO - root - 2017-12-16 16:59:09.954859: step 36700, loss = 0.51, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 17h:48m:55s remains)
INFO - root - 2017-12-16 16:59:12.282170: step 36710, loss = 0.43, batch loss = 0.25 (38.1 examples/sec; 0.210 sec/batch; 17h:15m:51s remains)
INFO - root - 2017-12-16 16:59:14.511883: step 36720, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.226 sec/batch; 18h:35m:56s remains)
INFO - root - 2017-12-16 16:59:16.765737: step 36730, loss = 0.52, batch loss = 0.34 (34.3 examples/sec; 0.233 sec/batch; 19h:11m:00s remains)
INFO - root - 2017-12-16 16:59:18.947725: step 36740, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 18h:12m:17s remains)
INFO - root - 2017-12-16 16:59:21.152697: step 36750, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 17h:52m:36s remains)
INFO - root - 2017-12-16 16:59:23.407535: step 36760, loss = 0.48, batch loss = 0.30 (34.7 examples/sec; 0.230 sec/batch; 18h:55m:04s remains)
INFO - root - 2017-12-16 16:59:25.616733: step 36770, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 18h:38m:53s remains)
INFO - root - 2017-12-16 16:59:27.828680: step 36780, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 18h:03m:51s remains)
INFO - root - 2017-12-16 16:59:30.034496: step 36790, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 17h:53m:48s remains)
INFO - root - 2017-12-16 16:59:32.218891: step 36800, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 18h:24m:48s remains)
INFO - root - 2017-12-16 16:59:34.620896: step 36810, loss = 0.50, batch loss = 0.32 (34.6 examples/sec; 0.231 sec/batch; 18h:58m:14s remains)
INFO - root - 2017-12-16 16:59:36.818863: step 36820, loss = 0.53, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 18h:27m:01s remains)
INFO - root - 2017-12-16 16:59:39.041293: step 36830, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 18h:17m:54s remains)
INFO - root - 2017-12-16 16:59:41.253039: step 36840, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 17h:37m:46s remains)
INFO - root - 2017-12-16 16:59:43.417740: step 36850, loss = 0.43, batch loss = 0.25 (37.8 examples/sec; 0.212 sec/batch; 17h:22m:15s remains)
INFO - root - 2017-12-16 16:59:45.610234: step 36860, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 17h:47m:07s remains)
INFO - root - 2017-12-16 16:59:47.816600: step 36870, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 17h:58m:47s remains)
INFO - root - 2017-12-16 16:59:50.005748: step 36880, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 18h:13m:53s remains)
INFO - root - 2017-12-16 16:59:52.221702: step 36890, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 18h:05m:25s remains)
INFO - root - 2017-12-16 16:59:54.402946: step 36900, loss = 0.48, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 17h:59m:58s remains)
INFO - root - 2017-12-16 16:59:56.748673: step 36910, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 18h:19m:30s remains)
INFO - root - 2017-12-16 16:59:58.960296: step 36920, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 17h:58m:54s remains)
INFO - root - 2017-12-16 17:00:01.184322: step 36930, loss = 0.42, batch loss = 0.25 (37.1 examples/sec; 0.216 sec/batch; 17h:42m:58s remains)
INFO - root - 2017-12-16 17:00:03.420751: step 36940, loss = 0.53, batch loss = 0.35 (32.1 examples/sec; 0.249 sec/batch; 20h:28m:42s remains)
INFO - root - 2017-12-16 17:00:05.655672: step 36950, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 17h:59m:16s remains)
INFO - root - 2017-12-16 17:00:07.882949: step 36960, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 18h:33m:19s remains)
INFO - root - 2017-12-16 17:00:10.150377: step 36970, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 18h:53m:36s remains)
INFO - root - 2017-12-16 17:00:12.364972: step 36980, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 17h:39m:08s remains)
INFO - root - 2017-12-16 17:00:14.576923: step 36990, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 18h:04m:46s remains)
INFO - root - 2017-12-16 17:00:16.824616: step 37000, loss = 0.45, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 17h:46m:36s remains)
INFO - root - 2017-12-16 17:00:19.157851: step 37010, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 17h:46m:53s remains)
INFO - root - 2017-12-16 17:00:21.337201: step 37020, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 18h:20m:13s remains)
INFO - root - 2017-12-16 17:00:23.582077: step 37030, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 18h:11m:27s remains)
INFO - root - 2017-12-16 17:00:25.775098: step 37040, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 17h:41m:55s remains)
INFO - root - 2017-12-16 17:00:27.958794: step 37050, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 18h:16m:58s remains)
INFO - root - 2017-12-16 17:00:30.190498: step 37060, loss = 0.47, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 17h:59m:48s remains)
INFO - root - 2017-12-16 17:00:32.381690: step 37070, loss = 0.45, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 17h:53m:04s remains)
INFO - root - 2017-12-16 17:00:34.593416: step 37080, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.229 sec/batch; 18h:46m:17s remains)
INFO - root - 2017-12-16 17:00:36.813605: step 37090, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.228 sec/batch; 18h:43m:55s remains)
INFO - root - 2017-12-16 17:00:39.037722: step 37100, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 17h:49m:38s remains)
INFO - root - 2017-12-16 17:00:41.358244: step 37110, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 17h:35m:32s remains)
INFO - root - 2017-12-16 17:00:43.577506: step 37120, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 18h:00m:49s remains)
INFO - root - 2017-12-16 17:00:45.763354: step 37130, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 17h:46m:46s remains)
INFO - root - 2017-12-16 17:00:47.979376: step 37140, loss = 0.59, batch loss = 0.41 (36.2 examples/sec; 0.221 sec/batch; 18h:07m:15s remains)
INFO - root - 2017-12-16 17:00:50.202925: step 37150, loss = 0.60, batch loss = 0.42 (35.8 examples/sec; 0.223 sec/batch; 18h:19m:21s remains)
INFO - root - 2017-12-16 17:00:52.409947: step 37160, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 18h:05m:26s remains)
INFO - root - 2017-12-16 17:00:54.604252: step 37170, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 17h:41m:49s remains)
INFO - root - 2017-12-16 17:00:56.846888: step 37180, loss = 0.48, batch loss = 0.30 (33.4 examples/sec; 0.239 sec/batch; 19h:37m:59s remains)
INFO - root - 2017-12-16 17:00:59.027554: step 37190, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 17h:36m:23s remains)
INFO - root - 2017-12-16 17:01:01.209302: step 37200, loss = 0.44, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 17h:41m:10s remains)
INFO - root - 2017-12-16 17:01:03.561415: step 37210, loss = 0.42, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 18h:17m:34s remains)
INFO - root - 2017-12-16 17:01:05.812581: step 37220, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 18h:30m:50s remains)
INFO - root - 2017-12-16 17:01:08.071420: step 37230, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 17h:40m:44s remains)
INFO - root - 2017-12-16 17:01:10.289427: step 37240, loss = 0.55, batch loss = 0.37 (37.9 examples/sec; 0.211 sec/batch; 17h:17m:49s remains)
INFO - root - 2017-12-16 17:01:12.481047: step 37250, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 17h:48m:15s remains)
INFO - root - 2017-12-16 17:01:14.693390: step 37260, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 17h:50m:11s remains)
INFO - root - 2017-12-16 17:01:16.903315: step 37270, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 18h:05m:46s remains)
INFO - root - 2017-12-16 17:01:19.116882: step 37280, loss = 0.43, batch loss = 0.25 (34.9 examples/sec; 0.229 sec/batch; 18h:48m:15s remains)
INFO - root - 2017-12-16 17:01:21.332414: step 37290, loss = 0.44, batch loss = 0.26 (33.7 examples/sec; 0.238 sec/batch; 19h:28m:52s remains)
INFO - root - 2017-12-16 17:01:23.543335: step 37300, loss = 0.44, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 18h:03m:39s remains)
INFO - root - 2017-12-16 17:01:25.911117: step 37310, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 17h:49m:30s remains)
INFO - root - 2017-12-16 17:01:28.170588: step 37320, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 18h:12m:11s remains)
INFO - root - 2017-12-16 17:01:30.387448: step 37330, loss = 0.57, batch loss = 0.39 (36.0 examples/sec; 0.222 sec/batch; 18h:13m:41s remains)
INFO - root - 2017-12-16 17:01:32.575117: step 37340, loss = 0.45, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 18h:05m:21s remains)
INFO - root - 2017-12-16 17:01:34.792727: step 37350, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 17h:50m:13s remains)
INFO - root - 2017-12-16 17:01:37.027079: step 37360, loss = 0.51, batch loss = 0.33 (34.1 examples/sec; 0.234 sec/batch; 19h:12m:51s remains)
INFO - root - 2017-12-16 17:01:39.267973: step 37370, loss = 0.57, batch loss = 0.39 (34.6 examples/sec; 0.231 sec/batch; 18h:55m:55s remains)
INFO - root - 2017-12-16 17:01:41.487196: step 37380, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 17h:52m:04s remains)
INFO - root - 2017-12-16 17:01:43.713287: step 37390, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 17h:33m:00s remains)
INFO - root - 2017-12-16 17:01:45.920524: step 37400, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 18h:03m:45s remains)
INFO - root - 2017-12-16 17:01:48.262267: step 37410, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 18h:25m:10s remains)
INFO - root - 2017-12-16 17:01:50.468772: step 37420, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 18h:17m:19s remains)
INFO - root - 2017-12-16 17:01:52.724852: step 37430, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 18h:10m:54s remains)
INFO - root - 2017-12-16 17:01:54.963369: step 37440, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 18h:18m:58s remains)
INFO - root - 2017-12-16 17:01:57.171588: step 37450, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 17h:46m:15s remains)
INFO - root - 2017-12-16 17:01:59.369078: step 37460, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 17h:37m:44s remains)
INFO - root - 2017-12-16 17:02:01.576761: step 37470, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.231 sec/batch; 18h:54m:46s remains)
INFO - root - 2017-12-16 17:02:03.771724: step 37480, loss = 0.57, batch loss = 0.39 (36.8 examples/sec; 0.217 sec/batch; 17h:47m:35s remains)
INFO - root - 2017-12-16 17:02:06.012605: step 37490, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.228 sec/batch; 18h:42m:45s remains)
INFO - root - 2017-12-16 17:02:08.194414: step 37500, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 17h:44m:58s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-37500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-37500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 17:02:10.998044: step 37510, loss = 0.48, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 17h:30m:53s remains)
INFO - root - 2017-12-16 17:02:13.183570: step 37520, loss = 0.52, batch loss = 0.34 (37.3 examples/sec; 0.214 sec/batch; 17h:34m:10s remains)
INFO - root - 2017-12-16 17:02:15.393664: step 37530, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 17h:53m:39s remains)
INFO - root - 2017-12-16 17:02:17.595166: step 37540, loss = 0.52, batch loss = 0.34 (37.6 examples/sec; 0.212 sec/batch; 17h:24m:36s remains)
INFO - root - 2017-12-16 17:02:19.797565: step 37550, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 18h:07m:20s remains)
INFO - root - 2017-12-16 17:02:22.003071: step 37560, loss = 0.46, batch loss = 0.29 (34.6 examples/sec; 0.231 sec/batch; 18h:56m:15s remains)
INFO - root - 2017-12-16 17:02:24.220810: step 37570, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 18h:16m:24s remains)
INFO - root - 2017-12-16 17:02:26.455659: step 37580, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 18h:18m:02s remains)
INFO - root - 2017-12-16 17:02:28.679725: step 37590, loss = 0.42, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 18h:21m:19s remains)
INFO - root - 2017-12-16 17:02:30.888203: step 37600, loss = 0.55, batch loss = 0.37 (37.0 examples/sec; 0.216 sec/batch; 17h:43m:57s remains)
INFO - root - 2017-12-16 17:02:33.188212: step 37610, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 17h:52m:42s remains)
INFO - root - 2017-12-16 17:02:35.360708: step 37620, loss = 0.55, batch loss = 0.37 (36.1 examples/sec; 0.222 sec/batch; 18h:09m:18s remains)
INFO - root - 2017-12-16 17:02:37.602190: step 37630, loss = 0.47, batch loss = 0.29 (34.0 examples/sec; 0.235 sec/batch; 19h:15m:20s remains)
INFO - root - 2017-12-16 17:02:39.836145: step 37640, loss = 0.47, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 18h:21m:58s remains)
INFO - root - 2017-12-16 17:02:42.051220: step 37650, loss = 0.54, batch loss = 0.36 (35.1 examples/sec; 0.228 sec/batch; 18h:40m:45s remains)
INFO - root - 2017-12-16 17:02:44.297642: step 37660, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 17h:50m:28s remains)
INFO - root - 2017-12-16 17:02:46.511845: step 37670, loss = 0.49, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 18h:18m:33s remains)
INFO - root - 2017-12-16 17:02:48.701709: step 37680, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 17h:50m:45s remains)
INFO - root - 2017-12-16 17:02:50.925914: step 37690, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 18h:30m:48s remains)
INFO - root - 2017-12-16 17:02:53.118805: step 37700, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 17h:48m:29s remains)
INFO - root - 2017-12-16 17:02:55.456031: step 37710, loss = 0.52, batch loss = 0.35 (36.1 examples/sec; 0.221 sec/batch; 18h:07m:28s remains)
INFO - root - 2017-12-16 17:02:57.661339: step 37720, loss = 0.46, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 18h:26m:01s remains)
INFO - root - 2017-12-16 17:02:59.838277: step 37730, loss = 0.42, batch loss = 0.24 (38.0 examples/sec; 0.210 sec/batch; 17h:13m:14s remains)
INFO - root - 2017-12-16 17:03:02.064959: step 37740, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 17h:30m:44s remains)
INFO - root - 2017-12-16 17:03:04.270422: step 37750, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 18h:27m:17s remains)
INFO - root - 2017-12-16 17:03:06.475515: step 37760, loss = 0.52, batch loss = 0.35 (35.5 examples/sec; 0.225 sec/batch; 18h:25m:42s remains)
INFO - root - 2017-12-16 17:03:08.706757: step 37770, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 17h:50m:33s remains)
INFO - root - 2017-12-16 17:03:10.932929: step 37780, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 18h:32m:10s remains)
INFO - root - 2017-12-16 17:03:13.148544: step 37790, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 17h:55m:57s remains)
INFO - root - 2017-12-16 17:03:15.352088: step 37800, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 18h:00m:22s remains)
INFO - root - 2017-12-16 17:03:17.731541: step 37810, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 18h:18m:10s remains)
INFO - root - 2017-12-16 17:03:19.960597: step 37820, loss = 0.46, batch loss = 0.28 (34.4 examples/sec; 0.232 sec/batch; 19h:01m:15s remains)
INFO - root - 2017-12-16 17:03:22.145831: step 37830, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 17h:44m:42s remains)
INFO - root - 2017-12-16 17:03:24.392880: step 37840, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 18h:16m:32s remains)
INFO - root - 2017-12-16 17:03:26.637660: step 37850, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.218 sec/batch; 17h:52m:31s remains)
INFO - root - 2017-12-16 17:03:28.853326: step 37860, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 17h:43m:37s remains)
INFO - root - 2017-12-16 17:03:31.061792: step 37870, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 17h:59m:31s remains)
INFO - root - 2017-12-16 17:03:33.253348: step 37880, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 17h:33m:26s remains)
INFO - root - 2017-12-16 17:03:35.484783: step 37890, loss = 0.55, batch loss = 0.38 (36.8 examples/sec; 0.217 sec/batch; 17h:46m:49s remains)
INFO - root - 2017-12-16 17:03:37.692070: step 37900, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.218 sec/batch; 17h:48m:04s remains)
INFO - root - 2017-12-16 17:03:40.021744: step 37910, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 17h:46m:00s remains)
INFO - root - 2017-12-16 17:03:42.230151: step 37920, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 17h:33m:02s remains)
INFO - root - 2017-12-16 17:03:44.474278: step 37930, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 17h:25m:10s remains)
INFO - root - 2017-12-16 17:03:46.700714: step 37940, loss = 0.54, batch loss = 0.36 (35.4 examples/sec; 0.226 sec/batch; 18h:30m:34s remains)
INFO - root - 2017-12-16 17:03:48.914128: step 37950, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 18h:37m:27s remains)
INFO - root - 2017-12-16 17:03:51.129199: step 37960, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 18h:16m:06s remains)
INFO - root - 2017-12-16 17:03:53.377899: step 37970, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.223 sec/batch; 18h:15m:28s remains)
INFO - root - 2017-12-16 17:03:55.612226: step 37980, loss = 0.56, batch loss = 0.38 (37.0 examples/sec; 0.216 sec/batch; 17h:42m:15s remains)
INFO - root - 2017-12-16 17:03:57.834310: step 37990, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 17h:50m:13s remains)
INFO - root - 2017-12-16 17:04:00.058208: step 38000, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.233 sec/batch; 19h:01m:13s remains)
INFO - root - 2017-12-16 17:04:02.396951: step 38010, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 17h:43m:55s remains)
INFO - root - 2017-12-16 17:04:04.611381: step 38020, loss = 0.46, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 17h:56m:00s remains)
INFO - root - 2017-12-16 17:04:06.823127: step 38030, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 17h:42m:08s remains)
INFO - root - 2017-12-16 17:04:09.051038: step 38040, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 18h:14m:49s remains)
INFO - root - 2017-12-16 17:04:11.299591: step 38050, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 18h:12m:20s remains)
INFO - root - 2017-12-16 17:04:13.492030: step 38060, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 18h:03m:07s remains)
INFO - root - 2017-12-16 17:04:15.709370: step 38070, loss = 0.47, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 17h:53m:04s remains)
INFO - root - 2017-12-16 17:04:17.914117: step 38080, loss = 0.44, batch loss = 0.26 (35.0 examples/sec; 0.228 sec/batch; 18h:40m:46s remains)
INFO - root - 2017-12-16 17:04:20.086055: step 38090, loss = 0.51, batch loss = 0.33 (37.5 examples/sec; 0.214 sec/batch; 17h:28m:09s remains)
INFO - root - 2017-12-16 17:04:22.288692: step 38100, loss = 0.52, batch loss = 0.35 (36.6 examples/sec; 0.218 sec/batch; 17h:51m:49s remains)
INFO - root - 2017-12-16 17:04:24.631167: step 38110, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 18h:26m:24s remains)
INFO - root - 2017-12-16 17:04:26.851462: step 38120, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 18h:09m:55s remains)
INFO - root - 2017-12-16 17:04:29.124721: step 38130, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 18h:44m:20s remains)
INFO - root - 2017-12-16 17:04:31.365835: step 38140, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 18h:01m:56s remains)
INFO - root - 2017-12-16 17:04:33.593137: step 38150, loss = 0.42, batch loss = 0.24 (37.1 examples/sec; 0.216 sec/batch; 17h:38m:03s remains)
INFO - root - 2017-12-16 17:04:35.769824: step 38160, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 17h:40m:35s remains)
INFO - root - 2017-12-16 17:04:37.986162: step 38170, loss = 0.59, batch loss = 0.41 (36.4 examples/sec; 0.220 sec/batch; 17h:59m:16s remains)
INFO - root - 2017-12-16 17:04:40.213725: step 38180, loss = 0.50, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 17h:56m:01s remains)
INFO - root - 2017-12-16 17:04:42.444033: step 38190, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 17h:42m:59s remains)
INFO - root - 2017-12-16 17:04:44.652797: step 38200, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 17h:54m:07s remains)
INFO - root - 2017-12-16 17:04:47.015730: step 38210, loss = 0.57, batch loss = 0.39 (37.1 examples/sec; 0.216 sec/batch; 17h:37m:50s remains)
INFO - root - 2017-12-16 17:04:49.278374: step 38220, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.219 sec/batch; 17h:52m:11s remains)
INFO - root - 2017-12-16 17:04:51.481572: step 38230, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 18h:34m:55s remains)
INFO - root - 2017-12-16 17:04:53.708054: step 38240, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.233 sec/batch; 19h:01m:01s remains)
INFO - root - 2017-12-16 17:04:55.938061: step 38250, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 18h:02m:01s remains)
INFO - root - 2017-12-16 17:04:58.171865: step 38260, loss = 0.48, batch loss = 0.30 (32.2 examples/sec; 0.248 sec/batch; 20h:16m:40s remains)
INFO - root - 2017-12-16 17:05:00.394362: step 38270, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 17h:47m:26s remains)
INFO - root - 2017-12-16 17:05:02.607228: step 38280, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 18h:10m:41s remains)
INFO - root - 2017-12-16 17:05:04.812469: step 38290, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 17h:52m:24s remains)
INFO - root - 2017-12-16 17:05:07.049221: step 38300, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 17h:58m:54s remains)
INFO - root - 2017-12-16 17:05:09.400098: step 38310, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 18h:15m:54s remains)
INFO - root - 2017-12-16 17:05:11.576907: step 38320, loss = 0.44, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 18h:03m:04s remains)
INFO - root - 2017-12-16 17:05:13.794742: step 38330, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 18h:28m:28s remains)
INFO - root - 2017-12-16 17:05:16.019647: step 38340, loss = 0.50, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 18h:09m:31s remains)
INFO - root - 2017-12-16 17:05:18.247685: step 38350, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 18h:16m:27s remains)
INFO - root - 2017-12-16 17:05:20.500139: step 38360, loss = 0.51, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 18h:30m:32s remains)
INFO - root - 2017-12-16 17:05:22.717473: step 38370, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.226 sec/batch; 18h:29m:56s remains)
INFO - root - 2017-12-16 17:05:24.942682: step 38380, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 18h:04m:11s remains)
INFO - root - 2017-12-16 17:05:27.136109: step 38390, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 18h:11m:55s remains)
INFO - root - 2017-12-16 17:05:29.351330: step 38400, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 17h:58m:08s remains)
INFO - root - 2017-12-16 17:05:31.749071: step 38410, loss = 0.42, batch loss = 0.24 (35.5 examples/sec; 0.225 sec/batch; 18h:24m:05s remains)
INFO - root - 2017-12-16 17:05:33.992622: step 38420, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 18h:35m:59s remains)
INFO - root - 2017-12-16 17:05:36.225386: step 38430, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 18h:04m:00s remains)
INFO - root - 2017-12-16 17:05:38.438653: step 38440, loss = 0.52, batch loss = 0.34 (37.3 examples/sec; 0.214 sec/batch; 17h:30m:07s remains)
INFO - root - 2017-12-16 17:05:40.659673: step 38450, loss = 0.47, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 17h:19m:15s remains)
INFO - root - 2017-12-16 17:05:42.869890: step 38460, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 17h:54m:35s remains)
INFO - root - 2017-12-16 17:05:45.085251: step 38470, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 18h:13m:29s remains)
INFO - root - 2017-12-16 17:05:47.263473: step 38480, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 17h:38m:45s remains)
INFO - root - 2017-12-16 17:05:49.478034: step 38490, loss = 0.54, batch loss = 0.36 (36.8 examples/sec; 0.217 sec/batch; 17h:45m:17s remains)
INFO - root - 2017-12-16 17:05:51.730399: step 38500, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 18h:28m:19s remains)
INFO - root - 2017-12-16 17:05:54.079983: step 38510, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 18h:12m:28s remains)
INFO - root - 2017-12-16 17:05:56.266437: step 38520, loss = 0.45, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 17h:37m:53s remains)
INFO - root - 2017-12-16 17:05:58.457387: step 38530, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 17h:36m:19s remains)
INFO - root - 2017-12-16 17:06:00.651135: step 38540, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 17h:40m:47s remains)
INFO - root - 2017-12-16 17:06:02.875899: step 38550, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.228 sec/batch; 18h:34m:35s remains)
INFO - root - 2017-12-16 17:06:05.087583: step 38560, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 18h:17m:10s remains)
INFO - root - 2017-12-16 17:06:07.283217: step 38570, loss = 0.54, batch loss = 0.36 (34.2 examples/sec; 0.234 sec/batch; 19h:04m:37s remains)
INFO - root - 2017-12-16 17:06:09.518791: step 38580, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 17h:26m:35s remains)
INFO - root - 2017-12-16 17:06:11.730165: step 38590, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 17h:58m:43s remains)
INFO - root - 2017-12-16 17:06:13.942528: step 38600, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 17h:32m:50s remains)
INFO - root - 2017-12-16 17:06:16.287416: step 38610, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 17h:23m:33s remains)
INFO - root - 2017-12-16 17:06:18.491292: step 38620, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 18h:36m:45s remains)
INFO - root - 2017-12-16 17:06:20.784849: step 38630, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.229 sec/batch; 18h:39m:13s remains)
INFO - root - 2017-12-16 17:06:23.012738: step 38640, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 18h:07m:56s remains)
INFO - root - 2017-12-16 17:06:25.239042: step 38650, loss = 0.51, batch loss = 0.33 (37.7 examples/sec; 0.212 sec/batch; 17h:18m:52s remains)
INFO - root - 2017-12-16 17:06:27.435499: step 38660, loss = 0.45, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 17h:58m:21s remains)
INFO - root - 2017-12-16 17:06:29.660974: step 38670, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 17h:58m:45s remains)
INFO - root - 2017-12-16 17:06:31.862102: step 38680, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 17h:49m:17s remains)
INFO - root - 2017-12-16 17:06:34.090375: step 38690, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 18h:08m:51s remains)
INFO - root - 2017-12-16 17:06:36.297526: step 38700, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 17h:22m:42s remains)
INFO - root - 2017-12-16 17:06:38.652996: step 38710, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 17h:44m:38s remains)
INFO - root - 2017-12-16 17:06:40.857271: step 38720, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 18h:33m:11s remains)
INFO - root - 2017-12-16 17:06:43.039479: step 38730, loss = 0.42, batch loss = 0.24 (37.8 examples/sec; 0.212 sec/batch; 17h:15m:53s remains)
INFO - root - 2017-12-16 17:06:45.234153: step 38740, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 17h:58m:56s remains)
INFO - root - 2017-12-16 17:06:47.457477: step 38750, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 18h:26m:42s remains)
INFO - root - 2017-12-16 17:06:49.710565: step 38760, loss = 0.50, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 18h:40m:48s remains)
INFO - root - 2017-12-16 17:06:51.925578: step 38770, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 17h:54m:18s remains)
INFO - root - 2017-12-16 17:06:54.174310: step 38780, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 17h:56m:28s remains)
INFO - root - 2017-12-16 17:06:56.377278: step 38790, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 18h:23m:28s remains)
INFO - root - 2017-12-16 17:06:58.598664: step 38800, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 17h:46m:55s remains)
INFO - root - 2017-12-16 17:07:00.980037: step 38810, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 18h:04m:27s remains)
INFO - root - 2017-12-16 17:07:03.171548: step 38820, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 18h:32m:17s remains)
INFO - root - 2017-12-16 17:07:05.407965: step 38830, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 17h:33m:13s remains)
INFO - root - 2017-12-16 17:07:07.628967: step 38840, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 17h:39m:10s remains)
INFO - root - 2017-12-16 17:07:09.862327: step 38850, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 18h:11m:20s remains)
INFO - root - 2017-12-16 17:07:12.115027: step 38860, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 18h:20m:53s remains)
INFO - root - 2017-12-16 17:07:14.334304: step 38870, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 17h:44m:20s remains)
INFO - root - 2017-12-16 17:07:16.544301: step 38880, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 17h:59m:19s remains)
INFO - root - 2017-12-16 17:07:18.742809: step 38890, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 17h:37m:52s remains)
INFO - root - 2017-12-16 17:07:20.948553: step 38900, loss = 0.42, batch loss = 0.24 (35.0 examples/sec; 0.228 sec/batch; 18h:37m:15s remains)
INFO - root - 2017-12-16 17:07:23.312540: step 38910, loss = 0.43, batch loss = 0.25 (34.5 examples/sec; 0.232 sec/batch; 18h:55m:52s remains)
INFO - root - 2017-12-16 17:07:25.581185: step 38920, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 17h:56m:26s remains)
INFO - root - 2017-12-16 17:07:27.794944: step 38930, loss = 0.53, batch loss = 0.35 (35.2 examples/sec; 0.227 sec/batch; 18h:31m:16s remains)
INFO - root - 2017-12-16 17:07:30.003002: step 38940, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 17h:52m:05s remains)
INFO - root - 2017-12-16 17:07:32.222704: step 38950, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 18h:09m:42s remains)
INFO - root - 2017-12-16 17:07:34.513514: step 38960, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 18h:26m:42s remains)
INFO - root - 2017-12-16 17:07:36.744910: step 38970, loss = 0.49, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 17h:35m:26s remains)
INFO - root - 2017-12-16 17:07:38.982000: step 38980, loss = 0.59, batch loss = 0.41 (36.3 examples/sec; 0.221 sec/batch; 17h:58m:50s remains)
INFO - root - 2017-12-16 17:07:41.165737: step 38990, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 17h:43m:12s remains)
INFO - root - 2017-12-16 17:07:43.418450: step 39000, loss = 0.55, batch loss = 0.37 (35.0 examples/sec; 0.228 sec/batch; 18h:37m:13s remains)
INFO - root - 2017-12-16 17:07:45.755713: step 39010, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 18h:30m:02s remains)
INFO - root - 2017-12-16 17:07:48.015297: step 39020, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 18h:12m:08s remains)
INFO - root - 2017-12-16 17:07:50.215135: step 39030, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 17h:30m:47s remains)
INFO - root - 2017-12-16 17:07:52.454764: step 39040, loss = 0.53, batch loss = 0.35 (35.3 examples/sec; 0.227 sec/batch; 18h:29m:07s remains)
INFO - root - 2017-12-16 17:07:54.651371: step 39050, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 18h:12m:00s remains)
INFO - root - 2017-12-16 17:07:56.825157: step 39060, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 17h:50m:03s remains)
INFO - root - 2017-12-16 17:07:59.020872: step 39070, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 17h:21m:17s remains)
INFO - root - 2017-12-16 17:08:01.224494: step 39080, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 18h:14m:52s remains)
INFO - root - 2017-12-16 17:08:03.469404: step 39090, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 18h:05m:45s remains)
INFO - root - 2017-12-16 17:08:05.662412: step 39100, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.226 sec/batch; 18h:23m:11s remains)
INFO - root - 2017-12-16 17:08:07.987387: step 39110, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 17h:27m:14s remains)
INFO - root - 2017-12-16 17:08:10.207279: step 39120, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 18h:01m:45s remains)
INFO - root - 2017-12-16 17:08:12.451138: step 39130, loss = 0.52, batch loss = 0.35 (37.1 examples/sec; 0.215 sec/batch; 17h:33m:09s remains)
INFO - root - 2017-12-16 17:08:14.701074: step 39140, loss = 0.44, batch loss = 0.27 (35.2 examples/sec; 0.228 sec/batch; 18h:32m:37s remains)
INFO - root - 2017-12-16 17:08:16.951039: step 39150, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 18h:11m:39s remains)
INFO - root - 2017-12-16 17:08:19.159227: step 39160, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 17h:34m:28s remains)
INFO - root - 2017-12-16 17:08:21.386695: step 39170, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 17h:52m:01s remains)
INFO - root - 2017-12-16 17:08:23.613748: step 39180, loss = 0.47, batch loss = 0.29 (34.3 examples/sec; 0.233 sec/batch; 19h:00m:30s remains)
INFO - root - 2017-12-16 17:08:25.873422: step 39190, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 18h:22m:14s remains)
INFO - root - 2017-12-16 17:08:28.039859: step 39200, loss = 0.51, batch loss = 0.33 (38.0 examples/sec; 0.210 sec/batch; 17h:08m:19s remains)
INFO - root - 2017-12-16 17:08:30.398140: step 39210, loss = 0.53, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 17h:52m:09s remains)
INFO - root - 2017-12-16 17:08:32.610479: step 39220, loss = 0.50, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 18h:21m:08s remains)
INFO - root - 2017-12-16 17:08:34.821838: step 39230, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 17h:43m:03s remains)
INFO - root - 2017-12-16 17:08:37.036853: step 39240, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 18h:12m:25s remains)
INFO - root - 2017-12-16 17:08:39.262318: step 39250, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 18h:15m:23s remains)
INFO - root - 2017-12-16 17:08:41.479456: step 39260, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 17h:28m:29s remains)
INFO - root - 2017-12-16 17:08:43.732310: step 39270, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 18h:19m:30s remains)
INFO - root - 2017-12-16 17:08:45.949473: step 39280, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 18h:00m:55s remains)
INFO - root - 2017-12-16 17:08:48.152254: step 39290, loss = 0.60, batch loss = 0.42 (37.2 examples/sec; 0.215 sec/batch; 17h:29m:51s remains)
INFO - root - 2017-12-16 17:08:50.385831: step 39300, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.233 sec/batch; 18h:56m:20s remains)
INFO - root - 2017-12-16 17:08:52.710014: step 39310, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 18h:50m:54s remains)
INFO - root - 2017-12-16 17:08:54.921369: step 39320, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 18h:06m:42s remains)
INFO - root - 2017-12-16 17:08:57.160328: step 39330, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 18h:09m:27s remains)
INFO - root - 2017-12-16 17:08:59.384083: step 39340, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 17h:43m:56s remains)
INFO - root - 2017-12-16 17:09:01.585682: step 39350, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 17h:40m:08s remains)
INFO - root - 2017-12-16 17:09:03.776815: step 39360, loss = 0.49, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 17h:17m:10s remains)
INFO - root - 2017-12-16 17:09:05.996664: step 39370, loss = 0.42, batch loss = 0.24 (36.0 examples/sec; 0.222 sec/batch; 18h:05m:59s remains)
INFO - root - 2017-12-16 17:09:08.207291: step 39380, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 17h:47m:28s remains)
INFO - root - 2017-12-16 17:09:10.405590: step 39390, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 18h:38m:35s remains)
INFO - root - 2017-12-16 17:09:12.669948: step 39400, loss = 0.53, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 18h:17m:15s remains)
INFO - root - 2017-12-16 17:09:14.990591: step 39410, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 17h:29m:38s remains)
INFO - root - 2017-12-16 17:09:17.257322: step 39420, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 17h:58m:37s remains)
INFO - root - 2017-12-16 17:09:19.465886: step 39430, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 18h:14m:31s remains)
INFO - root - 2017-12-16 17:09:21.668331: step 39440, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 18h:13m:16s remains)
INFO - root - 2017-12-16 17:09:23.924923: step 39450, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 18h:12m:25s remains)
INFO - root - 2017-12-16 17:09:26.143307: step 39460, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 18h:15m:10s remains)
INFO - root - 2017-12-16 17:09:28.313406: step 39470, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 17h:57m:27s remains)
INFO - root - 2017-12-16 17:09:30.517589: step 39480, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 18h:26m:23s remains)
INFO - root - 2017-12-16 17:09:32.756461: step 39490, loss = 0.59, batch loss = 0.41 (36.5 examples/sec; 0.219 sec/batch; 17h:49m:46s remains)
INFO - root - 2017-12-16 17:09:34.958287: step 39500, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 18h:33m:02s remains)
INFO - root - 2017-12-16 17:09:37.296588: step 39510, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 18h:03m:12s remains)
INFO - root - 2017-12-16 17:09:39.502790: step 39520, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 17h:39m:27s remains)
INFO - root - 2017-12-16 17:09:41.711312: step 39530, loss = 0.51, batch loss = 0.33 (35.2 examples/sec; 0.227 sec/batch; 18h:28m:16s remains)
INFO - root - 2017-12-16 17:09:43.949582: step 39540, loss = 0.45, batch loss = 0.27 (34.0 examples/sec; 0.235 sec/batch; 19h:07m:42s remains)
INFO - root - 2017-12-16 17:09:46.159872: step 39550, loss = 0.45, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 18h:08m:56s remains)
INFO - root - 2017-12-16 17:09:48.367899: step 39560, loss = 0.44, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 17h:16m:17s remains)
INFO - root - 2017-12-16 17:09:50.549149: step 39570, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 17h:52m:24s remains)
INFO - root - 2017-12-16 17:09:52.770037: step 39580, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 18h:39m:21s remains)
INFO - root - 2017-12-16 17:09:54.987685: step 39590, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 18h:50m:40s remains)
INFO - root - 2017-12-16 17:09:57.207019: step 39600, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 17h:52m:19s remains)
INFO - root - 2017-12-16 17:09:59.569958: step 39610, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 18h:27m:47s remains)
INFO - root - 2017-12-16 17:10:01.738517: step 39620, loss = 0.56, batch loss = 0.38 (38.0 examples/sec; 0.211 sec/batch; 17h:07m:42s remains)
INFO - root - 2017-12-16 17:10:03.982189: step 39630, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 18h:18m:03s remains)
INFO - root - 2017-12-16 17:10:06.222543: step 39640, loss = 0.50, batch loss = 0.32 (34.7 examples/sec; 0.231 sec/batch; 18h:45m:30s remains)
INFO - root - 2017-12-16 17:10:08.429751: step 39650, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 18h:10m:17s remains)
INFO - root - 2017-12-16 17:10:10.626380: step 39660, loss = 0.56, batch loss = 0.38 (37.9 examples/sec; 0.211 sec/batch; 17h:09m:51s remains)
INFO - root - 2017-12-16 17:10:12.824008: step 39670, loss = 0.47, batch loss = 0.30 (34.2 examples/sec; 0.234 sec/batch; 19h:01m:34s remains)
INFO - root - 2017-12-16 17:10:15.042664: step 39680, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 18h:15m:03s remains)
INFO - root - 2017-12-16 17:10:17.299978: step 39690, loss = 0.52, batch loss = 0.34 (34.2 examples/sec; 0.234 sec/batch; 19h:01m:31s remains)
INFO - root - 2017-12-16 17:10:19.546505: step 39700, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 17h:18m:05s remains)
INFO - root - 2017-12-16 17:10:21.929119: step 39710, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 17h:23m:08s remains)
INFO - root - 2017-12-16 17:10:24.141735: step 39720, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 17h:47m:44s remains)
INFO - root - 2017-12-16 17:10:26.401978: step 39730, loss = 0.52, batch loss = 0.35 (34.6 examples/sec; 0.231 sec/batch; 18h:47m:10s remains)
INFO - root - 2017-12-16 17:10:28.592426: step 39740, loss = 0.56, batch loss = 0.38 (35.5 examples/sec; 0.226 sec/batch; 18h:20m:56s remains)
INFO - root - 2017-12-16 17:10:30.802958: step 39750, loss = 0.56, batch loss = 0.38 (34.8 examples/sec; 0.230 sec/batch; 18h:40m:50s remains)
INFO - root - 2017-12-16 17:10:33.034571: step 39760, loss = 0.46, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 17h:48m:28s remains)
INFO - root - 2017-12-16 17:10:35.249706: step 39770, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 18h:06m:09s remains)
INFO - root - 2017-12-16 17:10:37.467695: step 39780, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 17h:20m:11s remains)
INFO - root - 2017-12-16 17:10:39.696442: step 39790, loss = 0.46, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 17h:33m:50s remains)
INFO - root - 2017-12-16 17:10:41.944109: step 39800, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 18h:09m:03s remains)
INFO - root - 2017-12-16 17:10:44.306986: step 39810, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 18h:14m:21s remains)
INFO - root - 2017-12-16 17:10:46.544014: step 39820, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 17h:54m:50s remains)
INFO - root - 2017-12-16 17:10:48.786634: step 39830, loss = 0.53, batch loss = 0.35 (34.2 examples/sec; 0.234 sec/batch; 19h:02m:01s remains)
INFO - root - 2017-12-16 17:10:50.999024: step 39840, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 17h:38m:40s remains)
INFO - root - 2017-12-16 17:10:53.238408: step 39850, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 18h:40m:13s remains)
INFO - root - 2017-12-16 17:10:55.455468: step 39860, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 17h:47m:50s remains)
INFO - root - 2017-12-16 17:10:57.661409: step 39870, loss = 0.51, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 17h:57m:19s remains)
INFO - root - 2017-12-16 17:10:59.838189: step 39880, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 18h:06m:09s remains)
INFO - root - 2017-12-16 17:11:02.051971: step 39890, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 18h:36m:35s remains)
INFO - root - 2017-12-16 17:11:04.260517: step 39900, loss = 0.60, batch loss = 0.43 (36.1 examples/sec; 0.221 sec/batch; 17h:59m:24s remains)
INFO - root - 2017-12-16 17:11:06.615139: step 39910, loss = 0.55, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 17h:54m:51s remains)
INFO - root - 2017-12-16 17:11:08.856533: step 39920, loss = 0.48, batch loss = 0.30 (33.2 examples/sec; 0.241 sec/batch; 19h:33m:36s remains)
INFO - root - 2017-12-16 17:11:11.104698: step 39930, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 17h:48m:00s remains)
INFO - root - 2017-12-16 17:11:13.324109: step 39940, loss = 0.54, batch loss = 0.36 (37.6 examples/sec; 0.213 sec/batch; 17h:16m:29s remains)
INFO - root - 2017-12-16 17:11:15.595388: step 39950, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 18h:22m:47s remains)
INFO - root - 2017-12-16 17:11:17.807403: step 39960, loss = 0.44, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 17h:37m:45s remains)
INFO - root - 2017-12-16 17:11:20.029866: step 39970, loss = 0.47, batch loss = 0.29 (34.4 examples/sec; 0.233 sec/batch; 18h:53m:36s remains)
INFO - root - 2017-12-16 17:11:22.247103: step 39980, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 18h:02m:51s remains)
INFO - root - 2017-12-16 17:11:24.454687: step 39990, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 17h:39m:43s remains)
INFO - root - 2017-12-16 17:11:26.700250: step 40000, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 18h:15m:29s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-40000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-40000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 17:11:29.784377: step 40010, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 17h:59m:35s remains)
INFO - root - 2017-12-16 17:11:31.996685: step 40020, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 17h:42m:17s remains)
INFO - root - 2017-12-16 17:11:34.219250: step 40030, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 17h:25m:24s remains)
INFO - root - 2017-12-16 17:11:36.413540: step 40040, loss = 0.41, batch loss = 0.24 (35.8 examples/sec; 0.223 sec/batch; 18h:09m:06s remains)
INFO - root - 2017-12-16 17:11:38.599618: step 40050, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 18h:20m:46s remains)
INFO - root - 2017-12-16 17:11:40.816151: step 40060, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 18h:25m:15s remains)
INFO - root - 2017-12-16 17:11:43.027035: step 40070, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 17h:26m:18s remains)
INFO - root - 2017-12-16 17:11:45.272748: step 40080, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 17h:41m:44s remains)
INFO - root - 2017-12-16 17:11:47.506370: step 40090, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 17h:24m:26s remains)
INFO - root - 2017-12-16 17:11:49.699755: step 40100, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 18h:28m:19s remains)
INFO - root - 2017-12-16 17:11:52.069031: step 40110, loss = 0.51, batch loss = 0.33 (34.3 examples/sec; 0.233 sec/batch; 18h:56m:36s remains)
INFO - root - 2017-12-16 17:11:54.310354: step 40120, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 18h:03m:12s remains)
INFO - root - 2017-12-16 17:11:56.561335: step 40130, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 17h:44m:41s remains)
INFO - root - 2017-12-16 17:11:58.755090: step 40140, loss = 0.60, batch loss = 0.42 (37.5 examples/sec; 0.213 sec/batch; 17h:18m:36s remains)
INFO - root - 2017-12-16 17:12:00.970358: step 40150, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 17h:47m:07s remains)
INFO - root - 2017-12-16 17:12:03.180212: step 40160, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.224 sec/batch; 18h:13m:24s remains)
INFO - root - 2017-12-16 17:12:05.382738: step 40170, loss = 0.41, batch loss = 0.23 (35.9 examples/sec; 0.223 sec/batch; 18h:06m:15s remains)
INFO - root - 2017-12-16 17:12:07.631439: step 40180, loss = 0.55, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 17h:53m:06s remains)
INFO - root - 2017-12-16 17:12:09.874625: step 40190, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 17h:53m:12s remains)
INFO - root - 2017-12-16 17:12:12.085391: step 40200, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 17h:35m:33s remains)
INFO - root - 2017-12-16 17:12:14.397638: step 40210, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 18h:05m:56s remains)
INFO - root - 2017-12-16 17:12:16.625360: step 40220, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 17h:46m:17s remains)
INFO - root - 2017-12-16 17:12:18.834146: step 40230, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 18h:15m:11s remains)
INFO - root - 2017-12-16 17:12:21.043215: step 40240, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 18h:14m:07s remains)
INFO - root - 2017-12-16 17:12:23.257803: step 40250, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 18h:12m:40s remains)
INFO - root - 2017-12-16 17:12:25.437889: step 40260, loss = 0.55, batch loss = 0.37 (35.0 examples/sec; 0.228 sec/batch; 18h:32m:27s remains)
INFO - root - 2017-12-16 17:12:27.645585: step 40270, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 17h:48m:45s remains)
INFO - root - 2017-12-16 17:12:29.874123: step 40280, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 18h:24m:00s remains)
INFO - root - 2017-12-16 17:12:32.113631: step 40290, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 17h:45m:31s remains)
INFO - root - 2017-12-16 17:12:34.366399: step 40300, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 18h:15m:54s remains)
INFO - root - 2017-12-16 17:12:36.775944: step 40310, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.224 sec/batch; 18h:08m:51s remains)
INFO - root - 2017-12-16 17:12:39.036954: step 40320, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 17h:36m:49s remains)
INFO - root - 2017-12-16 17:12:41.220793: step 40330, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 17h:53m:05s remains)
INFO - root - 2017-12-16 17:12:43.416424: step 40340, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 18h:00m:05s remains)
INFO - root - 2017-12-16 17:12:45.658529: step 40350, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 17h:35m:55s remains)
INFO - root - 2017-12-16 17:12:47.901112: step 40360, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 18h:16m:31s remains)
INFO - root - 2017-12-16 17:12:50.082688: step 40370, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 17h:33m:35s remains)
INFO - root - 2017-12-16 17:12:52.324527: step 40380, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 17h:49m:37s remains)
INFO - root - 2017-12-16 17:12:54.532821: step 40390, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 18h:09m:29s remains)
INFO - root - 2017-12-16 17:12:56.741233: step 40400, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 17h:42m:17s remains)
INFO - root - 2017-12-16 17:12:59.097830: step 40410, loss = 0.48, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 18h:10m:49s remains)
INFO - root - 2017-12-16 17:13:01.322710: step 40420, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 18h:19m:33s remains)
INFO - root - 2017-12-16 17:13:03.536452: step 40430, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 17h:52m:50s remains)
INFO - root - 2017-12-16 17:13:05.738184: step 40440, loss = 0.56, batch loss = 0.38 (37.3 examples/sec; 0.214 sec/batch; 17h:22m:58s remains)
INFO - root - 2017-12-16 17:13:07.981687: step 40450, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.231 sec/batch; 18h:46m:36s remains)
INFO - root - 2017-12-16 17:13:10.204737: step 40460, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 17h:25m:24s remains)
INFO - root - 2017-12-16 17:13:12.397811: step 40470, loss = 0.50, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 18h:03m:47s remains)
INFO - root - 2017-12-16 17:13:14.653646: step 40480, loss = 0.43, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 18h:23m:48s remains)
INFO - root - 2017-12-16 17:13:16.850489: step 40490, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 17h:35m:14s remains)
INFO - root - 2017-12-16 17:13:19.055173: step 40500, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 17h:12m:03s remains)
INFO - root - 2017-12-16 17:13:21.395296: step 40510, loss = 0.49, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 18h:20m:07s remains)
INFO - root - 2017-12-16 17:13:23.604429: step 40520, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 17h:36m:09s remains)
INFO - root - 2017-12-16 17:13:25.800865: step 40530, loss = 0.48, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 18h:13m:23s remains)
INFO - root - 2017-12-16 17:13:28.008101: step 40540, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 18h:18m:42s remains)
INFO - root - 2017-12-16 17:13:30.228612: step 40550, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 17h:46m:42s remains)
INFO - root - 2017-12-16 17:13:32.425913: step 40560, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 18h:03m:08s remains)
INFO - root - 2017-12-16 17:13:34.654604: step 40570, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 17h:18m:01s remains)
INFO - root - 2017-12-16 17:13:36.901437: step 40580, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 18h:02m:10s remains)
INFO - root - 2017-12-16 17:13:39.125616: step 40590, loss = 0.47, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 18h:10m:09s remains)
INFO - root - 2017-12-16 17:13:41.331150: step 40600, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 17h:54m:49s remains)
INFO - root - 2017-12-16 17:13:43.675174: step 40610, loss = 0.50, batch loss = 0.32 (33.9 examples/sec; 0.236 sec/batch; 19h:09m:33s remains)
INFO - root - 2017-12-16 17:13:45.923658: step 40620, loss = 0.49, batch loss = 0.31 (34.7 examples/sec; 0.230 sec/batch; 18h:40m:49s remains)
INFO - root - 2017-12-16 17:13:48.137500: step 40630, loss = 0.53, batch loss = 0.35 (37.5 examples/sec; 0.213 sec/batch; 17h:18m:14s remains)
INFO - root - 2017-12-16 17:13:50.343565: step 40640, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 18h:38m:58s remains)
INFO - root - 2017-12-16 17:13:52.531664: step 40650, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 17h:51m:03s remains)
INFO - root - 2017-12-16 17:13:54.736259: step 40660, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 18h:00m:43s remains)
INFO - root - 2017-12-16 17:13:56.958405: step 40670, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 18h:13m:54s remains)
INFO - root - 2017-12-16 17:13:59.189491: step 40680, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 17h:43m:19s remains)
INFO - root - 2017-12-16 17:14:01.395499: step 40690, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 17h:33m:10s remains)
INFO - root - 2017-12-16 17:14:03.615289: step 40700, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 17h:40m:11s remains)
INFO - root - 2017-12-16 17:14:06.004165: step 40710, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 17h:47m:57s remains)
INFO - root - 2017-12-16 17:14:08.202960: step 40720, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 17h:38m:27s remains)
INFO - root - 2017-12-16 17:14:10.407470: step 40730, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 18h:13m:58s remains)
INFO - root - 2017-12-16 17:14:12.603282: step 40740, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 17h:56m:56s remains)
INFO - root - 2017-12-16 17:14:14.821215: step 40750, loss = 0.45, batch loss = 0.27 (34.2 examples/sec; 0.234 sec/batch; 18h:56m:38s remains)
INFO - root - 2017-12-16 17:14:17.040122: step 40760, loss = 0.47, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 17h:39m:25s remains)
INFO - root - 2017-12-16 17:14:19.230090: step 40770, loss = 0.43, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 17h:54m:55s remains)
INFO - root - 2017-12-16 17:14:21.401062: step 40780, loss = 0.57, batch loss = 0.39 (36.1 examples/sec; 0.221 sec/batch; 17h:56m:16s remains)
INFO - root - 2017-12-16 17:14:23.614485: step 40790, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 17h:52m:41s remains)
INFO - root - 2017-12-16 17:14:25.857821: step 40800, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 17h:44m:28s remains)
INFO - root - 2017-12-16 17:14:28.175531: step 40810, loss = 0.56, batch loss = 0.38 (35.8 examples/sec; 0.224 sec/batch; 18h:07m:17s remains)
INFO - root - 2017-12-16 17:14:30.382552: step 40820, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 18h:13m:43s remains)
INFO - root - 2017-12-16 17:14:32.572052: step 40830, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 17h:57m:49s remains)
INFO - root - 2017-12-16 17:14:34.818049: step 40840, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 17h:39m:22s remains)
INFO - root - 2017-12-16 17:14:37.063641: step 40850, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 18h:06m:00s remains)
INFO - root - 2017-12-16 17:14:39.277027: step 40860, loss = 0.41, batch loss = 0.23 (35.6 examples/sec; 0.225 sec/batch; 18h:13m:25s remains)
INFO - root - 2017-12-16 17:14:41.514624: step 40870, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 17h:24m:34s remains)
INFO - root - 2017-12-16 17:14:43.719864: step 40880, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 18h:08m:16s remains)
INFO - root - 2017-12-16 17:14:45.951581: step 40890, loss = 0.48, batch loss = 0.30 (37.8 examples/sec; 0.212 sec/batch; 17h:09m:33s remains)
INFO - root - 2017-12-16 17:14:48.179205: step 40900, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 17h:55m:06s remains)
INFO - root - 2017-12-16 17:14:50.487962: step 40910, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 17h:43m:14s remains)
INFO - root - 2017-12-16 17:14:52.714153: step 40920, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 18h:17m:44s remains)
INFO - root - 2017-12-16 17:14:54.936865: step 40930, loss = 0.53, batch loss = 0.35 (37.1 examples/sec; 0.215 sec/batch; 17h:26m:53s remains)
INFO - root - 2017-12-16 17:14:57.202665: step 40940, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 18h:07m:43s remains)
INFO - root - 2017-12-16 17:14:59.412509: step 40950, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.216 sec/batch; 17h:28m:43s remains)
INFO - root - 2017-12-16 17:15:01.632082: step 40960, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 17h:50m:04s remains)
INFO - root - 2017-12-16 17:15:03.850897: step 40970, loss = 0.45, batch loss = 0.27 (34.2 examples/sec; 0.234 sec/batch; 18h:57m:09s remains)
INFO - root - 2017-12-16 17:15:06.080503: step 40980, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 18h:15m:30s remains)
INFO - root - 2017-12-16 17:15:08.298643: step 40990, loss = 0.42, batch loss = 0.24 (37.8 examples/sec; 0.212 sec/batch; 17h:08m:22s remains)
INFO - root - 2017-12-16 17:15:10.500490: step 41000, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 17h:28m:37s remains)
INFO - root - 2017-12-16 17:15:12.834394: step 41010, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 17h:58m:21s remains)
INFO - root - 2017-12-16 17:15:15.035632: step 41020, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 18h:11m:09s remains)
INFO - root - 2017-12-16 17:15:17.246617: step 41030, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 17h:37m:57s remains)
INFO - root - 2017-12-16 17:15:19.487773: step 41040, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 17h:38m:57s remains)
INFO - root - 2017-12-16 17:15:21.750315: step 41050, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 17h:25m:34s remains)
INFO - root - 2017-12-16 17:15:23.966653: step 41060, loss = 0.51, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 18h:05m:40s remains)
INFO - root - 2017-12-16 17:15:26.165843: step 41070, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 17h:31m:24s remains)
INFO - root - 2017-12-16 17:15:28.388886: step 41080, loss = 0.46, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 17h:35m:34s remains)
INFO - root - 2017-12-16 17:15:30.616742: step 41090, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 17h:46m:47s remains)
INFO - root - 2017-12-16 17:15:32.816142: step 41100, loss = 0.56, batch loss = 0.38 (36.7 examples/sec; 0.218 sec/batch; 17h:37m:58s remains)
INFO - root - 2017-12-16 17:15:35.128373: step 41110, loss = 0.43, batch loss = 0.25 (37.0 examples/sec; 0.216 sec/batch; 17h:29m:49s remains)
INFO - root - 2017-12-16 17:15:37.324642: step 41120, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 18h:07m:43s remains)
INFO - root - 2017-12-16 17:15:39.536012: step 41130, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 17h:58m:32s remains)
INFO - root - 2017-12-16 17:15:41.773942: step 41140, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 17h:19m:27s remains)
INFO - root - 2017-12-16 17:15:43.984993: step 41150, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 17h:54m:01s remains)
INFO - root - 2017-12-16 17:15:46.197705: step 41160, loss = 0.44, batch loss = 0.26 (33.9 examples/sec; 0.236 sec/batch; 19h:05m:13s remains)
INFO - root - 2017-12-16 17:15:48.387542: step 41170, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 17h:56m:06s remains)
INFO - root - 2017-12-16 17:15:50.623277: step 41180, loss = 0.50, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 17h:55m:06s remains)
INFO - root - 2017-12-16 17:15:52.845996: step 41190, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 17h:46m:21s remains)
INFO - root - 2017-12-16 17:15:55.064269: step 41200, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 17h:36m:30s remains)
INFO - root - 2017-12-16 17:15:57.444906: step 41210, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 18h:15m:23s remains)
INFO - root - 2017-12-16 17:15:59.692065: step 41220, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 18h:21m:58s remains)
INFO - root - 2017-12-16 17:16:01.935777: step 41230, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 18h:36m:53s remains)
INFO - root - 2017-12-16 17:16:04.170106: step 41240, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.219 sec/batch; 17h:45m:28s remains)
INFO - root - 2017-12-16 17:16:06.388068: step 41250, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 18h:22m:43s remains)
INFO - root - 2017-12-16 17:16:08.606112: step 41260, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 18h:12m:01s remains)
INFO - root - 2017-12-16 17:16:10.874465: step 41270, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 17h:50m:08s remains)
INFO - root - 2017-12-16 17:16:13.034934: step 41280, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 18h:22m:36s remains)
INFO - root - 2017-12-16 17:16:15.232584: step 41290, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 17h:38m:40s remains)
INFO - root - 2017-12-16 17:16:17.467709: step 41300, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 17h:30m:17s remains)
INFO - root - 2017-12-16 17:16:19.853442: step 41310, loss = 0.51, batch loss = 0.34 (35.2 examples/sec; 0.228 sec/batch; 18h:24m:28s remains)
INFO - root - 2017-12-16 17:16:22.100379: step 41320, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 18h:44m:02s remains)
INFO - root - 2017-12-16 17:16:24.323272: step 41330, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 18h:04m:05s remains)
INFO - root - 2017-12-16 17:16:26.523296: step 41340, loss = 0.45, batch loss = 0.27 (37.6 examples/sec; 0.213 sec/batch; 17h:13m:37s remains)
INFO - root - 2017-12-16 17:16:28.753221: step 41350, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 17h:45m:36s remains)
INFO - root - 2017-12-16 17:16:30.962126: step 41360, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 18h:04m:10s remains)
INFO - root - 2017-12-16 17:16:33.191905: step 41370, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 17h:43m:54s remains)
INFO - root - 2017-12-16 17:16:35.440921: step 41380, loss = 0.50, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 17h:59m:05s remains)
INFO - root - 2017-12-16 17:16:37.656851: step 41390, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 18h:15m:22s remains)
INFO - root - 2017-12-16 17:16:39.874442: step 41400, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 17h:38m:28s remains)
INFO - root - 2017-12-16 17:16:42.191159: step 41410, loss = 0.43, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 17h:19m:04s remains)
INFO - root - 2017-12-16 17:16:44.394220: step 41420, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 17h:53m:12s remains)
INFO - root - 2017-12-16 17:16:46.613087: step 41430, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 18h:02m:20s remains)
INFO - root - 2017-12-16 17:16:48.814798: step 41440, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 17h:25m:41s remains)
INFO - root - 2017-12-16 17:16:51.033076: step 41450, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 18h:03m:12s remains)
INFO - root - 2017-12-16 17:16:53.211299: step 41460, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 17h:15m:17s remains)
INFO - root - 2017-12-16 17:16:55.436537: step 41470, loss = 0.55, batch loss = 0.37 (35.1 examples/sec; 0.228 sec/batch; 18h:24m:25s remains)
INFO - root - 2017-12-16 17:16:57.637920: step 41480, loss = 0.45, batch loss = 0.27 (37.6 examples/sec; 0.213 sec/batch; 17h:12m:28s remains)
INFO - root - 2017-12-16 17:16:59.848661: step 41490, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 18h:11m:13s remains)
INFO - root - 2017-12-16 17:17:02.054860: step 41500, loss = 0.43, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 17h:16m:58s remains)
INFO - root - 2017-12-16 17:17:04.401126: step 41510, loss = 0.48, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 17h:36m:23s remains)
INFO - root - 2017-12-16 17:17:06.632623: step 41520, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 18h:02m:20s remains)
INFO - root - 2017-12-16 17:17:08.867495: step 41530, loss = 0.53, batch loss = 0.36 (34.0 examples/sec; 0.235 sec/batch; 19h:00m:06s remains)
INFO - root - 2017-12-16 17:17:11.084560: step 41540, loss = 0.50, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 18h:00m:45s remains)
INFO - root - 2017-12-16 17:17:13.312236: step 41550, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 17h:52m:20s remains)
INFO - root - 2017-12-16 17:17:15.524524: step 41560, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 17h:41m:13s remains)
INFO - root - 2017-12-16 17:17:17.713347: step 41570, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 17h:18m:17s remains)
INFO - root - 2017-12-16 17:17:19.918937: step 41580, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.219 sec/batch; 17h:44m:12s remains)
INFO - root - 2017-12-16 17:17:22.157412: step 41590, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 17h:57m:30s remains)
INFO - root - 2017-12-16 17:17:24.431854: step 41600, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 17h:41m:29s remains)
INFO - root - 2017-12-16 17:17:26.771241: step 41610, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 17h:32m:38s remains)
INFO - root - 2017-12-16 17:17:28.949732: step 41620, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 18h:12m:18s remains)
INFO - root - 2017-12-16 17:17:31.150099: step 41630, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.217 sec/batch; 17h:29m:35s remains)
INFO - root - 2017-12-16 17:17:33.360229: step 41640, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 17h:41m:25s remains)
INFO - root - 2017-12-16 17:17:35.603380: step 41650, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 17h:59m:23s remains)
INFO - root - 2017-12-16 17:17:37.828517: step 41660, loss = 0.54, batch loss = 0.36 (35.1 examples/sec; 0.228 sec/batch; 18h:23m:55s remains)
INFO - root - 2017-12-16 17:17:40.048165: step 41670, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 17h:48m:21s remains)
INFO - root - 2017-12-16 17:17:42.226761: step 41680, loss = 0.50, batch loss = 0.33 (35.2 examples/sec; 0.228 sec/batch; 18h:22m:59s remains)
INFO - root - 2017-12-16 17:17:44.431680: step 41690, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 17h:28m:39s remains)
INFO - root - 2017-12-16 17:17:46.619801: step 41700, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 17h:34m:30s remains)
INFO - root - 2017-12-16 17:17:48.932521: step 41710, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 17h:25m:22s remains)
INFO - root - 2017-12-16 17:17:51.172801: step 41720, loss = 0.51, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 18h:34m:28s remains)
INFO - root - 2017-12-16 17:17:53.364515: step 41730, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 17h:56m:21s remains)
INFO - root - 2017-12-16 17:17:55.590273: step 41740, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 17h:43m:20s remains)
INFO - root - 2017-12-16 17:17:57.825129: step 41750, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 17h:47m:49s remains)
INFO - root - 2017-12-16 17:18:00.046935: step 41760, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 18h:19m:12s remains)
INFO - root - 2017-12-16 17:18:02.240516: step 41770, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 18h:16m:13s remains)
INFO - root - 2017-12-16 17:18:04.495420: step 41780, loss = 0.54, batch loss = 0.36 (37.3 examples/sec; 0.214 sec/batch; 17h:18m:39s remains)
INFO - root - 2017-12-16 17:18:06.729451: step 41790, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 17h:57m:38s remains)
INFO - root - 2017-12-16 17:18:08.950512: step 41800, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 17h:17m:50s remains)
INFO - root - 2017-12-16 17:18:11.286953: step 41810, loss = 0.53, batch loss = 0.35 (35.4 examples/sec; 0.226 sec/batch; 18h:15m:26s remains)
INFO - root - 2017-12-16 17:18:13.491460: step 41820, loss = 0.42, batch loss = 0.24 (36.3 examples/sec; 0.220 sec/batch; 17h:46m:20s remains)
INFO - root - 2017-12-16 17:18:15.704043: step 41830, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 18h:09m:51s remains)
INFO - root - 2017-12-16 17:18:17.945499: step 41840, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 17h:55m:59s remains)
INFO - root - 2017-12-16 17:18:20.204269: step 41850, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.228 sec/batch; 18h:22m:12s remains)
INFO - root - 2017-12-16 17:18:22.423515: step 41860, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.226 sec/batch; 18h:16m:59s remains)
INFO - root - 2017-12-16 17:18:24.620880: step 41870, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 17h:54m:16s remains)
INFO - root - 2017-12-16 17:18:26.844921: step 41880, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 17h:36m:17s remains)
INFO - root - 2017-12-16 17:18:29.060177: step 41890, loss = 0.41, batch loss = 0.23 (35.2 examples/sec; 0.227 sec/batch; 18h:20m:23s remains)
INFO - root - 2017-12-16 17:18:31.304319: step 41900, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 17h:50m:13s remains)
INFO - root - 2017-12-16 17:18:33.663247: step 41910, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 17h:41m:23s remains)
INFO - root - 2017-12-16 17:18:35.865799: step 41920, loss = 0.55, batch loss = 0.37 (35.4 examples/sec; 0.226 sec/batch; 18h:15m:41s remains)
INFO - root - 2017-12-16 17:18:38.084105: step 41930, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 18h:06m:00s remains)
INFO - root - 2017-12-16 17:18:40.320160: step 41940, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 18h:10m:28s remains)
INFO - root - 2017-12-16 17:18:42.527966: step 41950, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 17h:55m:00s remains)
INFO - root - 2017-12-16 17:18:44.747369: step 41960, loss = 0.42, batch loss = 0.24 (35.2 examples/sec; 0.227 sec/batch; 18h:19m:24s remains)
INFO - root - 2017-12-16 17:18:46.964528: step 41970, loss = 0.55, batch loss = 0.37 (36.8 examples/sec; 0.217 sec/batch; 17h:31m:14s remains)
INFO - root - 2017-12-16 17:18:49.193666: step 41980, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 18h:00m:49s remains)
INFO - root - 2017-12-16 17:18:51.405387: step 41990, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 17h:27m:59s remains)
INFO - root - 2017-12-16 17:18:53.614288: step 42000, loss = 0.44, batch loss = 0.26 (35.0 examples/sec; 0.229 sec/batch; 18h:27m:14s remains)
INFO - root - 2017-12-16 17:18:55.991929: step 42010, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 18h:13m:55s remains)
INFO - root - 2017-12-16 17:18:58.209977: step 42020, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 17h:26m:28s remains)
INFO - root - 2017-12-16 17:19:00.420057: step 42030, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 18h:14m:51s remains)
INFO - root - 2017-12-16 17:19:02.678105: step 42040, loss = 0.53, batch loss = 0.35 (34.2 examples/sec; 0.234 sec/batch; 18h:53m:09s remains)
INFO - root - 2017-12-16 17:19:04.892935: step 42050, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 17h:26m:35s remains)
INFO - root - 2017-12-16 17:19:07.132917: step 42060, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 18h:09m:36s remains)
INFO - root - 2017-12-16 17:19:09.384545: step 42070, loss = 0.50, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 18h:14m:08s remains)
INFO - root - 2017-12-16 17:19:11.620433: step 42080, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 18h:26m:52s remains)
INFO - root - 2017-12-16 17:19:13.839097: step 42090, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 17h:31m:23s remains)
INFO - root - 2017-12-16 17:19:16.065163: step 42100, loss = 0.54, batch loss = 0.36 (35.2 examples/sec; 0.227 sec/batch; 18h:19m:31s remains)
INFO - root - 2017-12-16 17:19:18.387019: step 42110, loss = 0.56, batch loss = 0.38 (34.0 examples/sec; 0.235 sec/batch; 18h:58m:42s remains)
INFO - root - 2017-12-16 17:19:20.626677: step 42120, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 18h:10m:49s remains)
INFO - root - 2017-12-16 17:19:22.838130: step 42130, loss = 0.53, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 18h:08m:18s remains)
INFO - root - 2017-12-16 17:19:25.100468: step 42140, loss = 0.59, batch loss = 0.41 (36.9 examples/sec; 0.217 sec/batch; 17h:29m:36s remains)
INFO - root - 2017-12-16 17:19:27.304480: step 42150, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 17h:30m:45s remains)
INFO - root - 2017-12-16 17:19:29.496016: step 42160, loss = 0.42, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 18h:03m:45s remains)
INFO - root - 2017-12-16 17:19:31.735447: step 42170, loss = 0.44, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 17h:44m:15s remains)
INFO - root - 2017-12-16 17:19:33.912825: step 42180, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 18h:01m:13s remains)
INFO - root - 2017-12-16 17:19:36.111000: step 42190, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 17h:34m:15s remains)
INFO - root - 2017-12-16 17:19:38.295067: step 42200, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 17h:14m:05s remains)
INFO - root - 2017-12-16 17:19:40.645029: step 42210, loss = 0.54, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 17h:50m:21s remains)
INFO - root - 2017-12-16 17:19:42.858482: step 42220, loss = 0.54, batch loss = 0.36 (36.2 examples/sec; 0.221 sec/batch; 17h:50m:10s remains)
INFO - root - 2017-12-16 17:19:45.075179: step 42230, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 17h:56m:05s remains)
INFO - root - 2017-12-16 17:19:47.265497: step 42240, loss = 0.42, batch loss = 0.24 (36.1 examples/sec; 0.221 sec/batch; 17h:50m:40s remains)
INFO - root - 2017-12-16 17:19:49.449059: step 42250, loss = 0.56, batch loss = 0.38 (37.4 examples/sec; 0.214 sec/batch; 17h:16m:02s remains)
INFO - root - 2017-12-16 17:19:51.688898: step 42260, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 17h:59m:34s remains)
INFO - root - 2017-12-16 17:19:53.889476: step 42270, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 17h:33m:56s remains)
INFO - root - 2017-12-16 17:19:56.079497: step 42280, loss = 0.55, batch loss = 0.38 (37.1 examples/sec; 0.216 sec/batch; 17h:23m:07s remains)
INFO - root - 2017-12-16 17:19:58.280476: step 42290, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 17h:27m:26s remains)
INFO - root - 2017-12-16 17:20:00.500890: step 42300, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 17h:03m:58s remains)
INFO - root - 2017-12-16 17:20:02.877527: step 42310, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 17h:52m:31s remains)
INFO - root - 2017-12-16 17:20:05.102663: step 42320, loss = 0.47, batch loss = 0.29 (34.4 examples/sec; 0.232 sec/batch; 18h:43m:52s remains)
INFO - root - 2017-12-16 17:20:07.362825: step 42330, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 18h:30m:52s remains)
INFO - root - 2017-12-16 17:20:09.572987: step 42340, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 18h:21m:10s remains)
INFO - root - 2017-12-16 17:20:11.781239: step 42350, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 17h:48m:13s remains)
INFO - root - 2017-12-16 17:20:14.063172: step 42360, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 17h:57m:42s remains)
INFO - root - 2017-12-16 17:20:16.290716: step 42370, loss = 0.46, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 18h:47m:55s remains)
INFO - root - 2017-12-16 17:20:18.454723: step 42380, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 17h:33m:27s remains)
INFO - root - 2017-12-16 17:20:20.625725: step 42390, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 17h:51m:19s remains)
INFO - root - 2017-12-16 17:20:22.819339: step 42400, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 17h:59m:29s remains)
INFO - root - 2017-12-16 17:20:25.161838: step 42410, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 17h:49m:51s remains)
INFO - root - 2017-12-16 17:20:27.345674: step 42420, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 17h:25m:40s remains)
INFO - root - 2017-12-16 17:20:29.545758: step 42430, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 17h:30m:33s remains)
INFO - root - 2017-12-16 17:20:31.746427: step 42440, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 17h:26m:33s remains)
INFO - root - 2017-12-16 17:20:33.958068: step 42450, loss = 0.46, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 17h:27m:05s remains)
INFO - root - 2017-12-16 17:20:36.167139: step 42460, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 17h:47m:05s remains)
INFO - root - 2017-12-16 17:20:38.366615: step 42470, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 18h:12m:56s remains)
INFO - root - 2017-12-16 17:20:40.623567: step 42480, loss = 0.44, batch loss = 0.26 (34.0 examples/sec; 0.236 sec/batch; 18h:58m:50s remains)
INFO - root - 2017-12-16 17:20:42.874033: step 42490, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 17h:59m:18s remains)
INFO - root - 2017-12-16 17:20:45.093825: step 42500, loss = 0.43, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 17h:56m:03s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-42500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-42500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 17:20:47.942779: step 42510, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 18h:00m:31s remains)
INFO - root - 2017-12-16 17:20:50.177614: step 42520, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 18h:27m:25s remains)
INFO - root - 2017-12-16 17:20:52.397620: step 42530, loss = 0.41, batch loss = 0.23 (37.1 examples/sec; 0.216 sec/batch; 17h:23m:05s remains)
INFO - root - 2017-12-16 17:20:54.572829: step 42540, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 17h:31m:45s remains)
INFO - root - 2017-12-16 17:20:56.800332: step 42550, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 18h:09m:55s remains)
INFO - root - 2017-12-16 17:20:59.051545: step 42560, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.230 sec/batch; 18h:33m:34s remains)
INFO - root - 2017-12-16 17:21:01.214973: step 42570, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 17h:21m:14s remains)
INFO - root - 2017-12-16 17:21:03.417273: step 42580, loss = 0.42, batch loss = 0.24 (36.0 examples/sec; 0.222 sec/batch; 17h:54m:38s remains)
INFO - root - 2017-12-16 17:21:05.631233: step 42590, loss = 0.40, batch loss = 0.22 (36.9 examples/sec; 0.217 sec/batch; 17h:28m:19s remains)
INFO - root - 2017-12-16 17:21:07.821497: step 42600, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 18h:32m:08s remains)
INFO - root - 2017-12-16 17:21:10.194990: step 42610, loss = 0.56, batch loss = 0.38 (37.5 examples/sec; 0.213 sec/batch; 17h:10m:50s remains)
INFO - root - 2017-12-16 17:21:12.369709: step 42620, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 17h:09m:30s remains)
INFO - root - 2017-12-16 17:21:14.581339: step 42630, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 17h:21m:13s remains)
INFO - root - 2017-12-16 17:21:16.790317: step 42640, loss = 0.50, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 17h:33m:41s remains)
INFO - root - 2017-12-16 17:21:19.027919: step 42650, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 17h:33m:58s remains)
INFO - root - 2017-12-16 17:21:21.246843: step 42660, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 18h:03m:42s remains)
INFO - root - 2017-12-16 17:21:23.462288: step 42670, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.211 sec/batch; 17h:01m:33s remains)
INFO - root - 2017-12-16 17:21:25.689674: step 42680, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 18h:02m:37s remains)
INFO - root - 2017-12-16 17:21:27.896410: step 42690, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 17h:50m:21s remains)
INFO - root - 2017-12-16 17:21:30.087979: step 42700, loss = 0.43, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 18h:14m:15s remains)
INFO - root - 2017-12-16 17:21:32.448635: step 42710, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 18h:14m:16s remains)
INFO - root - 2017-12-16 17:21:34.654636: step 42720, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 17h:33m:31s remains)
INFO - root - 2017-12-16 17:21:36.884897: step 42730, loss = 0.44, batch loss = 0.26 (34.7 examples/sec; 0.230 sec/batch; 18h:32m:50s remains)
INFO - root - 2017-12-16 17:21:39.121283: step 42740, loss = 0.47, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 18h:01m:58s remains)
INFO - root - 2017-12-16 17:21:41.353314: step 42750, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 17h:58m:33s remains)
INFO - root - 2017-12-16 17:21:43.560402: step 42760, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 17h:41m:34s remains)
INFO - root - 2017-12-16 17:21:45.773134: step 42770, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 17h:56m:41s remains)
INFO - root - 2017-12-16 17:21:47.983156: step 42780, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 18h:17m:55s remains)
INFO - root - 2017-12-16 17:21:50.190459: step 42790, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 18h:31m:17s remains)
INFO - root - 2017-12-16 17:21:52.419916: step 42800, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 17h:22m:39s remains)
INFO - root - 2017-12-16 17:21:54.748953: step 42810, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 18h:12m:34s remains)
INFO - root - 2017-12-16 17:21:56.974516: step 42820, loss = 0.52, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 18h:17m:47s remains)
INFO - root - 2017-12-16 17:21:59.183166: step 42830, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 18h:08m:23s remains)
INFO - root - 2017-12-16 17:22:01.375872: step 42840, loss = 0.46, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 17h:46m:30s remains)
INFO - root - 2017-12-16 17:22:03.569378: step 42850, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 17h:40m:23s remains)
INFO - root - 2017-12-16 17:22:05.776914: step 42860, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 17h:22m:16s remains)
INFO - root - 2017-12-16 17:22:08.004965: step 42870, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 17h:45m:46s remains)
INFO - root - 2017-12-16 17:22:10.271434: step 42880, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 17h:22m:09s remains)
INFO - root - 2017-12-16 17:22:12.455937: step 42890, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 17h:20m:44s remains)
INFO - root - 2017-12-16 17:22:14.638445: step 42900, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 18h:02m:04s remains)
INFO - root - 2017-12-16 17:22:16.987110: step 42910, loss = 0.59, batch loss = 0.41 (36.7 examples/sec; 0.218 sec/batch; 17h:33m:02s remains)
INFO - root - 2017-12-16 17:22:19.199143: step 42920, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 17h:18m:20s remains)
INFO - root - 2017-12-16 17:22:21.396003: step 42930, loss = 0.45, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 17h:45m:29s remains)
INFO - root - 2017-12-16 17:22:23.606301: step 42940, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 17h:21m:59s remains)
INFO - root - 2017-12-16 17:22:25.828117: step 42950, loss = 0.48, batch loss = 0.31 (34.7 examples/sec; 0.230 sec/batch; 18h:31m:54s remains)
INFO - root - 2017-12-16 17:22:28.067808: step 42960, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 18h:00m:36s remains)
INFO - root - 2017-12-16 17:22:30.283581: step 42970, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 18h:10m:44s remains)
INFO - root - 2017-12-16 17:22:32.478488: step 42980, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 17h:37m:04s remains)
INFO - root - 2017-12-16 17:22:34.687690: step 42990, loss = 0.46, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 17h:36m:27s remains)
INFO - root - 2017-12-16 17:22:36.886971: step 43000, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 17h:12m:32s remains)
INFO - root - 2017-12-16 17:22:39.218402: step 43010, loss = 0.47, batch loss = 0.30 (35.6 examples/sec; 0.224 sec/batch; 18h:03m:01s remains)
INFO - root - 2017-12-16 17:22:41.372532: step 43020, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 17h:15m:34s remains)
INFO - root - 2017-12-16 17:22:43.583617: step 43030, loss = 0.47, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 17h:59m:37s remains)
INFO - root - 2017-12-16 17:22:45.804557: step 43040, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 17h:52m:03s remains)
INFO - root - 2017-12-16 17:22:48.015387: step 43050, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 17h:41m:36s remains)
INFO - root - 2017-12-16 17:22:50.219034: step 43060, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 17h:49m:26s remains)
INFO - root - 2017-12-16 17:22:52.390804: step 43070, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 17h:21m:11s remains)
INFO - root - 2017-12-16 17:22:54.593859: step 43080, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 18h:00m:59s remains)
INFO - root - 2017-12-16 17:22:56.785697: step 43090, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 17h:30m:51s remains)
INFO - root - 2017-12-16 17:22:58.960306: step 43100, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 17h:15m:27s remains)
INFO - root - 2017-12-16 17:23:01.313954: step 43110, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 17h:57m:53s remains)
INFO - root - 2017-12-16 17:23:03.555055: step 43120, loss = 0.45, batch loss = 0.27 (32.9 examples/sec; 0.243 sec/batch; 19h:33m:46s remains)
INFO - root - 2017-12-16 17:23:05.785928: step 43130, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 17h:56m:34s remains)
INFO - root - 2017-12-16 17:23:08.046653: step 43140, loss = 0.47, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 17h:53m:55s remains)
INFO - root - 2017-12-16 17:23:10.270701: step 43150, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 17h:39m:19s remains)
INFO - root - 2017-12-16 17:23:12.448252: step 43160, loss = 0.55, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 17h:40m:30s remains)
INFO - root - 2017-12-16 17:23:14.655394: step 43170, loss = 0.50, batch loss = 0.32 (33.1 examples/sec; 0.242 sec/batch; 19h:26m:23s remains)
INFO - root - 2017-12-16 17:23:16.866808: step 43180, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 17h:25m:52s remains)
INFO - root - 2017-12-16 17:23:19.060593: step 43190, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 17h:25m:13s remains)
INFO - root - 2017-12-16 17:23:21.263605: step 43200, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 17h:26m:51s remains)
INFO - root - 2017-12-16 17:23:23.599995: step 43210, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 17h:26m:03s remains)
INFO - root - 2017-12-16 17:23:25.832934: step 43220, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 17h:35m:53s remains)
INFO - root - 2017-12-16 17:23:28.080261: step 43230, loss = 0.49, batch loss = 0.32 (33.2 examples/sec; 0.241 sec/batch; 19h:20m:24s remains)
INFO - root - 2017-12-16 17:23:30.269173: step 43240, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 17h:11m:57s remains)
INFO - root - 2017-12-16 17:23:32.456440: step 43250, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 17h:27m:48s remains)
INFO - root - 2017-12-16 17:23:34.633139: step 43260, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 17h:29m:40s remains)
INFO - root - 2017-12-16 17:23:36.863400: step 43270, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 17h:40m:19s remains)
INFO - root - 2017-12-16 17:23:39.073471: step 43280, loss = 0.62, batch loss = 0.44 (35.8 examples/sec; 0.223 sec/batch; 17h:56m:28s remains)
INFO - root - 2017-12-16 17:23:41.294342: step 43290, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 18h:02m:51s remains)
INFO - root - 2017-12-16 17:23:43.473653: step 43300, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 17h:33m:04s remains)
INFO - root - 2017-12-16 17:23:45.814815: step 43310, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 17h:54m:28s remains)
INFO - root - 2017-12-16 17:23:48.047639: step 43320, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.219 sec/batch; 17h:33m:13s remains)
INFO - root - 2017-12-16 17:23:50.234820: step 43330, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 18h:07m:58s remains)
INFO - root - 2017-12-16 17:23:52.448933: step 43340, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 17h:20m:42s remains)
INFO - root - 2017-12-16 17:23:54.674261: step 43350, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 17h:38m:33s remains)
INFO - root - 2017-12-16 17:23:56.865685: step 43360, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 17h:25m:26s remains)
INFO - root - 2017-12-16 17:23:59.062513: step 43370, loss = 0.48, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 17h:29m:39s remains)
INFO - root - 2017-12-16 17:24:01.285153: step 43380, loss = 0.46, batch loss = 0.28 (34.1 examples/sec; 0.235 sec/batch; 18h:52m:04s remains)
INFO - root - 2017-12-16 17:24:03.480547: step 43390, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 18h:11m:41s remains)
INFO - root - 2017-12-16 17:24:05.730087: step 43400, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.226 sec/batch; 18h:07m:17s remains)
INFO - root - 2017-12-16 17:24:08.093031: step 43410, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 18h:07m:42s remains)
INFO - root - 2017-12-16 17:24:10.318094: step 43420, loss = 0.52, batch loss = 0.34 (35.0 examples/sec; 0.229 sec/batch; 18h:21m:03s remains)
INFO - root - 2017-12-16 17:24:12.541250: step 43430, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.223 sec/batch; 17h:55m:53s remains)
INFO - root - 2017-12-16 17:24:14.730140: step 43440, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 17h:33m:46s remains)
INFO - root - 2017-12-16 17:24:16.962769: step 43450, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 18h:08m:25s remains)
INFO - root - 2017-12-16 17:24:19.180471: step 43460, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 17h:14m:39s remains)
INFO - root - 2017-12-16 17:24:21.383417: step 43470, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 17h:45m:58s remains)
INFO - root - 2017-12-16 17:24:23.613264: step 43480, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 18h:03m:05s remains)
INFO - root - 2017-12-16 17:24:25.818336: step 43490, loss = 0.45, batch loss = 0.28 (34.0 examples/sec; 0.235 sec/batch; 18h:52m:32s remains)
INFO - root - 2017-12-16 17:24:28.067524: step 43500, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 17h:42m:07s remains)
INFO - root - 2017-12-16 17:24:30.393332: step 43510, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 17h:33m:59s remains)
INFO - root - 2017-12-16 17:24:32.612866: step 43520, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 17h:06m:53s remains)
INFO - root - 2017-12-16 17:24:34.797380: step 43530, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 17h:05m:46s remains)
INFO - root - 2017-12-16 17:24:37.004743: step 43540, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.226 sec/batch; 18h:09m:58s remains)
INFO - root - 2017-12-16 17:24:39.212944: step 43550, loss = 0.45, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 17h:09m:44s remains)
INFO - root - 2017-12-16 17:24:41.435987: step 43560, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 18h:05m:51s remains)
INFO - root - 2017-12-16 17:24:43.627254: step 43570, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 17h:06m:13s remains)
INFO - root - 2017-12-16 17:24:45.858458: step 43580, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 18h:13m:19s remains)
INFO - root - 2017-12-16 17:24:48.082563: step 43590, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.228 sec/batch; 18h:20m:13s remains)
INFO - root - 2017-12-16 17:24:50.295215: step 43600, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 17h:29m:04s remains)
INFO - root - 2017-12-16 17:24:52.572832: step 43610, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 17h:20m:19s remains)
INFO - root - 2017-12-16 17:24:54.810791: step 43620, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 17h:40m:57s remains)
INFO - root - 2017-12-16 17:24:57.022886: step 43630, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 17h:25m:46s remains)
INFO - root - 2017-12-16 17:24:59.213710: step 43640, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 17h:53m:57s remains)
INFO - root - 2017-12-16 17:25:01.411413: step 43650, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 17h:31m:24s remains)
INFO - root - 2017-12-16 17:25:03.582868: step 43660, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 17h:49m:19s remains)
INFO - root - 2017-12-16 17:25:05.774463: step 43670, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 17h:27m:30s remains)
INFO - root - 2017-12-16 17:25:08.035644: step 43680, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 17h:35m:29s remains)
INFO - root - 2017-12-16 17:25:10.266249: step 43690, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 17h:49m:44s remains)
INFO - root - 2017-12-16 17:25:12.459666: step 43700, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 17h:23m:30s remains)
INFO - root - 2017-12-16 17:25:14.798323: step 43710, loss = 0.46, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 17h:23m:18s remains)
INFO - root - 2017-12-16 17:25:16.997770: step 43720, loss = 0.57, batch loss = 0.39 (35.8 examples/sec; 0.223 sec/batch; 17h:54m:34s remains)
INFO - root - 2017-12-16 17:25:19.254202: step 43730, loss = 0.44, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 18h:10m:36s remains)
INFO - root - 2017-12-16 17:25:21.508779: step 43740, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 17h:48m:33s remains)
INFO - root - 2017-12-16 17:25:23.738454: step 43750, loss = 0.45, batch loss = 0.27 (34.6 examples/sec; 0.231 sec/batch; 18h:31m:07s remains)
INFO - root - 2017-12-16 17:25:25.937638: step 43760, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 17h:31m:44s remains)
INFO - root - 2017-12-16 17:25:28.181907: step 43770, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 18h:03m:17s remains)
INFO - root - 2017-12-16 17:25:30.370641: step 43780, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 17h:37m:38s remains)
INFO - root - 2017-12-16 17:25:32.611078: step 43790, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 17h:56m:49s remains)
INFO - root - 2017-12-16 17:25:34.857977: step 43800, loss = 0.46, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 17h:32m:50s remains)
INFO - root - 2017-12-16 17:25:37.195884: step 43810, loss = 0.44, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 18h:37m:13s remains)
INFO - root - 2017-12-16 17:25:39.372426: step 43820, loss = 0.50, batch loss = 0.32 (39.5 examples/sec; 0.203 sec/batch; 16h:15m:32s remains)
INFO - root - 2017-12-16 17:25:41.590932: step 43830, loss = 0.52, batch loss = 0.34 (34.9 examples/sec; 0.229 sec/batch; 18h:24m:01s remains)
INFO - root - 2017-12-16 17:25:43.765053: step 43840, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 17h:11m:28s remains)
INFO - root - 2017-12-16 17:25:45.998020: step 43850, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 17h:23m:41s remains)
INFO - root - 2017-12-16 17:25:48.197774: step 43860, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 17h:29m:49s remains)
INFO - root - 2017-12-16 17:25:50.394474: step 43870, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 17h:28m:56s remains)
INFO - root - 2017-12-16 17:25:52.598748: step 43880, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 17h:16m:57s remains)
INFO - root - 2017-12-16 17:25:54.824642: step 43890, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 17h:25m:25s remains)
INFO - root - 2017-12-16 17:25:57.000321: step 43900, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 17h:27m:37s remains)
INFO - root - 2017-12-16 17:25:59.351058: step 43910, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 18h:09m:41s remains)
INFO - root - 2017-12-16 17:26:01.563433: step 43920, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 17h:36m:15s remains)
INFO - root - 2017-12-16 17:26:03.774346: step 43930, loss = 0.45, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 17h:44m:00s remains)
INFO - root - 2017-12-16 17:26:05.990336: step 43940, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 17h:30m:56s remains)
INFO - root - 2017-12-16 17:26:08.181320: step 43950, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 17h:19m:04s remains)
INFO - root - 2017-12-16 17:26:10.380337: step 43960, loss = 0.58, batch loss = 0.40 (36.2 examples/sec; 0.221 sec/batch; 17h:41m:26s remains)
INFO - root - 2017-12-16 17:26:12.584341: step 43970, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 17h:25m:37s remains)
INFO - root - 2017-12-16 17:26:14.761066: step 43980, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 17h:03m:36s remains)
INFO - root - 2017-12-16 17:26:17.002533: step 43990, loss = 0.49, batch loss = 0.31 (37.9 examples/sec; 0.211 sec/batch; 16h:56m:01s remains)
INFO - root - 2017-12-16 17:26:19.231720: step 44000, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 17h:57m:06s remains)
INFO - root - 2017-12-16 17:26:21.602970: step 44010, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 17h:55m:46s remains)
INFO - root - 2017-12-16 17:26:23.792065: step 44020, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 17h:30m:39s remains)
INFO - root - 2017-12-16 17:26:25.980950: step 44030, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 17h:36m:31s remains)
INFO - root - 2017-12-16 17:26:28.208869: step 44040, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 17h:58m:37s remains)
INFO - root - 2017-12-16 17:26:30.432308: step 44050, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 17h:31m:15s remains)
INFO - root - 2017-12-16 17:26:32.669374: step 44060, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 17h:58m:11s remains)
INFO - root - 2017-12-16 17:26:34.883425: step 44070, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 17h:28m:10s remains)
INFO - root - 2017-12-16 17:26:37.087979: step 44080, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 17h:22m:47s remains)
INFO - root - 2017-12-16 17:26:39.268720: step 44090, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 17h:23m:47s remains)
INFO - root - 2017-12-16 17:26:41.504231: step 44100, loss = 0.48, batch loss = 0.30 (34.1 examples/sec; 0.235 sec/batch; 18h:48m:58s remains)
INFO - root - 2017-12-16 17:26:43.851574: step 44110, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 17h:19m:26s remains)
INFO - root - 2017-12-16 17:26:46.062649: step 44120, loss = 0.47, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 17h:18m:56s remains)
INFO - root - 2017-12-16 17:26:48.285141: step 44130, loss = 0.52, batch loss = 0.35 (36.6 examples/sec; 0.219 sec/batch; 17h:31m:13s remains)
INFO - root - 2017-12-16 17:26:50.494705: step 44140, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 17h:26m:34s remains)
INFO - root - 2017-12-16 17:26:52.692152: step 44150, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 17h:47m:15s remains)
INFO - root - 2017-12-16 17:26:54.925107: step 44160, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 17h:09m:34s remains)
INFO - root - 2017-12-16 17:26:57.127640: step 44170, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.214 sec/batch; 17h:09m:35s remains)
INFO - root - 2017-12-16 17:26:59.395090: step 44180, loss = 0.53, batch loss = 0.35 (33.6 examples/sec; 0.238 sec/batch; 19h:05m:49s remains)
INFO - root - 2017-12-16 17:27:01.649814: step 44190, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 17h:55m:55s remains)
INFO - root - 2017-12-16 17:27:03.865742: step 44200, loss = 0.53, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 17h:57m:11s remains)
INFO - root - 2017-12-16 17:27:06.194680: step 44210, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 18h:07m:00s remains)
INFO - root - 2017-12-16 17:27:08.408462: step 44220, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 17h:43m:27s remains)
INFO - root - 2017-12-16 17:27:10.616783: step 44230, loss = 0.47, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 18h:04m:51s remains)
INFO - root - 2017-12-16 17:27:12.791779: step 44240, loss = 0.55, batch loss = 0.37 (37.2 examples/sec; 0.215 sec/batch; 17h:14m:25s remains)
INFO - root - 2017-12-16 17:27:15.018419: step 44250, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 17h:36m:15s remains)
INFO - root - 2017-12-16 17:27:17.241435: step 44260, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 18h:07m:27s remains)
INFO - root - 2017-12-16 17:27:19.494509: step 44270, loss = 0.43, batch loss = 0.25 (37.0 examples/sec; 0.216 sec/batch; 17h:19m:28s remains)
INFO - root - 2017-12-16 17:27:21.706487: step 44280, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 17h:44m:16s remains)
INFO - root - 2017-12-16 17:27:23.925056: step 44290, loss = 0.54, batch loss = 0.36 (34.4 examples/sec; 0.232 sec/batch; 18h:36m:31s remains)
INFO - root - 2017-12-16 17:27:26.137643: step 44300, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 18h:19m:33s remains)
INFO - root - 2017-12-16 17:27:28.447716: step 44310, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 17h:37m:11s remains)
INFO - root - 2017-12-16 17:27:30.698153: step 44320, loss = 0.43, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 18h:11m:24s remains)
INFO - root - 2017-12-16 17:27:32.910969: step 44330, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.218 sec/batch; 17h:29m:23s remains)
INFO - root - 2017-12-16 17:27:35.075381: step 44340, loss = 0.42, batch loss = 0.24 (37.0 examples/sec; 0.216 sec/batch; 17h:17m:21s remains)
INFO - root - 2017-12-16 17:27:37.281844: step 44350, loss = 0.47, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 17h:39m:11s remains)
INFO - root - 2017-12-16 17:27:39.496137: step 44360, loss = 0.49, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 17h:30m:54s remains)
INFO - root - 2017-12-16 17:27:41.729437: step 44370, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.228 sec/batch; 18h:16m:05s remains)
INFO - root - 2017-12-16 17:27:43.934046: step 44380, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 17h:26m:38s remains)
INFO - root - 2017-12-16 17:27:46.174888: step 44390, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 18h:11m:09s remains)
INFO - root - 2017-12-16 17:27:48.413411: step 44400, loss = 0.51, batch loss = 0.33 (34.6 examples/sec; 0.231 sec/batch; 18h:30m:45s remains)
INFO - root - 2017-12-16 17:27:50.820332: step 44410, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 17h:41m:42s remains)
INFO - root - 2017-12-16 17:27:53.020512: step 44420, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 17h:45m:58s remains)
INFO - root - 2017-12-16 17:27:55.246838: step 44430, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 17h:19m:55s remains)
INFO - root - 2017-12-16 17:27:57.452126: step 44440, loss = 0.51, batch loss = 0.33 (34.9 examples/sec; 0.229 sec/batch; 18h:21m:42s remains)
INFO - root - 2017-12-16 17:27:59.646478: step 44450, loss = 0.54, batch loss = 0.36 (34.5 examples/sec; 0.232 sec/batch; 18h:32m:25s remains)
INFO - root - 2017-12-16 17:28:01.867915: step 44460, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 17h:10m:23s remains)
INFO - root - 2017-12-16 17:28:04.106209: step 44470, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 17h:17m:20s remains)
INFO - root - 2017-12-16 17:28:06.334849: step 44480, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 17h:27m:38s remains)
INFO - root - 2017-12-16 17:28:08.571915: step 44490, loss = 0.46, batch loss = 0.28 (33.1 examples/sec; 0.242 sec/batch; 19h:19m:21s remains)
INFO - root - 2017-12-16 17:28:10.791380: step 44500, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 17h:07m:42s remains)
INFO - root - 2017-12-16 17:28:13.191087: step 44510, loss = 0.52, batch loss = 0.35 (34.9 examples/sec; 0.229 sec/batch; 18h:19m:43s remains)
INFO - root - 2017-12-16 17:28:15.437620: step 44520, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 17h:53m:36s remains)
INFO - root - 2017-12-16 17:28:17.673110: step 44530, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 18h:10m:35s remains)
INFO - root - 2017-12-16 17:28:19.889935: step 44540, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 17h:33m:20s remains)
INFO - root - 2017-12-16 17:28:22.108813: step 44550, loss = 0.64, batch loss = 0.47 (37.0 examples/sec; 0.216 sec/batch; 17h:17m:50s remains)
INFO - root - 2017-12-16 17:28:24.370911: step 44560, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 17h:43m:27s remains)
INFO - root - 2017-12-16 17:28:26.601294: step 44570, loss = 0.56, batch loss = 0.38 (35.1 examples/sec; 0.228 sec/batch; 18h:12m:34s remains)
INFO - root - 2017-12-16 17:28:28.800094: step 44580, loss = 0.48, batch loss = 0.30 (34.0 examples/sec; 0.236 sec/batch; 18h:50m:41s remains)
INFO - root - 2017-12-16 17:28:31.030781: step 44590, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 17h:30m:29s remains)
INFO - root - 2017-12-16 17:28:33.222888: step 44600, loss = 0.44, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 17h:21m:29s remains)
INFO - root - 2017-12-16 17:28:35.537345: step 44610, loss = 0.50, batch loss = 0.32 (37.8 examples/sec; 0.212 sec/batch; 16h:56m:44s remains)
INFO - root - 2017-12-16 17:28:37.720467: step 44620, loss = 0.53, batch loss = 0.35 (37.4 examples/sec; 0.214 sec/batch; 17h:07m:33s remains)
INFO - root - 2017-12-16 17:28:39.976834: step 44630, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.224 sec/batch; 17h:53m:11s remains)
INFO - root - 2017-12-16 17:28:42.210746: step 44640, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 17h:21m:21s remains)
INFO - root - 2017-12-16 17:28:44.387063: step 44650, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 17h:50m:15s remains)
INFO - root - 2017-12-16 17:28:46.590192: step 44660, loss = 0.50, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 17h:39m:40s remains)
INFO - root - 2017-12-16 17:28:48.815005: step 44670, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 17h:28m:27s remains)
INFO - root - 2017-12-16 17:28:51.044721: step 44680, loss = 0.44, batch loss = 0.26 (33.4 examples/sec; 0.239 sec/batch; 19h:08m:35s remains)
INFO - root - 2017-12-16 17:28:53.279519: step 44690, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 17h:22m:01s remains)
INFO - root - 2017-12-16 17:28:55.477044: step 44700, loss = 0.55, batch loss = 0.37 (35.6 examples/sec; 0.225 sec/batch; 17h:57m:12s remains)
INFO - root - 2017-12-16 17:28:57.789337: step 44710, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 17h:25m:34s remains)
INFO - root - 2017-12-16 17:28:59.978205: step 44720, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 17h:39m:02s remains)
INFO - root - 2017-12-16 17:29:02.218484: step 44730, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 17h:38m:53s remains)
INFO - root - 2017-12-16 17:29:04.446114: step 44740, loss = 0.45, batch loss = 0.27 (34.1 examples/sec; 0.234 sec/batch; 18h:44m:34s remains)
INFO - root - 2017-12-16 17:29:06.690690: step 44750, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 17h:54m:54s remains)
INFO - root - 2017-12-16 17:29:08.910408: step 44760, loss = 0.44, batch loss = 0.27 (35.2 examples/sec; 0.228 sec/batch; 18h:11m:05s remains)
INFO - root - 2017-12-16 17:29:11.124421: step 44770, loss = 0.60, batch loss = 0.42 (36.4 examples/sec; 0.220 sec/batch; 17h:34m:45s remains)
INFO - root - 2017-12-16 17:29:13.393211: step 44780, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 17h:57m:15s remains)
INFO - root - 2017-12-16 17:29:15.626876: step 44790, loss = 0.51, batch loss = 0.33 (34.5 examples/sec; 0.232 sec/batch; 18h:30m:50s remains)
INFO - root - 2017-12-16 17:29:17.861949: step 44800, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 17h:52m:23s remains)
INFO - root - 2017-12-16 17:29:20.181672: step 44810, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 17h:39m:27s remains)
INFO - root - 2017-12-16 17:29:22.413303: step 44820, loss = 0.46, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 18h:01m:20s remains)
INFO - root - 2017-12-16 17:29:24.661877: step 44830, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 17h:51m:19s remains)
INFO - root - 2017-12-16 17:29:26.843666: step 44840, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 17h:16m:28s remains)
INFO - root - 2017-12-16 17:29:29.035360: step 44850, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 17h:50m:31s remains)
INFO - root - 2017-12-16 17:29:31.213488: step 44860, loss = 0.56, batch loss = 0.38 (36.6 examples/sec; 0.218 sec/batch; 17h:27m:28s remains)
INFO - root - 2017-12-16 17:29:33.418588: step 44870, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 18h:08m:56s remains)
INFO - root - 2017-12-16 17:29:35.636118: step 44880, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 18h:01m:02s remains)
INFO - root - 2017-12-16 17:29:37.878382: step 44890, loss = 0.47, batch loss = 0.29 (33.4 examples/sec; 0.239 sec/batch; 19h:06m:55s remains)
INFO - root - 2017-12-16 17:29:40.108217: step 44900, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 17h:27m:25s remains)
INFO - root - 2017-12-16 17:29:42.474454: step 44910, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 17h:44m:07s remains)
INFO - root - 2017-12-16 17:29:44.710210: step 44920, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.214 sec/batch; 17h:03m:19s remains)
INFO - root - 2017-12-16 17:29:46.925641: step 44930, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 17h:08m:43s remains)
INFO - root - 2017-12-16 17:29:49.148814: step 44940, loss = 0.47, batch loss = 0.29 (37.9 examples/sec; 0.211 sec/batch; 16h:51m:16s remains)
INFO - root - 2017-12-16 17:29:51.381506: step 44950, loss = 0.48, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 17h:56m:04s remains)
INFO - root - 2017-12-16 17:29:53.617391: step 44960, loss = 0.43, batch loss = 0.25 (33.0 examples/sec; 0.242 sec/batch; 19h:21m:28s remains)
INFO - root - 2017-12-16 17:29:55.858113: step 44970, loss = 0.46, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 17h:39m:41s remains)
INFO - root - 2017-12-16 17:29:58.077642: step 44980, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 17h:07m:08s remains)
INFO - root - 2017-12-16 17:30:00.318469: step 44990, loss = 0.43, batch loss = 0.25 (34.4 examples/sec; 0.233 sec/batch; 18h:35m:31s remains)
INFO - root - 2017-12-16 17:30:02.526044: step 45000, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 17h:16m:22s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-45000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-45000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 17:30:05.297204: step 45010, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 17h:32m:27s remains)
INFO - root - 2017-12-16 17:30:07.520544: step 45020, loss = 0.42, batch loss = 0.24 (35.9 examples/sec; 0.223 sec/batch; 17h:48m:17s remains)
INFO - root - 2017-12-16 17:30:09.710427: step 45030, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 18h:06m:32s remains)
INFO - root - 2017-12-16 17:30:11.942730: step 45040, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 17h:43m:47s remains)
INFO - root - 2017-12-16 17:30:14.166765: step 45050, loss = 0.49, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 17h:08m:10s remains)
INFO - root - 2017-12-16 17:30:16.382659: step 45060, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 17h:31m:18s remains)
INFO - root - 2017-12-16 17:30:18.586607: step 45070, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 17h:08m:49s remains)
INFO - root - 2017-12-16 17:30:20.807764: step 45080, loss = 0.50, batch loss = 0.32 (37.8 examples/sec; 0.211 sec/batch; 16h:52m:38s remains)
INFO - root - 2017-12-16 17:30:23.042311: step 45090, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 17h:21m:56s remains)
INFO - root - 2017-12-16 17:30:25.283425: step 45100, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 17h:39m:38s remains)
INFO - root - 2017-12-16 17:30:27.637467: step 45110, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 17h:42m:15s remains)
INFO - root - 2017-12-16 17:30:29.837811: step 45120, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 17h:06m:40s remains)
INFO - root - 2017-12-16 17:30:32.078149: step 45130, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 17h:30m:50s remains)
INFO - root - 2017-12-16 17:30:34.284327: step 45140, loss = 0.52, batch loss = 0.34 (37.8 examples/sec; 0.212 sec/batch; 16h:54m:48s remains)
INFO - root - 2017-12-16 17:30:36.498247: step 45150, loss = 0.46, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 18h:00m:11s remains)
INFO - root - 2017-12-16 17:30:38.722963: step 45160, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 17h:54m:16s remains)
INFO - root - 2017-12-16 17:30:40.966003: step 45170, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 18h:26m:41s remains)
INFO - root - 2017-12-16 17:30:43.180737: step 45180, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 18h:11m:04s remains)
INFO - root - 2017-12-16 17:30:45.415818: step 45190, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 17h:57m:18s remains)
INFO - root - 2017-12-16 17:30:47.623182: step 45200, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 17h:41m:51s remains)
INFO - root - 2017-12-16 17:30:49.995812: step 45210, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 18h:15m:26s remains)
INFO - root - 2017-12-16 17:30:52.216602: step 45220, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 18h:02m:43s remains)
INFO - root - 2017-12-16 17:30:54.420112: step 45230, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 17h:37m:28s remains)
INFO - root - 2017-12-16 17:30:56.644471: step 45240, loss = 0.57, batch loss = 0.39 (36.4 examples/sec; 0.220 sec/batch; 17h:32m:10s remains)
INFO - root - 2017-12-16 17:30:58.804936: step 45250, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 16h:55m:44s remains)
INFO - root - 2017-12-16 17:31:01.022094: step 45260, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 17h:04m:02s remains)
INFO - root - 2017-12-16 17:31:03.270660: step 45270, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 17h:35m:44s remains)
INFO - root - 2017-12-16 17:31:05.474513: step 45280, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.218 sec/batch; 17h:21m:20s remains)
INFO - root - 2017-12-16 17:31:07.670783: step 45290, loss = 0.41, batch loss = 0.24 (37.0 examples/sec; 0.216 sec/batch; 17h:15m:14s remains)
INFO - root - 2017-12-16 17:31:09.909474: step 45300, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 17h:57m:26s remains)
INFO - root - 2017-12-16 17:31:12.286451: step 45310, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.226 sec/batch; 17h:59m:50s remains)
INFO - root - 2017-12-16 17:31:14.482017: step 45320, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 17h:59m:11s remains)
INFO - root - 2017-12-16 17:31:16.709943: step 45330, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 17h:49m:47s remains)
INFO - root - 2017-12-16 17:31:18.921472: step 45340, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 17h:40m:36s remains)
INFO - root - 2017-12-16 17:31:21.111012: step 45350, loss = 0.55, batch loss = 0.37 (37.4 examples/sec; 0.214 sec/batch; 17h:03m:44s remains)
INFO - root - 2017-12-16 17:31:23.325706: step 45360, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 17h:20m:31s remains)
INFO - root - 2017-12-16 17:31:25.510377: step 45370, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 17h:18m:32s remains)
INFO - root - 2017-12-16 17:31:27.741498: step 45380, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 17h:53m:07s remains)
INFO - root - 2017-12-16 17:31:29.954948: step 45390, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 18h:07m:01s remains)
INFO - root - 2017-12-16 17:31:32.166505: step 45400, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 17h:25m:48s remains)
INFO - root - 2017-12-16 17:31:34.535619: step 45410, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 17h:19m:57s remains)
INFO - root - 2017-12-16 17:31:36.743873: step 45420, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 17h:48m:03s remains)
INFO - root - 2017-12-16 17:31:38.959826: step 45430, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 17h:28m:19s remains)
INFO - root - 2017-12-16 17:31:41.191952: step 45440, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 17h:57m:04s remains)
INFO - root - 2017-12-16 17:31:43.414765: step 45450, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 17h:26m:02s remains)
INFO - root - 2017-12-16 17:31:45.609314: step 45460, loss = 0.45, batch loss = 0.27 (38.3 examples/sec; 0.209 sec/batch; 16h:39m:18s remains)
INFO - root - 2017-12-16 17:31:47.867797: step 45470, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 18h:06m:53s remains)
INFO - root - 2017-12-16 17:31:50.128684: step 45480, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 17h:35m:00s remains)
INFO - root - 2017-12-16 17:31:52.377133: step 45490, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.214 sec/batch; 17h:04m:56s remains)
INFO - root - 2017-12-16 17:31:54.583315: step 45500, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 17h:18m:49s remains)
INFO - root - 2017-12-16 17:31:56.927677: step 45510, loss = 0.56, batch loss = 0.38 (36.3 examples/sec; 0.221 sec/batch; 17h:35m:27s remains)
INFO - root - 2017-12-16 17:31:59.130178: step 45520, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.224 sec/batch; 17h:49m:57s remains)
INFO - root - 2017-12-16 17:32:01.371013: step 45530, loss = 0.50, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 18h:18m:04s remains)
INFO - root - 2017-12-16 17:32:03.581429: step 45540, loss = 0.57, batch loss = 0.39 (38.0 examples/sec; 0.210 sec/batch; 16h:46m:32s remains)
INFO - root - 2017-12-16 17:32:05.789376: step 45550, loss = 0.46, batch loss = 0.28 (37.7 examples/sec; 0.212 sec/batch; 16h:54m:45s remains)
INFO - root - 2017-12-16 17:32:08.040101: step 45560, loss = 0.45, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 17h:22m:53s remains)
INFO - root - 2017-12-16 17:32:10.239447: step 45570, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.221 sec/batch; 17h:34m:31s remains)
INFO - root - 2017-12-16 17:32:12.442551: step 45580, loss = 0.56, batch loss = 0.38 (36.4 examples/sec; 0.220 sec/batch; 17h:32m:25s remains)
INFO - root - 2017-12-16 17:32:14.646049: step 45590, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 17h:16m:05s remains)
INFO - root - 2017-12-16 17:32:16.869599: step 45600, loss = 0.54, batch loss = 0.36 (37.2 examples/sec; 0.215 sec/batch; 17h:07m:54s remains)
INFO - root - 2017-12-16 17:32:19.197995: step 45610, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 17h:49m:27s remains)
INFO - root - 2017-12-16 17:32:21.409062: step 45620, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 17h:27m:41s remains)
INFO - root - 2017-12-16 17:32:23.642923: step 45630, loss = 0.50, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 18h:15m:24s remains)
INFO - root - 2017-12-16 17:32:25.829809: step 45640, loss = 0.44, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 17h:20m:32s remains)
INFO - root - 2017-12-16 17:32:28.032642: step 45650, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 17h:49m:14s remains)
INFO - root - 2017-12-16 17:32:30.223470: step 45660, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 17h:50m:55s remains)
INFO - root - 2017-12-16 17:32:32.400738: step 45670, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 17h:17m:29s remains)
INFO - root - 2017-12-16 17:32:34.658879: step 45680, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 17h:08m:50s remains)
INFO - root - 2017-12-16 17:32:36.862383: step 45690, loss = 0.49, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 17h:40m:18s remains)
INFO - root - 2017-12-16 17:32:39.057039: step 45700, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 17h:21m:53s remains)
INFO - root - 2017-12-16 17:32:41.401718: step 45710, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 17h:17m:46s remains)
INFO - root - 2017-12-16 17:32:43.597481: step 45720, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 17h:23m:07s remains)
INFO - root - 2017-12-16 17:32:45.787261: step 45730, loss = 0.43, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 17h:02m:47s remains)
INFO - root - 2017-12-16 17:32:48.027333: step 45740, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 17h:56m:55s remains)
INFO - root - 2017-12-16 17:32:50.256890: step 45750, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 17h:38m:49s remains)
INFO - root - 2017-12-16 17:32:52.495870: step 45760, loss = 0.53, batch loss = 0.35 (34.8 examples/sec; 0.230 sec/batch; 18h:17m:58s remains)
INFO - root - 2017-12-16 17:32:54.724900: step 45770, loss = 0.42, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 17h:51m:12s remains)
INFO - root - 2017-12-16 17:32:56.954962: step 45780, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 18h:29m:34s remains)
INFO - root - 2017-12-16 17:32:59.175934: step 45790, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 17h:39m:22s remains)
INFO - root - 2017-12-16 17:33:01.424399: step 45800, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 17h:54m:46s remains)
INFO - root - 2017-12-16 17:33:03.801601: step 45810, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 17h:33m:51s remains)
INFO - root - 2017-12-16 17:33:06.008484: step 45820, loss = 0.45, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 17h:21m:04s remains)
INFO - root - 2017-12-16 17:33:08.207518: step 45830, loss = 0.44, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 17h:57m:27s remains)
INFO - root - 2017-12-16 17:33:10.403559: step 45840, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.219 sec/batch; 17h:28m:37s remains)
INFO - root - 2017-12-16 17:33:12.619415: step 45850, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 17h:28m:27s remains)
INFO - root - 2017-12-16 17:33:14.851511: step 45860, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 17h:31m:48s remains)
INFO - root - 2017-12-16 17:33:17.039920: step 45870, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 17h:29m:06s remains)
INFO - root - 2017-12-16 17:33:19.264260: step 45880, loss = 0.48, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 17h:13m:22s remains)
INFO - root - 2017-12-16 17:33:21.506516: step 45890, loss = 0.57, batch loss = 0.39 (37.3 examples/sec; 0.214 sec/batch; 17h:03m:18s remains)
INFO - root - 2017-12-16 17:33:23.752801: step 45900, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 18h:09m:31s remains)
INFO - root - 2017-12-16 17:33:26.114277: step 45910, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 17h:53m:04s remains)
INFO - root - 2017-12-16 17:33:28.322486: step 45920, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.226 sec/batch; 18h:01m:09s remains)
INFO - root - 2017-12-16 17:33:30.545640: step 45930, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 17h:46m:54s remains)
INFO - root - 2017-12-16 17:33:32.780973: step 45940, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 17h:29m:50s remains)
INFO - root - 2017-12-16 17:33:35.024809: step 45950, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 17h:18m:57s remains)
INFO - root - 2017-12-16 17:33:37.229035: step 45960, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 17h:53m:53s remains)
INFO - root - 2017-12-16 17:33:39.421555: step 45970, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 17h:25m:26s remains)
INFO - root - 2017-12-16 17:33:41.620108: step 45980, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 17h:12m:49s remains)
INFO - root - 2017-12-16 17:33:43.831269: step 45990, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 17h:14m:12s remains)
INFO - root - 2017-12-16 17:33:46.052898: step 46000, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 17h:26m:25s remains)
INFO - root - 2017-12-16 17:33:48.410313: step 46010, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 17h:12m:30s remains)
INFO - root - 2017-12-16 17:33:50.617151: step 46020, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 17h:13m:15s remains)
INFO - root - 2017-12-16 17:33:52.847365: step 46030, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 18h:02m:01s remains)
INFO - root - 2017-12-16 17:33:55.063296: step 46040, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 17h:45m:54s remains)
INFO - root - 2017-12-16 17:33:57.283172: step 46050, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 17h:17m:38s remains)
INFO - root - 2017-12-16 17:33:59.519129: step 46060, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 17h:10m:36s remains)
INFO - root - 2017-12-16 17:34:01.730985: step 46070, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 17h:30m:42s remains)
INFO - root - 2017-12-16 17:34:03.959355: step 46080, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 17h:58m:25s remains)
INFO - root - 2017-12-16 17:34:06.181625: step 46090, loss = 0.56, batch loss = 0.38 (35.0 examples/sec; 0.229 sec/batch; 18h:12m:14s remains)
INFO - root - 2017-12-16 17:34:08.388438: step 46100, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 17h:25m:27s remains)
INFO - root - 2017-12-16 17:34:10.735809: step 46110, loss = 0.44, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 17h:13m:01s remains)
INFO - root - 2017-12-16 17:34:12.954453: step 46120, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 17h:53m:11s remains)
INFO - root - 2017-12-16 17:34:15.190139: step 46130, loss = 0.53, batch loss = 0.35 (35.0 examples/sec; 0.229 sec/batch; 18h:10m:41s remains)
INFO - root - 2017-12-16 17:34:17.400857: step 46140, loss = 0.54, batch loss = 0.36 (37.3 examples/sec; 0.214 sec/batch; 17h:03m:11s remains)
INFO - root - 2017-12-16 17:34:19.633090: step 46150, loss = 0.48, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 18h:16m:35s remains)
INFO - root - 2017-12-16 17:34:21.842801: step 46160, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 17h:16m:57s remains)
INFO - root - 2017-12-16 17:34:24.106273: step 46170, loss = 0.41, batch loss = 0.23 (36.9 examples/sec; 0.217 sec/batch; 17h:13m:59s remains)
INFO - root - 2017-12-16 17:34:26.307926: step 46180, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 17h:44m:53s remains)
INFO - root - 2017-12-16 17:34:28.530778: step 46190, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 17h:29m:47s remains)
INFO - root - 2017-12-16 17:34:30.740116: step 46200, loss = 0.41, batch loss = 0.23 (37.3 examples/sec; 0.214 sec/batch; 17h:03m:20s remains)
INFO - root - 2017-12-16 17:34:33.085089: step 46210, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 17h:23m:26s remains)
INFO - root - 2017-12-16 17:34:35.321164: step 46220, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 18h:05m:18s remains)
INFO - root - 2017-12-16 17:34:37.533172: step 46230, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 17h:06m:39s remains)
INFO - root - 2017-12-16 17:34:39.746628: step 46240, loss = 0.48, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 17h:41m:57s remains)
INFO - root - 2017-12-16 17:34:41.934028: step 46250, loss = 0.42, batch loss = 0.24 (36.5 examples/sec; 0.219 sec/batch; 17h:24m:25s remains)
INFO - root - 2017-12-16 17:34:44.132521: step 46260, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 17h:18m:29s remains)
INFO - root - 2017-12-16 17:34:46.342270: step 46270, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 17h:30m:05s remains)
INFO - root - 2017-12-16 17:34:48.535708: step 46280, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 18h:01m:28s remains)
INFO - root - 2017-12-16 17:34:50.821456: step 46290, loss = 0.45, batch loss = 0.27 (33.9 examples/sec; 0.236 sec/batch; 18h:45m:58s remains)
INFO - root - 2017-12-16 17:34:53.018427: step 46300, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 17h:59m:07s remains)
INFO - root - 2017-12-16 17:34:55.380621: step 46310, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 18h:27m:26s remains)
INFO - root - 2017-12-16 17:34:57.581326: step 46320, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 17h:26m:38s remains)
INFO - root - 2017-12-16 17:34:59.778043: step 46330, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 17h:37m:26s remains)
INFO - root - 2017-12-16 17:35:01.984900: step 46340, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 17h:26m:18s remains)
INFO - root - 2017-12-16 17:35:04.201086: step 46350, loss = 0.53, batch loss = 0.35 (38.0 examples/sec; 0.211 sec/batch; 16h:44m:56s remains)
INFO - root - 2017-12-16 17:35:06.465068: step 46360, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 17h:49m:02s remains)
INFO - root - 2017-12-16 17:35:08.672647: step 46370, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 17h:24m:32s remains)
INFO - root - 2017-12-16 17:35:10.917075: step 46380, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 17h:18m:51s remains)
INFO - root - 2017-12-16 17:35:13.127533: step 46390, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.233 sec/batch; 18h:29m:31s remains)
INFO - root - 2017-12-16 17:35:15.378987: step 46400, loss = 0.50, batch loss = 0.32 (35.0 examples/sec; 0.229 sec/batch; 18h:10m:50s remains)
INFO - root - 2017-12-16 17:35:17.737508: step 46410, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 17h:01m:26s remains)
INFO - root - 2017-12-16 17:35:19.935410: step 46420, loss = 0.46, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 17h:18m:31s remains)
INFO - root - 2017-12-16 17:35:22.149437: step 46430, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 17h:35m:26s remains)
INFO - root - 2017-12-16 17:35:24.372598: step 46440, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 17h:41m:47s remains)
INFO - root - 2017-12-16 17:35:26.603388: step 46450, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 17h:12m:04s remains)
INFO - root - 2017-12-16 17:35:28.805524: step 46460, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 17h:10m:52s remains)
INFO - root - 2017-12-16 17:35:31.033737: step 46470, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 17h:32m:11s remains)
INFO - root - 2017-12-16 17:35:33.235163: step 46480, loss = 0.49, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 17h:51m:16s remains)
INFO - root - 2017-12-16 17:35:35.470844: step 46490, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 17h:47m:04s remains)
INFO - root - 2017-12-16 17:35:37.692078: step 46500, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 17h:38m:01s remains)
INFO - root - 2017-12-16 17:35:40.042948: step 46510, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 17h:42m:54s remains)
INFO - root - 2017-12-16 17:35:42.284275: step 46520, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 17h:28m:44s remains)
INFO - root - 2017-12-16 17:35:44.476066: step 46530, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 17h:12m:24s remains)
INFO - root - 2017-12-16 17:35:46.743828: step 46540, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.229 sec/batch; 18h:10m:34s remains)
INFO - root - 2017-12-16 17:35:48.972731: step 46550, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 17h:13m:36s remains)
INFO - root - 2017-12-16 17:35:51.161512: step 46560, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 17h:12m:29s remains)
INFO - root - 2017-12-16 17:35:53.362122: step 46570, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.219 sec/batch; 17h:25m:59s remains)
INFO - root - 2017-12-16 17:35:55.552291: step 46580, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 17h:39m:29s remains)
INFO - root - 2017-12-16 17:35:57.796040: step 46590, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 18h:12m:25s remains)
INFO - root - 2017-12-16 17:36:00.003144: step 46600, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 17h:27m:14s remains)
INFO - root - 2017-12-16 17:36:02.363259: step 46610, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 17h:54m:12s remains)
INFO - root - 2017-12-16 17:36:04.549766: step 46620, loss = 0.56, batch loss = 0.39 (36.9 examples/sec; 0.217 sec/batch; 17h:14m:22s remains)
INFO - root - 2017-12-16 17:36:06.749526: step 46630, loss = 0.49, batch loss = 0.32 (34.9 examples/sec; 0.230 sec/batch; 18h:13m:39s remains)
INFO - root - 2017-12-16 17:36:08.975768: step 46640, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 16h:53m:15s remains)
INFO - root - 2017-12-16 17:36:11.211648: step 46650, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 18h:11m:24s remains)
INFO - root - 2017-12-16 17:36:13.464183: step 46660, loss = 0.46, batch loss = 0.28 (33.7 examples/sec; 0.237 sec/batch; 18h:49m:53s remains)
INFO - root - 2017-12-16 17:36:15.714833: step 46670, loss = 0.47, batch loss = 0.29 (33.3 examples/sec; 0.240 sec/batch; 19h:04m:48s remains)
INFO - root - 2017-12-16 17:36:17.974700: step 46680, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 17h:22m:48s remains)
INFO - root - 2017-12-16 17:36:20.215338: step 46690, loss = 0.44, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 18h:23m:59s remains)
INFO - root - 2017-12-16 17:36:22.419816: step 46700, loss = 0.45, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 17h:28m:18s remains)
INFO - root - 2017-12-16 17:36:24.788350: step 46710, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 17h:25m:40s remains)
INFO - root - 2017-12-16 17:36:26.977193: step 46720, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 17h:18m:11s remains)
INFO - root - 2017-12-16 17:36:29.177920: step 46730, loss = 0.58, batch loss = 0.40 (38.0 examples/sec; 0.210 sec/batch; 16h:41m:53s remains)
INFO - root - 2017-12-16 17:36:31.373411: step 46740, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 17h:20m:42s remains)
INFO - root - 2017-12-16 17:36:33.555976: step 46750, loss = 0.44, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 18h:02m:13s remains)
INFO - root - 2017-12-16 17:36:35.780548: step 46760, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 18h:09m:26s remains)
INFO - root - 2017-12-16 17:36:37.983500: step 46770, loss = 0.52, batch loss = 0.34 (37.5 examples/sec; 0.213 sec/batch; 16h:54m:58s remains)
INFO - root - 2017-12-16 17:36:40.236380: step 46780, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 17h:14m:43s remains)
INFO - root - 2017-12-16 17:36:42.475550: step 46790, loss = 0.44, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 17h:03m:37s remains)
INFO - root - 2017-12-16 17:36:44.713842: step 46800, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 17h:01m:36s remains)
INFO - root - 2017-12-16 17:36:47.045165: step 46810, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 17h:46m:37s remains)
INFO - root - 2017-12-16 17:36:49.269631: step 46820, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 17h:42m:48s remains)
INFO - root - 2017-12-16 17:36:51.543932: step 46830, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 17h:52m:34s remains)
INFO - root - 2017-12-16 17:36:53.771667: step 46840, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 17h:43m:50s remains)
INFO - root - 2017-12-16 17:36:56.002386: step 46850, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 18h:12m:36s remains)
INFO - root - 2017-12-16 17:36:58.201656: step 46860, loss = 0.49, batch loss = 0.31 (38.1 examples/sec; 0.210 sec/batch; 16h:38m:21s remains)
INFO - root - 2017-12-16 17:37:00.437120: step 46870, loss = 0.54, batch loss = 0.36 (34.9 examples/sec; 0.229 sec/batch; 18h:10m:42s remains)
INFO - root - 2017-12-16 17:37:02.654717: step 46880, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 17h:35m:38s remains)
INFO - root - 2017-12-16 17:37:04.854839: step 46890, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.224 sec/batch; 17h:48m:18s remains)
INFO - root - 2017-12-16 17:37:07.105407: step 46900, loss = 0.49, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 17h:42m:44s remains)
INFO - root - 2017-12-16 17:37:09.431533: step 46910, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 17h:05m:57s remains)
INFO - root - 2017-12-16 17:37:11.642835: step 46920, loss = 0.47, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 17h:29m:04s remains)
INFO - root - 2017-12-16 17:37:13.879786: step 46930, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 17h:13m:04s remains)
INFO - root - 2017-12-16 17:37:16.084642: step 46940, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 17h:12m:04s remains)
INFO - root - 2017-12-16 17:37:18.320228: step 46950, loss = 0.54, batch loss = 0.36 (33.8 examples/sec; 0.237 sec/batch; 18h:46m:52s remains)
INFO - root - 2017-12-16 17:37:20.542728: step 46960, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 17h:20m:06s remains)
INFO - root - 2017-12-16 17:37:22.748767: step 46970, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 17h:46m:58s remains)
INFO - root - 2017-12-16 17:37:24.965924: step 46980, loss = 0.56, batch loss = 0.38 (34.7 examples/sec; 0.230 sec/batch; 18h:16m:40s remains)
INFO - root - 2017-12-16 17:37:27.193447: step 46990, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 17h:55m:58s remains)
INFO - root - 2017-12-16 17:37:29.400996: step 47000, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 17h:50m:47s remains)
INFO - root - 2017-12-16 17:37:31.793065: step 47010, loss = 0.49, batch loss = 0.31 (33.7 examples/sec; 0.238 sec/batch; 18h:50m:37s remains)
INFO - root - 2017-12-16 17:37:33.994166: step 47020, loss = 0.55, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 17h:26m:50s remains)
INFO - root - 2017-12-16 17:37:36.227051: step 47030, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 17h:54m:51s remains)
INFO - root - 2017-12-16 17:37:38.492463: step 47040, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.231 sec/batch; 18h:21m:14s remains)
INFO - root - 2017-12-16 17:37:40.672386: step 47050, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 17h:35m:02s remains)
INFO - root - 2017-12-16 17:37:42.928329: step 47060, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 18h:11m:45s remains)
INFO - root - 2017-12-16 17:37:45.146029: step 47070, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 17h:44m:27s remains)
INFO - root - 2017-12-16 17:37:47.385664: step 47080, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 17h:55m:16s remains)
INFO - root - 2017-12-16 17:37:49.569367: step 47090, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 16h:59m:02s remains)
INFO - root - 2017-12-16 17:37:51.777151: step 47100, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.228 sec/batch; 18h:06m:37s remains)
INFO - root - 2017-12-16 17:37:54.152767: step 47110, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 17h:09m:38s remains)
INFO - root - 2017-12-16 17:37:56.395621: step 47120, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 17h:07m:27s remains)
INFO - root - 2017-12-16 17:37:58.616676: step 47130, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 17h:20m:06s remains)
INFO - root - 2017-12-16 17:38:00.882956: step 47140, loss = 0.41, batch loss = 0.23 (35.2 examples/sec; 0.227 sec/batch; 17h:59m:32s remains)
INFO - root - 2017-12-16 17:38:03.099962: step 47150, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 17h:53m:42s remains)
INFO - root - 2017-12-16 17:38:05.311152: step 47160, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 17h:43m:36s remains)
INFO - root - 2017-12-16 17:38:07.530530: step 47170, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 18h:03m:46s remains)
INFO - root - 2017-12-16 17:38:09.767467: step 47180, loss = 0.61, batch loss = 0.43 (37.3 examples/sec; 0.214 sec/batch; 16h:59m:49s remains)
INFO - root - 2017-12-16 17:38:12.042249: step 47190, loss = 0.50, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 17h:50m:29s remains)
INFO - root - 2017-12-16 17:38:14.224780: step 47200, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 17h:23m:26s remains)
INFO - root - 2017-12-16 17:38:16.557725: step 47210, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 18h:01m:37s remains)
INFO - root - 2017-12-16 17:38:18.744631: step 47220, loss = 0.46, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 17h:58m:26s remains)
INFO - root - 2017-12-16 17:38:20.975048: step 47230, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 17h:51m:16s remains)
INFO - root - 2017-12-16 17:38:23.206703: step 47240, loss = 0.41, batch loss = 0.23 (37.0 examples/sec; 0.216 sec/batch; 17h:08m:03s remains)
INFO - root - 2017-12-16 17:38:25.429765: step 47250, loss = 0.45, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 17h:29m:36s remains)
INFO - root - 2017-12-16 17:38:27.641272: step 47260, loss = 0.58, batch loss = 0.40 (36.7 examples/sec; 0.218 sec/batch; 17h:15m:13s remains)
INFO - root - 2017-12-16 17:38:29.854373: step 47270, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 17h:02m:50s remains)
INFO - root - 2017-12-16 17:38:32.103108: step 47280, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 17h:57m:29s remains)
INFO - root - 2017-12-16 17:38:34.315068: step 47290, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 17h:09m:00s remains)
INFO - root - 2017-12-16 17:38:36.503625: step 47300, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 16h:55m:52s remains)
INFO - root - 2017-12-16 17:38:38.817254: step 47310, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.214 sec/batch; 16h:55m:12s remains)
INFO - root - 2017-12-16 17:38:40.974672: step 47320, loss = 0.63, batch loss = 0.45 (37.5 examples/sec; 0.213 sec/batch; 16h:53m:01s remains)
INFO - root - 2017-12-16 17:38:43.200069: step 47330, loss = 0.43, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 17h:51m:41s remains)
INFO - root - 2017-12-16 17:38:45.391392: step 47340, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 17h:29m:10s remains)
INFO - root - 2017-12-16 17:38:47.581158: step 47350, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 17h:12m:23s remains)
INFO - root - 2017-12-16 17:38:49.802316: step 47360, loss = 0.48, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 17h:13m:17s remains)
INFO - root - 2017-12-16 17:38:51.962235: step 47370, loss = 0.50, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 17h:27m:28s remains)
INFO - root - 2017-12-16 17:38:54.175342: step 47380, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 17h:53m:49s remains)
INFO - root - 2017-12-16 17:38:56.358925: step 47390, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 17h:01m:24s remains)
INFO - root - 2017-12-16 17:38:58.607859: step 47400, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 17h:23m:44s remains)
INFO - root - 2017-12-16 17:39:00.939002: step 47410, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 17h:14m:31s remains)
INFO - root - 2017-12-16 17:39:03.144734: step 47420, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 17h:43m:33s remains)
INFO - root - 2017-12-16 17:39:05.353703: step 47430, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 17h:02m:16s remains)
INFO - root - 2017-12-16 17:39:07.614641: step 47440, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 18h:10m:56s remains)
INFO - root - 2017-12-16 17:39:09.799032: step 47450, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 16h:53m:35s remains)
INFO - root - 2017-12-16 17:39:12.035128: step 47460, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 18h:10m:44s remains)
INFO - root - 2017-12-16 17:39:14.288956: step 47470, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 17h:35m:00s remains)
INFO - root - 2017-12-16 17:39:16.509793: step 47480, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 17h:26m:40s remains)
INFO - root - 2017-12-16 17:39:18.729114: step 47490, loss = 0.54, batch loss = 0.37 (36.6 examples/sec; 0.219 sec/batch; 17h:18m:04s remains)
INFO - root - 2017-12-16 17:39:20.915174: step 47500, loss = 0.48, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 17h:02m:30s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-47500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-47500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 17:39:23.973444: step 47510, loss = 0.53, batch loss = 0.35 (34.5 examples/sec; 0.232 sec/batch; 18h:20m:54s remains)
INFO - root - 2017-12-16 17:39:26.152051: step 47520, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.221 sec/batch; 17h:27m:36s remains)
INFO - root - 2017-12-16 17:39:28.407865: step 47530, loss = 0.43, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 17h:56m:59s remains)
INFO - root - 2017-12-16 17:39:30.624479: step 47540, loss = 0.49, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 17h:00m:22s remains)
INFO - root - 2017-12-16 17:39:32.812985: step 47550, loss = 0.48, batch loss = 0.30 (34.0 examples/sec; 0.235 sec/batch; 18h:37m:02s remains)
INFO - root - 2017-12-16 17:39:35.003755: step 47560, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 17h:27m:12s remains)
INFO - root - 2017-12-16 17:39:37.242850: step 47570, loss = 0.46, batch loss = 0.28 (33.6 examples/sec; 0.238 sec/batch; 18h:50m:25s remains)
INFO - root - 2017-12-16 17:39:39.521971: step 47580, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 18h:17m:55s remains)
INFO - root - 2017-12-16 17:39:41.707688: step 47590, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 17h:16m:39s remains)
INFO - root - 2017-12-16 17:39:43.916815: step 47600, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 16h:56m:47s remains)
INFO - root - 2017-12-16 17:39:46.264346: step 47610, loss = 0.45, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 17h:48m:12s remains)
INFO - root - 2017-12-16 17:39:48.506631: step 47620, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 17h:12m:29s remains)
INFO - root - 2017-12-16 17:39:50.690454: step 47630, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 17h:48m:20s remains)
INFO - root - 2017-12-16 17:39:52.872066: step 47640, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 17h:01m:02s remains)
INFO - root - 2017-12-16 17:39:55.059403: step 47650, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 17h:44m:53s remains)
INFO - root - 2017-12-16 17:39:57.271015: step 47660, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 17h:35m:12s remains)
INFO - root - 2017-12-16 17:39:59.475350: step 47670, loss = 0.50, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 17h:49m:24s remains)
INFO - root - 2017-12-16 17:40:01.661743: step 47680, loss = 0.41, batch loss = 0.24 (37.1 examples/sec; 0.215 sec/batch; 17h:02m:41s remains)
INFO - root - 2017-12-16 17:40:03.858159: step 47690, loss = 0.42, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 17h:12m:01s remains)
INFO - root - 2017-12-16 17:40:06.035954: step 47700, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 17h:28m:29s remains)
INFO - root - 2017-12-16 17:40:08.379181: step 47710, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 17h:59m:32s remains)
INFO - root - 2017-12-16 17:40:10.554098: step 47720, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 17h:08m:54s remains)
INFO - root - 2017-12-16 17:40:12.771102: step 47730, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 17h:37m:41s remains)
INFO - root - 2017-12-16 17:40:14.963794: step 47740, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 17h:44m:13s remains)
INFO - root - 2017-12-16 17:40:17.146606: step 47750, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 17h:11m:39s remains)
INFO - root - 2017-12-16 17:40:19.339122: step 47760, loss = 0.40, batch loss = 0.22 (35.8 examples/sec; 0.223 sec/batch; 17h:39m:47s remains)
INFO - root - 2017-12-16 17:40:21.559046: step 47770, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 17h:01m:46s remains)
INFO - root - 2017-12-16 17:40:23.773971: step 47780, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 18h:01m:10s remains)
INFO - root - 2017-12-16 17:40:25.998817: step 47790, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 17h:26m:48s remains)
INFO - root - 2017-12-16 17:40:28.253698: step 47800, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 17h:49m:08s remains)
INFO - root - 2017-12-16 17:40:30.595759: step 47810, loss = 0.55, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 17h:19m:10s remains)
INFO - root - 2017-12-16 17:40:32.790588: step 47820, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 17h:28m:41s remains)
INFO - root - 2017-12-16 17:40:34.992380: step 47830, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 16h:51m:34s remains)
INFO - root - 2017-12-16 17:40:37.192170: step 47840, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 16h:58m:52s remains)
INFO - root - 2017-12-16 17:40:39.383358: step 47850, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 17h:17m:42s remains)
INFO - root - 2017-12-16 17:40:41.619113: step 47860, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 17h:43m:52s remains)
INFO - root - 2017-12-16 17:40:43.847330: step 47870, loss = 0.49, batch loss = 0.32 (35.3 examples/sec; 0.226 sec/batch; 17h:53m:48s remains)
INFO - root - 2017-12-16 17:40:46.068612: step 47880, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 17h:57m:48s remains)
INFO - root - 2017-12-16 17:40:48.259083: step 47890, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 16h:59m:26s remains)
INFO - root - 2017-12-16 17:40:50.444495: step 47900, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 17h:57m:04s remains)
INFO - root - 2017-12-16 17:40:52.786522: step 47910, loss = 0.51, batch loss = 0.33 (34.3 examples/sec; 0.233 sec/batch; 18h:25m:46s remains)
INFO - root - 2017-12-16 17:40:55.026790: step 47920, loss = 0.52, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 16h:59m:25s remains)
INFO - root - 2017-12-16 17:40:57.214212: step 47930, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 17h:17m:23s remains)
INFO - root - 2017-12-16 17:40:59.426802: step 47940, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 17h:35m:39s remains)
INFO - root - 2017-12-16 17:41:01.595887: step 47950, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 16h:55m:58s remains)
INFO - root - 2017-12-16 17:41:03.794567: step 47960, loss = 0.49, batch loss = 0.31 (37.8 examples/sec; 0.212 sec/batch; 16h:43m:32s remains)
INFO - root - 2017-12-16 17:41:06.012926: step 47970, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 17h:22m:56s remains)
INFO - root - 2017-12-16 17:41:08.240656: step 47980, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 17h:31m:00s remains)
INFO - root - 2017-12-16 17:41:10.428958: step 47990, loss = 0.43, batch loss = 0.25 (37.5 examples/sec; 0.213 sec/batch; 16h:50m:44s remains)
INFO - root - 2017-12-16 17:41:12.623172: step 48000, loss = 0.52, batch loss = 0.35 (37.4 examples/sec; 0.214 sec/batch; 16h:53m:31s remains)
INFO - root - 2017-12-16 17:41:14.954618: step 48010, loss = 0.54, batch loss = 0.36 (34.6 examples/sec; 0.231 sec/batch; 18h:16m:42s remains)
INFO - root - 2017-12-16 17:41:17.154082: step 48020, loss = 0.51, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 17h:10m:11s remains)
INFO - root - 2017-12-16 17:41:19.375551: step 48030, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 17h:32m:22s remains)
INFO - root - 2017-12-16 17:41:21.596480: step 48040, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 17h:07m:54s remains)
INFO - root - 2017-12-16 17:41:23.824406: step 48050, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 17h:02m:38s remains)
INFO - root - 2017-12-16 17:41:26.022778: step 48060, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 17h:55m:06s remains)
INFO - root - 2017-12-16 17:41:28.193918: step 48070, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 17h:12m:23s remains)
INFO - root - 2017-12-16 17:41:30.399522: step 48080, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 17h:31m:00s remains)
INFO - root - 2017-12-16 17:41:32.589400: step 48090, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 17h:11m:49s remains)
INFO - root - 2017-12-16 17:41:34.792393: step 48100, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 17h:29m:14s remains)
INFO - root - 2017-12-16 17:41:37.125539: step 48110, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 17h:27m:56s remains)
INFO - root - 2017-12-16 17:41:39.349601: step 48120, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 17h:12m:15s remains)
INFO - root - 2017-12-16 17:41:41.548923: step 48130, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 17h:50m:41s remains)
INFO - root - 2017-12-16 17:41:43.788289: step 48140, loss = 0.56, batch loss = 0.39 (35.6 examples/sec; 0.225 sec/batch; 17h:46m:12s remains)
INFO - root - 2017-12-16 17:41:46.048580: step 48150, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 17h:44m:26s remains)
INFO - root - 2017-12-16 17:41:48.243185: step 48160, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 17h:00m:23s remains)
INFO - root - 2017-12-16 17:41:50.452523: step 48170, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 16h:54m:38s remains)
INFO - root - 2017-12-16 17:41:52.631837: step 48180, loss = 0.51, batch loss = 0.33 (39.1 examples/sec; 0.204 sec/batch; 16h:08m:50s remains)
INFO - root - 2017-12-16 17:41:54.843182: step 48190, loss = 0.48, batch loss = 0.31 (37.1 examples/sec; 0.215 sec/batch; 17h:00m:32s remains)
INFO - root - 2017-12-16 17:41:57.054370: step 48200, loss = 0.44, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 17h:29m:42s remains)
INFO - root - 2017-12-16 17:41:59.392209: step 48210, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 17h:02m:20s remains)
INFO - root - 2017-12-16 17:42:01.597264: step 48220, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 17h:13m:53s remains)
INFO - root - 2017-12-16 17:42:03.808306: step 48230, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 17h:20m:00s remains)
INFO - root - 2017-12-16 17:42:05.999730: step 48240, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 16h:47m:32s remains)
INFO - root - 2017-12-16 17:42:08.205197: step 48250, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 17h:29m:38s remains)
INFO - root - 2017-12-16 17:42:10.412023: step 48260, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 17h:03m:50s remains)
INFO - root - 2017-12-16 17:42:12.621560: step 48270, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 17h:43m:51s remains)
INFO - root - 2017-12-16 17:42:14.805017: step 48280, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 17h:07m:28s remains)
INFO - root - 2017-12-16 17:42:17.010258: step 48290, loss = 0.44, batch loss = 0.26 (34.7 examples/sec; 0.230 sec/batch; 18h:11m:04s remains)
INFO - root - 2017-12-16 17:42:19.230042: step 48300, loss = 0.52, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 16h:51m:54s remains)
INFO - root - 2017-12-16 17:42:21.559983: step 48310, loss = 0.44, batch loss = 0.26 (38.0 examples/sec; 0.210 sec/batch; 16h:36m:31s remains)
INFO - root - 2017-12-16 17:42:23.799706: step 48320, loss = 0.49, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 17h:33m:27s remains)
INFO - root - 2017-12-16 17:42:26.010634: step 48330, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 17h:14m:01s remains)
INFO - root - 2017-12-16 17:42:28.192040: step 48340, loss = 0.52, batch loss = 0.34 (38.3 examples/sec; 0.209 sec/batch; 16h:29m:23s remains)
INFO - root - 2017-12-16 17:42:30.410224: step 48350, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 17h:30m:29s remains)
INFO - root - 2017-12-16 17:42:32.625775: step 48360, loss = 0.50, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 18h:05m:14s remains)
INFO - root - 2017-12-16 17:42:34.848339: step 48370, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 17h:28m:40s remains)
INFO - root - 2017-12-16 17:42:37.061957: step 48380, loss = 0.55, batch loss = 0.38 (34.9 examples/sec; 0.229 sec/batch; 18h:04m:58s remains)
INFO - root - 2017-12-16 17:42:39.270371: step 48390, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 17h:37m:27s remains)
INFO - root - 2017-12-16 17:42:41.512393: step 48400, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 17h:32m:36s remains)
INFO - root - 2017-12-16 17:42:43.883163: step 48410, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 17h:39m:30s remains)
INFO - root - 2017-12-16 17:42:46.105593: step 48420, loss = 0.55, batch loss = 0.37 (35.4 examples/sec; 0.226 sec/batch; 17h:48m:51s remains)
INFO - root - 2017-12-16 17:42:48.337580: step 48430, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 17h:04m:38s remains)
INFO - root - 2017-12-16 17:42:50.581544: step 48440, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 16h:45m:55s remains)
INFO - root - 2017-12-16 17:42:52.806472: step 48450, loss = 0.51, batch loss = 0.33 (33.5 examples/sec; 0.239 sec/batch; 18h:52m:04s remains)
INFO - root - 2017-12-16 17:42:55.011577: step 48460, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 17h:07m:57s remains)
INFO - root - 2017-12-16 17:42:57.200688: step 48470, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 16h:59m:53s remains)
INFO - root - 2017-12-16 17:42:59.353358: step 48480, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 16h:57m:09s remains)
INFO - root - 2017-12-16 17:43:01.533343: step 48490, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 16h:46m:41s remains)
INFO - root - 2017-12-16 17:43:03.751206: step 48500, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 16h:49m:13s remains)
INFO - root - 2017-12-16 17:43:06.124699: step 48510, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 17h:20m:26s remains)
INFO - root - 2017-12-16 17:43:08.351455: step 48520, loss = 0.53, batch loss = 0.35 (34.9 examples/sec; 0.229 sec/batch; 18h:05m:00s remains)
INFO - root - 2017-12-16 17:43:10.567711: step 48530, loss = 0.53, batch loss = 0.36 (35.8 examples/sec; 0.224 sec/batch; 17h:39m:03s remains)
INFO - root - 2017-12-16 17:43:12.759876: step 48540, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 17h:08m:57s remains)
INFO - root - 2017-12-16 17:43:14.952260: step 48550, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 17h:13m:08s remains)
INFO - root - 2017-12-16 17:43:17.137749: step 48560, loss = 0.56, batch loss = 0.38 (36.1 examples/sec; 0.221 sec/batch; 17h:27m:42s remains)
INFO - root - 2017-12-16 17:43:19.316591: step 48570, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 16h:52m:52s remains)
INFO - root - 2017-12-16 17:43:21.527258: step 48580, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 17h:00m:18s remains)
INFO - root - 2017-12-16 17:43:23.755614: step 48590, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.229 sec/batch; 18h:01m:18s remains)
INFO - root - 2017-12-16 17:43:25.998274: step 48600, loss = 0.47, batch loss = 0.29 (33.6 examples/sec; 0.238 sec/batch; 18h:45m:32s remains)
INFO - root - 2017-12-16 17:43:28.353536: step 48610, loss = 0.49, batch loss = 0.31 (34.7 examples/sec; 0.230 sec/batch; 18h:10m:09s remains)
INFO - root - 2017-12-16 17:43:30.562669: step 48620, loss = 0.42, batch loss = 0.24 (38.5 examples/sec; 0.208 sec/batch; 16h:22m:26s remains)
INFO - root - 2017-12-16 17:43:32.737837: step 48630, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 16h:56m:36s remains)
INFO - root - 2017-12-16 17:43:34.917999: step 48640, loss = 0.54, batch loss = 0.36 (37.4 examples/sec; 0.214 sec/batch; 16h:52m:47s remains)
INFO - root - 2017-12-16 17:43:37.122012: step 48650, loss = 0.55, batch loss = 0.37 (37.0 examples/sec; 0.216 sec/batch; 17h:02m:39s remains)
INFO - root - 2017-12-16 17:43:39.297519: step 48660, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 16h:49m:51s remains)
INFO - root - 2017-12-16 17:43:41.479734: step 48670, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 17h:07m:34s remains)
INFO - root - 2017-12-16 17:43:43.707178: step 48680, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 17h:11m:12s remains)
INFO - root - 2017-12-16 17:43:45.892490: step 48690, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 17h:10m:17s remains)
INFO - root - 2017-12-16 17:43:48.090712: step 48700, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 17h:40m:58s remains)
INFO - root - 2017-12-16 17:43:50.390731: step 48710, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 17h:18m:23s remains)
INFO - root - 2017-12-16 17:43:52.601154: step 48720, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 16h:46m:57s remains)
INFO - root - 2017-12-16 17:43:54.866879: step 48730, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 17h:52m:10s remains)
INFO - root - 2017-12-16 17:43:57.060412: step 48740, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 17h:10m:21s remains)
INFO - root - 2017-12-16 17:43:59.269198: step 48750, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.218 sec/batch; 17h:12m:32s remains)
INFO - root - 2017-12-16 17:44:01.502603: step 48760, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 17h:34m:18s remains)
INFO - root - 2017-12-16 17:44:03.682918: step 48770, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 17h:20m:13s remains)
INFO - root - 2017-12-16 17:44:05.896941: step 48780, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 17h:13m:42s remains)
INFO - root - 2017-12-16 17:44:08.164281: step 48790, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 17h:51m:24s remains)
INFO - root - 2017-12-16 17:44:10.362044: step 48800, loss = 0.48, batch loss = 0.30 (34.3 examples/sec; 0.233 sec/batch; 18h:24m:03s remains)
INFO - root - 2017-12-16 17:44:12.740986: step 48810, loss = 0.55, batch loss = 0.37 (35.8 examples/sec; 0.223 sec/batch; 17h:35m:46s remains)
INFO - root - 2017-12-16 17:44:14.980560: step 48820, loss = 0.43, batch loss = 0.25 (38.0 examples/sec; 0.211 sec/batch; 16h:36m:15s remains)
INFO - root - 2017-12-16 17:44:17.216727: step 48830, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 17h:21m:14s remains)
INFO - root - 2017-12-16 17:44:19.430592: step 48840, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 17h:00m:43s remains)
INFO - root - 2017-12-16 17:44:21.619818: step 48850, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 17h:29m:35s remains)
INFO - root - 2017-12-16 17:44:23.856360: step 48860, loss = 0.58, batch loss = 0.40 (35.4 examples/sec; 0.226 sec/batch; 17h:48m:27s remains)
INFO - root - 2017-12-16 17:44:26.045745: step 48870, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 17h:07m:02s remains)
INFO - root - 2017-12-16 17:44:28.258174: step 48880, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 17h:37m:44s remains)
INFO - root - 2017-12-16 17:44:30.456604: step 48890, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 17h:36m:42s remains)
INFO - root - 2017-12-16 17:44:32.689557: step 48900, loss = 0.43, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 17h:21m:27s remains)
INFO - root - 2017-12-16 17:44:35.008047: step 48910, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 17h:00m:10s remains)
INFO - root - 2017-12-16 17:44:37.209917: step 48920, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 16h:58m:01s remains)
INFO - root - 2017-12-16 17:44:39.401501: step 48930, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 17h:07m:22s remains)
INFO - root - 2017-12-16 17:44:41.649068: step 48940, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 16h:58m:53s remains)
INFO - root - 2017-12-16 17:44:43.864669: step 48950, loss = 0.50, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 18h:06m:56s remains)
INFO - root - 2017-12-16 17:44:46.052486: step 48960, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 16h:56m:43s remains)
INFO - root - 2017-12-16 17:44:48.267262: step 48970, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 17h:28m:49s remains)
INFO - root - 2017-12-16 17:44:50.474729: step 48980, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 17h:07m:34s remains)
INFO - root - 2017-12-16 17:44:52.664916: step 48990, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 17h:21m:41s remains)
INFO - root - 2017-12-16 17:44:54.881181: step 49000, loss = 0.56, batch loss = 0.38 (35.9 examples/sec; 0.223 sec/batch; 17h:33m:37s remains)
INFO - root - 2017-12-16 17:44:57.246249: step 49010, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 17h:32m:08s remains)
INFO - root - 2017-12-16 17:44:59.461522: step 49020, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 17h:10m:58s remains)
INFO - root - 2017-12-16 17:45:01.647323: step 49030, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 17h:19m:04s remains)
INFO - root - 2017-12-16 17:45:03.827813: step 49040, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 17h:47m:58s remains)
INFO - root - 2017-12-16 17:45:06.054171: step 49050, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 17h:37m:36s remains)
INFO - root - 2017-12-16 17:45:08.278923: step 49060, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 17h:11m:03s remains)
INFO - root - 2017-12-16 17:45:10.503891: step 49070, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 17h:38m:37s remains)
INFO - root - 2017-12-16 17:45:12.719722: step 49080, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 17h:15m:36s remains)
INFO - root - 2017-12-16 17:45:14.930575: step 49090, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 16h:50m:50s remains)
INFO - root - 2017-12-16 17:45:17.158153: step 49100, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 17h:12m:33s remains)
INFO - root - 2017-12-16 17:45:19.464347: step 49110, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 17h:12m:13s remains)
INFO - root - 2017-12-16 17:45:21.681436: step 49120, loss = 0.42, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 17h:31m:26s remains)
INFO - root - 2017-12-16 17:45:23.908995: step 49130, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 17h:35m:41s remains)
INFO - root - 2017-12-16 17:45:26.151626: step 49140, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 17h:39m:31s remains)
INFO - root - 2017-12-16 17:45:28.368886: step 49150, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 17h:06m:35s remains)
INFO - root - 2017-12-16 17:45:30.569565: step 49160, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 17h:30m:06s remains)
INFO - root - 2017-12-16 17:45:32.801322: step 49170, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 17h:16m:57s remains)
INFO - root - 2017-12-16 17:45:35.032256: step 49180, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 17h:09m:51s remains)
INFO - root - 2017-12-16 17:45:37.232953: step 49190, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 17h:34m:57s remains)
INFO - root - 2017-12-16 17:45:39.433178: step 49200, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 17h:18m:41s remains)
INFO - root - 2017-12-16 17:45:41.793419: step 49210, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 16h:59m:56s remains)
INFO - root - 2017-12-16 17:45:44.002178: step 49220, loss = 0.47, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 17h:20m:51s remains)
INFO - root - 2017-12-16 17:45:46.216922: step 49230, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 17h:22m:18s remains)
INFO - root - 2017-12-16 17:45:48.465355: step 49240, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 17h:26m:05s remains)
INFO - root - 2017-12-16 17:45:50.663432: step 49250, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.229 sec/batch; 17h:58m:57s remains)
INFO - root - 2017-12-16 17:45:52.851288: step 49260, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 17h:17m:55s remains)
INFO - root - 2017-12-16 17:45:55.060854: step 49270, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 17h:41m:08s remains)
INFO - root - 2017-12-16 17:45:57.310802: step 49280, loss = 0.47, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 17h:44m:17s remains)
INFO - root - 2017-12-16 17:45:59.535342: step 49290, loss = 0.50, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 17h:15m:07s remains)
INFO - root - 2017-12-16 17:46:01.758267: step 49300, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 17h:06m:15s remains)
INFO - root - 2017-12-16 17:46:04.146648: step 49310, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 17h:34m:17s remains)
INFO - root - 2017-12-16 17:46:06.374950: step 49320, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 17h:40m:11s remains)
INFO - root - 2017-12-16 17:46:08.592987: step 49330, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 17h:29m:06s remains)
INFO - root - 2017-12-16 17:46:10.822402: step 49340, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 16h:59m:20s remains)
INFO - root - 2017-12-16 17:46:13.046626: step 49350, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 18h:02m:21s remains)
INFO - root - 2017-12-16 17:46:15.264842: step 49360, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 17h:14m:46s remains)
INFO - root - 2017-12-16 17:46:17.482271: step 49370, loss = 0.50, batch loss = 0.32 (34.7 examples/sec; 0.231 sec/batch; 18h:07m:51s remains)
INFO - root - 2017-12-16 17:46:19.696602: step 49380, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 17h:08m:11s remains)
INFO - root - 2017-12-16 17:46:21.883535: step 49390, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 17h:13m:12s remains)
INFO - root - 2017-12-16 17:46:24.095035: step 49400, loss = 0.42, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 17h:18m:44s remains)
INFO - root - 2017-12-16 17:46:26.434849: step 49410, loss = 0.46, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 17h:04m:32s remains)
INFO - root - 2017-12-16 17:46:28.601945: step 49420, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.214 sec/batch; 16h:47m:30s remains)
INFO - root - 2017-12-16 17:46:30.856253: step 49430, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.232 sec/batch; 18h:16m:19s remains)
INFO - root - 2017-12-16 17:46:33.108300: step 49440, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 17h:21m:30s remains)
INFO - root - 2017-12-16 17:46:35.329366: step 49450, loss = 0.54, batch loss = 0.36 (37.9 examples/sec; 0.211 sec/batch; 16h:35m:56s remains)
INFO - root - 2017-12-16 17:46:37.562278: step 49460, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 17h:36m:33s remains)
INFO - root - 2017-12-16 17:46:39.783814: step 49470, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 17h:03m:26s remains)
INFO - root - 2017-12-16 17:46:42.010719: step 49480, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 17h:18m:16s remains)
INFO - root - 2017-12-16 17:46:44.222797: step 49490, loss = 0.61, batch loss = 0.43 (36.2 examples/sec; 0.221 sec/batch; 17h:21m:56s remains)
INFO - root - 2017-12-16 17:46:46.413647: step 49500, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 17h:02m:21s remains)
INFO - root - 2017-12-16 17:46:48.732733: step 49510, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 17h:27m:05s remains)
INFO - root - 2017-12-16 17:46:50.930541: step 49520, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 17h:44m:48s remains)
INFO - root - 2017-12-16 17:46:53.164345: step 49530, loss = 0.52, batch loss = 0.35 (35.2 examples/sec; 0.228 sec/batch; 17h:53m:00s remains)
INFO - root - 2017-12-16 17:46:55.371522: step 49540, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 18h:12m:43s remains)
INFO - root - 2017-12-16 17:46:57.586305: step 49550, loss = 0.53, batch loss = 0.36 (35.8 examples/sec; 0.224 sec/batch; 17h:35m:09s remains)
INFO - root - 2017-12-16 17:46:59.789537: step 49560, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 17h:09m:38s remains)
INFO - root - 2017-12-16 17:47:01.998542: step 49570, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 17h:43m:57s remains)
INFO - root - 2017-12-16 17:47:04.211495: step 49580, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 17h:26m:46s remains)
INFO - root - 2017-12-16 17:47:06.431765: step 49590, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 17h:00m:40s remains)
INFO - root - 2017-12-16 17:47:08.633477: step 49600, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 17h:13m:41s remains)
INFO - root - 2017-12-16 17:47:11.000014: step 49610, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 17h:11m:37s remains)
INFO - root - 2017-12-16 17:47:13.202318: step 49620, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 17h:07m:58s remains)
INFO - root - 2017-12-16 17:47:15.403222: step 49630, loss = 0.49, batch loss = 0.31 (34.5 examples/sec; 0.232 sec/batch; 18h:12m:48s remains)
INFO - root - 2017-12-16 17:47:17.642848: step 49640, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 17h:05m:52s remains)
INFO - root - 2017-12-16 17:47:19.862525: step 49650, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 16h:50m:01s remains)
INFO - root - 2017-12-16 17:47:22.081698: step 49660, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 17h:11m:36s remains)
INFO - root - 2017-12-16 17:47:24.300996: step 49670, loss = 0.49, batch loss = 0.32 (35.6 examples/sec; 0.224 sec/batch; 17h:37m:56s remains)
INFO - root - 2017-12-16 17:47:26.520888: step 49680, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 17h:29m:42s remains)
INFO - root - 2017-12-16 17:47:28.716322: step 49690, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 17h:19m:04s remains)
INFO - root - 2017-12-16 17:47:30.932614: step 49700, loss = 0.52, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 16h:46m:55s remains)
INFO - root - 2017-12-16 17:47:33.284736: step 49710, loss = 0.55, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 17h:15m:53s remains)
INFO - root - 2017-12-16 17:47:35.498047: step 49720, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 17h:29m:56s remains)
INFO - root - 2017-12-16 17:47:37.698363: step 49730, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 17h:27m:06s remains)
INFO - root - 2017-12-16 17:47:39.911075: step 49740, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 17h:40m:47s remains)
INFO - root - 2017-12-16 17:47:42.155675: step 49750, loss = 0.43, batch loss = 0.25 (34.9 examples/sec; 0.229 sec/batch; 17h:59m:30s remains)
INFO - root - 2017-12-16 17:47:44.355138: step 49760, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 17h:22m:58s remains)
INFO - root - 2017-12-16 17:47:46.600539: step 49770, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 17h:22m:09s remains)
INFO - root - 2017-12-16 17:47:48.804546: step 49780, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 17h:08m:38s remains)
INFO - root - 2017-12-16 17:47:51.027647: step 49790, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 16h:55m:51s remains)
INFO - root - 2017-12-16 17:47:53.237657: step 49800, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 16h:50m:39s remains)
INFO - root - 2017-12-16 17:47:55.605054: step 49810, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 16h:50m:40s remains)
INFO - root - 2017-12-16 17:47:57.824711: step 49820, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 17h:25m:26s remains)
INFO - root - 2017-12-16 17:48:00.055694: step 49830, loss = 0.56, batch loss = 0.38 (36.3 examples/sec; 0.221 sec/batch; 17h:18m:54s remains)
INFO - root - 2017-12-16 17:48:02.239087: step 49840, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 16h:37m:36s remains)
INFO - root - 2017-12-16 17:48:04.468342: step 49850, loss = 0.54, batch loss = 0.36 (37.4 examples/sec; 0.214 sec/batch; 16h:47m:58s remains)
INFO - root - 2017-12-16 17:48:06.667170: step 49860, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 17h:58m:29s remains)
INFO - root - 2017-12-16 17:48:08.920435: step 49870, loss = 0.53, batch loss = 0.36 (35.8 examples/sec; 0.224 sec/batch; 17h:33m:36s remains)
INFO - root - 2017-12-16 17:48:11.115889: step 49880, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 17h:47m:06s remains)
INFO - root - 2017-12-16 17:48:13.328527: step 49890, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 16h:54m:08s remains)
INFO - root - 2017-12-16 17:48:15.540418: step 49900, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 17h:28m:27s remains)
INFO - root - 2017-12-16 17:48:17.925719: step 49910, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 17h:15m:17s remains)
INFO - root - 2017-12-16 17:48:20.117513: step 49920, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 16h:47m:26s remains)
INFO - root - 2017-12-16 17:48:22.321941: step 49930, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 17h:41m:33s remains)
INFO - root - 2017-12-16 17:48:24.549598: step 49940, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 17h:29m:02s remains)
INFO - root - 2017-12-16 17:48:26.761116: step 49950, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 17h:20m:41s remains)
INFO - root - 2017-12-16 17:48:28.992057: step 49960, loss = 0.45, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 17h:58m:12s remains)
INFO - root - 2017-12-16 17:48:31.245514: step 49970, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 17h:19m:16s remains)
INFO - root - 2017-12-16 17:48:33.462249: step 49980, loss = 0.54, batch loss = 0.36 (36.0 examples/sec; 0.222 sec/batch; 17h:25m:34s remains)
INFO - root - 2017-12-16 17:48:35.682350: step 49990, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.223 sec/batch; 17h:27m:39s remains)
INFO - root - 2017-12-16 17:48:37.959103: step 50000, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 17h:55m:16s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-50000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-50000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 17:48:40.845555: step 50010, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 17h:11m:36s remains)
INFO - root - 2017-12-16 17:48:43.028776: step 50020, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 17h:02m:45s remains)
INFO - root - 2017-12-16 17:48:45.241618: step 50030, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 17h:27m:23s remains)
INFO - root - 2017-12-16 17:48:47.458643: step 50040, loss = 0.45, batch loss = 0.27 (34.2 examples/sec; 0.234 sec/batch; 18h:20m:32s remains)
INFO - root - 2017-12-16 17:48:49.688370: step 50050, loss = 0.50, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 17h:57m:36s remains)
INFO - root - 2017-12-16 17:48:51.919748: step 50060, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 17h:33m:54s remains)
INFO - root - 2017-12-16 17:48:54.147182: step 50070, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 17h:08m:31s remains)
INFO - root - 2017-12-16 17:48:56.357152: step 50080, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 17h:25m:57s remains)
INFO - root - 2017-12-16 17:48:58.579834: step 50090, loss = 0.43, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 17h:39m:48s remains)
INFO - root - 2017-12-16 17:49:00.801438: step 50100, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 17h:35m:42s remains)
INFO - root - 2017-12-16 17:49:03.155258: step 50110, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.215 sec/batch; 16h:53m:33s remains)
INFO - root - 2017-12-16 17:49:05.408334: step 50120, loss = 0.50, batch loss = 0.32 (34.7 examples/sec; 0.231 sec/batch; 18h:05m:24s remains)
INFO - root - 2017-12-16 17:49:07.630559: step 50130, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 18h:01m:51s remains)
INFO - root - 2017-12-16 17:49:09.860291: step 50140, loss = 0.52, batch loss = 0.34 (37.7 examples/sec; 0.212 sec/batch; 16h:39m:26s remains)
INFO - root - 2017-12-16 17:49:12.057655: step 50150, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.215 sec/batch; 16h:54m:01s remains)
INFO - root - 2017-12-16 17:49:14.270966: step 50160, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 17h:51m:16s remains)
INFO - root - 2017-12-16 17:49:16.482225: step 50170, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.223 sec/batch; 17h:27m:06s remains)
INFO - root - 2017-12-16 17:49:18.706924: step 50180, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 17h:23m:16s remains)
INFO - root - 2017-12-16 17:49:20.940406: step 50190, loss = 0.46, batch loss = 0.28 (34.4 examples/sec; 0.232 sec/batch; 18h:13m:02s remains)
INFO - root - 2017-12-16 17:49:23.163894: step 50200, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 16h:58m:03s remains)
INFO - root - 2017-12-16 17:49:25.455959: step 50210, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 17h:08m:11s remains)
INFO - root - 2017-12-16 17:49:27.696015: step 50220, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 18h:01m:52s remains)
INFO - root - 2017-12-16 17:49:29.888781: step 50230, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 16h:56m:17s remains)
INFO - root - 2017-12-16 17:49:32.152097: step 50240, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 17h:56m:52s remains)
INFO - root - 2017-12-16 17:49:34.346711: step 50250, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 17h:24m:16s remains)
INFO - root - 2017-12-16 17:49:36.567076: step 50260, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 17h:54m:26s remains)
INFO - root - 2017-12-16 17:49:38.812549: step 50270, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 16h:59m:02s remains)
INFO - root - 2017-12-16 17:49:41.008841: step 50280, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 17h:04m:56s remains)
INFO - root - 2017-12-16 17:49:43.201673: step 50290, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 17h:28m:09s remains)
INFO - root - 2017-12-16 17:49:45.403814: step 50300, loss = 0.53, batch loss = 0.35 (37.5 examples/sec; 0.213 sec/batch; 16h:43m:22s remains)
INFO - root - 2017-12-16 17:49:47.745139: step 50310, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 18h:09m:56s remains)
INFO - root - 2017-12-16 17:49:49.977631: step 50320, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 16h:57m:55s remains)
INFO - root - 2017-12-16 17:49:52.166557: step 50330, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 17h:02m:28s remains)
INFO - root - 2017-12-16 17:49:54.398182: step 50340, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 17h:14m:58s remains)
INFO - root - 2017-12-16 17:49:56.608600: step 50350, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 17h:40m:14s remains)
INFO - root - 2017-12-16 17:49:58.847933: step 50360, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 17h:13m:17s remains)
INFO - root - 2017-12-16 17:50:01.073577: step 50370, loss = 0.46, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 17h:30m:24s remains)
INFO - root - 2017-12-16 17:50:03.321935: step 50380, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 17h:49m:39s remains)
INFO - root - 2017-12-16 17:50:05.550029: step 50390, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 17h:16m:44s remains)
INFO - root - 2017-12-16 17:50:07.775609: step 50400, loss = 0.45, batch loss = 0.27 (34.3 examples/sec; 0.233 sec/batch; 18h:15m:09s remains)
INFO - root - 2017-12-16 17:50:10.129889: step 50410, loss = 0.51, batch loss = 0.33 (34.3 examples/sec; 0.234 sec/batch; 18h:18m:08s remains)
INFO - root - 2017-12-16 17:50:12.351224: step 50420, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 17h:21m:37s remains)
INFO - root - 2017-12-16 17:50:14.591443: step 50430, loss = 0.42, batch loss = 0.24 (35.9 examples/sec; 0.223 sec/batch; 17h:27m:13s remains)
INFO - root - 2017-12-16 17:50:16.796888: step 50440, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.224 sec/batch; 17h:35m:07s remains)
INFO - root - 2017-12-16 17:50:19.008302: step 50450, loss = 0.46, batch loss = 0.28 (32.9 examples/sec; 0.243 sec/batch; 19h:02m:37s remains)
INFO - root - 2017-12-16 17:50:21.249654: step 50460, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 17h:43m:40s remains)
INFO - root - 2017-12-16 17:50:23.446614: step 50470, loss = 0.59, batch loss = 0.41 (35.4 examples/sec; 0.226 sec/batch; 17h:41m:41s remains)
INFO - root - 2017-12-16 17:50:25.655184: step 50480, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 17h:06m:39s remains)
INFO - root - 2017-12-16 17:50:27.875714: step 50490, loss = 0.45, batch loss = 0.28 (34.9 examples/sec; 0.230 sec/batch; 17h:58m:41s remains)
INFO - root - 2017-12-16 17:50:30.071875: step 50500, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 16h:55m:15s remains)
INFO - root - 2017-12-16 17:50:32.412298: step 50510, loss = 0.42, batch loss = 0.24 (36.6 examples/sec; 0.218 sec/batch; 17h:06m:31s remains)
INFO - root - 2017-12-16 17:50:34.613450: step 50520, loss = 0.47, batch loss = 0.29 (38.2 examples/sec; 0.210 sec/batch; 16h:24m:45s remains)
INFO - root - 2017-12-16 17:50:36.838068: step 50530, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 17h:02m:53s remains)
INFO - root - 2017-12-16 17:50:39.054766: step 50540, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 17h:12m:29s remains)
INFO - root - 2017-12-16 17:50:41.272235: step 50550, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 17h:26m:24s remains)
INFO - root - 2017-12-16 17:50:43.488792: step 50560, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 17h:28m:40s remains)
INFO - root - 2017-12-16 17:50:45.713775: step 50570, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 17h:29m:28s remains)
INFO - root - 2017-12-16 17:50:47.942460: step 50580, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 17h:31m:01s remains)
INFO - root - 2017-12-16 17:50:50.140313: step 50590, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 17h:17m:39s remains)
INFO - root - 2017-12-16 17:50:52.359585: step 50600, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 17h:50m:43s remains)
INFO - root - 2017-12-16 17:50:54.721031: step 50610, loss = 0.53, batch loss = 0.35 (34.3 examples/sec; 0.233 sec/batch; 18h:16m:30s remains)
INFO - root - 2017-12-16 17:50:56.940955: step 50620, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 17h:54m:27s remains)
INFO - root - 2017-12-16 17:50:59.159984: step 50630, loss = 0.55, batch loss = 0.37 (34.5 examples/sec; 0.232 sec/batch; 18h:08m:26s remains)
INFO - root - 2017-12-16 17:51:01.357503: step 50640, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.226 sec/batch; 17h:40m:02s remains)
INFO - root - 2017-12-16 17:51:03.571140: step 50650, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 18h:01m:12s remains)
INFO - root - 2017-12-16 17:51:05.788290: step 50660, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 17h:54m:24s remains)
INFO - root - 2017-12-16 17:51:08.015695: step 50670, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 17h:28m:52s remains)
INFO - root - 2017-12-16 17:51:10.221346: step 50680, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 16h:44m:02s remains)
INFO - root - 2017-12-16 17:51:12.452316: step 50690, loss = 0.42, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 17h:11m:05s remains)
INFO - root - 2017-12-16 17:51:14.687108: step 50700, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 16h:49m:19s remains)
INFO - root - 2017-12-16 17:51:16.992969: step 50710, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 17h:00m:11s remains)
INFO - root - 2017-12-16 17:51:19.190625: step 50720, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 17h:01m:13s remains)
INFO - root - 2017-12-16 17:51:21.395173: step 50730, loss = 0.50, batch loss = 0.33 (35.2 examples/sec; 0.227 sec/batch; 17h:47m:25s remains)
INFO - root - 2017-12-16 17:51:23.600816: step 50740, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 17h:10m:34s remains)
INFO - root - 2017-12-16 17:51:25.842645: step 50750, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 17h:28m:08s remains)
INFO - root - 2017-12-16 17:51:28.052799: step 50760, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.230 sec/batch; 18h:02m:12s remains)
INFO - root - 2017-12-16 17:51:30.253213: step 50770, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 17h:07m:25s remains)
INFO - root - 2017-12-16 17:51:32.433671: step 50780, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 16h:53m:12s remains)
INFO - root - 2017-12-16 17:51:34.653192: step 50790, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 17h:05m:45s remains)
INFO - root - 2017-12-16 17:51:36.855627: step 50800, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 17h:29m:40s remains)
INFO - root - 2017-12-16 17:51:39.256966: step 50810, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.219 sec/batch; 17h:10m:28s remains)
INFO - root - 2017-12-16 17:51:41.494689: step 50820, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 17h:05m:02s remains)
INFO - root - 2017-12-16 17:51:43.682114: step 50830, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 17h:05m:48s remains)
INFO - root - 2017-12-16 17:51:45.911148: step 50840, loss = 0.47, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 17h:08m:09s remains)
INFO - root - 2017-12-16 17:51:48.092303: step 50850, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 16h:50m:26s remains)
INFO - root - 2017-12-16 17:51:50.296940: step 50860, loss = 0.57, batch loss = 0.39 (36.5 examples/sec; 0.219 sec/batch; 17h:08m:49s remains)
INFO - root - 2017-12-16 17:51:52.519847: step 50870, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 17h:17m:57s remains)
INFO - root - 2017-12-16 17:51:54.749626: step 50880, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 17h:06m:52s remains)
INFO - root - 2017-12-16 17:51:56.983138: step 50890, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 17h:23m:24s remains)
INFO - root - 2017-12-16 17:51:59.196461: step 50900, loss = 0.46, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 16h:58m:35s remains)
INFO - root - 2017-12-16 17:52:01.546073: step 50910, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 17h:14m:30s remains)
INFO - root - 2017-12-16 17:52:03.813482: step 50920, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 16h:48m:55s remains)
INFO - root - 2017-12-16 17:52:06.006273: step 50930, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 17h:01m:26s remains)
INFO - root - 2017-12-16 17:52:08.206362: step 50940, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 17h:18m:06s remains)
INFO - root - 2017-12-16 17:52:10.422033: step 50950, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 17h:04m:37s remains)
INFO - root - 2017-12-16 17:52:12.616112: step 50960, loss = 0.50, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 17h:10m:10s remains)
INFO - root - 2017-12-16 17:52:14.865940: step 50970, loss = 0.50, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 17h:59m:19s remains)
INFO - root - 2017-12-16 17:52:17.071036: step 50980, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 16h:47m:57s remains)
INFO - root - 2017-12-16 17:52:19.263407: step 50990, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 17h:03m:36s remains)
INFO - root - 2017-12-16 17:52:21.462280: step 51000, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 17h:25m:37s remains)
INFO - root - 2017-12-16 17:52:23.802895: step 51010, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 17h:27m:13s remains)
INFO - root - 2017-12-16 17:52:25.992068: step 51020, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 18h:02m:11s remains)
INFO - root - 2017-12-16 17:52:28.238060: step 51030, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 17h:32m:36s remains)
INFO - root - 2017-12-16 17:52:30.453724: step 51040, loss = 0.47, batch loss = 0.29 (33.9 examples/sec; 0.236 sec/batch; 18h:27m:17s remains)
INFO - root - 2017-12-16 17:52:32.691227: step 51050, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 17h:33m:47s remains)
INFO - root - 2017-12-16 17:52:34.935216: step 51060, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 17h:09m:02s remains)
INFO - root - 2017-12-16 17:52:37.188795: step 51070, loss = 0.48, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 17h:28m:50s remains)
INFO - root - 2017-12-16 17:52:39.425834: step 51080, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 17h:06m:48s remains)
INFO - root - 2017-12-16 17:52:41.658693: step 51090, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 17h:21m:56s remains)
INFO - root - 2017-12-16 17:52:43.896060: step 51100, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.224 sec/batch; 17h:28m:39s remains)
INFO - root - 2017-12-16 17:52:46.294485: step 51110, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 17h:28m:23s remains)
INFO - root - 2017-12-16 17:52:48.526303: step 51120, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 16h:52m:37s remains)
INFO - root - 2017-12-16 17:52:50.744717: step 51130, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 17h:25m:22s remains)
INFO - root - 2017-12-16 17:52:53.006088: step 51140, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 17h:11m:09s remains)
INFO - root - 2017-12-16 17:52:55.258557: step 51150, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 17h:22m:26s remains)
INFO - root - 2017-12-16 17:52:57.482032: step 51160, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.226 sec/batch; 17h:37m:45s remains)
INFO - root - 2017-12-16 17:52:59.710448: step 51170, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 17h:17m:36s remains)
INFO - root - 2017-12-16 17:53:01.921142: step 51180, loss = 0.57, batch loss = 0.39 (36.6 examples/sec; 0.219 sec/batch; 17h:04m:29s remains)
INFO - root - 2017-12-16 17:53:04.116463: step 51190, loss = 0.49, batch loss = 0.31 (37.9 examples/sec; 0.211 sec/batch; 16h:30m:07s remains)
INFO - root - 2017-12-16 17:53:06.316070: step 51200, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 17h:23m:00s remains)
INFO - root - 2017-12-16 17:53:08.701500: step 51210, loss = 0.56, batch loss = 0.38 (29.1 examples/sec; 0.275 sec/batch; 21h:27m:14s remains)
INFO - root - 2017-12-16 17:53:10.910203: step 51220, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 17h:07m:10s remains)
INFO - root - 2017-12-16 17:53:13.147650: step 51230, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 17h:30m:20s remains)
INFO - root - 2017-12-16 17:53:15.351081: step 51240, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 17h:30m:58s remains)
INFO - root - 2017-12-16 17:53:17.576619: step 51250, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 17h:09m:03s remains)
INFO - root - 2017-12-16 17:53:19.817060: step 51260, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 17h:08m:16s remains)
INFO - root - 2017-12-16 17:53:22.001469: step 51270, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 17h:07m:34s remains)
INFO - root - 2017-12-16 17:53:24.216373: step 51280, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 16h:59m:19s remains)
INFO - root - 2017-12-16 17:53:26.479584: step 51290, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 17h:31m:20s remains)
INFO - root - 2017-12-16 17:53:28.676847: step 51300, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 17h:10m:11s remains)
INFO - root - 2017-12-16 17:53:31.077478: step 51310, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 17h:19m:04s remains)
INFO - root - 2017-12-16 17:53:33.323471: step 51320, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 17h:57m:50s remains)
INFO - root - 2017-12-16 17:53:35.552353: step 51330, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 17h:38m:16s remains)
INFO - root - 2017-12-16 17:53:37.796367: step 51340, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 17h:25m:05s remains)
INFO - root - 2017-12-16 17:53:40.020192: step 51350, loss = 0.53, batch loss = 0.35 (35.3 examples/sec; 0.227 sec/batch; 17h:41m:25s remains)
INFO - root - 2017-12-16 17:53:42.233056: step 51360, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 16h:49m:20s remains)
INFO - root - 2017-12-16 17:53:44.545267: step 51370, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 17h:34m:42s remains)
INFO - root - 2017-12-16 17:53:46.780866: step 51380, loss = 0.44, batch loss = 0.26 (34.5 examples/sec; 0.232 sec/batch; 18h:07m:00s remains)
INFO - root - 2017-12-16 17:53:48.995016: step 51390, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 17h:31m:15s remains)
INFO - root - 2017-12-16 17:53:51.189686: step 51400, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 17h:07m:13s remains)
INFO - root - 2017-12-16 17:53:53.597820: step 51410, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.228 sec/batch; 17h:49m:19s remains)
INFO - root - 2017-12-16 17:53:55.805761: step 51420, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 16h:42m:02s remains)
INFO - root - 2017-12-16 17:53:58.051296: step 51430, loss = 0.47, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 17h:40m:40s remains)
INFO - root - 2017-12-16 17:54:00.258316: step 51440, loss = 0.46, batch loss = 0.28 (33.1 examples/sec; 0.242 sec/batch; 18h:52m:51s remains)
INFO - root - 2017-12-16 17:54:02.492640: step 51450, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 17h:04m:00s remains)
INFO - root - 2017-12-16 17:54:04.668734: step 51460, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 16h:42m:53s remains)
INFO - root - 2017-12-16 17:54:06.913303: step 51470, loss = 0.54, batch loss = 0.36 (35.1 examples/sec; 0.228 sec/batch; 17h:47m:33s remains)
INFO - root - 2017-12-16 17:54:09.108410: step 51480, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 16h:52m:57s remains)
INFO - root - 2017-12-16 17:54:11.307197: step 51490, loss = 0.57, batch loss = 0.39 (35.5 examples/sec; 0.225 sec/batch; 17h:35m:18s remains)
INFO - root - 2017-12-16 17:54:13.553572: step 51500, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 17h:36m:20s remains)
INFO - root - 2017-12-16 17:54:15.850725: step 51510, loss = 0.47, batch loss = 0.29 (38.5 examples/sec; 0.208 sec/batch; 16h:12m:18s remains)
INFO - root - 2017-12-16 17:54:18.070013: step 51520, loss = 0.42, batch loss = 0.24 (35.6 examples/sec; 0.224 sec/batch; 17h:31m:12s remains)
INFO - root - 2017-12-16 17:54:20.290787: step 51530, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 16h:43m:09s remains)
INFO - root - 2017-12-16 17:54:22.514988: step 51540, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 17h:53m:32s remains)
INFO - root - 2017-12-16 17:54:24.728793: step 51550, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 16h:31m:55s remains)
INFO - root - 2017-12-16 17:54:26.952737: step 51560, loss = 0.46, batch loss = 0.28 (34.1 examples/sec; 0.234 sec/batch; 18h:17m:30s remains)
INFO - root - 2017-12-16 17:54:29.171167: step 51570, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 17h:25m:18s remains)
INFO - root - 2017-12-16 17:54:31.412487: step 51580, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 17h:16m:01s remains)
INFO - root - 2017-12-16 17:54:33.651328: step 51590, loss = 0.47, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 18h:06m:32s remains)
INFO - root - 2017-12-16 17:54:35.895120: step 51600, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 16h:49m:13s remains)
INFO - root - 2017-12-16 17:54:38.299147: step 51610, loss = 0.43, batch loss = 0.25 (35.0 examples/sec; 0.228 sec/batch; 17h:49m:29s remains)
INFO - root - 2017-12-16 17:54:40.542365: step 51620, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 17h:10m:04s remains)
INFO - root - 2017-12-16 17:54:42.773063: step 51630, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.218 sec/batch; 16h:58m:12s remains)
INFO - root - 2017-12-16 17:54:44.986165: step 51640, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 17h:10m:01s remains)
INFO - root - 2017-12-16 17:54:47.202289: step 51650, loss = 0.47, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 17h:28m:42s remains)
INFO - root - 2017-12-16 17:54:49.425465: step 51660, loss = 0.51, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 17h:34m:23s remains)
INFO - root - 2017-12-16 17:54:51.636574: step 51670, loss = 0.51, batch loss = 0.34 (34.8 examples/sec; 0.230 sec/batch; 17h:55m:14s remains)
INFO - root - 2017-12-16 17:54:53.850649: step 51680, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 17h:25m:05s remains)
INFO - root - 2017-12-16 17:54:56.084027: step 51690, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 17h:28m:55s remains)
INFO - root - 2017-12-16 17:54:58.296102: step 51700, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 17h:22m:51s remains)
INFO - root - 2017-12-16 17:55:00.637849: step 51710, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.226 sec/batch; 17h:39m:14s remains)
INFO - root - 2017-12-16 17:55:02.831639: step 51720, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 17h:37m:12s remains)
INFO - root - 2017-12-16 17:55:05.056971: step 51730, loss = 0.52, batch loss = 0.35 (34.5 examples/sec; 0.232 sec/batch; 18h:04m:20s remains)
INFO - root - 2017-12-16 17:55:07.227184: step 51740, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 16h:54m:26s remains)
INFO - root - 2017-12-16 17:55:09.452211: step 51750, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 17h:09m:46s remains)
INFO - root - 2017-12-16 17:55:11.716362: step 51760, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 17h:35m:26s remains)
INFO - root - 2017-12-16 17:55:13.920470: step 51770, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 17h:20m:39s remains)
INFO - root - 2017-12-16 17:55:16.155278: step 51780, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 17h:11m:01s remains)
INFO - root - 2017-12-16 17:55:18.430825: step 51790, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 17h:35m:11s remains)
INFO - root - 2017-12-16 17:55:20.667354: step 51800, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 17h:43m:05s remains)
INFO - root - 2017-12-16 17:55:23.018448: step 51810, loss = 0.48, batch loss = 0.30 (33.8 examples/sec; 0.236 sec/batch; 18h:26m:15s remains)
INFO - root - 2017-12-16 17:55:25.247901: step 51820, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 16h:49m:32s remains)
INFO - root - 2017-12-16 17:55:27.452939: step 51830, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 17h:26m:23s remains)
INFO - root - 2017-12-16 17:55:29.669802: step 51840, loss = 0.44, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 17h:20m:34s remains)
INFO - root - 2017-12-16 17:55:31.880275: step 51850, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 17h:00m:49s remains)
INFO - root - 2017-12-16 17:55:34.092430: step 51860, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 16h:45m:20s remains)
INFO - root - 2017-12-16 17:55:36.326753: step 51870, loss = 0.51, batch loss = 0.33 (34.5 examples/sec; 0.232 sec/batch; 18h:04m:04s remains)
INFO - root - 2017-12-16 17:55:38.568399: step 51880, loss = 0.52, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 17h:47m:15s remains)
INFO - root - 2017-12-16 17:55:40.796064: step 51890, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 17h:25m:15s remains)
INFO - root - 2017-12-16 17:55:43.029097: step 51900, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 17h:00m:20s remains)
INFO - root - 2017-12-16 17:55:45.394448: step 51910, loss = 0.57, batch loss = 0.39 (34.8 examples/sec; 0.230 sec/batch; 17h:53m:45s remains)
INFO - root - 2017-12-16 17:55:47.628496: step 51920, loss = 0.45, batch loss = 0.28 (35.2 examples/sec; 0.228 sec/batch; 17h:44m:08s remains)
INFO - root - 2017-12-16 17:55:49.840628: step 51930, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 16h:52m:57s remains)
INFO - root - 2017-12-16 17:55:52.068691: step 51940, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 17h:19m:35s remains)
INFO - root - 2017-12-16 17:55:54.261116: step 51950, loss = 0.51, batch loss = 0.33 (37.5 examples/sec; 0.214 sec/batch; 16h:38m:41s remains)
INFO - root - 2017-12-16 17:55:56.460337: step 51960, loss = 0.45, batch loss = 0.27 (34.7 examples/sec; 0.231 sec/batch; 17h:58m:20s remains)
INFO - root - 2017-12-16 17:55:58.675136: step 51970, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 18h:03m:21s remains)
INFO - root - 2017-12-16 17:56:00.868661: step 51980, loss = 0.51, batch loss = 0.33 (35.1 examples/sec; 0.228 sec/batch; 17h:45m:52s remains)
INFO - root - 2017-12-16 17:56:03.075279: step 51990, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 17h:07m:16s remains)
INFO - root - 2017-12-16 17:56:05.281908: step 52000, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 16h:53m:18s remains)
INFO - root - 2017-12-16 17:56:07.683441: step 52010, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 17h:26m:14s remains)
INFO - root - 2017-12-16 17:56:09.946124: step 52020, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 17h:17m:41s remains)
INFO - root - 2017-12-16 17:56:12.190835: step 52030, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 16h:56m:06s remains)
INFO - root - 2017-12-16 17:56:14.441873: step 52040, loss = 0.48, batch loss = 0.30 (37.9 examples/sec; 0.211 sec/batch; 16h:27m:38s remains)
INFO - root - 2017-12-16 17:56:16.630664: step 52050, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 16h:56m:55s remains)
INFO - root - 2017-12-16 17:56:18.835952: step 52060, loss = 0.54, batch loss = 0.36 (36.8 examples/sec; 0.217 sec/batch; 16h:55m:51s remains)
INFO - root - 2017-12-16 17:56:21.056002: step 52070, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 17h:27m:11s remains)
INFO - root - 2017-12-16 17:56:23.270095: step 52080, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 17h:27m:37s remains)
INFO - root - 2017-12-16 17:56:25.513732: step 52090, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.214 sec/batch; 16h:37m:49s remains)
INFO - root - 2017-12-16 17:56:27.799657: step 52100, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.230 sec/batch; 17h:52m:32s remains)
INFO - root - 2017-12-16 17:56:30.146233: step 52110, loss = 0.53, batch loss = 0.35 (33.9 examples/sec; 0.236 sec/batch; 18h:23m:01s remains)
INFO - root - 2017-12-16 17:56:32.397668: step 52120, loss = 0.52, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 17h:46m:05s remains)
INFO - root - 2017-12-16 17:56:34.640622: step 52130, loss = 0.45, batch loss = 0.27 (34.2 examples/sec; 0.234 sec/batch; 18h:12m:22s remains)
INFO - root - 2017-12-16 17:56:36.844744: step 52140, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 17h:11m:04s remains)
INFO - root - 2017-12-16 17:56:39.076340: step 52150, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 16h:57m:43s remains)
INFO - root - 2017-12-16 17:56:41.315964: step 52160, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.226 sec/batch; 17h:33m:39s remains)
INFO - root - 2017-12-16 17:56:43.547758: step 52170, loss = 0.50, batch loss = 0.32 (33.6 examples/sec; 0.238 sec/batch; 18h:31m:52s remains)
INFO - root - 2017-12-16 17:56:45.742604: step 52180, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 16h:46m:24s remains)
INFO - root - 2017-12-16 17:56:47.957472: step 52190, loss = 0.44, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 16h:49m:33s remains)
INFO - root - 2017-12-16 17:56:50.214680: step 52200, loss = 0.57, batch loss = 0.39 (36.3 examples/sec; 0.220 sec/batch; 17h:08m:13s remains)
INFO - root - 2017-12-16 17:56:52.593726: step 52210, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 16h:52m:44s remains)
INFO - root - 2017-12-16 17:56:54.831890: step 52220, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 17h:07m:39s remains)
INFO - root - 2017-12-16 17:56:57.056423: step 52230, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 17h:00m:10s remains)
INFO - root - 2017-12-16 17:56:59.292783: step 52240, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 16h:47m:11s remains)
INFO - root - 2017-12-16 17:57:01.534873: step 52250, loss = 0.46, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 17h:25m:49s remains)
INFO - root - 2017-12-16 17:57:03.776020: step 52260, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 16h:32m:37s remains)
INFO - root - 2017-12-16 17:57:05.993809: step 52270, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 16h:50m:47s remains)
INFO - root - 2017-12-16 17:57:08.229063: step 52280, loss = 0.47, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 18h:13m:54s remains)
INFO - root - 2017-12-16 17:57:10.500450: step 52290, loss = 0.57, batch loss = 0.40 (34.4 examples/sec; 0.232 sec/batch; 18h:05m:04s remains)
INFO - root - 2017-12-16 17:57:12.694182: step 52300, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 16h:43m:32s remains)
INFO - root - 2017-12-16 17:57:15.030816: step 52310, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 16h:44m:00s remains)
INFO - root - 2017-12-16 17:57:17.285124: step 52320, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 17h:30m:43s remains)
INFO - root - 2017-12-16 17:57:19.492350: step 52330, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 17h:20m:05s remains)
INFO - root - 2017-12-16 17:57:21.716176: step 52340, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 17h:20m:18s remains)
INFO - root - 2017-12-16 17:57:23.980995: step 52350, loss = 0.46, batch loss = 0.28 (33.8 examples/sec; 0.236 sec/batch; 18h:23m:55s remains)
INFO - root - 2017-12-16 17:57:26.213228: step 52360, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 16h:51m:06s remains)
INFO - root - 2017-12-16 17:57:28.447228: step 52370, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 17h:01m:24s remains)
INFO - root - 2017-12-16 17:57:30.685248: step 52380, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 17h:23m:56s remains)
INFO - root - 2017-12-16 17:57:32.889240: step 52390, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 17h:25m:02s remains)
INFO - root - 2017-12-16 17:57:35.129264: step 52400, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.231 sec/batch; 17h:57m:17s remains)
INFO - root - 2017-12-16 17:57:37.489028: step 52410, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 17h:06m:58s remains)
INFO - root - 2017-12-16 17:57:39.702863: step 52420, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 16h:54m:49s remains)
INFO - root - 2017-12-16 17:57:41.903374: step 52430, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.230 sec/batch; 17h:51m:29s remains)
INFO - root - 2017-12-16 17:57:44.111887: step 52440, loss = 0.54, batch loss = 0.36 (35.5 examples/sec; 0.225 sec/batch; 17h:31m:38s remains)
INFO - root - 2017-12-16 17:57:46.295093: step 52450, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 16h:57m:57s remains)
INFO - root - 2017-12-16 17:57:48.536991: step 52460, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 17h:21m:25s remains)
INFO - root - 2017-12-16 17:57:50.742431: step 52470, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 17h:14m:20s remains)
INFO - root - 2017-12-16 17:57:52.998018: step 52480, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 16h:42m:37s remains)
INFO - root - 2017-12-16 17:57:55.200269: step 52490, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 17h:32m:32s remains)
INFO - root - 2017-12-16 17:57:57.404238: step 52500, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 17h:09m:58s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-52500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-52500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 17:58:00.494789: step 52510, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 18h:01m:51s remains)
INFO - root - 2017-12-16 17:58:02.707653: step 52520, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 17h:12m:18s remains)
INFO - root - 2017-12-16 17:58:04.946727: step 52530, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.221 sec/batch; 17h:12m:55s remains)
INFO - root - 2017-12-16 17:58:07.172108: step 52540, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 17h:12m:29s remains)
INFO - root - 2017-12-16 17:58:09.425868: step 52550, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 17h:12m:45s remains)
INFO - root - 2017-12-16 17:58:11.618600: step 52560, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 17h:41m:57s remains)
INFO - root - 2017-12-16 17:58:13.819048: step 52570, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 17h:26m:56s remains)
INFO - root - 2017-12-16 17:58:16.046789: step 52580, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 17h:42m:01s remains)
INFO - root - 2017-12-16 17:58:18.281528: step 52590, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 16h:35m:45s remains)
INFO - root - 2017-12-16 17:58:20.503093: step 52600, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 17h:05m:57s remains)
INFO - root - 2017-12-16 17:58:22.853381: step 52610, loss = 0.54, batch loss = 0.37 (36.7 examples/sec; 0.218 sec/batch; 16h:58m:03s remains)
INFO - root - 2017-12-16 17:58:25.098920: step 52620, loss = 0.54, batch loss = 0.36 (33.3 examples/sec; 0.240 sec/batch; 18h:40m:25s remains)
INFO - root - 2017-12-16 17:58:27.319507: step 52630, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.215 sec/batch; 16h:41m:34s remains)
INFO - root - 2017-12-16 17:58:29.521148: step 52640, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 16h:57m:32s remains)
INFO - root - 2017-12-16 17:58:31.698567: step 52650, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 16h:42m:09s remains)
INFO - root - 2017-12-16 17:58:33.918575: step 52660, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 17h:16m:02s remains)
INFO - root - 2017-12-16 17:58:36.133009: step 52670, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 16h:58m:58s remains)
INFO - root - 2017-12-16 17:58:38.359695: step 52680, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 16h:49m:35s remains)
INFO - root - 2017-12-16 17:58:40.614392: step 52690, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 17h:02m:39s remains)
INFO - root - 2017-12-16 17:58:42.786414: step 52700, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 17h:00m:02s remains)
INFO - root - 2017-12-16 17:58:45.120279: step 52710, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 17h:23m:19s remains)
INFO - root - 2017-12-16 17:58:47.375453: step 52720, loss = 0.47, batch loss = 0.29 (34.6 examples/sec; 0.231 sec/batch; 17h:57m:05s remains)
INFO - root - 2017-12-16 17:58:49.579426: step 52730, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 17h:32m:57s remains)
INFO - root - 2017-12-16 17:58:51.793475: step 52740, loss = 0.43, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 17h:19m:28s remains)
INFO - root - 2017-12-16 17:58:53.970666: step 52750, loss = 0.44, batch loss = 0.27 (37.6 examples/sec; 0.213 sec/batch; 16h:32m:06s remains)
INFO - root - 2017-12-16 17:58:56.203167: step 52760, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 17h:18m:08s remains)
INFO - root - 2017-12-16 17:58:58.405466: step 52770, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 16h:57m:35s remains)
INFO - root - 2017-12-16 17:59:00.599346: step 52780, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 16h:53m:38s remains)
INFO - root - 2017-12-16 17:59:02.775874: step 52790, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 17h:04m:18s remains)
INFO - root - 2017-12-16 17:59:04.966527: step 52800, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 17h:09m:11s remains)
INFO - root - 2017-12-16 17:59:07.296717: step 52810, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 16h:46m:53s remains)
INFO - root - 2017-12-16 17:59:09.527613: step 52820, loss = 0.50, batch loss = 0.32 (35.0 examples/sec; 0.229 sec/batch; 17h:45m:55s remains)
INFO - root - 2017-12-16 17:59:11.760651: step 52830, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 17h:41m:25s remains)
INFO - root - 2017-12-16 17:59:13.951380: step 52840, loss = 0.54, batch loss = 0.36 (36.1 examples/sec; 0.221 sec/batch; 17h:12m:14s remains)
INFO - root - 2017-12-16 17:59:16.169327: step 52850, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 17h:09m:27s remains)
INFO - root - 2017-12-16 17:59:18.380011: step 52860, loss = 0.46, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 17h:22m:55s remains)
INFO - root - 2017-12-16 17:59:20.621299: step 52870, loss = 0.50, batch loss = 0.32 (35.0 examples/sec; 0.228 sec/batch; 17h:44m:07s remains)
INFO - root - 2017-12-16 17:59:22.813530: step 52880, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 17h:16m:15s remains)
INFO - root - 2017-12-16 17:59:25.022446: step 52890, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 16h:57m:09s remains)
INFO - root - 2017-12-16 17:59:27.265850: step 52900, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 16h:51m:30s remains)
INFO - root - 2017-12-16 17:59:29.589959: step 52910, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 16h:42m:28s remains)
INFO - root - 2017-12-16 17:59:31.783565: step 52920, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 17h:00m:32s remains)
INFO - root - 2017-12-16 17:59:33.974131: step 52930, loss = 0.48, batch loss = 0.30 (38.3 examples/sec; 0.209 sec/batch; 16h:14m:01s remains)
INFO - root - 2017-12-16 17:59:36.203634: step 52940, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 17h:01m:19s remains)
INFO - root - 2017-12-16 17:59:38.424744: step 52950, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 16h:55m:54s remains)
INFO - root - 2017-12-16 17:59:40.658343: step 52960, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 17h:06m:17s remains)
INFO - root - 2017-12-16 17:59:42.863962: step 52970, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 17h:09m:05s remains)
INFO - root - 2017-12-16 17:59:45.078193: step 52980, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 17h:22m:48s remains)
INFO - root - 2017-12-16 17:59:47.275292: step 52990, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 16h:34m:11s remains)
INFO - root - 2017-12-16 17:59:49.463173: step 53000, loss = 0.46, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 17h:00m:51s remains)
INFO - root - 2017-12-16 17:59:51.772377: step 53010, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 17h:19m:43s remains)
INFO - root - 2017-12-16 17:59:53.972037: step 53020, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 16h:42m:28s remains)
INFO - root - 2017-12-16 17:59:56.150720: step 53030, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 16h:42m:45s remains)
INFO - root - 2017-12-16 17:59:58.348475: step 53040, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 16h:53m:58s remains)
INFO - root - 2017-12-16 18:00:00.523098: step 53050, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 16h:36m:22s remains)
INFO - root - 2017-12-16 18:00:02.706275: step 53060, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 16h:47m:18s remains)
INFO - root - 2017-12-16 18:00:04.955390: step 53070, loss = 0.47, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 17h:23m:47s remains)
INFO - root - 2017-12-16 18:00:07.147746: step 53080, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 17h:01m:37s remains)
INFO - root - 2017-12-16 18:00:09.395956: step 53090, loss = 0.45, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 17h:16m:24s remains)
INFO - root - 2017-12-16 18:00:11.581440: step 53100, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 16h:45m:01s remains)
INFO - root - 2017-12-16 18:00:13.884491: step 53110, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 17h:03m:52s remains)
INFO - root - 2017-12-16 18:00:16.082176: step 53120, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.231 sec/batch; 17h:54m:01s remains)
INFO - root - 2017-12-16 18:00:18.315824: step 53130, loss = 0.42, batch loss = 0.24 (35.9 examples/sec; 0.223 sec/batch; 17h:18m:26s remains)
INFO - root - 2017-12-16 18:00:20.517104: step 53140, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 17h:34m:58s remains)
INFO - root - 2017-12-16 18:00:22.756554: step 53150, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 17h:32m:28s remains)
INFO - root - 2017-12-16 18:00:24.985174: step 53160, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.217 sec/batch; 16h:47m:57s remains)
INFO - root - 2017-12-16 18:00:27.197410: step 53170, loss = 0.58, batch loss = 0.40 (37.1 examples/sec; 0.215 sec/batch; 16h:42m:50s remains)
INFO - root - 2017-12-16 18:00:29.465391: step 53180, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 17h:15m:08s remains)
INFO - root - 2017-12-16 18:00:31.688053: step 53190, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 16h:50m:55s remains)
INFO - root - 2017-12-16 18:00:33.882594: step 53200, loss = 0.56, batch loss = 0.38 (35.8 examples/sec; 0.224 sec/batch; 17h:20m:41s remains)
INFO - root - 2017-12-16 18:00:36.220035: step 53210, loss = 0.51, batch loss = 0.33 (35.2 examples/sec; 0.227 sec/batch; 17h:38m:28s remains)
INFO - root - 2017-12-16 18:00:38.489484: step 53220, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 17h:41m:45s remains)
INFO - root - 2017-12-16 18:00:40.702380: step 53230, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 16h:50m:47s remains)
INFO - root - 2017-12-16 18:00:42.909732: step 53240, loss = 0.41, batch loss = 0.23 (36.5 examples/sec; 0.219 sec/batch; 16h:59m:52s remains)
INFO - root - 2017-12-16 18:00:45.128871: step 53250, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 17h:21m:37s remains)
INFO - root - 2017-12-16 18:00:47.319811: step 53260, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 16h:56m:32s remains)
INFO - root - 2017-12-16 18:00:49.548006: step 53270, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.231 sec/batch; 17h:53m:19s remains)
INFO - root - 2017-12-16 18:00:51.758852: step 53280, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 17h:02m:14s remains)
INFO - root - 2017-12-16 18:00:53.996656: step 53290, loss = 0.56, batch loss = 0.38 (34.8 examples/sec; 0.230 sec/batch; 17h:50m:20s remains)
INFO - root - 2017-12-16 18:00:56.200493: step 53300, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 16h:58m:46s remains)
INFO - root - 2017-12-16 18:00:58.612820: step 53310, loss = 0.46, batch loss = 0.28 (38.0 examples/sec; 0.210 sec/batch; 16h:19m:17s remains)
INFO - root - 2017-12-16 18:01:00.775162: step 53320, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 16h:37m:32s remains)
INFO - root - 2017-12-16 18:01:02.992107: step 53330, loss = 0.58, batch loss = 0.40 (34.5 examples/sec; 0.232 sec/batch; 17h:58m:44s remains)
INFO - root - 2017-12-16 18:01:05.177657: step 53340, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.230 sec/batch; 17h:52m:05s remains)
INFO - root - 2017-12-16 18:01:07.388941: step 53350, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 17h:18m:20s remains)
INFO - root - 2017-12-16 18:01:09.597652: step 53360, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 17h:08m:07s remains)
INFO - root - 2017-12-16 18:01:11.768484: step 53370, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 16h:48m:39s remains)
INFO - root - 2017-12-16 18:01:14.029084: step 53380, loss = 0.48, batch loss = 0.31 (33.9 examples/sec; 0.236 sec/batch; 18h:17m:30s remains)
INFO - root - 2017-12-16 18:01:16.237167: step 53390, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.218 sec/batch; 16h:56m:04s remains)
INFO - root - 2017-12-16 18:01:18.469980: step 53400, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 17h:09m:22s remains)
INFO - root - 2017-12-16 18:01:20.783344: step 53410, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 17h:17m:17s remains)
INFO - root - 2017-12-16 18:01:22.979528: step 53420, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 17h:15m:58s remains)
INFO - root - 2017-12-16 18:01:25.234506: step 53430, loss = 0.47, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 17h:25m:32s remains)
INFO - root - 2017-12-16 18:01:27.430759: step 53440, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 16h:58m:57s remains)
INFO - root - 2017-12-16 18:01:29.609938: step 53450, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 16h:54m:56s remains)
INFO - root - 2017-12-16 18:01:31.804458: step 53460, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 16h:49m:12s remains)
INFO - root - 2017-12-16 18:01:34.038926: step 53470, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 17h:01m:25s remains)
INFO - root - 2017-12-16 18:01:36.249589: step 53480, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 17h:08m:20s remains)
INFO - root - 2017-12-16 18:01:38.434765: step 53490, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 16h:55m:35s remains)
INFO - root - 2017-12-16 18:01:40.632150: step 53500, loss = 0.53, batch loss = 0.35 (37.1 examples/sec; 0.216 sec/batch; 16h:43m:49s remains)
INFO - root - 2017-12-16 18:01:42.968015: step 53510, loss = 0.58, batch loss = 0.41 (37.2 examples/sec; 0.215 sec/batch; 16h:39m:59s remains)
INFO - root - 2017-12-16 18:01:45.185462: step 53520, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 17h:24m:48s remains)
INFO - root - 2017-12-16 18:01:47.402644: step 53530, loss = 0.54, batch loss = 0.36 (34.7 examples/sec; 0.230 sec/batch; 17h:51m:35s remains)
INFO - root - 2017-12-16 18:01:49.592091: step 53540, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 16h:56m:48s remains)
INFO - root - 2017-12-16 18:01:51.794531: step 53550, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 17h:04m:14s remains)
INFO - root - 2017-12-16 18:01:54.019211: step 53560, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 17h:01m:24s remains)
INFO - root - 2017-12-16 18:01:56.225554: step 53570, loss = 0.50, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 17h:48m:27s remains)
INFO - root - 2017-12-16 18:01:58.469061: step 53580, loss = 0.45, batch loss = 0.27 (34.7 examples/sec; 0.231 sec/batch; 17h:51m:45s remains)
INFO - root - 2017-12-16 18:02:00.666027: step 53590, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 17h:38m:27s remains)
INFO - root - 2017-12-16 18:02:02.851277: step 53600, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 16h:47m:32s remains)
INFO - root - 2017-12-16 18:02:05.208305: step 53610, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 16h:53m:03s remains)
INFO - root - 2017-12-16 18:02:07.385985: step 53620, loss = 0.47, batch loss = 0.29 (39.3 examples/sec; 0.203 sec/batch; 15h:45m:32s remains)
INFO - root - 2017-12-16 18:02:09.646143: step 53630, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 16h:53m:50s remains)
INFO - root - 2017-12-16 18:02:11.858736: step 53640, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 17h:12m:45s remains)
INFO - root - 2017-12-16 18:02:14.039836: step 53650, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 17h:08m:44s remains)
INFO - root - 2017-12-16 18:02:16.273666: step 53660, loss = 0.42, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 17h:04m:43s remains)
INFO - root - 2017-12-16 18:02:18.468142: step 53670, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 16h:52m:01s remains)
INFO - root - 2017-12-16 18:02:20.702217: step 53680, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 17h:22m:13s remains)
INFO - root - 2017-12-16 18:02:22.885556: step 53690, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 16h:32m:51s remains)
INFO - root - 2017-12-16 18:02:25.123023: step 53700, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 17h:26m:55s remains)
INFO - root - 2017-12-16 18:02:27.465401: step 53710, loss = 0.47, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 17h:12m:35s remains)
INFO - root - 2017-12-16 18:02:29.667953: step 53720, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 16h:23m:14s remains)
INFO - root - 2017-12-16 18:02:31.856046: step 53730, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 16h:52m:01s remains)
INFO - root - 2017-12-16 18:02:34.075688: step 53740, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 16h:57m:58s remains)
INFO - root - 2017-12-16 18:02:36.307335: step 53750, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 17h:15m:11s remains)
INFO - root - 2017-12-16 18:02:38.517758: step 53760, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.215 sec/batch; 16h:40m:48s remains)
INFO - root - 2017-12-16 18:02:40.730145: step 53770, loss = 0.42, batch loss = 0.24 (36.8 examples/sec; 0.217 sec/batch; 16h:49m:06s remains)
INFO - root - 2017-12-16 18:02:42.933589: step 53780, loss = 0.49, batch loss = 0.31 (34.2 examples/sec; 0.234 sec/batch; 18h:05m:02s remains)
INFO - root - 2017-12-16 18:02:45.150913: step 53790, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 16h:38m:21s remains)
INFO - root - 2017-12-16 18:02:47.332769: step 53800, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 16h:33m:24s remains)
INFO - root - 2017-12-16 18:02:49.638136: step 53810, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 16h:46m:40s remains)
INFO - root - 2017-12-16 18:02:51.849187: step 53820, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 17h:13m:02s remains)
INFO - root - 2017-12-16 18:02:54.092253: step 53830, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 17h:03m:48s remains)
INFO - root - 2017-12-16 18:02:56.300470: step 53840, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 17h:03m:41s remains)
INFO - root - 2017-12-16 18:02:58.513206: step 53850, loss = 0.43, batch loss = 0.25 (33.4 examples/sec; 0.239 sec/batch; 18h:31m:44s remains)
INFO - root - 2017-12-16 18:03:00.749692: step 53860, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.218 sec/batch; 16h:54m:01s remains)
INFO - root - 2017-12-16 18:03:02.948286: step 53870, loss = 0.47, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 16h:42m:42s remains)
INFO - root - 2017-12-16 18:03:05.243333: step 53880, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 17h:13m:24s remains)
INFO - root - 2017-12-16 18:03:07.465824: step 53890, loss = 0.52, batch loss = 0.34 (35.0 examples/sec; 0.229 sec/batch; 17h:42m:36s remains)
INFO - root - 2017-12-16 18:03:09.670405: step 53900, loss = 0.43, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 16h:33m:52s remains)
INFO - root - 2017-12-16 18:03:12.044505: step 53910, loss = 0.44, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 17h:16m:04s remains)
INFO - root - 2017-12-16 18:03:14.269768: step 53920, loss = 0.51, batch loss = 0.34 (37.1 examples/sec; 0.216 sec/batch; 16h:42m:29s remains)
INFO - root - 2017-12-16 18:03:16.486920: step 53930, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 17h:32m:02s remains)
INFO - root - 2017-12-16 18:03:18.697061: step 53940, loss = 0.51, batch loss = 0.33 (34.9 examples/sec; 0.230 sec/batch; 17h:45m:43s remains)
INFO - root - 2017-12-16 18:03:20.931257: step 53950, loss = 0.49, batch loss = 0.31 (34.4 examples/sec; 0.233 sec/batch; 17h:59m:34s remains)
INFO - root - 2017-12-16 18:03:23.121994: step 53960, loss = 0.57, batch loss = 0.39 (35.6 examples/sec; 0.224 sec/batch; 17h:21m:45s remains)
INFO - root - 2017-12-16 18:03:25.324136: step 53970, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 17h:04m:38s remains)
INFO - root - 2017-12-16 18:03:27.495198: step 53980, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 16h:39m:51s remains)
INFO - root - 2017-12-16 18:03:29.698253: step 53990, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 16h:54m:14s remains)
INFO - root - 2017-12-16 18:03:31.924371: step 54000, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.228 sec/batch; 17h:36m:04s remains)
INFO - root - 2017-12-16 18:03:34.256985: step 54010, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 16h:45m:55s remains)
INFO - root - 2017-12-16 18:03:36.472237: step 54020, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 16h:57m:52s remains)
INFO - root - 2017-12-16 18:03:38.703977: step 54030, loss = 0.57, batch loss = 0.39 (37.2 examples/sec; 0.215 sec/batch; 16h:39m:03s remains)
INFO - root - 2017-12-16 18:03:40.905750: step 54040, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 16h:50m:24s remains)
INFO - root - 2017-12-16 18:03:43.077227: step 54050, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.224 sec/batch; 17h:21m:40s remains)
INFO - root - 2017-12-16 18:03:45.298740: step 54060, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 16h:48m:17s remains)
INFO - root - 2017-12-16 18:03:47.484422: step 54070, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 16h:58m:40s remains)
INFO - root - 2017-12-16 18:03:49.674901: step 54080, loss = 0.48, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 17h:11m:02s remains)
INFO - root - 2017-12-16 18:03:51.884697: step 54090, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 17h:13m:28s remains)
INFO - root - 2017-12-16 18:03:54.123519: step 54100, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 17h:12m:40s remains)
INFO - root - 2017-12-16 18:03:56.448748: step 54110, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 16h:52m:23s remains)
INFO - root - 2017-12-16 18:03:58.694131: step 54120, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 17h:35m:09s remains)
INFO - root - 2017-12-16 18:04:00.897419: step 54130, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 17h:27m:01s remains)
INFO - root - 2017-12-16 18:04:03.115876: step 54140, loss = 0.53, batch loss = 0.35 (35.4 examples/sec; 0.226 sec/batch; 17h:27m:06s remains)
INFO - root - 2017-12-16 18:04:05.366727: step 54150, loss = 0.59, batch loss = 0.41 (35.3 examples/sec; 0.226 sec/batch; 17h:30m:29s remains)
INFO - root - 2017-12-16 18:04:07.557158: step 54160, loss = 0.53, batch loss = 0.35 (37.6 examples/sec; 0.213 sec/batch; 16h:27m:57s remains)
INFO - root - 2017-12-16 18:04:09.730105: step 54170, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 17h:07m:13s remains)
INFO - root - 2017-12-16 18:04:11.987317: step 54180, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 16h:52m:22s remains)
INFO - root - 2017-12-16 18:04:14.207020: step 54190, loss = 0.44, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 16h:38m:19s remains)
INFO - root - 2017-12-16 18:04:16.391025: step 54200, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 16h:55m:41s remains)
INFO - root - 2017-12-16 18:04:18.706211: step 54210, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 16h:35m:53s remains)
INFO - root - 2017-12-16 18:04:20.892856: step 54220, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 16h:51m:57s remains)
INFO - root - 2017-12-16 18:04:23.093728: step 54230, loss = 0.42, batch loss = 0.24 (36.5 examples/sec; 0.219 sec/batch; 16h:57m:30s remains)
INFO - root - 2017-12-16 18:04:25.303027: step 54240, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 16h:55m:57s remains)
INFO - root - 2017-12-16 18:04:27.535611: step 54250, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 16h:55m:01s remains)
INFO - root - 2017-12-16 18:04:29.758464: step 54260, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 17h:56m:46s remains)
INFO - root - 2017-12-16 18:04:31.951207: step 54270, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 16h:39m:35s remains)
INFO - root - 2017-12-16 18:04:34.155935: step 54280, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 16h:39m:51s remains)
INFO - root - 2017-12-16 18:04:36.384399: step 54290, loss = 0.51, batch loss = 0.33 (37.5 examples/sec; 0.213 sec/batch; 16h:27m:54s remains)
INFO - root - 2017-12-16 18:04:38.647911: step 54300, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 17h:35m:23s remains)
INFO - root - 2017-12-16 18:04:41.016291: step 54310, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 16h:59m:39s remains)
INFO - root - 2017-12-16 18:04:43.229724: step 54320, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 16h:45m:14s remains)
INFO - root - 2017-12-16 18:04:45.441619: step 54330, loss = 0.50, batch loss = 0.32 (37.5 examples/sec; 0.214 sec/batch; 16h:30m:08s remains)
INFO - root - 2017-12-16 18:04:47.622012: step 54340, loss = 0.50, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 16h:41m:37s remains)
INFO - root - 2017-12-16 18:04:49.855346: step 54350, loss = 0.50, batch loss = 0.32 (34.2 examples/sec; 0.234 sec/batch; 18h:02m:54s remains)
INFO - root - 2017-12-16 18:04:52.066173: step 54360, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 16h:26m:48s remains)
INFO - root - 2017-12-16 18:04:54.227384: step 54370, loss = 0.45, batch loss = 0.28 (37.7 examples/sec; 0.212 sec/batch; 16h:22m:57s remains)
INFO - root - 2017-12-16 18:04:56.437517: step 54380, loss = 0.49, batch loss = 0.31 (33.3 examples/sec; 0.240 sec/batch; 18h:32m:16s remains)
INFO - root - 2017-12-16 18:04:58.639992: step 54390, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 17h:12m:27s remains)
INFO - root - 2017-12-16 18:05:00.853790: step 54400, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.218 sec/batch; 16h:51m:48s remains)
INFO - root - 2017-12-16 18:05:03.199900: step 54410, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 16h:52m:18s remains)
INFO - root - 2017-12-16 18:05:05.435521: step 54420, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 16h:56m:41s remains)
INFO - root - 2017-12-16 18:05:07.645619: step 54430, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 16h:49m:04s remains)
INFO - root - 2017-12-16 18:05:09.842086: step 54440, loss = 0.54, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 17h:11m:48s remains)
INFO - root - 2017-12-16 18:05:12.071081: step 54450, loss = 0.54, batch loss = 0.36 (36.4 examples/sec; 0.220 sec/batch; 16h:59m:20s remains)
INFO - root - 2017-12-16 18:05:14.279545: step 54460, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 17h:05m:19s remains)
INFO - root - 2017-12-16 18:05:16.529839: step 54470, loss = 0.53, batch loss = 0.35 (35.4 examples/sec; 0.226 sec/batch; 17h:27m:20s remains)
INFO - root - 2017-12-16 18:05:18.761221: step 54480, loss = 0.56, batch loss = 0.38 (33.9 examples/sec; 0.236 sec/batch; 18h:15m:04s remains)
INFO - root - 2017-12-16 18:05:20.991662: step 54490, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 17h:05m:46s remains)
INFO - root - 2017-12-16 18:05:23.198215: step 54500, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 17h:15m:39s remains)
INFO - root - 2017-12-16 18:05:25.512044: step 54510, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 17h:35m:20s remains)
INFO - root - 2017-12-16 18:05:27.742152: step 54520, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 16h:43m:39s remains)
INFO - root - 2017-12-16 18:05:29.922982: step 54530, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 17h:35m:34s remains)
INFO - root - 2017-12-16 18:05:32.160012: step 54540, loss = 0.47, batch loss = 0.30 (35.2 examples/sec; 0.228 sec/batch; 17h:34m:03s remains)
INFO - root - 2017-12-16 18:05:34.389256: step 54550, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 17h:04m:05s remains)
INFO - root - 2017-12-16 18:05:36.620704: step 54560, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 16h:27m:53s remains)
INFO - root - 2017-12-16 18:05:38.841646: step 54570, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 17h:00m:21s remains)
INFO - root - 2017-12-16 18:05:41.038478: step 54580, loss = 0.52, batch loss = 0.34 (34.9 examples/sec; 0.229 sec/batch; 17h:42m:47s remains)
INFO - root - 2017-12-16 18:05:43.246610: step 54590, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 16h:53m:24s remains)
INFO - root - 2017-12-16 18:05:45.455643: step 54600, loss = 0.59, batch loss = 0.41 (35.7 examples/sec; 0.224 sec/batch; 17h:19m:21s remains)
INFO - root - 2017-12-16 18:05:47.820318: step 54610, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 17h:00m:14s remains)
INFO - root - 2017-12-16 18:05:50.019760: step 54620, loss = 0.55, batch loss = 0.38 (37.4 examples/sec; 0.214 sec/batch; 16h:31m:17s remains)
INFO - root - 2017-12-16 18:05:52.229339: step 54630, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 16h:37m:05s remains)
INFO - root - 2017-12-16 18:05:54.442024: step 54640, loss = 0.46, batch loss = 0.28 (38.0 examples/sec; 0.211 sec/batch; 16h:14m:56s remains)
INFO - root - 2017-12-16 18:05:56.641077: step 54650, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 16h:58m:35s remains)
INFO - root - 2017-12-16 18:05:58.885412: step 54660, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 16h:45m:52s remains)
INFO - root - 2017-12-16 18:06:01.104874: step 54670, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 16h:51m:48s remains)
INFO - root - 2017-12-16 18:06:03.342771: step 54680, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 16h:40m:23s remains)
INFO - root - 2017-12-16 18:06:05.608766: step 54690, loss = 0.51, batch loss = 0.33 (32.7 examples/sec; 0.244 sec/batch; 18h:51m:43s remains)
INFO - root - 2017-12-16 18:06:07.817322: step 54700, loss = 0.45, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 16h:43m:55s remains)
INFO - root - 2017-12-16 18:06:10.187208: step 54710, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 16h:58m:32s remains)
INFO - root - 2017-12-16 18:06:12.393536: step 54720, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 16h:32m:08s remains)
INFO - root - 2017-12-16 18:06:14.594355: step 54730, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.218 sec/batch; 16h:51m:29s remains)
INFO - root - 2017-12-16 18:06:16.826445: step 54740, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 17h:30m:50s remains)
INFO - root - 2017-12-16 18:06:19.053375: step 54750, loss = 0.50, batch loss = 0.32 (34.2 examples/sec; 0.234 sec/batch; 18h:03m:49s remains)
INFO - root - 2017-12-16 18:06:21.296358: step 54760, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 17h:23m:51s remains)
INFO - root - 2017-12-16 18:06:23.526760: step 54770, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 17h:01m:13s remains)
INFO - root - 2017-12-16 18:06:25.768344: step 54780, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 17h:18m:12s remains)
INFO - root - 2017-12-16 18:06:28.022856: step 54790, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 17h:08m:13s remains)
INFO - root - 2017-12-16 18:06:30.257983: step 54800, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 17h:07m:07s remains)
INFO - root - 2017-12-16 18:06:32.630003: step 54810, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.231 sec/batch; 17h:48m:38s remains)
INFO - root - 2017-12-16 18:06:34.859839: step 54820, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 16h:59m:06s remains)
INFO - root - 2017-12-16 18:06:37.066022: step 54830, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 16h:39m:51s remains)
INFO - root - 2017-12-16 18:06:39.282161: step 54840, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 17h:29m:04s remains)
INFO - root - 2017-12-16 18:06:41.504299: step 54850, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 17h:07m:28s remains)
INFO - root - 2017-12-16 18:06:43.739161: step 54860, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 17h:21m:29s remains)
INFO - root - 2017-12-16 18:06:45.947604: step 54870, loss = 0.57, batch loss = 0.39 (35.3 examples/sec; 0.227 sec/batch; 17h:29m:32s remains)
INFO - root - 2017-12-16 18:06:48.150405: step 54880, loss = 0.53, batch loss = 0.36 (37.4 examples/sec; 0.214 sec/batch; 16h:28m:31s remains)
INFO - root - 2017-12-16 18:06:50.335342: step 54890, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 17h:10m:34s remains)
INFO - root - 2017-12-16 18:06:52.552867: step 54900, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 16h:43m:38s remains)
INFO - root - 2017-12-16 18:06:54.880842: step 54910, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 17h:10m:17s remains)
INFO - root - 2017-12-16 18:06:57.063761: step 54920, loss = 0.50, batch loss = 0.32 (38.1 examples/sec; 0.210 sec/batch; 16h:12m:26s remains)
INFO - root - 2017-12-16 18:06:59.268501: step 54930, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 17h:30m:59s remains)
INFO - root - 2017-12-16 18:07:01.479673: step 54940, loss = 0.49, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 16h:22m:06s remains)
INFO - root - 2017-12-16 18:07:03.715818: step 54950, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 17h:13m:36s remains)
INFO - root - 2017-12-16 18:07:05.953037: step 54960, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.226 sec/batch; 17h:27m:29s remains)
INFO - root - 2017-12-16 18:07:08.197234: step 54970, loss = 0.44, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 17h:14m:41s remains)
INFO - root - 2017-12-16 18:07:10.398869: step 54980, loss = 0.51, batch loss = 0.33 (35.1 examples/sec; 0.228 sec/batch; 17h:34m:46s remains)
INFO - root - 2017-12-16 18:07:12.647843: step 54990, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 17h:05m:42s remains)
INFO - root - 2017-12-16 18:07:14.851726: step 55000, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 17h:43m:43s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-55000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-55000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 18:07:17.699563: step 55010, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 16h:27m:57s remains)
INFO - root - 2017-12-16 18:07:19.881628: step 55020, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 17h:01m:32s remains)
INFO - root - 2017-12-16 18:07:22.123239: step 55030, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.233 sec/batch; 17h:56m:58s remains)
INFO - root - 2017-12-16 18:07:24.380273: step 55040, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.228 sec/batch; 17h:32m:16s remains)
INFO - root - 2017-12-16 18:07:26.568907: step 55050, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 16h:26m:54s remains)
INFO - root - 2017-12-16 18:07:28.792477: step 55060, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 17h:06m:23s remains)
INFO - root - 2017-12-16 18:07:31.053378: step 55070, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 17h:25m:51s remains)
INFO - root - 2017-12-16 18:07:33.290714: step 55080, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 16h:42m:49s remains)
INFO - root - 2017-12-16 18:07:35.550468: step 55090, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 17h:08m:54s remains)
INFO - root - 2017-12-16 18:07:37.776159: step 55100, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 16h:56m:29s remains)
INFO - root - 2017-12-16 18:07:40.143761: step 55110, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.218 sec/batch; 16h:49m:40s remains)
INFO - root - 2017-12-16 18:07:42.362730: step 55120, loss = 0.57, batch loss = 0.39 (37.1 examples/sec; 0.216 sec/batch; 16h:36m:24s remains)
INFO - root - 2017-12-16 18:07:44.568433: step 55130, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 16h:28m:38s remains)
INFO - root - 2017-12-16 18:07:46.782468: step 55140, loss = 0.48, batch loss = 0.30 (34.7 examples/sec; 0.231 sec/batch; 17h:47m:05s remains)
INFO - root - 2017-12-16 18:07:49.004996: step 55150, loss = 0.49, batch loss = 0.31 (34.1 examples/sec; 0.234 sec/batch; 18h:03m:35s remains)
INFO - root - 2017-12-16 18:07:51.233324: step 55160, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 16h:52m:15s remains)
INFO - root - 2017-12-16 18:07:53.464843: step 55170, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 17h:10m:35s remains)
INFO - root - 2017-12-16 18:07:55.693896: step 55180, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 16h:52m:00s remains)
INFO - root - 2017-12-16 18:07:57.917615: step 55190, loss = 0.50, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 17h:11m:45s remains)
INFO - root - 2017-12-16 18:08:00.116626: step 55200, loss = 0.53, batch loss = 0.35 (35.8 examples/sec; 0.223 sec/batch; 17h:11m:36s remains)
INFO - root - 2017-12-16 18:08:02.473819: step 55210, loss = 0.47, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 17h:05m:09s remains)
INFO - root - 2017-12-16 18:08:04.677516: step 55220, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 17h:12m:45s remains)
INFO - root - 2017-12-16 18:08:06.868939: step 55230, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 16h:34m:58s remains)
INFO - root - 2017-12-16 18:08:09.116933: step 55240, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 17h:01m:57s remains)
INFO - root - 2017-12-16 18:08:11.359411: step 55250, loss = 0.49, batch loss = 0.31 (34.0 examples/sec; 0.235 sec/batch; 18h:06m:05s remains)
INFO - root - 2017-12-16 18:08:13.571588: step 55260, loss = 0.49, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 16h:30m:55s remains)
INFO - root - 2017-12-16 18:08:15.799823: step 55270, loss = 0.58, batch loss = 0.40 (37.4 examples/sec; 0.214 sec/batch; 16h:29m:38s remains)
INFO - root - 2017-12-16 18:08:18.040021: step 55280, loss = 0.46, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 17h:19m:02s remains)
INFO - root - 2017-12-16 18:08:20.264118: step 55290, loss = 0.44, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 16h:33m:29s remains)
INFO - root - 2017-12-16 18:08:22.458484: step 55300, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 16h:45m:11s remains)
INFO - root - 2017-12-16 18:08:24.792287: step 55310, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 16h:38m:42s remains)
INFO - root - 2017-12-16 18:08:27.025833: step 55320, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 16h:42m:09s remains)
INFO - root - 2017-12-16 18:08:29.236040: step 55330, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 17h:36m:14s remains)
INFO - root - 2017-12-16 18:08:31.426880: step 55340, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 17h:22m:44s remains)
INFO - root - 2017-12-16 18:08:33.646232: step 55350, loss = 0.48, batch loss = 0.31 (37.8 examples/sec; 0.212 sec/batch; 16h:18m:52s remains)
INFO - root - 2017-12-16 18:08:35.851127: step 55360, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 17h:00m:56s remains)
INFO - root - 2017-12-16 18:08:38.085457: step 55370, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 17h:17m:11s remains)
INFO - root - 2017-12-16 18:08:40.309500: step 55380, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 17h:11m:15s remains)
INFO - root - 2017-12-16 18:08:42.528058: step 55390, loss = 0.47, batch loss = 0.30 (37.5 examples/sec; 0.214 sec/batch; 16h:26m:06s remains)
INFO - root - 2017-12-16 18:08:44.758668: step 55400, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 17h:10m:27s remains)
INFO - root - 2017-12-16 18:08:47.162532: step 55410, loss = 0.49, batch loss = 0.32 (34.0 examples/sec; 0.235 sec/batch; 18h:05m:35s remains)
INFO - root - 2017-12-16 18:08:49.373187: step 55420, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 17h:26m:41s remains)
INFO - root - 2017-12-16 18:08:51.584843: step 55430, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 16h:45m:53s remains)
INFO - root - 2017-12-16 18:08:53.798417: step 55440, loss = 0.42, batch loss = 0.24 (35.0 examples/sec; 0.228 sec/batch; 17h:34m:42s remains)
INFO - root - 2017-12-16 18:08:56.033069: step 55450, loss = 0.53, batch loss = 0.36 (36.8 examples/sec; 0.218 sec/batch; 16h:44m:32s remains)
INFO - root - 2017-12-16 18:08:58.254024: step 55460, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 17h:27m:30s remains)
INFO - root - 2017-12-16 18:09:00.480149: step 55470, loss = 0.51, batch loss = 0.33 (34.3 examples/sec; 0.233 sec/batch; 17h:55m:24s remains)
INFO - root - 2017-12-16 18:09:02.702304: step 55480, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.232 sec/batch; 17h:53m:12s remains)
INFO - root - 2017-12-16 18:09:04.963809: step 55490, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 17h:28m:29s remains)
INFO - root - 2017-12-16 18:09:07.185169: step 55500, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 16h:39m:21s remains)
INFO - root - 2017-12-16 18:09:09.532644: step 55510, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 16h:44m:56s remains)
INFO - root - 2017-12-16 18:09:11.772518: step 55520, loss = 0.49, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 16h:45m:55s remains)
INFO - root - 2017-12-16 18:09:13.979695: step 55530, loss = 0.59, batch loss = 0.41 (34.8 examples/sec; 0.230 sec/batch; 17h:41m:25s remains)
INFO - root - 2017-12-16 18:09:16.178805: step 55540, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 16h:58m:30s remains)
INFO - root - 2017-12-16 18:09:18.375593: step 55550, loss = 0.45, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 16h:44m:57s remains)
INFO - root - 2017-12-16 18:09:20.654875: step 55560, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 17h:10m:28s remains)
INFO - root - 2017-12-16 18:09:22.858671: step 55570, loss = 0.46, batch loss = 0.28 (33.7 examples/sec; 0.237 sec/batch; 18h:15m:30s remains)
INFO - root - 2017-12-16 18:09:25.076407: step 55580, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 16h:53m:07s remains)
INFO - root - 2017-12-16 18:09:27.284010: step 55590, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 16h:37m:52s remains)
INFO - root - 2017-12-16 18:09:29.485142: step 55600, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 16h:35m:19s remains)
INFO - root - 2017-12-16 18:09:31.825785: step 55610, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 16h:49m:17s remains)
INFO - root - 2017-12-16 18:09:34.055225: step 55620, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 16h:27m:28s remains)
INFO - root - 2017-12-16 18:09:36.275668: step 55630, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 17h:20m:46s remains)
INFO - root - 2017-12-16 18:09:38.489176: step 55640, loss = 0.56, batch loss = 0.39 (35.5 examples/sec; 0.226 sec/batch; 17h:20m:33s remains)
INFO - root - 2017-12-16 18:09:40.729405: step 55650, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 16h:42m:18s remains)
INFO - root - 2017-12-16 18:09:42.942812: step 55660, loss = 0.54, batch loss = 0.36 (35.0 examples/sec; 0.229 sec/batch; 17h:35m:10s remains)
INFO - root - 2017-12-16 18:09:45.133814: step 55670, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 16h:45m:43s remains)
INFO - root - 2017-12-16 18:09:47.340679: step 55680, loss = 0.46, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 16h:29m:57s remains)
INFO - root - 2017-12-16 18:09:49.549680: step 55690, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.228 sec/batch; 17h:29m:47s remains)
INFO - root - 2017-12-16 18:09:51.740554: step 55700, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 16h:26m:51s remains)
INFO - root - 2017-12-16 18:09:54.096099: step 55710, loss = 0.44, batch loss = 0.26 (34.3 examples/sec; 0.233 sec/batch; 17h:55m:40s remains)
INFO - root - 2017-12-16 18:09:56.324100: step 55720, loss = 0.53, batch loss = 0.35 (35.1 examples/sec; 0.228 sec/batch; 17h:31m:56s remains)
INFO - root - 2017-12-16 18:09:58.553317: step 55730, loss = 0.45, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 16h:57m:08s remains)
INFO - root - 2017-12-16 18:10:00.747404: step 55740, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 16h:46m:51s remains)
INFO - root - 2017-12-16 18:10:02.944386: step 55750, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 16h:59m:12s remains)
INFO - root - 2017-12-16 18:10:05.129877: step 55760, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 16h:25m:34s remains)
INFO - root - 2017-12-16 18:10:07.348789: step 55770, loss = 0.45, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 17h:19m:55s remains)
INFO - root - 2017-12-16 18:10:09.578842: step 55780, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 17h:18m:11s remains)
INFO - root - 2017-12-16 18:10:11.783974: step 55790, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 16h:54m:34s remains)
INFO - root - 2017-12-16 18:10:13.994871: step 55800, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.219 sec/batch; 16h:48m:11s remains)
INFO - root - 2017-12-16 18:10:16.331646: step 55810, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.224 sec/batch; 17h:11m:49s remains)
INFO - root - 2017-12-16 18:10:18.539065: step 55820, loss = 0.44, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 16h:37m:53s remains)
INFO - root - 2017-12-16 18:10:20.769312: step 55830, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 16h:47m:16s remains)
INFO - root - 2017-12-16 18:10:22.968407: step 55840, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.219 sec/batch; 16h:48m:02s remains)
INFO - root - 2017-12-16 18:10:25.177717: step 55850, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 16h:45m:46s remains)
INFO - root - 2017-12-16 18:10:27.413291: step 55860, loss = 0.42, batch loss = 0.24 (34.5 examples/sec; 0.232 sec/batch; 17h:48m:26s remains)
INFO - root - 2017-12-16 18:10:29.641420: step 55870, loss = 0.55, batch loss = 0.37 (36.8 examples/sec; 0.218 sec/batch; 16h:43m:34s remains)
INFO - root - 2017-12-16 18:10:31.843241: step 55880, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 17h:02m:43s remains)
INFO - root - 2017-12-16 18:10:34.062966: step 55890, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 17h:17m:14s remains)
INFO - root - 2017-12-16 18:10:36.286478: step 55900, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 16h:48m:50s remains)
INFO - root - 2017-12-16 18:10:38.666102: step 55910, loss = 0.48, batch loss = 0.30 (34.1 examples/sec; 0.235 sec/batch; 18h:02m:06s remains)
INFO - root - 2017-12-16 18:10:40.905292: step 55920, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 17h:28m:09s remains)
INFO - root - 2017-12-16 18:10:43.098101: step 55930, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 17h:00m:59s remains)
INFO - root - 2017-12-16 18:10:45.326999: step 55940, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 16h:58m:59s remains)
INFO - root - 2017-12-16 18:10:47.535521: step 55950, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 16h:32m:31s remains)
INFO - root - 2017-12-16 18:10:49.752627: step 55960, loss = 0.52, batch loss = 0.34 (37.6 examples/sec; 0.213 sec/batch; 16h:19m:41s remains)
INFO - root - 2017-12-16 18:10:51.955207: step 55970, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 16h:52m:39s remains)
INFO - root - 2017-12-16 18:10:54.155981: step 55980, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 16h:42m:12s remains)
INFO - root - 2017-12-16 18:10:56.359305: step 55990, loss = 0.51, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 16h:52m:43s remains)
INFO - root - 2017-12-16 18:10:58.573080: step 56000, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 17h:12m:00s remains)
INFO - root - 2017-12-16 18:11:00.949308: step 56010, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 17h:08m:55s remains)
INFO - root - 2017-12-16 18:11:03.188279: step 56020, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 17h:10m:08s remains)
INFO - root - 2017-12-16 18:11:05.391132: step 56030, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 16h:59m:00s remains)
INFO - root - 2017-12-16 18:11:07.610541: step 56040, loss = 0.46, batch loss = 0.28 (34.2 examples/sec; 0.234 sec/batch; 17h:57m:02s remains)
INFO - root - 2017-12-16 18:11:09.841575: step 56050, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 17h:02m:16s remains)
INFO - root - 2017-12-16 18:11:12.059566: step 56060, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 16h:55m:11s remains)
INFO - root - 2017-12-16 18:11:14.271807: step 56070, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 17h:16m:53s remains)
INFO - root - 2017-12-16 18:11:16.518872: step 56080, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 17h:06m:24s remains)
INFO - root - 2017-12-16 18:11:18.789977: step 56090, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 16h:47m:23s remains)
INFO - root - 2017-12-16 18:11:20.980424: step 56100, loss = 0.53, batch loss = 0.36 (36.0 examples/sec; 0.222 sec/batch; 17h:02m:23s remains)
INFO - root - 2017-12-16 18:11:23.302717: step 56110, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 16h:33m:19s remains)
INFO - root - 2017-12-16 18:11:25.533478: step 56120, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 17h:40m:11s remains)
INFO - root - 2017-12-16 18:11:27.808558: step 56130, loss = 0.55, batch loss = 0.37 (35.1 examples/sec; 0.228 sec/batch; 17h:29m:04s remains)
INFO - root - 2017-12-16 18:11:30.032785: step 56140, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 17h:12m:25s remains)
INFO - root - 2017-12-16 18:11:32.254778: step 56150, loss = 0.46, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 17h:00m:02s remains)
INFO - root - 2017-12-16 18:11:34.462865: step 56160, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 17h:00m:06s remains)
INFO - root - 2017-12-16 18:11:36.661040: step 56170, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 16h:48m:56s remains)
INFO - root - 2017-12-16 18:11:38.877862: step 56180, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.229 sec/batch; 17h:32m:23s remains)
INFO - root - 2017-12-16 18:11:41.064801: step 56190, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 16h:52m:06s remains)
INFO - root - 2017-12-16 18:11:43.287735: step 56200, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 16h:56m:43s remains)
INFO - root - 2017-12-16 18:11:45.650182: step 56210, loss = 0.51, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 16h:35m:47s remains)
INFO - root - 2017-12-16 18:11:47.895796: step 56220, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 17h:24m:56s remains)
INFO - root - 2017-12-16 18:11:50.123336: step 56230, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 16h:51m:29s remains)
INFO - root - 2017-12-16 18:11:52.351132: step 56240, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.228 sec/batch; 17h:30m:59s remains)
INFO - root - 2017-12-16 18:11:54.549652: step 56250, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 17h:18m:07s remains)
INFO - root - 2017-12-16 18:11:56.780966: step 56260, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 16h:56m:11s remains)
INFO - root - 2017-12-16 18:11:58.981692: step 56270, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 16h:48m:56s remains)
INFO - root - 2017-12-16 18:12:01.187356: step 56280, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 17h:14m:07s remains)
INFO - root - 2017-12-16 18:12:03.395208: step 56290, loss = 0.49, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 16h:57m:39s remains)
INFO - root - 2017-12-16 18:12:05.662982: step 56300, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 17h:17m:32s remains)
INFO - root - 2017-12-16 18:12:08.121777: step 56310, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 17h:30m:09s remains)
INFO - root - 2017-12-16 18:12:10.321914: step 56320, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 16h:43m:24s remains)
INFO - root - 2017-12-16 18:12:12.577075: step 56330, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.229 sec/batch; 17h:32m:26s remains)
INFO - root - 2017-12-16 18:12:14.813416: step 56340, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 16h:47m:14s remains)
INFO - root - 2017-12-16 18:12:17.044220: step 56350, loss = 0.51, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 17h:28m:04s remains)
INFO - root - 2017-12-16 18:12:19.267795: step 56360, loss = 0.54, batch loss = 0.36 (36.0 examples/sec; 0.222 sec/batch; 17h:02m:24s remains)
INFO - root - 2017-12-16 18:12:21.495962: step 56370, loss = 0.46, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 17h:23m:30s remains)
INFO - root - 2017-12-16 18:12:23.750841: step 56380, loss = 0.50, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 17h:03m:13s remains)
INFO - root - 2017-12-16 18:12:25.986371: step 56390, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 17h:26m:34s remains)
INFO - root - 2017-12-16 18:12:28.207124: step 56400, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 16h:25m:52s remains)
INFO - root - 2017-12-16 18:12:30.549649: step 56410, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 16h:36m:32s remains)
INFO - root - 2017-12-16 18:12:32.731910: step 56420, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 16h:47m:43s remains)
INFO - root - 2017-12-16 18:12:34.982854: step 56430, loss = 0.50, batch loss = 0.32 (34.3 examples/sec; 0.234 sec/batch; 17h:54m:28s remains)
INFO - root - 2017-12-16 18:12:37.192067: step 56440, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 17h:15m:12s remains)
INFO - root - 2017-12-16 18:12:39.386319: step 56450, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 16h:42m:07s remains)
INFO - root - 2017-12-16 18:12:41.619364: step 56460, loss = 0.48, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 17h:07m:32s remains)
INFO - root - 2017-12-16 18:12:43.811162: step 56470, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 17h:15m:11s remains)
INFO - root - 2017-12-16 18:12:46.021249: step 56480, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 17h:06m:38s remains)
INFO - root - 2017-12-16 18:12:48.212988: step 56490, loss = 0.54, batch loss = 0.36 (37.1 examples/sec; 0.216 sec/batch; 16h:32m:05s remains)
INFO - root - 2017-12-16 18:12:50.429603: step 56500, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 16h:40m:39s remains)
INFO - root - 2017-12-16 18:12:52.770756: step 56510, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 17h:06m:05s remains)
INFO - root - 2017-12-16 18:12:54.955753: step 56520, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 16h:33m:28s remains)
INFO - root - 2017-12-16 18:12:57.171138: step 56530, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 16h:59m:56s remains)
INFO - root - 2017-12-16 18:12:59.416961: step 56540, loss = 0.57, batch loss = 0.39 (35.0 examples/sec; 0.228 sec/batch; 17h:30m:53s remains)
INFO - root - 2017-12-16 18:13:01.606252: step 56550, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 17h:46m:46s remains)
INFO - root - 2017-12-16 18:13:03.854847: step 56560, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 16h:58m:35s remains)
INFO - root - 2017-12-16 18:13:06.083585: step 56570, loss = 0.44, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 17h:00m:14s remains)
INFO - root - 2017-12-16 18:13:08.349737: step 56580, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 17h:25m:52s remains)
INFO - root - 2017-12-16 18:13:10.534305: step 56590, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 17h:12m:30s remains)
INFO - root - 2017-12-16 18:13:12.754479: step 56600, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 17h:15m:33s remains)
INFO - root - 2017-12-16 18:13:15.103032: step 56610, loss = 0.51, batch loss = 0.33 (32.9 examples/sec; 0.243 sec/batch; 18h:39m:02s remains)
INFO - root - 2017-12-16 18:13:17.332858: step 56620, loss = 0.49, batch loss = 0.31 (34.4 examples/sec; 0.232 sec/batch; 17h:48m:04s remains)
INFO - root - 2017-12-16 18:13:19.542841: step 56630, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 16h:42m:17s remains)
INFO - root - 2017-12-16 18:13:21.731797: step 56640, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 16h:51m:04s remains)
INFO - root - 2017-12-16 18:13:23.986941: step 56650, loss = 0.61, batch loss = 0.43 (35.0 examples/sec; 0.229 sec/batch; 17h:31m:42s remains)
INFO - root - 2017-12-16 18:13:26.218585: step 56660, loss = 0.52, batch loss = 0.34 (33.9 examples/sec; 0.236 sec/batch; 18h:04m:19s remains)
INFO - root - 2017-12-16 18:13:28.440285: step 56670, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 17h:06m:46s remains)
INFO - root - 2017-12-16 18:13:30.716469: step 56680, loss = 0.42, batch loss = 0.24 (34.8 examples/sec; 0.230 sec/batch; 17h:36m:44s remains)
INFO - root - 2017-12-16 18:13:32.934084: step 56690, loss = 0.47, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 16h:26m:59s remains)
INFO - root - 2017-12-16 18:13:35.155451: step 56700, loss = 0.42, batch loss = 0.24 (34.1 examples/sec; 0.235 sec/batch; 17h:59m:12s remains)
INFO - root - 2017-12-16 18:13:37.509565: step 56710, loss = 0.50, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 16h:41m:44s remains)
INFO - root - 2017-12-16 18:13:39.750294: step 56720, loss = 0.42, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 16h:37m:39s remains)
INFO - root - 2017-12-16 18:13:41.898015: step 56730, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 16h:33m:06s remains)
INFO - root - 2017-12-16 18:13:44.153492: step 56740, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 16h:57m:04s remains)
INFO - root - 2017-12-16 18:13:46.366812: step 56750, loss = 0.46, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 16h:29m:15s remains)
INFO - root - 2017-12-16 18:13:48.611382: step 56760, loss = 0.45, batch loss = 0.27 (33.8 examples/sec; 0.237 sec/batch; 18h:06m:58s remains)
INFO - root - 2017-12-16 18:13:50.823604: step 56770, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 16h:45m:29s remains)
INFO - root - 2017-12-16 18:13:53.058707: step 56780, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 17h:14m:08s remains)
INFO - root - 2017-12-16 18:13:55.333508: step 56790, loss = 0.53, batch loss = 0.36 (36.0 examples/sec; 0.222 sec/batch; 17h:01m:39s remains)
INFO - root - 2017-12-16 18:13:57.588648: step 56800, loss = 0.41, batch loss = 0.23 (35.0 examples/sec; 0.228 sec/batch; 17h:29m:22s remains)
INFO - root - 2017-12-16 18:13:59.980544: step 56810, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.228 sec/batch; 17h:25m:24s remains)
INFO - root - 2017-12-16 18:14:02.192527: step 56820, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 16h:44m:27s remains)
INFO - root - 2017-12-16 18:14:04.404528: step 56830, loss = 0.47, batch loss = 0.29 (34.0 examples/sec; 0.236 sec/batch; 18h:02m:04s remains)
INFO - root - 2017-12-16 18:14:06.628895: step 56840, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 17h:03m:48s remains)
INFO - root - 2017-12-16 18:14:08.828865: step 56850, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 16h:51m:32s remains)
INFO - root - 2017-12-16 18:14:11.031134: step 56860, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 16h:31m:02s remains)
INFO - root - 2017-12-16 18:14:13.238784: step 56870, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 17h:14m:35s remains)
INFO - root - 2017-12-16 18:14:15.460879: step 56880, loss = 0.47, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 17h:53m:11s remains)
INFO - root - 2017-12-16 18:14:17.706313: step 56890, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 17h:00m:58s remains)
INFO - root - 2017-12-16 18:14:19.925492: step 56900, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 16h:47m:31s remains)
INFO - root - 2017-12-16 18:14:22.281393: step 56910, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 16h:47m:09s remains)
INFO - root - 2017-12-16 18:14:24.508959: step 56920, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 16h:46m:38s remains)
INFO - root - 2017-12-16 18:14:26.702236: step 56930, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 17h:09m:10s remains)
INFO - root - 2017-12-16 18:14:28.961318: step 56940, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 17h:20m:50s remains)
INFO - root - 2017-12-16 18:14:31.177004: step 56950, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 16h:44m:48s remains)
INFO - root - 2017-12-16 18:14:33.347972: step 56960, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 16h:25m:04s remains)
INFO - root - 2017-12-16 18:14:35.570039: step 56970, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 17h:00m:13s remains)
INFO - root - 2017-12-16 18:14:37.788127: step 56980, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 16h:35m:45s remains)
INFO - root - 2017-12-16 18:14:39.979322: step 56990, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.226 sec/batch; 17h:19m:42s remains)
INFO - root - 2017-12-16 18:14:42.169266: step 57000, loss = 0.42, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 17h:12m:38s remains)
INFO - root - 2017-12-16 18:14:44.479069: step 57010, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 16h:42m:11s remains)
INFO - root - 2017-12-16 18:14:46.678132: step 57020, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 16h:46m:31s remains)
INFO - root - 2017-12-16 18:14:48.858507: step 57030, loss = 0.45, batch loss = 0.27 (38.0 examples/sec; 0.211 sec/batch; 16h:07m:00s remains)
INFO - root - 2017-12-16 18:14:51.031000: step 57040, loss = 0.46, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 17h:01m:52s remains)
INFO - root - 2017-12-16 18:14:53.274025: step 57050, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 16h:31m:00s remains)
INFO - root - 2017-12-16 18:14:55.468660: step 57060, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 17h:00m:43s remains)
INFO - root - 2017-12-16 18:14:57.714931: step 57070, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 16h:47m:55s remains)
INFO - root - 2017-12-16 18:14:59.945295: step 57080, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 16h:46m:54s remains)
INFO - root - 2017-12-16 18:15:02.120012: step 57090, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.218 sec/batch; 16h:38m:39s remains)
INFO - root - 2017-12-16 18:15:04.317678: step 57100, loss = 0.51, batch loss = 0.33 (34.6 examples/sec; 0.231 sec/batch; 17h:40m:31s remains)
INFO - root - 2017-12-16 18:15:06.661439: step 57110, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 17h:00m:53s remains)
INFO - root - 2017-12-16 18:15:08.882480: step 57120, loss = 0.49, batch loss = 0.31 (34.2 examples/sec; 0.234 sec/batch; 17h:54m:17s remains)
INFO - root - 2017-12-16 18:15:11.117831: step 57130, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 16h:52m:16s remains)
INFO - root - 2017-12-16 18:15:13.351373: step 57140, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 16h:27m:27s remains)
INFO - root - 2017-12-16 18:15:15.555052: step 57150, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 16h:22m:27s remains)
INFO - root - 2017-12-16 18:15:17.751276: step 57160, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 16h:33m:19s remains)
INFO - root - 2017-12-16 18:15:19.963546: step 57170, loss = 0.45, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 16h:21m:19s remains)
INFO - root - 2017-12-16 18:15:22.175085: step 57180, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 17h:12m:47s remains)
INFO - root - 2017-12-16 18:15:24.392266: step 57190, loss = 0.50, batch loss = 0.32 (34.7 examples/sec; 0.230 sec/batch; 17h:36m:34s remains)
INFO - root - 2017-12-16 18:15:26.586264: step 57200, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 16h:48m:46s remains)
INFO - root - 2017-12-16 18:15:28.894723: step 57210, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 16h:19m:33s remains)
INFO - root - 2017-12-16 18:15:31.065946: step 57220, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 16h:26m:55s remains)
INFO - root - 2017-12-16 18:15:33.296213: step 57230, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 17h:42m:59s remains)
INFO - root - 2017-12-16 18:15:35.510612: step 57240, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 16h:54m:11s remains)
INFO - root - 2017-12-16 18:15:37.738903: step 57250, loss = 0.51, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 16h:58m:55s remains)
INFO - root - 2017-12-16 18:15:39.991521: step 57260, loss = 0.45, batch loss = 0.27 (34.7 examples/sec; 0.231 sec/batch; 17h:37m:37s remains)
INFO - root - 2017-12-16 18:15:42.216481: step 57270, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 16h:34m:08s remains)
INFO - root - 2017-12-16 18:15:44.425275: step 57280, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 16h:59m:08s remains)
INFO - root - 2017-12-16 18:15:46.613365: step 57290, loss = 0.52, batch loss = 0.34 (35.0 examples/sec; 0.229 sec/batch; 17h:28m:17s remains)
INFO - root - 2017-12-16 18:15:48.843440: step 57300, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 16h:28m:41s remains)
INFO - root - 2017-12-16 18:15:51.156424: step 57310, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 16h:36m:30s remains)
INFO - root - 2017-12-16 18:15:53.360336: step 57320, loss = 0.45, batch loss = 0.28 (38.2 examples/sec; 0.210 sec/batch; 16h:01m:01s remains)
INFO - root - 2017-12-16 18:15:55.548624: step 57330, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.214 sec/batch; 16h:19m:33s remains)
INFO - root - 2017-12-16 18:15:57.746476: step 57340, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 16h:48m:39s remains)
INFO - root - 2017-12-16 18:15:59.977600: step 57350, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 16h:43m:55s remains)
INFO - root - 2017-12-16 18:16:02.169460: step 57360, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 17h:29m:34s remains)
INFO - root - 2017-12-16 18:16:04.384393: step 57370, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 16h:48m:15s remains)
INFO - root - 2017-12-16 18:16:06.573084: step 57380, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 16h:50m:04s remains)
INFO - root - 2017-12-16 18:16:08.873673: step 57390, loss = 0.46, batch loss = 0.28 (33.6 examples/sec; 0.238 sec/batch; 18h:12m:21s remains)
INFO - root - 2017-12-16 18:16:11.095240: step 57400, loss = 0.43, batch loss = 0.25 (38.1 examples/sec; 0.210 sec/batch; 16h:01m:42s remains)
INFO - root - 2017-12-16 18:16:13.431213: step 57410, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 16h:24m:39s remains)
INFO - root - 2017-12-16 18:16:15.621495: step 57420, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 16h:31m:12s remains)
INFO - root - 2017-12-16 18:16:17.837497: step 57430, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 16h:37m:33s remains)
INFO - root - 2017-12-16 18:16:20.021697: step 57440, loss = 0.44, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 16h:42m:53s remains)
INFO - root - 2017-12-16 18:16:22.241894: step 57450, loss = 0.49, batch loss = 0.31 (34.7 examples/sec; 0.231 sec/batch; 17h:38m:04s remains)
INFO - root - 2017-12-16 18:16:24.467439: step 57460, loss = 0.59, batch loss = 0.41 (36.8 examples/sec; 0.217 sec/batch; 16h:35m:40s remains)
INFO - root - 2017-12-16 18:16:26.698038: step 57470, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 17h:00m:25s remains)
INFO - root - 2017-12-16 18:16:28.861674: step 57480, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 16h:33m:37s remains)
INFO - root - 2017-12-16 18:16:31.096741: step 57490, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 16h:45m:47s remains)
INFO - root - 2017-12-16 18:16:33.284942: step 57500, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 17h:02m:47s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-57500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-57500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 18:16:36.272239: step 57510, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 16h:28m:35s remains)
INFO - root - 2017-12-16 18:16:38.475555: step 57520, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 17h:01m:17s remains)
INFO - root - 2017-12-16 18:16:40.668722: step 57530, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 16h:46m:18s remains)
INFO - root - 2017-12-16 18:16:42.864891: step 57540, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 16h:27m:20s remains)
INFO - root - 2017-12-16 18:16:45.062902: step 57550, loss = 0.46, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 17h:10m:31s remains)
INFO - root - 2017-12-16 18:16:47.285119: step 57560, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 16h:21m:34s remains)
INFO - root - 2017-12-16 18:16:49.468861: step 57570, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 16h:39m:39s remains)
INFO - root - 2017-12-16 18:16:51.675800: step 57580, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 16h:37m:33s remains)
INFO - root - 2017-12-16 18:16:53.886210: step 57590, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 17h:04m:52s remains)
INFO - root - 2017-12-16 18:16:56.092453: step 57600, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 16h:33m:01s remains)
INFO - root - 2017-12-16 18:16:58.413535: step 57610, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 16h:52m:31s remains)
INFO - root - 2017-12-16 18:17:00.664587: step 57620, loss = 0.40, batch loss = 0.22 (33.8 examples/sec; 0.237 sec/batch; 18h:04m:31s remains)
INFO - root - 2017-12-16 18:17:02.922465: step 57630, loss = 0.49, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 17h:15m:05s remains)
INFO - root - 2017-12-16 18:17:05.152644: step 57640, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 16h:14m:40s remains)
INFO - root - 2017-12-16 18:17:07.363465: step 57650, loss = 0.44, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 16h:31m:21s remains)
INFO - root - 2017-12-16 18:17:09.596676: step 57660, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 16h:34m:35s remains)
INFO - root - 2017-12-16 18:17:11.810813: step 57670, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 16h:56m:46s remains)
INFO - root - 2017-12-16 18:17:13.993264: step 57680, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 16h:51m:59s remains)
INFO - root - 2017-12-16 18:17:16.190106: step 57690, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 16h:28m:45s remains)
INFO - root - 2017-12-16 18:17:18.381634: step 57700, loss = 0.45, batch loss = 0.27 (38.1 examples/sec; 0.210 sec/batch; 16h:02m:37s remains)
INFO - root - 2017-12-16 18:17:20.716454: step 57710, loss = 0.51, batch loss = 0.34 (34.6 examples/sec; 0.231 sec/batch; 17h:39m:16s remains)
INFO - root - 2017-12-16 18:17:22.914776: step 57720, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 16h:33m:03s remains)
INFO - root - 2017-12-16 18:17:25.105963: step 57730, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 16h:24m:26s remains)
INFO - root - 2017-12-16 18:17:27.336781: step 57740, loss = 0.47, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 17h:05m:08s remains)
INFO - root - 2017-12-16 18:17:29.507446: step 57750, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 16h:49m:19s remains)
INFO - root - 2017-12-16 18:17:31.696458: step 57760, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 16h:35m:56s remains)
INFO - root - 2017-12-16 18:17:33.892270: step 57770, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 16h:36m:25s remains)
INFO - root - 2017-12-16 18:17:36.086975: step 57780, loss = 0.49, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 16h:40m:14s remains)
INFO - root - 2017-12-16 18:17:38.319269: step 57790, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 16h:37m:03s remains)
INFO - root - 2017-12-16 18:17:40.508336: step 57800, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 16h:21m:49s remains)
INFO - root - 2017-12-16 18:17:42.848415: step 57810, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 17h:31m:57s remains)
INFO - root - 2017-12-16 18:17:45.027040: step 57820, loss = 0.51, batch loss = 0.33 (38.4 examples/sec; 0.209 sec/batch; 15h:54m:50s remains)
INFO - root - 2017-12-16 18:17:47.211342: step 57830, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 16h:44m:34s remains)
INFO - root - 2017-12-16 18:17:49.404040: step 57840, loss = 0.50, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 17h:02m:53s remains)
INFO - root - 2017-12-16 18:17:51.586473: step 57850, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 16h:12m:14s remains)
INFO - root - 2017-12-16 18:17:53.808715: step 57860, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 16h:51m:08s remains)
INFO - root - 2017-12-16 18:17:55.996031: step 57870, loss = 0.45, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 16h:37m:44s remains)
INFO - root - 2017-12-16 18:17:58.183088: step 57880, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 16h:39m:27s remains)
INFO - root - 2017-12-16 18:18:00.400243: step 57890, loss = 0.54, batch loss = 0.36 (34.7 examples/sec; 0.230 sec/batch; 17h:34m:29s remains)
INFO - root - 2017-12-16 18:18:02.634251: step 57900, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 16h:33m:55s remains)
INFO - root - 2017-12-16 18:18:05.003855: step 57910, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 17h:06m:49s remains)
INFO - root - 2017-12-16 18:18:07.206154: step 57920, loss = 0.44, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 17h:07m:26s remains)
INFO - root - 2017-12-16 18:18:09.421149: step 57930, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 17h:29m:02s remains)
INFO - root - 2017-12-16 18:18:11.623531: step 57940, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 16h:57m:57s remains)
INFO - root - 2017-12-16 18:18:13.847133: step 57950, loss = 0.42, batch loss = 0.24 (36.6 examples/sec; 0.219 sec/batch; 16h:41m:07s remains)
INFO - root - 2017-12-16 18:18:16.033730: step 57960, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 16h:48m:54s remains)
INFO - root - 2017-12-16 18:18:18.252505: step 57970, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 16h:54m:47s remains)
INFO - root - 2017-12-16 18:18:20.463026: step 57980, loss = 0.55, batch loss = 0.37 (36.0 examples/sec; 0.222 sec/batch; 16h:56m:05s remains)
INFO - root - 2017-12-16 18:18:22.690240: step 57990, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.224 sec/batch; 17h:02m:33s remains)
INFO - root - 2017-12-16 18:18:24.932573: step 58000, loss = 0.50, batch loss = 0.32 (34.7 examples/sec; 0.230 sec/batch; 17h:33m:39s remains)
INFO - root - 2017-12-16 18:18:27.284532: step 58010, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 16h:23m:29s remains)
INFO - root - 2017-12-16 18:18:29.505659: step 58020, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 17h:23m:22s remains)
INFO - root - 2017-12-16 18:18:31.755989: step 58030, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 16h:47m:56s remains)
INFO - root - 2017-12-16 18:18:33.953326: step 58040, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 16h:32m:20s remains)
INFO - root - 2017-12-16 18:18:36.153749: step 58050, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 16h:45m:58s remains)
INFO - root - 2017-12-16 18:18:38.336860: step 58060, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.215 sec/batch; 16h:21m:32s remains)
INFO - root - 2017-12-16 18:18:40.516541: step 58070, loss = 0.53, batch loss = 0.36 (36.1 examples/sec; 0.221 sec/batch; 16h:52m:12s remains)
INFO - root - 2017-12-16 18:18:42.688377: step 58080, loss = 0.42, batch loss = 0.24 (36.9 examples/sec; 0.217 sec/batch; 16h:32m:00s remains)
INFO - root - 2017-12-16 18:18:44.898742: step 58090, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 16h:54m:56s remains)
INFO - root - 2017-12-16 18:18:47.086310: step 58100, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 16h:43m:59s remains)
INFO - root - 2017-12-16 18:18:49.439991: step 58110, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 16h:38m:21s remains)
INFO - root - 2017-12-16 18:18:51.681349: step 58120, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 17h:38m:57s remains)
INFO - root - 2017-12-16 18:18:53.927364: step 58130, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 16h:36m:51s remains)
INFO - root - 2017-12-16 18:18:56.114895: step 58140, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 16h:43m:43s remains)
INFO - root - 2017-12-16 18:18:58.301745: step 58150, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 16h:52m:19s remains)
INFO - root - 2017-12-16 18:19:00.499347: step 58160, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 16h:46m:52s remains)
INFO - root - 2017-12-16 18:19:02.717560: step 58170, loss = 0.43, batch loss = 0.25 (34.3 examples/sec; 0.233 sec/batch; 17h:47m:16s remains)
INFO - root - 2017-12-16 18:19:04.936768: step 58180, loss = 0.46, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 16h:51m:35s remains)
INFO - root - 2017-12-16 18:19:07.135790: step 58190, loss = 0.52, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 17h:21m:41s remains)
INFO - root - 2017-12-16 18:19:09.328671: step 58200, loss = 0.49, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 16h:23m:30s remains)
INFO - root - 2017-12-16 18:19:11.710584: step 58210, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 17h:28m:30s remains)
INFO - root - 2017-12-16 18:19:13.942553: step 58220, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 17h:05m:18s remains)
INFO - root - 2017-12-16 18:19:16.162168: step 58230, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 16h:45m:13s remains)
INFO - root - 2017-12-16 18:19:18.348738: step 58240, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.218 sec/batch; 16h:34m:43s remains)
INFO - root - 2017-12-16 18:19:20.560438: step 58250, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 16h:48m:48s remains)
INFO - root - 2017-12-16 18:19:22.860672: step 58260, loss = 0.43, batch loss = 0.25 (34.3 examples/sec; 0.233 sec/batch; 17h:45m:22s remains)
INFO - root - 2017-12-16 18:19:25.060705: step 58270, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 16h:34m:25s remains)
INFO - root - 2017-12-16 18:19:27.248720: step 58280, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 16h:20m:59s remains)
INFO - root - 2017-12-16 18:19:29.451376: step 58290, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 16h:30m:17s remains)
INFO - root - 2017-12-16 18:19:31.655340: step 58300, loss = 0.56, batch loss = 0.38 (36.0 examples/sec; 0.223 sec/batch; 16h:56m:49s remains)
INFO - root - 2017-12-16 18:19:34.012996: step 58310, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 16h:38m:29s remains)
INFO - root - 2017-12-16 18:19:36.200581: step 58320, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 17h:15m:37s remains)
INFO - root - 2017-12-16 18:19:38.404389: step 58330, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 17h:02m:34s remains)
INFO - root - 2017-12-16 18:19:40.637765: step 58340, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 17h:22m:26s remains)
INFO - root - 2017-12-16 18:19:42.852299: step 58350, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 16h:32m:05s remains)
INFO - root - 2017-12-16 18:19:45.093520: step 58360, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 16h:37m:41s remains)
INFO - root - 2017-12-16 18:19:47.329302: step 58370, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 16h:45m:09s remains)
INFO - root - 2017-12-16 18:19:49.551543: step 58380, loss = 0.50, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 16h:43m:58s remains)
INFO - root - 2017-12-16 18:19:51.808281: step 58390, loss = 0.53, batch loss = 0.35 (35.5 examples/sec; 0.225 sec/batch; 17h:09m:37s remains)
INFO - root - 2017-12-16 18:19:54.068353: step 58400, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.229 sec/batch; 17h:24m:49s remains)
INFO - root - 2017-12-16 18:19:56.413396: step 58410, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 16h:47m:36s remains)
INFO - root - 2017-12-16 18:19:58.605067: step 58420, loss = 0.47, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 16h:08m:10s remains)
INFO - root - 2017-12-16 18:20:00.770431: step 58430, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 16h:54m:19s remains)
INFO - root - 2017-12-16 18:20:02.984013: step 58440, loss = 0.51, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 16h:30m:09s remains)
INFO - root - 2017-12-16 18:20:05.203760: step 58450, loss = 0.56, batch loss = 0.38 (35.3 examples/sec; 0.227 sec/batch; 17h:14m:46s remains)
INFO - root - 2017-12-16 18:20:07.421378: step 58460, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 16h:37m:22s remains)
INFO - root - 2017-12-16 18:20:09.634673: step 58470, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 16h:24m:25s remains)
INFO - root - 2017-12-16 18:20:11.846701: step 58480, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 16h:26m:37s remains)
INFO - root - 2017-12-16 18:20:14.022163: step 58490, loss = 0.62, batch loss = 0.44 (36.0 examples/sec; 0.222 sec/batch; 16h:54m:12s remains)
INFO - root - 2017-12-16 18:20:16.205782: step 58500, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.229 sec/batch; 17h:24m:25s remains)
INFO - root - 2017-12-16 18:20:18.594530: step 58510, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 16h:55m:23s remains)
INFO - root - 2017-12-16 18:20:20.804516: step 58520, loss = 0.43, batch loss = 0.25 (37.6 examples/sec; 0.213 sec/batch; 16h:12m:23s remains)
INFO - root - 2017-12-16 18:20:23.025896: step 58530, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 17h:23m:37s remains)
INFO - root - 2017-12-16 18:20:25.293591: step 58540, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.231 sec/batch; 17h:35m:05s remains)
INFO - root - 2017-12-16 18:20:27.484595: step 58550, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 16h:54m:13s remains)
INFO - root - 2017-12-16 18:20:29.683788: step 58560, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 16h:31m:16s remains)
INFO - root - 2017-12-16 18:20:31.893162: step 58570, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 17h:05m:36s remains)
INFO - root - 2017-12-16 18:20:34.135533: step 58580, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 17h:03m:32s remains)
INFO - root - 2017-12-16 18:20:36.314778: step 58590, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 16h:40m:09s remains)
INFO - root - 2017-12-16 18:20:38.527686: step 58600, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.228 sec/batch; 17h:18m:41s remains)
INFO - root - 2017-12-16 18:20:40.855449: step 58610, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 16h:23m:41s remains)
INFO - root - 2017-12-16 18:20:43.084148: step 58620, loss = 0.42, batch loss = 0.25 (34.3 examples/sec; 0.233 sec/batch; 17h:43m:48s remains)
INFO - root - 2017-12-16 18:20:45.303764: step 58630, loss = 0.58, batch loss = 0.40 (36.0 examples/sec; 0.222 sec/batch; 16h:55m:18s remains)
INFO - root - 2017-12-16 18:20:47.512933: step 58640, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 16h:32m:38s remains)
INFO - root - 2017-12-16 18:20:49.715164: step 58650, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 16h:56m:26s remains)
INFO - root - 2017-12-16 18:20:51.889839: step 58660, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.211 sec/batch; 16h:05m:01s remains)
INFO - root - 2017-12-16 18:20:54.100584: step 58670, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 16h:44m:33s remains)
INFO - root - 2017-12-16 18:20:56.290536: step 58680, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 16h:25m:16s remains)
INFO - root - 2017-12-16 18:20:58.473188: step 58690, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 16h:32m:27s remains)
INFO - root - 2017-12-16 18:21:00.665059: step 58700, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 16h:38m:17s remains)
INFO - root - 2017-12-16 18:21:02.983779: step 58710, loss = 0.53, batch loss = 0.35 (37.5 examples/sec; 0.214 sec/batch; 16h:14m:41s remains)
INFO - root - 2017-12-16 18:21:05.206119: step 58720, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 16h:56m:15s remains)
INFO - root - 2017-12-16 18:21:07.431032: step 58730, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 16h:33m:23s remains)
INFO - root - 2017-12-16 18:21:09.633274: step 58740, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 16h:37m:00s remains)
INFO - root - 2017-12-16 18:21:11.836285: step 58750, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 16h:31m:55s remains)
INFO - root - 2017-12-16 18:21:14.052324: step 58760, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 16h:26m:42s remains)
INFO - root - 2017-12-16 18:21:16.254997: step 58770, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 17h:01m:52s remains)
INFO - root - 2017-12-16 18:21:18.478723: step 58780, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 16h:36m:24s remains)
INFO - root - 2017-12-16 18:21:20.659628: step 58790, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 16h:46m:09s remains)
INFO - root - 2017-12-16 18:21:22.896179: step 58800, loss = 0.57, batch loss = 0.39 (35.9 examples/sec; 0.223 sec/batch; 16h:55m:20s remains)
INFO - root - 2017-12-16 18:21:25.285728: step 58810, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 16h:29m:42s remains)
INFO - root - 2017-12-16 18:21:27.502946: step 58820, loss = 0.57, batch loss = 0.39 (36.4 examples/sec; 0.220 sec/batch; 16h:41m:43s remains)
INFO - root - 2017-12-16 18:21:29.772582: step 58830, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 17h:18m:35s remains)
INFO - root - 2017-12-16 18:21:31.955460: step 58840, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 16h:14m:30s remains)
INFO - root - 2017-12-16 18:21:34.157084: step 58850, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 16h:47m:14s remains)
INFO - root - 2017-12-16 18:21:36.356244: step 58860, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 16h:25m:18s remains)
INFO - root - 2017-12-16 18:21:38.588050: step 58870, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 16h:27m:20s remains)
INFO - root - 2017-12-16 18:21:40.816254: step 58880, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 16h:37m:20s remains)
INFO - root - 2017-12-16 18:21:43.014228: step 58890, loss = 0.50, batch loss = 0.32 (37.5 examples/sec; 0.214 sec/batch; 16h:13m:42s remains)
INFO - root - 2017-12-16 18:21:45.262096: step 58900, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 16h:43m:49s remains)
INFO - root - 2017-12-16 18:21:47.594696: step 58910, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 16h:42m:42s remains)
INFO - root - 2017-12-16 18:21:49.771828: step 58920, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 16h:23m:51s remains)
INFO - root - 2017-12-16 18:21:51.989343: step 58930, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 16h:29m:42s remains)
INFO - root - 2017-12-16 18:21:54.196013: step 58940, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 16h:28m:24s remains)
INFO - root - 2017-12-16 18:21:56.423314: step 58950, loss = 0.57, batch loss = 0.39 (35.3 examples/sec; 0.226 sec/batch; 17h:12m:16s remains)
INFO - root - 2017-12-16 18:21:58.622105: step 58960, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 16h:22m:20s remains)
INFO - root - 2017-12-16 18:22:00.802554: step 58970, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.215 sec/batch; 16h:18m:59s remains)
INFO - root - 2017-12-16 18:22:03.015685: step 58980, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 17h:26m:31s remains)
INFO - root - 2017-12-16 18:22:05.212578: step 58990, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 16h:28m:48s remains)
INFO - root - 2017-12-16 18:22:07.397375: step 59000, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 17h:22m:52s remains)
INFO - root - 2017-12-16 18:22:09.760651: step 59010, loss = 0.47, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 16h:31m:31s remains)
INFO - root - 2017-12-16 18:22:12.008698: step 59020, loss = 0.48, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 16h:34m:48s remains)
INFO - root - 2017-12-16 18:22:14.194029: step 59030, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 16h:16m:26s remains)
INFO - root - 2017-12-16 18:22:16.387368: step 59040, loss = 0.43, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 17h:01m:54s remains)
INFO - root - 2017-12-16 18:22:18.627277: step 59050, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 16h:54m:50s remains)
INFO - root - 2017-12-16 18:22:20.842727: step 59060, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 16h:23m:51s remains)
INFO - root - 2017-12-16 18:22:23.047089: step 59070, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 16h:27m:57s remains)
INFO - root - 2017-12-16 18:22:25.270993: step 59080, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 16h:52m:36s remains)
INFO - root - 2017-12-16 18:22:27.468522: step 59090, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 16h:44m:43s remains)
INFO - root - 2017-12-16 18:22:29.663333: step 59100, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 16h:19m:51s remains)
INFO - root - 2017-12-16 18:22:31.974651: step 59110, loss = 0.53, batch loss = 0.35 (37.4 examples/sec; 0.214 sec/batch; 16h:15m:30s remains)
INFO - root - 2017-12-16 18:22:34.195101: step 59120, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 17h:10m:45s remains)
INFO - root - 2017-12-16 18:22:36.382518: step 59130, loss = 0.55, batch loss = 0.37 (35.8 examples/sec; 0.223 sec/batch; 16h:56m:55s remains)
INFO - root - 2017-12-16 18:22:38.582041: step 59140, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 16h:31m:02s remains)
INFO - root - 2017-12-16 18:22:40.793833: step 59150, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 16h:36m:35s remains)
INFO - root - 2017-12-16 18:22:42.971375: step 59160, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 16h:16m:09s remains)
INFO - root - 2017-12-16 18:22:45.211211: step 59170, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 16h:36m:52s remains)
INFO - root - 2017-12-16 18:22:47.403048: step 59180, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 17h:01m:41s remains)
INFO - root - 2017-12-16 18:22:49.616953: step 59190, loss = 0.48, batch loss = 0.31 (34.5 examples/sec; 0.232 sec/batch; 17h:37m:48s remains)
INFO - root - 2017-12-16 18:22:51.846848: step 59200, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 16h:28m:30s remains)
INFO - root - 2017-12-16 18:22:54.203121: step 59210, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 16h:38m:54s remains)
INFO - root - 2017-12-16 18:22:56.395383: step 59220, loss = 0.44, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 16h:26m:45s remains)
INFO - root - 2017-12-16 18:22:58.651040: step 59230, loss = 0.49, batch loss = 0.31 (33.3 examples/sec; 0.240 sec/batch; 18h:15m:02s remains)
INFO - root - 2017-12-16 18:23:00.859974: step 59240, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 16h:18m:20s remains)
INFO - root - 2017-12-16 18:23:03.042136: step 59250, loss = 0.52, batch loss = 0.35 (35.1 examples/sec; 0.228 sec/batch; 17h:17m:32s remains)
INFO - root - 2017-12-16 18:23:05.277351: step 59260, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 16h:24m:12s remains)
INFO - root - 2017-12-16 18:23:07.500419: step 59270, loss = 0.46, batch loss = 0.28 (33.9 examples/sec; 0.236 sec/batch; 17h:53m:29s remains)
INFO - root - 2017-12-16 18:23:09.746662: step 59280, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 16h:40m:17s remains)
INFO - root - 2017-12-16 18:23:11.976393: step 59290, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 16h:25m:27s remains)
INFO - root - 2017-12-16 18:23:14.198874: step 59300, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 16h:48m:07s remains)
INFO - root - 2017-12-16 18:23:16.521252: step 59310, loss = 0.45, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 16h:23m:34s remains)
INFO - root - 2017-12-16 18:23:18.736320: step 59320, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.215 sec/batch; 16h:20m:35s remains)
INFO - root - 2017-12-16 18:23:20.947970: step 59330, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 16h:37m:55s remains)
INFO - root - 2017-12-16 18:23:23.174074: step 59340, loss = 0.44, batch loss = 0.26 (34.5 examples/sec; 0.232 sec/batch; 17h:35m:11s remains)
INFO - root - 2017-12-16 18:23:25.369385: step 59350, loss = 0.54, batch loss = 0.36 (36.2 examples/sec; 0.221 sec/batch; 16h:46m:07s remains)
INFO - root - 2017-12-16 18:23:27.564111: step 59360, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 16h:32m:34s remains)
INFO - root - 2017-12-16 18:23:29.798179: step 59370, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 16h:31m:20s remains)
INFO - root - 2017-12-16 18:23:32.011160: step 59380, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 16h:50m:55s remains)
INFO - root - 2017-12-16 18:23:34.253160: step 59390, loss = 0.54, batch loss = 0.36 (36.8 examples/sec; 0.217 sec/batch; 16h:29m:18s remains)
INFO - root - 2017-12-16 18:23:36.457660: step 59400, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 16h:30m:53s remains)
INFO - root - 2017-12-16 18:23:38.810611: step 59410, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 17h:11m:25s remains)
INFO - root - 2017-12-16 18:23:40.983304: step 59420, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 16h:46m:21s remains)
INFO - root - 2017-12-16 18:23:43.190028: step 59430, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 16h:44m:47s remains)
INFO - root - 2017-12-16 18:23:45.402804: step 59440, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 16h:54m:56s remains)
INFO - root - 2017-12-16 18:23:47.628108: step 59450, loss = 0.55, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 16h:38m:03s remains)
INFO - root - 2017-12-16 18:23:49.850583: step 59460, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.214 sec/batch; 16h:11m:40s remains)
INFO - root - 2017-12-16 18:23:52.063452: step 59470, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 16h:47m:55s remains)
INFO - root - 2017-12-16 18:23:54.234472: step 59480, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 16h:22m:23s remains)
INFO - root - 2017-12-16 18:23:56.447940: step 59490, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 16h:33m:44s remains)
INFO - root - 2017-12-16 18:23:58.659003: step 59500, loss = 0.56, batch loss = 0.38 (35.0 examples/sec; 0.229 sec/batch; 17h:19m:56s remains)
INFO - root - 2017-12-16 18:24:01.001193: step 59510, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 16h:46m:06s remains)
INFO - root - 2017-12-16 18:24:03.243470: step 59520, loss = 0.50, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 16h:59m:39s remains)
INFO - root - 2017-12-16 18:24:05.518032: step 59530, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 17h:26m:55s remains)
INFO - root - 2017-12-16 18:24:07.767601: step 59540, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 17h:03m:42s remains)
INFO - root - 2017-12-16 18:24:09.984599: step 59550, loss = 0.42, batch loss = 0.24 (35.6 examples/sec; 0.225 sec/batch; 17h:02m:56s remains)
INFO - root - 2017-12-16 18:24:12.201365: step 59560, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 16h:45m:03s remains)
INFO - root - 2017-12-16 18:24:14.443898: step 59570, loss = 0.50, batch loss = 0.32 (35.0 examples/sec; 0.229 sec/batch; 17h:20m:58s remains)
INFO - root - 2017-12-16 18:24:16.661501: step 59580, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 16h:42m:51s remains)
INFO - root - 2017-12-16 18:24:18.867988: step 59590, loss = 0.55, batch loss = 0.38 (35.3 examples/sec; 0.227 sec/batch; 17h:10m:19s remains)
INFO - root - 2017-12-16 18:24:21.123070: step 59600, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 16h:39m:35s remains)
INFO - root - 2017-12-16 18:24:23.456789: step 59610, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 16h:50m:09s remains)
INFO - root - 2017-12-16 18:24:25.656626: step 59620, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 17h:03m:57s remains)
INFO - root - 2017-12-16 18:24:27.899328: step 59630, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 17h:22m:26s remains)
INFO - root - 2017-12-16 18:24:30.116834: step 59640, loss = 0.41, batch loss = 0.23 (36.9 examples/sec; 0.217 sec/batch; 16h:26m:34s remains)
INFO - root - 2017-12-16 18:24:32.326159: step 59650, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 17h:08m:56s remains)
INFO - root - 2017-12-16 18:24:34.515012: step 59660, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 16h:48m:46s remains)
INFO - root - 2017-12-16 18:24:36.696629: step 59670, loss = 0.44, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 16h:14m:15s remains)
INFO - root - 2017-12-16 18:24:38.892359: step 59680, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 16h:22m:07s remains)
INFO - root - 2017-12-16 18:24:41.071507: step 59690, loss = 0.52, batch loss = 0.35 (37.3 examples/sec; 0.215 sec/batch; 16h:15m:33s remains)
INFO - root - 2017-12-16 18:24:43.262613: step 59700, loss = 0.46, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 16h:18m:14s remains)
INFO - root - 2017-12-16 18:24:45.581466: step 59710, loss = 0.56, batch loss = 0.38 (36.7 examples/sec; 0.218 sec/batch; 16h:31m:17s remains)
INFO - root - 2017-12-16 18:24:47.812515: step 59720, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 17h:01m:18s remains)
INFO - root - 2017-12-16 18:24:50.071761: step 59730, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 16h:34m:53s remains)
INFO - root - 2017-12-16 18:24:52.288700: step 59740, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 16h:38m:10s remains)
INFO - root - 2017-12-16 18:24:54.497397: step 59750, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 16h:13m:32s remains)
INFO - root - 2017-12-16 18:24:56.712286: step 59760, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 16h:34m:13s remains)
INFO - root - 2017-12-16 18:24:58.921338: step 59770, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 16h:37m:37s remains)
INFO - root - 2017-12-16 18:25:01.123157: step 59780, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 16h:23m:48s remains)
INFO - root - 2017-12-16 18:25:03.308731: step 59790, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 17h:14m:52s remains)
INFO - root - 2017-12-16 18:25:05.482379: step 59800, loss = 0.59, batch loss = 0.41 (36.8 examples/sec; 0.217 sec/batch; 16h:27m:46s remains)
INFO - root - 2017-12-16 18:25:07.842370: step 59810, loss = 0.56, batch loss = 0.38 (34.3 examples/sec; 0.233 sec/batch; 17h:40m:54s remains)
INFO - root - 2017-12-16 18:25:10.037612: step 59820, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 16h:09m:45s remains)
INFO - root - 2017-12-16 18:25:12.241275: step 59830, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 16h:35m:51s remains)
INFO - root - 2017-12-16 18:25:14.450197: step 59840, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 16h:29m:21s remains)
INFO - root - 2017-12-16 18:25:16.651577: step 59850, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 16h:50m:02s remains)
INFO - root - 2017-12-16 18:25:18.852955: step 59860, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 16h:42m:53s remains)
INFO - root - 2017-12-16 18:25:21.065037: step 59870, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 16h:38m:41s remains)
INFO - root - 2017-12-16 18:25:23.296550: step 59880, loss = 0.46, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 16h:57m:12s remains)
INFO - root - 2017-12-16 18:25:25.477725: step 59890, loss = 0.52, batch loss = 0.34 (37.8 examples/sec; 0.212 sec/batch; 16h:01m:48s remains)
INFO - root - 2017-12-16 18:25:27.685775: step 59900, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 16h:33m:50s remains)
INFO - root - 2017-12-16 18:25:30.077804: step 59910, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.224 sec/batch; 16h:56m:11s remains)
INFO - root - 2017-12-16 18:25:32.274372: step 59920, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 16h:45m:27s remains)
INFO - root - 2017-12-16 18:25:34.519400: step 59930, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 17h:01m:50s remains)
INFO - root - 2017-12-16 18:25:36.720625: step 59940, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 16h:52m:27s remains)
INFO - root - 2017-12-16 18:25:38.937126: step 59950, loss = 0.54, batch loss = 0.37 (35.2 examples/sec; 0.227 sec/batch; 17h:12m:00s remains)
INFO - root - 2017-12-16 18:25:41.179103: step 59960, loss = 0.44, batch loss = 0.26 (35.0 examples/sec; 0.229 sec/batch; 17h:18m:14s remains)
INFO - root - 2017-12-16 18:25:43.420975: step 59970, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 16h:53m:01s remains)
INFO - root - 2017-12-16 18:25:45.600389: step 59980, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 16h:06m:34s remains)
INFO - root - 2017-12-16 18:25:47.850637: step 59990, loss = 0.53, batch loss = 0.35 (35.2 examples/sec; 0.227 sec/batch; 17h:12m:16s remains)
INFO - root - 2017-12-16 18:25:50.077566: step 60000, loss = 0.53, batch loss = 0.35 (35.4 examples/sec; 0.226 sec/batch; 17h:07m:05s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-60000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-60000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 18:25:52.841692: step 60010, loss = 0.53, batch loss = 0.36 (36.1 examples/sec; 0.221 sec/batch; 16h:45m:15s remains)
INFO - root - 2017-12-16 18:25:55.067531: step 60020, loss = 0.46, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 16h:50m:35s remains)
INFO - root - 2017-12-16 18:25:57.260416: step 60030, loss = 0.55, batch loss = 0.37 (34.7 examples/sec; 0.230 sec/batch; 17h:26m:14s remains)
INFO - root - 2017-12-16 18:25:59.508158: step 60040, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 16h:31m:38s remains)
INFO - root - 2017-12-16 18:26:01.736706: step 60050, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 16h:20m:35s remains)
INFO - root - 2017-12-16 18:26:03.937771: step 60060, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.221 sec/batch; 16h:41m:57s remains)
INFO - root - 2017-12-16 18:26:06.173451: step 60070, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 16h:23m:37s remains)
INFO - root - 2017-12-16 18:26:08.380796: step 60080, loss = 0.42, batch loss = 0.24 (37.4 examples/sec; 0.214 sec/batch; 16h:11m:40s remains)
INFO - root - 2017-12-16 18:26:10.577069: step 60090, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 16h:16m:51s remains)
INFO - root - 2017-12-16 18:26:12.797231: step 60100, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 16h:34m:40s remains)
INFO - root - 2017-12-16 18:26:15.118308: step 60110, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 16h:31m:32s remains)
INFO - root - 2017-12-16 18:26:17.309892: step 60120, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 16h:50m:44s remains)
INFO - root - 2017-12-16 18:26:19.525419: step 60130, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 16h:52m:26s remains)
INFO - root - 2017-12-16 18:26:21.759571: step 60140, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 16h:50m:24s remains)
INFO - root - 2017-12-16 18:26:24.024927: step 60150, loss = 0.42, batch loss = 0.24 (35.2 examples/sec; 0.227 sec/batch; 17h:12m:06s remains)
INFO - root - 2017-12-16 18:26:26.293506: step 60160, loss = 0.45, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 17h:18m:01s remains)
INFO - root - 2017-12-16 18:26:28.537183: step 60170, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.218 sec/batch; 16h:31m:30s remains)
INFO - root - 2017-12-16 18:26:30.734596: step 60180, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 16h:58m:08s remains)
INFO - root - 2017-12-16 18:26:32.947632: step 60190, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 16h:58m:06s remains)
INFO - root - 2017-12-16 18:26:35.176204: step 60200, loss = 0.48, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 16h:26m:22s remains)
INFO - root - 2017-12-16 18:26:37.525476: step 60210, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 16h:45m:29s remains)
INFO - root - 2017-12-16 18:26:39.763853: step 60220, loss = 0.47, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 16h:16m:07s remains)
INFO - root - 2017-12-16 18:26:42.026378: step 60230, loss = 0.46, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 16h:37m:26s remains)
INFO - root - 2017-12-16 18:26:44.232043: step 60240, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 16h:31m:14s remains)
INFO - root - 2017-12-16 18:26:46.464366: step 60250, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 17h:09m:22s remains)
INFO - root - 2017-12-16 18:26:48.712434: step 60260, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 16h:41m:09s remains)
INFO - root - 2017-12-16 18:26:50.908262: step 60270, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 16h:02m:39s remains)
INFO - root - 2017-12-16 18:26:53.116120: step 60280, loss = 0.50, batch loss = 0.32 (34.7 examples/sec; 0.231 sec/batch; 17h:26m:09s remains)
INFO - root - 2017-12-16 18:26:55.355330: step 60290, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.228 sec/batch; 17h:12m:08s remains)
INFO - root - 2017-12-16 18:26:57.561396: step 60300, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 17h:12m:03s remains)
INFO - root - 2017-12-16 18:26:59.914367: step 60310, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 16h:15m:03s remains)
INFO - root - 2017-12-16 18:27:02.155298: step 60320, loss = 0.44, batch loss = 0.27 (34.2 examples/sec; 0.234 sec/batch; 17h:40m:08s remains)
INFO - root - 2017-12-16 18:27:04.357023: step 60330, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 17h:06m:11s remains)
INFO - root - 2017-12-16 18:27:06.570026: step 60340, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 16h:23m:42s remains)
INFO - root - 2017-12-16 18:27:08.837579: step 60350, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 16h:53m:28s remains)
INFO - root - 2017-12-16 18:27:11.081033: step 60360, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 16h:44m:35s remains)
INFO - root - 2017-12-16 18:27:13.325937: step 60370, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 16h:52m:55s remains)
INFO - root - 2017-12-16 18:27:15.545959: step 60380, loss = 0.41, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 16h:57m:24s remains)
INFO - root - 2017-12-16 18:27:17.770697: step 60390, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 16h:18m:59s remains)
INFO - root - 2017-12-16 18:27:20.005201: step 60400, loss = 0.48, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 16h:25m:59s remains)
INFO - root - 2017-12-16 18:27:22.343684: step 60410, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 16h:45m:15s remains)
INFO - root - 2017-12-16 18:27:24.550654: step 60420, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 16h:44m:58s remains)
INFO - root - 2017-12-16 18:27:26.768351: step 60430, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 16h:24m:43s remains)
INFO - root - 2017-12-16 18:27:28.986005: step 60440, loss = 0.51, batch loss = 0.34 (35.3 examples/sec; 0.226 sec/batch; 17h:06m:13s remains)
INFO - root - 2017-12-16 18:27:31.236440: step 60450, loss = 0.43, batch loss = 0.26 (34.7 examples/sec; 0.231 sec/batch; 17h:26m:17s remains)
INFO - root - 2017-12-16 18:27:33.424024: step 60460, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 16h:30m:09s remains)
INFO - root - 2017-12-16 18:27:35.662397: step 60470, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.231 sec/batch; 17h:25m:52s remains)
INFO - root - 2017-12-16 18:27:37.904376: step 60480, loss = 0.48, batch loss = 0.30 (34.7 examples/sec; 0.231 sec/batch; 17h:26m:36s remains)
INFO - root - 2017-12-16 18:27:40.122865: step 60490, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 16h:33m:40s remains)
INFO - root - 2017-12-16 18:27:42.358315: step 60500, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 16h:56m:23s remains)
INFO - root - 2017-12-16 18:27:44.708930: step 60510, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 16h:04m:26s remains)
INFO - root - 2017-12-16 18:27:46.895847: step 60520, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 16h:07m:02s remains)
INFO - root - 2017-12-16 18:27:49.119260: step 60530, loss = 0.44, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 16h:52m:41s remains)
INFO - root - 2017-12-16 18:27:51.361511: step 60540, loss = 0.46, batch loss = 0.28 (34.2 examples/sec; 0.234 sec/batch; 17h:41m:43s remains)
INFO - root - 2017-12-16 18:27:53.561683: step 60550, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 16h:09m:27s remains)
INFO - root - 2017-12-16 18:27:55.770078: step 60560, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 17h:02m:57s remains)
INFO - root - 2017-12-16 18:27:57.986167: step 60570, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 16h:25m:51s remains)
INFO - root - 2017-12-16 18:28:00.186544: step 60580, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 16h:11m:07s remains)
INFO - root - 2017-12-16 18:28:02.392951: step 60590, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 16h:18m:57s remains)
INFO - root - 2017-12-16 18:28:04.615687: step 60600, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 16h:21m:12s remains)
INFO - root - 2017-12-16 18:28:06.937745: step 60610, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 16h:20m:33s remains)
INFO - root - 2017-12-16 18:28:09.197160: step 60620, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 16h:53m:18s remains)
INFO - root - 2017-12-16 18:28:11.382899: step 60630, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 16h:28m:53s remains)
INFO - root - 2017-12-16 18:28:13.578593: step 60640, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 17h:04m:42s remains)
INFO - root - 2017-12-16 18:28:15.785047: step 60650, loss = 0.44, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 16h:16m:51s remains)
INFO - root - 2017-12-16 18:28:17.980130: step 60660, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 16h:50m:50s remains)
INFO - root - 2017-12-16 18:28:20.214814: step 60670, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 16h:38m:52s remains)
INFO - root - 2017-12-16 18:28:22.415044: step 60680, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 16h:35m:03s remains)
INFO - root - 2017-12-16 18:28:24.657499: step 60690, loss = 0.49, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 17h:18m:44s remains)
INFO - root - 2017-12-16 18:28:26.865626: step 60700, loss = 0.59, batch loss = 0.41 (35.7 examples/sec; 0.224 sec/batch; 16h:55m:10s remains)
INFO - root - 2017-12-16 18:28:29.190165: step 60710, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 17h:04m:42s remains)
INFO - root - 2017-12-16 18:28:31.379197: step 60720, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 16h:20m:24s remains)
INFO - root - 2017-12-16 18:28:33.575276: step 60730, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 17h:15m:04s remains)
INFO - root - 2017-12-16 18:28:35.794264: step 60740, loss = 0.44, batch loss = 0.26 (34.7 examples/sec; 0.231 sec/batch; 17h:25m:01s remains)
INFO - root - 2017-12-16 18:28:37.986277: step 60750, loss = 0.43, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 16h:08m:48s remains)
INFO - root - 2017-12-16 18:28:40.209193: step 60760, loss = 0.55, batch loss = 0.38 (36.6 examples/sec; 0.219 sec/batch; 16h:30m:49s remains)
INFO - root - 2017-12-16 18:28:42.400195: step 60770, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 16h:43m:08s remains)
INFO - root - 2017-12-16 18:28:44.633111: step 60780, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 16h:27m:55s remains)
INFO - root - 2017-12-16 18:28:46.833078: step 60790, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 16h:23m:17s remains)
INFO - root - 2017-12-16 18:28:49.062453: step 60800, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 17h:02m:00s remains)
INFO - root - 2017-12-16 18:28:51.425710: step 60810, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 16h:51m:26s remains)
INFO - root - 2017-12-16 18:28:53.653171: step 60820, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 17h:27m:42s remains)
INFO - root - 2017-12-16 18:28:55.873665: step 60830, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 16h:55m:07s remains)
INFO - root - 2017-12-16 18:28:58.113843: step 60840, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 16h:41m:54s remains)
INFO - root - 2017-12-16 18:29:00.345949: step 60850, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 16h:58m:41s remains)
INFO - root - 2017-12-16 18:29:02.550636: step 60860, loss = 0.53, batch loss = 0.36 (34.9 examples/sec; 0.229 sec/batch; 17h:17m:58s remains)
INFO - root - 2017-12-16 18:29:04.766543: step 60870, loss = 0.43, batch loss = 0.25 (35.1 examples/sec; 0.228 sec/batch; 17h:13m:02s remains)
INFO - root - 2017-12-16 18:29:07.049518: step 60880, loss = 0.46, batch loss = 0.28 (31.2 examples/sec; 0.256 sec/batch; 19h:18m:54s remains)
INFO - root - 2017-12-16 18:29:09.302293: step 60890, loss = 0.46, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 17h:36m:44s remains)
INFO - root - 2017-12-16 18:29:11.526149: step 60900, loss = 0.55, batch loss = 0.37 (36.9 examples/sec; 0.217 sec/batch; 16h:20m:17s remains)
INFO - root - 2017-12-16 18:29:13.815407: step 60910, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 16h:04m:27s remains)
INFO - root - 2017-12-16 18:29:16.037214: step 60920, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 16h:36m:26s remains)
INFO - root - 2017-12-16 18:29:18.290195: step 60930, loss = 0.52, batch loss = 0.34 (35.0 examples/sec; 0.228 sec/batch; 17h:13m:47s remains)
INFO - root - 2017-12-16 18:29:20.511184: step 60940, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 16h:10m:51s remains)
INFO - root - 2017-12-16 18:29:22.702248: step 60950, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 16h:35m:49s remains)
INFO - root - 2017-12-16 18:29:24.894512: step 60960, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 16h:28m:56s remains)
INFO - root - 2017-12-16 18:29:27.078225: step 60970, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 16h:34m:35s remains)
INFO - root - 2017-12-16 18:29:29.326780: step 60980, loss = 0.43, batch loss = 0.25 (33.8 examples/sec; 0.236 sec/batch; 17h:49m:30s remains)
INFO - root - 2017-12-16 18:29:31.554135: step 60990, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 16h:30m:17s remains)
INFO - root - 2017-12-16 18:29:33.761844: step 61000, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 17h:07m:21s remains)
INFO - root - 2017-12-16 18:29:36.091038: step 61010, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 16h:41m:34s remains)
INFO - root - 2017-12-16 18:29:38.320730: step 61020, loss = 0.52, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 16h:18m:29s remains)
INFO - root - 2017-12-16 18:29:40.532020: step 61030, loss = 0.49, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 16h:52m:29s remains)
INFO - root - 2017-12-16 18:29:42.698923: step 61040, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 16h:30m:37s remains)
INFO - root - 2017-12-16 18:29:44.958059: step 61050, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 16h:46m:36s remains)
INFO - root - 2017-12-16 18:29:47.181200: step 61060, loss = 0.46, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 16h:56m:07s remains)
INFO - root - 2017-12-16 18:29:49.381213: step 61070, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 16h:14m:44s remains)
INFO - root - 2017-12-16 18:29:51.620382: step 61080, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 16h:27m:35s remains)
INFO - root - 2017-12-16 18:29:53.856338: step 61090, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.217 sec/batch; 16h:19m:20s remains)
INFO - root - 2017-12-16 18:29:56.083204: step 61100, loss = 0.49, batch loss = 0.31 (33.2 examples/sec; 0.241 sec/batch; 18h:11m:25s remains)
INFO - root - 2017-12-16 18:29:58.473581: step 61110, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 16h:26m:35s remains)
INFO - root - 2017-12-16 18:30:00.710792: step 61120, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 16h:27m:13s remains)
INFO - root - 2017-12-16 18:30:02.926284: step 61130, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 17h:07m:53s remains)
INFO - root - 2017-12-16 18:30:05.143017: step 61140, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.223 sec/batch; 16h:46m:18s remains)
INFO - root - 2017-12-16 18:30:07.350598: step 61150, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 16h:27m:25s remains)
INFO - root - 2017-12-16 18:30:09.554376: step 61160, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 17h:01m:00s remains)
INFO - root - 2017-12-16 18:30:11.758182: step 61170, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 16h:50m:05s remains)
INFO - root - 2017-12-16 18:30:13.983289: step 61180, loss = 0.42, batch loss = 0.24 (36.9 examples/sec; 0.217 sec/batch; 16h:21m:03s remains)
INFO - root - 2017-12-16 18:30:16.228820: step 61190, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 17h:08m:13s remains)
INFO - root - 2017-12-16 18:30:18.464429: step 61200, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 16h:18m:53s remains)
INFO - root - 2017-12-16 18:30:20.828503: step 61210, loss = 0.45, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 16h:34m:26s remains)
INFO - root - 2017-12-16 18:30:23.046930: step 61220, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.224 sec/batch; 16h:54m:55s remains)
INFO - root - 2017-12-16 18:30:25.291478: step 61230, loss = 0.44, batch loss = 0.26 (32.3 examples/sec; 0.248 sec/batch; 18h:40m:10s remains)
INFO - root - 2017-12-16 18:30:27.554869: step 61240, loss = 0.44, batch loss = 0.26 (33.6 examples/sec; 0.238 sec/batch; 17h:54m:59s remains)
INFO - root - 2017-12-16 18:30:29.803302: step 61250, loss = 0.42, batch loss = 0.24 (35.6 examples/sec; 0.225 sec/batch; 16h:57m:06s remains)
INFO - root - 2017-12-16 18:30:32.051411: step 61260, loss = 0.47, batch loss = 0.29 (32.9 examples/sec; 0.243 sec/batch; 18h:19m:39s remains)
INFO - root - 2017-12-16 18:30:34.256716: step 61270, loss = 0.48, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 16h:27m:36s remains)
INFO - root - 2017-12-16 18:30:36.521800: step 61280, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 16h:52m:33s remains)
INFO - root - 2017-12-16 18:30:38.747536: step 61290, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 16h:52m:49s remains)
INFO - root - 2017-12-16 18:30:40.939647: step 61300, loss = 0.47, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 16h:31m:48s remains)
INFO - root - 2017-12-16 18:30:43.305500: step 61310, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 16h:22m:23s remains)
INFO - root - 2017-12-16 18:30:45.532055: step 61320, loss = 0.47, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 17h:01m:10s remains)
INFO - root - 2017-12-16 18:30:47.764787: step 61330, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 16h:24m:00s remains)
INFO - root - 2017-12-16 18:30:49.957750: step 61340, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 16h:50m:02s remains)
INFO - root - 2017-12-16 18:30:52.124893: step 61350, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 16h:09m:45s remains)
INFO - root - 2017-12-16 18:30:54.352652: step 61360, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 16h:44m:32s remains)
INFO - root - 2017-12-16 18:30:56.537668: step 61370, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 17h:18m:07s remains)
INFO - root - 2017-12-16 18:30:58.788095: step 61380, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 16h:56m:59s remains)
INFO - root - 2017-12-16 18:31:01.036047: step 61390, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 16h:58m:03s remains)
INFO - root - 2017-12-16 18:31:03.274230: step 61400, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 16h:43m:32s remains)
INFO - root - 2017-12-16 18:31:05.643630: step 61410, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 16h:49m:25s remains)
INFO - root - 2017-12-16 18:31:07.862130: step 61420, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 16h:16m:12s remains)
INFO - root - 2017-12-16 18:31:10.065135: step 61430, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.229 sec/batch; 17h:13m:09s remains)
INFO - root - 2017-12-16 18:31:12.297303: step 61440, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 16h:43m:05s remains)
INFO - root - 2017-12-16 18:31:14.509182: step 61450, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 17h:26m:38s remains)
INFO - root - 2017-12-16 18:31:16.724366: step 61460, loss = 0.46, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 16h:27m:34s remains)
INFO - root - 2017-12-16 18:31:18.959005: step 61470, loss = 0.52, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 17h:06m:42s remains)
INFO - root - 2017-12-16 18:31:21.173306: step 61480, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 16h:26m:13s remains)
INFO - root - 2017-12-16 18:31:23.406823: step 61490, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 16h:47m:04s remains)
INFO - root - 2017-12-16 18:31:25.616789: step 61500, loss = 0.51, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 16h:37m:03s remains)
INFO - root - 2017-12-16 18:31:27.963566: step 61510, loss = 0.53, batch loss = 0.35 (35.8 examples/sec; 0.224 sec/batch; 16h:50m:19s remains)
INFO - root - 2017-12-16 18:31:30.200879: step 61520, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.223 sec/batch; 16h:44m:54s remains)
INFO - root - 2017-12-16 18:31:32.383531: step 61530, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 16h:13m:37s remains)
INFO - root - 2017-12-16 18:31:34.644346: step 61540, loss = 0.44, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 16h:53m:07s remains)
INFO - root - 2017-12-16 18:31:36.875102: step 61550, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 16h:17m:30s remains)
INFO - root - 2017-12-16 18:31:39.097736: step 61560, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 16h:56m:36s remains)
INFO - root - 2017-12-16 18:31:41.332657: step 61570, loss = 0.46, batch loss = 0.29 (34.0 examples/sec; 0.236 sec/batch; 17h:43m:34s remains)
INFO - root - 2017-12-16 18:31:43.571049: step 61580, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 17h:09m:51s remains)
INFO - root - 2017-12-16 18:31:45.749912: step 61590, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 16h:28m:01s remains)
INFO - root - 2017-12-16 18:31:47.953596: step 61600, loss = 0.48, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 16h:50m:03s remains)
INFO - root - 2017-12-16 18:31:50.301512: step 61610, loss = 0.44, batch loss = 0.27 (38.2 examples/sec; 0.209 sec/batch; 15h:44m:26s remains)
INFO - root - 2017-12-16 18:31:52.528063: step 61620, loss = 0.43, batch loss = 0.25 (35.0 examples/sec; 0.229 sec/batch; 17h:12m:27s remains)
INFO - root - 2017-12-16 18:31:54.740787: step 61630, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 16h:23m:24s remains)
INFO - root - 2017-12-16 18:31:56.978123: step 61640, loss = 0.47, batch loss = 0.30 (34.2 examples/sec; 0.234 sec/batch; 17h:37m:16s remains)
INFO - root - 2017-12-16 18:31:59.237919: step 61650, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 16h:29m:47s remains)
INFO - root - 2017-12-16 18:32:01.453311: step 61660, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 16h:43m:24s remains)
INFO - root - 2017-12-16 18:32:03.712304: step 61670, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 17h:14m:31s remains)
INFO - root - 2017-12-16 18:32:05.908555: step 61680, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 16h:46m:12s remains)
INFO - root - 2017-12-16 18:32:08.126416: step 61690, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 16h:20m:38s remains)
INFO - root - 2017-12-16 18:32:10.380078: step 61700, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.224 sec/batch; 16h:53m:09s remains)
INFO - root - 2017-12-16 18:32:12.741903: step 61710, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 16h:38m:44s remains)
INFO - root - 2017-12-16 18:32:14.954454: step 61720, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 16h:55m:49s remains)
INFO - root - 2017-12-16 18:32:17.176859: step 61730, loss = 0.55, batch loss = 0.37 (35.4 examples/sec; 0.226 sec/batch; 16h:59m:20s remains)
INFO - root - 2017-12-16 18:32:19.384847: step 61740, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 16h:33m:55s remains)
INFO - root - 2017-12-16 18:32:21.565232: step 61750, loss = 0.46, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 16h:25m:23s remains)
INFO - root - 2017-12-16 18:32:23.805993: step 61760, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 17h:09m:03s remains)
INFO - root - 2017-12-16 18:32:26.021896: step 61770, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 16h:09m:19s remains)
INFO - root - 2017-12-16 18:32:28.264024: step 61780, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 16h:47m:04s remains)
INFO - root - 2017-12-16 18:32:30.494339: step 61790, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 16h:18m:25s remains)
INFO - root - 2017-12-16 18:32:32.746600: step 61800, loss = 0.46, batch loss = 0.29 (34.3 examples/sec; 0.233 sec/batch; 17h:31m:43s remains)
INFO - root - 2017-12-16 18:32:35.105212: step 61810, loss = 0.54, batch loss = 0.36 (35.1 examples/sec; 0.228 sec/batch; 17h:08m:34s remains)
INFO - root - 2017-12-16 18:32:37.319265: step 61820, loss = 0.55, batch loss = 0.37 (36.8 examples/sec; 0.217 sec/batch; 16h:21m:05s remains)
INFO - root - 2017-12-16 18:32:39.546742: step 61830, loss = 0.44, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 16h:56m:16s remains)
INFO - root - 2017-12-16 18:32:41.782436: step 61840, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 16h:26m:11s remains)
INFO - root - 2017-12-16 18:32:44.006998: step 61850, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 16h:59m:07s remains)
INFO - root - 2017-12-16 18:32:46.245152: step 61860, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 16h:40m:16s remains)
INFO - root - 2017-12-16 18:32:48.488115: step 61870, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 16h:50m:14s remains)
INFO - root - 2017-12-16 18:32:50.724250: step 61880, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 16h:58m:35s remains)
INFO - root - 2017-12-16 18:32:52.989664: step 61890, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 17h:02m:15s remains)
INFO - root - 2017-12-16 18:32:55.211545: step 61900, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 16h:39m:24s remains)
INFO - root - 2017-12-16 18:32:57.537184: step 61910, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 17h:02m:11s remains)
INFO - root - 2017-12-16 18:32:59.758627: step 61920, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 16h:54m:08s remains)
INFO - root - 2017-12-16 18:33:01.995747: step 61930, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 16h:55m:42s remains)
INFO - root - 2017-12-16 18:33:04.201889: step 61940, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 16h:36m:16s remains)
INFO - root - 2017-12-16 18:33:06.422616: step 61950, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 16h:15m:34s remains)
INFO - root - 2017-12-16 18:33:08.638619: step 61960, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 16h:51m:15s remains)
INFO - root - 2017-12-16 18:33:10.872588: step 61970, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 17h:03m:51s remains)
INFO - root - 2017-12-16 18:33:13.126905: step 61980, loss = 0.50, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 16h:48m:14s remains)
INFO - root - 2017-12-16 18:33:15.332236: step 61990, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.228 sec/batch; 17h:10m:00s remains)
INFO - root - 2017-12-16 18:33:17.594637: step 62000, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 17h:12m:22s remains)
INFO - root - 2017-12-16 18:33:19.973703: step 62010, loss = 0.46, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 16h:21m:00s remains)
INFO - root - 2017-12-16 18:33:22.197098: step 62020, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 16h:05m:26s remains)
INFO - root - 2017-12-16 18:33:24.426045: step 62030, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 17h:16m:40s remains)
INFO - root - 2017-12-16 18:33:26.645585: step 62040, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 17h:16m:52s remains)
INFO - root - 2017-12-16 18:33:28.858114: step 62050, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 16h:14m:28s remains)
INFO - root - 2017-12-16 18:33:31.112065: step 62060, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 17h:06m:51s remains)
INFO - root - 2017-12-16 18:33:33.295545: step 62070, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 16h:56m:18s remains)
INFO - root - 2017-12-16 18:33:35.510959: step 62080, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 16h:21m:39s remains)
INFO - root - 2017-12-16 18:33:37.706076: step 62090, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 16h:29m:27s remains)
INFO - root - 2017-12-16 18:33:39.910572: step 62100, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.215 sec/batch; 16h:11m:10s remains)
INFO - root - 2017-12-16 18:33:42.310986: step 62110, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 17h:01m:27s remains)
INFO - root - 2017-12-16 18:33:44.515834: step 62120, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 16h:23m:21s remains)
INFO - root - 2017-12-16 18:33:46.714484: step 62130, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 16h:13m:48s remains)
INFO - root - 2017-12-16 18:33:48.935802: step 62140, loss = 0.55, batch loss = 0.37 (35.5 examples/sec; 0.225 sec/batch; 16h:54m:59s remains)
INFO - root - 2017-12-16 18:33:51.130933: step 62150, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 16h:22m:04s remains)
INFO - root - 2017-12-16 18:33:53.403375: step 62160, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 16h:27m:32s remains)
INFO - root - 2017-12-16 18:33:55.603293: step 62170, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.224 sec/batch; 16h:48m:09s remains)
INFO - root - 2017-12-16 18:33:57.816854: step 62180, loss = 0.47, batch loss = 0.29 (33.3 examples/sec; 0.240 sec/batch; 18h:03m:31s remains)
INFO - root - 2017-12-16 18:34:00.034094: step 62190, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 16h:08m:19s remains)
INFO - root - 2017-12-16 18:34:02.224233: step 62200, loss = 0.45, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 16h:00m:05s remains)
INFO - root - 2017-12-16 18:34:04.591107: step 62210, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 16h:15m:45s remains)
INFO - root - 2017-12-16 18:34:06.767442: step 62220, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 16h:39m:19s remains)
INFO - root - 2017-12-16 18:34:09.001177: step 62230, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 16h:13m:26s remains)
INFO - root - 2017-12-16 18:34:11.175587: step 62240, loss = 0.49, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 16h:07m:21s remains)
INFO - root - 2017-12-16 18:34:13.349690: step 62250, loss = 0.44, batch loss = 0.26 (37.8 examples/sec; 0.212 sec/batch; 15h:53m:25s remains)
INFO - root - 2017-12-16 18:34:15.499533: step 62260, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 16h:08m:06s remains)
INFO - root - 2017-12-16 18:34:17.676461: step 62270, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 16h:11m:58s remains)
INFO - root - 2017-12-16 18:34:19.912491: step 62280, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 16h:28m:04s remains)
INFO - root - 2017-12-16 18:34:22.119953: step 62290, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 16h:49m:57s remains)
INFO - root - 2017-12-16 18:34:24.389916: step 62300, loss = 0.55, batch loss = 0.38 (37.5 examples/sec; 0.213 sec/batch; 15h:59m:56s remains)
INFO - root - 2017-12-16 18:34:26.716252: step 62310, loss = 0.53, batch loss = 0.35 (33.9 examples/sec; 0.236 sec/batch; 17h:41m:23s remains)
INFO - root - 2017-12-16 18:34:28.928769: step 62320, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 16h:14m:23s remains)
INFO - root - 2017-12-16 18:34:31.149625: step 62330, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 16h:49m:29s remains)
INFO - root - 2017-12-16 18:34:33.389487: step 62340, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 16h:48m:13s remains)
INFO - root - 2017-12-16 18:34:35.583961: step 62350, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 16h:35m:41s remains)
INFO - root - 2017-12-16 18:34:37.824064: step 62360, loss = 0.45, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 17h:00m:41s remains)
INFO - root - 2017-12-16 18:34:40.036715: step 62370, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 16h:13m:41s remains)
INFO - root - 2017-12-16 18:34:42.224474: step 62380, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 16h:43m:20s remains)
INFO - root - 2017-12-16 18:34:44.425171: step 62390, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 16h:44m:50s remains)
INFO - root - 2017-12-16 18:34:46.640976: step 62400, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 16h:34m:54s remains)
INFO - root - 2017-12-16 18:34:48.972491: step 62410, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 16h:26m:54s remains)
INFO - root - 2017-12-16 18:34:51.193917: step 62420, loss = 0.56, batch loss = 0.38 (37.2 examples/sec; 0.215 sec/batch; 16h:07m:19s remains)
INFO - root - 2017-12-16 18:34:53.382038: step 62430, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 16h:23m:18s remains)
INFO - root - 2017-12-16 18:34:55.617879: step 62440, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 16h:34m:22s remains)
INFO - root - 2017-12-16 18:34:57.799679: step 62450, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 16h:21m:44s remains)
INFO - root - 2017-12-16 18:34:59.987187: step 62460, loss = 0.43, batch loss = 0.25 (34.8 examples/sec; 0.230 sec/batch; 17h:13m:30s remains)
INFO - root - 2017-12-16 18:35:02.193907: step 62470, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 16h:38m:58s remains)
INFO - root - 2017-12-16 18:35:04.405506: step 62480, loss = 0.53, batch loss = 0.35 (33.9 examples/sec; 0.236 sec/batch; 17h:42m:59s remains)
INFO - root - 2017-12-16 18:35:06.617222: step 62490, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 16h:20m:27s remains)
INFO - root - 2017-12-16 18:35:08.863717: step 62500, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 16h:06m:00s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-62500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-62500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 18:35:11.788731: step 62510, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 16h:08m:17s remains)
INFO - root - 2017-12-16 18:35:13.984074: step 62520, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 16h:19m:04s remains)
INFO - root - 2017-12-16 18:35:16.219240: step 62530, loss = 0.50, batch loss = 0.32 (34.7 examples/sec; 0.231 sec/batch; 17h:17m:27s remains)
INFO - root - 2017-12-16 18:35:18.437123: step 62540, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 17h:02m:06s remains)
INFO - root - 2017-12-16 18:35:20.630012: step 62550, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 16h:03m:13s remains)
INFO - root - 2017-12-16 18:35:22.793067: step 62560, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 16h:43m:16s remains)
INFO - root - 2017-12-16 18:35:24.990973: step 62570, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 16h:16m:29s remains)
INFO - root - 2017-12-16 18:35:27.190785: step 62580, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 15h:57m:59s remains)
INFO - root - 2017-12-16 18:35:29.390967: step 62590, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 17h:02m:59s remains)
INFO - root - 2017-12-16 18:35:31.611440: step 62600, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 16h:31m:02s remains)
INFO - root - 2017-12-16 18:35:33.908721: step 62610, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 16h:16m:35s remains)
INFO - root - 2017-12-16 18:35:36.114272: step 62620, loss = 0.53, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 16h:41m:53s remains)
INFO - root - 2017-12-16 18:35:38.368352: step 62630, loss = 0.57, batch loss = 0.39 (37.0 examples/sec; 0.216 sec/batch; 16h:12m:11s remains)
INFO - root - 2017-12-16 18:35:40.589957: step 62640, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 16h:26m:59s remains)
INFO - root - 2017-12-16 18:35:42.791815: step 62650, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 16h:59m:06s remains)
INFO - root - 2017-12-16 18:35:45.011241: step 62660, loss = 0.53, batch loss = 0.35 (37.6 examples/sec; 0.213 sec/batch; 15h:57m:14s remains)
INFO - root - 2017-12-16 18:35:47.244795: step 62670, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.218 sec/batch; 16h:18m:19s remains)
INFO - root - 2017-12-16 18:35:49.466188: step 62680, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 16h:49m:57s remains)
INFO - root - 2017-12-16 18:35:51.639136: step 62690, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.215 sec/batch; 16h:08m:21s remains)
INFO - root - 2017-12-16 18:35:53.827548: step 62700, loss = 0.53, batch loss = 0.35 (37.5 examples/sec; 0.213 sec/batch; 15h:58m:39s remains)
INFO - root - 2017-12-16 18:35:56.191642: step 62710, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 16h:14m:11s remains)
INFO - root - 2017-12-16 18:35:58.428745: step 62720, loss = 0.48, batch loss = 0.30 (33.6 examples/sec; 0.238 sec/batch; 17h:52m:03s remains)
INFO - root - 2017-12-16 18:36:00.649650: step 62730, loss = 0.52, batch loss = 0.34 (35.0 examples/sec; 0.229 sec/batch; 17h:07m:47s remains)
INFO - root - 2017-12-16 18:36:02.850192: step 62740, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 15h:59m:14s remains)
INFO - root - 2017-12-16 18:36:05.026277: step 62750, loss = 0.45, batch loss = 0.27 (38.6 examples/sec; 0.207 sec/batch; 15h:32m:23s remains)
INFO - root - 2017-12-16 18:36:07.283652: step 62760, loss = 0.47, batch loss = 0.29 (32.3 examples/sec; 0.247 sec/batch; 18h:32m:00s remains)
INFO - root - 2017-12-16 18:36:09.465526: step 62770, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 16h:19m:13s remains)
INFO - root - 2017-12-16 18:36:11.656759: step 62780, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 15h:54m:57s remains)
INFO - root - 2017-12-16 18:36:13.823891: step 62790, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 16h:22m:14s remains)
INFO - root - 2017-12-16 18:36:16.051820: step 62800, loss = 0.56, batch loss = 0.38 (35.8 examples/sec; 0.224 sec/batch; 16h:44m:40s remains)
INFO - root - 2017-12-16 18:36:18.421233: step 62810, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 16h:22m:11s remains)
INFO - root - 2017-12-16 18:36:20.636495: step 62820, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 16h:18m:02s remains)
INFO - root - 2017-12-16 18:36:22.863948: step 62830, loss = 0.56, batch loss = 0.38 (34.3 examples/sec; 0.233 sec/batch; 17h:28m:13s remains)
INFO - root - 2017-12-16 18:36:25.071407: step 62840, loss = 0.50, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 16h:26m:09s remains)
INFO - root - 2017-12-16 18:36:27.298253: step 62850, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 16h:20m:28s remains)
INFO - root - 2017-12-16 18:36:29.533167: step 62860, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 16h:22m:53s remains)
INFO - root - 2017-12-16 18:36:31.730969: step 62870, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 16h:11m:30s remains)
INFO - root - 2017-12-16 18:36:33.958089: step 62880, loss = 0.45, batch loss = 0.28 (34.4 examples/sec; 0.232 sec/batch; 17h:24m:24s remains)
INFO - root - 2017-12-16 18:36:36.162164: step 62890, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 16h:23m:07s remains)
INFO - root - 2017-12-16 18:36:38.362218: step 62900, loss = 0.48, batch loss = 0.30 (37.9 examples/sec; 0.211 sec/batch; 15h:49m:23s remains)
INFO - root - 2017-12-16 18:36:40.727169: step 62910, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 16h:56m:16s remains)
INFO - root - 2017-12-16 18:36:42.926958: step 62920, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 16h:11m:22s remains)
INFO - root - 2017-12-16 18:36:45.135373: step 62930, loss = 0.63, batch loss = 0.45 (36.3 examples/sec; 0.220 sec/batch; 16h:29m:25s remains)
INFO - root - 2017-12-16 18:36:47.364126: step 62940, loss = 0.56, batch loss = 0.38 (36.8 examples/sec; 0.217 sec/batch; 16h:16m:10s remains)
INFO - root - 2017-12-16 18:36:49.606155: step 62950, loss = 0.54, batch loss = 0.36 (37.4 examples/sec; 0.214 sec/batch; 16h:02m:14s remains)
INFO - root - 2017-12-16 18:36:51.789080: step 62960, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 16h:02m:21s remains)
INFO - root - 2017-12-16 18:36:53.993516: step 62970, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 16h:30m:59s remains)
INFO - root - 2017-12-16 18:36:56.205877: step 62980, loss = 0.45, batch loss = 0.27 (33.1 examples/sec; 0.241 sec/batch; 18h:04m:47s remains)
INFO - root - 2017-12-16 18:36:58.415283: step 62990, loss = 0.49, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 16h:04m:23s remains)
INFO - root - 2017-12-16 18:37:00.601905: step 63000, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 16h:02m:08s remains)
INFO - root - 2017-12-16 18:37:02.936582: step 63010, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.231 sec/batch; 17h:15m:47s remains)
INFO - root - 2017-12-16 18:37:05.188303: step 63020, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 16h:12m:29s remains)
INFO - root - 2017-12-16 18:37:07.380875: step 63030, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 16h:42m:17s remains)
INFO - root - 2017-12-16 18:37:09.572153: step 63040, loss = 0.44, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 16h:08m:20s remains)
INFO - root - 2017-12-16 18:37:11.777804: step 63050, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 16h:20m:12s remains)
INFO - root - 2017-12-16 18:37:14.021474: step 63060, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 16h:16m:22s remains)
INFO - root - 2017-12-16 18:37:16.222804: step 63070, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 16h:12m:28s remains)
INFO - root - 2017-12-16 18:37:18.430647: step 63080, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 16h:40m:32s remains)
INFO - root - 2017-12-16 18:37:20.668349: step 63090, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.224 sec/batch; 16h:44m:29s remains)
INFO - root - 2017-12-16 18:37:22.892967: step 63100, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 17h:21m:04s remains)
INFO - root - 2017-12-16 18:37:25.251383: step 63110, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 16h:41m:53s remains)
INFO - root - 2017-12-16 18:37:27.456997: step 63120, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 16h:21m:49s remains)
INFO - root - 2017-12-16 18:37:29.656978: step 63130, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 16h:13m:56s remains)
INFO - root - 2017-12-16 18:37:31.884732: step 63140, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 16h:37m:55s remains)
INFO - root - 2017-12-16 18:37:34.127489: step 63150, loss = 0.45, batch loss = 0.28 (34.1 examples/sec; 0.235 sec/batch; 17h:33m:52s remains)
INFO - root - 2017-12-16 18:37:36.357960: step 63160, loss = 0.56, batch loss = 0.38 (35.3 examples/sec; 0.226 sec/batch; 16h:56m:29s remains)
INFO - root - 2017-12-16 18:37:38.590331: step 63170, loss = 0.51, batch loss = 0.33 (33.2 examples/sec; 0.241 sec/batch; 18h:02m:18s remains)
INFO - root - 2017-12-16 18:37:40.820917: step 63180, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 16h:17m:09s remains)
INFO - root - 2017-12-16 18:37:43.022005: step 63190, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 16h:17m:48s remains)
INFO - root - 2017-12-16 18:37:45.225247: step 63200, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 16h:32m:27s remains)
INFO - root - 2017-12-16 18:37:47.625973: step 63210, loss = 0.53, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 16h:49m:48s remains)
INFO - root - 2017-12-16 18:37:49.840990: step 63220, loss = 0.55, batch loss = 0.37 (35.8 examples/sec; 0.223 sec/batch; 16h:42m:19s remains)
INFO - root - 2017-12-16 18:37:52.080170: step 63230, loss = 0.52, batch loss = 0.35 (35.3 examples/sec; 0.227 sec/batch; 16h:58m:29s remains)
INFO - root - 2017-12-16 18:37:54.325722: step 63240, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 16h:54m:22s remains)
INFO - root - 2017-12-16 18:37:56.518973: step 63250, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 16h:11m:57s remains)
INFO - root - 2017-12-16 18:37:58.727771: step 63260, loss = 0.48, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 16h:36m:42s remains)
INFO - root - 2017-12-16 18:38:00.969883: step 63270, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 16h:37m:43s remains)
INFO - root - 2017-12-16 18:38:03.201127: step 63280, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 16h:14m:16s remains)
INFO - root - 2017-12-16 18:38:05.415551: step 63290, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 16h:39m:13s remains)
INFO - root - 2017-12-16 18:38:07.595509: step 63300, loss = 0.49, batch loss = 0.31 (38.5 examples/sec; 0.208 sec/batch; 15h:33m:09s remains)
INFO - root - 2017-12-16 18:38:09.985615: step 63310, loss = 0.52, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 15h:58m:38s remains)
INFO - root - 2017-12-16 18:38:12.229605: step 63320, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 16h:26m:37s remains)
INFO - root - 2017-12-16 18:38:14.430935: step 63330, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 16h:36m:01s remains)
INFO - root - 2017-12-16 18:38:16.653656: step 63340, loss = 0.55, batch loss = 0.37 (34.4 examples/sec; 0.233 sec/batch; 17h:24m:26s remains)
INFO - root - 2017-12-16 18:38:18.866510: step 63350, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 16h:50m:03s remains)
INFO - root - 2017-12-16 18:38:21.089258: step 63360, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 16h:07m:07s remains)
INFO - root - 2017-12-16 18:38:23.295107: step 63370, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 16h:44m:58s remains)
INFO - root - 2017-12-16 18:38:25.515080: step 63380, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 16h:27m:46s remains)
INFO - root - 2017-12-16 18:38:27.723687: step 63390, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 16h:45m:42s remains)
INFO - root - 2017-12-16 18:38:29.928437: step 63400, loss = 0.51, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 16h:44m:31s remains)
INFO - root - 2017-12-16 18:38:32.231649: step 63410, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 16h:33m:40s remains)
INFO - root - 2017-12-16 18:38:34.483154: step 63420, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 16h:48m:05s remains)
INFO - root - 2017-12-16 18:38:36.664197: step 63430, loss = 0.43, batch loss = 0.25 (37.5 examples/sec; 0.213 sec/batch; 15h:56m:38s remains)
INFO - root - 2017-12-16 18:38:38.906849: step 63440, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 16h:27m:41s remains)
INFO - root - 2017-12-16 18:38:41.119578: step 63450, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 16h:10m:13s remains)
INFO - root - 2017-12-16 18:38:43.301860: step 63460, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 16h:01m:07s remains)
INFO - root - 2017-12-16 18:38:45.525299: step 63470, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 16h:12m:54s remains)
INFO - root - 2017-12-16 18:38:47.762003: step 63480, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 16h:02m:24s remains)
INFO - root - 2017-12-16 18:38:49.949756: step 63490, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 15h:59m:56s remains)
INFO - root - 2017-12-16 18:38:52.180191: step 63500, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 16h:34m:03s remains)
INFO - root - 2017-12-16 18:38:54.510075: step 63510, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 16h:48m:14s remains)
INFO - root - 2017-12-16 18:38:56.718440: step 63520, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 16h:30m:20s remains)
INFO - root - 2017-12-16 18:38:58.960615: step 63530, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 16h:38m:20s remains)
INFO - root - 2017-12-16 18:39:01.168408: step 63540, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 16h:19m:23s remains)
INFO - root - 2017-12-16 18:39:03.413118: step 63550, loss = 0.46, batch loss = 0.28 (32.7 examples/sec; 0.244 sec/batch; 18h:15m:54s remains)
INFO - root - 2017-12-16 18:39:05.626167: step 63560, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 16h:17m:23s remains)
INFO - root - 2017-12-16 18:39:07.873251: step 63570, loss = 0.43, batch loss = 0.25 (34.7 examples/sec; 0.231 sec/batch; 17h:13m:15s remains)
INFO - root - 2017-12-16 18:39:10.106375: step 63580, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.214 sec/batch; 15h:57m:17s remains)
INFO - root - 2017-12-16 18:39:12.321553: step 63590, loss = 0.54, batch loss = 0.36 (35.4 examples/sec; 0.226 sec/batch; 16h:52m:43s remains)
INFO - root - 2017-12-16 18:39:14.524029: step 63600, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 16h:29m:12s remains)
INFO - root - 2017-12-16 18:39:16.871663: step 63610, loss = 0.47, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 16h:31m:54s remains)
INFO - root - 2017-12-16 18:39:19.131857: step 63620, loss = 0.47, batch loss = 0.30 (35.6 examples/sec; 0.224 sec/batch; 16h:45m:38s remains)
INFO - root - 2017-12-16 18:39:21.366002: step 63630, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 17h:05m:42s remains)
INFO - root - 2017-12-16 18:39:23.583132: step 63640, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 16h:22m:01s remains)
INFO - root - 2017-12-16 18:39:25.800501: step 63650, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 16h:25m:51s remains)
INFO - root - 2017-12-16 18:39:27.998650: step 63660, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 16h:06m:05s remains)
INFO - root - 2017-12-16 18:39:30.202576: step 63670, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 16h:15m:21s remains)
INFO - root - 2017-12-16 18:39:32.415644: step 63680, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 16h:24m:09s remains)
INFO - root - 2017-12-16 18:39:34.609212: step 63690, loss = 0.49, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 16h:43m:59s remains)
INFO - root - 2017-12-16 18:39:36.827339: step 63700, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 16h:02m:14s remains)
INFO - root - 2017-12-16 18:39:39.166289: step 63710, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.215 sec/batch; 16h:04m:52s remains)
INFO - root - 2017-12-16 18:39:41.400870: step 63720, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 16h:48m:22s remains)
INFO - root - 2017-12-16 18:39:43.592642: step 63730, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.221 sec/batch; 16h:28m:10s remains)
INFO - root - 2017-12-16 18:39:45.807759: step 63740, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.221 sec/batch; 16h:27m:50s remains)
INFO - root - 2017-12-16 18:39:48.021496: step 63750, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 16h:21m:51s remains)
INFO - root - 2017-12-16 18:39:50.253234: step 63760, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 17h:05m:25s remains)
INFO - root - 2017-12-16 18:39:52.474382: step 63770, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 16h:23m:38s remains)
INFO - root - 2017-12-16 18:39:54.640960: step 63780, loss = 0.48, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 15h:53m:20s remains)
INFO - root - 2017-12-16 18:39:56.876329: step 63790, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 16h:11m:29s remains)
INFO - root - 2017-12-16 18:39:59.096755: step 63800, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 16h:01m:48s remains)
INFO - root - 2017-12-16 18:40:01.447074: step 63810, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 16h:31m:01s remains)
INFO - root - 2017-12-16 18:40:03.715488: step 63820, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 17h:01m:38s remains)
INFO - root - 2017-12-16 18:40:05.957538: step 63830, loss = 0.44, batch loss = 0.27 (34.3 examples/sec; 0.233 sec/batch; 17h:25m:21s remains)
INFO - root - 2017-12-16 18:40:08.200611: step 63840, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 16h:28m:20s remains)
INFO - root - 2017-12-16 18:40:10.436638: step 63850, loss = 0.54, batch loss = 0.36 (37.4 examples/sec; 0.214 sec/batch; 15h:58m:25s remains)
INFO - root - 2017-12-16 18:40:12.646369: step 63860, loss = 0.51, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 16h:58m:09s remains)
INFO - root - 2017-12-16 18:40:14.844113: step 63870, loss = 0.49, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 16h:48m:32s remains)
INFO - root - 2017-12-16 18:40:17.037066: step 63880, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 16h:28m:16s remains)
INFO - root - 2017-12-16 18:40:19.252149: step 63890, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 16h:44m:21s remains)
INFO - root - 2017-12-16 18:40:21.446160: step 63900, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 16h:16m:53s remains)
INFO - root - 2017-12-16 18:40:23.796422: step 63910, loss = 0.45, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 16h:14m:58s remains)
INFO - root - 2017-12-16 18:40:26.048351: step 63920, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 16h:37m:18s remains)
INFO - root - 2017-12-16 18:40:28.233808: step 63930, loss = 0.51, batch loss = 0.34 (37.3 examples/sec; 0.215 sec/batch; 16h:00m:40s remains)
INFO - root - 2017-12-16 18:40:30.464605: step 63940, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 16h:49m:20s remains)
INFO - root - 2017-12-16 18:40:32.689524: step 63950, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 16h:55m:47s remains)
INFO - root - 2017-12-16 18:40:34.898831: step 63960, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 16h:47m:30s remains)
INFO - root - 2017-12-16 18:40:37.122097: step 63970, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 17h:06m:59s remains)
INFO - root - 2017-12-16 18:40:39.353178: step 63980, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 16h:45m:12s remains)
INFO - root - 2017-12-16 18:40:41.577820: step 63990, loss = 0.53, batch loss = 0.35 (35.0 examples/sec; 0.228 sec/batch; 17h:01m:55s remains)
INFO - root - 2017-12-16 18:40:43.810750: step 64000, loss = 0.46, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 17h:04m:25s remains)
INFO - root - 2017-12-16 18:40:46.174258: step 64010, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 17h:05m:41s remains)
INFO - root - 2017-12-16 18:40:48.394529: step 64020, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 16h:34m:32s remains)
INFO - root - 2017-12-16 18:40:50.602827: step 64030, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 16h:12m:39s remains)
INFO - root - 2017-12-16 18:40:52.801154: step 64040, loss = 0.52, batch loss = 0.35 (37.9 examples/sec; 0.211 sec/batch; 15h:44m:34s remains)
INFO - root - 2017-12-16 18:40:55.016130: step 64050, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 15h:47m:27s remains)
INFO - root - 2017-12-16 18:40:57.209009: step 64060, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 16h:08m:56s remains)
INFO - root - 2017-12-16 18:40:59.439792: step 64070, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 16h:24m:58s remains)
INFO - root - 2017-12-16 18:41:01.687768: step 64080, loss = 0.59, batch loss = 0.41 (36.8 examples/sec; 0.217 sec/batch; 16h:11m:45s remains)
INFO - root - 2017-12-16 18:41:03.905208: step 64090, loss = 0.43, batch loss = 0.25 (37.0 examples/sec; 0.216 sec/batch; 16h:07m:47s remains)
INFO - root - 2017-12-16 18:41:06.153171: step 64100, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 16h:09m:22s remains)
INFO - root - 2017-12-16 18:41:08.571985: step 64110, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.228 sec/batch; 17h:01m:04s remains)
INFO - root - 2017-12-16 18:41:10.809038: step 64120, loss = 0.46, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 16h:54m:16s remains)
INFO - root - 2017-12-16 18:41:12.995501: step 64130, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 15h:57m:04s remains)
INFO - root - 2017-12-16 18:41:15.188538: step 64140, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 16h:29m:45s remains)
INFO - root - 2017-12-16 18:41:17.461599: step 64150, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 16h:00m:57s remains)
INFO - root - 2017-12-16 18:41:19.662756: step 64160, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 16h:33m:46s remains)
INFO - root - 2017-12-16 18:41:21.860519: step 64170, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 16h:47m:35s remains)
INFO - root - 2017-12-16 18:41:24.080692: step 64180, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 16h:37m:37s remains)
INFO - root - 2017-12-16 18:41:26.263886: step 64190, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 16h:44m:15s remains)
INFO - root - 2017-12-16 18:41:28.475890: step 64200, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 16h:15m:21s remains)
INFO - root - 2017-12-16 18:41:30.835885: step 64210, loss = 0.45, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 16h:32m:38s remains)
INFO - root - 2017-12-16 18:41:33.050859: step 64220, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 16h:43m:05s remains)
INFO - root - 2017-12-16 18:41:35.335636: step 64230, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 16h:56m:06s remains)
INFO - root - 2017-12-16 18:41:37.557746: step 64240, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 16h:25m:38s remains)
INFO - root - 2017-12-16 18:41:39.756254: step 64250, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 16h:29m:23s remains)
INFO - root - 2017-12-16 18:41:42.002116: step 64260, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 16h:32m:17s remains)
INFO - root - 2017-12-16 18:41:44.213626: step 64270, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 16h:44m:52s remains)
INFO - root - 2017-12-16 18:41:46.420018: step 64280, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 17h:06m:56s remains)
INFO - root - 2017-12-16 18:41:48.620558: step 64290, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 16h:32m:42s remains)
INFO - root - 2017-12-16 18:41:50.815969: step 64300, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 16h:15m:40s remains)
INFO - root - 2017-12-16 18:41:53.156085: step 64310, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 16h:23m:33s remains)
INFO - root - 2017-12-16 18:41:55.372410: step 64320, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 16h:42m:21s remains)
INFO - root - 2017-12-16 18:41:57.594321: step 64330, loss = 0.43, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 15h:57m:06s remains)
INFO - root - 2017-12-16 18:41:59.789164: step 64340, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 16h:13m:01s remains)
INFO - root - 2017-12-16 18:42:02.050685: step 64350, loss = 0.58, batch loss = 0.40 (36.5 examples/sec; 0.219 sec/batch; 16h:18m:24s remains)
INFO - root - 2017-12-16 18:42:04.284129: step 64360, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 16h:19m:23s remains)
INFO - root - 2017-12-16 18:42:06.486393: step 64370, loss = 0.44, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 16h:04m:17s remains)
INFO - root - 2017-12-16 18:42:08.748615: step 64380, loss = 0.57, batch loss = 0.40 (33.3 examples/sec; 0.240 sec/batch; 17h:53m:44s remains)
INFO - root - 2017-12-16 18:42:10.939945: step 64390, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.226 sec/batch; 16h:48m:02s remains)
INFO - root - 2017-12-16 18:42:13.189318: step 64400, loss = 0.45, batch loss = 0.27 (33.5 examples/sec; 0.239 sec/batch; 17h:46m:31s remains)
INFO - root - 2017-12-16 18:42:15.511317: step 64410, loss = 0.56, batch loss = 0.38 (36.9 examples/sec; 0.217 sec/batch; 16h:07m:46s remains)
INFO - root - 2017-12-16 18:42:17.724480: step 64420, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 16h:22m:24s remains)
INFO - root - 2017-12-16 18:42:19.985732: step 64430, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 17h:16m:32s remains)
INFO - root - 2017-12-16 18:42:22.192677: step 64440, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 16h:14m:17s remains)
INFO - root - 2017-12-16 18:42:24.424197: step 64450, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 16h:29m:17s remains)
INFO - root - 2017-12-16 18:42:26.620157: step 64460, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 16h:21m:18s remains)
INFO - root - 2017-12-16 18:42:28.877604: step 64470, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 16h:36m:13s remains)
INFO - root - 2017-12-16 18:42:31.128084: step 64480, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 17h:12m:19s remains)
INFO - root - 2017-12-16 18:42:33.351720: step 64490, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 16h:35m:20s remains)
INFO - root - 2017-12-16 18:42:35.540474: step 64500, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 15h:58m:39s remains)
INFO - root - 2017-12-16 18:42:37.917551: step 64510, loss = 0.45, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 16h:31m:08s remains)
INFO - root - 2017-12-16 18:42:40.158999: step 64520, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 17h:02m:33s remains)
INFO - root - 2017-12-16 18:42:42.368025: step 64530, loss = 0.54, batch loss = 0.36 (34.7 examples/sec; 0.231 sec/batch; 17h:10m:12s remains)
INFO - root - 2017-12-16 18:42:44.630235: step 64540, loss = 0.49, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 16h:44m:15s remains)
INFO - root - 2017-12-16 18:42:46.896916: step 64550, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 16h:06m:18s remains)
INFO - root - 2017-12-16 18:42:49.130248: step 64560, loss = 0.42, batch loss = 0.24 (36.0 examples/sec; 0.222 sec/batch; 16h:31m:54s remains)
INFO - root - 2017-12-16 18:42:51.397259: step 64570, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 16h:51m:02s remains)
INFO - root - 2017-12-16 18:42:53.653119: step 64580, loss = 0.44, batch loss = 0.26 (34.3 examples/sec; 0.234 sec/batch; 17h:22m:48s remains)
INFO - root - 2017-12-16 18:42:55.888315: step 64590, loss = 0.42, batch loss = 0.24 (33.3 examples/sec; 0.240 sec/batch; 17h:53m:12s remains)
INFO - root - 2017-12-16 18:42:58.123933: step 64600, loss = 0.53, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 16h:42m:57s remains)
INFO - root - 2017-12-16 18:43:00.459329: step 64610, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 16h:39m:32s remains)
INFO - root - 2017-12-16 18:43:02.708940: step 64620, loss = 0.53, batch loss = 0.35 (35.2 examples/sec; 0.227 sec/batch; 16h:54m:49s remains)
INFO - root - 2017-12-16 18:43:04.929374: step 64630, loss = 0.47, batch loss = 0.29 (34.4 examples/sec; 0.233 sec/batch; 17h:19m:24s remains)
INFO - root - 2017-12-16 18:43:07.131036: step 64640, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 16h:37m:01s remains)
INFO - root - 2017-12-16 18:43:09.382603: step 64650, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 16h:25m:18s remains)
INFO - root - 2017-12-16 18:43:11.634785: step 64660, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 16h:18m:17s remains)
INFO - root - 2017-12-16 18:43:13.853616: step 64670, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 16h:39m:48s remains)
INFO - root - 2017-12-16 18:43:16.074693: step 64680, loss = 0.45, batch loss = 0.27 (38.4 examples/sec; 0.208 sec/batch; 15h:29m:47s remains)
INFO - root - 2017-12-16 18:43:18.332188: step 64690, loss = 0.40, batch loss = 0.22 (35.0 examples/sec; 0.228 sec/batch; 16h:59m:17s remains)
INFO - root - 2017-12-16 18:43:20.554511: step 64700, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 16h:11m:11s remains)
INFO - root - 2017-12-16 18:43:22.922644: step 64710, loss = 0.49, batch loss = 0.31 (33.6 examples/sec; 0.238 sec/batch; 17h:41m:16s remains)
INFO - root - 2017-12-16 18:43:25.154121: step 64720, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 16h:53m:31s remains)
INFO - root - 2017-12-16 18:43:27.397552: step 64730, loss = 0.43, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 16h:31m:30s remains)
INFO - root - 2017-12-16 18:43:29.598568: step 64740, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 16h:13m:23s remains)
INFO - root - 2017-12-16 18:43:31.829113: step 64750, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 16h:09m:23s remains)
INFO - root - 2017-12-16 18:43:34.079114: step 64760, loss = 0.61, batch loss = 0.43 (36.1 examples/sec; 0.222 sec/batch; 16h:29m:04s remains)
INFO - root - 2017-12-16 18:43:36.316828: step 64770, loss = 0.51, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 17h:05m:40s remains)
INFO - root - 2017-12-16 18:43:38.577470: step 64780, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.231 sec/batch; 17h:11m:04s remains)
INFO - root - 2017-12-16 18:43:40.798501: step 64790, loss = 0.47, batch loss = 0.30 (33.6 examples/sec; 0.238 sec/batch; 17h:40m:56s remains)
INFO - root - 2017-12-16 18:43:43.008275: step 64800, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 16h:35m:28s remains)
INFO - root - 2017-12-16 18:43:45.328100: step 64810, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 16h:39m:55s remains)
INFO - root - 2017-12-16 18:43:47.544552: step 64820, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 15h:51m:16s remains)
INFO - root - 2017-12-16 18:43:49.750268: step 64830, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 16h:33m:05s remains)
INFO - root - 2017-12-16 18:43:51.940903: step 64840, loss = 0.59, batch loss = 0.41 (36.8 examples/sec; 0.217 sec/batch; 16h:10m:12s remains)
INFO - root - 2017-12-16 18:43:54.204431: step 64850, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 16h:47m:23s remains)
INFO - root - 2017-12-16 18:43:56.407210: step 64860, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 15h:53m:37s remains)
INFO - root - 2017-12-16 18:43:58.683645: step 64870, loss = 0.51, batch loss = 0.33 (33.9 examples/sec; 0.236 sec/batch; 17h:31m:50s remains)
INFO - root - 2017-12-16 18:44:00.915027: step 64880, loss = 0.48, batch loss = 0.30 (34.0 examples/sec; 0.235 sec/batch; 17h:28m:35s remains)
INFO - root - 2017-12-16 18:44:03.113853: step 64890, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 16h:36m:06s remains)
INFO - root - 2017-12-16 18:44:05.333218: step 64900, loss = 0.43, batch loss = 0.25 (33.8 examples/sec; 0.237 sec/batch; 17h:34m:47s remains)
INFO - root - 2017-12-16 18:44:07.647646: step 64910, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.226 sec/batch; 16h:46m:14s remains)
INFO - root - 2017-12-16 18:44:09.893869: step 64920, loss = 0.41, batch loss = 0.23 (36.4 examples/sec; 0.220 sec/batch; 16h:20m:11s remains)
INFO - root - 2017-12-16 18:44:12.185581: step 64930, loss = 0.45, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 16h:45m:55s remains)
INFO - root - 2017-12-16 18:44:14.436634: step 64940, loss = 0.46, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 16h:50m:15s remains)
INFO - root - 2017-12-16 18:44:16.655454: step 64950, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 16h:26m:31s remains)
INFO - root - 2017-12-16 18:44:18.843759: step 64960, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 16h:06m:19s remains)
INFO - root - 2017-12-16 18:44:21.068250: step 64970, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 16h:38m:45s remains)
INFO - root - 2017-12-16 18:44:23.298928: step 64980, loss = 0.47, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 16h:43m:50s remains)
INFO - root - 2017-12-16 18:44:25.553149: step 64990, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.230 sec/batch; 17h:06m:45s remains)
INFO - root - 2017-12-16 18:44:27.767961: step 65000, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 16h:14m:55s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-65000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-65000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 18:44:30.530032: step 65010, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 15h:47m:58s remains)
INFO - root - 2017-12-16 18:44:32.720825: step 65020, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 15h:55m:25s remains)
INFO - root - 2017-12-16 18:44:34.930896: step 65030, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 16h:12m:01s remains)
INFO - root - 2017-12-16 18:44:37.149156: step 65040, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 16h:08m:33s remains)
INFO - root - 2017-12-16 18:44:39.363245: step 65050, loss = 0.54, batch loss = 0.37 (36.6 examples/sec; 0.218 sec/batch; 16h:13m:47s remains)
INFO - root - 2017-12-16 18:44:41.562788: step 65060, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 16h:25m:38s remains)
INFO - root - 2017-12-16 18:44:43.784254: step 65070, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 16h:22m:50s remains)
INFO - root - 2017-12-16 18:44:46.010663: step 65080, loss = 0.42, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 16h:21m:03s remains)
INFO - root - 2017-12-16 18:44:48.220346: step 65090, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 16h:47m:48s remains)
INFO - root - 2017-12-16 18:44:50.435955: step 65100, loss = 0.47, batch loss = 0.30 (33.8 examples/sec; 0.237 sec/batch; 17h:35m:15s remains)
INFO - root - 2017-12-16 18:44:52.757782: step 65110, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 16h:27m:46s remains)
INFO - root - 2017-12-16 18:44:54.987904: step 65120, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 16h:41m:05s remains)
INFO - root - 2017-12-16 18:44:57.205199: step 65130, loss = 0.53, batch loss = 0.36 (34.9 examples/sec; 0.229 sec/batch; 17h:02m:13s remains)
INFO - root - 2017-12-16 18:44:59.447188: step 65140, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 16h:26m:45s remains)
INFO - root - 2017-12-16 18:45:01.665138: step 65150, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 16h:03m:34s remains)
INFO - root - 2017-12-16 18:45:03.901176: step 65160, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 16h:26m:15s remains)
INFO - root - 2017-12-16 18:45:06.121984: step 65170, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 16h:47m:05s remains)
INFO - root - 2017-12-16 18:45:08.349918: step 65180, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 16h:11m:10s remains)
INFO - root - 2017-12-16 18:45:10.569058: step 65190, loss = 0.52, batch loss = 0.34 (34.9 examples/sec; 0.229 sec/batch; 17h:00m:03s remains)
INFO - root - 2017-12-16 18:45:12.798705: step 65200, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 16h:13m:31s remains)
INFO - root - 2017-12-16 18:45:15.198140: step 65210, loss = 0.44, batch loss = 0.27 (35.0 examples/sec; 0.228 sec/batch; 16h:57m:35s remains)
INFO - root - 2017-12-16 18:45:17.427738: step 65220, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 16h:02m:53s remains)
INFO - root - 2017-12-16 18:45:19.612829: step 65230, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 15h:54m:21s remains)
INFO - root - 2017-12-16 18:45:21.814218: step 65240, loss = 0.54, batch loss = 0.36 (36.4 examples/sec; 0.220 sec/batch; 16h:18m:29s remains)
INFO - root - 2017-12-16 18:45:24.005918: step 65250, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 15h:58m:37s remains)
INFO - root - 2017-12-16 18:45:26.205814: step 65260, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.215 sec/batch; 15h:59m:13s remains)
INFO - root - 2017-12-16 18:45:28.453475: step 65270, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 16h:39m:19s remains)
INFO - root - 2017-12-16 18:45:30.672864: step 65280, loss = 0.51, batch loss = 0.34 (37.3 examples/sec; 0.214 sec/batch; 15h:54m:36s remains)
INFO - root - 2017-12-16 18:45:32.920018: step 65290, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 16h:49m:02s remains)
INFO - root - 2017-12-16 18:45:35.127544: step 65300, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 16h:11m:38s remains)
INFO - root - 2017-12-16 18:45:37.433609: step 65310, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 16h:23m:54s remains)
INFO - root - 2017-12-16 18:45:39.643732: step 65320, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 15h:55m:44s remains)
INFO - root - 2017-12-16 18:45:41.849895: step 65330, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 16h:05m:01s remains)
INFO - root - 2017-12-16 18:45:44.035291: step 65340, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 16h:16m:20s remains)
INFO - root - 2017-12-16 18:45:46.256103: step 65350, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 16h:11m:52s remains)
INFO - root - 2017-12-16 18:45:48.466851: step 65360, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 16h:43m:32s remains)
INFO - root - 2017-12-16 18:45:50.699073: step 65370, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 16h:04m:35s remains)
INFO - root - 2017-12-16 18:45:52.937526: step 65380, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 16h:18m:39s remains)
INFO - root - 2017-12-16 18:45:55.197490: step 65390, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 16h:59m:09s remains)
INFO - root - 2017-12-16 18:45:57.478414: step 65400, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 16h:22m:16s remains)
INFO - root - 2017-12-16 18:45:59.836582: step 65410, loss = 0.55, batch loss = 0.37 (37.9 examples/sec; 0.211 sec/batch; 15h:40m:05s remains)
INFO - root - 2017-12-16 18:46:02.028494: step 65420, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 16h:45m:24s remains)
INFO - root - 2017-12-16 18:46:04.254317: step 65430, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 16h:01m:08s remains)
INFO - root - 2017-12-16 18:46:06.523337: step 65440, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 16h:34m:01s remains)
INFO - root - 2017-12-16 18:46:08.726625: step 65450, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 16h:22m:26s remains)
INFO - root - 2017-12-16 18:46:10.959041: step 65460, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 16h:49m:55s remains)
INFO - root - 2017-12-16 18:46:13.183534: step 65470, loss = 0.56, batch loss = 0.38 (35.4 examples/sec; 0.226 sec/batch; 16h:44m:57s remains)
INFO - root - 2017-12-16 18:46:15.380479: step 65480, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 16h:33m:16s remains)
INFO - root - 2017-12-16 18:46:17.602079: step 65490, loss = 0.48, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 16h:03m:57s remains)
INFO - root - 2017-12-16 18:46:19.830698: step 65500, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 16h:14m:58s remains)
INFO - root - 2017-12-16 18:46:22.196388: step 65510, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 16h:14m:13s remains)
INFO - root - 2017-12-16 18:46:24.439261: step 65520, loss = 0.42, batch loss = 0.24 (35.9 examples/sec; 0.223 sec/batch; 16h:32m:02s remains)
INFO - root - 2017-12-16 18:46:26.649125: step 65530, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 15h:57m:27s remains)
INFO - root - 2017-12-16 18:46:28.888361: step 65540, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 16h:22m:27s remains)
INFO - root - 2017-12-16 18:46:31.109140: step 65550, loss = 0.52, batch loss = 0.34 (37.7 examples/sec; 0.212 sec/batch; 15h:43m:29s remains)
INFO - root - 2017-12-16 18:46:33.308134: step 65560, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 16h:04m:15s remains)
INFO - root - 2017-12-16 18:46:35.538980: step 65570, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 16h:36m:37s remains)
INFO - root - 2017-12-16 18:46:37.782252: step 65580, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 16h:14m:19s remains)
INFO - root - 2017-12-16 18:46:39.968192: step 65590, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 16h:18m:19s remains)
INFO - root - 2017-12-16 18:46:42.196261: step 65600, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 16h:37m:04s remains)
INFO - root - 2017-12-16 18:46:44.538974: step 65610, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 16h:40m:31s remains)
INFO - root - 2017-12-16 18:46:46.747221: step 65620, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 16h:35m:37s remains)
INFO - root - 2017-12-16 18:46:48.967933: step 65630, loss = 0.50, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 16h:01m:55s remains)
INFO - root - 2017-12-16 18:46:51.180101: step 65640, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 16h:42m:11s remains)
INFO - root - 2017-12-16 18:46:53.434981: step 65650, loss = 0.48, batch loss = 0.30 (33.6 examples/sec; 0.238 sec/batch; 17h:37m:52s remains)
INFO - root - 2017-12-16 18:46:55.654356: step 65660, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.226 sec/batch; 16h:42m:58s remains)
INFO - root - 2017-12-16 18:46:57.882403: step 65670, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 16h:54m:24s remains)
INFO - root - 2017-12-16 18:47:00.117201: step 65680, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 16h:35m:56s remains)
INFO - root - 2017-12-16 18:47:02.353637: step 65690, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 15h:49m:11s remains)
INFO - root - 2017-12-16 18:47:04.559132: step 65700, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 16h:25m:13s remains)
INFO - root - 2017-12-16 18:47:06.893856: step 65710, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 16h:27m:32s remains)
INFO - root - 2017-12-16 18:47:09.116829: step 65720, loss = 0.54, batch loss = 0.36 (35.6 examples/sec; 0.224 sec/batch; 16h:37m:51s remains)
INFO - root - 2017-12-16 18:47:11.327980: step 65730, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 16h:12m:49s remains)
INFO - root - 2017-12-16 18:47:13.568192: step 65740, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 16h:36m:33s remains)
INFO - root - 2017-12-16 18:47:15.769583: step 65750, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 16h:02m:17s remains)
INFO - root - 2017-12-16 18:47:17.977631: step 65760, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 16h:16m:59s remains)
INFO - root - 2017-12-16 18:47:20.215264: step 65770, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 16h:38m:25s remains)
INFO - root - 2017-12-16 18:47:22.417617: step 65780, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 15h:46m:49s remains)
INFO - root - 2017-12-16 18:47:24.681095: step 65790, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 15h:51m:29s remains)
INFO - root - 2017-12-16 18:47:26.923837: step 65800, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 16h:46m:59s remains)
INFO - root - 2017-12-16 18:47:29.262997: step 65810, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 16h:34m:05s remains)
INFO - root - 2017-12-16 18:47:31.465440: step 65820, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 16h:19m:27s remains)
INFO - root - 2017-12-16 18:47:33.700621: step 65830, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 15h:55m:16s remains)
INFO - root - 2017-12-16 18:47:35.932480: step 65840, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 16h:19m:40s remains)
INFO - root - 2017-12-16 18:47:38.125601: step 65850, loss = 0.52, batch loss = 0.34 (34.2 examples/sec; 0.234 sec/batch; 17h:18m:50s remains)
INFO - root - 2017-12-16 18:47:40.359235: step 65860, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 16h:15m:46s remains)
INFO - root - 2017-12-16 18:47:42.577265: step 65870, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 16h:17m:02s remains)
INFO - root - 2017-12-16 18:47:44.761810: step 65880, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 16h:21m:57s remains)
INFO - root - 2017-12-16 18:47:46.974602: step 65890, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 16h:45m:22s remains)
INFO - root - 2017-12-16 18:47:49.176339: step 65900, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 16h:05m:14s remains)
INFO - root - 2017-12-16 18:47:51.532550: step 65910, loss = 0.58, batch loss = 0.40 (35.3 examples/sec; 0.226 sec/batch; 16h:46m:04s remains)
INFO - root - 2017-12-16 18:47:53.742495: step 65920, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 16h:02m:10s remains)
INFO - root - 2017-12-16 18:47:55.954665: step 65930, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 16h:45m:54s remains)
INFO - root - 2017-12-16 18:47:58.164388: step 65940, loss = 0.46, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 15h:51m:22s remains)
INFO - root - 2017-12-16 18:48:00.382306: step 65950, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 15h:59m:11s remains)
INFO - root - 2017-12-16 18:48:02.599662: step 65960, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 15h:53m:39s remains)
INFO - root - 2017-12-16 18:48:04.829949: step 65970, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 15h:51m:56s remains)
INFO - root - 2017-12-16 18:48:07.034785: step 65980, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 16h:12m:10s remains)
INFO - root - 2017-12-16 18:48:09.273327: step 65990, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 16h:12m:48s remains)
INFO - root - 2017-12-16 18:48:11.480694: step 66000, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 16h:11m:40s remains)
INFO - root - 2017-12-16 18:48:13.793344: step 66010, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.214 sec/batch; 15h:48m:32s remains)
INFO - root - 2017-12-16 18:48:15.988194: step 66020, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 16h:46m:39s remains)
INFO - root - 2017-12-16 18:48:18.207995: step 66030, loss = 0.55, batch loss = 0.37 (36.8 examples/sec; 0.217 sec/batch; 16h:05m:31s remains)
INFO - root - 2017-12-16 18:48:20.440495: step 66040, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 16h:58m:39s remains)
INFO - root - 2017-12-16 18:48:22.691899: step 66050, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 16h:32m:00s remains)
INFO - root - 2017-12-16 18:48:24.928868: step 66060, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 16h:35m:04s remains)
INFO - root - 2017-12-16 18:48:27.120483: step 66070, loss = 0.45, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 16h:29m:32s remains)
INFO - root - 2017-12-16 18:48:29.331224: step 66080, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 15h:56m:28s remains)
INFO - root - 2017-12-16 18:48:31.527668: step 66090, loss = 0.52, batch loss = 0.35 (38.0 examples/sec; 0.210 sec/batch; 15h:34m:19s remains)
INFO - root - 2017-12-16 18:48:33.748873: step 66100, loss = 0.55, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 16h:16m:27s remains)
INFO - root - 2017-12-16 18:48:36.102617: step 66110, loss = 0.48, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 16h:30m:36s remains)
INFO - root - 2017-12-16 18:48:38.343798: step 66120, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 16h:20m:48s remains)
INFO - root - 2017-12-16 18:48:40.564702: step 66130, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 16h:38m:31s remains)
INFO - root - 2017-12-16 18:48:42.824420: step 66140, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 16h:42m:25s remains)
INFO - root - 2017-12-16 18:48:45.039839: step 66150, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 16h:13m:08s remains)
INFO - root - 2017-12-16 18:48:47.284117: step 66160, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 16h:12m:35s remains)
INFO - root - 2017-12-16 18:48:49.540293: step 66170, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.232 sec/batch; 17h:11m:16s remains)
INFO - root - 2017-12-16 18:48:51.740249: step 66180, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 16h:43m:20s remains)
INFO - root - 2017-12-16 18:48:53.973866: step 66190, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 16h:41m:59s remains)
INFO - root - 2017-12-16 18:48:56.189216: step 66200, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 16h:24m:47s remains)
INFO - root - 2017-12-16 18:48:58.530264: step 66210, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 16h:23m:09s remains)
INFO - root - 2017-12-16 18:49:00.782216: step 66220, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 16h:02m:04s remains)
INFO - root - 2017-12-16 18:49:02.998633: step 66230, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 16h:26m:54s remains)
INFO - root - 2017-12-16 18:49:05.206934: step 66240, loss = 0.42, batch loss = 0.24 (37.4 examples/sec; 0.214 sec/batch; 15h:48m:11s remains)
INFO - root - 2017-12-16 18:49:07.446889: step 66250, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.226 sec/batch; 16h:44m:22s remains)
INFO - root - 2017-12-16 18:49:09.657838: step 66260, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 15h:54m:40s remains)
INFO - root - 2017-12-16 18:49:11.880318: step 66270, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 16h:18m:18s remains)
INFO - root - 2017-12-16 18:49:14.099437: step 66280, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 16h:37m:24s remains)
INFO - root - 2017-12-16 18:49:16.313883: step 66290, loss = 0.42, batch loss = 0.24 (37.6 examples/sec; 0.213 sec/batch; 15h:43m:27s remains)
INFO - root - 2017-12-16 18:49:18.550746: step 66300, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 16h:52m:13s remains)
INFO - root - 2017-12-16 18:49:20.867169: step 66310, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 16h:33m:19s remains)
INFO - root - 2017-12-16 18:49:23.086793: step 66320, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 16h:05m:35s remains)
INFO - root - 2017-12-16 18:49:25.290853: step 66330, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 15h:59m:06s remains)
INFO - root - 2017-12-16 18:49:27.484997: step 66340, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 16h:03m:24s remains)
INFO - root - 2017-12-16 18:49:29.716768: step 66350, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 16h:29m:36s remains)
INFO - root - 2017-12-16 18:49:31.921290: step 66360, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 16h:59m:55s remains)
INFO - root - 2017-12-16 18:49:34.158325: step 66370, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 16h:25m:48s remains)
INFO - root - 2017-12-16 18:49:36.380810: step 66380, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 16h:23m:10s remains)
INFO - root - 2017-12-16 18:49:38.617724: step 66390, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 16h:22m:44s remains)
INFO - root - 2017-12-16 18:49:40.832831: step 66400, loss = 0.42, batch loss = 0.24 (38.1 examples/sec; 0.210 sec/batch; 15h:30m:29s remains)
INFO - root - 2017-12-16 18:49:43.146210: step 66410, loss = 0.55, batch loss = 0.37 (35.6 examples/sec; 0.225 sec/batch; 16h:35m:56s remains)
INFO - root - 2017-12-16 18:49:45.361864: step 66420, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 16h:36m:53s remains)
INFO - root - 2017-12-16 18:49:47.572323: step 66430, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.215 sec/batch; 15h:55m:33s remains)
INFO - root - 2017-12-16 18:49:49.764459: step 66440, loss = 0.51, batch loss = 0.33 (35.2 examples/sec; 0.227 sec/batch; 16h:47m:15s remains)
INFO - root - 2017-12-16 18:49:51.978925: step 66450, loss = 0.51, batch loss = 0.33 (35.0 examples/sec; 0.228 sec/batch; 16h:52m:49s remains)
INFO - root - 2017-12-16 18:49:54.209160: step 66460, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 16h:08m:41s remains)
INFO - root - 2017-12-16 18:49:56.427730: step 66470, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 16h:28m:17s remains)
INFO - root - 2017-12-16 18:49:58.657786: step 66480, loss = 0.42, batch loss = 0.25 (34.6 examples/sec; 0.231 sec/batch; 17h:05m:36s remains)
INFO - root - 2017-12-16 18:50:00.823921: step 66490, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 15h:57m:40s remains)
INFO - root - 2017-12-16 18:50:03.092380: step 66500, loss = 0.45, batch loss = 0.27 (34.7 examples/sec; 0.230 sec/batch; 17h:00m:44s remains)
INFO - root - 2017-12-16 18:50:05.452339: step 66510, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 16h:42m:38s remains)
INFO - root - 2017-12-16 18:50:07.703031: step 66520, loss = 0.52, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 16h:24m:04s remains)
INFO - root - 2017-12-16 18:50:09.929296: step 66530, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 16h:27m:29s remains)
INFO - root - 2017-12-16 18:50:12.160489: step 66540, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 16h:57m:50s remains)
INFO - root - 2017-12-16 18:50:14.357055: step 66550, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 16h:18m:51s remains)
INFO - root - 2017-12-16 18:50:16.545783: step 66560, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 15h:51m:55s remains)
INFO - root - 2017-12-16 18:50:18.780318: step 66570, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 16h:23m:57s remains)
INFO - root - 2017-12-16 18:50:21.021928: step 66580, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 16h:02m:21s remains)
INFO - root - 2017-12-16 18:50:23.277241: step 66590, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 16h:13m:39s remains)
INFO - root - 2017-12-16 18:50:25.512666: step 66600, loss = 0.44, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 16h:10m:03s remains)
INFO - root - 2017-12-16 18:50:27.849960: step 66610, loss = 0.47, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 16h:27m:18s remains)
INFO - root - 2017-12-16 18:50:30.049061: step 66620, loss = 0.56, batch loss = 0.38 (37.1 examples/sec; 0.216 sec/batch; 15h:56m:07s remains)
INFO - root - 2017-12-16 18:50:32.290257: step 66630, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 16h:33m:28s remains)
INFO - root - 2017-12-16 18:50:34.461950: step 66640, loss = 0.51, batch loss = 0.34 (37.1 examples/sec; 0.215 sec/batch; 15h:54m:38s remains)
INFO - root - 2017-12-16 18:50:36.673043: step 66650, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.228 sec/batch; 16h:52m:19s remains)
INFO - root - 2017-12-16 18:50:38.910386: step 66660, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 16h:10m:49s remains)
INFO - root - 2017-12-16 18:50:41.114024: step 66670, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 15h:51m:39s remains)
INFO - root - 2017-12-16 18:50:43.359012: step 66680, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 16h:50m:58s remains)
INFO - root - 2017-12-16 18:50:45.541098: step 66690, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 16h:29m:47s remains)
INFO - root - 2017-12-16 18:50:47.778371: step 66700, loss = 0.44, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 16h:29m:12s remains)
INFO - root - 2017-12-16 18:50:50.107763: step 66710, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 16h:34m:59s remains)
INFO - root - 2017-12-16 18:50:52.321980: step 66720, loss = 0.53, batch loss = 0.35 (34.8 examples/sec; 0.230 sec/batch; 16h:56m:53s remains)
INFO - root - 2017-12-16 18:50:54.561397: step 66730, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 16h:24m:21s remains)
INFO - root - 2017-12-16 18:50:56.811182: step 66740, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 16h:39m:25s remains)
INFO - root - 2017-12-16 18:50:59.036074: step 66750, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 16h:16m:24s remains)
INFO - root - 2017-12-16 18:51:01.267947: step 66760, loss = 0.46, batch loss = 0.28 (34.2 examples/sec; 0.234 sec/batch; 17h:14m:49s remains)
INFO - root - 2017-12-16 18:51:03.510733: step 66770, loss = 0.46, batch loss = 0.28 (34.2 examples/sec; 0.234 sec/batch; 17h:15m:12s remains)
INFO - root - 2017-12-16 18:51:05.714330: step 66780, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 16h:18m:29s remains)
INFO - root - 2017-12-16 18:51:07.915046: step 66790, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 16h:27m:42s remains)
INFO - root - 2017-12-16 18:51:10.125785: step 66800, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.215 sec/batch; 15h:50m:07s remains)
INFO - root - 2017-12-16 18:51:12.466633: step 66810, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 16h:54m:34s remains)
INFO - root - 2017-12-16 18:51:14.673426: step 66820, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 16h:31m:20s remains)
INFO - root - 2017-12-16 18:51:16.886217: step 66830, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 16h:27m:07s remains)
INFO - root - 2017-12-16 18:51:19.127050: step 66840, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 16h:28m:49s remains)
INFO - root - 2017-12-16 18:51:21.316673: step 66850, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 16h:20m:57s remains)
INFO - root - 2017-12-16 18:51:23.543274: step 66860, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 16h:37m:45s remains)
INFO - root - 2017-12-16 18:51:25.779993: step 66870, loss = 0.51, batch loss = 0.33 (33.0 examples/sec; 0.243 sec/batch; 17h:54m:23s remains)
INFO - root - 2017-12-16 18:51:28.005946: step 66880, loss = 0.43, batch loss = 0.25 (33.4 examples/sec; 0.240 sec/batch; 17h:40m:59s remains)
INFO - root - 2017-12-16 18:51:30.209825: step 66890, loss = 0.47, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 16h:00m:48s remains)
INFO - root - 2017-12-16 18:51:32.442127: step 66900, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 15h:56m:31s remains)
INFO - root - 2017-12-16 18:51:34.810642: step 66910, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 16h:16m:44s remains)
INFO - root - 2017-12-16 18:51:37.020703: step 66920, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 16h:29m:36s remains)
INFO - root - 2017-12-16 18:51:39.217719: step 66930, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 16h:02m:00s remains)
INFO - root - 2017-12-16 18:51:41.456453: step 66940, loss = 0.47, batch loss = 0.29 (33.9 examples/sec; 0.236 sec/batch; 17h:23m:32s remains)
INFO - root - 2017-12-16 18:51:43.690150: step 66950, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 16h:11m:34s remains)
INFO - root - 2017-12-16 18:51:45.930064: step 66960, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 16h:03m:14s remains)
INFO - root - 2017-12-16 18:51:48.163534: step 66970, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 16h:41m:50s remains)
INFO - root - 2017-12-16 18:51:50.364042: step 66980, loss = 0.51, batch loss = 0.33 (37.8 examples/sec; 0.212 sec/batch; 15h:36m:02s remains)
INFO - root - 2017-12-16 18:51:52.615103: step 66990, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 16h:35m:30s remains)
INFO - root - 2017-12-16 18:51:54.864199: step 67000, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.221 sec/batch; 16h:19m:20s remains)
INFO - root - 2017-12-16 18:51:57.189594: step 67010, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 15h:47m:56s remains)
INFO - root - 2017-12-16 18:51:59.382931: step 67020, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 16h:22m:22s remains)
INFO - root - 2017-12-16 18:52:01.618477: step 67030, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 16h:23m:46s remains)
INFO - root - 2017-12-16 18:52:03.863731: step 67040, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 16h:20m:41s remains)
INFO - root - 2017-12-16 18:52:06.080989: step 67050, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 16h:38m:52s remains)
INFO - root - 2017-12-16 18:52:08.318249: step 67060, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 15h:48m:12s remains)
INFO - root - 2017-12-16 18:52:10.550207: step 67070, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 16h:00m:01s remains)
INFO - root - 2017-12-16 18:52:12.766423: step 67080, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 16h:08m:44s remains)
INFO - root - 2017-12-16 18:52:15.013145: step 67090, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 16h:15m:54s remains)
INFO - root - 2017-12-16 18:52:17.257116: step 67100, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.226 sec/batch; 16h:37m:30s remains)
INFO - root - 2017-12-16 18:52:19.574850: step 67110, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 16h:04m:21s remains)
INFO - root - 2017-12-16 18:52:21.783764: step 67120, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 16h:34m:54s remains)
INFO - root - 2017-12-16 18:52:24.003825: step 67130, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 15h:54m:17s remains)
INFO - root - 2017-12-16 18:52:26.231409: step 67140, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 16h:48m:02s remains)
INFO - root - 2017-12-16 18:52:28.437841: step 67150, loss = 0.54, batch loss = 0.36 (36.1 examples/sec; 0.221 sec/batch; 16h:18m:57s remains)
INFO - root - 2017-12-16 18:52:30.706225: step 67160, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 16h:31m:21s remains)
INFO - root - 2017-12-16 18:52:32.961167: step 67170, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.223 sec/batch; 16h:24m:01s remains)
INFO - root - 2017-12-16 18:52:35.171898: step 67180, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 16h:03m:50s remains)
INFO - root - 2017-12-16 18:52:37.413884: step 67190, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 16h:02m:53s remains)
INFO - root - 2017-12-16 18:52:39.647403: step 67200, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 16h:03m:49s remains)
INFO - root - 2017-12-16 18:52:41.991927: step 67210, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 15h:57m:23s remains)
INFO - root - 2017-12-16 18:52:44.239538: step 67220, loss = 0.45, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 16h:48m:57s remains)
INFO - root - 2017-12-16 18:52:46.437806: step 67230, loss = 0.56, batch loss = 0.38 (37.1 examples/sec; 0.216 sec/batch; 15h:54m:01s remains)
INFO - root - 2017-12-16 18:52:48.634868: step 67240, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 15h:58m:32s remains)
INFO - root - 2017-12-16 18:52:50.839539: step 67250, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 16h:03m:55s remains)
INFO - root - 2017-12-16 18:52:53.038042: step 67260, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 16h:24m:48s remains)
INFO - root - 2017-12-16 18:52:55.318664: step 67270, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 16h:40m:04s remains)
INFO - root - 2017-12-16 18:52:57.563355: step 67280, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 16h:08m:26s remains)
INFO - root - 2017-12-16 18:52:59.756797: step 67290, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 15h:44m:46s remains)
INFO - root - 2017-12-16 18:53:01.999819: step 67300, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 16h:29m:29s remains)
INFO - root - 2017-12-16 18:53:04.358695: step 67310, loss = 0.42, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 16h:03m:07s remains)
INFO - root - 2017-12-16 18:53:06.611642: step 67320, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 16h:43m:04s remains)
INFO - root - 2017-12-16 18:53:08.851089: step 67330, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 16h:21m:46s remains)
INFO - root - 2017-12-16 18:53:11.078977: step 67340, loss = 0.50, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 16h:37m:36s remains)
INFO - root - 2017-12-16 18:53:13.319653: step 67350, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 16h:30m:24s remains)
INFO - root - 2017-12-16 18:53:15.532542: step 67360, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 16h:06m:11s remains)
INFO - root - 2017-12-16 18:53:17.788299: step 67370, loss = 0.52, batch loss = 0.35 (35.5 examples/sec; 0.225 sec/batch; 16h:35m:21s remains)
INFO - root - 2017-12-16 18:53:20.016967: step 67380, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 16h:19m:44s remains)
INFO - root - 2017-12-16 18:53:22.247694: step 67390, loss = 0.49, batch loss = 0.31 (38.0 examples/sec; 0.211 sec/batch; 15h:30m:44s remains)
INFO - root - 2017-12-16 18:53:24.509201: step 67400, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 16h:27m:28s remains)
INFO - root - 2017-12-16 18:53:26.855193: step 67410, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 16h:28m:11s remains)
INFO - root - 2017-12-16 18:53:29.037906: step 67420, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 16h:14m:00s remains)
INFO - root - 2017-12-16 18:53:31.206793: step 67430, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 15h:48m:01s remains)
INFO - root - 2017-12-16 18:53:33.409609: step 67440, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 16h:45m:00s remains)
INFO - root - 2017-12-16 18:53:35.637133: step 67450, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 16h:01m:22s remains)
INFO - root - 2017-12-16 18:53:37.846051: step 67460, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 16h:18m:41s remains)
INFO - root - 2017-12-16 18:53:40.079426: step 67470, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 15h:53m:09s remains)
INFO - root - 2017-12-16 18:53:42.294272: step 67480, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 15h:57m:30s remains)
INFO - root - 2017-12-16 18:53:44.487922: step 67490, loss = 0.42, batch loss = 0.24 (36.9 examples/sec; 0.217 sec/batch; 15h:56m:46s remains)
INFO - root - 2017-12-16 18:53:46.696945: step 67500, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 15h:58m:18s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-67500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-67500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 18:53:49.468493: step 67510, loss = 0.56, batch loss = 0.38 (38.0 examples/sec; 0.210 sec/batch; 15h:29m:07s remains)
INFO - root - 2017-12-16 18:53:51.685815: step 67520, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 16h:07m:55s remains)
INFO - root - 2017-12-16 18:53:53.919432: step 67530, loss = 0.51, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 16h:23m:20s remains)
INFO - root - 2017-12-16 18:53:56.112434: step 67540, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 16h:06m:27s remains)
INFO - root - 2017-12-16 18:53:58.340702: step 67550, loss = 0.51, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 16h:35m:37s remains)
INFO - root - 2017-12-16 18:54:00.577504: step 67560, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 16h:31m:35s remains)
INFO - root - 2017-12-16 18:54:02.764803: step 67570, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 15h:52m:18s remains)
INFO - root - 2017-12-16 18:54:04.993901: step 67580, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 16h:29m:51s remains)
INFO - root - 2017-12-16 18:54:07.192186: step 67590, loss = 0.41, batch loss = 0.24 (34.8 examples/sec; 0.230 sec/batch; 16h:54m:53s remains)
INFO - root - 2017-12-16 18:54:09.415492: step 67600, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 15h:43m:30s remains)
INFO - root - 2017-12-16 18:54:11.767521: step 67610, loss = 0.52, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 16h:14m:59s remains)
INFO - root - 2017-12-16 18:54:13.986345: step 67620, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.215 sec/batch; 15h:47m:44s remains)
INFO - root - 2017-12-16 18:54:16.170179: step 67630, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 16h:00m:06s remains)
INFO - root - 2017-12-16 18:54:18.402293: step 67640, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 16h:37m:33s remains)
INFO - root - 2017-12-16 18:54:20.614870: step 67650, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 16h:46m:14s remains)
INFO - root - 2017-12-16 18:54:22.835488: step 67660, loss = 0.53, batch loss = 0.35 (35.3 examples/sec; 0.226 sec/batch; 16h:39m:39s remains)
INFO - root - 2017-12-16 18:54:25.063204: step 67670, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 16h:20m:06s remains)
INFO - root - 2017-12-16 18:54:27.332825: step 67680, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 15h:45m:22s remains)
INFO - root - 2017-12-16 18:54:29.566731: step 67690, loss = 0.44, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 17h:02m:44s remains)
INFO - root - 2017-12-16 18:54:31.798653: step 67700, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 16h:14m:49s remains)
INFO - root - 2017-12-16 18:54:34.166910: step 67710, loss = 0.45, batch loss = 0.27 (33.4 examples/sec; 0.239 sec/batch; 17h:36m:11s remains)
INFO - root - 2017-12-16 18:54:36.411303: step 67720, loss = 0.60, batch loss = 0.42 (36.9 examples/sec; 0.217 sec/batch; 15h:55m:50s remains)
INFO - root - 2017-12-16 18:54:38.650473: step 67730, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 16h:33m:17s remains)
INFO - root - 2017-12-16 18:54:40.841472: step 67740, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 16h:13m:55s remains)
INFO - root - 2017-12-16 18:54:43.030837: step 67750, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 15h:57m:07s remains)
INFO - root - 2017-12-16 18:54:45.224469: step 67760, loss = 0.49, batch loss = 0.31 (33.7 examples/sec; 0.237 sec/batch; 17h:26m:37s remains)
INFO - root - 2017-12-16 18:54:47.462779: step 67770, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 16h:43m:28s remains)
INFO - root - 2017-12-16 18:54:49.703062: step 67780, loss = 0.50, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 15h:55m:15s remains)
INFO - root - 2017-12-16 18:54:51.956426: step 67790, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 16h:28m:22s remains)
INFO - root - 2017-12-16 18:54:54.167499: step 67800, loss = 0.51, batch loss = 0.33 (33.7 examples/sec; 0.238 sec/batch; 17h:28m:47s remains)
INFO - root - 2017-12-16 18:54:56.536460: step 67810, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 16h:59m:45s remains)
INFO - root - 2017-12-16 18:54:58.763347: step 67820, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 16h:05m:46s remains)
INFO - root - 2017-12-16 18:55:00.981822: step 67830, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 16h:54m:36s remains)
INFO - root - 2017-12-16 18:55:03.197223: step 67840, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 15h:57m:39s remains)
INFO - root - 2017-12-16 18:55:05.376980: step 67850, loss = 0.44, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 16h:17m:48s remains)
INFO - root - 2017-12-16 18:55:07.621640: step 67860, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 16h:22m:28s remains)
INFO - root - 2017-12-16 18:55:09.868784: step 67870, loss = 0.43, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 16h:18m:51s remains)
INFO - root - 2017-12-16 18:55:12.091853: step 67880, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 16h:01m:05s remains)
INFO - root - 2017-12-16 18:55:14.290223: step 67890, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.218 sec/batch; 16h:03m:02s remains)
INFO - root - 2017-12-16 18:55:16.515396: step 67900, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 16h:03m:01s remains)
INFO - root - 2017-12-16 18:55:18.828043: step 67910, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 16h:04m:34s remains)
INFO - root - 2017-12-16 18:55:21.045177: step 67920, loss = 0.47, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 16h:07m:09s remains)
INFO - root - 2017-12-16 18:55:23.257352: step 67930, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 15h:39m:00s remains)
INFO - root - 2017-12-16 18:55:25.504238: step 67940, loss = 0.47, batch loss = 0.29 (34.1 examples/sec; 0.234 sec/batch; 17h:13m:04s remains)
INFO - root - 2017-12-16 18:55:27.725276: step 67950, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 16h:15m:13s remains)
INFO - root - 2017-12-16 18:55:29.957997: step 67960, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 15h:42m:22s remains)
INFO - root - 2017-12-16 18:55:32.140356: step 67970, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 16h:00m:11s remains)
INFO - root - 2017-12-16 18:55:34.304141: step 67980, loss = 0.53, batch loss = 0.35 (37.9 examples/sec; 0.211 sec/batch; 15h:30m:22s remains)
INFO - root - 2017-12-16 18:55:36.530644: step 67990, loss = 0.52, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 16h:27m:30s remains)
INFO - root - 2017-12-16 18:55:38.740257: step 68000, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 16h:22m:34s remains)
INFO - root - 2017-12-16 18:55:41.117674: step 68010, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.223 sec/batch; 16h:23m:43s remains)
INFO - root - 2017-12-16 18:55:43.329915: step 68020, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 16h:06m:19s remains)
INFO - root - 2017-12-16 18:55:45.538231: step 68030, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 16h:05m:25s remains)
INFO - root - 2017-12-16 18:55:47.766974: step 68040, loss = 0.51, batch loss = 0.33 (33.9 examples/sec; 0.236 sec/batch; 17h:21m:31s remains)
INFO - root - 2017-12-16 18:55:49.983225: step 68050, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 15h:56m:08s remains)
INFO - root - 2017-12-16 18:55:52.190036: step 68060, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 16h:37m:48s remains)
INFO - root - 2017-12-16 18:55:54.401659: step 68070, loss = 0.50, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 16h:00m:12s remains)
INFO - root - 2017-12-16 18:55:56.636066: step 68080, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 16h:22m:22s remains)
INFO - root - 2017-12-16 18:55:58.902029: step 68090, loss = 0.42, batch loss = 0.24 (33.1 examples/sec; 0.242 sec/batch; 17h:46m:30s remains)
INFO - root - 2017-12-16 18:56:01.142003: step 68100, loss = 0.50, batch loss = 0.32 (34.0 examples/sec; 0.236 sec/batch; 17h:18m:17s remains)
INFO - root - 2017-12-16 18:56:03.501383: step 68110, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 15h:52m:56s remains)
INFO - root - 2017-12-16 18:56:05.694503: step 68120, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 16h:15m:55s remains)
INFO - root - 2017-12-16 18:56:07.949093: step 68130, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 16h:24m:17s remains)
INFO - root - 2017-12-16 18:56:10.188566: step 68140, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 15h:53m:35s remains)
INFO - root - 2017-12-16 18:56:12.419777: step 68150, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 16h:38m:35s remains)
INFO - root - 2017-12-16 18:56:14.643489: step 68160, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 16h:34m:36s remains)
INFO - root - 2017-12-16 18:56:16.911811: step 68170, loss = 0.52, batch loss = 0.34 (34.4 examples/sec; 0.233 sec/batch; 17h:04m:56s remains)
INFO - root - 2017-12-16 18:56:19.123869: step 68180, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 16h:01m:28s remains)
INFO - root - 2017-12-16 18:56:21.320807: step 68190, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 16h:21m:16s remains)
INFO - root - 2017-12-16 18:56:23.534776: step 68200, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 16h:24m:59s remains)
INFO - root - 2017-12-16 18:56:25.880790: step 68210, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.224 sec/batch; 16h:28m:42s remains)
INFO - root - 2017-12-16 18:56:28.109776: step 68220, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 17h:01m:50s remains)
INFO - root - 2017-12-16 18:56:30.292662: step 68230, loss = 0.43, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 15h:37m:37s remains)
INFO - root - 2017-12-16 18:56:32.504844: step 68240, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 15h:52m:15s remains)
INFO - root - 2017-12-16 18:56:34.741578: step 68250, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 16h:19m:14s remains)
INFO - root - 2017-12-16 18:56:36.960868: step 68260, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 15h:42m:09s remains)
INFO - root - 2017-12-16 18:56:39.178787: step 68270, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 16h:19m:18s remains)
INFO - root - 2017-12-16 18:56:41.362552: step 68280, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 16h:01m:07s remains)
INFO - root - 2017-12-16 18:56:43.573072: step 68290, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 16h:00m:57s remains)
INFO - root - 2017-12-16 18:56:45.797975: step 68300, loss = 0.54, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 16h:13m:28s remains)
INFO - root - 2017-12-16 18:56:48.169712: step 68310, loss = 0.47, batch loss = 0.29 (37.9 examples/sec; 0.211 sec/batch; 15h:29m:14s remains)
INFO - root - 2017-12-16 18:56:50.355360: step 68320, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 16h:12m:40s remains)
INFO - root - 2017-12-16 18:56:52.603968: step 68330, loss = 0.54, batch loss = 0.36 (32.9 examples/sec; 0.243 sec/batch; 17h:49m:57s remains)
INFO - root - 2017-12-16 18:56:54.837943: step 68340, loss = 0.47, batch loss = 0.29 (34.0 examples/sec; 0.235 sec/batch; 17h:15m:49s remains)
INFO - root - 2017-12-16 18:56:57.096879: step 68350, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 16h:21m:44s remains)
INFO - root - 2017-12-16 18:56:59.326478: step 68360, loss = 0.42, batch loss = 0.24 (35.8 examples/sec; 0.223 sec/batch; 16h:23m:37s remains)
INFO - root - 2017-12-16 18:57:01.518215: step 68370, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.218 sec/batch; 15h:57m:50s remains)
INFO - root - 2017-12-16 18:57:03.788793: step 68380, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 16h:25m:23s remains)
INFO - root - 2017-12-16 18:57:05.978177: step 68390, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 16h:06m:05s remains)
INFO - root - 2017-12-16 18:57:08.183548: step 68400, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 16h:06m:53s remains)
INFO - root - 2017-12-16 18:57:10.502800: step 68410, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 16h:03m:22s remains)
INFO - root - 2017-12-16 18:57:12.729238: step 68420, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.221 sec/batch; 16h:14m:03s remains)
INFO - root - 2017-12-16 18:57:14.910129: step 68430, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 15h:42m:36s remains)
INFO - root - 2017-12-16 18:57:17.129943: step 68440, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 16h:08m:38s remains)
INFO - root - 2017-12-16 18:57:19.359467: step 68450, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 16h:38m:59s remains)
INFO - root - 2017-12-16 18:57:21.562621: step 68460, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 15h:50m:37s remains)
INFO - root - 2017-12-16 18:57:23.767540: step 68470, loss = 0.55, batch loss = 0.37 (34.2 examples/sec; 0.234 sec/batch; 17h:08m:09s remains)
INFO - root - 2017-12-16 18:57:25.977400: step 68480, loss = 0.56, batch loss = 0.38 (33.8 examples/sec; 0.236 sec/batch; 17h:20m:12s remains)
INFO - root - 2017-12-16 18:57:28.215356: step 68490, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 16h:07m:57s remains)
INFO - root - 2017-12-16 18:57:30.421792: step 68500, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 15h:40m:56s remains)
INFO - root - 2017-12-16 18:57:32.741099: step 68510, loss = 0.49, batch loss = 0.31 (33.2 examples/sec; 0.241 sec/batch; 17h:39m:16s remains)
INFO - root - 2017-12-16 18:57:34.935978: step 68520, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 16h:08m:36s remains)
INFO - root - 2017-12-16 18:57:37.104389: step 68530, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 16h:09m:07s remains)
INFO - root - 2017-12-16 18:57:39.289406: step 68540, loss = 0.59, batch loss = 0.41 (35.8 examples/sec; 0.223 sec/batch; 16h:22m:43s remains)
INFO - root - 2017-12-16 18:57:41.491506: step 68550, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 16h:08m:49s remains)
INFO - root - 2017-12-16 18:57:43.684217: step 68560, loss = 0.50, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 16h:02m:34s remains)
INFO - root - 2017-12-16 18:57:45.928503: step 68570, loss = 0.55, batch loss = 0.37 (35.6 examples/sec; 0.224 sec/batch; 16h:27m:30s remains)
INFO - root - 2017-12-16 18:57:48.127399: step 68580, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 16h:14m:40s remains)
INFO - root - 2017-12-16 18:57:50.354440: step 68590, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 16h:23m:49s remains)
INFO - root - 2017-12-16 18:57:52.580753: step 68600, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 16h:25m:41s remains)
INFO - root - 2017-12-16 18:57:54.917701: step 68610, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 15h:56m:19s remains)
INFO - root - 2017-12-16 18:57:57.131195: step 68620, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 16h:03m:59s remains)
INFO - root - 2017-12-16 18:57:59.381802: step 68630, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 16h:36m:24s remains)
INFO - root - 2017-12-16 18:58:01.618278: step 68640, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 15h:55m:52s remains)
INFO - root - 2017-12-16 18:58:03.830391: step 68650, loss = 0.50, batch loss = 0.33 (37.3 examples/sec; 0.214 sec/batch; 15h:42m:57s remains)
INFO - root - 2017-12-16 18:58:06.028863: step 68660, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 15h:55m:07s remains)
INFO - root - 2017-12-16 18:58:08.240301: step 68670, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 16h:04m:58s remains)
INFO - root - 2017-12-16 18:58:10.468785: step 68680, loss = 0.58, batch loss = 0.40 (36.5 examples/sec; 0.219 sec/batch; 16h:03m:35s remains)
INFO - root - 2017-12-16 18:58:12.706061: step 68690, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 15h:41m:01s remains)
INFO - root - 2017-12-16 18:58:14.905878: step 68700, loss = 0.61, batch loss = 0.43 (37.0 examples/sec; 0.216 sec/batch; 15h:49m:59s remains)
INFO - root - 2017-12-16 18:58:17.239736: step 68710, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 16h:19m:01s remains)
INFO - root - 2017-12-16 18:58:19.423272: step 68720, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 16h:13m:01s remains)
INFO - root - 2017-12-16 18:58:21.675948: step 68730, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 16h:33m:46s remains)
INFO - root - 2017-12-16 18:58:23.886702: step 68740, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 15h:52m:09s remains)
INFO - root - 2017-12-16 18:58:26.092797: step 68750, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 16h:37m:38s remains)
INFO - root - 2017-12-16 18:58:28.310888: step 68760, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 15h:44m:13s remains)
INFO - root - 2017-12-16 18:58:30.485403: step 68770, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 16h:38m:15s remains)
INFO - root - 2017-12-16 18:58:32.686758: step 68780, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 16h:19m:07s remains)
INFO - root - 2017-12-16 18:58:34.908155: step 68790, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 16h:21m:31s remains)
INFO - root - 2017-12-16 18:58:37.107503: step 68800, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 16h:18m:10s remains)
INFO - root - 2017-12-16 18:58:39.442694: step 68810, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 16h:32m:37s remains)
INFO - root - 2017-12-16 18:58:41.671421: step 68820, loss = 0.53, batch loss = 0.35 (34.2 examples/sec; 0.234 sec/batch; 17h:07m:16s remains)
INFO - root - 2017-12-16 18:58:43.842831: step 68830, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 16h:01m:01s remains)
INFO - root - 2017-12-16 18:58:46.079859: step 68840, loss = 0.43, batch loss = 0.25 (33.3 examples/sec; 0.240 sec/batch; 17h:35m:30s remains)
INFO - root - 2017-12-16 18:58:48.292639: step 68850, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 16h:11m:26s remains)
INFO - root - 2017-12-16 18:58:50.515757: step 68860, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 15h:49m:40s remains)
INFO - root - 2017-12-16 18:58:52.691413: step 68870, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 15h:54m:15s remains)
INFO - root - 2017-12-16 18:58:54.907069: step 68880, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 16h:32m:49s remains)
INFO - root - 2017-12-16 18:58:57.098493: step 68890, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 16h:02m:36s remains)
INFO - root - 2017-12-16 18:58:59.321847: step 68900, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.231 sec/batch; 16h:56m:54s remains)
INFO - root - 2017-12-16 18:59:01.688942: step 68910, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 15h:50m:24s remains)
INFO - root - 2017-12-16 18:59:03.906465: step 68920, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 15h:53m:09s remains)
INFO - root - 2017-12-16 18:59:06.126966: step 68930, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 15h:58m:34s remains)
INFO - root - 2017-12-16 18:59:08.370448: step 68940, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 15h:53m:32s remains)
INFO - root - 2017-12-16 18:59:10.560169: step 68950, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 15h:59m:59s remains)
INFO - root - 2017-12-16 18:59:12.739401: step 68960, loss = 0.50, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 15h:43m:57s remains)
INFO - root - 2017-12-16 18:59:14.919478: step 68970, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 15h:59m:30s remains)
INFO - root - 2017-12-16 18:59:17.150317: step 68980, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 15h:36m:31s remains)
INFO - root - 2017-12-16 18:59:19.396917: step 68990, loss = 0.50, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 15h:57m:01s remains)
INFO - root - 2017-12-16 18:59:21.624935: step 69000, loss = 0.48, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 15h:58m:48s remains)
INFO - root - 2017-12-16 18:59:23.996934: step 69010, loss = 0.46, batch loss = 0.28 (34.5 examples/sec; 0.232 sec/batch; 16h:58m:48s remains)
INFO - root - 2017-12-16 18:59:26.221410: step 69020, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 16h:08m:04s remains)
INFO - root - 2017-12-16 18:59:28.432037: step 69030, loss = 0.59, batch loss = 0.41 (37.0 examples/sec; 0.216 sec/batch; 15h:49m:09s remains)
INFO - root - 2017-12-16 18:59:30.601806: step 69040, loss = 0.54, batch loss = 0.36 (37.7 examples/sec; 0.212 sec/batch; 15h:30m:48s remains)
INFO - root - 2017-12-16 18:59:32.803516: step 69050, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 16h:09m:51s remains)
INFO - root - 2017-12-16 18:59:35.046647: step 69060, loss = 0.43, batch loss = 0.25 (32.6 examples/sec; 0.246 sec/batch; 17h:58m:51s remains)
INFO - root - 2017-12-16 18:59:37.243689: step 69070, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 15h:34m:15s remains)
INFO - root - 2017-12-16 18:59:39.457496: step 69080, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 16h:11m:47s remains)
INFO - root - 2017-12-16 18:59:41.680025: step 69090, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 16h:27m:32s remains)
INFO - root - 2017-12-16 18:59:43.888393: step 69100, loss = 0.48, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 16h:16m:07s remains)
INFO - root - 2017-12-16 18:59:46.192699: step 69110, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 16h:27m:32s remains)
INFO - root - 2017-12-16 18:59:48.405102: step 69120, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 16h:00m:00s remains)
INFO - root - 2017-12-16 18:59:50.612001: step 69130, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 15h:56m:19s remains)
INFO - root - 2017-12-16 18:59:52.814154: step 69140, loss = 0.45, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 16h:27m:58s remains)
INFO - root - 2017-12-16 18:59:55.045043: step 69150, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 16h:45m:09s remains)
INFO - root - 2017-12-16 18:59:57.246654: step 69160, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 15h:29m:08s remains)
INFO - root - 2017-12-16 18:59:59.444637: step 69170, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 16h:38m:04s remains)
INFO - root - 2017-12-16 19:00:01.662286: step 69180, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 15h:50m:12s remains)
INFO - root - 2017-12-16 19:00:03.850686: step 69190, loss = 0.49, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 16h:20m:31s remains)
INFO - root - 2017-12-16 19:00:06.142106: step 69200, loss = 0.44, batch loss = 0.26 (34.2 examples/sec; 0.234 sec/batch; 17h:06m:45s remains)
INFO - root - 2017-12-16 19:00:08.464887: step 69210, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 15h:55m:43s remains)
INFO - root - 2017-12-16 19:00:10.631808: step 69220, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 16h:06m:31s remains)
INFO - root - 2017-12-16 19:00:12.826070: step 69230, loss = 0.45, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 15h:39m:56s remains)
INFO - root - 2017-12-16 19:00:15.021151: step 69240, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 16h:13m:00s remains)
INFO - root - 2017-12-16 19:00:17.196188: step 69250, loss = 0.45, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 15h:35m:28s remains)
INFO - root - 2017-12-16 19:00:19.398351: step 69260, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 16h:03m:04s remains)
INFO - root - 2017-12-16 19:00:21.583899: step 69270, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 16h:07m:31s remains)
INFO - root - 2017-12-16 19:00:23.801719: step 69280, loss = 0.55, batch loss = 0.37 (34.9 examples/sec; 0.229 sec/batch; 16h:44m:44s remains)
INFO - root - 2017-12-16 19:00:25.991053: step 69290, loss = 0.46, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 16h:02m:12s remains)
INFO - root - 2017-12-16 19:00:28.189738: step 69300, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 16h:20m:38s remains)
INFO - root - 2017-12-16 19:00:30.495063: step 69310, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 15h:59m:38s remains)
INFO - root - 2017-12-16 19:00:32.737269: step 69320, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 15h:56m:54s remains)
INFO - root - 2017-12-16 19:00:34.935117: step 69330, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 16h:01m:14s remains)
INFO - root - 2017-12-16 19:00:37.170707: step 69340, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 16h:25m:09s remains)
INFO - root - 2017-12-16 19:00:39.391498: step 69350, loss = 0.46, batch loss = 0.29 (34.0 examples/sec; 0.235 sec/batch; 17h:10m:27s remains)
INFO - root - 2017-12-16 19:00:41.590650: step 69360, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 15h:44m:12s remains)
INFO - root - 2017-12-16 19:00:43.794319: step 69370, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 15h:40m:40s remains)
INFO - root - 2017-12-16 19:00:45.968868: step 69380, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.221 sec/batch; 16h:07m:08s remains)
INFO - root - 2017-12-16 19:00:48.212107: step 69390, loss = 0.49, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 16h:02m:38s remains)
INFO - root - 2017-12-16 19:00:50.417077: step 69400, loss = 0.45, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 15h:58m:30s remains)
INFO - root - 2017-12-16 19:00:52.726376: step 69410, loss = 0.50, batch loss = 0.33 (37.9 examples/sec; 0.211 sec/batch; 15h:25m:58s remains)
INFO - root - 2017-12-16 19:00:54.933201: step 69420, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 16h:21m:17s remains)
INFO - root - 2017-12-16 19:00:57.157301: step 69430, loss = 0.53, batch loss = 0.35 (37.4 examples/sec; 0.214 sec/batch; 15h:38m:31s remains)
INFO - root - 2017-12-16 19:00:59.387730: step 69440, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 16h:22m:15s remains)
INFO - root - 2017-12-16 19:01:01.594940: step 69450, loss = 0.44, batch loss = 0.26 (34.5 examples/sec; 0.232 sec/batch; 16h:57m:46s remains)
INFO - root - 2017-12-16 19:01:03.800704: step 69460, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 16h:40m:13s remains)
INFO - root - 2017-12-16 19:01:06.033960: step 69470, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 15h:51m:12s remains)
INFO - root - 2017-12-16 19:01:08.287248: step 69480, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 16h:40m:10s remains)
INFO - root - 2017-12-16 19:01:10.512047: step 69490, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 15h:51m:14s remains)
INFO - root - 2017-12-16 19:01:12.705186: step 69500, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 15h:49m:08s remains)
INFO - root - 2017-12-16 19:01:15.016431: step 69510, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 16h:00m:08s remains)
INFO - root - 2017-12-16 19:01:17.215343: step 69520, loss = 0.55, batch loss = 0.37 (35.0 examples/sec; 0.229 sec/batch; 16h:42m:25s remains)
INFO - root - 2017-12-16 19:01:19.413706: step 69530, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 16h:04m:40s remains)
INFO - root - 2017-12-16 19:01:21.649469: step 69540, loss = 0.55, batch loss = 0.37 (37.8 examples/sec; 0.212 sec/batch; 15h:28m:37s remains)
INFO - root - 2017-12-16 19:01:23.871998: step 69550, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 16h:10m:52s remains)
INFO - root - 2017-12-16 19:01:26.055770: step 69560, loss = 0.46, batch loss = 0.28 (37.7 examples/sec; 0.212 sec/batch; 15h:30m:48s remains)
INFO - root - 2017-12-16 19:01:28.250777: step 69570, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 15h:56m:41s remains)
INFO - root - 2017-12-16 19:01:30.469608: step 69580, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 16h:13m:15s remains)
INFO - root - 2017-12-16 19:01:32.684095: step 69590, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 16h:04m:38s remains)
INFO - root - 2017-12-16 19:01:34.882695: step 69600, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 15h:38m:26s remains)
INFO - root - 2017-12-16 19:01:37.252569: step 69610, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 16h:02m:35s remains)
INFO - root - 2017-12-16 19:01:39.477196: step 69620, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.215 sec/batch; 15h:43m:37s remains)
INFO - root - 2017-12-16 19:01:41.682978: step 69630, loss = 0.55, batch loss = 0.38 (36.6 examples/sec; 0.218 sec/batch; 15h:57m:12s remains)
INFO - root - 2017-12-16 19:01:43.884828: step 69640, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.214 sec/batch; 15h:35m:26s remains)
INFO - root - 2017-12-16 19:01:46.069597: step 69650, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 16h:02m:57s remains)
INFO - root - 2017-12-16 19:01:48.229995: step 69660, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 16h:08m:53s remains)
INFO - root - 2017-12-16 19:01:50.458862: step 69670, loss = 0.43, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 15h:51m:03s remains)
INFO - root - 2017-12-16 19:01:52.714008: step 69680, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 16h:09m:31s remains)
INFO - root - 2017-12-16 19:01:54.950900: step 69690, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 15h:30m:33s remains)
INFO - root - 2017-12-16 19:01:57.121440: step 69700, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 16h:01m:46s remains)
INFO - root - 2017-12-16 19:01:59.426024: step 69710, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 15h:32m:23s remains)
INFO - root - 2017-12-16 19:02:01.649480: step 69720, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 16h:35m:03s remains)
INFO - root - 2017-12-16 19:02:03.886193: step 69730, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 16h:22m:46s remains)
INFO - root - 2017-12-16 19:02:06.124513: step 69740, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 16h:25m:45s remains)
INFO - root - 2017-12-16 19:02:08.331537: step 69750, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 16h:02m:00s remains)
INFO - root - 2017-12-16 19:02:10.530288: step 69760, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.221 sec/batch; 16h:05m:47s remains)
INFO - root - 2017-12-16 19:02:12.754713: step 69770, loss = 0.55, batch loss = 0.38 (36.3 examples/sec; 0.220 sec/batch; 16h:04m:59s remains)
INFO - root - 2017-12-16 19:02:14.946092: step 69780, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 15h:36m:18s remains)
INFO - root - 2017-12-16 19:02:17.219008: step 69790, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 16h:12m:42s remains)
INFO - root - 2017-12-16 19:02:19.410551: step 69800, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 16h:16m:51s remains)
INFO - root - 2017-12-16 19:02:21.744410: step 69810, loss = 0.49, batch loss = 0.31 (34.2 examples/sec; 0.234 sec/batch; 17h:03m:15s remains)
INFO - root - 2017-12-16 19:02:23.973505: step 69820, loss = 0.44, batch loss = 0.26 (33.4 examples/sec; 0.240 sec/batch; 17h:29m:05s remains)
INFO - root - 2017-12-16 19:02:26.208567: step 69830, loss = 0.55, batch loss = 0.37 (35.2 examples/sec; 0.227 sec/batch; 16h:34m:08s remains)
INFO - root - 2017-12-16 19:02:28.432261: step 69840, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 16h:18m:53s remains)
INFO - root - 2017-12-16 19:02:30.666790: step 69850, loss = 0.57, batch loss = 0.40 (36.5 examples/sec; 0.219 sec/batch; 15h:58m:42s remains)
INFO - root - 2017-12-16 19:02:32.852786: step 69860, loss = 0.43, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 15h:51m:18s remains)
INFO - root - 2017-12-16 19:02:35.063920: step 69870, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 15h:56m:13s remains)
INFO - root - 2017-12-16 19:02:37.254290: step 69880, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 15h:58m:35s remains)
INFO - root - 2017-12-16 19:02:39.438446: step 69890, loss = 0.45, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 15h:45m:21s remains)
INFO - root - 2017-12-16 19:02:41.658964: step 69900, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 15h:52m:23s remains)
INFO - root - 2017-12-16 19:02:44.024440: step 69910, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 16h:13m:26s remains)
INFO - root - 2017-12-16 19:02:46.238744: step 69920, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 15h:45m:23s remains)
INFO - root - 2017-12-16 19:02:48.432189: step 69930, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 16h:30m:03s remains)
INFO - root - 2017-12-16 19:02:50.640446: step 69940, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 16h:09m:34s remains)
INFO - root - 2017-12-16 19:02:52.854477: step 69950, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 16h:38m:07s remains)
INFO - root - 2017-12-16 19:02:55.107294: step 69960, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 15h:57m:02s remains)
INFO - root - 2017-12-16 19:02:57.276608: step 69970, loss = 0.55, batch loss = 0.38 (36.6 examples/sec; 0.219 sec/batch; 15h:56m:20s remains)
INFO - root - 2017-12-16 19:02:59.519516: step 69980, loss = 0.50, batch loss = 0.32 (33.8 examples/sec; 0.236 sec/batch; 17h:14m:23s remains)
INFO - root - 2017-12-16 19:03:01.733720: step 69990, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 15h:52m:28s remains)
INFO - root - 2017-12-16 19:03:03.960003: step 70000, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 15h:25m:38s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-70000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-70000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 19:03:06.942484: step 70010, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 16h:13m:01s remains)
INFO - root - 2017-12-16 19:03:09.165970: step 70020, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 16h:13m:05s remains)
INFO - root - 2017-12-16 19:03:11.368690: step 70030, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 15h:51m:14s remains)
INFO - root - 2017-12-16 19:03:13.613284: step 70040, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 16h:16m:50s remains)
INFO - root - 2017-12-16 19:03:15.795795: step 70050, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 15h:53m:51s remains)
INFO - root - 2017-12-16 19:03:17.992923: step 70060, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 16h:22m:41s remains)
INFO - root - 2017-12-16 19:03:20.215907: step 70070, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 16h:07m:00s remains)
INFO - root - 2017-12-16 19:03:22.435343: step 70080, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 16h:03m:23s remains)
INFO - root - 2017-12-16 19:03:24.655849: step 70090, loss = 0.45, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 16h:04m:14s remains)
INFO - root - 2017-12-16 19:03:26.858700: step 70100, loss = 0.52, batch loss = 0.34 (37.5 examples/sec; 0.213 sec/batch; 15h:32m:02s remains)
INFO - root - 2017-12-16 19:03:29.233130: step 70110, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 15h:37m:00s remains)
INFO - root - 2017-12-16 19:03:31.444816: step 70120, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 16h:13m:43s remains)
INFO - root - 2017-12-16 19:03:33.689918: step 70130, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 15h:52m:24s remains)
INFO - root - 2017-12-16 19:03:35.934941: step 70140, loss = 0.57, batch loss = 0.39 (36.0 examples/sec; 0.222 sec/batch; 16h:11m:42s remains)
INFO - root - 2017-12-16 19:03:38.104935: step 70150, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 15h:48m:36s remains)
INFO - root - 2017-12-16 19:03:40.339504: step 70160, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 16h:09m:00s remains)
INFO - root - 2017-12-16 19:03:42.548044: step 70170, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 15h:52m:53s remains)
INFO - root - 2017-12-16 19:03:44.734125: step 70180, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 15h:50m:52s remains)
INFO - root - 2017-12-16 19:03:46.952497: step 70190, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 16h:10m:17s remains)
INFO - root - 2017-12-16 19:03:49.153444: step 70200, loss = 0.42, batch loss = 0.25 (37.3 examples/sec; 0.215 sec/batch; 15h:38m:18s remains)
INFO - root - 2017-12-16 19:03:51.518369: step 70210, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 15h:46m:43s remains)
INFO - root - 2017-12-16 19:03:53.733122: step 70220, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 15h:59m:22s remains)
INFO - root - 2017-12-16 19:03:55.937736: step 70230, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 16h:36m:11s remains)
INFO - root - 2017-12-16 19:03:58.163965: step 70240, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 16h:21m:45s remains)
INFO - root - 2017-12-16 19:04:00.368238: step 70250, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 16h:25m:19s remains)
INFO - root - 2017-12-16 19:04:02.609722: step 70260, loss = 0.45, batch loss = 0.27 (33.3 examples/sec; 0.240 sec/batch; 17h:28m:54s remains)
INFO - root - 2017-12-16 19:04:04.822110: step 70270, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 15h:57m:21s remains)
INFO - root - 2017-12-16 19:04:07.084110: step 70280, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 16h:06m:33s remains)
INFO - root - 2017-12-16 19:04:09.338595: step 70290, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 15h:53m:11s remains)
INFO - root - 2017-12-16 19:04:11.622403: step 70300, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 16h:10m:09s remains)
INFO - root - 2017-12-16 19:04:13.988672: step 70310, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 16h:22m:30s remains)
INFO - root - 2017-12-16 19:04:16.203707: step 70320, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 15h:25m:10s remains)
INFO - root - 2017-12-16 19:04:18.404490: step 70330, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 16h:09m:45s remains)
INFO - root - 2017-12-16 19:04:20.574476: step 70340, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 16h:06m:12s remains)
INFO - root - 2017-12-16 19:04:22.804264: step 70350, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 15h:57m:30s remains)
INFO - root - 2017-12-16 19:04:25.022377: step 70360, loss = 0.43, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 15h:38m:57s remains)
INFO - root - 2017-12-16 19:04:27.213686: step 70370, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 16h:22m:45s remains)
INFO - root - 2017-12-16 19:04:29.420198: step 70380, loss = 0.50, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 15h:50m:50s remains)
INFO - root - 2017-12-16 19:04:31.663962: step 70390, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 16h:17m:39s remains)
INFO - root - 2017-12-16 19:04:33.873756: step 70400, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 15h:33m:59s remains)
INFO - root - 2017-12-16 19:04:36.202977: step 70410, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 16h:07m:09s remains)
INFO - root - 2017-12-16 19:04:38.410051: step 70420, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 16h:06m:45s remains)
INFO - root - 2017-12-16 19:04:40.604917: step 70430, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 15h:50m:44s remains)
INFO - root - 2017-12-16 19:04:42.794452: step 70440, loss = 0.51, batch loss = 0.33 (37.6 examples/sec; 0.213 sec/batch; 15h:28m:43s remains)
INFO - root - 2017-12-16 19:04:45.036099: step 70450, loss = 0.52, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 15h:48m:35s remains)
INFO - root - 2017-12-16 19:04:47.227888: step 70460, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 16h:02m:32s remains)
INFO - root - 2017-12-16 19:04:49.453712: step 70470, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 15h:57m:11s remains)
INFO - root - 2017-12-16 19:04:51.644548: step 70480, loss = 0.54, batch loss = 0.36 (36.1 examples/sec; 0.221 sec/batch; 16h:06m:58s remains)
INFO - root - 2017-12-16 19:04:53.860437: step 70490, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.233 sec/batch; 16h:55m:24s remains)
INFO - root - 2017-12-16 19:04:56.068294: step 70500, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 15h:57m:54s remains)
INFO - root - 2017-12-16 19:04:58.401544: step 70510, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 15h:45m:35s remains)
INFO - root - 2017-12-16 19:05:00.627681: step 70520, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 16h:20m:45s remains)
INFO - root - 2017-12-16 19:05:02.829871: step 70530, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 15h:37m:08s remains)
INFO - root - 2017-12-16 19:05:05.010023: step 70540, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 15h:46m:45s remains)
INFO - root - 2017-12-16 19:05:07.207261: step 70550, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 16h:12m:53s remains)
INFO - root - 2017-12-16 19:05:09.431250: step 70560, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.215 sec/batch; 15h:37m:28s remains)
INFO - root - 2017-12-16 19:05:11.632294: step 70570, loss = 0.50, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 16h:44m:01s remains)
INFO - root - 2017-12-16 19:05:13.838674: step 70580, loss = 0.57, batch loss = 0.39 (35.8 examples/sec; 0.223 sec/batch; 16h:14m:24s remains)
INFO - root - 2017-12-16 19:05:16.062203: step 70590, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 15h:46m:32s remains)
INFO - root - 2017-12-16 19:05:18.274304: step 70600, loss = 0.48, batch loss = 0.30 (37.8 examples/sec; 0.212 sec/batch; 15h:24m:40s remains)
INFO - root - 2017-12-16 19:05:20.596185: step 70610, loss = 0.47, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 16h:07m:55s remains)
INFO - root - 2017-12-16 19:05:22.794898: step 70620, loss = 0.50, batch loss = 0.32 (37.5 examples/sec; 0.213 sec/batch; 15h:31m:00s remains)
INFO - root - 2017-12-16 19:05:25.035836: step 70630, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 15h:34m:18s remains)
INFO - root - 2017-12-16 19:05:27.238539: step 70640, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 15h:30m:30s remains)
INFO - root - 2017-12-16 19:05:29.465585: step 70650, loss = 0.44, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 16h:04m:41s remains)
INFO - root - 2017-12-16 19:05:31.698765: step 70660, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 16h:14m:51s remains)
INFO - root - 2017-12-16 19:05:33.921487: step 70670, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 16h:25m:44s remains)
INFO - root - 2017-12-16 19:05:36.120599: step 70680, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 16h:08m:46s remains)
INFO - root - 2017-12-16 19:05:38.367881: step 70690, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.218 sec/batch; 15h:49m:49s remains)
INFO - root - 2017-12-16 19:05:40.588439: step 70700, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 15h:41m:35s remains)
INFO - root - 2017-12-16 19:05:42.928159: step 70710, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 15h:57m:58s remains)
INFO - root - 2017-12-16 19:05:45.132284: step 70720, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 15h:32m:20s remains)
INFO - root - 2017-12-16 19:05:47.380585: step 70730, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 15h:58m:55s remains)
INFO - root - 2017-12-16 19:05:49.622072: step 70740, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 16h:09m:09s remains)
INFO - root - 2017-12-16 19:05:51.885775: step 70750, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 15h:52m:30s remains)
INFO - root - 2017-12-16 19:05:54.090991: step 70760, loss = 0.50, batch loss = 0.32 (34.6 examples/sec; 0.231 sec/batch; 16h:47m:53s remains)
INFO - root - 2017-12-16 19:05:56.273621: step 70770, loss = 0.56, batch loss = 0.38 (36.6 examples/sec; 0.219 sec/batch; 15h:54m:00s remains)
INFO - root - 2017-12-16 19:05:58.442857: step 70780, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 15h:40m:31s remains)
INFO - root - 2017-12-16 19:06:00.636512: step 70790, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 15h:47m:29s remains)
INFO - root - 2017-12-16 19:06:02.836757: step 70800, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 15h:50m:02s remains)
INFO - root - 2017-12-16 19:06:05.153901: step 70810, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 16h:21m:24s remains)
INFO - root - 2017-12-16 19:06:07.343584: step 70820, loss = 0.42, batch loss = 0.24 (36.6 examples/sec; 0.218 sec/batch; 15h:52m:30s remains)
INFO - root - 2017-12-16 19:06:09.563579: step 70830, loss = 0.58, batch loss = 0.40 (35.8 examples/sec; 0.224 sec/batch; 16h:15m:11s remains)
INFO - root - 2017-12-16 19:06:11.746624: step 70840, loss = 0.53, batch loss = 0.35 (37.1 examples/sec; 0.215 sec/batch; 15h:39m:29s remains)
INFO - root - 2017-12-16 19:06:13.975132: step 70850, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 16h:16m:59s remains)
INFO - root - 2017-12-16 19:06:16.216650: step 70860, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 16h:32m:44s remains)
INFO - root - 2017-12-16 19:06:18.456504: step 70870, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 15h:49m:42s remains)
INFO - root - 2017-12-16 19:06:20.683098: step 70880, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 16h:08m:25s remains)
INFO - root - 2017-12-16 19:06:22.906533: step 70890, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.230 sec/batch; 16h:43m:52s remains)
INFO - root - 2017-12-16 19:06:25.145057: step 70900, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 16h:17m:02s remains)
INFO - root - 2017-12-16 19:06:27.500598: step 70910, loss = 0.51, batch loss = 0.33 (33.2 examples/sec; 0.241 sec/batch; 17h:31m:28s remains)
INFO - root - 2017-12-16 19:06:29.719647: step 70920, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 15h:46m:38s remains)
INFO - root - 2017-12-16 19:06:31.938524: step 70930, loss = 0.42, batch loss = 0.24 (37.6 examples/sec; 0.213 sec/batch; 15h:27m:32s remains)
INFO - root - 2017-12-16 19:06:34.167101: step 70940, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 16h:03m:45s remains)
INFO - root - 2017-12-16 19:06:36.351450: step 70950, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 15h:41m:07s remains)
INFO - root - 2017-12-16 19:06:38.579685: step 70960, loss = 0.42, batch loss = 0.24 (35.8 examples/sec; 0.223 sec/batch; 16h:12m:51s remains)
INFO - root - 2017-12-16 19:06:40.835771: step 70970, loss = 0.43, batch loss = 0.25 (34.8 examples/sec; 0.230 sec/batch; 16h:43m:17s remains)
INFO - root - 2017-12-16 19:06:43.054233: step 70980, loss = 0.42, batch loss = 0.24 (37.3 examples/sec; 0.214 sec/batch; 15h:34m:37s remains)
INFO - root - 2017-12-16 19:06:45.288574: step 70990, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 16h:09m:24s remains)
INFO - root - 2017-12-16 19:06:47.514472: step 71000, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.226 sec/batch; 16h:26m:48s remains)
INFO - root - 2017-12-16 19:06:49.877425: step 71010, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 15h:52m:45s remains)
INFO - root - 2017-12-16 19:06:52.094792: step 71020, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 16h:14m:57s remains)
INFO - root - 2017-12-16 19:06:54.288758: step 71030, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 15h:56m:58s remains)
INFO - root - 2017-12-16 19:06:56.512507: step 71040, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 15h:21m:50s remains)
INFO - root - 2017-12-16 19:06:58.725847: step 71050, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 16h:10m:19s remains)
INFO - root - 2017-12-16 19:07:00.986857: step 71060, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 16h:32m:17s remains)
INFO - root - 2017-12-16 19:07:03.204042: step 71070, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 15h:53m:16s remains)
INFO - root - 2017-12-16 19:07:05.431470: step 71080, loss = 0.52, batch loss = 0.34 (34.4 examples/sec; 0.233 sec/batch; 16h:54m:06s remains)
INFO - root - 2017-12-16 19:07:07.681600: step 71090, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 16h:20m:06s remains)
INFO - root - 2017-12-16 19:07:09.972456: step 71100, loss = 0.43, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 16h:16m:31s remains)
INFO - root - 2017-12-16 19:07:12.331394: step 71110, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 15h:58m:57s remains)
INFO - root - 2017-12-16 19:07:14.571281: step 71120, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 15h:48m:38s remains)
INFO - root - 2017-12-16 19:07:16.798503: step 71130, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 16h:31m:57s remains)
INFO - root - 2017-12-16 19:07:18.996883: step 71140, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 15h:42m:15s remains)
INFO - root - 2017-12-16 19:07:21.222726: step 71150, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 15h:50m:17s remains)
INFO - root - 2017-12-16 19:07:23.434417: step 71160, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 16h:09m:53s remains)
INFO - root - 2017-12-16 19:07:25.650528: step 71170, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 16h:23m:43s remains)
INFO - root - 2017-12-16 19:07:27.891344: step 71180, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 16h:28m:53s remains)
INFO - root - 2017-12-16 19:07:30.090701: step 71190, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 16h:02m:04s remains)
INFO - root - 2017-12-16 19:07:32.314098: step 71200, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 16h:01m:24s remains)
INFO - root - 2017-12-16 19:07:34.632490: step 71210, loss = 0.43, batch loss = 0.25 (37.6 examples/sec; 0.213 sec/batch; 15h:26m:12s remains)
INFO - root - 2017-12-16 19:07:36.866559: step 71220, loss = 0.52, batch loss = 0.34 (34.9 examples/sec; 0.229 sec/batch; 16h:37m:42s remains)
INFO - root - 2017-12-16 19:07:39.108588: step 71230, loss = 0.51, batch loss = 0.33 (35.2 examples/sec; 0.227 sec/batch; 16h:30m:32s remains)
INFO - root - 2017-12-16 19:07:41.310943: step 71240, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 15h:43m:34s remains)
INFO - root - 2017-12-16 19:07:43.553007: step 71250, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 16h:40m:25s remains)
INFO - root - 2017-12-16 19:07:45.770621: step 71260, loss = 0.44, batch loss = 0.26 (34.3 examples/sec; 0.233 sec/batch; 16h:56m:18s remains)
INFO - root - 2017-12-16 19:07:47.993992: step 71270, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 15h:42m:53s remains)
INFO - root - 2017-12-16 19:07:50.213967: step 71280, loss = 0.52, batch loss = 0.34 (34.1 examples/sec; 0.235 sec/batch; 17h:02m:32s remains)
INFO - root - 2017-12-16 19:07:52.460914: step 71290, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 16h:34m:54s remains)
INFO - root - 2017-12-16 19:07:54.689038: step 71300, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 16h:37m:49s remains)
INFO - root - 2017-12-16 19:07:57.022450: step 71310, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 16h:18m:03s remains)
INFO - root - 2017-12-16 19:07:59.275222: step 71320, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 16h:13m:48s remains)
INFO - root - 2017-12-16 19:08:01.528711: step 71330, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 15h:42m:57s remains)
INFO - root - 2017-12-16 19:08:03.756594: step 71340, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 16h:18m:31s remains)
INFO - root - 2017-12-16 19:08:06.001050: step 71350, loss = 0.51, batch loss = 0.34 (34.4 examples/sec; 0.232 sec/batch; 16h:51m:48s remains)
INFO - root - 2017-12-16 19:08:08.254573: step 71360, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 15h:45m:22s remains)
INFO - root - 2017-12-16 19:08:10.491338: step 71370, loss = 0.55, batch loss = 0.37 (37.1 examples/sec; 0.216 sec/batch; 15h:39m:25s remains)
INFO - root - 2017-12-16 19:08:12.707846: step 71380, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 15h:45m:03s remains)
INFO - root - 2017-12-16 19:08:14.924608: step 71390, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 15h:56m:46s remains)
INFO - root - 2017-12-16 19:08:17.135895: step 71400, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 15h:35m:34s remains)
INFO - root - 2017-12-16 19:08:19.481353: step 71410, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 16h:11m:55s remains)
INFO - root - 2017-12-16 19:08:21.724671: step 71420, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 16h:00m:34s remains)
INFO - root - 2017-12-16 19:08:23.909944: step 71430, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 16h:19m:55s remains)
INFO - root - 2017-12-16 19:08:26.082118: step 71440, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 15h:41m:22s remains)
INFO - root - 2017-12-16 19:08:28.285153: step 71450, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 16h:22m:45s remains)
INFO - root - 2017-12-16 19:08:30.495040: step 71460, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 15h:49m:29s remains)
INFO - root - 2017-12-16 19:08:32.703015: step 71470, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 15h:43m:48s remains)
INFO - root - 2017-12-16 19:08:34.952309: step 71480, loss = 0.43, batch loss = 0.25 (34.9 examples/sec; 0.229 sec/batch; 16h:37m:54s remains)
INFO - root - 2017-12-16 19:08:37.208436: step 71490, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.224 sec/batch; 16h:16m:35s remains)
INFO - root - 2017-12-16 19:08:39.437690: step 71500, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 16h:19m:16s remains)
INFO - root - 2017-12-16 19:08:41.847545: step 71510, loss = 0.49, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 16h:05m:40s remains)
INFO - root - 2017-12-16 19:08:44.100578: step 71520, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 16h:14m:43s remains)
INFO - root - 2017-12-16 19:08:46.324968: step 71530, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 16h:10m:17s remains)
INFO - root - 2017-12-16 19:08:48.586708: step 71540, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 15h:52m:02s remains)
INFO - root - 2017-12-16 19:08:50.781045: step 71550, loss = 0.47, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 15h:35m:22s remains)
INFO - root - 2017-12-16 19:08:53.024817: step 71560, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 16h:06m:36s remains)
INFO - root - 2017-12-16 19:08:55.241475: step 71570, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 15h:40m:33s remains)
INFO - root - 2017-12-16 19:08:57.435452: step 71580, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 16h:01m:17s remains)
INFO - root - 2017-12-16 19:08:59.633870: step 71590, loss = 0.56, batch loss = 0.38 (37.0 examples/sec; 0.216 sec/batch; 15h:41m:08s remains)
INFO - root - 2017-12-16 19:09:01.825979: step 71600, loss = 0.48, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 15h:46m:20s remains)
INFO - root - 2017-12-16 19:09:04.179196: step 71610, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 15h:34m:59s remains)
INFO - root - 2017-12-16 19:09:06.448144: step 71620, loss = 0.42, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 15h:51m:14s remains)
INFO - root - 2017-12-16 19:09:08.690647: step 71630, loss = 0.47, batch loss = 0.29 (33.7 examples/sec; 0.237 sec/batch; 17h:11m:30s remains)
INFO - root - 2017-12-16 19:09:10.922090: step 71640, loss = 0.48, batch loss = 0.30 (33.6 examples/sec; 0.238 sec/batch; 17h:13m:57s remains)
INFO - root - 2017-12-16 19:09:13.199571: step 71650, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 16h:28m:28s remains)
INFO - root - 2017-12-16 19:09:15.437390: step 71660, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 15h:47m:44s remains)
INFO - root - 2017-12-16 19:09:17.624567: step 71670, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 15h:59m:21s remains)
INFO - root - 2017-12-16 19:09:19.855266: step 71680, loss = 0.49, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 16h:31m:22s remains)
INFO - root - 2017-12-16 19:09:22.046823: step 71690, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 16h:16m:58s remains)
INFO - root - 2017-12-16 19:09:24.291722: step 71700, loss = 0.47, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 16h:57m:57s remains)
INFO - root - 2017-12-16 19:09:26.628118: step 71710, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 15h:38m:14s remains)
INFO - root - 2017-12-16 19:09:28.827091: step 71720, loss = 0.54, batch loss = 0.36 (34.9 examples/sec; 0.229 sec/batch; 16h:35m:20s remains)
INFO - root - 2017-12-16 19:09:31.057935: step 71730, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 16h:14m:20s remains)
INFO - root - 2017-12-16 19:09:33.293301: step 71740, loss = 0.45, batch loss = 0.27 (33.8 examples/sec; 0.237 sec/batch; 17h:08m:17s remains)
INFO - root - 2017-12-16 19:09:35.514761: step 71750, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:54m:19s remains)
INFO - root - 2017-12-16 19:09:37.754086: step 71760, loss = 0.52, batch loss = 0.34 (37.5 examples/sec; 0.213 sec/batch; 15h:27m:27s remains)
INFO - root - 2017-12-16 19:09:39.987391: step 71770, loss = 0.53, batch loss = 0.35 (37.4 examples/sec; 0.214 sec/batch; 15h:30m:04s remains)
INFO - root - 2017-12-16 19:09:42.197489: step 71780, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 16h:03m:25s remains)
INFO - root - 2017-12-16 19:09:44.402374: step 71790, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 16h:22m:14s remains)
INFO - root - 2017-12-16 19:09:46.615763: step 71800, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 16h:01m:26s remains)
INFO - root - 2017-12-16 19:09:48.942982: step 71810, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 16h:10m:08s remains)
INFO - root - 2017-12-16 19:09:51.194432: step 71820, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 16h:21m:58s remains)
INFO - root - 2017-12-16 19:09:53.412405: step 71830, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 16h:08m:19s remains)
INFO - root - 2017-12-16 19:09:55.635212: step 71840, loss = 0.48, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 15h:40m:07s remains)
INFO - root - 2017-12-16 19:09:57.836735: step 71850, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 16h:12m:46s remains)
INFO - root - 2017-12-16 19:10:00.060533: step 71860, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 16h:21m:15s remains)
INFO - root - 2017-12-16 19:10:02.294480: step 71870, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 16h:07m:26s remains)
INFO - root - 2017-12-16 19:10:04.510118: step 71880, loss = 0.49, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 16h:03m:25s remains)
INFO - root - 2017-12-16 19:10:06.725228: step 71890, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 16h:06m:18s remains)
INFO - root - 2017-12-16 19:10:08.982964: step 71900, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 16h:17m:37s remains)
INFO - root - 2017-12-16 19:10:11.325377: step 71910, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 16h:01m:11s remains)
INFO - root - 2017-12-16 19:10:13.535422: step 71920, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 15h:56m:13s remains)
INFO - root - 2017-12-16 19:10:15.722166: step 71930, loss = 0.50, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 16h:21m:59s remains)
INFO - root - 2017-12-16 19:10:17.917832: step 71940, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 16h:30m:49s remains)
INFO - root - 2017-12-16 19:10:20.108674: step 71950, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 15h:58m:49s remains)
INFO - root - 2017-12-16 19:10:22.350415: step 71960, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 16h:07m:48s remains)
INFO - root - 2017-12-16 19:10:24.575765: step 71970, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 15h:44m:08s remains)
INFO - root - 2017-12-16 19:10:26.772860: step 71980, loss = 0.54, batch loss = 0.36 (37.0 examples/sec; 0.216 sec/batch; 15h:38m:14s remains)
INFO - root - 2017-12-16 19:10:28.955764: step 71990, loss = 0.48, batch loss = 0.30 (37.9 examples/sec; 0.211 sec/batch; 15h:15m:27s remains)
INFO - root - 2017-12-16 19:10:31.148988: step 72000, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 15h:57m:10s remains)
INFO - root - 2017-12-16 19:10:33.516135: step 72010, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 16h:29m:24s remains)
INFO - root - 2017-12-16 19:10:35.753343: step 72020, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 16h:29m:25s remains)
INFO - root - 2017-12-16 19:10:37.955486: step 72030, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.215 sec/batch; 15h:34m:58s remains)
INFO - root - 2017-12-16 19:10:40.131383: step 72040, loss = 0.48, batch loss = 0.30 (37.8 examples/sec; 0.212 sec/batch; 15h:18m:16s remains)
INFO - root - 2017-12-16 19:10:42.365067: step 72050, loss = 0.51, batch loss = 0.33 (35.1 examples/sec; 0.228 sec/batch; 16h:28m:45s remains)
INFO - root - 2017-12-16 19:10:44.590155: step 72060, loss = 0.42, batch loss = 0.24 (37.5 examples/sec; 0.213 sec/batch; 15h:24m:56s remains)
INFO - root - 2017-12-16 19:10:46.761219: step 72070, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 15h:34m:24s remains)
INFO - root - 2017-12-16 19:10:48.968410: step 72080, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 16h:02m:14s remains)
INFO - root - 2017-12-16 19:10:51.167285: step 72090, loss = 0.51, batch loss = 0.34 (36.3 examples/sec; 0.221 sec/batch; 15h:57m:27s remains)
INFO - root - 2017-12-16 19:10:53.374795: step 72100, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 15h:48m:49s remains)
INFO - root - 2017-12-16 19:10:55.716731: step 72110, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 15h:38m:14s remains)
INFO - root - 2017-12-16 19:10:57.954412: step 72120, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 16h:04m:09s remains)
INFO - root - 2017-12-16 19:11:00.141341: step 72130, loss = 0.54, batch loss = 0.37 (37.0 examples/sec; 0.216 sec/batch; 15h:38m:53s remains)
INFO - root - 2017-12-16 19:11:02.355485: step 72140, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.221 sec/batch; 15h:57m:14s remains)
INFO - root - 2017-12-16 19:11:04.548290: step 72150, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 15h:56m:23s remains)
INFO - root - 2017-12-16 19:11:06.754393: step 72160, loss = 0.42, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 16h:16m:33s remains)
INFO - root - 2017-12-16 19:11:08.983684: step 72170, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 15h:55m:41s remains)
INFO - root - 2017-12-16 19:11:11.199584: step 72180, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 15h:50m:26s remains)
INFO - root - 2017-12-16 19:11:13.422101: step 72190, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 16h:05m:50s remains)
INFO - root - 2017-12-16 19:11:15.641559: step 72200, loss = 0.57, batch loss = 0.39 (35.6 examples/sec; 0.225 sec/batch; 16h:14m:27s remains)
INFO - root - 2017-12-16 19:11:17.969686: step 72210, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 15h:32m:31s remains)
INFO - root - 2017-12-16 19:11:20.174870: step 72220, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 16h:00m:44s remains)
INFO - root - 2017-12-16 19:11:22.397078: step 72230, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 15h:48m:17s remains)
INFO - root - 2017-12-16 19:11:24.657126: step 72240, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 16h:23m:13s remains)
INFO - root - 2017-12-16 19:11:26.856518: step 72250, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 16h:04m:48s remains)
INFO - root - 2017-12-16 19:11:29.039233: step 72260, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 15h:55m:31s remains)
INFO - root - 2017-12-16 19:11:31.262977: step 72270, loss = 0.49, batch loss = 0.31 (37.8 examples/sec; 0.212 sec/batch; 15h:17m:56s remains)
INFO - root - 2017-12-16 19:11:33.461563: step 72280, loss = 0.52, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 16h:28m:16s remains)
INFO - root - 2017-12-16 19:11:35.670422: step 72290, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 16h:33m:50s remains)
INFO - root - 2017-12-16 19:11:37.912423: step 72300, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 16h:33m:19s remains)
INFO - root - 2017-12-16 19:11:40.259831: step 72310, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 15h:32m:29s remains)
INFO - root - 2017-12-16 19:11:42.541851: step 72320, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.223 sec/batch; 16h:08m:42s remains)
INFO - root - 2017-12-16 19:11:44.723418: step 72330, loss = 0.51, batch loss = 0.33 (37.9 examples/sec; 0.211 sec/batch; 15h:16m:25s remains)
INFO - root - 2017-12-16 19:11:46.920470: step 72340, loss = 0.48, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 16h:00m:54s remains)
INFO - root - 2017-12-16 19:11:49.082075: step 72350, loss = 0.42, batch loss = 0.24 (37.0 examples/sec; 0.216 sec/batch; 15h:37m:42s remains)
INFO - root - 2017-12-16 19:11:51.297247: step 72360, loss = 0.43, batch loss = 0.25 (34.5 examples/sec; 0.232 sec/batch; 16h:45m:56s remains)
INFO - root - 2017-12-16 19:11:53.517612: step 72370, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 16h:09m:41s remains)
INFO - root - 2017-12-16 19:11:55.722074: step 72380, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 16h:16m:31s remains)
INFO - root - 2017-12-16 19:11:57.946701: step 72390, loss = 0.51, batch loss = 0.33 (34.2 examples/sec; 0.234 sec/batch; 16h:53m:10s remains)
INFO - root - 2017-12-16 19:12:00.159620: step 72400, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 15h:50m:59s remains)
INFO - root - 2017-12-16 19:12:02.498184: step 72410, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 15h:44m:15s remains)
INFO - root - 2017-12-16 19:12:04.721202: step 72420, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 15h:37m:41s remains)
INFO - root - 2017-12-16 19:12:06.894142: step 72430, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 15h:27m:38s remains)
INFO - root - 2017-12-16 19:12:09.104832: step 72440, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 15h:40m:56s remains)
INFO - root - 2017-12-16 19:12:11.339102: step 72450, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 16h:15m:29s remains)
INFO - root - 2017-12-16 19:12:13.586423: step 72460, loss = 0.44, batch loss = 0.26 (34.7 examples/sec; 0.231 sec/batch; 16h:39m:43s remains)
INFO - root - 2017-12-16 19:12:15.772138: step 72470, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:53m:31s remains)
INFO - root - 2017-12-16 19:12:18.008476: step 72480, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 16h:18m:59s remains)
INFO - root - 2017-12-16 19:12:20.210729: step 72490, loss = 0.52, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 16h:14m:06s remains)
INFO - root - 2017-12-16 19:12:22.429499: step 72500, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 15h:54m:51s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-72500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-72500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 19:12:25.207680: step 72510, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 15h:59m:36s remains)
INFO - root - 2017-12-16 19:12:27.449434: step 72520, loss = 0.45, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 16h:39m:27s remains)
INFO - root - 2017-12-16 19:12:29.681314: step 72530, loss = 0.43, batch loss = 0.25 (37.3 examples/sec; 0.215 sec/batch; 15h:30m:27s remains)
INFO - root - 2017-12-16 19:12:31.888621: step 72540, loss = 0.63, batch loss = 0.45 (36.8 examples/sec; 0.218 sec/batch; 15h:42m:31s remains)
INFO - root - 2017-12-16 19:12:34.113841: step 72550, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 15h:45m:11s remains)
INFO - root - 2017-12-16 19:12:36.324234: step 72560, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 15h:41m:52s remains)
INFO - root - 2017-12-16 19:12:38.558755: step 72570, loss = 0.59, batch loss = 0.41 (35.0 examples/sec; 0.228 sec/batch; 16h:29m:43s remains)
INFO - root - 2017-12-16 19:12:40.734407: step 72580, loss = 0.56, batch loss = 0.38 (37.5 examples/sec; 0.213 sec/batch; 15h:23m:12s remains)
INFO - root - 2017-12-16 19:12:42.919279: step 72590, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 15h:45m:42s remains)
INFO - root - 2017-12-16 19:12:45.147559: step 72600, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 16h:04m:11s remains)
INFO - root - 2017-12-16 19:12:47.498597: step 72610, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 16h:07m:45s remains)
INFO - root - 2017-12-16 19:12:49.716196: step 72620, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 15h:41m:39s remains)
INFO - root - 2017-12-16 19:12:51.968465: step 72630, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 15h:53m:51s remains)
INFO - root - 2017-12-16 19:12:54.142013: step 72640, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 15h:41m:39s remains)
INFO - root - 2017-12-16 19:12:56.331011: step 72650, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 15h:50m:41s remains)
INFO - root - 2017-12-16 19:12:58.560665: step 72660, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 15h:37m:24s remains)
INFO - root - 2017-12-16 19:13:00.778438: step 72670, loss = 0.49, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 16h:03m:30s remains)
INFO - root - 2017-12-16 19:13:02.960024: step 72680, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 16h:03m:20s remains)
INFO - root - 2017-12-16 19:13:05.183786: step 72690, loss = 0.42, batch loss = 0.24 (33.0 examples/sec; 0.242 sec/batch; 17h:29m:55s remains)
INFO - root - 2017-12-16 19:13:07.393045: step 72700, loss = 0.58, batch loss = 0.41 (37.3 examples/sec; 0.214 sec/batch; 15h:28m:14s remains)
INFO - root - 2017-12-16 19:13:09.770221: step 72710, loss = 0.49, batch loss = 0.31 (34.0 examples/sec; 0.235 sec/batch; 16h:59m:07s remains)
INFO - root - 2017-12-16 19:13:11.965502: step 72720, loss = 0.54, batch loss = 0.36 (36.8 examples/sec; 0.218 sec/batch; 15h:41m:57s remains)
INFO - root - 2017-12-16 19:13:14.204528: step 72730, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 16h:00m:15s remains)
INFO - root - 2017-12-16 19:13:16.438833: step 72740, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 15h:45m:59s remains)
INFO - root - 2017-12-16 19:13:18.623949: step 72750, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 15h:17m:01s remains)
INFO - root - 2017-12-16 19:13:20.853897: step 72760, loss = 0.45, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 16h:33m:03s remains)
INFO - root - 2017-12-16 19:13:23.066831: step 72770, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 16h:02m:29s remains)
INFO - root - 2017-12-16 19:13:25.254445: step 72780, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 15h:29m:53s remains)
INFO - root - 2017-12-16 19:13:27.507433: step 72790, loss = 0.57, batch loss = 0.39 (35.3 examples/sec; 0.226 sec/batch; 16h:19m:35s remains)
INFO - root - 2017-12-16 19:13:29.711092: step 72800, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 16h:41m:38s remains)
INFO - root - 2017-12-16 19:13:32.037072: step 72810, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 15h:35m:27s remains)
INFO - root - 2017-12-16 19:13:34.257857: step 72820, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 16h:19m:40s remains)
INFO - root - 2017-12-16 19:13:36.524650: step 72830, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 16h:08m:02s remains)
INFO - root - 2017-12-16 19:13:38.744368: step 72840, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 15h:38m:57s remains)
INFO - root - 2017-12-16 19:13:40.973642: step 72850, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 16h:10m:19s remains)
INFO - root - 2017-12-16 19:13:43.185130: step 72860, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 15h:41m:48s remains)
INFO - root - 2017-12-16 19:13:45.393443: step 72870, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 16h:08m:56s remains)
INFO - root - 2017-12-16 19:13:47.604881: step 72880, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 15h:39m:50s remains)
INFO - root - 2017-12-16 19:13:49.796616: step 72890, loss = 0.53, batch loss = 0.35 (37.1 examples/sec; 0.216 sec/batch; 15h:34m:05s remains)
INFO - root - 2017-12-16 19:13:51.982277: step 72900, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 16h:18m:43s remains)
INFO - root - 2017-12-16 19:13:54.346787: step 72910, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 15h:40m:49s remains)
INFO - root - 2017-12-16 19:13:56.558061: step 72920, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 15h:55m:56s remains)
INFO - root - 2017-12-16 19:13:58.790595: step 72930, loss = 0.51, batch loss = 0.34 (37.5 examples/sec; 0.213 sec/batch; 15h:21m:56s remains)
INFO - root - 2017-12-16 19:14:00.992048: step 72940, loss = 0.46, batch loss = 0.28 (34.4 examples/sec; 0.233 sec/batch; 16h:46m:03s remains)
INFO - root - 2017-12-16 19:14:03.221349: step 72950, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 15h:33m:34s remains)
INFO - root - 2017-12-16 19:14:05.490945: step 72960, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 16h:23m:24s remains)
INFO - root - 2017-12-16 19:14:07.699384: step 72970, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 16h:08m:42s remains)
INFO - root - 2017-12-16 19:14:09.878821: step 72980, loss = 0.57, batch loss = 0.39 (36.9 examples/sec; 0.217 sec/batch; 15h:38m:36s remains)
INFO - root - 2017-12-16 19:14:12.082539: step 72990, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 15h:49m:44s remains)
INFO - root - 2017-12-16 19:14:14.253647: step 73000, loss = 0.52, batch loss = 0.34 (38.7 examples/sec; 0.207 sec/batch; 14h:54m:01s remains)
INFO - root - 2017-12-16 19:14:16.584854: step 73010, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 15h:47m:08s remains)
INFO - root - 2017-12-16 19:14:18.842503: step 73020, loss = 0.48, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 16h:01m:18s remains)
INFO - root - 2017-12-16 19:14:21.044109: step 73030, loss = 0.45, batch loss = 0.27 (37.6 examples/sec; 0.213 sec/batch; 15h:19m:48s remains)
INFO - root - 2017-12-16 19:14:23.266960: step 73040, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 15h:40m:10s remains)
INFO - root - 2017-12-16 19:14:25.485694: step 73050, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 16h:23m:05s remains)
INFO - root - 2017-12-16 19:14:27.679529: step 73060, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 15h:32m:33s remains)
INFO - root - 2017-12-16 19:14:29.886960: step 73070, loss = 0.55, batch loss = 0.37 (35.3 examples/sec; 0.227 sec/batch; 16h:20m:48s remains)
INFO - root - 2017-12-16 19:14:32.093139: step 73080, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 16h:19m:56s remains)
INFO - root - 2017-12-16 19:14:34.329804: step 73090, loss = 0.55, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 15h:54m:36s remains)
INFO - root - 2017-12-16 19:14:36.539948: step 73100, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 15h:58m:36s remains)
INFO - root - 2017-12-16 19:14:38.896423: step 73110, loss = 0.43, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 15h:53m:44s remains)
INFO - root - 2017-12-16 19:14:41.091388: step 73120, loss = 0.48, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 15h:41m:24s remains)
INFO - root - 2017-12-16 19:14:43.311105: step 73130, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.226 sec/batch; 16h:14m:58s remains)
INFO - root - 2017-12-16 19:14:45.498387: step 73140, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 16h:11m:33s remains)
INFO - root - 2017-12-16 19:14:47.749768: step 73150, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.230 sec/batch; 16h:32m:05s remains)
INFO - root - 2017-12-16 19:14:49.960524: step 73160, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 16h:16m:12s remains)
INFO - root - 2017-12-16 19:14:52.225120: step 73170, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 16h:06m:44s remains)
INFO - root - 2017-12-16 19:14:54.470559: step 73180, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 15h:49m:34s remains)
INFO - root - 2017-12-16 19:14:56.710137: step 73190, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 16h:25m:31s remains)
INFO - root - 2017-12-16 19:14:58.913394: step 73200, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 16h:08m:20s remains)
INFO - root - 2017-12-16 19:15:01.267559: step 73210, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 15h:58m:51s remains)
INFO - root - 2017-12-16 19:15:03.515887: step 73220, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 15h:39m:38s remains)
INFO - root - 2017-12-16 19:15:05.731915: step 73230, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.215 sec/batch; 15h:30m:37s remains)
INFO - root - 2017-12-16 19:15:07.967134: step 73240, loss = 0.47, batch loss = 0.29 (34.3 examples/sec; 0.233 sec/batch; 16h:48m:01s remains)
INFO - root - 2017-12-16 19:15:10.190347: step 73250, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 16h:08m:52s remains)
INFO - root - 2017-12-16 19:15:12.431527: step 73260, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 16h:13m:09s remains)
INFO - root - 2017-12-16 19:15:14.640485: step 73270, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 15h:56m:38s remains)
INFO - root - 2017-12-16 19:15:16.878785: step 73280, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 15h:43m:18s remains)
INFO - root - 2017-12-16 19:15:19.088038: step 73290, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 15h:54m:19s remains)
INFO - root - 2017-12-16 19:15:21.312544: step 73300, loss = 0.47, batch loss = 0.29 (34.3 examples/sec; 0.234 sec/batch; 16h:48m:44s remains)
INFO - root - 2017-12-16 19:15:23.657816: step 73310, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 15h:46m:48s remains)
INFO - root - 2017-12-16 19:15:25.870666: step 73320, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 15h:58m:57s remains)
INFO - root - 2017-12-16 19:15:28.105985: step 73330, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 16h:14m:20s remains)
INFO - root - 2017-12-16 19:15:30.281494: step 73340, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 15h:52m:50s remains)
INFO - root - 2017-12-16 19:15:32.528578: step 73350, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.230 sec/batch; 16h:34m:50s remains)
INFO - root - 2017-12-16 19:15:34.760640: step 73360, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 16h:07m:22s remains)
INFO - root - 2017-12-16 19:15:36.958386: step 73370, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 15h:49m:47s remains)
INFO - root - 2017-12-16 19:15:39.171942: step 73380, loss = 0.55, batch loss = 0.37 (36.1 examples/sec; 0.221 sec/batch; 15h:56m:34s remains)
INFO - root - 2017-12-16 19:15:41.377757: step 73390, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 15h:31m:15s remains)
INFO - root - 2017-12-16 19:15:43.587902: step 73400, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 15h:48m:36s remains)
INFO - root - 2017-12-16 19:15:45.939379: step 73410, loss = 0.56, batch loss = 0.38 (36.3 examples/sec; 0.220 sec/batch; 15h:51m:01s remains)
INFO - root - 2017-12-16 19:15:48.165076: step 73420, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 15h:36m:46s remains)
INFO - root - 2017-12-16 19:15:50.391702: step 73430, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 16h:06m:04s remains)
INFO - root - 2017-12-16 19:15:52.622858: step 73440, loss = 0.45, batch loss = 0.28 (33.7 examples/sec; 0.237 sec/batch; 17h:05m:22s remains)
INFO - root - 2017-12-16 19:15:54.855929: step 73450, loss = 0.53, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 16h:09m:39s remains)
INFO - root - 2017-12-16 19:15:57.078161: step 73460, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 15h:37m:59s remains)
INFO - root - 2017-12-16 19:15:59.278282: step 73470, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 16h:33m:05s remains)
INFO - root - 2017-12-16 19:16:01.477504: step 73480, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 15h:43m:43s remains)
INFO - root - 2017-12-16 19:16:03.705831: step 73490, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 15h:41m:07s remains)
INFO - root - 2017-12-16 19:16:05.925616: step 73500, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:49m:37s remains)
INFO - root - 2017-12-16 19:16:08.286922: step 73510, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 15h:45m:15s remains)
INFO - root - 2017-12-16 19:16:10.536228: step 73520, loss = 0.56, batch loss = 0.38 (37.0 examples/sec; 0.216 sec/batch; 15h:34m:25s remains)
INFO - root - 2017-12-16 19:16:12.783654: step 73530, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 16h:03m:04s remains)
INFO - root - 2017-12-16 19:16:14.991527: step 73540, loss = 0.63, batch loss = 0.45 (36.1 examples/sec; 0.222 sec/batch; 15h:56m:12s remains)
INFO - root - 2017-12-16 19:16:17.220387: step 73550, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 15h:22m:49s remains)
INFO - root - 2017-12-16 19:16:19.451015: step 73560, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 16h:06m:32s remains)
INFO - root - 2017-12-16 19:16:21.691425: step 73570, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 15h:27m:57s remains)
INFO - root - 2017-12-16 19:16:23.917384: step 73580, loss = 0.49, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 16h:10m:42s remains)
INFO - root - 2017-12-16 19:16:26.150422: step 73590, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 15h:41m:22s remains)
INFO - root - 2017-12-16 19:16:28.376634: step 73600, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.216 sec/batch; 15h:31m:26s remains)
INFO - root - 2017-12-16 19:16:30.748704: step 73610, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 15h:56m:31s remains)
INFO - root - 2017-12-16 19:16:32.945178: step 73620, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 15h:26m:20s remains)
INFO - root - 2017-12-16 19:16:35.137263: step 73630, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 15h:57m:18s remains)
INFO - root - 2017-12-16 19:16:37.388633: step 73640, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 16h:17m:23s remains)
INFO - root - 2017-12-16 19:16:39.623318: step 73650, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 15h:45m:41s remains)
INFO - root - 2017-12-16 19:16:41.830607: step 73660, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 15h:54m:11s remains)
INFO - root - 2017-12-16 19:16:44.020549: step 73670, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 16h:02m:44s remains)
INFO - root - 2017-12-16 19:16:46.231825: step 73680, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.233 sec/batch; 16h:42m:56s remains)
INFO - root - 2017-12-16 19:16:48.443814: step 73690, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 15h:40m:23s remains)
INFO - root - 2017-12-16 19:16:50.648314: step 73700, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 16h:14m:59s remains)
INFO - root - 2017-12-16 19:16:53.043381: step 73710, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 15h:49m:59s remains)
INFO - root - 2017-12-16 19:16:55.296103: step 73720, loss = 0.50, batch loss = 0.32 (37.6 examples/sec; 0.213 sec/batch; 15h:16m:58s remains)
INFO - root - 2017-12-16 19:16:57.550910: step 73730, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 16h:12m:58s remains)
INFO - root - 2017-12-16 19:16:59.776120: step 73740, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 16h:21m:00s remains)
INFO - root - 2017-12-16 19:17:01.980844: step 73750, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 16h:01m:04s remains)
INFO - root - 2017-12-16 19:17:04.160009: step 73760, loss = 0.43, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 15h:34m:40s remains)
INFO - root - 2017-12-16 19:17:06.394550: step 73770, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 15h:41m:45s remains)
INFO - root - 2017-12-16 19:17:08.627130: step 73780, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 16h:03m:55s remains)
INFO - root - 2017-12-16 19:17:10.861511: step 73790, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 16h:08m:18s remains)
INFO - root - 2017-12-16 19:17:13.077999: step 73800, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 16h:08m:11s remains)
INFO - root - 2017-12-16 19:17:15.449954: step 73810, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 16h:28m:55s remains)
INFO - root - 2017-12-16 19:17:17.651908: step 73820, loss = 0.41, batch loss = 0.23 (37.9 examples/sec; 0.211 sec/batch; 15h:10m:18s remains)
INFO - root - 2017-12-16 19:17:19.843445: step 73830, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 15h:28m:17s remains)
INFO - root - 2017-12-16 19:17:22.089061: step 73840, loss = 0.45, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 15h:58m:57s remains)
INFO - root - 2017-12-16 19:17:24.335095: step 73850, loss = 0.51, batch loss = 0.34 (33.7 examples/sec; 0.237 sec/batch; 17h:03m:00s remains)
INFO - root - 2017-12-16 19:17:26.563909: step 73860, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 15h:44m:48s remains)
INFO - root - 2017-12-16 19:17:28.799420: step 73870, loss = 0.43, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 16h:05m:47s remains)
INFO - root - 2017-12-16 19:17:31.057366: step 73880, loss = 0.47, batch loss = 0.29 (33.6 examples/sec; 0.238 sec/batch; 17h:07m:45s remains)
INFO - root - 2017-12-16 19:17:33.253353: step 73890, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 15h:27m:30s remains)
INFO - root - 2017-12-16 19:17:35.484133: step 73900, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 16h:31m:51s remains)
INFO - root - 2017-12-16 19:17:37.824625: step 73910, loss = 0.55, batch loss = 0.37 (35.7 examples/sec; 0.224 sec/batch; 16h:06m:37s remains)
INFO - root - 2017-12-16 19:17:40.062472: step 73920, loss = 0.48, batch loss = 0.31 (34.2 examples/sec; 0.234 sec/batch; 16h:48m:24s remains)
INFO - root - 2017-12-16 19:17:42.290896: step 73930, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 16h:01m:10s remains)
INFO - root - 2017-12-16 19:17:44.496104: step 73940, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 15h:31m:32s remains)
INFO - root - 2017-12-16 19:17:46.680626: step 73950, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 15h:31m:53s remains)
INFO - root - 2017-12-16 19:17:48.908216: step 73960, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 16h:13m:16s remains)
INFO - root - 2017-12-16 19:17:51.130029: step 73970, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 16h:07m:41s remains)
INFO - root - 2017-12-16 19:17:53.346579: step 73980, loss = 0.43, batch loss = 0.25 (37.3 examples/sec; 0.214 sec/batch; 15h:23m:12s remains)
INFO - root - 2017-12-16 19:17:55.562880: step 73990, loss = 0.45, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 16h:00m:09s remains)
INFO - root - 2017-12-16 19:17:57.783636: step 74000, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 15h:38m:15s remains)
INFO - root - 2017-12-16 19:18:00.143667: step 74010, loss = 0.46, batch loss = 0.28 (34.5 examples/sec; 0.232 sec/batch; 16h:39m:32s remains)
INFO - root - 2017-12-16 19:18:02.375990: step 74020, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.221 sec/batch; 15h:53m:38s remains)
INFO - root - 2017-12-16 19:18:04.561258: step 74030, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 15h:38m:06s remains)
INFO - root - 2017-12-16 19:18:06.788211: step 74040, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 16h:07m:12s remains)
INFO - root - 2017-12-16 19:18:09.054561: step 74050, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 15h:47m:45s remains)
INFO - root - 2017-12-16 19:18:11.272545: step 74060, loss = 0.43, batch loss = 0.26 (37.1 examples/sec; 0.215 sec/batch; 15h:27m:57s remains)
INFO - root - 2017-12-16 19:18:13.464891: step 74070, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 15h:50m:14s remains)
INFO - root - 2017-12-16 19:18:15.699152: step 74080, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 16h:12m:52s remains)
INFO - root - 2017-12-16 19:18:17.885767: step 74090, loss = 0.50, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 15h:31m:03s remains)
INFO - root - 2017-12-16 19:18:20.079391: step 74100, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 15h:32m:14s remains)
INFO - root - 2017-12-16 19:18:22.418133: step 74110, loss = 0.42, batch loss = 0.24 (35.5 examples/sec; 0.225 sec/batch; 16h:10m:50s remains)
INFO - root - 2017-12-16 19:18:24.634851: step 74120, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 15h:35m:08s remains)
INFO - root - 2017-12-16 19:18:26.842090: step 74130, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 16h:04m:41s remains)
INFO - root - 2017-12-16 19:18:29.080867: step 74140, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 15h:35m:54s remains)
INFO - root - 2017-12-16 19:18:31.283537: step 74150, loss = 0.43, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 15h:28m:31s remains)
INFO - root - 2017-12-16 19:18:33.506447: step 74160, loss = 0.51, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 15h:29m:47s remains)
INFO - root - 2017-12-16 19:18:35.734543: step 74170, loss = 0.49, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 15h:30m:41s remains)
INFO - root - 2017-12-16 19:18:37.938607: step 74180, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 15h:52m:26s remains)
INFO - root - 2017-12-16 19:18:40.155768: step 74190, loss = 0.56, batch loss = 0.38 (36.0 examples/sec; 0.222 sec/batch; 15h:56m:54s remains)
INFO - root - 2017-12-16 19:18:42.392200: step 74200, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 16h:16m:42s remains)
INFO - root - 2017-12-16 19:18:44.734492: step 74210, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 15h:58m:09s remains)
INFO - root - 2017-12-16 19:18:46.959445: step 74220, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 15h:34m:07s remains)
INFO - root - 2017-12-16 19:18:49.176233: step 74230, loss = 0.58, batch loss = 0.40 (36.8 examples/sec; 0.218 sec/batch; 15h:36m:59s remains)
INFO - root - 2017-12-16 19:18:51.410892: step 74240, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 15h:33m:29s remains)
INFO - root - 2017-12-16 19:18:53.655934: step 74250, loss = 0.54, batch loss = 0.36 (35.5 examples/sec; 0.225 sec/batch; 16h:09m:59s remains)
INFO - root - 2017-12-16 19:18:55.878323: step 74260, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 15h:29m:50s remains)
INFO - root - 2017-12-16 19:18:58.077497: step 74270, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 16h:12m:03s remains)
INFO - root - 2017-12-16 19:19:00.284377: step 74280, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 15h:57m:12s remains)
INFO - root - 2017-12-16 19:19:02.477254: step 74290, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 15h:57m:13s remains)
INFO - root - 2017-12-16 19:19:04.709426: step 74300, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 16h:21m:07s remains)
INFO - root - 2017-12-16 19:19:07.103815: step 74310, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 15h:41m:42s remains)
INFO - root - 2017-12-16 19:19:09.281719: step 74320, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 15h:39m:15s remains)
INFO - root - 2017-12-16 19:19:11.487382: step 74330, loss = 0.53, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 16h:07m:10s remains)
INFO - root - 2017-12-16 19:19:13.692617: step 74340, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 16h:20m:39s remains)
INFO - root - 2017-12-16 19:19:15.906100: step 74350, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 16h:00m:52s remains)
INFO - root - 2017-12-16 19:19:18.109638: step 74360, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 15h:55m:57s remains)
INFO - root - 2017-12-16 19:19:20.336531: step 74370, loss = 0.56, batch loss = 0.38 (35.0 examples/sec; 0.229 sec/batch; 16h:24m:38s remains)
INFO - root - 2017-12-16 19:19:22.555318: step 74380, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 15h:51m:59s remains)
INFO - root - 2017-12-16 19:19:24.790679: step 74390, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 15h:46m:52s remains)
INFO - root - 2017-12-16 19:19:26.964780: step 74400, loss = 0.51, batch loss = 0.33 (38.3 examples/sec; 0.209 sec/batch; 14h:58m:15s remains)
INFO - root - 2017-12-16 19:19:29.352690: step 74410, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 15h:42m:18s remains)
INFO - root - 2017-12-16 19:19:31.554616: step 74420, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 16h:10m:29s remains)
INFO - root - 2017-12-16 19:19:33.756745: step 74430, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 15h:14m:39s remains)
INFO - root - 2017-12-16 19:19:35.984143: step 74440, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.229 sec/batch; 16h:23m:00s remains)
INFO - root - 2017-12-16 19:19:38.205078: step 74450, loss = 0.48, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 16h:07m:14s remains)
INFO - root - 2017-12-16 19:19:40.407923: step 74460, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 15h:37m:11s remains)
INFO - root - 2017-12-16 19:19:42.647184: step 74470, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 15h:49m:52s remains)
INFO - root - 2017-12-16 19:19:44.848997: step 74480, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 15h:11m:51s remains)
INFO - root - 2017-12-16 19:19:47.104939: step 74490, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 16h:16m:02s remains)
INFO - root - 2017-12-16 19:19:49.287138: step 74500, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.223 sec/batch; 15h:56m:45s remains)
INFO - root - 2017-12-16 19:19:51.611577: step 74510, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:43m:52s remains)
INFO - root - 2017-12-16 19:19:53.810708: step 74520, loss = 0.46, batch loss = 0.28 (33.3 examples/sec; 0.240 sec/batch; 17h:12m:51s remains)
INFO - root - 2017-12-16 19:19:56.025995: step 74530, loss = 0.45, batch loss = 0.28 (34.5 examples/sec; 0.232 sec/batch; 16h:35m:33s remains)
INFO - root - 2017-12-16 19:19:58.237798: step 74540, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 15h:20m:01s remains)
INFO - root - 2017-12-16 19:20:00.458927: step 74550, loss = 0.51, batch loss = 0.33 (35.1 examples/sec; 0.228 sec/batch; 16h:19m:08s remains)
INFO - root - 2017-12-16 19:20:02.698332: step 74560, loss = 0.54, batch loss = 0.36 (37.0 examples/sec; 0.216 sec/batch; 15h:29m:10s remains)
INFO - root - 2017-12-16 19:20:04.930985: step 74570, loss = 0.51, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 15h:32m:29s remains)
INFO - root - 2017-12-16 19:20:07.143284: step 74580, loss = 0.42, batch loss = 0.24 (36.1 examples/sec; 0.221 sec/batch; 15h:51m:56s remains)
INFO - root - 2017-12-16 19:20:09.363364: step 74590, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 15h:37m:49s remains)
INFO - root - 2017-12-16 19:20:11.605088: step 74600, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 15h:28m:23s remains)
INFO - root - 2017-12-16 19:20:13.937042: step 74610, loss = 0.44, batch loss = 0.26 (37.8 examples/sec; 0.212 sec/batch; 15h:09m:42s remains)
INFO - root - 2017-12-16 19:20:16.154382: step 74620, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 15h:30m:40s remains)
INFO - root - 2017-12-16 19:20:18.378605: step 74630, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 16h:15m:31s remains)
INFO - root - 2017-12-16 19:20:20.576230: step 74640, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 15h:28m:06s remains)
INFO - root - 2017-12-16 19:20:22.816030: step 74650, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 15h:46m:55s remains)
INFO - root - 2017-12-16 19:20:25.012261: step 74660, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 15h:10m:39s remains)
INFO - root - 2017-12-16 19:20:27.229438: step 74670, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 15h:28m:43s remains)
INFO - root - 2017-12-16 19:20:29.480451: step 74680, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 15h:12m:30s remains)
INFO - root - 2017-12-16 19:20:31.701335: step 74690, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 15h:34m:03s remains)
INFO - root - 2017-12-16 19:20:33.857097: step 74700, loss = 0.50, batch loss = 0.32 (38.0 examples/sec; 0.211 sec/batch; 15h:05m:12s remains)
INFO - root - 2017-12-16 19:20:36.244948: step 74710, loss = 0.47, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 16h:43m:51s remains)
INFO - root - 2017-12-16 19:20:38.442121: step 74720, loss = 0.45, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 16h:25m:12s remains)
INFO - root - 2017-12-16 19:20:40.681746: step 74730, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 15h:38m:36s remains)
INFO - root - 2017-12-16 19:20:42.932193: step 74740, loss = 0.55, batch loss = 0.37 (36.1 examples/sec; 0.222 sec/batch; 15h:52m:43s remains)
INFO - root - 2017-12-16 19:20:45.132982: step 74750, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 15h:30m:32s remains)
INFO - root - 2017-12-16 19:20:47.330167: step 74760, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 15h:39m:13s remains)
INFO - root - 2017-12-16 19:20:49.569082: step 74770, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 15h:41m:47s remains)
INFO - root - 2017-12-16 19:20:51.785698: step 74780, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 15h:41m:32s remains)
INFO - root - 2017-12-16 19:20:54.057412: step 74790, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 16h:06m:18s remains)
INFO - root - 2017-12-16 19:20:56.283941: step 74800, loss = 0.45, batch loss = 0.28 (34.4 examples/sec; 0.232 sec/batch; 16h:37m:33s remains)
INFO - root - 2017-12-16 19:20:58.627634: step 74810, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 15h:32m:41s remains)
INFO - root - 2017-12-16 19:21:00.841332: step 74820, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.218 sec/batch; 15h:37m:31s remains)
INFO - root - 2017-12-16 19:21:03.041328: step 74830, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 15h:36m:34s remains)
INFO - root - 2017-12-16 19:21:05.252809: step 74840, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 15h:30m:10s remains)
INFO - root - 2017-12-16 19:21:07.471137: step 74850, loss = 0.46, batch loss = 0.28 (34.5 examples/sec; 0.232 sec/batch; 16h:34m:19s remains)
INFO - root - 2017-12-16 19:21:09.677462: step 74860, loss = 0.43, batch loss = 0.25 (35.1 examples/sec; 0.228 sec/batch; 16h:17m:44s remains)
INFO - root - 2017-12-16 19:21:11.914912: step 74870, loss = 0.48, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 15h:49m:47s remains)
INFO - root - 2017-12-16 19:21:14.154524: step 74880, loss = 0.51, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 15h:52m:19s remains)
INFO - root - 2017-12-16 19:21:16.409452: step 74890, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 15h:50m:10s remains)
INFO - root - 2017-12-16 19:21:18.626877: step 74900, loss = 0.48, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 15h:51m:19s remains)
INFO - root - 2017-12-16 19:21:21.009651: step 74910, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 16h:06m:33s remains)
INFO - root - 2017-12-16 19:21:23.248367: step 74920, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 15h:39m:16s remains)
INFO - root - 2017-12-16 19:21:25.468084: step 74930, loss = 0.47, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 15h:38m:47s remains)
INFO - root - 2017-12-16 19:21:27.668613: step 74940, loss = 0.44, batch loss = 0.26 (35.0 examples/sec; 0.229 sec/batch; 16h:21m:11s remains)
INFO - root - 2017-12-16 19:21:29.891606: step 74950, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 15h:40m:46s remains)
INFO - root - 2017-12-16 19:21:32.075091: step 74960, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:44m:33s remains)
INFO - root - 2017-12-16 19:21:34.285412: step 74970, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 15h:54m:22s remains)
INFO - root - 2017-12-16 19:21:36.505347: step 74980, loss = 0.43, batch loss = 0.25 (35.0 examples/sec; 0.228 sec/batch; 16h:19m:51s remains)
INFO - root - 2017-12-16 19:21:38.719760: step 74990, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.218 sec/batch; 15h:37m:25s remains)
INFO - root - 2017-12-16 19:21:40.952406: step 75000, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 16h:02m:46s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-75000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-75000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 19:21:43.926716: step 75010, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 15h:47m:03s remains)
INFO - root - 2017-12-16 19:21:46.153123: step 75020, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.223 sec/batch; 15h:54m:56s remains)
INFO - root - 2017-12-16 19:21:48.360453: step 75030, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.215 sec/batch; 15h:20m:47s remains)
INFO - root - 2017-12-16 19:21:50.566664: step 75040, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 15h:20m:10s remains)
INFO - root - 2017-12-16 19:21:52.796303: step 75050, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 16h:03m:48s remains)
INFO - root - 2017-12-16 19:21:55.038338: step 75060, loss = 0.50, batch loss = 0.32 (33.9 examples/sec; 0.236 sec/batch; 16h:52m:29s remains)
INFO - root - 2017-12-16 19:21:57.224825: step 75070, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 15h:43m:13s remains)
INFO - root - 2017-12-16 19:21:59.407900: step 75080, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 16h:07m:26s remains)
INFO - root - 2017-12-16 19:22:01.633011: step 75090, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 16h:06m:49s remains)
INFO - root - 2017-12-16 19:22:03.801963: step 75100, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 15h:55m:37s remains)
INFO - root - 2017-12-16 19:22:06.154281: step 75110, loss = 0.57, batch loss = 0.39 (37.3 examples/sec; 0.214 sec/batch; 15h:18m:57s remains)
INFO - root - 2017-12-16 19:22:08.363575: step 75120, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 15h:40m:02s remains)
INFO - root - 2017-12-16 19:22:10.595589: step 75130, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 16h:06m:25s remains)
INFO - root - 2017-12-16 19:22:12.813190: step 75140, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 16h:14m:55s remains)
INFO - root - 2017-12-16 19:22:15.004166: step 75150, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 15h:34m:50s remains)
INFO - root - 2017-12-16 19:22:17.176715: step 75160, loss = 0.42, batch loss = 0.24 (37.5 examples/sec; 0.213 sec/batch; 15h:15m:28s remains)
INFO - root - 2017-12-16 19:22:19.362472: step 75170, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 15h:31m:55s remains)
INFO - root - 2017-12-16 19:22:21.581423: step 75180, loss = 0.46, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 16h:06m:34s remains)
INFO - root - 2017-12-16 19:22:23.793692: step 75190, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 16h:09m:52s remains)
INFO - root - 2017-12-16 19:22:26.010877: step 75200, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 15h:41m:03s remains)
INFO - root - 2017-12-16 19:22:28.333345: step 75210, loss = 0.51, batch loss = 0.33 (37.5 examples/sec; 0.213 sec/batch; 15h:13m:44s remains)
INFO - root - 2017-12-16 19:22:30.515685: step 75220, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 15h:46m:35s remains)
INFO - root - 2017-12-16 19:22:32.733123: step 75230, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 15h:49m:30s remains)
INFO - root - 2017-12-16 19:22:34.944576: step 75240, loss = 0.44, batch loss = 0.26 (37.7 examples/sec; 0.212 sec/batch; 15h:09m:57s remains)
INFO - root - 2017-12-16 19:22:37.110361: step 75250, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 15h:41m:25s remains)
INFO - root - 2017-12-16 19:22:39.356530: step 75260, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 15h:47m:54s remains)
INFO - root - 2017-12-16 19:22:41.546592: step 75270, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 15h:11m:24s remains)
INFO - root - 2017-12-16 19:22:43.751307: step 75280, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 16h:21m:21s remains)
INFO - root - 2017-12-16 19:22:45.933125: step 75290, loss = 0.48, batch loss = 0.30 (37.9 examples/sec; 0.211 sec/batch; 15h:05m:49s remains)
INFO - root - 2017-12-16 19:22:48.133440: step 75300, loss = 0.45, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 16h:04m:12s remains)
INFO - root - 2017-12-16 19:22:50.473188: step 75310, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:41m:42s remains)
INFO - root - 2017-12-16 19:22:52.685455: step 75320, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 15h:56m:46s remains)
INFO - root - 2017-12-16 19:22:54.863559: step 75330, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 15h:34m:38s remains)
INFO - root - 2017-12-16 19:22:57.095804: step 75340, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 15h:45m:22s remains)
INFO - root - 2017-12-16 19:22:59.301021: step 75350, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 15h:36m:04s remains)
INFO - root - 2017-12-16 19:23:01.500646: step 75360, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 15h:51m:45s remains)
INFO - root - 2017-12-16 19:23:03.708949: step 75370, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 15h:44m:39s remains)
INFO - root - 2017-12-16 19:23:05.939544: step 75380, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:41m:28s remains)
INFO - root - 2017-12-16 19:23:08.140950: step 75390, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 15h:53m:23s remains)
INFO - root - 2017-12-16 19:23:10.362102: step 75400, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 16h:04m:34s remains)
INFO - root - 2017-12-16 19:23:12.664911: step 75410, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 15h:26m:21s remains)
INFO - root - 2017-12-16 19:23:14.850050: step 75420, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 15h:40m:45s remains)
INFO - root - 2017-12-16 19:23:17.057826: step 75430, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 15h:42m:53s remains)
INFO - root - 2017-12-16 19:23:19.262702: step 75440, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:40m:28s remains)
INFO - root - 2017-12-16 19:23:21.456311: step 75450, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.211 sec/batch; 15h:05m:31s remains)
INFO - root - 2017-12-16 19:23:23.683789: step 75460, loss = 0.46, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 15h:18m:39s remains)
INFO - root - 2017-12-16 19:23:25.880993: step 75470, loss = 0.52, batch loss = 0.34 (34.3 examples/sec; 0.233 sec/batch; 16h:38m:26s remains)
INFO - root - 2017-12-16 19:23:28.072461: step 75480, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 15h:34m:56s remains)
INFO - root - 2017-12-16 19:23:30.256069: step 75490, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 15h:49m:14s remains)
INFO - root - 2017-12-16 19:23:32.449475: step 75500, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 15h:51m:05s remains)
INFO - root - 2017-12-16 19:23:34.776309: step 75510, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.228 sec/batch; 16h:18m:36s remains)
INFO - root - 2017-12-16 19:23:36.973711: step 75520, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 15h:51m:34s remains)
INFO - root - 2017-12-16 19:23:39.195610: step 75530, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 16h:12m:22s remains)
INFO - root - 2017-12-16 19:23:41.397083: step 75540, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 15h:12m:04s remains)
INFO - root - 2017-12-16 19:23:43.612066: step 75550, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 16h:10m:16s remains)
INFO - root - 2017-12-16 19:23:45.828905: step 75560, loss = 0.43, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 15h:35m:16s remains)
INFO - root - 2017-12-16 19:23:48.035772: step 75570, loss = 0.51, batch loss = 0.33 (33.9 examples/sec; 0.236 sec/batch; 16h:49m:08s remains)
INFO - root - 2017-12-16 19:23:50.249249: step 75580, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 15h:48m:43s remains)
INFO - root - 2017-12-16 19:23:52.447347: step 75590, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 16h:05m:19s remains)
INFO - root - 2017-12-16 19:23:54.728678: step 75600, loss = 0.54, batch loss = 0.36 (37.6 examples/sec; 0.213 sec/batch; 15h:09m:53s remains)
INFO - root - 2017-12-16 19:23:57.052576: step 75610, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 15h:55m:41s remains)
INFO - root - 2017-12-16 19:23:59.245963: step 75620, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 16h:33m:34s remains)
INFO - root - 2017-12-16 19:24:01.475744: step 75630, loss = 0.51, batch loss = 0.33 (34.6 examples/sec; 0.232 sec/batch; 16h:31m:05s remains)
INFO - root - 2017-12-16 19:24:03.705822: step 75640, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 15h:41m:53s remains)
INFO - root - 2017-12-16 19:24:05.958878: step 75650, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 15h:32m:51s remains)
INFO - root - 2017-12-16 19:24:08.160844: step 75660, loss = 0.52, batch loss = 0.34 (34.9 examples/sec; 0.229 sec/batch; 16h:21m:48s remains)
INFO - root - 2017-12-16 19:24:10.388006: step 75670, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 15h:45m:14s remains)
INFO - root - 2017-12-16 19:24:12.649284: step 75680, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 15h:52m:20s remains)
INFO - root - 2017-12-16 19:24:14.862008: step 75690, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 16h:16m:30s remains)
INFO - root - 2017-12-16 19:24:17.059915: step 75700, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 15h:51m:51s remains)
INFO - root - 2017-12-16 19:24:19.406682: step 75710, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.219 sec/batch; 15h:36m:13s remains)
INFO - root - 2017-12-16 19:24:21.589809: step 75720, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 15h:25m:23s remains)
INFO - root - 2017-12-16 19:24:23.831965: step 75730, loss = 0.55, batch loss = 0.37 (33.0 examples/sec; 0.243 sec/batch; 17h:18m:34s remains)
INFO - root - 2017-12-16 19:24:26.038619: step 75740, loss = 0.50, batch loss = 0.32 (37.7 examples/sec; 0.212 sec/batch; 15h:08m:34s remains)
INFO - root - 2017-12-16 19:24:28.292425: step 75750, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 15h:35m:17s remains)
INFO - root - 2017-12-16 19:24:30.503652: step 75760, loss = 0.41, batch loss = 0.24 (37.0 examples/sec; 0.216 sec/batch; 15h:25m:41s remains)
INFO - root - 2017-12-16 19:24:32.728775: step 75770, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:40m:59s remains)
INFO - root - 2017-12-16 19:24:34.920857: step 75780, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 15h:37m:17s remains)
INFO - root - 2017-12-16 19:24:37.147737: step 75790, loss = 0.55, batch loss = 0.37 (37.2 examples/sec; 0.215 sec/batch; 15h:20m:47s remains)
INFO - root - 2017-12-16 19:24:39.357850: step 75800, loss = 0.52, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 15h:14m:54s remains)
INFO - root - 2017-12-16 19:24:41.696221: step 75810, loss = 0.42, batch loss = 0.24 (36.5 examples/sec; 0.219 sec/batch; 15h:38m:01s remains)
INFO - root - 2017-12-16 19:24:43.878914: step 75820, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 15h:57m:57s remains)
INFO - root - 2017-12-16 19:24:46.110952: step 75830, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 15h:50m:46s remains)
INFO - root - 2017-12-16 19:24:48.333007: step 75840, loss = 0.48, batch loss = 0.30 (33.7 examples/sec; 0.237 sec/batch; 16h:55m:51s remains)
INFO - root - 2017-12-16 19:24:50.561597: step 75850, loss = 0.49, batch loss = 0.31 (33.5 examples/sec; 0.239 sec/batch; 17h:02m:37s remains)
INFO - root - 2017-12-16 19:24:52.756338: step 75860, loss = 0.42, batch loss = 0.24 (37.3 examples/sec; 0.215 sec/batch; 15h:18m:27s remains)
INFO - root - 2017-12-16 19:24:54.979222: step 75870, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 16h:02m:24s remains)
INFO - root - 2017-12-16 19:24:57.206977: step 75880, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 16h:17m:18s remains)
INFO - root - 2017-12-16 19:24:59.416138: step 75890, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 15h:32m:27s remains)
INFO - root - 2017-12-16 19:25:01.632035: step 75900, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 15h:51m:14s remains)
INFO - root - 2017-12-16 19:25:03.975866: step 75910, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 15h:42m:26s remains)
INFO - root - 2017-12-16 19:25:06.203945: step 75920, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 16h:01m:11s remains)
INFO - root - 2017-12-16 19:25:08.431048: step 75930, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 15h:40m:39s remains)
INFO - root - 2017-12-16 19:25:10.650962: step 75940, loss = 0.56, batch loss = 0.39 (36.6 examples/sec; 0.219 sec/batch; 15h:35m:02s remains)
INFO - root - 2017-12-16 19:25:12.869950: step 75950, loss = 0.52, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 15h:30m:49s remains)
INFO - root - 2017-12-16 19:25:15.058815: step 75960, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 15h:33m:23s remains)
INFO - root - 2017-12-16 19:25:17.289706: step 75970, loss = 0.48, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 15h:30m:45s remains)
INFO - root - 2017-12-16 19:25:19.550065: step 75980, loss = 0.47, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 16h:08m:31s remains)
INFO - root - 2017-12-16 19:25:21.782812: step 75990, loss = 0.46, batch loss = 0.28 (34.1 examples/sec; 0.235 sec/batch; 16h:43m:56s remains)
INFO - root - 2017-12-16 19:25:24.000866: step 76000, loss = 0.47, batch loss = 0.29 (34.4 examples/sec; 0.232 sec/batch; 16h:33m:20s remains)
INFO - root - 2017-12-16 19:25:26.351342: step 76010, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 15h:39m:44s remains)
INFO - root - 2017-12-16 19:25:28.533161: step 76020, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 15h:20m:41s remains)
INFO - root - 2017-12-16 19:25:30.772205: step 76030, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 15h:31m:14s remains)
INFO - root - 2017-12-16 19:25:33.003374: step 76040, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 16h:02m:37s remains)
INFO - root - 2017-12-16 19:25:35.232628: step 76050, loss = 0.56, batch loss = 0.39 (37.1 examples/sec; 0.216 sec/batch; 15h:22m:31s remains)
INFO - root - 2017-12-16 19:25:37.474601: step 76060, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 15h:53m:41s remains)
INFO - root - 2017-12-16 19:25:39.653357: step 76070, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 15h:18m:02s remains)
INFO - root - 2017-12-16 19:25:41.863684: step 76080, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 16h:19m:06s remains)
INFO - root - 2017-12-16 19:25:44.121653: step 76090, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 15h:31m:03s remains)
INFO - root - 2017-12-16 19:25:46.317653: step 76100, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 15h:49m:06s remains)
INFO - root - 2017-12-16 19:25:48.653537: step 76110, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 15h:47m:27s remains)
INFO - root - 2017-12-16 19:25:50.865045: step 76120, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 15h:21m:29s remains)
INFO - root - 2017-12-16 19:25:53.085279: step 76130, loss = 0.55, batch loss = 0.37 (36.9 examples/sec; 0.217 sec/batch; 15h:25m:40s remains)
INFO - root - 2017-12-16 19:25:55.254350: step 76140, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 15h:35m:55s remains)
INFO - root - 2017-12-16 19:25:57.449823: step 76150, loss = 0.50, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 15h:35m:00s remains)
INFO - root - 2017-12-16 19:25:59.674805: step 76160, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 15h:16m:13s remains)
INFO - root - 2017-12-16 19:26:01.943227: step 76170, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.232 sec/batch; 16h:29m:00s remains)
INFO - root - 2017-12-16 19:26:04.179485: step 76180, loss = 0.59, batch loss = 0.41 (36.0 examples/sec; 0.222 sec/batch; 15h:50m:01s remains)
INFO - root - 2017-12-16 19:26:06.409050: step 76190, loss = 0.50, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 15h:37m:22s remains)
INFO - root - 2017-12-16 19:26:08.612072: step 76200, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 15h:43m:09s remains)
INFO - root - 2017-12-16 19:26:10.938522: step 76210, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 15h:17m:07s remains)
INFO - root - 2017-12-16 19:26:13.155398: step 76220, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 16h:12m:43s remains)
INFO - root - 2017-12-16 19:26:15.344193: step 76230, loss = 0.56, batch loss = 0.38 (36.4 examples/sec; 0.220 sec/batch; 15h:39m:02s remains)
INFO - root - 2017-12-16 19:26:17.615709: step 76240, loss = 0.66, batch loss = 0.48 (33.4 examples/sec; 0.239 sec/batch; 17h:01m:56s remains)
INFO - root - 2017-12-16 19:26:19.865950: step 76250, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 16h:15m:46s remains)
INFO - root - 2017-12-16 19:26:22.092736: step 76260, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 16h:10m:05s remains)
INFO - root - 2017-12-16 19:26:24.324629: step 76270, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 15h:19m:24s remains)
INFO - root - 2017-12-16 19:26:26.553614: step 76280, loss = 0.43, batch loss = 0.25 (37.3 examples/sec; 0.215 sec/batch; 15h:16m:56s remains)
INFO - root - 2017-12-16 19:26:28.805771: step 76290, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 15h:53m:45s remains)
INFO - root - 2017-12-16 19:26:30.980424: step 76300, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 15h:40m:48s remains)
INFO - root - 2017-12-16 19:26:33.368077: step 76310, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 15h:49m:46s remains)
INFO - root - 2017-12-16 19:26:35.588773: step 76320, loss = 0.44, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 15h:22m:45s remains)
INFO - root - 2017-12-16 19:26:37.796654: step 76330, loss = 0.50, batch loss = 0.32 (34.6 examples/sec; 0.231 sec/batch; 16h:26m:43s remains)
INFO - root - 2017-12-16 19:26:40.006083: step 76340, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.226 sec/batch; 16h:02m:52s remains)
INFO - root - 2017-12-16 19:26:42.203847: step 76350, loss = 0.45, batch loss = 0.27 (37.8 examples/sec; 0.211 sec/batch; 15h:02m:38s remains)
INFO - root - 2017-12-16 19:26:44.407899: step 76360, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 15h:23m:35s remains)
INFO - root - 2017-12-16 19:26:46.596588: step 76370, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 15h:37m:23s remains)
INFO - root - 2017-12-16 19:26:48.803958: step 76380, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 15h:37m:51s remains)
INFO - root - 2017-12-16 19:26:50.981278: step 76390, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 15h:27m:59s remains)
INFO - root - 2017-12-16 19:26:53.171539: step 76400, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 15h:41m:19s remains)
INFO - root - 2017-12-16 19:26:55.505675: step 76410, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 15h:33m:18s remains)
INFO - root - 2017-12-16 19:26:57.729082: step 76420, loss = 0.47, batch loss = 0.29 (33.4 examples/sec; 0.239 sec/batch; 17h:01m:50s remains)
INFO - root - 2017-12-16 19:26:59.959844: step 76430, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 15h:50m:02s remains)
INFO - root - 2017-12-16 19:27:02.155691: step 76440, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.224 sec/batch; 15h:57m:54s remains)
INFO - root - 2017-12-16 19:27:04.344077: step 76450, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 15h:32m:14s remains)
INFO - root - 2017-12-16 19:27:06.568804: step 76460, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 16h:07m:06s remains)
INFO - root - 2017-12-16 19:27:08.837925: step 76470, loss = 0.45, batch loss = 0.27 (34.6 examples/sec; 0.231 sec/batch; 16h:26m:20s remains)
INFO - root - 2017-12-16 19:27:11.045908: step 76480, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 15h:59m:09s remains)
INFO - root - 2017-12-16 19:27:13.259256: step 76490, loss = 0.40, batch loss = 0.22 (36.7 examples/sec; 0.218 sec/batch; 15h:29m:44s remains)
INFO - root - 2017-12-16 19:27:15.437634: step 76500, loss = 0.47, batch loss = 0.29 (38.0 examples/sec; 0.210 sec/batch; 14h:57m:07s remains)
INFO - root - 2017-12-16 19:27:17.788105: step 76510, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 16h:13m:45s remains)
INFO - root - 2017-12-16 19:27:20.015799: step 76520, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 15h:53m:52s remains)
INFO - root - 2017-12-16 19:27:22.230769: step 76530, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.226 sec/batch; 16h:05m:30s remains)
INFO - root - 2017-12-16 19:27:24.470663: step 76540, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 15h:43m:01s remains)
INFO - root - 2017-12-16 19:27:26.693799: step 76550, loss = 0.42, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 15h:41m:34s remains)
INFO - root - 2017-12-16 19:27:28.913480: step 76560, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 16h:06m:29s remains)
INFO - root - 2017-12-16 19:27:31.121261: step 76570, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 15h:29m:24s remains)
INFO - root - 2017-12-16 19:27:33.287441: step 76580, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 15h:40m:20s remains)
INFO - root - 2017-12-16 19:27:35.488221: step 76590, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 15h:39m:28s remains)
INFO - root - 2017-12-16 19:27:37.685529: step 76600, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 16h:26m:57s remains)
INFO - root - 2017-12-16 19:27:40.072550: step 76610, loss = 0.50, batch loss = 0.32 (33.0 examples/sec; 0.243 sec/batch; 17h:15m:15s remains)
INFO - root - 2017-12-16 19:27:42.328138: step 76620, loss = 0.50, batch loss = 0.32 (34.0 examples/sec; 0.236 sec/batch; 16h:44m:37s remains)
INFO - root - 2017-12-16 19:27:44.559631: step 76630, loss = 0.54, batch loss = 0.36 (35.2 examples/sec; 0.227 sec/batch; 16h:09m:50s remains)
INFO - root - 2017-12-16 19:27:46.740869: step 76640, loss = 0.54, batch loss = 0.36 (35.6 examples/sec; 0.225 sec/batch; 15h:59m:04s remains)
INFO - root - 2017-12-16 19:27:48.927082: step 76650, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 15h:35m:46s remains)
INFO - root - 2017-12-16 19:27:51.139704: step 76660, loss = 0.63, batch loss = 0.45 (37.6 examples/sec; 0.213 sec/batch; 15h:07m:22s remains)
INFO - root - 2017-12-16 19:27:53.368011: step 76670, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 15h:55m:50s remains)
INFO - root - 2017-12-16 19:27:55.578177: step 76680, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 15h:25m:47s remains)
INFO - root - 2017-12-16 19:27:57.798469: step 76690, loss = 0.55, batch loss = 0.37 (36.8 examples/sec; 0.217 sec/batch; 15h:26m:14s remains)
INFO - root - 2017-12-16 19:28:00.072284: step 76700, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 15h:38m:33s remains)
INFO - root - 2017-12-16 19:28:02.415345: step 76710, loss = 0.55, batch loss = 0.37 (36.3 examples/sec; 0.221 sec/batch; 15h:40m:31s remains)
INFO - root - 2017-12-16 19:28:04.612040: step 76720, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 15h:12m:33s remains)
INFO - root - 2017-12-16 19:28:06.818812: step 76730, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 15h:59m:43s remains)
INFO - root - 2017-12-16 19:28:09.022411: step 76740, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 15h:52m:51s remains)
INFO - root - 2017-12-16 19:28:11.225820: step 76750, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 15h:51m:58s remains)
INFO - root - 2017-12-16 19:28:13.426390: step 76760, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:36m:54s remains)
INFO - root - 2017-12-16 19:28:15.664365: step 76770, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 15h:11m:32s remains)
INFO - root - 2017-12-16 19:28:17.870245: step 76780, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 15h:27m:33s remains)
INFO - root - 2017-12-16 19:28:20.071951: step 76790, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 15h:20m:16s remains)
INFO - root - 2017-12-16 19:28:22.309738: step 76800, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 16h:01m:35s remains)
INFO - root - 2017-12-16 19:28:24.662703: step 76810, loss = 0.47, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 16h:03m:38s remains)
INFO - root - 2017-12-16 19:28:26.881935: step 76820, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 15h:45m:30s remains)
INFO - root - 2017-12-16 19:28:29.088927: step 76830, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 16h:11m:36s remains)
INFO - root - 2017-12-16 19:28:31.280915: step 76840, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 15h:13m:39s remains)
INFO - root - 2017-12-16 19:28:33.543359: step 76850, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 15h:28m:48s remains)
INFO - root - 2017-12-16 19:28:35.748861: step 76860, loss = 0.51, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 16h:19m:09s remains)
INFO - root - 2017-12-16 19:28:37.974976: step 76870, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 15h:57m:45s remains)
INFO - root - 2017-12-16 19:28:40.209218: step 76880, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 15h:30m:40s remains)
INFO - root - 2017-12-16 19:28:42.438586: step 76890, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 15h:55m:34s remains)
INFO - root - 2017-12-16 19:28:44.640026: step 76900, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 15h:08m:55s remains)
INFO - root - 2017-12-16 19:28:46.979801: step 76910, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 15h:46m:54s remains)
INFO - root - 2017-12-16 19:28:49.233431: step 76920, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 15h:48m:44s remains)
INFO - root - 2017-12-16 19:28:51.469733: step 76930, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.223 sec/batch; 15h:47m:51s remains)
INFO - root - 2017-12-16 19:28:53.707809: step 76940, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 15h:51m:32s remains)
INFO - root - 2017-12-16 19:28:55.907887: step 76950, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 15h:25m:49s remains)
INFO - root - 2017-12-16 19:28:58.132565: step 76960, loss = 0.54, batch loss = 0.36 (35.2 examples/sec; 0.227 sec/batch; 16h:07m:42s remains)
INFO - root - 2017-12-16 19:29:00.329790: step 76970, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 15h:43m:59s remains)
INFO - root - 2017-12-16 19:29:02.524663: step 76980, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 15h:24m:51s remains)
INFO - root - 2017-12-16 19:29:04.757327: step 76990, loss = 0.41, batch loss = 0.23 (37.8 examples/sec; 0.212 sec/batch; 15h:01m:23s remains)
INFO - root - 2017-12-16 19:29:06.988347: step 77000, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 16h:07m:58s remains)
INFO - root - 2017-12-16 19:29:09.326380: step 77010, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 15h:42m:37s remains)
INFO - root - 2017-12-16 19:29:11.582172: step 77020, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.224 sec/batch; 15h:55m:32s remains)
INFO - root - 2017-12-16 19:29:13.800204: step 77030, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 15h:58m:43s remains)
INFO - root - 2017-12-16 19:29:16.017229: step 77040, loss = 0.47, batch loss = 0.30 (34.0 examples/sec; 0.235 sec/batch; 16h:42m:00s remains)
INFO - root - 2017-12-16 19:29:18.210125: step 77050, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 15h:43m:54s remains)
INFO - root - 2017-12-16 19:29:20.430537: step 77060, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 15h:27m:15s remains)
INFO - root - 2017-12-16 19:29:22.699373: step 77070, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 15h:42m:54s remains)
INFO - root - 2017-12-16 19:29:24.904806: step 77080, loss = 0.59, batch loss = 0.42 (36.7 examples/sec; 0.218 sec/batch; 15h:27m:17s remains)
INFO - root - 2017-12-16 19:29:27.071063: step 77090, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 15h:07m:31s remains)
INFO - root - 2017-12-16 19:29:29.300214: step 77100, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 15h:59m:11s remains)
INFO - root - 2017-12-16 19:29:31.636433: step 77110, loss = 0.48, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 15h:48m:37s remains)
INFO - root - 2017-12-16 19:29:33.855079: step 77120, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.221 sec/batch; 15h:38m:50s remains)
INFO - root - 2017-12-16 19:29:36.071341: step 77130, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.228 sec/batch; 16h:08m:37s remains)
INFO - root - 2017-12-16 19:29:38.303731: step 77140, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 15h:54m:58s remains)
INFO - root - 2017-12-16 19:29:40.516901: step 77150, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 15h:43m:21s remains)
INFO - root - 2017-12-16 19:29:42.695529: step 77160, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 15h:29m:04s remains)
INFO - root - 2017-12-16 19:29:44.987351: step 77170, loss = 0.56, batch loss = 0.38 (35.4 examples/sec; 0.226 sec/batch; 16h:01m:07s remains)
INFO - root - 2017-12-16 19:29:47.216527: step 77180, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 15h:55m:49s remains)
INFO - root - 2017-12-16 19:29:49.424547: step 77190, loss = 0.50, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 15h:42m:28s remains)
INFO - root - 2017-12-16 19:29:51.655261: step 77200, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 15h:33m:52s remains)
INFO - root - 2017-12-16 19:29:54.015535: step 77210, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 15h:31m:23s remains)
INFO - root - 2017-12-16 19:29:56.249708: step 77220, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 15h:59m:34s remains)
INFO - root - 2017-12-16 19:29:58.465420: step 77230, loss = 0.49, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 15h:03m:15s remains)
INFO - root - 2017-12-16 19:30:00.685837: step 77240, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 15h:27m:40s remains)
INFO - root - 2017-12-16 19:30:02.897916: step 77250, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.224 sec/batch; 15h:51m:41s remains)
INFO - root - 2017-12-16 19:30:05.155589: step 77260, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 15h:43m:10s remains)
INFO - root - 2017-12-16 19:30:07.414081: step 77270, loss = 0.46, batch loss = 0.28 (33.6 examples/sec; 0.238 sec/batch; 16h:51m:53s remains)
INFO - root - 2017-12-16 19:30:09.661650: step 77280, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 15h:55m:30s remains)
INFO - root - 2017-12-16 19:30:11.851365: step 77290, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 15h:29m:28s remains)
INFO - root - 2017-12-16 19:30:14.054201: step 77300, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 15h:43m:16s remains)
INFO - root - 2017-12-16 19:30:16.456625: step 77310, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 15h:56m:23s remains)
INFO - root - 2017-12-16 19:30:18.653980: step 77320, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 15h:27m:29s remains)
INFO - root - 2017-12-16 19:30:20.898683: step 77330, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 15h:26m:57s remains)
INFO - root - 2017-12-16 19:30:23.130844: step 77340, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 15h:43m:49s remains)
INFO - root - 2017-12-16 19:30:25.370157: step 77350, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 16h:14m:13s remains)
INFO - root - 2017-12-16 19:30:27.581325: step 77360, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 16h:05m:38s remains)
INFO - root - 2017-12-16 19:30:29.753676: step 77370, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 15h:15m:33s remains)
INFO - root - 2017-12-16 19:30:31.969381: step 77380, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 15h:28m:37s remains)
INFO - root - 2017-12-16 19:30:34.185016: step 77390, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 15h:22m:16s remains)
INFO - root - 2017-12-16 19:30:36.416301: step 77400, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 15h:49m:40s remains)
INFO - root - 2017-12-16 19:30:38.746328: step 77410, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 15h:31m:24s remains)
INFO - root - 2017-12-16 19:30:40.945151: step 77420, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 15h:51m:57s remains)
INFO - root - 2017-12-16 19:30:43.171933: step 77430, loss = 0.49, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 15h:22m:44s remains)
INFO - root - 2017-12-16 19:30:45.343483: step 77440, loss = 0.49, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 15h:35m:19s remains)
INFO - root - 2017-12-16 19:30:47.536760: step 77450, loss = 0.43, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 16h:03m:29s remains)
INFO - root - 2017-12-16 19:30:49.751097: step 77460, loss = 0.47, batch loss = 0.29 (32.3 examples/sec; 0.247 sec/batch; 17h:31m:57s remains)
INFO - root - 2017-12-16 19:30:51.994972: step 77470, loss = 0.45, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 15h:49m:22s remains)
INFO - root - 2017-12-16 19:30:54.231179: step 77480, loss = 0.44, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 16h:25m:11s remains)
INFO - root - 2017-12-16 19:30:56.439268: step 77490, loss = 0.46, batch loss = 0.28 (37.9 examples/sec; 0.211 sec/batch; 14h:57m:06s remains)
INFO - root - 2017-12-16 19:30:58.650032: step 77500, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 15h:25m:46s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-77500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-77500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 19:31:01.428333: step 77510, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 15h:31m:13s remains)
INFO - root - 2017-12-16 19:31:03.656282: step 77520, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 15h:40m:53s remains)
INFO - root - 2017-12-16 19:31:05.833167: step 77530, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 15h:36m:00s remains)
INFO - root - 2017-12-16 19:31:08.098401: step 77540, loss = 0.54, batch loss = 0.36 (36.1 examples/sec; 0.222 sec/batch; 15h:41m:23s remains)
INFO - root - 2017-12-16 19:31:10.354565: step 77550, loss = 0.46, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 15h:45m:42s remains)
INFO - root - 2017-12-16 19:31:12.554747: step 77560, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 15h:49m:35s remains)
INFO - root - 2017-12-16 19:31:14.766909: step 77570, loss = 0.52, batch loss = 0.34 (37.8 examples/sec; 0.211 sec/batch; 14h:58m:36s remains)
INFO - root - 2017-12-16 19:31:16.950687: step 77580, loss = 0.47, batch loss = 0.29 (34.4 examples/sec; 0.232 sec/batch; 16h:26m:50s remains)
INFO - root - 2017-12-16 19:31:19.198735: step 77590, loss = 0.53, batch loss = 0.35 (35.2 examples/sec; 0.227 sec/batch; 16h:05m:41s remains)
INFO - root - 2017-12-16 19:31:21.415378: step 77600, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 15h:30m:50s remains)
INFO - root - 2017-12-16 19:31:23.737086: step 77610, loss = 0.53, batch loss = 0.35 (35.2 examples/sec; 0.227 sec/batch; 16h:06m:11s remains)
INFO - root - 2017-12-16 19:31:25.934229: step 77620, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 15h:37m:32s remains)
INFO - root - 2017-12-16 19:31:28.111499: step 77630, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 15h:34m:26s remains)
INFO - root - 2017-12-16 19:31:30.366186: step 77640, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 15h:51m:25s remains)
INFO - root - 2017-12-16 19:31:32.563524: step 77650, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 15h:48m:16s remains)
INFO - root - 2017-12-16 19:31:34.771101: step 77660, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 15h:59m:10s remains)
INFO - root - 2017-12-16 19:31:37.017643: step 77670, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 16h:00m:08s remains)
INFO - root - 2017-12-16 19:31:39.244173: step 77680, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 15h:08m:43s remains)
INFO - root - 2017-12-16 19:31:41.461731: step 77690, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 15h:38m:31s remains)
INFO - root - 2017-12-16 19:31:43.706588: step 77700, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 15h:54m:03s remains)
INFO - root - 2017-12-16 19:31:46.081100: step 77710, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 15h:23m:04s remains)
INFO - root - 2017-12-16 19:31:48.313302: step 77720, loss = 0.48, batch loss = 0.30 (33.5 examples/sec; 0.239 sec/batch; 16h:54m:20s remains)
INFO - root - 2017-12-16 19:31:50.498339: step 77730, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 15h:32m:28s remains)
INFO - root - 2017-12-16 19:31:52.689004: step 77740, loss = 0.50, batch loss = 0.33 (35.3 examples/sec; 0.226 sec/batch; 16h:01m:26s remains)
INFO - root - 2017-12-16 19:31:54.918554: step 77750, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 16h:07m:28s remains)
INFO - root - 2017-12-16 19:31:57.112138: step 77760, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 15h:55m:44s remains)
INFO - root - 2017-12-16 19:31:59.308344: step 77770, loss = 0.52, batch loss = 0.34 (34.9 examples/sec; 0.230 sec/batch; 16h:14m:31s remains)
INFO - root - 2017-12-16 19:32:01.590212: step 77780, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 15h:38m:33s remains)
INFO - root - 2017-12-16 19:32:03.835137: step 77790, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 15h:34m:36s remains)
INFO - root - 2017-12-16 19:32:06.040746: step 77800, loss = 0.57, batch loss = 0.39 (36.7 examples/sec; 0.218 sec/batch; 15h:25m:06s remains)
INFO - root - 2017-12-16 19:32:08.396044: step 77810, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 15h:21m:51s remains)
INFO - root - 2017-12-16 19:32:10.655783: step 77820, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 15h:45m:33s remains)
INFO - root - 2017-12-16 19:32:12.865787: step 77830, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 15h:47m:28s remains)
INFO - root - 2017-12-16 19:32:15.108608: step 77840, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 15h:48m:56s remains)
INFO - root - 2017-12-16 19:32:17.318344: step 77850, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 15h:25m:12s remains)
INFO - root - 2017-12-16 19:32:19.493467: step 77860, loss = 0.57, batch loss = 0.39 (36.8 examples/sec; 0.217 sec/batch; 15h:21m:40s remains)
INFO - root - 2017-12-16 19:32:21.690269: step 77870, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 15h:13m:17s remains)
INFO - root - 2017-12-16 19:32:23.910408: step 77880, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 15h:37m:18s remains)
INFO - root - 2017-12-16 19:32:26.139110: step 77890, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 15h:48m:28s remains)
INFO - root - 2017-12-16 19:32:28.363529: step 77900, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 15h:26m:17s remains)
INFO - root - 2017-12-16 19:32:30.701600: step 77910, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 16h:08m:19s remains)
INFO - root - 2017-12-16 19:32:32.895374: step 77920, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 15h:42m:25s remains)
INFO - root - 2017-12-16 19:32:35.122940: step 77930, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 15h:25m:25s remains)
INFO - root - 2017-12-16 19:32:37.353531: step 77940, loss = 0.54, batch loss = 0.37 (34.1 examples/sec; 0.234 sec/batch; 16h:34m:20s remains)
INFO - root - 2017-12-16 19:32:39.610717: step 77950, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:33m:29s remains)
INFO - root - 2017-12-16 19:32:41.825586: step 77960, loss = 0.46, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 15h:35m:22s remains)
INFO - root - 2017-12-16 19:32:44.029577: step 77970, loss = 0.53, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 15h:30m:13s remains)
INFO - root - 2017-12-16 19:32:46.213271: step 77980, loss = 0.49, batch loss = 0.31 (34.3 examples/sec; 0.233 sec/batch; 16h:28m:29s remains)
INFO - root - 2017-12-16 19:32:48.441061: step 77990, loss = 0.47, batch loss = 0.29 (34.4 examples/sec; 0.232 sec/batch; 16h:25m:05s remains)
INFO - root - 2017-12-16 19:32:50.685376: step 78000, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 16h:12m:23s remains)
INFO - root - 2017-12-16 19:32:53.101037: step 78010, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 16h:11m:03s remains)
INFO - root - 2017-12-16 19:32:55.275498: step 78020, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 15h:45m:41s remains)
INFO - root - 2017-12-16 19:32:57.504728: step 78030, loss = 0.55, batch loss = 0.37 (36.1 examples/sec; 0.221 sec/batch; 15h:39m:03s remains)
INFO - root - 2017-12-16 19:32:59.691772: step 78040, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 15h:31m:39s remains)
INFO - root - 2017-12-16 19:33:01.922196: step 78050, loss = 0.48, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 15h:35m:48s remains)
INFO - root - 2017-12-16 19:33:04.143986: step 78060, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 15h:42m:08s remains)
INFO - root - 2017-12-16 19:33:06.396642: step 78070, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 15h:52m:23s remains)
INFO - root - 2017-12-16 19:33:08.615101: step 78080, loss = 0.46, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 15h:48m:59s remains)
INFO - root - 2017-12-16 19:33:10.860279: step 78090, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 16h:14m:37s remains)
INFO - root - 2017-12-16 19:33:13.088171: step 78100, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:32m:05s remains)
INFO - root - 2017-12-16 19:33:15.439826: step 78110, loss = 0.56, batch loss = 0.38 (34.7 examples/sec; 0.231 sec/batch; 16h:17m:28s remains)
INFO - root - 2017-12-16 19:33:17.620772: step 78120, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 15h:41m:48s remains)
INFO - root - 2017-12-16 19:33:19.886778: step 78130, loss = 0.49, batch loss = 0.31 (34.3 examples/sec; 0.233 sec/batch; 16h:29m:11s remains)
INFO - root - 2017-12-16 19:33:22.120489: step 78140, loss = 0.47, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 15h:54m:38s remains)
INFO - root - 2017-12-16 19:33:24.350236: step 78150, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 15h:40m:06s remains)
INFO - root - 2017-12-16 19:33:26.551938: step 78160, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 15h:31m:18s remains)
INFO - root - 2017-12-16 19:33:28.761695: step 78170, loss = 0.41, batch loss = 0.24 (37.0 examples/sec; 0.216 sec/batch; 15h:16m:35s remains)
INFO - root - 2017-12-16 19:33:30.968506: step 78180, loss = 0.57, batch loss = 0.39 (36.2 examples/sec; 0.221 sec/batch; 15h:35m:53s remains)
INFO - root - 2017-12-16 19:33:33.191773: step 78190, loss = 0.42, batch loss = 0.24 (33.6 examples/sec; 0.238 sec/batch; 16h:49m:35s remains)
INFO - root - 2017-12-16 19:33:35.395296: step 78200, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 15h:28m:59s remains)
INFO - root - 2017-12-16 19:33:37.719739: step 78210, loss = 0.53, batch loss = 0.35 (35.1 examples/sec; 0.228 sec/batch; 16h:05m:09s remains)
INFO - root - 2017-12-16 19:33:39.957045: step 78220, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 16h:04m:54s remains)
INFO - root - 2017-12-16 19:33:42.178897: step 78230, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 15h:21m:25s remains)
INFO - root - 2017-12-16 19:33:44.402179: step 78240, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 15h:33m:21s remains)
INFO - root - 2017-12-16 19:33:46.589203: step 78250, loss = 0.46, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 16h:29m:06s remains)
INFO - root - 2017-12-16 19:33:48.823702: step 78260, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 15h:34m:06s remains)
INFO - root - 2017-12-16 19:33:51.076797: step 78270, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 15h:11m:21s remains)
INFO - root - 2017-12-16 19:33:53.332179: step 78280, loss = 0.44, batch loss = 0.26 (34.6 examples/sec; 0.231 sec/batch; 16h:19m:04s remains)
INFO - root - 2017-12-16 19:33:55.549124: step 78290, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 15h:20m:24s remains)
INFO - root - 2017-12-16 19:33:57.789031: step 78300, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 15h:33m:28s remains)
INFO - root - 2017-12-16 19:34:00.115701: step 78310, loss = 0.56, batch loss = 0.38 (36.8 examples/sec; 0.217 sec/batch; 15h:20m:05s remains)
INFO - root - 2017-12-16 19:34:02.334514: step 78320, loss = 0.42, batch loss = 0.24 (36.3 examples/sec; 0.221 sec/batch; 15h:34m:12s remains)
INFO - root - 2017-12-16 19:34:04.545790: step 78330, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 15h:46m:44s remains)
INFO - root - 2017-12-16 19:34:06.752330: step 78340, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 15h:31m:32s remains)
INFO - root - 2017-12-16 19:34:08.998287: step 78350, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 15h:42m:23s remains)
INFO - root - 2017-12-16 19:34:11.227489: step 78360, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 15h:37m:55s remains)
INFO - root - 2017-12-16 19:34:13.464881: step 78370, loss = 0.60, batch loss = 0.42 (35.4 examples/sec; 0.226 sec/batch; 15h:56m:34s remains)
INFO - root - 2017-12-16 19:34:15.679638: step 78380, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 15h:25m:31s remains)
INFO - root - 2017-12-16 19:34:17.894191: step 78390, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 15h:43m:37s remains)
INFO - root - 2017-12-16 19:34:20.097173: step 78400, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 15h:40m:13s remains)
INFO - root - 2017-12-16 19:34:22.407049: step 78410, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 15h:17m:53s remains)
INFO - root - 2017-12-16 19:34:24.642181: step 78420, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 15h:45m:29s remains)
INFO - root - 2017-12-16 19:34:26.869501: step 78430, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 15h:46m:28s remains)
INFO - root - 2017-12-16 19:34:29.105513: step 78440, loss = 0.50, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 15h:25m:54s remains)
INFO - root - 2017-12-16 19:34:31.310693: step 78450, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 15h:46m:17s remains)
INFO - root - 2017-12-16 19:34:33.550229: step 78460, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 15h:26m:47s remains)
INFO - root - 2017-12-16 19:34:35.760986: step 78470, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 15h:28m:06s remains)
INFO - root - 2017-12-16 19:34:37.965253: step 78480, loss = 0.43, batch loss = 0.25 (35.1 examples/sec; 0.228 sec/batch; 16h:05m:45s remains)
INFO - root - 2017-12-16 19:34:40.185934: step 78490, loss = 0.47, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 15h:06m:02s remains)
INFO - root - 2017-12-16 19:34:42.451305: step 78500, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 15h:35m:29s remains)
INFO - root - 2017-12-16 19:34:44.857852: step 78510, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 15h:58m:58s remains)
INFO - root - 2017-12-16 19:34:47.094351: step 78520, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 15h:42m:37s remains)
INFO - root - 2017-12-16 19:34:49.278759: step 78530, loss = 0.45, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 15h:11m:19s remains)
INFO - root - 2017-12-16 19:34:51.475031: step 78540, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 15h:23m:05s remains)
INFO - root - 2017-12-16 19:34:53.699815: step 78550, loss = 0.42, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 15h:42m:43s remains)
INFO - root - 2017-12-16 19:34:55.904751: step 78560, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 15h:20m:49s remains)
INFO - root - 2017-12-16 19:34:58.129063: step 78570, loss = 0.55, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 15h:30m:50s remains)
INFO - root - 2017-12-16 19:35:00.358554: step 78580, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 15h:30m:38s remains)
INFO - root - 2017-12-16 19:35:02.544414: step 78590, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 15h:19m:37s remains)
INFO - root - 2017-12-16 19:35:04.776397: step 78600, loss = 0.58, batch loss = 0.40 (35.6 examples/sec; 0.225 sec/batch; 15h:50m:06s remains)
INFO - root - 2017-12-16 19:35:07.131641: step 78610, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 15h:26m:06s remains)
INFO - root - 2017-12-16 19:35:09.340584: step 78620, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 15h:13m:45s remains)
INFO - root - 2017-12-16 19:35:11.602786: step 78630, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 15h:36m:34s remains)
INFO - root - 2017-12-16 19:35:13.828750: step 78640, loss = 0.53, batch loss = 0.35 (37.1 examples/sec; 0.216 sec/batch; 15h:12m:09s remains)
INFO - root - 2017-12-16 19:35:16.047719: step 78650, loss = 0.49, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 15h:06m:49s remains)
INFO - root - 2017-12-16 19:35:18.228582: step 78660, loss = 0.52, batch loss = 0.35 (35.5 examples/sec; 0.225 sec/batch; 15h:52m:27s remains)
INFO - root - 2017-12-16 19:35:20.453465: step 78670, loss = 0.48, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 15h:31m:02s remains)
INFO - root - 2017-12-16 19:35:22.672159: step 78680, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 15h:58m:47s remains)
INFO - root - 2017-12-16 19:35:24.858093: step 78690, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 15h:28m:19s remains)
INFO - root - 2017-12-16 19:35:27.094409: step 78700, loss = 0.47, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 16h:29m:05s remains)
INFO - root - 2017-12-16 19:35:29.404948: step 78710, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.215 sec/batch; 15h:11m:20s remains)
INFO - root - 2017-12-16 19:35:31.648071: step 78720, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 15h:53m:37s remains)
INFO - root - 2017-12-16 19:35:33.883329: step 78730, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 15h:08m:49s remains)
INFO - root - 2017-12-16 19:35:36.376771: step 78740, loss = 0.52, batch loss = 0.34 (33.2 examples/sec; 0.241 sec/batch; 16h:58m:36s remains)
INFO - root - 2017-12-16 19:35:38.600519: step 78750, loss = 0.45, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 15h:46m:47s remains)
INFO - root - 2017-12-16 19:35:40.831503: step 78760, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 15h:45m:34s remains)
INFO - root - 2017-12-16 19:35:43.077568: step 78770, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 15h:50m:27s remains)
INFO - root - 2017-12-16 19:35:45.281833: step 78780, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 15h:28m:33s remains)
INFO - root - 2017-12-16 19:35:47.487568: step 78790, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 15h:17m:22s remains)
INFO - root - 2017-12-16 19:35:49.746237: step 78800, loss = 0.55, batch loss = 0.37 (34.3 examples/sec; 0.233 sec/batch; 16h:24m:47s remains)
INFO - root - 2017-12-16 19:35:52.164961: step 78810, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 15h:54m:19s remains)
INFO - root - 2017-12-16 19:35:54.424049: step 78820, loss = 0.42, batch loss = 0.24 (37.2 examples/sec; 0.215 sec/batch; 15h:09m:43s remains)
INFO - root - 2017-12-16 19:35:56.666212: step 78830, loss = 0.56, batch loss = 0.38 (32.9 examples/sec; 0.243 sec/batch; 17h:07m:29s remains)
INFO - root - 2017-12-16 19:35:58.900251: step 78840, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 15h:31m:06s remains)
INFO - root - 2017-12-16 19:36:01.121590: step 78850, loss = 0.50, batch loss = 0.32 (35.0 examples/sec; 0.228 sec/batch; 16h:05m:58s remains)
INFO - root - 2017-12-16 19:36:03.346594: step 78860, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 15h:41m:16s remains)
INFO - root - 2017-12-16 19:36:05.564840: step 78870, loss = 0.55, batch loss = 0.37 (35.8 examples/sec; 0.223 sec/batch; 15h:44m:16s remains)
INFO - root - 2017-12-16 19:36:07.794542: step 78880, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 15h:24m:47s remains)
INFO - root - 2017-12-16 19:36:10.013506: step 78890, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 16h:09m:59s remains)
INFO - root - 2017-12-16 19:36:12.291191: step 78900, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.223 sec/batch; 15h:43m:32s remains)
INFO - root - 2017-12-16 19:36:14.660876: step 78910, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.233 sec/batch; 16h:22m:43s remains)
INFO - root - 2017-12-16 19:36:16.859613: step 78920, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 15h:23m:43s remains)
INFO - root - 2017-12-16 19:36:19.118889: step 78930, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 15h:23m:45s remains)
INFO - root - 2017-12-16 19:36:21.363716: step 78940, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 15h:17m:51s remains)
INFO - root - 2017-12-16 19:36:23.571616: step 78950, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 15h:22m:24s remains)
INFO - root - 2017-12-16 19:36:25.771203: step 78960, loss = 0.52, batch loss = 0.34 (34.9 examples/sec; 0.229 sec/batch; 16h:08m:09s remains)
INFO - root - 2017-12-16 19:36:27.980592: step 78970, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 15h:09m:50s remains)
INFO - root - 2017-12-16 19:36:30.184948: step 78980, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 16h:02m:49s remains)
INFO - root - 2017-12-16 19:36:32.383805: step 78990, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 15h:11m:13s remains)
INFO - root - 2017-12-16 19:36:34.617105: step 79000, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 15h:14m:13s remains)
INFO - root - 2017-12-16 19:36:36.978443: step 79010, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:28m:26s remains)
INFO - root - 2017-12-16 19:36:39.220746: step 79020, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 15h:35m:22s remains)
INFO - root - 2017-12-16 19:36:41.417095: step 79030, loss = 0.53, batch loss = 0.35 (34.7 examples/sec; 0.230 sec/batch; 16h:12m:47s remains)
INFO - root - 2017-12-16 19:36:43.647938: step 79040, loss = 0.46, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 15h:46m:54s remains)
INFO - root - 2017-12-16 19:36:45.845277: step 79050, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 15h:01m:28s remains)
INFO - root - 2017-12-16 19:36:48.062991: step 79060, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 15h:22m:45s remains)
INFO - root - 2017-12-16 19:36:50.276175: step 79070, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 15h:06m:41s remains)
INFO - root - 2017-12-16 19:36:52.473569: step 79080, loss = 0.47, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 16h:01m:37s remains)
INFO - root - 2017-12-16 19:36:54.701550: step 79090, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 15h:52m:12s remains)
INFO - root - 2017-12-16 19:36:56.932952: step 79100, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 15h:47m:36s remains)
INFO - root - 2017-12-16 19:36:59.305048: step 79110, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 15h:32m:36s remains)
INFO - root - 2017-12-16 19:37:01.539070: step 79120, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 16h:10m:51s remains)
INFO - root - 2017-12-16 19:37:03.748682: step 79130, loss = 0.44, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 15h:34m:27s remains)
INFO - root - 2017-12-16 19:37:05.944372: step 79140, loss = 0.45, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 15h:23m:11s remains)
INFO - root - 2017-12-16 19:37:08.138186: step 79150, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 15h:21m:59s remains)
INFO - root - 2017-12-16 19:37:10.343055: step 79160, loss = 0.47, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 15h:27m:52s remains)
INFO - root - 2017-12-16 19:37:12.575185: step 79170, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 16h:09m:58s remains)
INFO - root - 2017-12-16 19:37:14.783138: step 79180, loss = 0.42, batch loss = 0.24 (36.1 examples/sec; 0.222 sec/batch; 15h:36m:20s remains)
INFO - root - 2017-12-16 19:37:17.013342: step 79190, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 15h:20m:09s remains)
INFO - root - 2017-12-16 19:37:19.205827: step 79200, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 15h:08m:05s remains)
INFO - root - 2017-12-16 19:37:21.588342: step 79210, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 15h:39m:52s remains)
INFO - root - 2017-12-16 19:37:23.824636: step 79220, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.219 sec/batch; 15h:26m:29s remains)
INFO - root - 2017-12-16 19:37:26.061826: step 79230, loss = 0.41, batch loss = 0.23 (36.0 examples/sec; 0.222 sec/batch; 15h:37m:15s remains)
INFO - root - 2017-12-16 19:37:28.265295: step 79240, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 15h:30m:26s remains)
INFO - root - 2017-12-16 19:37:30.526490: step 79250, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 16h:00m:40s remains)
INFO - root - 2017-12-16 19:37:32.738923: step 79260, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 16h:15m:02s remains)
INFO - root - 2017-12-16 19:37:34.966365: step 79270, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.214 sec/batch; 15h:01m:25s remains)
INFO - root - 2017-12-16 19:37:37.182001: step 79280, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 15h:20m:47s remains)
INFO - root - 2017-12-16 19:37:39.391802: step 79290, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 15h:14m:44s remains)
INFO - root - 2017-12-16 19:37:41.668404: step 79300, loss = 0.43, batch loss = 0.26 (34.3 examples/sec; 0.233 sec/batch; 16h:23m:46s remains)
INFO - root - 2017-12-16 19:37:43.998785: step 79310, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 15h:12m:09s remains)
INFO - root - 2017-12-16 19:37:46.227962: step 79320, loss = 0.57, batch loss = 0.39 (35.7 examples/sec; 0.224 sec/batch; 15h:45m:56s remains)
INFO - root - 2017-12-16 19:37:48.466765: step 79330, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 15h:18m:19s remains)
INFO - root - 2017-12-16 19:37:50.670460: step 79340, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 15h:18m:46s remains)
INFO - root - 2017-12-16 19:37:52.859552: step 79350, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 15h:40m:39s remains)
INFO - root - 2017-12-16 19:37:55.110347: step 79360, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 15h:52m:11s remains)
INFO - root - 2017-12-16 19:37:57.339856: step 79370, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 15h:44m:21s remains)
INFO - root - 2017-12-16 19:37:59.544661: step 79380, loss = 0.41, batch loss = 0.24 (35.3 examples/sec; 0.227 sec/batch; 15h:55m:36s remains)
INFO - root - 2017-12-16 19:38:01.775916: step 79390, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 14h:59m:33s remains)
INFO - root - 2017-12-16 19:38:04.019865: step 79400, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 16h:01m:44s remains)
INFO - root - 2017-12-16 19:38:06.358200: step 79410, loss = 0.55, batch loss = 0.37 (35.7 examples/sec; 0.224 sec/batch; 15h:46m:27s remains)
INFO - root - 2017-12-16 19:38:08.592471: step 79420, loss = 0.44, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 15h:34m:04s remains)
INFO - root - 2017-12-16 19:38:10.815777: step 79430, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 14h:53m:50s remains)
INFO - root - 2017-12-16 19:38:13.006650: step 79440, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 15h:08m:37s remains)
INFO - root - 2017-12-16 19:38:15.217201: step 79450, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 15h:31m:40s remains)
INFO - root - 2017-12-16 19:38:17.421162: step 79460, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 15h:18m:56s remains)
INFO - root - 2017-12-16 19:38:19.647389: step 79470, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.228 sec/batch; 16h:02m:49s remains)
INFO - root - 2017-12-16 19:38:21.872909: step 79480, loss = 0.50, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 15h:16m:27s remains)
INFO - root - 2017-12-16 19:38:24.102135: step 79490, loss = 0.54, batch loss = 0.36 (35.1 examples/sec; 0.228 sec/batch; 15h:59m:51s remains)
INFO - root - 2017-12-16 19:38:26.315727: step 79500, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 15h:33m:42s remains)
INFO - root - 2017-12-16 19:38:28.667191: step 79510, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 15h:49m:24s remains)
INFO - root - 2017-12-16 19:38:30.914486: step 79520, loss = 0.55, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 15h:23m:23s remains)
INFO - root - 2017-12-16 19:38:33.108965: step 79530, loss = 0.50, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 15h:45m:31s remains)
INFO - root - 2017-12-16 19:38:35.310403: step 79540, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 15h:08m:19s remains)
INFO - root - 2017-12-16 19:38:37.532765: step 79550, loss = 0.46, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 15h:56m:24s remains)
INFO - root - 2017-12-16 19:38:39.765686: step 79560, loss = 0.47, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 15h:03m:21s remains)
INFO - root - 2017-12-16 19:38:41.988088: step 79570, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 15h:36m:47s remains)
INFO - root - 2017-12-16 19:38:44.212342: step 79580, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 15h:33m:52s remains)
INFO - root - 2017-12-16 19:38:46.464537: step 79590, loss = 0.43, batch loss = 0.25 (33.5 examples/sec; 0.239 sec/batch; 16h:45m:38s remains)
INFO - root - 2017-12-16 19:38:48.715558: step 79600, loss = 0.45, batch loss = 0.27 (33.8 examples/sec; 0.237 sec/batch; 16h:38m:25s remains)
INFO - root - 2017-12-16 19:38:51.057798: step 79610, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 15h:30m:43s remains)
INFO - root - 2017-12-16 19:38:53.280740: step 79620, loss = 0.49, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 14h:54m:37s remains)
INFO - root - 2017-12-16 19:38:55.480037: step 79630, loss = 0.51, batch loss = 0.33 (38.1 examples/sec; 0.210 sec/batch; 14h:45m:02s remains)
INFO - root - 2017-12-16 19:38:57.698504: step 79640, loss = 0.44, batch loss = 0.26 (35.0 examples/sec; 0.229 sec/batch; 16h:03m:22s remains)
INFO - root - 2017-12-16 19:38:59.885756: step 79650, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 15h:27m:54s remains)
INFO - root - 2017-12-16 19:39:02.134893: step 79660, loss = 0.50, batch loss = 0.32 (34.2 examples/sec; 0.234 sec/batch; 16h:24m:40s remains)
INFO - root - 2017-12-16 19:39:04.350832: step 79670, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:26m:57s remains)
INFO - root - 2017-12-16 19:39:06.565786: step 79680, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 15h:51m:29s remains)
INFO - root - 2017-12-16 19:39:08.829451: step 79690, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 15h:47m:00s remains)
INFO - root - 2017-12-16 19:39:11.037186: step 79700, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 15h:59m:23s remains)
INFO - root - 2017-12-16 19:39:13.457137: step 79710, loss = 0.46, batch loss = 0.28 (34.0 examples/sec; 0.235 sec/batch; 16h:31m:07s remains)
INFO - root - 2017-12-16 19:39:15.661426: step 79720, loss = 0.45, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 15h:33m:09s remains)
INFO - root - 2017-12-16 19:39:17.885591: step 79730, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 15h:42m:03s remains)
INFO - root - 2017-12-16 19:39:20.122635: step 79740, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 15h:18m:02s remains)
INFO - root - 2017-12-16 19:39:22.328756: step 79750, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 15h:54m:37s remains)
INFO - root - 2017-12-16 19:39:24.544304: step 79760, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 15h:16m:11s remains)
INFO - root - 2017-12-16 19:39:26.771574: step 79770, loss = 0.50, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 16h:08m:15s remains)
INFO - root - 2017-12-16 19:39:29.004055: step 79780, loss = 0.49, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 15h:48m:31s remains)
INFO - root - 2017-12-16 19:39:31.262548: step 79790, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 15h:31m:49s remains)
INFO - root - 2017-12-16 19:39:33.508640: step 79800, loss = 0.54, batch loss = 0.37 (36.6 examples/sec; 0.219 sec/batch; 15h:21m:27s remains)
INFO - root - 2017-12-16 19:39:35.843369: step 79810, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.226 sec/batch; 15h:53m:20s remains)
INFO - root - 2017-12-16 19:39:38.045125: step 79820, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 15h:44m:37s remains)
INFO - root - 2017-12-16 19:39:40.262731: step 79830, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 15h:35m:58s remains)
INFO - root - 2017-12-16 19:39:42.480835: step 79840, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 15h:25m:25s remains)
INFO - root - 2017-12-16 19:39:44.707265: step 79850, loss = 0.56, batch loss = 0.38 (36.0 examples/sec; 0.222 sec/batch; 15h:34m:40s remains)
INFO - root - 2017-12-16 19:39:46.948247: step 79860, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 15h:26m:10s remains)
INFO - root - 2017-12-16 19:39:49.142524: step 79870, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 15h:02m:39s remains)
INFO - root - 2017-12-16 19:39:51.390847: step 79880, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 16h:11m:15s remains)
INFO - root - 2017-12-16 19:39:53.619352: step 79890, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 15h:16m:22s remains)
INFO - root - 2017-12-16 19:39:55.865080: step 79900, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 15h:10m:53s remains)
INFO - root - 2017-12-16 19:39:58.218974: step 79910, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 16h:07m:16s remains)
INFO - root - 2017-12-16 19:40:00.406491: step 79920, loss = 0.42, batch loss = 0.24 (37.5 examples/sec; 0.213 sec/batch; 14h:57m:37s remains)
INFO - root - 2017-12-16 19:40:02.648026: step 79930, loss = 0.49, batch loss = 0.31 (34.2 examples/sec; 0.234 sec/batch; 16h:24m:51s remains)
INFO - root - 2017-12-16 19:40:04.886418: step 79940, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 15h:50m:23s remains)
INFO - root - 2017-12-16 19:40:07.102279: step 79950, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.232 sec/batch; 16h:17m:43s remains)
INFO - root - 2017-12-16 19:40:09.297325: step 79960, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 15h:07m:10s remains)
INFO - root - 2017-12-16 19:40:11.530974: step 79970, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 15h:12m:14s remains)
INFO - root - 2017-12-16 19:40:13.790081: step 79980, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 16h:05m:09s remains)
INFO - root - 2017-12-16 19:40:16.010480: step 79990, loss = 0.57, batch loss = 0.39 (36.9 examples/sec; 0.217 sec/batch; 15h:11m:46s remains)
INFO - root - 2017-12-16 19:40:18.240066: step 80000, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.217 sec/batch; 15h:11m:07s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-80000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-80000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 19:40:21.236064: step 80010, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 15h:26m:58s remains)
INFO - root - 2017-12-16 19:40:23.496451: step 80020, loss = 0.46, batch loss = 0.28 (33.8 examples/sec; 0.237 sec/batch; 16h:35m:13s remains)
INFO - root - 2017-12-16 19:40:25.719390: step 80030, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 15h:25m:12s remains)
INFO - root - 2017-12-16 19:40:27.917026: step 80040, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 15h:10m:24s remains)
INFO - root - 2017-12-16 19:40:30.141572: step 80050, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 15h:14m:55s remains)
INFO - root - 2017-12-16 19:40:32.372818: step 80060, loss = 0.52, batch loss = 0.34 (34.8 examples/sec; 0.230 sec/batch; 16h:06m:21s remains)
INFO - root - 2017-12-16 19:40:34.599862: step 80070, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.230 sec/batch; 16h:09m:04s remains)
INFO - root - 2017-12-16 19:40:36.789080: step 80080, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 15h:19m:50s remains)
INFO - root - 2017-12-16 19:40:39.027026: step 80090, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 15h:54m:28s remains)
INFO - root - 2017-12-16 19:40:41.304968: step 80100, loss = 0.55, batch loss = 0.37 (33.8 examples/sec; 0.237 sec/batch; 16h:36m:15s remains)
INFO - root - 2017-12-16 19:40:43.656137: step 80110, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 15h:14m:24s remains)
INFO - root - 2017-12-16 19:40:45.852525: step 80120, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 15h:37m:55s remains)
INFO - root - 2017-12-16 19:40:48.052624: step 80130, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 15h:27m:15s remains)
INFO - root - 2017-12-16 19:40:50.253104: step 80140, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 14h:57m:14s remains)
INFO - root - 2017-12-16 19:40:52.495324: step 80150, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 15h:27m:46s remains)
INFO - root - 2017-12-16 19:40:54.732224: step 80160, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 15h:20m:33s remains)
INFO - root - 2017-12-16 19:40:57.012222: step 80170, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 15h:31m:28s remains)
INFO - root - 2017-12-16 19:40:59.216251: step 80180, loss = 0.44, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 15h:12m:03s remains)
INFO - root - 2017-12-16 19:41:01.410479: step 80190, loss = 0.50, batch loss = 0.32 (37.8 examples/sec; 0.212 sec/batch; 14h:50m:01s remains)
INFO - root - 2017-12-16 19:41:03.660173: step 80200, loss = 0.42, batch loss = 0.24 (37.2 examples/sec; 0.215 sec/batch; 15h:03m:28s remains)
INFO - root - 2017-12-16 19:41:06.040408: step 80210, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 15h:21m:58s remains)
INFO - root - 2017-12-16 19:41:08.299150: step 80220, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 15h:13m:54s remains)
INFO - root - 2017-12-16 19:41:10.525987: step 80230, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 15h:47m:30s remains)
INFO - root - 2017-12-16 19:41:12.783107: step 80240, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 15h:18m:11s remains)
INFO - root - 2017-12-16 19:41:15.003756: step 80250, loss = 0.61, batch loss = 0.43 (36.5 examples/sec; 0.219 sec/batch; 15h:20m:38s remains)
INFO - root - 2017-12-16 19:41:17.250902: step 80260, loss = 0.53, batch loss = 0.35 (35.2 examples/sec; 0.227 sec/batch; 15h:55m:34s remains)
INFO - root - 2017-12-16 19:41:19.484769: step 80270, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 15h:12m:29s remains)
INFO - root - 2017-12-16 19:41:21.748724: step 80280, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 15h:52m:42s remains)
INFO - root - 2017-12-16 19:41:23.938322: step 80290, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 15h:29m:53s remains)
INFO - root - 2017-12-16 19:41:26.163514: step 80300, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 15h:01m:45s remains)
INFO - root - 2017-12-16 19:41:28.508917: step 80310, loss = 0.53, batch loss = 0.35 (35.0 examples/sec; 0.229 sec/batch; 16h:01m:33s remains)
INFO - root - 2017-12-16 19:41:30.733990: step 80320, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 15h:43m:06s remains)
INFO - root - 2017-12-16 19:41:32.942603: step 80330, loss = 0.57, batch loss = 0.39 (35.7 examples/sec; 0.224 sec/batch; 15h:41m:46s remains)
INFO - root - 2017-12-16 19:41:35.152683: step 80340, loss = 0.53, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 15h:44m:42s remains)
INFO - root - 2017-12-16 19:41:37.367691: step 80350, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 15h:26m:07s remains)
INFO - root - 2017-12-16 19:41:39.551719: step 80360, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 15h:42m:57s remains)
INFO - root - 2017-12-16 19:41:41.809132: step 80370, loss = 0.42, batch loss = 0.25 (33.8 examples/sec; 0.237 sec/batch; 16h:34m:08s remains)
INFO - root - 2017-12-16 19:41:44.016727: step 80380, loss = 0.49, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 14h:52m:42s remains)
INFO - root - 2017-12-16 19:41:46.237231: step 80390, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 15h:30m:29s remains)
INFO - root - 2017-12-16 19:41:48.476236: step 80400, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 15h:23m:24s remains)
INFO - root - 2017-12-16 19:41:50.830112: step 80410, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 15h:16m:37s remains)
INFO - root - 2017-12-16 19:41:53.032034: step 80420, loss = 0.46, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 15h:37m:13s remains)
INFO - root - 2017-12-16 19:41:55.293552: step 80430, loss = 0.61, batch loss = 0.44 (35.2 examples/sec; 0.227 sec/batch; 15h:55m:17s remains)
INFO - root - 2017-12-16 19:41:57.505607: step 80440, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 15h:14m:45s remains)
INFO - root - 2017-12-16 19:41:59.706595: step 80450, loss = 0.53, batch loss = 0.35 (35.0 examples/sec; 0.228 sec/batch; 15h:59m:49s remains)
INFO - root - 2017-12-16 19:42:01.937126: step 80460, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 15h:51m:34s remains)
INFO - root - 2017-12-16 19:42:04.160426: step 80470, loss = 0.51, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 15h:42m:07s remains)
INFO - root - 2017-12-16 19:42:06.388179: step 80480, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 15h:34m:46s remains)
INFO - root - 2017-12-16 19:42:08.646544: step 80490, loss = 0.40, batch loss = 0.22 (34.3 examples/sec; 0.233 sec/batch; 16h:19m:18s remains)
INFO - root - 2017-12-16 19:42:10.844395: step 80500, loss = 0.46, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 15h:46m:14s remains)
INFO - root - 2017-12-16 19:42:13.209661: step 80510, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.231 sec/batch; 16h:11m:51s remains)
INFO - root - 2017-12-16 19:42:15.426106: step 80520, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 15h:07m:37s remains)
INFO - root - 2017-12-16 19:42:17.638612: step 80530, loss = 0.58, batch loss = 0.40 (35.5 examples/sec; 0.226 sec/batch; 15h:47m:23s remains)
INFO - root - 2017-12-16 19:42:19.840216: step 80540, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 15h:40m:47s remains)
INFO - root - 2017-12-16 19:42:22.045938: step 80550, loss = 0.55, batch loss = 0.37 (34.6 examples/sec; 0.231 sec/batch; 16h:10m:20s remains)
INFO - root - 2017-12-16 19:42:24.305317: step 80560, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 15h:46m:00s remains)
INFO - root - 2017-12-16 19:42:26.525928: step 80570, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 15h:44m:57s remains)
INFO - root - 2017-12-16 19:42:28.719157: step 80580, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 15h:27m:39s remains)
INFO - root - 2017-12-16 19:42:31.004953: step 80590, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 15h:33m:19s remains)
INFO - root - 2017-12-16 19:42:33.238767: step 80600, loss = 0.43, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 15h:11m:09s remains)
INFO - root - 2017-12-16 19:42:35.602496: step 80610, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 15h:41m:37s remains)
INFO - root - 2017-12-16 19:42:37.843863: step 80620, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 16h:01m:02s remains)
INFO - root - 2017-12-16 19:42:40.080254: step 80630, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 15h:38m:46s remains)
INFO - root - 2017-12-16 19:42:42.284946: step 80640, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:21m:41s remains)
INFO - root - 2017-12-16 19:42:44.505228: step 80650, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 15h:35m:20s remains)
INFO - root - 2017-12-16 19:42:46.714391: step 80660, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.214 sec/batch; 14h:56m:22s remains)
INFO - root - 2017-12-16 19:42:48.977285: step 80670, loss = 0.48, batch loss = 0.30 (33.4 examples/sec; 0.239 sec/batch; 16h:45m:06s remains)
INFO - root - 2017-12-16 19:42:51.186185: step 80680, loss = 0.48, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 15h:39m:36s remains)
INFO - root - 2017-12-16 19:42:53.410740: step 80690, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 15h:40m:53s remains)
INFO - root - 2017-12-16 19:42:55.619021: step 80700, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 15h:20m:09s remains)
INFO - root - 2017-12-16 19:42:57.983448: step 80710, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 15h:49m:44s remains)
INFO - root - 2017-12-16 19:43:00.183653: step 80720, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 15h:49m:09s remains)
INFO - root - 2017-12-16 19:43:02.384161: step 80730, loss = 0.47, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 15h:37m:01s remains)
INFO - root - 2017-12-16 19:43:04.619873: step 80740, loss = 0.46, batch loss = 0.28 (37.7 examples/sec; 0.212 sec/batch; 14h:49m:29s remains)
INFO - root - 2017-12-16 19:43:06.858179: step 80750, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 15h:48m:04s remains)
INFO - root - 2017-12-16 19:43:09.076435: step 80760, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 15h:24m:10s remains)
INFO - root - 2017-12-16 19:43:11.273734: step 80770, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 15h:27m:26s remains)
INFO - root - 2017-12-16 19:43:13.485403: step 80780, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 15h:01m:24s remains)
INFO - root - 2017-12-16 19:43:15.692257: step 80790, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 15h:29m:52s remains)
INFO - root - 2017-12-16 19:43:17.909012: step 80800, loss = 0.53, batch loss = 0.35 (37.8 examples/sec; 0.212 sec/batch; 14h:48m:47s remains)
INFO - root - 2017-12-16 19:43:20.234650: step 80810, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 15h:42m:09s remains)
INFO - root - 2017-12-16 19:43:22.434657: step 80820, loss = 0.48, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 15h:00m:21s remains)
INFO - root - 2017-12-16 19:43:24.646271: step 80830, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 14h:54m:28s remains)
INFO - root - 2017-12-16 19:43:26.861796: step 80840, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 15h:28m:02s remains)
INFO - root - 2017-12-16 19:43:29.038886: step 80850, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 15h:48m:02s remains)
INFO - root - 2017-12-16 19:43:31.264790: step 80860, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 15h:38m:38s remains)
INFO - root - 2017-12-16 19:43:33.510757: step 80870, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 16h:02m:06s remains)
INFO - root - 2017-12-16 19:43:35.738104: step 80880, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 15h:32m:58s remains)
INFO - root - 2017-12-16 19:43:37.942092: step 80890, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 15h:52m:13s remains)
INFO - root - 2017-12-16 19:43:40.209721: step 80900, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 15h:30m:10s remains)
INFO - root - 2017-12-16 19:43:42.559222: step 80910, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 15h:22m:53s remains)
INFO - root - 2017-12-16 19:43:44.783145: step 80920, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 15h:31m:40s remains)
INFO - root - 2017-12-16 19:43:47.006593: step 80930, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 15h:25m:58s remains)
INFO - root - 2017-12-16 19:43:49.253383: step 80940, loss = 0.48, batch loss = 0.30 (33.4 examples/sec; 0.239 sec/batch; 16h:42m:59s remains)
INFO - root - 2017-12-16 19:43:51.485811: step 80950, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 15h:40m:46s remains)
INFO - root - 2017-12-16 19:43:53.721519: step 80960, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 15h:38m:37s remains)
INFO - root - 2017-12-16 19:43:55.923238: step 80970, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 15h:08m:07s remains)
INFO - root - 2017-12-16 19:43:58.155139: step 80980, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 15h:44m:06s remains)
INFO - root - 2017-12-16 19:44:00.416193: step 80990, loss = 0.54, batch loss = 0.36 (34.1 examples/sec; 0.235 sec/batch; 16h:23m:56s remains)
INFO - root - 2017-12-16 19:44:02.653894: step 81000, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 15h:23m:47s remains)
INFO - root - 2017-12-16 19:44:05.046803: step 81010, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 15h:32m:58s remains)
INFO - root - 2017-12-16 19:44:07.312675: step 81020, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 15h:48m:19s remains)
INFO - root - 2017-12-16 19:44:09.536890: step 81030, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 15h:43m:28s remains)
INFO - root - 2017-12-16 19:44:11.803423: step 81040, loss = 0.42, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 15h:39m:25s remains)
INFO - root - 2017-12-16 19:44:14.049214: step 81050, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 15h:50m:52s remains)
INFO - root - 2017-12-16 19:44:16.309529: step 81060, loss = 0.51, batch loss = 0.33 (33.7 examples/sec; 0.237 sec/batch; 16h:35m:00s remains)
INFO - root - 2017-12-16 19:44:18.560119: step 81070, loss = 0.43, batch loss = 0.25 (33.6 examples/sec; 0.238 sec/batch; 16h:39m:02s remains)
INFO - root - 2017-12-16 19:44:20.785463: step 81080, loss = 0.57, batch loss = 0.39 (36.9 examples/sec; 0.217 sec/batch; 15h:08m:28s remains)
INFO - root - 2017-12-16 19:44:23.017014: step 81090, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 14h:57m:11s remains)
INFO - root - 2017-12-16 19:44:25.283890: step 81100, loss = 0.46, batch loss = 0.28 (30.7 examples/sec; 0.260 sec/batch; 18h:10m:20s remains)
INFO - root - 2017-12-16 19:44:27.659577: step 81110, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 15h:43m:44s remains)
INFO - root - 2017-12-16 19:44:29.886256: step 81120, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 15h:21m:12s remains)
INFO - root - 2017-12-16 19:44:32.130500: step 81130, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 15h:50m:10s remains)
INFO - root - 2017-12-16 19:44:34.371396: step 81140, loss = 0.50, batch loss = 0.32 (34.1 examples/sec; 0.234 sec/batch; 16h:21m:32s remains)
INFO - root - 2017-12-16 19:44:36.561763: step 81150, loss = 0.50, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 15h:29m:10s remains)
INFO - root - 2017-12-16 19:44:38.815248: step 81160, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 15h:38m:04s remains)
INFO - root - 2017-12-16 19:44:41.045315: step 81170, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 15h:35m:52s remains)
INFO - root - 2017-12-16 19:44:43.280690: step 81180, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 15h:43m:30s remains)
INFO - root - 2017-12-16 19:44:45.460975: step 81190, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.221 sec/batch; 15h:23m:34s remains)
INFO - root - 2017-12-16 19:44:47.653711: step 81200, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 15h:17m:59s remains)
INFO - root - 2017-12-16 19:44:50.051206: step 81210, loss = 0.48, batch loss = 0.30 (34.1 examples/sec; 0.234 sec/batch; 16h:21m:44s remains)
INFO - root - 2017-12-16 19:44:52.297561: step 81220, loss = 0.50, batch loss = 0.32 (32.9 examples/sec; 0.243 sec/batch; 16h:58m:30s remains)
INFO - root - 2017-12-16 19:44:54.528531: step 81230, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 14h:55m:39s remains)
INFO - root - 2017-12-16 19:44:56.759602: step 81240, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 15h:32m:15s remains)
INFO - root - 2017-12-16 19:44:58.984841: step 81250, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 15h:56m:08s remains)
INFO - root - 2017-12-16 19:45:01.251288: step 81260, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.221 sec/batch; 15h:26m:56s remains)
INFO - root - 2017-12-16 19:45:03.468268: step 81270, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.233 sec/batch; 16h:13m:41s remains)
INFO - root - 2017-12-16 19:45:05.675480: step 81280, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 15h:40m:00s remains)
INFO - root - 2017-12-16 19:45:07.891363: step 81290, loss = 0.58, batch loss = 0.40 (34.4 examples/sec; 0.232 sec/batch; 16h:12m:52s remains)
INFO - root - 2017-12-16 19:45:10.135019: step 81300, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 15h:44m:55s remains)
INFO - root - 2017-12-16 19:45:12.497015: step 81310, loss = 0.45, batch loss = 0.27 (34.3 examples/sec; 0.233 sec/batch; 16h:16m:10s remains)
INFO - root - 2017-12-16 19:45:14.735223: step 81320, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.223 sec/batch; 15h:31m:32s remains)
INFO - root - 2017-12-16 19:45:16.938498: step 81330, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 15h:08m:22s remains)
INFO - root - 2017-12-16 19:45:19.168787: step 81340, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 15h:22m:23s remains)
INFO - root - 2017-12-16 19:45:21.366539: step 81350, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 15h:06m:26s remains)
INFO - root - 2017-12-16 19:45:23.567147: step 81360, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.218 sec/batch; 15h:14m:04s remains)
INFO - root - 2017-12-16 19:45:25.754900: step 81370, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 15h:15m:16s remains)
INFO - root - 2017-12-16 19:45:27.969997: step 81380, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 15h:12m:13s remains)
INFO - root - 2017-12-16 19:45:30.161108: step 81390, loss = 0.43, batch loss = 0.25 (37.5 examples/sec; 0.213 sec/batch; 14h:52m:26s remains)
INFO - root - 2017-12-16 19:45:32.382114: step 81400, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 15h:15m:48s remains)
INFO - root - 2017-12-16 19:45:34.740570: step 81410, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 15h:14m:57s remains)
INFO - root - 2017-12-16 19:45:36.969974: step 81420, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 15h:21m:14s remains)
INFO - root - 2017-12-16 19:45:39.211280: step 81430, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 15h:48m:41s remains)
INFO - root - 2017-12-16 19:45:41.424927: step 81440, loss = 0.46, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 15h:25m:12s remains)
INFO - root - 2017-12-16 19:45:43.653446: step 81450, loss = 0.46, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 15h:42m:13s remains)
INFO - root - 2017-12-16 19:45:45.949441: step 81460, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 15h:29m:04s remains)
INFO - root - 2017-12-16 19:45:48.177020: step 81470, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 15h:37m:37s remains)
INFO - root - 2017-12-16 19:45:50.362975: step 81480, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 15h:32m:28s remains)
INFO - root - 2017-12-16 19:45:52.575537: step 81490, loss = 0.46, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 14h:57m:22s remains)
INFO - root - 2017-12-16 19:45:54.798614: step 81500, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 15h:41m:46s remains)
INFO - root - 2017-12-16 19:45:57.137333: step 81510, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 15h:06m:52s remains)
INFO - root - 2017-12-16 19:45:59.353264: step 81520, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 15h:36m:56s remains)
INFO - root - 2017-12-16 19:46:01.563159: step 81530, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 15h:28m:06s remains)
INFO - root - 2017-12-16 19:46:03.772119: step 81540, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 15h:18m:24s remains)
INFO - root - 2017-12-16 19:46:05.979610: step 81550, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 16h:10m:03s remains)
INFO - root - 2017-12-16 19:46:08.234618: step 81560, loss = 0.54, batch loss = 0.36 (35.3 examples/sec; 0.227 sec/batch; 15h:48m:04s remains)
INFO - root - 2017-12-16 19:46:10.443721: step 81570, loss = 0.56, batch loss = 0.38 (37.3 examples/sec; 0.214 sec/batch; 14h:57m:03s remains)
INFO - root - 2017-12-16 19:46:12.656692: step 81580, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.230 sec/batch; 16h:02m:54s remains)
INFO - root - 2017-12-16 19:46:14.896440: step 81590, loss = 0.51, batch loss = 0.33 (33.2 examples/sec; 0.241 sec/batch; 16h:46m:31s remains)
INFO - root - 2017-12-16 19:46:17.147507: step 81600, loss = 0.47, batch loss = 0.29 (34.6 examples/sec; 0.232 sec/batch; 16h:08m:11s remains)
INFO - root - 2017-12-16 19:46:19.481335: step 81610, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 15h:15m:39s remains)
INFO - root - 2017-12-16 19:46:21.706157: step 81620, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.228 sec/batch; 15h:51m:18s remains)
INFO - root - 2017-12-16 19:46:23.964456: step 81630, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 15h:06m:57s remains)
INFO - root - 2017-12-16 19:46:26.184098: step 81640, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 15h:18m:01s remains)
INFO - root - 2017-12-16 19:46:28.387859: step 81650, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 15h:31m:55s remains)
INFO - root - 2017-12-16 19:46:30.652134: step 81660, loss = 0.43, batch loss = 0.25 (33.5 examples/sec; 0.239 sec/batch; 16h:38m:39s remains)
INFO - root - 2017-12-16 19:46:32.859690: step 81670, loss = 0.46, batch loss = 0.29 (37.9 examples/sec; 0.211 sec/batch; 14h:42m:27s remains)
INFO - root - 2017-12-16 19:46:35.115717: step 81680, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 15h:29m:00s remains)
INFO - root - 2017-12-16 19:46:37.353410: step 81690, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 15h:47m:03s remains)
INFO - root - 2017-12-16 19:46:39.556658: step 81700, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 15h:44m:17s remains)
INFO - root - 2017-12-16 19:46:41.905970: step 81710, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 15h:12m:53s remains)
INFO - root - 2017-12-16 19:46:44.111485: step 81720, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.223 sec/batch; 15h:30m:04s remains)
INFO - root - 2017-12-16 19:46:46.292328: step 81730, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 15h:21m:03s remains)
INFO - root - 2017-12-16 19:46:48.492286: step 81740, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 15h:13m:57s remains)
INFO - root - 2017-12-16 19:46:50.739452: step 81750, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 15h:38m:29s remains)
INFO - root - 2017-12-16 19:46:52.941721: step 81760, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 14h:59m:39s remains)
INFO - root - 2017-12-16 19:46:55.172333: step 81770, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 15h:33m:08s remains)
INFO - root - 2017-12-16 19:46:57.403464: step 81780, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 15h:08m:10s remains)
INFO - root - 2017-12-16 19:46:59.606355: step 81790, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 15h:18m:13s remains)
INFO - root - 2017-12-16 19:47:01.824479: step 81800, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 15h:23m:42s remains)
INFO - root - 2017-12-16 19:47:04.212610: step 81810, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.231 sec/batch; 16h:03m:33s remains)
INFO - root - 2017-12-16 19:47:06.438051: step 81820, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 15h:07m:56s remains)
INFO - root - 2017-12-16 19:47:08.624902: step 81830, loss = 0.59, batch loss = 0.41 (37.2 examples/sec; 0.215 sec/batch; 14h:58m:47s remains)
INFO - root - 2017-12-16 19:47:10.822794: step 81840, loss = 0.62, batch loss = 0.44 (36.0 examples/sec; 0.222 sec/batch; 15h:28m:53s remains)
INFO - root - 2017-12-16 19:47:13.035861: step 81850, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 15h:02m:58s remains)
INFO - root - 2017-12-16 19:47:15.200890: step 81860, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 15h:01m:46s remains)
INFO - root - 2017-12-16 19:47:17.401702: step 81870, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 15h:43m:56s remains)
INFO - root - 2017-12-16 19:47:19.616664: step 81880, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 15h:14m:37s remains)
INFO - root - 2017-12-16 19:47:21.803632: step 81890, loss = 0.54, batch loss = 0.36 (37.8 examples/sec; 0.212 sec/batch; 14h:45m:07s remains)
INFO - root - 2017-12-16 19:47:24.009642: step 81900, loss = 0.50, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 14h:52m:13s remains)
INFO - root - 2017-12-16 19:47:26.373161: step 81910, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 15h:09m:52s remains)
INFO - root - 2017-12-16 19:47:28.597498: step 81920, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 15h:23m:16s remains)
INFO - root - 2017-12-16 19:47:30.797117: step 81930, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 15h:20m:10s remains)
INFO - root - 2017-12-16 19:47:32.986456: step 81940, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 15h:26m:53s remains)
INFO - root - 2017-12-16 19:47:35.175915: step 81950, loss = 0.49, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 15h:33m:18s remains)
INFO - root - 2017-12-16 19:47:37.363914: step 81960, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 16h:07m:40s remains)
INFO - root - 2017-12-16 19:47:39.595418: step 81970, loss = 0.48, batch loss = 0.30 (34.7 examples/sec; 0.230 sec/batch; 16h:02m:05s remains)
INFO - root - 2017-12-16 19:47:41.842013: step 81980, loss = 0.42, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 15h:35m:38s remains)
INFO - root - 2017-12-16 19:47:44.080214: step 81990, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 15h:52m:02s remains)
INFO - root - 2017-12-16 19:47:46.331173: step 82000, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.218 sec/batch; 15h:08m:20s remains)
INFO - root - 2017-12-16 19:47:48.715580: step 82010, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 15h:32m:43s remains)
INFO - root - 2017-12-16 19:47:50.926847: step 82020, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 15h:09m:12s remains)
INFO - root - 2017-12-16 19:47:53.122062: step 82030, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 15h:12m:53s remains)
INFO - root - 2017-12-16 19:47:55.340282: step 82040, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 15h:20m:01s remains)
INFO - root - 2017-12-16 19:47:57.568404: step 82050, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 15h:30m:33s remains)
INFO - root - 2017-12-16 19:47:59.755812: step 82060, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 15h:18m:53s remains)
INFO - root - 2017-12-16 19:48:02.046264: step 82070, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 16h:06m:38s remains)
INFO - root - 2017-12-16 19:48:04.230267: step 82080, loss = 0.44, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 15h:11m:43s remains)
INFO - root - 2017-12-16 19:48:06.466609: step 82090, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.231 sec/batch; 16h:04m:27s remains)
INFO - root - 2017-12-16 19:48:08.670361: step 82100, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 15h:27m:11s remains)
INFO - root - 2017-12-16 19:48:11.058553: step 82110, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 15h:35m:14s remains)
INFO - root - 2017-12-16 19:48:13.297886: step 82120, loss = 0.53, batch loss = 0.35 (32.2 examples/sec; 0.249 sec/batch; 17h:18m:01s remains)
INFO - root - 2017-12-16 19:48:15.510527: step 82130, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 15h:15m:46s remains)
INFO - root - 2017-12-16 19:48:17.698528: step 82140, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 15h:15m:33s remains)
INFO - root - 2017-12-16 19:48:19.915582: step 82150, loss = 0.56, batch loss = 0.39 (35.2 examples/sec; 0.227 sec/batch; 15h:47m:02s remains)
INFO - root - 2017-12-16 19:48:22.143928: step 82160, loss = 0.46, batch loss = 0.28 (34.2 examples/sec; 0.234 sec/batch; 16h:15m:51s remains)
INFO - root - 2017-12-16 19:48:24.375707: step 82170, loss = 0.41, batch loss = 0.23 (34.9 examples/sec; 0.229 sec/batch; 15h:57m:27s remains)
INFO - root - 2017-12-16 19:48:26.596506: step 82180, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 14h:55m:39s remains)
INFO - root - 2017-12-16 19:48:28.811297: step 82190, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 15h:31m:42s remains)
INFO - root - 2017-12-16 19:48:31.047829: step 82200, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 15h:30m:43s remains)
INFO - root - 2017-12-16 19:48:33.350925: step 82210, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 15h:46m:35s remains)
INFO - root - 2017-12-16 19:48:35.552364: step 82220, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 15h:50m:54s remains)
INFO - root - 2017-12-16 19:48:37.790991: step 82230, loss = 0.51, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 15h:47m:05s remains)
INFO - root - 2017-12-16 19:48:39.994318: step 82240, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 14h:46m:02s remains)
INFO - root - 2017-12-16 19:48:42.182239: step 82250, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 15h:04m:43s remains)
INFO - root - 2017-12-16 19:48:44.409023: step 82260, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 15h:12m:44s remains)
INFO - root - 2017-12-16 19:48:46.629165: step 82270, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 15h:13m:21s remains)
INFO - root - 2017-12-16 19:48:48.833653: step 82280, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 15h:25m:55s remains)
INFO - root - 2017-12-16 19:48:51.019867: step 82290, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 15h:16m:10s remains)
INFO - root - 2017-12-16 19:48:53.272027: step 82300, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 15h:55m:00s remains)
INFO - root - 2017-12-16 19:48:55.592988: step 82310, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 15h:21m:00s remains)
INFO - root - 2017-12-16 19:48:57.788811: step 82320, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 15h:52m:05s remains)
INFO - root - 2017-12-16 19:49:00.008270: step 82330, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 15h:44m:49s remains)
INFO - root - 2017-12-16 19:49:02.262572: step 82340, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 15h:30m:35s remains)
INFO - root - 2017-12-16 19:49:04.460016: step 82350, loss = 0.55, batch loss = 0.37 (35.8 examples/sec; 0.224 sec/batch; 15h:31m:52s remains)
INFO - root - 2017-12-16 19:49:06.721396: step 82360, loss = 0.48, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 15h:41m:08s remains)
INFO - root - 2017-12-16 19:49:09.008227: step 82370, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 15h:48m:15s remains)
INFO - root - 2017-12-16 19:49:11.240154: step 82380, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 15h:09m:00s remains)
INFO - root - 2017-12-16 19:49:13.463721: step 82390, loss = 0.43, batch loss = 0.25 (37.0 examples/sec; 0.216 sec/batch; 15h:00m:20s remains)
INFO - root - 2017-12-16 19:49:15.669465: step 82400, loss = 0.43, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 15h:09m:34s remains)
INFO - root - 2017-12-16 19:49:18.025169: step 82410, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 15h:23m:22s remains)
INFO - root - 2017-12-16 19:49:20.250056: step 82420, loss = 0.49, batch loss = 0.31 (34.0 examples/sec; 0.235 sec/batch; 16h:20m:02s remains)
INFO - root - 2017-12-16 19:49:22.490778: step 82430, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 16h:06m:48s remains)
INFO - root - 2017-12-16 19:49:24.707380: step 82440, loss = 0.54, batch loss = 0.36 (34.4 examples/sec; 0.233 sec/batch; 16h:09m:34s remains)
INFO - root - 2017-12-16 19:49:26.995348: step 82450, loss = 0.52, batch loss = 0.34 (34.4 examples/sec; 0.233 sec/batch; 16h:09m:02s remains)
INFO - root - 2017-12-16 19:49:29.208526: step 82460, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 15h:34m:23s remains)
INFO - root - 2017-12-16 19:49:31.411103: step 82470, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 14h:56m:07s remains)
INFO - root - 2017-12-16 19:49:33.644204: step 82480, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 16h:03m:46s remains)
INFO - root - 2017-12-16 19:49:35.888096: step 82490, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 15h:02m:46s remains)
INFO - root - 2017-12-16 19:49:38.129862: step 82500, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 15h:35m:46s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-82500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-82500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 19:49:40.866514: step 82510, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.215 sec/batch; 14h:57m:41s remains)
INFO - root - 2017-12-16 19:49:43.083416: step 82520, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 16h:03m:33s remains)
INFO - root - 2017-12-16 19:49:45.298135: step 82530, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 15h:17m:23s remains)
INFO - root - 2017-12-16 19:49:47.497769: step 82540, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 15h:21m:43s remains)
INFO - root - 2017-12-16 19:49:49.758910: step 82550, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 15h:32m:08s remains)
INFO - root - 2017-12-16 19:49:51.977089: step 82560, loss = 0.45, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 15h:21m:47s remains)
INFO - root - 2017-12-16 19:49:54.226440: step 82570, loss = 0.48, batch loss = 0.30 (34.3 examples/sec; 0.233 sec/batch; 16h:11m:33s remains)
INFO - root - 2017-12-16 19:49:56.431126: step 82580, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 15h:15m:45s remains)
INFO - root - 2017-12-16 19:49:58.656360: step 82590, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:16m:38s remains)
INFO - root - 2017-12-16 19:50:00.898411: step 82600, loss = 0.47, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 15h:36m:58s remains)
INFO - root - 2017-12-16 19:50:03.260362: step 82610, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 15h:12m:19s remains)
INFO - root - 2017-12-16 19:50:05.513215: step 82620, loss = 0.42, batch loss = 0.24 (35.4 examples/sec; 0.226 sec/batch; 15h:40m:58s remains)
INFO - root - 2017-12-16 19:50:07.764731: step 82630, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 15h:45m:35s remains)
INFO - root - 2017-12-16 19:50:09.993236: step 82640, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 15h:33m:16s remains)
INFO - root - 2017-12-16 19:50:12.233950: step 82650, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 14h:57m:08s remains)
INFO - root - 2017-12-16 19:50:14.481155: step 82660, loss = 0.48, batch loss = 0.30 (34.3 examples/sec; 0.233 sec/batch; 16h:10m:07s remains)
INFO - root - 2017-12-16 19:50:16.736031: step 82670, loss = 0.53, batch loss = 0.35 (34.9 examples/sec; 0.229 sec/batch; 15h:55m:01s remains)
INFO - root - 2017-12-16 19:50:18.954283: step 82680, loss = 0.60, batch loss = 0.42 (35.5 examples/sec; 0.225 sec/batch; 15h:38m:26s remains)
INFO - root - 2017-12-16 19:50:21.143182: step 82690, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 15h:12m:53s remains)
INFO - root - 2017-12-16 19:50:23.406683: step 82700, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 15h:58m:14s remains)
INFO - root - 2017-12-16 19:50:25.763280: step 82710, loss = 0.45, batch loss = 0.27 (34.8 examples/sec; 0.230 sec/batch; 15h:55m:50s remains)
INFO - root - 2017-12-16 19:50:28.000689: step 82720, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.218 sec/batch; 15h:05m:27s remains)
INFO - root - 2017-12-16 19:50:30.230590: step 82730, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 15h:11m:46s remains)
INFO - root - 2017-12-16 19:50:32.454352: step 82740, loss = 0.47, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 15h:16m:46s remains)
INFO - root - 2017-12-16 19:50:34.656511: step 82750, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.218 sec/batch; 15h:08m:46s remains)
INFO - root - 2017-12-16 19:50:36.817877: step 82760, loss = 0.44, batch loss = 0.26 (37.5 examples/sec; 0.213 sec/batch; 14h:48m:22s remains)
INFO - root - 2017-12-16 19:50:39.087330: step 82770, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 15h:10m:50s remains)
INFO - root - 2017-12-16 19:50:41.301262: step 82780, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 14h:57m:31s remains)
INFO - root - 2017-12-16 19:50:43.526885: step 82790, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 15h:30m:36s remains)
INFO - root - 2017-12-16 19:50:45.747796: step 82800, loss = 0.56, batch loss = 0.38 (35.8 examples/sec; 0.223 sec/batch; 15h:29m:58s remains)
INFO - root - 2017-12-16 19:50:48.073257: step 82810, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 15h:13m:32s remains)
INFO - root - 2017-12-16 19:50:50.267874: step 82820, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 15h:13m:54s remains)
INFO - root - 2017-12-16 19:50:52.486484: step 82830, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.226 sec/batch; 15h:41m:48s remains)
INFO - root - 2017-12-16 19:50:54.659160: step 82840, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 14h:50m:54s remains)
INFO - root - 2017-12-16 19:50:56.901933: step 82850, loss = 0.56, batch loss = 0.38 (36.1 examples/sec; 0.221 sec/batch; 15h:21m:00s remains)
INFO - root - 2017-12-16 19:50:59.126787: step 82860, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 14h:59m:01s remains)
INFO - root - 2017-12-16 19:51:01.354618: step 82870, loss = 0.52, batch loss = 0.34 (34.4 examples/sec; 0.232 sec/batch; 16h:06m:42s remains)
INFO - root - 2017-12-16 19:51:03.569799: step 82880, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 14h:47m:30s remains)
INFO - root - 2017-12-16 19:51:06.145061: step 82890, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 15h:27m:29s remains)
INFO - root - 2017-12-16 19:51:08.341073: step 82900, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 15h:09m:01s remains)
INFO - root - 2017-12-16 19:51:10.690650: step 82910, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 15h:06m:04s remains)
INFO - root - 2017-12-16 19:51:12.897388: step 82920, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 15h:47m:38s remains)
INFO - root - 2017-12-16 19:51:15.122083: step 82930, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 14h:59m:34s remains)
INFO - root - 2017-12-16 19:51:17.358595: step 82940, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 15h:29m:59s remains)
INFO - root - 2017-12-16 19:51:19.607067: step 82950, loss = 0.53, batch loss = 0.35 (35.4 examples/sec; 0.226 sec/batch; 15h:40m:43s remains)
INFO - root - 2017-12-16 19:51:21.807970: step 82960, loss = 0.57, batch loss = 0.40 (36.6 examples/sec; 0.219 sec/batch; 15h:09m:15s remains)
INFO - root - 2017-12-16 19:51:24.067078: step 82970, loss = 0.48, batch loss = 0.30 (34.2 examples/sec; 0.234 sec/batch; 16h:12m:23s remains)
INFO - root - 2017-12-16 19:51:26.285790: step 82980, loss = 0.47, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 15h:52m:25s remains)
INFO - root - 2017-12-16 19:51:28.488892: step 82990, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 15h:36m:13s remains)
INFO - root - 2017-12-16 19:51:30.710975: step 83000, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 15h:46m:52s remains)
INFO - root - 2017-12-16 19:51:33.070398: step 83010, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 15h:39m:56s remains)
INFO - root - 2017-12-16 19:51:35.323179: step 83020, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 15h:13m:37s remains)
INFO - root - 2017-12-16 19:51:37.563675: step 83030, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 15h:13m:10s remains)
INFO - root - 2017-12-16 19:51:39.770397: step 83040, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 15h:27m:53s remains)
INFO - root - 2017-12-16 19:51:41.968184: step 83050, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 15h:29m:00s remains)
INFO - root - 2017-12-16 19:51:44.163561: step 83060, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 15h:47m:30s remains)
INFO - root - 2017-12-16 19:51:46.385727: step 83070, loss = 0.47, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 15h:12m:14s remains)
INFO - root - 2017-12-16 19:51:48.619653: step 83080, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 15h:16m:22s remains)
INFO - root - 2017-12-16 19:51:50.876781: step 83090, loss = 0.43, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 15h:52m:15s remains)
INFO - root - 2017-12-16 19:51:53.099118: step 83100, loss = 0.48, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 15h:30m:17s remains)
INFO - root - 2017-12-16 19:51:55.436748: step 83110, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 15h:05m:29s remains)
INFO - root - 2017-12-16 19:51:57.640756: step 83120, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.228 sec/batch; 15h:49m:22s remains)
INFO - root - 2017-12-16 19:51:59.868779: step 83130, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 14h:59m:12s remains)
INFO - root - 2017-12-16 19:52:02.094582: step 83140, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 15h:05m:23s remains)
INFO - root - 2017-12-16 19:52:04.358330: step 83150, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.232 sec/batch; 16h:05m:30s remains)
INFO - root - 2017-12-16 19:52:06.574721: step 83160, loss = 0.47, batch loss = 0.30 (37.8 examples/sec; 0.212 sec/batch; 14h:39m:08s remains)
INFO - root - 2017-12-16 19:52:08.777539: step 83170, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 15h:15m:51s remains)
INFO - root - 2017-12-16 19:52:11.022358: step 83180, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 15h:11m:46s remains)
INFO - root - 2017-12-16 19:52:13.238359: step 83190, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 15h:36m:35s remains)
INFO - root - 2017-12-16 19:52:15.449682: step 83200, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 15h:24m:40s remains)
INFO - root - 2017-12-16 19:52:17.795042: step 83210, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 15h:27m:41s remains)
INFO - root - 2017-12-16 19:52:20.010902: step 83220, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 14h:53m:52s remains)
INFO - root - 2017-12-16 19:52:22.233636: step 83230, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 15h:46m:53s remains)
INFO - root - 2017-12-16 19:52:24.446692: step 83240, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 15h:06m:27s remains)
INFO - root - 2017-12-16 19:52:26.677588: step 83250, loss = 0.53, batch loss = 0.36 (36.2 examples/sec; 0.221 sec/batch; 15h:18m:22s remains)
INFO - root - 2017-12-16 19:52:28.898520: step 83260, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 15h:37m:15s remains)
INFO - root - 2017-12-16 19:52:31.113785: step 83270, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 15h:35m:05s remains)
INFO - root - 2017-12-16 19:52:33.342518: step 83280, loss = 0.51, batch loss = 0.33 (35.0 examples/sec; 0.229 sec/batch; 15h:50m:23s remains)
INFO - root - 2017-12-16 19:52:35.547155: step 83290, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 14h:58m:27s remains)
INFO - root - 2017-12-16 19:52:37.768744: step 83300, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 15h:00m:51s remains)
INFO - root - 2017-12-16 19:52:40.134495: step 83310, loss = 0.42, batch loss = 0.25 (37.3 examples/sec; 0.215 sec/batch; 14h:51m:06s remains)
INFO - root - 2017-12-16 19:52:42.345650: step 83320, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 15h:17m:11s remains)
INFO - root - 2017-12-16 19:52:44.569195: step 83330, loss = 0.42, batch loss = 0.24 (35.6 examples/sec; 0.225 sec/batch; 15h:32m:55s remains)
INFO - root - 2017-12-16 19:52:46.784698: step 83340, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 14h:54m:41s remains)
INFO - root - 2017-12-16 19:52:48.999830: step 83350, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 15h:47m:39s remains)
INFO - root - 2017-12-16 19:52:51.194218: step 83360, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 15h:08m:26s remains)
INFO - root - 2017-12-16 19:52:53.423699: step 83370, loss = 0.53, batch loss = 0.35 (34.5 examples/sec; 0.232 sec/batch; 16h:04m:04s remains)
INFO - root - 2017-12-16 19:52:55.639154: step 83380, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 15h:06m:17s remains)
INFO - root - 2017-12-16 19:52:57.861825: step 83390, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 14h:56m:55s remains)
INFO - root - 2017-12-16 19:53:00.051998: step 83400, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 15h:03m:39s remains)
INFO - root - 2017-12-16 19:53:02.389649: step 83410, loss = 0.57, batch loss = 0.39 (36.6 examples/sec; 0.218 sec/batch; 15h:06m:33s remains)
INFO - root - 2017-12-16 19:53:04.562599: step 83420, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 16h:02m:56s remains)
INFO - root - 2017-12-16 19:53:06.753823: step 83430, loss = 0.55, batch loss = 0.38 (36.5 examples/sec; 0.219 sec/batch; 15h:11m:04s remains)
INFO - root - 2017-12-16 19:53:08.985114: step 83440, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 15h:02m:55s remains)
INFO - root - 2017-12-16 19:53:11.185748: step 83450, loss = 0.59, batch loss = 0.41 (36.7 examples/sec; 0.218 sec/batch; 15h:05m:40s remains)
INFO - root - 2017-12-16 19:53:13.405216: step 83460, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 15h:51m:29s remains)
INFO - root - 2017-12-16 19:53:15.616331: step 83470, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 14h:56m:53s remains)
INFO - root - 2017-12-16 19:53:17.822082: step 83480, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 14h:52m:41s remains)
INFO - root - 2017-12-16 19:53:20.032305: step 83490, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 15h:13m:50s remains)
INFO - root - 2017-12-16 19:53:22.222407: step 83500, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 15h:06m:03s remains)
INFO - root - 2017-12-16 19:53:24.586319: step 83510, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 15h:22m:58s remains)
INFO - root - 2017-12-16 19:53:26.772048: step 83520, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 15h:41m:15s remains)
INFO - root - 2017-12-16 19:53:28.954974: step 83530, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 15h:10m:51s remains)
INFO - root - 2017-12-16 19:53:31.162229: step 83540, loss = 0.45, batch loss = 0.27 (37.6 examples/sec; 0.213 sec/batch; 14h:43m:26s remains)
INFO - root - 2017-12-16 19:53:33.408202: step 83550, loss = 0.57, batch loss = 0.39 (36.7 examples/sec; 0.218 sec/batch; 15h:04m:33s remains)
INFO - root - 2017-12-16 19:53:35.620049: step 83560, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 15h:25m:00s remains)
INFO - root - 2017-12-16 19:53:37.838127: step 83570, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 15h:27m:46s remains)
INFO - root - 2017-12-16 19:53:40.059011: step 83580, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.214 sec/batch; 14h:49m:17s remains)
INFO - root - 2017-12-16 19:53:42.238822: step 83590, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 15h:17m:34s remains)
INFO - root - 2017-12-16 19:53:44.390289: step 83600, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 14h:59m:28s remains)
INFO - root - 2017-12-16 19:53:46.724706: step 83610, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 14h:55m:32s remains)
INFO - root - 2017-12-16 19:53:48.958096: step 83620, loss = 0.55, batch loss = 0.37 (35.6 examples/sec; 0.225 sec/batch; 15h:32m:34s remains)
INFO - root - 2017-12-16 19:53:51.165770: step 83630, loss = 0.52, batch loss = 0.34 (34.8 examples/sec; 0.230 sec/batch; 15h:53m:55s remains)
INFO - root - 2017-12-16 19:53:53.375870: step 83640, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 15h:18m:43s remains)
INFO - root - 2017-12-16 19:53:55.579509: step 83650, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 15h:17m:00s remains)
INFO - root - 2017-12-16 19:53:57.751451: step 83660, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:10m:29s remains)
INFO - root - 2017-12-16 19:53:59.955171: step 83670, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 15h:28m:01s remains)
INFO - root - 2017-12-16 19:54:02.156013: step 83680, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 14h:57m:04s remains)
INFO - root - 2017-12-16 19:54:04.400565: step 83690, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 15h:06m:32s remains)
INFO - root - 2017-12-16 19:54:06.621086: step 83700, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 15h:09m:33s remains)
INFO - root - 2017-12-16 19:54:08.985376: step 83710, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 14h:58m:44s remains)
INFO - root - 2017-12-16 19:54:11.169281: step 83720, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 15h:13m:00s remains)
INFO - root - 2017-12-16 19:54:13.367385: step 83730, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 15h:33m:00s remains)
INFO - root - 2017-12-16 19:54:15.582422: step 83740, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 15h:32m:04s remains)
INFO - root - 2017-12-16 19:54:17.815100: step 83750, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 15h:29m:53s remains)
INFO - root - 2017-12-16 19:54:20.012155: step 83760, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 15h:09m:08s remains)
INFO - root - 2017-12-16 19:54:22.200824: step 83770, loss = 0.47, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 14h:49m:30s remains)
INFO - root - 2017-12-16 19:54:24.417241: step 83780, loss = 0.56, batch loss = 0.39 (36.5 examples/sec; 0.219 sec/batch; 15h:09m:16s remains)
INFO - root - 2017-12-16 19:54:26.653451: step 83790, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 15h:23m:53s remains)
INFO - root - 2017-12-16 19:54:28.867693: step 83800, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 15h:17m:36s remains)
INFO - root - 2017-12-16 19:54:31.221620: step 83810, loss = 0.52, batch loss = 0.34 (34.8 examples/sec; 0.230 sec/batch; 15h:52m:11s remains)
INFO - root - 2017-12-16 19:54:33.407110: step 83820, loss = 0.56, batch loss = 0.38 (37.3 examples/sec; 0.214 sec/batch; 14h:47m:59s remains)
INFO - root - 2017-12-16 19:54:35.648429: step 83830, loss = 0.43, batch loss = 0.25 (35.0 examples/sec; 0.228 sec/batch; 15h:46m:00s remains)
INFO - root - 2017-12-16 19:54:37.817070: step 83840, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 14h:40m:29s remains)
INFO - root - 2017-12-16 19:54:40.013510: step 83850, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 14h:52m:17s remains)
INFO - root - 2017-12-16 19:54:42.245833: step 83860, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 14h:56m:34s remains)
INFO - root - 2017-12-16 19:54:44.439330: step 83870, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 14h:56m:05s remains)
INFO - root - 2017-12-16 19:54:46.617573: step 83880, loss = 0.51, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 15h:10m:29s remains)
INFO - root - 2017-12-16 19:54:48.798437: step 83890, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 14h:50m:51s remains)
INFO - root - 2017-12-16 19:54:51.002647: step 83900, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 15h:31m:21s remains)
INFO - root - 2017-12-16 19:54:53.368834: step 83910, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 15h:31m:23s remains)
INFO - root - 2017-12-16 19:54:55.593298: step 83920, loss = 0.51, batch loss = 0.33 (34.0 examples/sec; 0.236 sec/batch; 16h:16m:09s remains)
INFO - root - 2017-12-16 19:54:57.805814: step 83930, loss = 0.48, batch loss = 0.30 (38.5 examples/sec; 0.208 sec/batch; 14h:19m:59s remains)
INFO - root - 2017-12-16 19:54:59.994831: step 83940, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 15h:32m:45s remains)
INFO - root - 2017-12-16 19:55:02.214335: step 83950, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 14h:55m:02s remains)
INFO - root - 2017-12-16 19:55:04.402880: step 83960, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.218 sec/batch; 15h:04m:57s remains)
INFO - root - 2017-12-16 19:55:06.628129: step 83970, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.224 sec/batch; 15h:29m:45s remains)
INFO - root - 2017-12-16 19:55:08.834955: step 83980, loss = 0.44, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 15h:24m:01s remains)
INFO - root - 2017-12-16 19:55:11.035054: step 83990, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 15h:31m:04s remains)
INFO - root - 2017-12-16 19:55:13.250955: step 84000, loss = 0.44, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 15h:16m:55s remains)
INFO - root - 2017-12-16 19:55:15.625777: step 84010, loss = 0.47, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 15h:02m:26s remains)
INFO - root - 2017-12-16 19:55:17.839911: step 84020, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 15h:03m:56s remains)
INFO - root - 2017-12-16 19:55:20.034380: step 84030, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 15h:26m:25s remains)
INFO - root - 2017-12-16 19:55:22.225216: step 84040, loss = 0.43, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 14h:56m:22s remains)
INFO - root - 2017-12-16 19:55:24.455850: step 84050, loss = 0.50, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 15h:21m:16s remains)
INFO - root - 2017-12-16 19:55:26.648770: step 84060, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 14h:53m:51s remains)
INFO - root - 2017-12-16 19:55:28.854957: step 84070, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 15h:18m:41s remains)
INFO - root - 2017-12-16 19:55:31.082480: step 84080, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 15h:02m:34s remains)
INFO - root - 2017-12-16 19:55:33.273474: step 84090, loss = 0.44, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 15h:09m:19s remains)
INFO - root - 2017-12-16 19:55:35.479902: step 84100, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 15h:42m:22s remains)
INFO - root - 2017-12-16 19:55:37.815210: step 84110, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 14h:44m:56s remains)
INFO - root - 2017-12-16 19:55:40.069241: step 84120, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 15h:22m:15s remains)
INFO - root - 2017-12-16 19:55:42.252486: step 84130, loss = 0.45, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 14h:39m:58s remains)
INFO - root - 2017-12-16 19:55:44.458222: step 84140, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 14h:58m:46s remains)
INFO - root - 2017-12-16 19:55:46.674133: step 84150, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 15h:23m:31s remains)
INFO - root - 2017-12-16 19:55:48.853119: step 84160, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 14h:59m:54s remains)
INFO - root - 2017-12-16 19:55:51.040848: step 84170, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 14h:51m:44s remains)
INFO - root - 2017-12-16 19:55:53.264331: step 84180, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.228 sec/batch; 15h:41m:53s remains)
INFO - root - 2017-12-16 19:55:55.470556: step 84190, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 14h:39m:58s remains)
INFO - root - 2017-12-16 19:55:57.651951: step 84200, loss = 0.57, batch loss = 0.39 (36.9 examples/sec; 0.217 sec/batch; 14h:56m:04s remains)
INFO - root - 2017-12-16 19:55:59.986442: step 84210, loss = 0.47, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 14h:55m:23s remains)
INFO - root - 2017-12-16 19:56:02.184009: step 84220, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 15h:11m:39s remains)
INFO - root - 2017-12-16 19:56:04.419792: step 84230, loss = 0.45, batch loss = 0.28 (33.9 examples/sec; 0.236 sec/batch; 16h:16m:40s remains)
INFO - root - 2017-12-16 19:56:06.628335: step 84240, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.219 sec/batch; 15h:04m:07s remains)
INFO - root - 2017-12-16 19:56:08.837890: step 84250, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 14h:59m:28s remains)
INFO - root - 2017-12-16 19:56:11.078074: step 84260, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 15h:16m:04s remains)
INFO - root - 2017-12-16 19:56:13.297196: step 84270, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 15h:15m:35s remains)
INFO - root - 2017-12-16 19:56:15.489580: step 84280, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 14h:45m:53s remains)
INFO - root - 2017-12-16 19:56:17.714027: step 84290, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 14h:48m:48s remains)
INFO - root - 2017-12-16 19:56:19.936291: step 84300, loss = 0.55, batch loss = 0.37 (35.7 examples/sec; 0.224 sec/batch; 15h:26m:37s remains)
INFO - root - 2017-12-16 19:56:22.279937: step 84310, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 15h:28m:57s remains)
INFO - root - 2017-12-16 19:56:24.478560: step 84320, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 15h:29m:11s remains)
INFO - root - 2017-12-16 19:56:26.683340: step 84330, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 15h:12m:42s remains)
INFO - root - 2017-12-16 19:56:28.909298: step 84340, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 15h:36m:33s remains)
INFO - root - 2017-12-16 19:56:31.143766: step 84350, loss = 0.62, batch loss = 0.44 (35.5 examples/sec; 0.225 sec/batch; 15h:31m:38s remains)
INFO - root - 2017-12-16 19:56:33.359305: step 84360, loss = 0.44, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 14h:39m:02s remains)
INFO - root - 2017-12-16 19:56:35.576525: step 84370, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 14h:48m:18s remains)
INFO - root - 2017-12-16 19:56:37.773161: step 84380, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 14h:46m:38s remains)
INFO - root - 2017-12-16 19:56:40.037006: step 84390, loss = 0.52, batch loss = 0.35 (35.0 examples/sec; 0.229 sec/batch; 15h:45m:02s remains)
INFO - root - 2017-12-16 19:56:42.203848: step 84400, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 15h:01m:29s remains)
INFO - root - 2017-12-16 19:56:44.558755: step 84410, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 14h:58m:25s remains)
INFO - root - 2017-12-16 19:56:46.759586: step 84420, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 15h:19m:05s remains)
INFO - root - 2017-12-16 19:56:48.963660: step 84430, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.216 sec/batch; 14h:51m:40s remains)
INFO - root - 2017-12-16 19:56:51.193696: step 84440, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 14h:59m:09s remains)
INFO - root - 2017-12-16 19:56:53.437587: step 84450, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 15h:21m:40s remains)
INFO - root - 2017-12-16 19:56:55.665119: step 84460, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 15h:08m:15s remains)
INFO - root - 2017-12-16 19:56:57.895894: step 84470, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 14h:49m:40s remains)
INFO - root - 2017-12-16 19:57:00.073067: step 84480, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.215 sec/batch; 14h:50m:14s remains)
INFO - root - 2017-12-16 19:57:02.301998: step 84490, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 15h:01m:12s remains)
INFO - root - 2017-12-16 19:57:04.499401: step 84500, loss = 0.43, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 15h:06m:07s remains)
INFO - root - 2017-12-16 19:57:06.840696: step 84510, loss = 0.42, batch loss = 0.25 (36.6 examples/sec; 0.218 sec/batch; 15h:03m:00s remains)
INFO - root - 2017-12-16 19:57:09.030679: step 84520, loss = 0.46, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 15h:29m:40s remains)
INFO - root - 2017-12-16 19:57:11.222569: step 84530, loss = 0.45, batch loss = 0.27 (34.6 examples/sec; 0.231 sec/batch; 15h:55m:21s remains)
INFO - root - 2017-12-16 19:57:13.466584: step 84540, loss = 0.45, batch loss = 0.27 (34.3 examples/sec; 0.234 sec/batch; 16h:04m:59s remains)
INFO - root - 2017-12-16 19:57:15.689062: step 84550, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 15h:26m:29s remains)
INFO - root - 2017-12-16 19:57:17.903862: step 84560, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 15h:32m:14s remains)
INFO - root - 2017-12-16 19:57:20.117857: step 84570, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 15h:12m:00s remains)
INFO - root - 2017-12-16 19:57:22.364063: step 84580, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 15h:22m:35s remains)
INFO - root - 2017-12-16 19:57:24.573812: step 84590, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 15h:31m:34s remains)
INFO - root - 2017-12-16 19:57:26.772579: step 84600, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 15h:32m:36s remains)
INFO - root - 2017-12-16 19:57:29.119142: step 84610, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 14h:48m:34s remains)
INFO - root - 2017-12-16 19:57:31.361153: step 84620, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 15h:24m:25s remains)
INFO - root - 2017-12-16 19:57:33.567739: step 84630, loss = 0.48, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 15h:13m:05s remains)
INFO - root - 2017-12-16 19:57:35.770549: step 84640, loss = 0.47, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 14h:57m:19s remains)
INFO - root - 2017-12-16 19:57:37.966875: step 84650, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 15h:30m:34s remains)
INFO - root - 2017-12-16 19:57:40.171645: step 84660, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 15h:04m:07s remains)
INFO - root - 2017-12-16 19:57:42.390776: step 84670, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 15h:03m:52s remains)
INFO - root - 2017-12-16 19:57:44.581808: step 84680, loss = 0.56, batch loss = 0.39 (36.1 examples/sec; 0.222 sec/batch; 15h:15m:05s remains)
INFO - root - 2017-12-16 19:57:46.805895: step 84690, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 14h:53m:53s remains)
INFO - root - 2017-12-16 19:57:49.035635: step 84700, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 14h:54m:00s remains)
INFO - root - 2017-12-16 19:57:51.419919: step 84710, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 15h:26m:09s remains)
INFO - root - 2017-12-16 19:57:53.665473: step 84720, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 15h:13m:28s remains)
INFO - root - 2017-12-16 19:57:55.875655: step 84730, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 15h:04m:19s remains)
INFO - root - 2017-12-16 19:57:58.090698: step 84740, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 15h:04m:29s remains)
INFO - root - 2017-12-16 19:58:00.308936: step 84750, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 15h:16m:35s remains)
INFO - root - 2017-12-16 19:58:02.529741: step 84760, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 15h:00m:59s remains)
INFO - root - 2017-12-16 19:58:04.762041: step 84770, loss = 0.48, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 15h:33m:37s remains)
INFO - root - 2017-12-16 19:58:06.980604: step 84780, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 15h:05m:46s remains)
INFO - root - 2017-12-16 19:58:09.172844: step 84790, loss = 0.45, batch loss = 0.27 (37.8 examples/sec; 0.212 sec/batch; 14h:34m:11s remains)
INFO - root - 2017-12-16 19:58:11.392875: step 84800, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 15h:12m:43s remains)
INFO - root - 2017-12-16 19:58:13.730840: step 84810, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 15h:31m:44s remains)
INFO - root - 2017-12-16 19:58:15.911955: step 84820, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 14h:56m:13s remains)
INFO - root - 2017-12-16 19:58:18.138154: step 84830, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 15h:28m:04s remains)
INFO - root - 2017-12-16 19:58:20.396153: step 84840, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 15h:24m:54s remains)
INFO - root - 2017-12-16 19:58:22.651724: step 84850, loss = 0.49, batch loss = 0.32 (34.0 examples/sec; 0.235 sec/batch; 16h:10m:56s remains)
INFO - root - 2017-12-16 19:58:24.866636: step 84860, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 15h:14m:26s remains)
INFO - root - 2017-12-16 19:58:27.095901: step 84870, loss = 0.56, batch loss = 0.38 (35.1 examples/sec; 0.228 sec/batch; 15h:41m:40s remains)
INFO - root - 2017-12-16 19:58:29.316534: step 84880, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 15h:14m:35s remains)
INFO - root - 2017-12-16 19:58:31.547821: step 84890, loss = 0.42, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 15h:18m:54s remains)
INFO - root - 2017-12-16 19:58:33.745986: step 84900, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 14h:50m:12s remains)
INFO - root - 2017-12-16 19:58:36.088310: step 84910, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 15h:19m:45s remains)
INFO - root - 2017-12-16 19:58:38.308371: step 84920, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 15h:21m:01s remains)
INFO - root - 2017-12-16 19:58:40.508574: step 84930, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 15h:04m:50s remains)
INFO - root - 2017-12-16 19:58:42.736350: step 84940, loss = 0.49, batch loss = 0.31 (37.8 examples/sec; 0.212 sec/batch; 14h:32m:54s remains)
INFO - root - 2017-12-16 19:58:44.973907: step 84950, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 14h:35m:59s remains)
INFO - root - 2017-12-16 19:58:47.153465: step 84960, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 15h:16m:04s remains)
INFO - root - 2017-12-16 19:58:49.364376: step 84970, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 14h:47m:12s remains)
INFO - root - 2017-12-16 19:58:51.601941: step 84980, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 15h:13m:16s remains)
INFO - root - 2017-12-16 19:58:53.812156: step 84990, loss = 0.48, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 15h:15m:56s remains)
INFO - root - 2017-12-16 19:58:56.072011: step 85000, loss = 0.49, batch loss = 0.32 (33.7 examples/sec; 0.238 sec/batch; 16h:20m:39s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-85000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-85000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 19:58:58.852270: step 85010, loss = 0.51, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 15h:07m:23s remains)
INFO - root - 2017-12-16 19:59:01.057960: step 85020, loss = 0.45, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 15h:34m:20s remains)
INFO - root - 2017-12-16 19:59:03.261006: step 85030, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 15h:21m:23s remains)
INFO - root - 2017-12-16 19:59:05.474674: step 85040, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 15h:21m:57s remains)
INFO - root - 2017-12-16 19:59:07.679346: step 85050, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 15h:24m:49s remains)
INFO - root - 2017-12-16 19:59:09.871983: step 85060, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 15h:27m:18s remains)
INFO - root - 2017-12-16 19:59:12.119811: step 85070, loss = 0.48, batch loss = 0.31 (35.0 examples/sec; 0.229 sec/batch; 15h:42m:22s remains)
INFO - root - 2017-12-16 19:59:14.360009: step 85080, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 15h:15m:34s remains)
INFO - root - 2017-12-16 19:59:16.546461: step 85090, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 14h:40m:58s remains)
INFO - root - 2017-12-16 19:59:18.764465: step 85100, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 15h:14m:04s remains)
INFO - root - 2017-12-16 19:59:21.110180: step 85110, loss = 0.47, batch loss = 0.30 (35.8 examples/sec; 0.224 sec/batch; 15h:22m:36s remains)
INFO - root - 2017-12-16 19:59:23.348868: step 85120, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 15h:16m:48s remains)
INFO - root - 2017-12-16 19:59:25.577582: step 85130, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 15h:17m:45s remains)
INFO - root - 2017-12-16 19:59:27.801372: step 85140, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 15h:26m:20s remains)
INFO - root - 2017-12-16 19:59:30.047736: step 85150, loss = 0.51, batch loss = 0.33 (35.0 examples/sec; 0.229 sec/batch; 15h:43m:01s remains)
INFO - root - 2017-12-16 19:59:32.283239: step 85160, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 14h:52m:20s remains)
INFO - root - 2017-12-16 19:59:34.439898: step 85170, loss = 0.46, batch loss = 0.28 (37.7 examples/sec; 0.212 sec/batch; 14h:35m:30s remains)
INFO - root - 2017-12-16 19:59:36.636305: step 85180, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 15h:01m:41s remains)
INFO - root - 2017-12-16 19:59:38.874837: step 85190, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 15h:14m:31s remains)
INFO - root - 2017-12-16 19:59:41.108527: step 85200, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 15h:17m:55s remains)
INFO - root - 2017-12-16 19:59:43.429445: step 85210, loss = 0.46, batch loss = 0.28 (34.2 examples/sec; 0.234 sec/batch; 16h:02m:49s remains)
INFO - root - 2017-12-16 19:59:45.611942: step 85220, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 15h:16m:58s remains)
INFO - root - 2017-12-16 19:59:47.862129: step 85230, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 15h:05m:08s remains)
INFO - root - 2017-12-16 19:59:50.085628: step 85240, loss = 0.46, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 16h:01m:43s remains)
INFO - root - 2017-12-16 19:59:52.289466: step 85250, loss = 0.50, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 14h:57m:49s remains)
INFO - root - 2017-12-16 19:59:54.536867: step 85260, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 14h:50m:14s remains)
INFO - root - 2017-12-16 19:59:56.773451: step 85270, loss = 0.53, batch loss = 0.36 (35.5 examples/sec; 0.226 sec/batch; 15h:29m:16s remains)
INFO - root - 2017-12-16 19:59:58.986861: step 85280, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 15h:03m:48s remains)
INFO - root - 2017-12-16 20:00:01.179865: step 85290, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 15h:23m:26s remains)
INFO - root - 2017-12-16 20:00:03.411780: step 85300, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 15h:46m:44s remains)
INFO - root - 2017-12-16 20:00:05.742862: step 85310, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 15h:18m:14s remains)
INFO - root - 2017-12-16 20:00:07.974369: step 85320, loss = 0.43, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 15h:17m:14s remains)
INFO - root - 2017-12-16 20:00:10.217894: step 85330, loss = 0.55, batch loss = 0.37 (35.8 examples/sec; 0.223 sec/batch; 15h:19m:39s remains)
INFO - root - 2017-12-16 20:00:12.421214: step 85340, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 14h:52m:44s remains)
INFO - root - 2017-12-16 20:00:14.623105: step 85350, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 15h:00m:21s remains)
INFO - root - 2017-12-16 20:00:16.842014: step 85360, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 15h:13m:25s remains)
INFO - root - 2017-12-16 20:00:19.087018: step 85370, loss = 0.45, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 15h:13m:35s remains)
INFO - root - 2017-12-16 20:00:21.312263: step 85380, loss = 0.46, batch loss = 0.29 (33.4 examples/sec; 0.239 sec/batch; 16h:26m:09s remains)
INFO - root - 2017-12-16 20:00:23.533573: step 85390, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 15h:05m:45s remains)
INFO - root - 2017-12-16 20:00:25.765723: step 85400, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 14h:56m:41s remains)
INFO - root - 2017-12-16 20:00:28.088995: step 85410, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 14h:59m:46s remains)
INFO - root - 2017-12-16 20:00:30.281587: step 85420, loss = 0.41, batch loss = 0.23 (36.2 examples/sec; 0.221 sec/batch; 15h:11m:12s remains)
INFO - root - 2017-12-16 20:00:32.514562: step 85430, loss = 0.42, batch loss = 0.24 (36.4 examples/sec; 0.220 sec/batch; 15h:06m:14s remains)
INFO - root - 2017-12-16 20:00:34.772094: step 85440, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.218 sec/batch; 14h:56m:04s remains)
INFO - root - 2017-12-16 20:00:36.986410: step 85450, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 14h:53m:17s remains)
INFO - root - 2017-12-16 20:00:39.239075: step 85460, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 14h:56m:19s remains)
INFO - root - 2017-12-16 20:00:41.432696: step 85470, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 15h:13m:57s remains)
INFO - root - 2017-12-16 20:00:43.649230: step 85480, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 15h:44m:01s remains)
INFO - root - 2017-12-16 20:00:45.852240: step 85490, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 15h:12m:08s remains)
INFO - root - 2017-12-16 20:00:48.067933: step 85500, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 15h:21m:21s remains)
INFO - root - 2017-12-16 20:00:50.426820: step 85510, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 15h:31m:19s remains)
INFO - root - 2017-12-16 20:00:52.675533: step 85520, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 14h:49m:30s remains)
INFO - root - 2017-12-16 20:00:54.901781: step 85530, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.215 sec/batch; 14h:46m:36s remains)
INFO - root - 2017-12-16 20:00:57.131528: step 85540, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 15h:42m:29s remains)
INFO - root - 2017-12-16 20:00:59.363726: step 85550, loss = 0.49, batch loss = 0.31 (34.7 examples/sec; 0.231 sec/batch; 15h:48m:56s remains)
INFO - root - 2017-12-16 20:01:01.620038: step 85560, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 15h:12m:55s remains)
INFO - root - 2017-12-16 20:01:03.844794: step 85570, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 15h:09m:42s remains)
INFO - root - 2017-12-16 20:01:06.077176: step 85580, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 15h:21m:06s remains)
INFO - root - 2017-12-16 20:01:08.274275: step 85590, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 15h:27m:08s remains)
INFO - root - 2017-12-16 20:01:10.483985: step 85600, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 14h:47m:09s remains)
INFO - root - 2017-12-16 20:01:12.792378: step 85610, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 15h:20m:54s remains)
INFO - root - 2017-12-16 20:01:14.966875: step 85620, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 14h:57m:41s remains)
INFO - root - 2017-12-16 20:01:17.178186: step 85630, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 15h:15m:00s remains)
INFO - root - 2017-12-16 20:01:19.440019: step 85640, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 15h:30m:48s remains)
INFO - root - 2017-12-16 20:01:21.672585: step 85650, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 15h:26m:15s remains)
INFO - root - 2017-12-16 20:01:23.923462: step 85660, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.229 sec/batch; 15h:40m:03s remains)
INFO - root - 2017-12-16 20:01:26.124381: step 85670, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.223 sec/batch; 15h:15m:26s remains)
INFO - root - 2017-12-16 20:01:28.411090: step 85680, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 14h:58m:22s remains)
INFO - root - 2017-12-16 20:01:30.626331: step 85690, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 15h:06m:06s remains)
INFO - root - 2017-12-16 20:01:32.840738: step 85700, loss = 0.47, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 15h:21m:08s remains)
INFO - root - 2017-12-16 20:01:35.212540: step 85710, loss = 0.50, batch loss = 0.33 (37.6 examples/sec; 0.213 sec/batch; 14h:34m:33s remains)
INFO - root - 2017-12-16 20:01:37.467547: step 85720, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 15h:27m:20s remains)
INFO - root - 2017-12-16 20:01:39.700772: step 85730, loss = 0.49, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 14h:54m:28s remains)
INFO - root - 2017-12-16 20:01:41.896982: step 85740, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 15h:06m:32s remains)
INFO - root - 2017-12-16 20:01:44.118695: step 85750, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 14h:46m:04s remains)
INFO - root - 2017-12-16 20:01:46.293696: step 85760, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 15h:00m:48s remains)
INFO - root - 2017-12-16 20:01:48.504812: step 85770, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 15h:34m:59s remains)
INFO - root - 2017-12-16 20:01:50.690216: step 85780, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 14h:55m:32s remains)
INFO - root - 2017-12-16 20:01:52.890684: step 85790, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 15h:00m:02s remains)
INFO - root - 2017-12-16 20:01:55.108843: step 85800, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 15h:10m:48s remains)
INFO - root - 2017-12-16 20:01:57.471968: step 85810, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 15h:23m:53s remains)
INFO - root - 2017-12-16 20:01:59.677215: step 85820, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.218 sec/batch; 14h:54m:27s remains)
INFO - root - 2017-12-16 20:02:01.875001: step 85830, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:02m:43s remains)
INFO - root - 2017-12-16 20:02:04.075657: step 85840, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.215 sec/batch; 14h:45m:20s remains)
INFO - root - 2017-12-16 20:02:06.286325: step 85850, loss = 0.44, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 14h:52m:31s remains)
INFO - root - 2017-12-16 20:02:08.517438: step 85860, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 15h:20m:49s remains)
INFO - root - 2017-12-16 20:02:10.731265: step 85870, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 14h:55m:20s remains)
INFO - root - 2017-12-16 20:02:12.958420: step 85880, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 14h:44m:58s remains)
INFO - root - 2017-12-16 20:02:15.183655: step 85890, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 15h:22m:03s remains)
INFO - root - 2017-12-16 20:02:17.378660: step 85900, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 14h:56m:36s remains)
INFO - root - 2017-12-16 20:02:19.757295: step 85910, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 15h:04m:50s remains)
INFO - root - 2017-12-16 20:02:21.971572: step 85920, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 15h:02m:12s remains)
INFO - root - 2017-12-16 20:02:24.170907: step 85930, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.224 sec/batch; 15h:22m:19s remains)
INFO - root - 2017-12-16 20:02:26.406257: step 85940, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 15h:25m:40s remains)
INFO - root - 2017-12-16 20:02:28.643472: step 85950, loss = 0.56, batch loss = 0.38 (36.2 examples/sec; 0.221 sec/batch; 15h:07m:22s remains)
INFO - root - 2017-12-16 20:02:30.823132: step 85960, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 15h:29m:08s remains)
INFO - root - 2017-12-16 20:02:33.020588: step 85970, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 14h:43m:17s remains)
INFO - root - 2017-12-16 20:02:35.260063: step 85980, loss = 0.46, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 15h:57m:53s remains)
INFO - root - 2017-12-16 20:02:37.496546: step 85990, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 15h:21m:19s remains)
INFO - root - 2017-12-16 20:02:39.769782: step 86000, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 14h:52m:28s remains)
INFO - root - 2017-12-16 20:02:42.080893: step 86010, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 15h:25m:28s remains)
INFO - root - 2017-12-16 20:02:44.261997: step 86020, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 14h:42m:50s remains)
INFO - root - 2017-12-16 20:02:46.505374: step 86030, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.233 sec/batch; 15h:56m:29s remains)
INFO - root - 2017-12-16 20:02:48.722683: step 86040, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 15h:16m:31s remains)
INFO - root - 2017-12-16 20:02:50.924343: step 86050, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 15h:34m:05s remains)
INFO - root - 2017-12-16 20:02:53.125090: step 86060, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 15h:12m:23s remains)
INFO - root - 2017-12-16 20:02:55.340607: step 86070, loss = 0.44, batch loss = 0.27 (33.4 examples/sec; 0.240 sec/batch; 16h:24m:26s remains)
INFO - root - 2017-12-16 20:02:57.576004: step 86080, loss = 0.49, batch loss = 0.31 (34.3 examples/sec; 0.233 sec/batch; 15h:58m:04s remains)
INFO - root - 2017-12-16 20:02:59.792599: step 86090, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 15h:00m:18s remains)
INFO - root - 2017-12-16 20:03:01.993393: step 86100, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 15h:21m:29s remains)
INFO - root - 2017-12-16 20:03:04.425144: step 86110, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 14h:57m:26s remains)
INFO - root - 2017-12-16 20:03:06.635029: step 86120, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 14h:47m:21s remains)
INFO - root - 2017-12-16 20:03:08.884755: step 86130, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.215 sec/batch; 14h:44m:20s remains)
INFO - root - 2017-12-16 20:03:11.075787: step 86140, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 15h:25m:32s remains)
INFO - root - 2017-12-16 20:03:13.307337: step 86150, loss = 0.43, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 15h:00m:25s remains)
INFO - root - 2017-12-16 20:03:15.523390: step 86160, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 14h:51m:11s remains)
INFO - root - 2017-12-16 20:03:17.756411: step 86170, loss = 0.54, batch loss = 0.37 (35.8 examples/sec; 0.223 sec/batch; 15h:16m:55s remains)
INFO - root - 2017-12-16 20:03:19.963979: step 86180, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 15h:01m:53s remains)
INFO - root - 2017-12-16 20:03:22.161396: step 86190, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 15h:05m:50s remains)
INFO - root - 2017-12-16 20:03:24.400816: step 86200, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 14h:58m:57s remains)
INFO - root - 2017-12-16 20:03:26.767779: step 86210, loss = 0.43, batch loss = 0.25 (35.0 examples/sec; 0.229 sec/batch; 15h:39m:11s remains)
INFO - root - 2017-12-16 20:03:28.994533: step 86220, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 15h:01m:43s remains)
INFO - root - 2017-12-16 20:03:31.204280: step 86230, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 15h:10m:58s remains)
INFO - root - 2017-12-16 20:03:33.425298: step 86240, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 15h:09m:19s remains)
INFO - root - 2017-12-16 20:03:35.645733: step 86250, loss = 0.50, batch loss = 0.32 (37.5 examples/sec; 0.213 sec/batch; 14h:36m:04s remains)
INFO - root - 2017-12-16 20:03:37.865105: step 86260, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 14h:54m:09s remains)
INFO - root - 2017-12-16 20:03:40.073502: step 86270, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 15h:14m:53s remains)
INFO - root - 2017-12-16 20:03:42.241541: step 86280, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 14h:37m:08s remains)
INFO - root - 2017-12-16 20:03:44.433523: step 86290, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 15h:04m:48s remains)
INFO - root - 2017-12-16 20:03:46.634230: step 86300, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 14h:43m:16s remains)
INFO - root - 2017-12-16 20:03:48.998738: step 86310, loss = 0.58, batch loss = 0.40 (35.3 examples/sec; 0.227 sec/batch; 15h:29m:23s remains)
INFO - root - 2017-12-16 20:03:51.257590: step 86320, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 15h:48m:35s remains)
INFO - root - 2017-12-16 20:03:53.498011: step 86330, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 14h:59m:59s remains)
INFO - root - 2017-12-16 20:03:55.708435: step 86340, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 14h:55m:07s remains)
INFO - root - 2017-12-16 20:03:57.907276: step 86350, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 15h:08m:54s remains)
INFO - root - 2017-12-16 20:04:00.097306: step 86360, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 15h:06m:33s remains)
INFO - root - 2017-12-16 20:04:02.314708: step 86370, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.216 sec/batch; 14h:45m:22s remains)
INFO - root - 2017-12-16 20:04:04.521746: step 86380, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 14h:58m:21s remains)
INFO - root - 2017-12-16 20:04:06.772378: step 86390, loss = 0.49, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 15h:03m:37s remains)
INFO - root - 2017-12-16 20:04:09.037908: step 86400, loss = 0.44, batch loss = 0.27 (35.0 examples/sec; 0.229 sec/batch; 15h:38m:26s remains)
INFO - root - 2017-12-16 20:04:11.388389: step 86410, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 15h:10m:18s remains)
INFO - root - 2017-12-16 20:04:13.599846: step 86420, loss = 0.52, batch loss = 0.35 (36.3 examples/sec; 0.221 sec/batch; 15h:04m:27s remains)
INFO - root - 2017-12-16 20:04:15.821438: step 86430, loss = 0.48, batch loss = 0.30 (34.0 examples/sec; 0.235 sec/batch; 16h:05m:48s remains)
INFO - root - 2017-12-16 20:04:18.039939: step 86440, loss = 0.47, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 15h:18m:00s remains)
INFO - root - 2017-12-16 20:04:20.248560: step 86450, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 14h:53m:32s remains)
INFO - root - 2017-12-16 20:04:22.457194: step 86460, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 15h:09m:18s remains)
INFO - root - 2017-12-16 20:04:24.697240: step 86470, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 15h:19m:48s remains)
INFO - root - 2017-12-16 20:04:26.929989: step 86480, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 14h:50m:55s remains)
INFO - root - 2017-12-16 20:04:29.173622: step 86490, loss = 0.53, batch loss = 0.35 (34.7 examples/sec; 0.231 sec/batch; 15h:45m:33s remains)
INFO - root - 2017-12-16 20:04:31.428357: step 86500, loss = 0.43, batch loss = 0.25 (37.5 examples/sec; 0.213 sec/batch; 14h:35m:01s remains)
INFO - root - 2017-12-16 20:04:33.784411: step 86510, loss = 0.47, batch loss = 0.29 (33.7 examples/sec; 0.238 sec/batch; 16h:14m:06s remains)
INFO - root - 2017-12-16 20:04:36.021175: step 86520, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 15h:14m:55s remains)
INFO - root - 2017-12-16 20:04:38.222462: step 86530, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 14h:49m:35s remains)
INFO - root - 2017-12-16 20:04:40.457537: step 86540, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 14h:46m:17s remains)
INFO - root - 2017-12-16 20:04:42.672011: step 86550, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 14h:50m:16s remains)
INFO - root - 2017-12-16 20:04:44.882069: step 86560, loss = 0.44, batch loss = 0.26 (37.7 examples/sec; 0.212 sec/batch; 14h:30m:23s remains)
INFO - root - 2017-12-16 20:04:47.085648: step 86570, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 15h:02m:19s remains)
INFO - root - 2017-12-16 20:04:49.293772: step 86580, loss = 0.45, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 14h:59m:53s remains)
INFO - root - 2017-12-16 20:04:51.501188: step 86590, loss = 0.55, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 15h:04m:48s remains)
INFO - root - 2017-12-16 20:04:53.764320: step 86600, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 15h:23m:11s remains)
INFO - root - 2017-12-16 20:04:56.083947: step 86610, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 14h:56m:07s remains)
INFO - root - 2017-12-16 20:04:58.242654: step 86620, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 14h:46m:36s remains)
INFO - root - 2017-12-16 20:05:00.434655: step 86630, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 15h:06m:26s remains)
INFO - root - 2017-12-16 20:05:02.640814: step 86640, loss = 0.43, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 15h:04m:11s remains)
INFO - root - 2017-12-16 20:05:04.845320: step 86650, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 15h:02m:55s remains)
INFO - root - 2017-12-16 20:05:07.040410: step 86660, loss = 0.44, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 14h:56m:15s remains)
INFO - root - 2017-12-16 20:05:09.266245: step 86670, loss = 0.46, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 14h:54m:07s remains)
INFO - root - 2017-12-16 20:05:11.492249: step 86680, loss = 0.61, batch loss = 0.43 (37.1 examples/sec; 0.216 sec/batch; 14h:44m:13s remains)
INFO - root - 2017-12-16 20:05:13.709390: step 86690, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.214 sec/batch; 14h:38m:03s remains)
INFO - root - 2017-12-16 20:05:15.880167: step 86700, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 14h:53m:01s remains)
INFO - root - 2017-12-16 20:05:18.222550: step 86710, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 14h:50m:32s remains)
INFO - root - 2017-12-16 20:05:20.463185: step 86720, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 15h:16m:45s remains)
INFO - root - 2017-12-16 20:05:22.687063: step 86730, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 15h:17m:02s remains)
INFO - root - 2017-12-16 20:05:24.925360: step 86740, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 15h:21m:29s remains)
INFO - root - 2017-12-16 20:05:27.098122: step 86750, loss = 0.44, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 14h:39m:46s remains)
INFO - root - 2017-12-16 20:05:29.289675: step 86760, loss = 0.52, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 15h:33m:52s remains)
INFO - root - 2017-12-16 20:05:31.465757: step 86770, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 14h:34m:03s remains)
INFO - root - 2017-12-16 20:05:33.699256: step 86780, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 14h:53m:20s remains)
INFO - root - 2017-12-16 20:05:35.869084: step 86790, loss = 0.44, batch loss = 0.26 (38.1 examples/sec; 0.210 sec/batch; 14h:20m:33s remains)
INFO - root - 2017-12-16 20:05:38.077028: step 86800, loss = 0.56, batch loss = 0.38 (35.7 examples/sec; 0.224 sec/batch; 15h:17m:19s remains)
INFO - root - 2017-12-16 20:05:40.386878: step 86810, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 14h:50m:24s remains)
INFO - root - 2017-12-16 20:05:42.613042: step 86820, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 15h:09m:01s remains)
INFO - root - 2017-12-16 20:05:44.806978: step 86830, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 15h:01m:30s remains)
INFO - root - 2017-12-16 20:05:46.996123: step 86840, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 14h:49m:04s remains)
INFO - root - 2017-12-16 20:05:49.231983: step 86850, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 14h:46m:49s remains)
INFO - root - 2017-12-16 20:05:51.462412: step 86860, loss = 0.47, batch loss = 0.30 (34.4 examples/sec; 0.232 sec/batch; 15h:51m:18s remains)
INFO - root - 2017-12-16 20:05:53.676749: step 86870, loss = 0.45, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 15h:19m:29s remains)
INFO - root - 2017-12-16 20:05:55.864666: step 86880, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 14h:39m:11s remains)
INFO - root - 2017-12-16 20:05:58.068229: step 86890, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 14h:48m:43s remains)
INFO - root - 2017-12-16 20:06:00.267552: step 86900, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 14h:52m:19s remains)
INFO - root - 2017-12-16 20:06:02.623593: step 86910, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 15h:15m:10s remains)
INFO - root - 2017-12-16 20:06:04.857452: step 86920, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 14h:48m:56s remains)
INFO - root - 2017-12-16 20:06:07.072556: step 86930, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 14h:52m:36s remains)
INFO - root - 2017-12-16 20:06:09.296499: step 86940, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 14h:42m:09s remains)
INFO - root - 2017-12-16 20:06:11.503631: step 86950, loss = 0.44, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 14h:31m:41s remains)
INFO - root - 2017-12-16 20:06:13.755026: step 86960, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 14h:39m:27s remains)
INFO - root - 2017-12-16 20:06:15.982511: step 86970, loss = 0.44, batch loss = 0.26 (34.6 examples/sec; 0.231 sec/batch; 15h:46m:44s remains)
INFO - root - 2017-12-16 20:06:18.195385: step 86980, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 15h:07m:38s remains)
INFO - root - 2017-12-16 20:06:20.433097: step 86990, loss = 0.47, batch loss = 0.29 (33.5 examples/sec; 0.239 sec/batch; 16h:18m:03s remains)
INFO - root - 2017-12-16 20:06:22.648284: step 87000, loss = 0.56, batch loss = 0.38 (35.8 examples/sec; 0.223 sec/batch; 15h:13m:45s remains)
INFO - root - 2017-12-16 20:06:24.987893: step 87010, loss = 0.47, batch loss = 0.29 (37.9 examples/sec; 0.211 sec/batch; 14h:24m:40s remains)
INFO - root - 2017-12-16 20:06:27.171930: step 87020, loss = 0.50, batch loss = 0.32 (37.9 examples/sec; 0.211 sec/batch; 14h:23m:46s remains)
INFO - root - 2017-12-16 20:06:29.377183: step 87030, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 14h:48m:13s remains)
INFO - root - 2017-12-16 20:06:31.621990: step 87040, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 15h:00m:43s remains)
INFO - root - 2017-12-16 20:06:33.820178: step 87050, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 14h:55m:38s remains)
INFO - root - 2017-12-16 20:06:36.030721: step 87060, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 15h:07m:00s remains)
INFO - root - 2017-12-16 20:06:38.248323: step 87070, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 15h:15m:58s remains)
INFO - root - 2017-12-16 20:06:40.484950: step 87080, loss = 0.43, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 15h:26m:46s remains)
INFO - root - 2017-12-16 20:06:42.775059: step 87090, loss = 0.49, batch loss = 0.31 (32.2 examples/sec; 0.248 sec/batch; 16h:55m:19s remains)
INFO - root - 2017-12-16 20:06:45.000732: step 87100, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 14h:49m:09s remains)
INFO - root - 2017-12-16 20:06:47.339495: step 87110, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 14h:36m:25s remains)
INFO - root - 2017-12-16 20:06:49.536795: step 87120, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 14h:47m:38s remains)
INFO - root - 2017-12-16 20:06:51.754745: step 87130, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 15h:16m:09s remains)
INFO - root - 2017-12-16 20:06:53.941816: step 87140, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 14h:57m:20s remains)
INFO - root - 2017-12-16 20:06:56.181035: step 87150, loss = 0.54, batch loss = 0.37 (35.7 examples/sec; 0.224 sec/batch; 15h:15m:27s remains)
INFO - root - 2017-12-16 20:06:58.426332: step 87160, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.215 sec/batch; 14h:37m:17s remains)
INFO - root - 2017-12-16 20:07:00.645637: step 87170, loss = 0.57, batch loss = 0.40 (36.3 examples/sec; 0.220 sec/batch; 15h:00m:07s remains)
INFO - root - 2017-12-16 20:07:02.854971: step 87180, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 15h:19m:55s remains)
INFO - root - 2017-12-16 20:07:05.061525: step 87190, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 14h:35m:01s remains)
INFO - root - 2017-12-16 20:07:07.240275: step 87200, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 14h:36m:15s remains)
INFO - root - 2017-12-16 20:07:09.559390: step 87210, loss = 0.49, batch loss = 0.31 (34.0 examples/sec; 0.235 sec/batch; 16h:01m:19s remains)
INFO - root - 2017-12-16 20:07:11.777980: step 87220, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 15h:16m:24s remains)
INFO - root - 2017-12-16 20:07:13.979137: step 87230, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.216 sec/batch; 14h:41m:11s remains)
INFO - root - 2017-12-16 20:07:16.162452: step 87240, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 15h:07m:08s remains)
INFO - root - 2017-12-16 20:07:18.352209: step 87250, loss = 0.45, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 15h:22m:28s remains)
INFO - root - 2017-12-16 20:07:20.599497: step 87260, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 14h:56m:06s remains)
INFO - root - 2017-12-16 20:07:22.807458: step 87270, loss = 0.46, batch loss = 0.28 (33.2 examples/sec; 0.241 sec/batch; 16h:25m:53s remains)
INFO - root - 2017-12-16 20:07:24.990513: step 87280, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 15h:18m:49s remains)
INFO - root - 2017-12-16 20:07:27.205144: step 87290, loss = 0.43, batch loss = 0.25 (37.6 examples/sec; 0.213 sec/batch; 14h:28m:33s remains)
INFO - root - 2017-12-16 20:07:29.387923: step 87300, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 15h:33m:02s remains)
INFO - root - 2017-12-16 20:07:31.703688: step 87310, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 14h:41m:23s remains)
INFO - root - 2017-12-16 20:07:33.905294: step 87320, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 15h:05m:42s remains)
INFO - root - 2017-12-16 20:07:36.114368: step 87330, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 15h:22m:37s remains)
INFO - root - 2017-12-16 20:07:38.370531: step 87340, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 15h:21m:16s remains)
INFO - root - 2017-12-16 20:07:40.617547: step 87350, loss = 0.42, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 15h:02m:24s remains)
INFO - root - 2017-12-16 20:07:42.835473: step 87360, loss = 0.60, batch loss = 0.42 (35.9 examples/sec; 0.223 sec/batch; 15h:09m:30s remains)
INFO - root - 2017-12-16 20:07:45.024064: step 87370, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 14h:26m:53s remains)
INFO - root - 2017-12-16 20:07:47.272056: step 87380, loss = 0.46, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 15h:54m:33s remains)
INFO - root - 2017-12-16 20:07:49.479039: step 87390, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 15h:23m:14s remains)
INFO - root - 2017-12-16 20:07:51.680195: step 87400, loss = 0.52, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 14h:33m:10s remains)
INFO - root - 2017-12-16 20:07:54.083257: step 87410, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 15h:02m:36s remains)
INFO - root - 2017-12-16 20:07:56.332277: step 87420, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 15h:06m:33s remains)
INFO - root - 2017-12-16 20:07:58.518562: step 87430, loss = 0.43, batch loss = 0.25 (37.3 examples/sec; 0.214 sec/batch; 14h:35m:33s remains)
INFO - root - 2017-12-16 20:08:00.725419: step 87440, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 14h:50m:25s remains)
INFO - root - 2017-12-16 20:08:02.959534: step 87450, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 15h:27m:55s remains)
INFO - root - 2017-12-16 20:08:05.210779: step 87460, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 15h:02m:28s remains)
INFO - root - 2017-12-16 20:08:07.431235: step 87470, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 15h:08m:35s remains)
INFO - root - 2017-12-16 20:08:09.687068: step 87480, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 14h:45m:39s remains)
INFO - root - 2017-12-16 20:08:11.912176: step 87490, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 15h:00m:31s remains)
INFO - root - 2017-12-16 20:08:14.145106: step 87500, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 14h:45m:45s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-87500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-87500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 20:08:17.141630: step 87510, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 15h:11m:29s remains)
INFO - root - 2017-12-16 20:08:19.361947: step 87520, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 14h:49m:42s remains)
INFO - root - 2017-12-16 20:08:21.541845: step 87530, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 15h:03m:23s remains)
INFO - root - 2017-12-16 20:08:23.791526: step 87540, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 15h:05m:55s remains)
INFO - root - 2017-12-16 20:08:26.025087: step 87550, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 15h:12m:44s remains)
INFO - root - 2017-12-16 20:08:28.228411: step 87560, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 14h:41m:33s remains)
INFO - root - 2017-12-16 20:08:30.447291: step 87570, loss = 0.52, batch loss = 0.34 (33.9 examples/sec; 0.236 sec/batch; 16h:03m:23s remains)
INFO - root - 2017-12-16 20:08:32.671782: step 87580, loss = 0.55, batch loss = 0.38 (36.4 examples/sec; 0.219 sec/batch; 14h:55m:54s remains)
INFO - root - 2017-12-16 20:08:34.886488: step 87590, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 14h:51m:40s remains)
INFO - root - 2017-12-16 20:08:37.099080: step 87600, loss = 0.47, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 14h:57m:22s remains)
INFO - root - 2017-12-16 20:08:39.485980: step 87610, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 14h:48m:40s remains)
INFO - root - 2017-12-16 20:08:41.692324: step 87620, loss = 0.43, batch loss = 0.25 (37.0 examples/sec; 0.216 sec/batch; 14h:42m:06s remains)
INFO - root - 2017-12-16 20:08:43.903054: step 87630, loss = 0.57, batch loss = 0.39 (36.7 examples/sec; 0.218 sec/batch; 14h:50m:14s remains)
INFO - root - 2017-12-16 20:08:46.091999: step 87640, loss = 0.53, batch loss = 0.35 (35.0 examples/sec; 0.229 sec/batch; 15h:33m:08s remains)
INFO - root - 2017-12-16 20:08:48.302913: step 87650, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 14h:53m:30s remains)
INFO - root - 2017-12-16 20:08:50.490719: step 87660, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 15h:18m:19s remains)
INFO - root - 2017-12-16 20:08:52.723153: step 87670, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 14h:57m:33s remains)
INFO - root - 2017-12-16 20:08:54.960391: step 87680, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 15h:11m:37s remains)
INFO - root - 2017-12-16 20:08:57.153925: step 87690, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 15h:10m:57s remains)
INFO - root - 2017-12-16 20:08:59.369256: step 87700, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.223 sec/batch; 15h:11m:52s remains)
INFO - root - 2017-12-16 20:09:01.714904: step 87710, loss = 0.54, batch loss = 0.37 (34.5 examples/sec; 0.232 sec/batch; 15h:45m:47s remains)
INFO - root - 2017-12-16 20:09:03.972639: step 87720, loss = 0.47, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 15h:53m:10s remains)
INFO - root - 2017-12-16 20:09:06.206244: step 87730, loss = 0.44, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 14h:36m:32s remains)
INFO - root - 2017-12-16 20:09:08.411262: step 87740, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 15h:10m:02s remains)
INFO - root - 2017-12-16 20:09:10.625750: step 87750, loss = 0.59, batch loss = 0.41 (36.8 examples/sec; 0.217 sec/batch; 14h:47m:02s remains)
INFO - root - 2017-12-16 20:09:12.814083: step 87760, loss = 0.53, batch loss = 0.36 (36.8 examples/sec; 0.217 sec/batch; 14h:46m:02s remains)
INFO - root - 2017-12-16 20:09:15.050337: step 87770, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 15h:11m:50s remains)
INFO - root - 2017-12-16 20:09:17.246456: step 87780, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 15h:19m:07s remains)
INFO - root - 2017-12-16 20:09:19.459944: step 87790, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 14h:54m:16s remains)
INFO - root - 2017-12-16 20:09:21.696884: step 87800, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 15h:05m:54s remains)
INFO - root - 2017-12-16 20:09:24.089147: step 87810, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 15h:09m:12s remains)
INFO - root - 2017-12-16 20:09:26.300737: step 87820, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 15h:09m:34s remains)
INFO - root - 2017-12-16 20:09:28.520969: step 87830, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 14h:41m:46s remains)
INFO - root - 2017-12-16 20:09:30.761273: step 87840, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 14h:51m:11s remains)
INFO - root - 2017-12-16 20:09:32.992350: step 87850, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 14h:58m:57s remains)
INFO - root - 2017-12-16 20:09:35.239563: step 87860, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 15h:11m:08s remains)
INFO - root - 2017-12-16 20:09:37.459010: step 87870, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 14h:58m:03s remains)
INFO - root - 2017-12-16 20:09:39.666654: step 87880, loss = 0.46, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 14h:28m:22s remains)
INFO - root - 2017-12-16 20:09:41.853540: step 87890, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.228 sec/batch; 15h:27m:44s remains)
INFO - root - 2017-12-16 20:09:44.088155: step 87900, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 15h:08m:37s remains)
INFO - root - 2017-12-16 20:09:46.441201: step 87910, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 14h:58m:30s remains)
INFO - root - 2017-12-16 20:09:48.681780: step 87920, loss = 0.53, batch loss = 0.35 (35.3 examples/sec; 0.227 sec/batch; 15h:24m:34s remains)
INFO - root - 2017-12-16 20:09:50.890676: step 87930, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 14h:33m:09s remains)
INFO - root - 2017-12-16 20:09:53.132149: step 87940, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 15h:16m:55s remains)
INFO - root - 2017-12-16 20:09:55.331193: step 87950, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 15h:42m:54s remains)
INFO - root - 2017-12-16 20:09:57.576941: step 87960, loss = 0.55, batch loss = 0.37 (37.1 examples/sec; 0.216 sec/batch; 14h:39m:47s remains)
INFO - root - 2017-12-16 20:09:59.760965: step 87970, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 14h:53m:18s remains)
INFO - root - 2017-12-16 20:10:01.956896: step 87980, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 15h:07m:35s remains)
INFO - root - 2017-12-16 20:10:04.165829: step 87990, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 15h:04m:15s remains)
INFO - root - 2017-12-16 20:10:06.449213: step 88000, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 15h:45m:31s remains)
INFO - root - 2017-12-16 20:10:08.901225: step 88010, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 15h:10m:33s remains)
INFO - root - 2017-12-16 20:10:11.096398: step 88020, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 14h:59m:52s remains)
INFO - root - 2017-12-16 20:10:13.348525: step 88030, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 15h:07m:54s remains)
INFO - root - 2017-12-16 20:10:15.578380: step 88040, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 14h:51m:36s remains)
INFO - root - 2017-12-16 20:10:17.813127: step 88050, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 15h:13m:10s remains)
INFO - root - 2017-12-16 20:10:20.014865: step 88060, loss = 0.62, batch loss = 0.44 (35.1 examples/sec; 0.228 sec/batch; 15h:28m:35s remains)
INFO - root - 2017-12-16 20:10:22.255539: step 88070, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 14h:51m:31s remains)
INFO - root - 2017-12-16 20:10:24.478919: step 88080, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 14h:25m:04s remains)
INFO - root - 2017-12-16 20:10:26.702893: step 88090, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 15h:19m:50s remains)
INFO - root - 2017-12-16 20:10:28.926554: step 88100, loss = 0.48, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 14h:35m:46s remains)
INFO - root - 2017-12-16 20:10:31.313790: step 88110, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 14h:41m:22s remains)
INFO - root - 2017-12-16 20:10:33.516559: step 88120, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 14h:37m:34s remains)
INFO - root - 2017-12-16 20:10:35.727946: step 88130, loss = 0.49, batch loss = 0.31 (34.1 examples/sec; 0.235 sec/batch; 15h:55m:31s remains)
INFO - root - 2017-12-16 20:10:37.951000: step 88140, loss = 0.47, batch loss = 0.29 (33.7 examples/sec; 0.237 sec/batch; 16h:05m:44s remains)
INFO - root - 2017-12-16 20:10:40.168680: step 88150, loss = 0.52, batch loss = 0.35 (36.6 examples/sec; 0.219 sec/batch; 14h:50m:51s remains)
INFO - root - 2017-12-16 20:10:42.357537: step 88160, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 14h:43m:33s remains)
INFO - root - 2017-12-16 20:10:44.607129: step 88170, loss = 0.47, batch loss = 0.29 (33.5 examples/sec; 0.239 sec/batch; 16h:13m:43s remains)
INFO - root - 2017-12-16 20:10:46.826424: step 88180, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 14h:58m:35s remains)
INFO - root - 2017-12-16 20:10:49.058551: step 88190, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 14h:35m:27s remains)
INFO - root - 2017-12-16 20:10:51.273463: step 88200, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 14h:48m:43s remains)
INFO - root - 2017-12-16 20:10:53.641478: step 88210, loss = 0.45, batch loss = 0.28 (34.0 examples/sec; 0.235 sec/batch; 15h:58m:41s remains)
INFO - root - 2017-12-16 20:10:55.872125: step 88220, loss = 0.44, batch loss = 0.26 (33.7 examples/sec; 0.237 sec/batch; 16h:05m:37s remains)
INFO - root - 2017-12-16 20:10:58.104564: step 88230, loss = 0.52, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 15h:27m:08s remains)
INFO - root - 2017-12-16 20:11:00.367846: step 88240, loss = 0.54, batch loss = 0.36 (35.2 examples/sec; 0.227 sec/batch; 15h:25m:08s remains)
INFO - root - 2017-12-16 20:11:02.593378: step 88250, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 15h:02m:14s remains)
INFO - root - 2017-12-16 20:11:04.847432: step 88260, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 15h:15m:36s remains)
INFO - root - 2017-12-16 20:11:07.104202: step 88270, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 15h:08m:17s remains)
INFO - root - 2017-12-16 20:11:09.335760: step 88280, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.233 sec/batch; 15h:47m:45s remains)
INFO - root - 2017-12-16 20:11:11.543347: step 88290, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 14h:30m:00s remains)
INFO - root - 2017-12-16 20:11:13.807861: step 88300, loss = 0.47, batch loss = 0.29 (34.1 examples/sec; 0.235 sec/batch; 15h:56m:06s remains)
INFO - root - 2017-12-16 20:11:16.204643: step 88310, loss = 0.54, batch loss = 0.36 (36.0 examples/sec; 0.223 sec/batch; 15h:05m:33s remains)
INFO - root - 2017-12-16 20:11:18.417244: step 88320, loss = 0.61, batch loss = 0.43 (37.7 examples/sec; 0.212 sec/batch; 14h:24m:16s remains)
INFO - root - 2017-12-16 20:11:20.623509: step 88330, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 15h:16m:57s remains)
INFO - root - 2017-12-16 20:11:22.877315: step 88340, loss = 0.46, batch loss = 0.28 (33.5 examples/sec; 0.239 sec/batch; 16h:11m:11s remains)
INFO - root - 2017-12-16 20:11:25.137113: step 88350, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 15h:00m:39s remains)
INFO - root - 2017-12-16 20:11:27.348602: step 88360, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.223 sec/batch; 15h:05m:28s remains)
INFO - root - 2017-12-16 20:11:29.545598: step 88370, loss = 0.43, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 14h:46m:09s remains)
INFO - root - 2017-12-16 20:11:31.722594: step 88380, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 14h:47m:04s remains)
INFO - root - 2017-12-16 20:11:33.954435: step 88390, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 14h:58m:46s remains)
INFO - root - 2017-12-16 20:11:36.210666: step 88400, loss = 0.50, batch loss = 0.33 (35.5 examples/sec; 0.226 sec/batch; 15h:17m:39s remains)
INFO - root - 2017-12-16 20:11:38.565490: step 88410, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 15h:00m:09s remains)
INFO - root - 2017-12-16 20:11:40.807771: step 88420, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 14h:29m:57s remains)
INFO - root - 2017-12-16 20:11:43.087814: step 88430, loss = 0.43, batch loss = 0.25 (34.8 examples/sec; 0.230 sec/batch; 15h:34m:12s remains)
INFO - root - 2017-12-16 20:11:45.319468: step 88440, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 15h:25m:12s remains)
INFO - root - 2017-12-16 20:11:47.598598: step 88450, loss = 0.53, batch loss = 0.35 (35.4 examples/sec; 0.226 sec/batch; 15h:18m:38s remains)
INFO - root - 2017-12-16 20:11:49.857581: step 88460, loss = 0.51, batch loss = 0.33 (34.5 examples/sec; 0.232 sec/batch; 15h:42m:22s remains)
INFO - root - 2017-12-16 20:11:52.092927: step 88470, loss = 0.42, batch loss = 0.24 (34.6 examples/sec; 0.231 sec/batch; 15h:40m:08s remains)
INFO - root - 2017-12-16 20:11:54.352194: step 88480, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 15h:35m:09s remains)
INFO - root - 2017-12-16 20:11:56.597779: step 88490, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 14h:54m:23s remains)
INFO - root - 2017-12-16 20:11:58.822795: step 88500, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 14h:25m:50s remains)
INFO - root - 2017-12-16 20:12:01.243184: step 88510, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 15h:03m:41s remains)
INFO - root - 2017-12-16 20:12:03.473700: step 88520, loss = 0.51, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 14h:44m:57s remains)
INFO - root - 2017-12-16 20:12:05.717226: step 88530, loss = 0.53, batch loss = 0.35 (34.3 examples/sec; 0.233 sec/batch; 15h:49m:26s remains)
INFO - root - 2017-12-16 20:12:07.965854: step 88540, loss = 0.45, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 15h:05m:35s remains)
INFO - root - 2017-12-16 20:12:10.184186: step 88550, loss = 0.44, batch loss = 0.26 (33.4 examples/sec; 0.240 sec/batch; 16h:14m:58s remains)
INFO - root - 2017-12-16 20:12:12.384430: step 88560, loss = 0.47, batch loss = 0.29 (38.1 examples/sec; 0.210 sec/batch; 14h:14m:15s remains)
INFO - root - 2017-12-16 20:12:14.584158: step 88570, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 14h:52m:58s remains)
INFO - root - 2017-12-16 20:12:16.778406: step 88580, loss = 0.47, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 14h:27m:14s remains)
INFO - root - 2017-12-16 20:12:18.972570: step 88590, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 14h:39m:33s remains)
INFO - root - 2017-12-16 20:12:21.190483: step 88600, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 14h:30m:52s remains)
INFO - root - 2017-12-16 20:12:23.544702: step 88610, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 14h:54m:40s remains)
INFO - root - 2017-12-16 20:12:25.741126: step 88620, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 15h:02m:46s remains)
INFO - root - 2017-12-16 20:12:27.946812: step 88630, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 14h:55m:46s remains)
INFO - root - 2017-12-16 20:12:30.157818: step 88640, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 14h:31m:08s remains)
INFO - root - 2017-12-16 20:12:32.379211: step 88650, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 14h:47m:42s remains)
INFO - root - 2017-12-16 20:12:34.575002: step 88660, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 14h:47m:05s remains)
INFO - root - 2017-12-16 20:12:36.752207: step 88670, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 14h:21m:19s remains)
INFO - root - 2017-12-16 20:12:38.981860: step 88680, loss = 0.47, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 14h:37m:51s remains)
INFO - root - 2017-12-16 20:12:41.231877: step 88690, loss = 0.46, batch loss = 0.29 (32.3 examples/sec; 0.247 sec/batch; 16h:44m:53s remains)
INFO - root - 2017-12-16 20:12:43.428236: step 88700, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 14h:53m:17s remains)
INFO - root - 2017-12-16 20:12:45.806449: step 88710, loss = 0.54, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 15h:05m:31s remains)
INFO - root - 2017-12-16 20:12:47.998078: step 88720, loss = 0.43, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 14h:30m:06s remains)
INFO - root - 2017-12-16 20:12:50.209677: step 88730, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 15h:02m:27s remains)
INFO - root - 2017-12-16 20:12:52.437575: step 88740, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 14h:48m:44s remains)
INFO - root - 2017-12-16 20:12:54.660094: step 88750, loss = 0.43, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 14h:40m:35s remains)
INFO - root - 2017-12-16 20:12:56.860957: step 88760, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 15h:15m:50s remains)
INFO - root - 2017-12-16 20:12:59.103348: step 88770, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 14h:50m:36s remains)
INFO - root - 2017-12-16 20:13:01.317971: step 88780, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 14h:48m:03s remains)
INFO - root - 2017-12-16 20:13:03.568472: step 88790, loss = 0.42, batch loss = 0.24 (35.8 examples/sec; 0.224 sec/batch; 15h:07m:55s remains)
INFO - root - 2017-12-16 20:13:05.800119: step 88800, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 15h:12m:52s remains)
INFO - root - 2017-12-16 20:13:08.156702: step 88810, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 14h:57m:24s remains)
INFO - root - 2017-12-16 20:13:10.372691: step 88820, loss = 0.45, batch loss = 0.27 (38.1 examples/sec; 0.210 sec/batch; 14h:12m:32s remains)
INFO - root - 2017-12-16 20:13:12.576385: step 88830, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 15h:03m:05s remains)
INFO - root - 2017-12-16 20:13:14.783766: step 88840, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 14h:37m:28s remains)
INFO - root - 2017-12-16 20:13:16.979371: step 88850, loss = 0.43, batch loss = 0.25 (37.6 examples/sec; 0.213 sec/batch; 14h:24m:51s remains)
INFO - root - 2017-12-16 20:13:19.204935: step 88860, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 14h:44m:54s remains)
INFO - root - 2017-12-16 20:13:21.454727: step 88870, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 14h:46m:08s remains)
INFO - root - 2017-12-16 20:13:23.675848: step 88880, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 15h:12m:06s remains)
INFO - root - 2017-12-16 20:13:25.895050: step 88890, loss = 0.43, batch loss = 0.25 (37.8 examples/sec; 0.211 sec/batch; 14h:18m:43s remains)
INFO - root - 2017-12-16 20:13:28.145374: step 88900, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 15h:10m:52s remains)
INFO - root - 2017-12-16 20:13:30.500154: step 88910, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 15h:17m:51s remains)
INFO - root - 2017-12-16 20:13:32.710226: step 88920, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 15h:17m:42s remains)
INFO - root - 2017-12-16 20:13:34.941454: step 88930, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 14h:54m:18s remains)
INFO - root - 2017-12-16 20:13:37.125710: step 88940, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 15h:04m:12s remains)
INFO - root - 2017-12-16 20:13:39.355560: step 88950, loss = 0.49, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 14h:28m:07s remains)
INFO - root - 2017-12-16 20:13:41.556779: step 88960, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 15h:03m:35s remains)
INFO - root - 2017-12-16 20:13:43.798638: step 88970, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 15h:05m:58s remains)
INFO - root - 2017-12-16 20:13:46.025364: step 88980, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 14h:44m:34s remains)
INFO - root - 2017-12-16 20:13:48.205945: step 88990, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 14h:43m:46s remains)
INFO - root - 2017-12-16 20:13:50.356187: step 89000, loss = 0.42, batch loss = 0.24 (37.2 examples/sec; 0.215 sec/batch; 14h:32m:17s remains)
INFO - root - 2017-12-16 20:13:52.653700: step 89010, loss = 0.46, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 14h:55m:39s remains)
INFO - root - 2017-12-16 20:13:54.859864: step 89020, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 15h:11m:52s remains)
INFO - root - 2017-12-16 20:13:57.044799: step 89030, loss = 0.44, batch loss = 0.27 (34.8 examples/sec; 0.230 sec/batch; 15h:33m:31s remains)
INFO - root - 2017-12-16 20:13:59.248029: step 89040, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 14h:50m:09s remains)
INFO - root - 2017-12-16 20:14:01.466819: step 89050, loss = 0.50, batch loss = 0.32 (37.5 examples/sec; 0.213 sec/batch; 14h:25m:57s remains)
INFO - root - 2017-12-16 20:14:03.666143: step 89060, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 14h:48m:11s remains)
INFO - root - 2017-12-16 20:14:05.856319: step 89070, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 15h:01m:46s remains)
INFO - root - 2017-12-16 20:14:08.043937: step 89080, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 15h:05m:46s remains)
INFO - root - 2017-12-16 20:14:10.241072: step 89090, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 14h:25m:55s remains)
INFO - root - 2017-12-16 20:14:12.428103: step 89100, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 14h:45m:55s remains)
INFO - root - 2017-12-16 20:14:14.775667: step 89110, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 14h:56m:15s remains)
INFO - root - 2017-12-16 20:14:16.959428: step 89120, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 14h:49m:48s remains)
INFO - root - 2017-12-16 20:14:19.132452: step 89130, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 14h:39m:12s remains)
INFO - root - 2017-12-16 20:14:21.329064: step 89140, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 14h:50m:03s remains)
INFO - root - 2017-12-16 20:14:23.529064: step 89150, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 14h:57m:52s remains)
INFO - root - 2017-12-16 20:14:25.723977: step 89160, loss = 0.42, batch loss = 0.24 (37.0 examples/sec; 0.216 sec/batch; 14h:36m:56s remains)
INFO - root - 2017-12-16 20:14:27.914766: step 89170, loss = 0.58, batch loss = 0.40 (34.9 examples/sec; 0.229 sec/batch; 15h:30m:38s remains)
INFO - root - 2017-12-16 20:14:30.123097: step 89180, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 14h:34m:51s remains)
INFO - root - 2017-12-16 20:14:32.337850: step 89190, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 14h:32m:15s remains)
INFO - root - 2017-12-16 20:14:34.523118: step 89200, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 15h:01m:08s remains)
INFO - root - 2017-12-16 20:14:36.851172: step 89210, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 14h:59m:44s remains)
INFO - root - 2017-12-16 20:14:39.037301: step 89220, loss = 0.42, batch loss = 0.24 (37.1 examples/sec; 0.216 sec/batch; 14h:34m:02s remains)
INFO - root - 2017-12-16 20:14:41.228046: step 89230, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 14h:51m:28s remains)
INFO - root - 2017-12-16 20:14:43.448960: step 89240, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 15h:23m:37s remains)
INFO - root - 2017-12-16 20:14:45.642787: step 89250, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.216 sec/batch; 14h:35m:21s remains)
INFO - root - 2017-12-16 20:14:47.857837: step 89260, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 14h:59m:48s remains)
INFO - root - 2017-12-16 20:14:50.102699: step 89270, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 14h:49m:36s remains)
INFO - root - 2017-12-16 20:14:52.291972: step 89280, loss = 0.51, batch loss = 0.33 (38.2 examples/sec; 0.209 sec/batch; 14h:08m:06s remains)
INFO - root - 2017-12-16 20:14:54.547494: step 89290, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 15h:38m:56s remains)
INFO - root - 2017-12-16 20:14:56.756319: step 89300, loss = 0.41, batch loss = 0.23 (36.1 examples/sec; 0.222 sec/batch; 14h:58m:18s remains)
INFO - root - 2017-12-16 20:14:59.091281: step 89310, loss = 0.47, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 14h:31m:39s remains)
INFO - root - 2017-12-16 20:15:01.249202: step 89320, loss = 0.54, batch loss = 0.36 (37.1 examples/sec; 0.216 sec/batch; 14h:34m:41s remains)
INFO - root - 2017-12-16 20:15:03.484344: step 89330, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 14h:53m:05s remains)
INFO - root - 2017-12-16 20:15:05.708741: step 89340, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 14h:53m:04s remains)
INFO - root - 2017-12-16 20:15:07.939783: step 89350, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 15h:00m:45s remains)
INFO - root - 2017-12-16 20:15:10.155925: step 89360, loss = 0.44, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 14h:50m:12s remains)
INFO - root - 2017-12-16 20:15:12.363753: step 89370, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 15h:16m:20s remains)
INFO - root - 2017-12-16 20:15:14.580776: step 89380, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 14h:49m:29s remains)
INFO - root - 2017-12-16 20:15:16.772109: step 89390, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 15h:19m:52s remains)
INFO - root - 2017-12-16 20:15:19.009797: step 89400, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 14h:42m:53s remains)
INFO - root - 2017-12-16 20:15:21.342034: step 89410, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.231 sec/batch; 15h:34m:11s remains)
INFO - root - 2017-12-16 20:15:23.561626: step 89420, loss = 0.48, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 14h:36m:18s remains)
INFO - root - 2017-12-16 20:15:25.785059: step 89430, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 14h:55m:25s remains)
INFO - root - 2017-12-16 20:15:27.973541: step 89440, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 14h:53m:20s remains)
INFO - root - 2017-12-16 20:15:30.174882: step 89450, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 14h:32m:40s remains)
INFO - root - 2017-12-16 20:15:32.426067: step 89460, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 15h:11m:55s remains)
INFO - root - 2017-12-16 20:15:34.631126: step 89470, loss = 0.44, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 14h:46m:40s remains)
INFO - root - 2017-12-16 20:15:36.861966: step 89480, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 14h:54m:36s remains)
INFO - root - 2017-12-16 20:15:39.087279: step 89490, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 14h:47m:44s remains)
INFO - root - 2017-12-16 20:15:41.292235: step 89500, loss = 0.46, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 15h:45m:31s remains)
INFO - root - 2017-12-16 20:15:43.615773: step 89510, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 15h:03m:14s remains)
INFO - root - 2017-12-16 20:15:45.829344: step 89520, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 14h:54m:59s remains)
INFO - root - 2017-12-16 20:15:48.015319: step 89530, loss = 0.51, batch loss = 0.33 (35.0 examples/sec; 0.228 sec/batch; 15h:24m:17s remains)
INFO - root - 2017-12-16 20:15:50.234835: step 89540, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 15h:03m:36s remains)
INFO - root - 2017-12-16 20:15:52.438714: step 89550, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 14h:49m:09s remains)
INFO - root - 2017-12-16 20:15:54.651548: step 89560, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 14h:47m:44s remains)
INFO - root - 2017-12-16 20:15:56.847672: step 89570, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 14h:39m:22s remains)
INFO - root - 2017-12-16 20:15:59.026056: step 89580, loss = 0.46, batch loss = 0.29 (37.5 examples/sec; 0.214 sec/batch; 14h:24m:50s remains)
INFO - root - 2017-12-16 20:16:01.240472: step 89590, loss = 0.45, batch loss = 0.27 (34.1 examples/sec; 0.235 sec/batch; 15h:51m:10s remains)
INFO - root - 2017-12-16 20:16:03.495329: step 89600, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 15h:12m:39s remains)
INFO - root - 2017-12-16 20:16:05.839755: step 89610, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 14h:42m:03s remains)
INFO - root - 2017-12-16 20:16:08.042761: step 89620, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 15h:16m:46s remains)
INFO - root - 2017-12-16 20:16:10.257170: step 89630, loss = 0.58, batch loss = 0.40 (37.0 examples/sec; 0.216 sec/batch; 14h:34m:37s remains)
INFO - root - 2017-12-16 20:16:12.474252: step 89640, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 15h:10m:27s remains)
INFO - root - 2017-12-16 20:16:14.681180: step 89650, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 14h:53m:21s remains)
INFO - root - 2017-12-16 20:16:16.893348: step 89660, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 14h:45m:17s remains)
INFO - root - 2017-12-16 20:16:19.094852: step 89670, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 14h:44m:05s remains)
INFO - root - 2017-12-16 20:16:21.306048: step 89680, loss = 0.54, batch loss = 0.36 (36.1 examples/sec; 0.221 sec/batch; 14h:56m:22s remains)
INFO - root - 2017-12-16 20:16:23.497507: step 89690, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 14h:56m:46s remains)
INFO - root - 2017-12-16 20:16:25.711344: step 89700, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 14h:33m:36s remains)
INFO - root - 2017-12-16 20:16:28.050911: step 89710, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 14h:46m:53s remains)
INFO - root - 2017-12-16 20:16:30.242896: step 89720, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 14h:20m:54s remains)
INFO - root - 2017-12-16 20:16:32.472439: step 89730, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 14h:33m:57s remains)
INFO - root - 2017-12-16 20:16:34.663659: step 89740, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 14h:34m:30s remains)
INFO - root - 2017-12-16 20:16:36.909162: step 89750, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 15h:21m:50s remains)
INFO - root - 2017-12-16 20:16:39.106196: step 89760, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 14h:16m:15s remains)
INFO - root - 2017-12-16 20:16:41.329541: step 89770, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 14h:55m:05s remains)
INFO - root - 2017-12-16 20:16:43.511860: step 89780, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 15h:09m:58s remains)
INFO - root - 2017-12-16 20:16:45.683108: step 89790, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 14h:40m:10s remains)
INFO - root - 2017-12-16 20:16:47.919523: step 89800, loss = 0.46, batch loss = 0.29 (33.9 examples/sec; 0.236 sec/batch; 15h:55m:51s remains)
INFO - root - 2017-12-16 20:16:50.248106: step 89810, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 15h:08m:45s remains)
INFO - root - 2017-12-16 20:16:52.441737: step 89820, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 14h:22m:26s remains)
INFO - root - 2017-12-16 20:16:54.671813: step 89830, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 14h:25m:50s remains)
INFO - root - 2017-12-16 20:16:56.894711: step 89840, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 15h:22m:17s remains)
INFO - root - 2017-12-16 20:16:59.124353: step 89850, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 14h:54m:44s remains)
INFO - root - 2017-12-16 20:17:01.316606: step 89860, loss = 0.47, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 14h:46m:34s remains)
INFO - root - 2017-12-16 20:17:03.552919: step 89870, loss = 0.50, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 15h:27m:19s remains)
INFO - root - 2017-12-16 20:17:05.738254: step 89880, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 15h:06m:11s remains)
INFO - root - 2017-12-16 20:17:07.927391: step 89890, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 15h:09m:17s remains)
INFO - root - 2017-12-16 20:17:10.151909: step 89900, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 14h:29m:22s remains)
INFO - root - 2017-12-16 20:17:12.465691: step 89910, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 14h:24m:16s remains)
INFO - root - 2017-12-16 20:17:14.709814: step 89920, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 15h:28m:32s remains)
INFO - root - 2017-12-16 20:17:16.933305: step 89930, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.226 sec/batch; 15h:11m:55s remains)
INFO - root - 2017-12-16 20:17:19.133933: step 89940, loss = 0.45, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 15h:29m:15s remains)
INFO - root - 2017-12-16 20:17:21.352868: step 89950, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 14h:52m:20s remains)
INFO - root - 2017-12-16 20:17:23.559172: step 89960, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 14h:39m:49s remains)
INFO - root - 2017-12-16 20:17:25.750977: step 89970, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 14h:39m:10s remains)
INFO - root - 2017-12-16 20:17:27.969112: step 89980, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 14h:56m:51s remains)
INFO - root - 2017-12-16 20:17:30.191137: step 89990, loss = 0.57, batch loss = 0.40 (35.9 examples/sec; 0.223 sec/batch; 15h:01m:38s remains)
INFO - root - 2017-12-16 20:17:32.400724: step 90000, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 14h:57m:30s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-90000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-90000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 20:17:35.236533: step 90010, loss = 0.51, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 15h:08m:47s remains)
INFO - root - 2017-12-16 20:17:37.418462: step 90020, loss = 0.43, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 14h:25m:19s remains)
INFO - root - 2017-12-16 20:17:39.623271: step 90030, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 15h:07m:39s remains)
INFO - root - 2017-12-16 20:17:41.831140: step 90040, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 14h:36m:26s remains)
INFO - root - 2017-12-16 20:17:44.040988: step 90050, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 15h:13m:25s remains)
INFO - root - 2017-12-16 20:17:46.252032: step 90060, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 15h:23m:48s remains)
INFO - root - 2017-12-16 20:17:48.457189: step 90070, loss = 0.53, batch loss = 0.35 (35.4 examples/sec; 0.226 sec/batch; 15h:12m:00s remains)
INFO - root - 2017-12-16 20:17:50.674901: step 90080, loss = 0.58, batch loss = 0.40 (35.6 examples/sec; 0.225 sec/batch; 15h:09m:06s remains)
INFO - root - 2017-12-16 20:17:52.909111: step 90090, loss = 0.45, batch loss = 0.27 (34.2 examples/sec; 0.234 sec/batch; 15h:44m:37s remains)
INFO - root - 2017-12-16 20:17:55.157649: step 90100, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:59m:24s remains)
INFO - root - 2017-12-16 20:17:57.512480: step 90110, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 15h:04m:05s remains)
INFO - root - 2017-12-16 20:17:59.744134: step 90120, loss = 0.47, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 14h:53m:14s remains)
INFO - root - 2017-12-16 20:18:01.964129: step 90130, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 15h:12m:04s remains)
INFO - root - 2017-12-16 20:18:04.209361: step 90140, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 15h:15m:55s remains)
INFO - root - 2017-12-16 20:18:06.416486: step 90150, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 15h:12m:27s remains)
INFO - root - 2017-12-16 20:18:08.659363: step 90160, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 15h:08m:42s remains)
INFO - root - 2017-12-16 20:18:10.882535: step 90170, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 14h:48m:12s remains)
INFO - root - 2017-12-16 20:18:13.121562: step 90180, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 15h:01m:40s remains)
INFO - root - 2017-12-16 20:18:15.348932: step 90190, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 15h:10m:35s remains)
INFO - root - 2017-12-16 20:18:17.571948: step 90200, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 15h:15m:25s remains)
INFO - root - 2017-12-16 20:18:19.966913: step 90210, loss = 0.49, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 15h:15m:16s remains)
INFO - root - 2017-12-16 20:18:22.154391: step 90220, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 15h:07m:00s remains)
INFO - root - 2017-12-16 20:18:24.399146: step 90230, loss = 0.44, batch loss = 0.26 (34.3 examples/sec; 0.233 sec/batch; 15h:41m:01s remains)
INFO - root - 2017-12-16 20:18:26.652904: step 90240, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 14h:55m:57s remains)
INFO - root - 2017-12-16 20:18:28.892988: step 90250, loss = 0.58, batch loss = 0.40 (35.4 examples/sec; 0.226 sec/batch; 15h:12m:49s remains)
INFO - root - 2017-12-16 20:18:31.089617: step 90260, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 14h:17m:44s remains)
INFO - root - 2017-12-16 20:18:33.310783: step 90270, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 15h:19m:46s remains)
INFO - root - 2017-12-16 20:18:35.485508: step 90280, loss = 0.51, batch loss = 0.33 (37.8 examples/sec; 0.212 sec/batch; 14h:14m:53s remains)
INFO - root - 2017-12-16 20:18:37.721926: step 90290, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 14h:53m:39s remains)
INFO - root - 2017-12-16 20:18:39.921881: step 90300, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 14h:27m:51s remains)
INFO - root - 2017-12-16 20:18:42.307197: step 90310, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 15h:25m:35s remains)
INFO - root - 2017-12-16 20:18:44.539144: step 90320, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 15h:04m:10s remains)
INFO - root - 2017-12-16 20:18:46.760628: step 90330, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 14h:54m:53s remains)
INFO - root - 2017-12-16 20:18:48.950360: step 90340, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 14h:57m:02s remains)
INFO - root - 2017-12-16 20:18:51.150901: step 90350, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 14h:49m:51s remains)
INFO - root - 2017-12-16 20:18:53.394936: step 90360, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 14h:28m:10s remains)
INFO - root - 2017-12-16 20:18:55.602071: step 90370, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 14h:59m:11s remains)
INFO - root - 2017-12-16 20:18:57.826418: step 90380, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 15h:07m:07s remains)
INFO - root - 2017-12-16 20:19:00.057607: step 90390, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 15h:27m:59s remains)
INFO - root - 2017-12-16 20:19:02.255916: step 90400, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 14h:56m:14s remains)
INFO - root - 2017-12-16 20:19:04.627541: step 90410, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 14h:56m:29s remains)
INFO - root - 2017-12-16 20:19:06.864787: step 90420, loss = 0.51, batch loss = 0.33 (33.6 examples/sec; 0.238 sec/batch; 15h:59m:40s remains)
INFO - root - 2017-12-16 20:19:09.114433: step 90430, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 14h:42m:20s remains)
INFO - root - 2017-12-16 20:19:11.297370: step 90440, loss = 0.43, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 14h:55m:52s remains)
INFO - root - 2017-12-16 20:19:13.539825: step 90450, loss = 0.42, batch loss = 0.24 (36.5 examples/sec; 0.219 sec/batch; 14h:45m:21s remains)
INFO - root - 2017-12-16 20:19:15.794692: step 90460, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 14h:55m:08s remains)
INFO - root - 2017-12-16 20:19:18.043996: step 90470, loss = 0.50, batch loss = 0.32 (35.0 examples/sec; 0.229 sec/batch; 15h:22m:47s remains)
INFO - root - 2017-12-16 20:19:20.249854: step 90480, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 14h:38m:16s remains)
INFO - root - 2017-12-16 20:19:22.444335: step 90490, loss = 0.46, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 15h:11m:20s remains)
INFO - root - 2017-12-16 20:19:24.677629: step 90500, loss = 0.55, batch loss = 0.37 (35.3 examples/sec; 0.226 sec/batch; 15h:13m:21s remains)
INFO - root - 2017-12-16 20:19:27.021862: step 90510, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 14h:32m:57s remains)
INFO - root - 2017-12-16 20:19:29.216197: step 90520, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 14h:40m:59s remains)
INFO - root - 2017-12-16 20:19:31.411361: step 90530, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 15h:11m:59s remains)
INFO - root - 2017-12-16 20:19:33.640354: step 90540, loss = 0.56, batch loss = 0.38 (35.3 examples/sec; 0.227 sec/batch; 15h:13m:45s remains)
INFO - root - 2017-12-16 20:19:35.846314: step 90550, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 14h:39m:51s remains)
INFO - root - 2017-12-16 20:19:38.082522: step 90560, loss = 0.45, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 14h:27m:14s remains)
INFO - root - 2017-12-16 20:19:40.293749: step 90570, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:57m:17s remains)
INFO - root - 2017-12-16 20:19:42.499736: step 90580, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 14h:47m:50s remains)
INFO - root - 2017-12-16 20:19:44.710074: step 90590, loss = 0.43, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 15h:13m:34s remains)
INFO - root - 2017-12-16 20:19:46.896432: step 90600, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 14h:24m:49s remains)
INFO - root - 2017-12-16 20:19:49.221014: step 90610, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 14h:46m:53s remains)
INFO - root - 2017-12-16 20:19:51.477125: step 90620, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 15h:06m:18s remains)
INFO - root - 2017-12-16 20:19:53.676523: step 90630, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 14h:42m:08s remains)
INFO - root - 2017-12-16 20:19:55.871555: step 90640, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 14h:17m:12s remains)
INFO - root - 2017-12-16 20:19:58.125042: step 90650, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 15h:17m:37s remains)
INFO - root - 2017-12-16 20:20:00.322602: step 90660, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 14h:48m:00s remains)
INFO - root - 2017-12-16 20:20:02.526543: step 90670, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.228 sec/batch; 15h:17m:01s remains)
INFO - root - 2017-12-16 20:20:04.764789: step 90680, loss = 0.49, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 14h:33m:14s remains)
INFO - root - 2017-12-16 20:20:06.998209: step 90690, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 15h:11m:47s remains)
INFO - root - 2017-12-16 20:20:09.243613: step 90700, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 14h:31m:43s remains)
INFO - root - 2017-12-16 20:20:11.592417: step 90710, loss = 0.47, batch loss = 0.30 (34.3 examples/sec; 0.233 sec/batch; 15h:40m:25s remains)
INFO - root - 2017-12-16 20:20:13.837904: step 90720, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 14h:52m:52s remains)
INFO - root - 2017-12-16 20:20:16.074429: step 90730, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 14h:28m:52s remains)
INFO - root - 2017-12-16 20:20:18.312988: step 90740, loss = 0.50, batch loss = 0.32 (38.6 examples/sec; 0.207 sec/batch; 13h:55m:33s remains)
INFO - root - 2017-12-16 20:20:20.571337: step 90750, loss = 0.49, batch loss = 0.31 (34.0 examples/sec; 0.235 sec/batch; 15h:47m:14s remains)
INFO - root - 2017-12-16 20:20:22.819762: step 90760, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 15h:06m:16s remains)
INFO - root - 2017-12-16 20:20:25.015995: step 90770, loss = 0.50, batch loss = 0.32 (37.5 examples/sec; 0.213 sec/batch; 14h:20m:03s remains)
INFO - root - 2017-12-16 20:20:27.222965: step 90780, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 14h:43m:37s remains)
INFO - root - 2017-12-16 20:20:29.435115: step 90790, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 15h:07m:21s remains)
INFO - root - 2017-12-16 20:20:31.635755: step 90800, loss = 0.42, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 14h:57m:11s remains)
INFO - root - 2017-12-16 20:20:33.992706: step 90810, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.219 sec/batch; 14h:40m:23s remains)
INFO - root - 2017-12-16 20:20:36.236156: step 90820, loss = 0.47, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 15h:41m:16s remains)
INFO - root - 2017-12-16 20:20:38.455169: step 90830, loss = 0.51, batch loss = 0.33 (34.5 examples/sec; 0.232 sec/batch; 15h:34m:53s remains)
INFO - root - 2017-12-16 20:20:40.654992: step 90840, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 14h:46m:43s remains)
INFO - root - 2017-12-16 20:20:42.903152: step 90850, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 14h:34m:38s remains)
INFO - root - 2017-12-16 20:20:45.144770: step 90860, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 14h:57m:46s remains)
INFO - root - 2017-12-16 20:20:47.367511: step 90870, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 14h:47m:53s remains)
INFO - root - 2017-12-16 20:20:49.568396: step 90880, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 14h:38m:33s remains)
INFO - root - 2017-12-16 20:20:51.803636: step 90890, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 14h:29m:19s remains)
INFO - root - 2017-12-16 20:20:54.016811: step 90900, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 15h:01m:55s remains)
INFO - root - 2017-12-16 20:20:56.359434: step 90910, loss = 0.52, batch loss = 0.34 (35.0 examples/sec; 0.228 sec/batch; 15h:19m:17s remains)
INFO - root - 2017-12-16 20:20:58.554907: step 90920, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 15h:34m:08s remains)
INFO - root - 2017-12-16 20:21:00.787210: step 90930, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 14h:47m:49s remains)
INFO - root - 2017-12-16 20:21:02.990806: step 90940, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 14h:53m:16s remains)
INFO - root - 2017-12-16 20:21:05.206401: step 90950, loss = 0.46, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 15h:17m:32s remains)
INFO - root - 2017-12-16 20:21:07.423510: step 90960, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 14h:42m:55s remains)
INFO - root - 2017-12-16 20:21:09.641788: step 90970, loss = 0.47, batch loss = 0.29 (38.3 examples/sec; 0.209 sec/batch; 14h:00m:55s remains)
INFO - root - 2017-12-16 20:21:11.835503: step 90980, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 15h:08m:28s remains)
INFO - root - 2017-12-16 20:21:14.050252: step 90990, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 14h:45m:13s remains)
INFO - root - 2017-12-16 20:21:16.294546: step 91000, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 15h:07m:37s remains)
INFO - root - 2017-12-16 20:21:18.675733: step 91010, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.232 sec/batch; 15h:35m:23s remains)
INFO - root - 2017-12-16 20:21:20.880596: step 91020, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 14h:29m:09s remains)
INFO - root - 2017-12-16 20:21:23.071687: step 91030, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.219 sec/batch; 14h:40m:44s remains)
INFO - root - 2017-12-16 20:21:25.262616: step 91040, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 14h:50m:31s remains)
INFO - root - 2017-12-16 20:21:27.467556: step 91050, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 14h:41m:56s remains)
INFO - root - 2017-12-16 20:21:29.672463: step 91060, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 14h:52m:20s remains)
INFO - root - 2017-12-16 20:21:31.898687: step 91070, loss = 0.43, batch loss = 0.25 (38.5 examples/sec; 0.208 sec/batch; 13h:56m:14s remains)
INFO - root - 2017-12-16 20:21:34.109390: step 91080, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 14h:21m:32s remains)
INFO - root - 2017-12-16 20:21:36.324150: step 91090, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 14h:45m:20s remains)
INFO - root - 2017-12-16 20:21:38.526165: step 91100, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 14h:57m:45s remains)
INFO - root - 2017-12-16 20:21:40.917890: step 91110, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 15h:00m:39s remains)
INFO - root - 2017-12-16 20:21:43.141222: step 91120, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 15h:30m:24s remains)
INFO - root - 2017-12-16 20:21:45.369588: step 91130, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 14h:35m:00s remains)
INFO - root - 2017-12-16 20:21:47.563206: step 91140, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 15h:07m:48s remains)
INFO - root - 2017-12-16 20:21:49.778847: step 91150, loss = 0.47, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 15h:12m:31s remains)
INFO - root - 2017-12-16 20:21:51.982144: step 91160, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 14h:55m:10s remains)
INFO - root - 2017-12-16 20:21:54.206680: step 91170, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 15h:01m:00s remains)
INFO - root - 2017-12-16 20:21:56.422844: step 91180, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 14h:20m:22s remains)
INFO - root - 2017-12-16 20:21:58.617580: step 91190, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 14h:29m:44s remains)
INFO - root - 2017-12-16 20:22:00.810681: step 91200, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 14h:58m:52s remains)
INFO - root - 2017-12-16 20:22:03.159839: step 91210, loss = 0.50, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 14h:41m:53s remains)
INFO - root - 2017-12-16 20:22:05.370136: step 91220, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 14h:34m:31s remains)
INFO - root - 2017-12-16 20:22:07.569730: step 91230, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 14h:49m:51s remains)
INFO - root - 2017-12-16 20:22:09.745159: step 91240, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 15h:05m:37s remains)
INFO - root - 2017-12-16 20:22:11.964761: step 91250, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 14h:57m:46s remains)
INFO - root - 2017-12-16 20:22:14.155230: step 91260, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 14h:51m:17s remains)
INFO - root - 2017-12-16 20:22:16.343304: step 91270, loss = 0.45, batch loss = 0.27 (33.8 examples/sec; 0.237 sec/batch; 15h:52m:56s remains)
INFO - root - 2017-12-16 20:22:18.594296: step 91280, loss = 0.54, batch loss = 0.36 (35.6 examples/sec; 0.225 sec/batch; 15h:04m:11s remains)
INFO - root - 2017-12-16 20:22:20.820057: step 91290, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 14h:50m:13s remains)
INFO - root - 2017-12-16 20:22:23.028926: step 91300, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.215 sec/batch; 14h:25m:41s remains)
INFO - root - 2017-12-16 20:22:25.360343: step 91310, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 14h:48m:30s remains)
INFO - root - 2017-12-16 20:22:27.591326: step 91320, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.215 sec/batch; 14h:25m:56s remains)
INFO - root - 2017-12-16 20:22:29.769716: step 91330, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 14h:57m:05s remains)
INFO - root - 2017-12-16 20:22:31.958678: step 91340, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 14h:38m:49s remains)
INFO - root - 2017-12-16 20:22:34.186479: step 91350, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 15h:16m:34s remains)
INFO - root - 2017-12-16 20:22:36.376692: step 91360, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 14h:40m:03s remains)
INFO - root - 2017-12-16 20:22:38.579367: step 91370, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 14h:36m:12s remains)
INFO - root - 2017-12-16 20:22:40.782117: step 91380, loss = 0.44, batch loss = 0.26 (35.0 examples/sec; 0.229 sec/batch; 15h:19m:25s remains)
INFO - root - 2017-12-16 20:22:42.981326: step 91390, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 15h:10m:11s remains)
INFO - root - 2017-12-16 20:22:45.189695: step 91400, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 14h:51m:53s remains)
INFO - root - 2017-12-16 20:22:47.543732: step 91410, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.224 sec/batch; 15h:01m:58s remains)
INFO - root - 2017-12-16 20:22:49.793359: step 91420, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 14h:50m:24s remains)
INFO - root - 2017-12-16 20:22:51.998963: step 91430, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 14h:42m:46s remains)
INFO - root - 2017-12-16 20:22:54.215353: step 91440, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 14h:57m:32s remains)
INFO - root - 2017-12-16 20:22:56.443509: step 91450, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 14h:52m:27s remains)
INFO - root - 2017-12-16 20:22:58.654895: step 91460, loss = 0.50, batch loss = 0.32 (34.4 examples/sec; 0.232 sec/batch; 15h:32m:56s remains)
INFO - root - 2017-12-16 20:23:00.852676: step 91470, loss = 0.47, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 14h:42m:39s remains)
INFO - root - 2017-12-16 20:23:03.052364: step 91480, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 14h:43m:40s remains)
INFO - root - 2017-12-16 20:23:05.306573: step 91490, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 14h:38m:11s remains)
INFO - root - 2017-12-16 20:23:07.532238: step 91500, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 14h:16m:59s remains)
INFO - root - 2017-12-16 20:23:09.897400: step 91510, loss = 0.44, batch loss = 0.27 (34.8 examples/sec; 0.230 sec/batch; 15h:23m:27s remains)
INFO - root - 2017-12-16 20:23:12.187692: step 91520, loss = 0.53, batch loss = 0.35 (37.1 examples/sec; 0.216 sec/batch; 14h:26m:46s remains)
INFO - root - 2017-12-16 20:23:14.370441: step 91530, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 14h:51m:08s remains)
INFO - root - 2017-12-16 20:23:16.584061: step 91540, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 14h:45m:14s remains)
INFO - root - 2017-12-16 20:23:18.777407: step 91550, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.224 sec/batch; 15h:01m:15s remains)
INFO - root - 2017-12-16 20:23:20.986695: step 91560, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 14h:54m:15s remains)
INFO - root - 2017-12-16 20:23:23.201841: step 91570, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 14h:57m:49s remains)
INFO - root - 2017-12-16 20:23:25.391403: step 91580, loss = 0.44, batch loss = 0.26 (34.3 examples/sec; 0.233 sec/batch; 15h:35m:15s remains)
INFO - root - 2017-12-16 20:23:27.574179: step 91590, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 14h:29m:04s remains)
INFO - root - 2017-12-16 20:23:29.799460: step 91600, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 15h:04m:00s remains)
INFO - root - 2017-12-16 20:23:32.127401: step 91610, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 14h:37m:19s remains)
INFO - root - 2017-12-16 20:23:34.321946: step 91620, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 14h:55m:06s remains)
INFO - root - 2017-12-16 20:23:36.528689: step 91630, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 15h:14m:59s remains)
INFO - root - 2017-12-16 20:23:38.739578: step 91640, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.226 sec/batch; 15h:09m:08s remains)
INFO - root - 2017-12-16 20:23:40.952737: step 91650, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 14h:49m:06s remains)
INFO - root - 2017-12-16 20:23:43.155770: step 91660, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 14h:33m:06s remains)
INFO - root - 2017-12-16 20:23:45.358505: step 91670, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 14h:49m:02s remains)
INFO - root - 2017-12-16 20:23:47.592056: step 91680, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 14h:58m:50s remains)
INFO - root - 2017-12-16 20:23:49.815932: step 91690, loss = 0.48, batch loss = 0.30 (34.3 examples/sec; 0.233 sec/batch; 15h:34m:54s remains)
INFO - root - 2017-12-16 20:23:52.054747: step 91700, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 14h:42m:25s remains)
INFO - root - 2017-12-16 20:23:54.458848: step 91710, loss = 0.49, batch loss = 0.31 (34.7 examples/sec; 0.231 sec/batch; 15h:25m:49s remains)
INFO - root - 2017-12-16 20:23:56.671311: step 91720, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 14h:31m:13s remains)
INFO - root - 2017-12-16 20:23:58.875947: step 91730, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 14h:42m:21s remains)
INFO - root - 2017-12-16 20:24:01.054948: step 91740, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 14h:27m:40s remains)
INFO - root - 2017-12-16 20:24:03.267736: step 91750, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 14h:25m:25s remains)
INFO - root - 2017-12-16 20:24:05.465389: step 91760, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 14h:36m:49s remains)
INFO - root - 2017-12-16 20:24:07.678814: step 91770, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 14h:25m:21s remains)
INFO - root - 2017-12-16 20:24:09.881167: step 91780, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 15h:02m:35s remains)
INFO - root - 2017-12-16 20:24:12.103414: step 91790, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 14h:45m:43s remains)
INFO - root - 2017-12-16 20:24:14.338969: step 91800, loss = 0.48, batch loss = 0.30 (33.9 examples/sec; 0.236 sec/batch; 15h:45m:53s remains)
INFO - root - 2017-12-16 20:24:16.677156: step 91810, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 14h:43m:59s remains)
INFO - root - 2017-12-16 20:24:18.900688: step 91820, loss = 0.54, batch loss = 0.36 (35.5 examples/sec; 0.225 sec/batch; 15h:04m:05s remains)
INFO - root - 2017-12-16 20:24:21.122078: step 91830, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 15h:02m:30s remains)
INFO - root - 2017-12-16 20:24:23.340245: step 91840, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 15h:01m:51s remains)
INFO - root - 2017-12-16 20:24:25.568998: step 91850, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 14h:34m:12s remains)
INFO - root - 2017-12-16 20:24:27.809292: step 91860, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 14h:51m:34s remains)
INFO - root - 2017-12-16 20:24:30.039086: step 91870, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 14h:25m:28s remains)
INFO - root - 2017-12-16 20:24:32.252938: step 91880, loss = 0.45, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 14h:13m:28s remains)
INFO - root - 2017-12-16 20:24:34.485391: step 91890, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 14h:44m:47s remains)
INFO - root - 2017-12-16 20:24:36.724624: step 91900, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 14h:43m:47s remains)
INFO - root - 2017-12-16 20:24:39.039948: step 91910, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 14h:27m:10s remains)
INFO - root - 2017-12-16 20:24:41.272068: step 91920, loss = 0.48, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 14h:28m:40s remains)
INFO - root - 2017-12-16 20:24:43.449085: step 91930, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 14h:18m:09s remains)
INFO - root - 2017-12-16 20:24:45.662010: step 91940, loss = 0.55, batch loss = 0.37 (35.8 examples/sec; 0.224 sec/batch; 14h:56m:53s remains)
INFO - root - 2017-12-16 20:24:47.911440: step 91950, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 14h:41m:46s remains)
INFO - root - 2017-12-16 20:24:50.093719: step 91960, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 14h:40m:13s remains)
INFO - root - 2017-12-16 20:24:52.312805: step 91970, loss = 0.53, batch loss = 0.35 (33.6 examples/sec; 0.238 sec/batch; 15h:55m:50s remains)
INFO - root - 2017-12-16 20:24:54.535533: step 91980, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 14h:44m:07s remains)
INFO - root - 2017-12-16 20:24:56.733133: step 91990, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 14h:38m:33s remains)
INFO - root - 2017-12-16 20:24:58.962583: step 92000, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 15h:00m:05s remains)
INFO - root - 2017-12-16 20:25:01.320387: step 92010, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 14h:39m:25s remains)
INFO - root - 2017-12-16 20:25:03.521282: step 92020, loss = 0.55, batch loss = 0.37 (34.0 examples/sec; 0.235 sec/batch; 15h:41m:45s remains)
INFO - root - 2017-12-16 20:25:05.757783: step 92030, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 14h:18m:06s remains)
INFO - root - 2017-12-16 20:25:07.997978: step 92040, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 14h:49m:05s remains)
INFO - root - 2017-12-16 20:25:10.261191: step 92050, loss = 0.53, batch loss = 0.36 (37.3 examples/sec; 0.215 sec/batch; 14h:20m:04s remains)
INFO - root - 2017-12-16 20:25:12.458672: step 92060, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 14h:32m:52s remains)
INFO - root - 2017-12-16 20:25:14.649156: step 92070, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 14h:36m:43s remains)
INFO - root - 2017-12-16 20:25:16.866159: step 92080, loss = 0.50, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 14h:39m:16s remains)
INFO - root - 2017-12-16 20:25:19.113513: step 92090, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 15h:02m:23s remains)
INFO - root - 2017-12-16 20:25:21.319635: step 92100, loss = 0.50, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 14h:39m:44s remains)
INFO - root - 2017-12-16 20:25:23.674442: step 92110, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 15h:07m:29s remains)
INFO - root - 2017-12-16 20:25:25.906606: step 92120, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.231 sec/batch; 15h:27m:00s remains)
INFO - root - 2017-12-16 20:25:28.133250: step 92130, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 14h:56m:36s remains)
INFO - root - 2017-12-16 20:25:30.308257: step 92140, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 14h:15m:09s remains)
INFO - root - 2017-12-16 20:25:32.531848: step 92150, loss = 0.51, batch loss = 0.33 (34.9 examples/sec; 0.229 sec/batch; 15h:18m:23s remains)
INFO - root - 2017-12-16 20:25:34.767978: step 92160, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 14h:37m:00s remains)
INFO - root - 2017-12-16 20:25:36.964509: step 92170, loss = 0.43, batch loss = 0.25 (37.3 examples/sec; 0.214 sec/batch; 14h:19m:06s remains)
INFO - root - 2017-12-16 20:25:39.221284: step 92180, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 14h:28m:16s remains)
INFO - root - 2017-12-16 20:25:41.412719: step 92190, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 14h:30m:22s remains)
INFO - root - 2017-12-16 20:25:43.644157: step 92200, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 15h:00m:01s remains)
INFO - root - 2017-12-16 20:25:46.005729: step 92210, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 14h:36m:22s remains)
INFO - root - 2017-12-16 20:25:48.247172: step 92220, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 14h:58m:26s remains)
INFO - root - 2017-12-16 20:25:50.459704: step 92230, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 15h:02m:44s remains)
INFO - root - 2017-12-16 20:25:52.669731: step 92240, loss = 0.49, batch loss = 0.31 (34.5 examples/sec; 0.232 sec/batch; 15h:28m:41s remains)
INFO - root - 2017-12-16 20:25:54.866412: step 92250, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 14h:43m:43s remains)
INFO - root - 2017-12-16 20:25:57.086749: step 92260, loss = 0.57, batch loss = 0.39 (36.5 examples/sec; 0.219 sec/batch; 14h:37m:17s remains)
INFO - root - 2017-12-16 20:25:59.325969: step 92270, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 14h:24m:28s remains)
INFO - root - 2017-12-16 20:26:01.544823: step 92280, loss = 0.58, batch loss = 0.40 (36.8 examples/sec; 0.217 sec/batch; 14h:30m:44s remains)
INFO - root - 2017-12-16 20:26:03.768044: step 92290, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 14h:46m:31s remains)
INFO - root - 2017-12-16 20:26:06.041110: step 92300, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 15h:01m:33s remains)
INFO - root - 2017-12-16 20:26:08.397372: step 92310, loss = 0.54, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 14h:52m:50s remains)
INFO - root - 2017-12-16 20:26:10.609009: step 92320, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 14h:37m:59s remains)
INFO - root - 2017-12-16 20:26:12.783092: step 92330, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 14h:24m:57s remains)
INFO - root - 2017-12-16 20:26:15.007856: step 92340, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 14h:37m:51s remains)
INFO - root - 2017-12-16 20:26:17.181529: step 92350, loss = 0.42, batch loss = 0.25 (35.8 examples/sec; 0.224 sec/batch; 14h:55m:12s remains)
INFO - root - 2017-12-16 20:26:19.390935: step 92360, loss = 0.41, batch loss = 0.23 (35.5 examples/sec; 0.225 sec/batch; 15h:01m:29s remains)
INFO - root - 2017-12-16 20:26:21.574957: step 92370, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 14h:26m:12s remains)
INFO - root - 2017-12-16 20:26:23.771716: step 92380, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 14h:46m:37s remains)
INFO - root - 2017-12-16 20:26:25.983872: step 92390, loss = 0.47, batch loss = 0.29 (33.5 examples/sec; 0.239 sec/batch; 15h:55m:51s remains)
INFO - root - 2017-12-16 20:26:28.198886: step 92400, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 14h:39m:32s remains)
INFO - root - 2017-12-16 20:26:30.540684: step 92410, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 14h:44m:59s remains)
INFO - root - 2017-12-16 20:26:32.745073: step 92420, loss = 0.49, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 14h:09m:12s remains)
INFO - root - 2017-12-16 20:26:34.972131: step 92430, loss = 0.42, batch loss = 0.24 (36.0 examples/sec; 0.222 sec/batch; 14h:50m:00s remains)
INFO - root - 2017-12-16 20:26:37.171426: step 92440, loss = 0.52, batch loss = 0.35 (37.8 examples/sec; 0.212 sec/batch; 14h:06m:26s remains)
INFO - root - 2017-12-16 20:26:39.406769: step 92450, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 15h:15m:25s remains)
INFO - root - 2017-12-16 20:26:41.589350: step 92460, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 15h:01m:49s remains)
INFO - root - 2017-12-16 20:26:43.814937: step 92470, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 14h:56m:11s remains)
INFO - root - 2017-12-16 20:26:46.038854: step 92480, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 14h:43m:55s remains)
INFO - root - 2017-12-16 20:26:48.261938: step 92490, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 15h:01m:39s remains)
INFO - root - 2017-12-16 20:26:50.495326: step 92500, loss = 0.46, batch loss = 0.28 (33.9 examples/sec; 0.236 sec/batch; 15h:43m:35s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-92500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-92500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 20:26:53.507833: step 92510, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 14h:37m:25s remains)
INFO - root - 2017-12-16 20:26:55.705577: step 92520, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 15h:09m:52s remains)
INFO - root - 2017-12-16 20:26:57.918985: step 92530, loss = 0.42, batch loss = 0.24 (36.8 examples/sec; 0.217 sec/batch; 14h:29m:13s remains)
INFO - root - 2017-12-16 20:27:00.132707: step 92540, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 14h:45m:09s remains)
INFO - root - 2017-12-16 20:27:02.334080: step 92550, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 14h:52m:36s remains)
INFO - root - 2017-12-16 20:27:04.570678: step 92560, loss = 0.43, batch loss = 0.25 (34.3 examples/sec; 0.233 sec/batch; 15h:32m:37s remains)
INFO - root - 2017-12-16 20:27:06.815238: step 92570, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.232 sec/batch; 15h:29m:42s remains)
INFO - root - 2017-12-16 20:27:09.075260: step 92580, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 14h:58m:48s remains)
INFO - root - 2017-12-16 20:27:11.263043: step 92590, loss = 0.43, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 14h:15m:39s remains)
INFO - root - 2017-12-16 20:27:13.465406: step 92600, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.224 sec/batch; 14h:57m:16s remains)
INFO - root - 2017-12-16 20:27:15.828593: step 92610, loss = 0.47, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 14h:39m:14s remains)
INFO - root - 2017-12-16 20:27:18.077460: step 92620, loss = 0.44, batch loss = 0.26 (35.0 examples/sec; 0.228 sec/batch; 15h:12m:40s remains)
INFO - root - 2017-12-16 20:27:20.307831: step 92630, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 14h:48m:13s remains)
INFO - root - 2017-12-16 20:27:22.532630: step 92640, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.232 sec/batch; 15h:25m:36s remains)
INFO - root - 2017-12-16 20:27:24.783945: step 92650, loss = 0.45, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 14h:41m:48s remains)
INFO - root - 2017-12-16 20:27:26.990503: step 92660, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 14h:56m:10s remains)
INFO - root - 2017-12-16 20:27:29.241424: step 92670, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 14h:40m:30s remains)
INFO - root - 2017-12-16 20:27:31.460576: step 92680, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:51m:14s remains)
INFO - root - 2017-12-16 20:27:33.676448: step 92690, loss = 0.56, batch loss = 0.39 (36.9 examples/sec; 0.217 sec/batch; 14h:26m:49s remains)
INFO - root - 2017-12-16 20:27:35.896020: step 92700, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 15h:16m:59s remains)
INFO - root - 2017-12-16 20:27:38.260226: step 92710, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 15h:08m:57s remains)
INFO - root - 2017-12-16 20:27:40.543269: step 92720, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 14h:46m:21s remains)
INFO - root - 2017-12-16 20:27:42.740144: step 92730, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 15h:02m:28s remains)
INFO - root - 2017-12-16 20:27:44.972931: step 92740, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 14h:55m:00s remains)
INFO - root - 2017-12-16 20:27:47.189985: step 92750, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 14h:36m:59s remains)
INFO - root - 2017-12-16 20:27:49.436257: step 92760, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 14h:33m:57s remains)
INFO - root - 2017-12-16 20:27:51.665705: step 92770, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 14h:47m:52s remains)
INFO - root - 2017-12-16 20:27:53.876592: step 92780, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 14h:33m:00s remains)
INFO - root - 2017-12-16 20:27:56.124164: step 92790, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 15h:11m:29s remains)
INFO - root - 2017-12-16 20:27:58.338662: step 92800, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 14h:27m:01s remains)
INFO - root - 2017-12-16 20:28:00.745315: step 92810, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 15h:05m:01s remains)
INFO - root - 2017-12-16 20:28:02.965122: step 92820, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 14h:46m:01s remains)
INFO - root - 2017-12-16 20:28:05.218271: step 92830, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 14h:46m:37s remains)
INFO - root - 2017-12-16 20:28:07.446781: step 92840, loss = 0.46, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 15h:32m:15s remains)
INFO - root - 2017-12-16 20:28:09.671372: step 92850, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 14h:36m:18s remains)
INFO - root - 2017-12-16 20:28:11.899639: step 92860, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 14h:36m:52s remains)
INFO - root - 2017-12-16 20:28:14.099898: step 92870, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 14h:48m:24s remains)
INFO - root - 2017-12-16 20:28:16.355090: step 92880, loss = 0.47, batch loss = 0.29 (33.3 examples/sec; 0.240 sec/batch; 15h:59m:19s remains)
INFO - root - 2017-12-16 20:28:18.580043: step 92890, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.218 sec/batch; 14h:29m:19s remains)
INFO - root - 2017-12-16 20:28:20.794339: step 92900, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.229 sec/batch; 15h:12m:37s remains)
INFO - root - 2017-12-16 20:28:23.129890: step 92910, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 14h:34m:01s remains)
INFO - root - 2017-12-16 20:28:25.346039: step 92920, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 14h:51m:32s remains)
INFO - root - 2017-12-16 20:28:27.583165: step 92930, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 15h:10m:31s remains)
INFO - root - 2017-12-16 20:28:29.832641: step 92940, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 14h:37m:27s remains)
INFO - root - 2017-12-16 20:28:32.037700: step 92950, loss = 0.46, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 14h:57m:46s remains)
INFO - root - 2017-12-16 20:28:34.297160: step 92960, loss = 0.53, batch loss = 0.36 (36.2 examples/sec; 0.221 sec/batch; 14h:43m:13s remains)
INFO - root - 2017-12-16 20:28:36.486241: step 92970, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 14h:24m:06s remains)
INFO - root - 2017-12-16 20:28:38.718022: step 92980, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 14h:57m:23s remains)
INFO - root - 2017-12-16 20:28:40.939999: step 92990, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 14h:40m:58s remains)
INFO - root - 2017-12-16 20:28:43.129194: step 93000, loss = 0.42, batch loss = 0.24 (37.1 examples/sec; 0.216 sec/batch; 14h:21m:39s remains)
INFO - root - 2017-12-16 20:28:45.448377: step 93010, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 14h:32m:52s remains)
INFO - root - 2017-12-16 20:28:47.671999: step 93020, loss = 0.45, batch loss = 0.27 (34.6 examples/sec; 0.231 sec/batch; 15h:21m:55s remains)
INFO - root - 2017-12-16 20:28:49.864325: step 93030, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 15h:02m:43s remains)
INFO - root - 2017-12-16 20:28:52.125383: step 93040, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 15h:06m:31s remains)
INFO - root - 2017-12-16 20:28:54.337133: step 93050, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 14h:07m:56s remains)
INFO - root - 2017-12-16 20:28:56.501914: step 93060, loss = 0.56, batch loss = 0.38 (37.5 examples/sec; 0.213 sec/batch; 14h:10m:49s remains)
INFO - root - 2017-12-16 20:28:58.756222: step 93070, loss = 0.46, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 14h:34m:22s remains)
INFO - root - 2017-12-16 20:29:00.973596: step 93080, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 14h:52m:26s remains)
INFO - root - 2017-12-16 20:29:03.170660: step 93090, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 14h:47m:05s remains)
INFO - root - 2017-12-16 20:29:05.387057: step 93100, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 14h:29m:41s remains)
INFO - root - 2017-12-16 20:29:07.712603: step 93110, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 14h:24m:24s remains)
INFO - root - 2017-12-16 20:29:09.929382: step 93120, loss = 0.51, batch loss = 0.33 (37.5 examples/sec; 0.213 sec/batch; 14h:10m:41s remains)
INFO - root - 2017-12-16 20:29:12.166520: step 93130, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 14h:32m:38s remains)
INFO - root - 2017-12-16 20:29:14.353822: step 93140, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 14h:16m:36s remains)
INFO - root - 2017-12-16 20:29:16.522507: step 93150, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 14h:19m:39s remains)
INFO - root - 2017-12-16 20:29:18.730254: step 93160, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 14h:52m:26s remains)
INFO - root - 2017-12-16 20:29:20.942413: step 93170, loss = 0.54, batch loss = 0.37 (35.8 examples/sec; 0.224 sec/batch; 14h:52m:23s remains)
INFO - root - 2017-12-16 20:29:23.135717: step 93180, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 14h:30m:04s remains)
INFO - root - 2017-12-16 20:29:25.355077: step 93190, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 15h:08m:14s remains)
INFO - root - 2017-12-16 20:29:27.593987: step 93200, loss = 0.54, batch loss = 0.36 (35.6 examples/sec; 0.225 sec/batch; 14h:56m:45s remains)
INFO - root - 2017-12-16 20:29:29.896541: step 93210, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 14h:34m:25s remains)
INFO - root - 2017-12-16 20:29:32.073667: step 93220, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 14h:22m:18s remains)
INFO - root - 2017-12-16 20:29:34.336335: step 93230, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 15h:03m:37s remains)
INFO - root - 2017-12-16 20:29:36.570023: step 93240, loss = 0.45, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 14h:18m:50s remains)
INFO - root - 2017-12-16 20:29:38.773908: step 93250, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 14h:17m:33s remains)
INFO - root - 2017-12-16 20:29:40.982797: step 93260, loss = 0.48, batch loss = 0.30 (38.3 examples/sec; 0.209 sec/batch; 13h:53m:17s remains)
INFO - root - 2017-12-16 20:29:43.169604: step 93270, loss = 0.45, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 14h:46m:25s remains)
INFO - root - 2017-12-16 20:29:45.321053: step 93280, loss = 0.48, batch loss = 0.30 (37.8 examples/sec; 0.212 sec/batch; 14h:04m:29s remains)
INFO - root - 2017-12-16 20:29:47.523178: step 93290, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 15h:00m:17s remains)
INFO - root - 2017-12-16 20:29:49.713747: step 93300, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 14h:23m:58s remains)
INFO - root - 2017-12-16 20:29:51.994836: step 93310, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 14h:21m:52s remains)
INFO - root - 2017-12-16 20:29:54.212137: step 93320, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 14h:18m:52s remains)
INFO - root - 2017-12-16 20:29:56.418259: step 93330, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 14h:41m:38s remains)
INFO - root - 2017-12-16 20:29:58.619539: step 93340, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 14h:15m:51s remains)
INFO - root - 2017-12-16 20:30:00.800321: step 93350, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 14h:29m:11s remains)
INFO - root - 2017-12-16 20:30:03.015629: step 93360, loss = 0.50, batch loss = 0.32 (37.6 examples/sec; 0.213 sec/batch; 14h:08m:47s remains)
INFO - root - 2017-12-16 20:30:05.232361: step 93370, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 14h:17m:10s remains)
INFO - root - 2017-12-16 20:30:07.488772: step 93380, loss = 0.51, batch loss = 0.33 (35.1 examples/sec; 0.228 sec/batch; 15h:07m:55s remains)
INFO - root - 2017-12-16 20:30:09.672127: step 93390, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 14h:14m:47s remains)
INFO - root - 2017-12-16 20:30:11.870765: step 93400, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 14h:20m:59s remains)
INFO - root - 2017-12-16 20:30:14.245284: step 93410, loss = 0.45, batch loss = 0.27 (37.9 examples/sec; 0.211 sec/batch; 14h:01m:34s remains)
INFO - root - 2017-12-16 20:30:16.455475: step 93420, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.223 sec/batch; 14h:46m:36s remains)
INFO - root - 2017-12-16 20:30:18.683320: step 93430, loss = 0.56, batch loss = 0.38 (36.5 examples/sec; 0.219 sec/batch; 14h:33m:00s remains)
INFO - root - 2017-12-16 20:30:20.947760: step 93440, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.218 sec/batch; 14h:29m:56s remains)
INFO - root - 2017-12-16 20:30:23.122290: step 93450, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 14h:24m:53s remains)
INFO - root - 2017-12-16 20:30:25.314142: step 93460, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.215 sec/batch; 14h:14m:57s remains)
INFO - root - 2017-12-16 20:30:27.508713: step 93470, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 14h:34m:27s remains)
INFO - root - 2017-12-16 20:30:29.744847: step 93480, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 14h:36m:01s remains)
INFO - root - 2017-12-16 20:30:31.939607: step 93490, loss = 0.47, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 14h:25m:47s remains)
INFO - root - 2017-12-16 20:30:34.141335: step 93500, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 15h:21m:21s remains)
INFO - root - 2017-12-16 20:30:36.473295: step 93510, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.218 sec/batch; 14h:26m:58s remains)
INFO - root - 2017-12-16 20:30:38.690545: step 93520, loss = 0.49, batch loss = 0.31 (33.7 examples/sec; 0.237 sec/batch; 15h:45m:51s remains)
INFO - root - 2017-12-16 20:30:40.928800: step 93530, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 15h:01m:20s remains)
INFO - root - 2017-12-16 20:30:43.138875: step 93540, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 15h:00m:09s remains)
INFO - root - 2017-12-16 20:30:45.361765: step 93550, loss = 0.44, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 14h:57m:41s remains)
INFO - root - 2017-12-16 20:30:47.580587: step 93560, loss = 0.50, batch loss = 0.32 (33.7 examples/sec; 0.237 sec/batch; 15h:44m:17s remains)
INFO - root - 2017-12-16 20:30:49.768930: step 93570, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 14h:55m:39s remains)
INFO - root - 2017-12-16 20:30:52.040048: step 93580, loss = 0.54, batch loss = 0.36 (35.5 examples/sec; 0.226 sec/batch; 14h:58m:05s remains)
INFO - root - 2017-12-16 20:30:54.250370: step 93590, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 14h:28m:00s remains)
INFO - root - 2017-12-16 20:30:56.453817: step 93600, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 14h:21m:10s remains)
INFO - root - 2017-12-16 20:30:58.838604: step 93610, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 14h:53m:13s remains)
INFO - root - 2017-12-16 20:31:01.066417: step 93620, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.224 sec/batch; 14h:53m:46s remains)
INFO - root - 2017-12-16 20:31:03.248416: step 93630, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 14h:12m:29s remains)
INFO - root - 2017-12-16 20:31:05.482509: step 93640, loss = 0.43, batch loss = 0.25 (35.0 examples/sec; 0.229 sec/batch; 15h:10m:57s remains)
INFO - root - 2017-12-16 20:31:07.718118: step 93650, loss = 0.48, batch loss = 0.31 (34.7 examples/sec; 0.231 sec/batch; 15h:17m:39s remains)
INFO - root - 2017-12-16 20:31:09.949605: step 93660, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 14h:43m:15s remains)
INFO - root - 2017-12-16 20:31:12.178536: step 93670, loss = 0.46, batch loss = 0.28 (34.5 examples/sec; 0.232 sec/batch; 15h:23m:25s remains)
INFO - root - 2017-12-16 20:31:14.375201: step 93680, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 14h:26m:12s remains)
INFO - root - 2017-12-16 20:31:16.571090: step 93690, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 14h:55m:34s remains)
INFO - root - 2017-12-16 20:31:18.824044: step 93700, loss = 0.49, batch loss = 0.31 (34.3 examples/sec; 0.233 sec/batch; 15h:27m:04s remains)
INFO - root - 2017-12-16 20:31:21.151682: step 93710, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 14h:30m:19s remains)
INFO - root - 2017-12-16 20:31:23.363974: step 93720, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.216 sec/batch; 14h:18m:25s remains)
INFO - root - 2017-12-16 20:31:25.576173: step 93730, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 14h:12m:57s remains)
INFO - root - 2017-12-16 20:31:27.776568: step 93740, loss = 0.51, batch loss = 0.33 (34.5 examples/sec; 0.232 sec/batch; 15h:23m:19s remains)
INFO - root - 2017-12-16 20:31:30.004336: step 93750, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.216 sec/batch; 14h:18m:43s remains)
INFO - root - 2017-12-16 20:31:32.162584: step 93760, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 14h:22m:16s remains)
INFO - root - 2017-12-16 20:31:34.375589: step 93770, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 14h:58m:36s remains)
INFO - root - 2017-12-16 20:31:36.566441: step 93780, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 14h:13m:17s remains)
INFO - root - 2017-12-16 20:31:38.779854: step 93790, loss = 0.43, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 14h:49m:43s remains)
INFO - root - 2017-12-16 20:31:41.009310: step 93800, loss = 0.47, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 14h:30m:30s remains)
INFO - root - 2017-12-16 20:31:43.330358: step 93810, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 14h:12m:45s remains)
INFO - root - 2017-12-16 20:31:45.547208: step 93820, loss = 0.43, batch loss = 0.25 (35.2 examples/sec; 0.227 sec/batch; 15h:03m:45s remains)
INFO - root - 2017-12-16 20:31:47.770295: step 93830, loss = 0.61, batch loss = 0.43 (33.5 examples/sec; 0.239 sec/batch; 15h:50m:29s remains)
INFO - root - 2017-12-16 20:31:49.997788: step 93840, loss = 0.54, batch loss = 0.36 (37.7 examples/sec; 0.212 sec/batch; 14h:05m:06s remains)
INFO - root - 2017-12-16 20:31:52.191324: step 93850, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 14h:27m:38s remains)
INFO - root - 2017-12-16 20:31:54.416090: step 93860, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 14h:34m:34s remains)
INFO - root - 2017-12-16 20:31:56.609751: step 93870, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 14h:21m:28s remains)
INFO - root - 2017-12-16 20:31:58.824792: step 93880, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 14h:22m:06s remains)
INFO - root - 2017-12-16 20:32:01.017613: step 93890, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 14h:23m:38s remains)
INFO - root - 2017-12-16 20:32:03.217735: step 93900, loss = 0.55, batch loss = 0.37 (37.2 examples/sec; 0.215 sec/batch; 14h:15m:05s remains)
INFO - root - 2017-12-16 20:32:05.543611: step 93910, loss = 0.50, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 14h:26m:39s remains)
INFO - root - 2017-12-16 20:32:07.734959: step 93920, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 14h:20m:20s remains)
INFO - root - 2017-12-16 20:32:09.933344: step 93930, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 14h:10m:34s remains)
INFO - root - 2017-12-16 20:32:12.156132: step 93940, loss = 0.45, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 14h:36m:19s remains)
INFO - root - 2017-12-16 20:32:14.420263: step 93950, loss = 0.46, batch loss = 0.28 (32.8 examples/sec; 0.244 sec/batch; 16h:09m:49s remains)
INFO - root - 2017-12-16 20:32:16.635677: step 93960, loss = 0.45, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 14h:20m:59s remains)
INFO - root - 2017-12-16 20:32:18.851319: step 93970, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 14h:29m:31s remains)
INFO - root - 2017-12-16 20:32:21.066066: step 93980, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 14h:30m:38s remains)
INFO - root - 2017-12-16 20:32:23.280133: step 93990, loss = 0.46, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 14h:44m:36s remains)
INFO - root - 2017-12-16 20:32:25.496057: step 94000, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 14h:28m:58s remains)
INFO - root - 2017-12-16 20:32:27.827894: step 94010, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:45m:53s remains)
INFO - root - 2017-12-16 20:32:30.043546: step 94020, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 14h:19m:09s remains)
INFO - root - 2017-12-16 20:32:32.250987: step 94030, loss = 0.42, batch loss = 0.24 (36.6 examples/sec; 0.218 sec/batch; 14h:27m:56s remains)
INFO - root - 2017-12-16 20:32:34.494466: step 94040, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 14h:22m:02s remains)
INFO - root - 2017-12-16 20:32:36.719606: step 94050, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.221 sec/batch; 14h:36m:39s remains)
INFO - root - 2017-12-16 20:32:38.923635: step 94060, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 14h:24m:09s remains)
INFO - root - 2017-12-16 20:32:41.147477: step 94070, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 14h:37m:24s remains)
INFO - root - 2017-12-16 20:32:43.385385: step 94080, loss = 0.55, batch loss = 0.38 (35.8 examples/sec; 0.224 sec/batch; 14h:48m:15s remains)
INFO - root - 2017-12-16 20:32:45.618507: step 94090, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 14h:55m:24s remains)
INFO - root - 2017-12-16 20:32:47.818831: step 94100, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 14h:44m:27s remains)
INFO - root - 2017-12-16 20:32:50.133437: step 94110, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 14h:17m:02s remains)
INFO - root - 2017-12-16 20:32:52.353006: step 94120, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 14h:23m:50s remains)
INFO - root - 2017-12-16 20:32:54.582721: step 94130, loss = 0.56, batch loss = 0.38 (34.8 examples/sec; 0.230 sec/batch; 15h:12m:49s remains)
INFO - root - 2017-12-16 20:32:56.782627: step 94140, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 14h:41m:40s remains)
INFO - root - 2017-12-16 20:32:58.973309: step 94150, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 14h:21m:58s remains)
INFO - root - 2017-12-16 20:33:01.193115: step 94160, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 14h:53m:53s remains)
INFO - root - 2017-12-16 20:33:03.442720: step 94170, loss = 0.46, batch loss = 0.28 (34.0 examples/sec; 0.235 sec/batch; 15h:34m:48s remains)
INFO - root - 2017-12-16 20:33:05.639266: step 94180, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 14h:26m:15s remains)
INFO - root - 2017-12-16 20:33:07.830062: step 94190, loss = 0.47, batch loss = 0.29 (38.5 examples/sec; 0.208 sec/batch; 13h:46m:03s remains)
INFO - root - 2017-12-16 20:33:10.116798: step 94200, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 15h:09m:16s remains)
INFO - root - 2017-12-16 20:33:12.461874: step 94210, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 15h:04m:32s remains)
INFO - root - 2017-12-16 20:33:14.645871: step 94220, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 14h:19m:21s remains)
INFO - root - 2017-12-16 20:33:16.883137: step 94230, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.221 sec/batch; 14h:39m:34s remains)
INFO - root - 2017-12-16 20:33:19.149893: step 94240, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 14h:26m:16s remains)
INFO - root - 2017-12-16 20:33:21.378176: step 94250, loss = 0.47, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 14h:04m:27s remains)
INFO - root - 2017-12-16 20:33:23.591680: step 94260, loss = 0.49, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 14h:32m:45s remains)
INFO - root - 2017-12-16 20:33:25.808261: step 94270, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 14h:33m:46s remains)
INFO - root - 2017-12-16 20:33:28.076489: step 94280, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 14h:47m:11s remains)
INFO - root - 2017-12-16 20:33:30.311567: step 94290, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.224 sec/batch; 14h:51m:10s remains)
INFO - root - 2017-12-16 20:33:32.504370: step 94300, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 14h:21m:15s remains)
INFO - root - 2017-12-16 20:33:34.826410: step 94310, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 14h:13m:36s remains)
INFO - root - 2017-12-16 20:33:37.019497: step 94320, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 14h:37m:50s remains)
INFO - root - 2017-12-16 20:33:39.255844: step 94330, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 14h:40m:40s remains)
INFO - root - 2017-12-16 20:33:41.430537: step 94340, loss = 0.54, batch loss = 0.36 (35.6 examples/sec; 0.224 sec/batch; 14h:51m:00s remains)
INFO - root - 2017-12-16 20:33:43.682769: step 94350, loss = 0.50, batch loss = 0.33 (35.1 examples/sec; 0.228 sec/batch; 15h:05m:01s remains)
INFO - root - 2017-12-16 20:33:45.894560: step 94360, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 14h:30m:30s remains)
INFO - root - 2017-12-16 20:33:48.105610: step 94370, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 14h:30m:06s remains)
INFO - root - 2017-12-16 20:33:50.351151: step 94380, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 14h:31m:12s remains)
INFO - root - 2017-12-16 20:33:52.559836: step 94390, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 15h:10m:26s remains)
INFO - root - 2017-12-16 20:33:54.806603: step 94400, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 14h:22m:19s remains)
INFO - root - 2017-12-16 20:33:57.125081: step 94410, loss = 0.44, batch loss = 0.26 (38.0 examples/sec; 0.210 sec/batch; 13h:54m:48s remains)
INFO - root - 2017-12-16 20:33:59.338654: step 94420, loss = 0.50, batch loss = 0.33 (34.5 examples/sec; 0.232 sec/batch; 15h:20m:38s remains)
INFO - root - 2017-12-16 20:34:01.603378: step 94430, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 14h:14m:23s remains)
INFO - root - 2017-12-16 20:34:03.836255: step 94440, loss = 0.48, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 14h:21m:00s remains)
INFO - root - 2017-12-16 20:34:06.041970: step 94450, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 14h:25m:34s remains)
INFO - root - 2017-12-16 20:34:08.255885: step 94460, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:45m:13s remains)
INFO - root - 2017-12-16 20:34:10.515136: step 94470, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 15h:03m:11s remains)
INFO - root - 2017-12-16 20:34:12.741714: step 94480, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 15h:05m:13s remains)
INFO - root - 2017-12-16 20:34:14.971862: step 94490, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 14h:24m:14s remains)
INFO - root - 2017-12-16 20:34:17.154570: step 94500, loss = 0.54, batch loss = 0.36 (36.2 examples/sec; 0.221 sec/batch; 14h:37m:37s remains)
INFO - root - 2017-12-16 20:34:19.495164: step 94510, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 14h:40m:36s remains)
INFO - root - 2017-12-16 20:34:21.727866: step 94520, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 14h:58m:33s remains)
INFO - root - 2017-12-16 20:34:23.965268: step 94530, loss = 0.44, batch loss = 0.26 (35.0 examples/sec; 0.229 sec/batch; 15h:07m:30s remains)
INFO - root - 2017-12-16 20:34:26.173950: step 94540, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 14h:48m:33s remains)
INFO - root - 2017-12-16 20:34:28.410809: step 94550, loss = 0.45, batch loss = 0.27 (31.9 examples/sec; 0.251 sec/batch; 16h:34m:18s remains)
INFO - root - 2017-12-16 20:34:30.621569: step 94560, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 14h:32m:46s remains)
INFO - root - 2017-12-16 20:34:32.848185: step 94570, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 15h:02m:51s remains)
INFO - root - 2017-12-16 20:34:35.053992: step 94580, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 14h:21m:59s remains)
INFO - root - 2017-12-16 20:34:37.283944: step 94590, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 14h:54m:30s remains)
INFO - root - 2017-12-16 20:34:39.504810: step 94600, loss = 0.48, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 14h:18m:13s remains)
INFO - root - 2017-12-16 20:34:41.861761: step 94610, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 14h:55m:40s remains)
INFO - root - 2017-12-16 20:34:44.112620: step 94620, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 14h:23m:06s remains)
INFO - root - 2017-12-16 20:34:46.311746: step 94630, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 14h:23m:35s remains)
INFO - root - 2017-12-16 20:34:48.513850: step 94640, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 14h:26m:40s remains)
INFO - root - 2017-12-16 20:34:50.732238: step 94650, loss = 0.53, batch loss = 0.35 (32.4 examples/sec; 0.247 sec/batch; 16h:18m:13s remains)
INFO - root - 2017-12-16 20:34:52.958728: step 94660, loss = 0.51, batch loss = 0.33 (34.6 examples/sec; 0.231 sec/batch; 15h:17m:16s remains)
INFO - root - 2017-12-16 20:34:55.187414: step 94670, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 14h:12m:30s remains)
INFO - root - 2017-12-16 20:34:57.424964: step 94680, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 14h:30m:01s remains)
INFO - root - 2017-12-16 20:34:59.651302: step 94690, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 14h:36m:17s remains)
INFO - root - 2017-12-16 20:35:01.841223: step 94700, loss = 0.50, batch loss = 0.32 (37.6 examples/sec; 0.213 sec/batch; 14h:04m:10s remains)
INFO - root - 2017-12-16 20:35:04.184818: step 94710, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 14h:11m:35s remains)
INFO - root - 2017-12-16 20:35:06.369389: step 94720, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 14h:16m:25s remains)
INFO - root - 2017-12-16 20:35:08.553724: step 94730, loss = 0.48, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 14h:35m:13s remains)
INFO - root - 2017-12-16 20:35:10.823966: step 94740, loss = 0.45, batch loss = 0.27 (33.9 examples/sec; 0.236 sec/batch; 15h:34m:10s remains)
INFO - root - 2017-12-16 20:35:13.036286: step 94750, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 14h:57m:42s remains)
INFO - root - 2017-12-16 20:35:15.240946: step 94760, loss = 0.43, batch loss = 0.25 (34.1 examples/sec; 0.235 sec/batch; 15h:30m:30s remains)
INFO - root - 2017-12-16 20:35:17.511060: step 94770, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 14h:47m:26s remains)
INFO - root - 2017-12-16 20:35:19.715949: step 94780, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 14h:28m:30s remains)
INFO - root - 2017-12-16 20:35:21.903342: step 94790, loss = 0.51, batch loss = 0.34 (36.3 examples/sec; 0.221 sec/batch; 14h:33m:49s remains)
INFO - root - 2017-12-16 20:35:24.138790: step 94800, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 15h:03m:10s remains)
INFO - root - 2017-12-16 20:35:26.467833: step 94810, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 14h:27m:10s remains)
INFO - root - 2017-12-16 20:35:28.691536: step 94820, loss = 0.48, batch loss = 0.30 (33.5 examples/sec; 0.239 sec/batch; 15h:45m:25s remains)
INFO - root - 2017-12-16 20:35:30.890801: step 94830, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 14h:22m:54s remains)
INFO - root - 2017-12-16 20:35:33.080679: step 94840, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.223 sec/batch; 14h:41m:24s remains)
INFO - root - 2017-12-16 20:35:35.305613: step 94850, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 14h:48m:19s remains)
INFO - root - 2017-12-16 20:35:37.525013: step 94860, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 14h:30m:26s remains)
INFO - root - 2017-12-16 20:35:39.760620: step 94870, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 14h:18m:34s remains)
INFO - root - 2017-12-16 20:35:41.979387: step 94880, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 14h:45m:32s remains)
INFO - root - 2017-12-16 20:35:44.221403: step 94890, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 14h:25m:48s remains)
INFO - root - 2017-12-16 20:35:46.442988: step 94900, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 14h:43m:49s remains)
INFO - root - 2017-12-16 20:35:48.778886: step 94910, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 14h:43m:06s remains)
INFO - root - 2017-12-16 20:35:51.045858: step 94920, loss = 0.43, batch loss = 0.25 (32.7 examples/sec; 0.245 sec/batch; 16h:10m:06s remains)
INFO - root - 2017-12-16 20:35:53.292323: step 94930, loss = 0.47, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 14h:30m:06s remains)
INFO - root - 2017-12-16 20:35:55.486338: step 94940, loss = 0.55, batch loss = 0.37 (37.5 examples/sec; 0.213 sec/batch; 14h:03m:50s remains)
INFO - root - 2017-12-16 20:35:57.714475: step 94950, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 14h:16m:34s remains)
INFO - root - 2017-12-16 20:35:59.952221: step 94960, loss = 0.48, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 14h:49m:38s remains)
INFO - root - 2017-12-16 20:36:02.193894: step 94970, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 14h:26m:16s remains)
INFO - root - 2017-12-16 20:36:04.423497: step 94980, loss = 0.42, batch loss = 0.24 (36.1 examples/sec; 0.222 sec/batch; 14h:36m:56s remains)
INFO - root - 2017-12-16 20:36:06.639397: step 94990, loss = 0.55, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 14h:28m:09s remains)
INFO - root - 2017-12-16 20:36:08.812027: step 95000, loss = 0.52, batch loss = 0.35 (34.6 examples/sec; 0.231 sec/batch; 15h:14m:11s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-95000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-95000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 20:36:11.604821: step 95010, loss = 0.50, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 14h:34m:25s remains)
INFO - root - 2017-12-16 20:36:13.826977: step 95020, loss = 0.53, batch loss = 0.35 (35.2 examples/sec; 0.227 sec/batch; 14h:59m:28s remains)
INFO - root - 2017-12-16 20:36:16.071166: step 95030, loss = 0.42, batch loss = 0.24 (36.1 examples/sec; 0.222 sec/batch; 14h:37m:08s remains)
INFO - root - 2017-12-16 20:36:18.261936: step 95040, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.229 sec/batch; 15h:05m:30s remains)
INFO - root - 2017-12-16 20:36:20.485516: step 95050, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 14h:49m:49s remains)
INFO - root - 2017-12-16 20:36:22.738320: step 95060, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 14h:49m:30s remains)
INFO - root - 2017-12-16 20:36:24.967652: step 95070, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 14h:38m:19s remains)
INFO - root - 2017-12-16 20:36:27.189232: step 95080, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 14h:21m:03s remains)
INFO - root - 2017-12-16 20:36:29.400272: step 95090, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 14h:33m:41s remains)
INFO - root - 2017-12-16 20:36:31.604457: step 95100, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.223 sec/batch; 14h:43m:21s remains)
INFO - root - 2017-12-16 20:36:33.984244: step 95110, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 14h:41m:41s remains)
INFO - root - 2017-12-16 20:36:36.267294: step 95120, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 14h:27m:03s remains)
INFO - root - 2017-12-16 20:36:38.479467: step 95130, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.224 sec/batch; 14h:48m:05s remains)
INFO - root - 2017-12-16 20:36:40.687133: step 95140, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 14h:55m:58s remains)
INFO - root - 2017-12-16 20:36:42.896442: step 95150, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 14h:39m:03s remains)
INFO - root - 2017-12-16 20:36:45.122859: step 95160, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 14h:20m:39s remains)
INFO - root - 2017-12-16 20:36:47.327225: step 95170, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.221 sec/batch; 14h:32m:52s remains)
INFO - root - 2017-12-16 20:36:49.538300: step 95180, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 14h:21m:02s remains)
INFO - root - 2017-12-16 20:36:51.739652: step 95190, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 14h:19m:44s remains)
INFO - root - 2017-12-16 20:36:53.936718: step 95200, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 15h:00m:28s remains)
INFO - root - 2017-12-16 20:36:56.274697: step 95210, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 14h:41m:56s remains)
INFO - root - 2017-12-16 20:36:58.455865: step 95220, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 14h:16m:50s remains)
INFO - root - 2017-12-16 20:37:00.651443: step 95230, loss = 0.48, batch loss = 0.30 (37.9 examples/sec; 0.211 sec/batch; 13h:55m:48s remains)
INFO - root - 2017-12-16 20:37:02.882155: step 95240, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 14h:31m:42s remains)
INFO - root - 2017-12-16 20:37:05.091055: step 95250, loss = 0.57, batch loss = 0.39 (36.4 examples/sec; 0.220 sec/batch; 14h:28m:00s remains)
INFO - root - 2017-12-16 20:37:07.321370: step 95260, loss = 0.45, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 14h:38m:23s remains)
INFO - root - 2017-12-16 20:37:09.558090: step 95270, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 14h:43m:00s remains)
INFO - root - 2017-12-16 20:37:11.773087: step 95280, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 14h:38m:22s remains)
INFO - root - 2017-12-16 20:37:13.970864: step 95290, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 14h:22m:53s remains)
INFO - root - 2017-12-16 20:37:16.199103: step 95300, loss = 0.53, batch loss = 0.35 (35.8 examples/sec; 0.223 sec/batch; 14h:43m:20s remains)
INFO - root - 2017-12-16 20:37:18.509636: step 95310, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 14h:27m:53s remains)
INFO - root - 2017-12-16 20:37:20.754133: step 95320, loss = 0.44, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 14h:01m:39s remains)
INFO - root - 2017-12-16 20:37:22.972295: step 95330, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 14h:34m:04s remains)
INFO - root - 2017-12-16 20:37:25.213291: step 95340, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 14h:45m:49s remains)
INFO - root - 2017-12-16 20:37:27.421818: step 95350, loss = 0.42, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 14h:33m:38s remains)
INFO - root - 2017-12-16 20:37:29.627198: step 95360, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 14h:31m:11s remains)
INFO - root - 2017-12-16 20:37:31.840832: step 95370, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 14h:16m:32s remains)
INFO - root - 2017-12-16 20:37:34.058908: step 95380, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 14h:28m:21s remains)
INFO - root - 2017-12-16 20:37:36.285275: step 95390, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 14h:32m:08s remains)
INFO - root - 2017-12-16 20:37:38.524915: step 95400, loss = 0.55, batch loss = 0.37 (36.1 examples/sec; 0.221 sec/batch; 14h:34m:46s remains)
INFO - root - 2017-12-16 20:37:40.868933: step 95410, loss = 0.45, batch loss = 0.28 (35.0 examples/sec; 0.228 sec/batch; 15h:02m:31s remains)
INFO - root - 2017-12-16 20:37:43.066140: step 95420, loss = 0.57, batch loss = 0.39 (36.7 examples/sec; 0.218 sec/batch; 14h:21m:37s remains)
INFO - root - 2017-12-16 20:37:45.278719: step 95430, loss = 0.50, batch loss = 0.32 (37.6 examples/sec; 0.213 sec/batch; 14h:01m:01s remains)
INFO - root - 2017-12-16 20:37:47.493310: step 95440, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 14h:20m:19s remains)
INFO - root - 2017-12-16 20:37:49.719911: step 95450, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 14h:21m:05s remains)
INFO - root - 2017-12-16 20:37:51.942417: step 95460, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 14h:56m:27s remains)
INFO - root - 2017-12-16 20:37:54.156898: step 95470, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 14h:32m:36s remains)
INFO - root - 2017-12-16 20:37:56.374576: step 95480, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 14h:47m:32s remains)
INFO - root - 2017-12-16 20:37:58.595143: step 95490, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 14h:14m:38s remains)
INFO - root - 2017-12-16 20:38:00.823972: step 95500, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 14h:25m:28s remains)
INFO - root - 2017-12-16 20:38:03.180933: step 95510, loss = 0.47, batch loss = 0.29 (33.9 examples/sec; 0.236 sec/batch; 15h:33m:07s remains)
INFO - root - 2017-12-16 20:38:05.407505: step 95520, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 14h:39m:04s remains)
INFO - root - 2017-12-16 20:38:07.619417: step 95530, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 14h:30m:40s remains)
INFO - root - 2017-12-16 20:38:09.816740: step 95540, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 14h:25m:14s remains)
INFO - root - 2017-12-16 20:38:12.040252: step 95550, loss = 0.47, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 14h:24m:56s remains)
INFO - root - 2017-12-16 20:38:14.300368: step 95560, loss = 0.45, batch loss = 0.27 (34.3 examples/sec; 0.233 sec/batch; 15h:20m:05s remains)
INFO - root - 2017-12-16 20:38:16.496225: step 95570, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 14h:39m:39s remains)
INFO - root - 2017-12-16 20:38:18.702942: step 95580, loss = 0.41, batch loss = 0.24 (36.0 examples/sec; 0.222 sec/batch; 14h:36m:35s remains)
INFO - root - 2017-12-16 20:38:20.928156: step 95590, loss = 0.44, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 14h:55m:33s remains)
INFO - root - 2017-12-16 20:38:23.152331: step 95600, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 14h:17m:13s remains)
INFO - root - 2017-12-16 20:38:25.522673: step 95610, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 14h:55m:18s remains)
INFO - root - 2017-12-16 20:38:27.737990: step 95620, loss = 0.50, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 14h:46m:21s remains)
INFO - root - 2017-12-16 20:38:29.945741: step 95630, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 15h:14m:10s remains)
INFO - root - 2017-12-16 20:38:32.152356: step 95640, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 14h:52m:16s remains)
INFO - root - 2017-12-16 20:38:34.363926: step 95650, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 14h:37m:23s remains)
INFO - root - 2017-12-16 20:38:36.578688: step 95660, loss = 0.55, batch loss = 0.37 (36.3 examples/sec; 0.221 sec/batch; 14h:30m:26s remains)
INFO - root - 2017-12-16 20:38:38.788840: step 95670, loss = 0.43, batch loss = 0.25 (37.0 examples/sec; 0.216 sec/batch; 14h:14m:16s remains)
INFO - root - 2017-12-16 20:38:41.020598: step 95680, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 14h:57m:25s remains)
INFO - root - 2017-12-16 20:38:43.209848: step 95690, loss = 0.50, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 14h:21m:26s remains)
INFO - root - 2017-12-16 20:38:45.387952: step 95700, loss = 0.45, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:40m:25s remains)
INFO - root - 2017-12-16 20:38:47.739168: step 95710, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 14h:45m:06s remains)
INFO - root - 2017-12-16 20:38:49.989819: step 95720, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 14h:24m:54s remains)
INFO - root - 2017-12-16 20:38:52.230498: step 95730, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 14h:52m:40s remains)
INFO - root - 2017-12-16 20:38:54.426769: step 95740, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 14h:44m:21s remains)
INFO - root - 2017-12-16 20:38:56.650377: step 95750, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.215 sec/batch; 14h:10m:11s remains)
INFO - root - 2017-12-16 20:38:58.838190: step 95760, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 14h:10m:58s remains)
INFO - root - 2017-12-16 20:39:01.032306: step 95770, loss = 0.44, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 14h:21m:24s remains)
INFO - root - 2017-12-16 20:39:03.236756: step 95780, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 14h:25m:38s remains)
INFO - root - 2017-12-16 20:39:05.498516: step 95790, loss = 0.58, batch loss = 0.40 (35.3 examples/sec; 0.227 sec/batch; 14h:54m:31s remains)
INFO - root - 2017-12-16 20:39:07.730002: step 95800, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 14h:46m:01s remains)
INFO - root - 2017-12-16 20:39:10.075385: step 95810, loss = 0.53, batch loss = 0.35 (35.3 examples/sec; 0.226 sec/batch; 14h:53m:08s remains)
INFO - root - 2017-12-16 20:39:12.288674: step 95820, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 15h:04m:48s remains)
INFO - root - 2017-12-16 20:39:14.521875: step 95830, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 14h:39m:12s remains)
INFO - root - 2017-12-16 20:39:16.748810: step 95840, loss = 0.46, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 14h:11m:45s remains)
INFO - root - 2017-12-16 20:39:18.970488: step 95850, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 14h:10m:58s remains)
INFO - root - 2017-12-16 20:39:21.189043: step 95860, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 14h:59m:48s remains)
INFO - root - 2017-12-16 20:39:23.449923: step 95870, loss = 0.47, batch loss = 0.29 (33.0 examples/sec; 0.243 sec/batch; 15h:56m:54s remains)
INFO - root - 2017-12-16 20:39:25.668248: step 95880, loss = 0.50, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 14h:18m:33s remains)
INFO - root - 2017-12-16 20:39:27.928888: step 95890, loss = 0.54, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 14h:25m:20s remains)
INFO - root - 2017-12-16 20:39:30.102662: step 95900, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 14h:08m:07s remains)
INFO - root - 2017-12-16 20:39:32.458812: step 95910, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:39m:16s remains)
INFO - root - 2017-12-16 20:39:34.678765: step 95920, loss = 0.47, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 14h:17m:03s remains)
INFO - root - 2017-12-16 20:39:36.910380: step 95930, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 14h:47m:07s remains)
INFO - root - 2017-12-16 20:39:39.127365: step 95940, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 14h:06m:34s remains)
INFO - root - 2017-12-16 20:39:41.331583: step 95950, loss = 0.53, batch loss = 0.35 (37.4 examples/sec; 0.214 sec/batch; 14h:03m:24s remains)
INFO - root - 2017-12-16 20:39:43.556749: step 95960, loss = 0.43, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 14h:16m:43s remains)
INFO - root - 2017-12-16 20:39:45.791206: step 95970, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 14h:08m:02s remains)
INFO - root - 2017-12-16 20:39:48.019737: step 95980, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 14h:31m:09s remains)
INFO - root - 2017-12-16 20:39:50.239918: step 95990, loss = 0.50, batch loss = 0.32 (34.3 examples/sec; 0.233 sec/batch; 15h:19m:55s remains)
INFO - root - 2017-12-16 20:39:52.435790: step 96000, loss = 0.44, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 14h:57m:59s remains)
INFO - root - 2017-12-16 20:39:54.821356: step 96010, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 14h:32m:33s remains)
INFO - root - 2017-12-16 20:39:57.065372: step 96020, loss = 0.53, batch loss = 0.35 (32.2 examples/sec; 0.248 sec/batch; 16h:18m:16s remains)
INFO - root - 2017-12-16 20:39:59.321504: step 96030, loss = 0.58, batch loss = 0.40 (34.1 examples/sec; 0.234 sec/batch; 15h:23m:38s remains)
INFO - root - 2017-12-16 20:40:01.531188: step 96040, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 14h:37m:16s remains)
INFO - root - 2017-12-16 20:40:03.744640: step 96050, loss = 0.53, batch loss = 0.35 (35.3 examples/sec; 0.227 sec/batch; 14h:53m:26s remains)
INFO - root - 2017-12-16 20:40:05.965683: step 96060, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 14h:14m:05s remains)
INFO - root - 2017-12-16 20:40:08.156836: step 96070, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 14h:25m:07s remains)
INFO - root - 2017-12-16 20:40:10.369773: step 96080, loss = 0.55, batch loss = 0.37 (37.4 examples/sec; 0.214 sec/batch; 14h:02m:14s remains)
INFO - root - 2017-12-16 20:40:12.560749: step 96090, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 14h:26m:47s remains)
INFO - root - 2017-12-16 20:40:14.788612: step 96100, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 14h:41m:53s remains)
INFO - root - 2017-12-16 20:40:17.126877: step 96110, loss = 0.48, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 14h:18m:26s remains)
INFO - root - 2017-12-16 20:40:19.333704: step 96120, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 14h:32m:00s remains)
INFO - root - 2017-12-16 20:40:21.578999: step 96130, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 15h:03m:29s remains)
INFO - root - 2017-12-16 20:40:23.774096: step 96140, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 13h:58m:47s remains)
INFO - root - 2017-12-16 20:40:25.986584: step 96150, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 14h:28m:03s remains)
INFO - root - 2017-12-16 20:40:28.183578: step 96160, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 14h:17m:16s remains)
INFO - root - 2017-12-16 20:40:30.402518: step 96170, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 14h:33m:01s remains)
INFO - root - 2017-12-16 20:40:32.641042: step 96180, loss = 0.53, batch loss = 0.36 (36.2 examples/sec; 0.221 sec/batch; 14h:30m:25s remains)
INFO - root - 2017-12-16 20:40:34.862233: step 96190, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.228 sec/batch; 14h:56m:21s remains)
INFO - root - 2017-12-16 20:40:37.085961: step 96200, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 14h:42m:13s remains)
INFO - root - 2017-12-16 20:40:39.460853: step 96210, loss = 0.47, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 14h:18m:16s remains)
INFO - root - 2017-12-16 20:40:41.688238: step 96220, loss = 0.51, batch loss = 0.33 (35.2 examples/sec; 0.227 sec/batch; 14h:55m:49s remains)
INFO - root - 2017-12-16 20:40:43.885754: step 96230, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 14h:27m:59s remains)
INFO - root - 2017-12-16 20:40:46.113791: step 96240, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 14h:42m:55s remains)
INFO - root - 2017-12-16 20:40:48.321817: step 96250, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 14h:10m:35s remains)
INFO - root - 2017-12-16 20:40:50.539919: step 96260, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 14h:45m:40s remains)
INFO - root - 2017-12-16 20:40:52.758429: step 96270, loss = 0.42, batch loss = 0.24 (34.2 examples/sec; 0.234 sec/batch; 15h:20m:55s remains)
INFO - root - 2017-12-16 20:40:55.027108: step 96280, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 14h:30m:37s remains)
INFO - root - 2017-12-16 20:40:57.229019: step 96290, loss = 0.46, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 14h:17m:44s remains)
INFO - root - 2017-12-16 20:40:59.444390: step 96300, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 14h:34m:11s remains)
INFO - root - 2017-12-16 20:41:01.814967: step 96310, loss = 0.51, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 14h:38m:13s remains)
INFO - root - 2017-12-16 20:41:04.021648: step 96320, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.214 sec/batch; 14h:00m:33s remains)
INFO - root - 2017-12-16 20:41:06.312936: step 96330, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 14h:39m:14s remains)
INFO - root - 2017-12-16 20:41:08.479094: step 96340, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 14h:49m:56s remains)
INFO - root - 2017-12-16 20:41:10.716815: step 96350, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 14h:32m:26s remains)
INFO - root - 2017-12-16 20:41:12.965799: step 96360, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:36m:30s remains)
INFO - root - 2017-12-16 20:41:15.167132: step 96370, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 14h:24m:46s remains)
INFO - root - 2017-12-16 20:41:17.362850: step 96380, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 14h:27m:02s remains)
INFO - root - 2017-12-16 20:41:19.606473: step 96390, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 14h:24m:30s remains)
INFO - root - 2017-12-16 20:41:21.838942: step 96400, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 14h:07m:01s remains)
INFO - root - 2017-12-16 20:41:24.194398: step 96410, loss = 0.52, batch loss = 0.34 (34.5 examples/sec; 0.232 sec/batch; 15h:11m:56s remains)
INFO - root - 2017-12-16 20:41:26.410705: step 96420, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 14h:30m:16s remains)
INFO - root - 2017-12-16 20:41:28.666053: step 96430, loss = 0.53, batch loss = 0.35 (34.6 examples/sec; 0.231 sec/batch; 15h:09m:44s remains)
INFO - root - 2017-12-16 20:41:30.878510: step 96440, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 14h:31m:43s remains)
INFO - root - 2017-12-16 20:41:33.091179: step 96450, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 14h:37m:00s remains)
INFO - root - 2017-12-16 20:41:35.295498: step 96460, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 14h:23m:10s remains)
INFO - root - 2017-12-16 20:41:37.535265: step 96470, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 14h:22m:06s remains)
INFO - root - 2017-12-16 20:41:39.734198: step 96480, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.218 sec/batch; 14h:15m:53s remains)
INFO - root - 2017-12-16 20:41:41.946464: step 96490, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 14h:13m:32s remains)
INFO - root - 2017-12-16 20:41:44.154389: step 96500, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 14h:30m:55s remains)
INFO - root - 2017-12-16 20:41:46.514505: step 96510, loss = 0.49, batch loss = 0.32 (34.1 examples/sec; 0.235 sec/batch; 15h:23m:38s remains)
INFO - root - 2017-12-16 20:41:48.763046: step 96520, loss = 0.57, batch loss = 0.39 (36.0 examples/sec; 0.222 sec/batch; 14h:33m:40s remains)
INFO - root - 2017-12-16 20:41:50.990395: step 96530, loss = 0.51, batch loss = 0.33 (34.5 examples/sec; 0.232 sec/batch; 15h:11m:07s remains)
INFO - root - 2017-12-16 20:41:53.238965: step 96540, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 15h:00m:30s remains)
INFO - root - 2017-12-16 20:41:55.461860: step 96550, loss = 0.50, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 14h:10m:11s remains)
INFO - root - 2017-12-16 20:41:57.686382: step 96560, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 14h:47m:19s remains)
INFO - root - 2017-12-16 20:41:59.881759: step 96570, loss = 0.49, batch loss = 0.31 (33.9 examples/sec; 0.236 sec/batch; 15h:28m:19s remains)
INFO - root - 2017-12-16 20:42:02.116050: step 96580, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 14h:41m:39s remains)
INFO - root - 2017-12-16 20:42:04.349977: step 96590, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 14h:47m:50s remains)
INFO - root - 2017-12-16 20:42:06.577199: step 96600, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 14h:04m:23s remains)
INFO - root - 2017-12-16 20:42:08.929401: step 96610, loss = 0.45, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 14h:38m:56s remains)
INFO - root - 2017-12-16 20:42:11.186389: step 96620, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 14h:46m:14s remains)
INFO - root - 2017-12-16 20:42:13.383367: step 96630, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.232 sec/batch; 15h:13m:06s remains)
INFO - root - 2017-12-16 20:42:15.606080: step 96640, loss = 0.42, batch loss = 0.24 (34.8 examples/sec; 0.230 sec/batch; 15h:03m:52s remains)
INFO - root - 2017-12-16 20:42:17.857702: step 96650, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.228 sec/batch; 14h:58m:09s remains)
INFO - root - 2017-12-16 20:42:20.092827: step 96660, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 14h:54m:53s remains)
INFO - root - 2017-12-16 20:42:22.303342: step 96670, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 13h:58m:42s remains)
INFO - root - 2017-12-16 20:42:24.514782: step 96680, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 14h:25m:36s remains)
INFO - root - 2017-12-16 20:42:26.748478: step 96690, loss = 0.54, batch loss = 0.36 (36.2 examples/sec; 0.221 sec/batch; 14h:27m:40s remains)
INFO - root - 2017-12-16 20:42:28.991137: step 96700, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 14h:10m:20s remains)
INFO - root - 2017-12-16 20:42:31.377763: step 96710, loss = 0.51, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 14h:39m:51s remains)
INFO - root - 2017-12-16 20:42:33.585339: step 96720, loss = 0.43, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 14h:17m:53s remains)
INFO - root - 2017-12-16 20:42:35.834479: step 96730, loss = 0.46, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 14h:25m:11s remains)
INFO - root - 2017-12-16 20:42:38.103992: step 96740, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 14h:37m:53s remains)
INFO - root - 2017-12-16 20:42:40.365140: step 96750, loss = 0.44, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 14h:17m:55s remains)
INFO - root - 2017-12-16 20:42:42.598689: step 96760, loss = 0.59, batch loss = 0.42 (36.4 examples/sec; 0.220 sec/batch; 14h:23m:21s remains)
INFO - root - 2017-12-16 20:42:44.826470: step 96770, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 14h:37m:09s remains)
INFO - root - 2017-12-16 20:42:47.040230: step 96780, loss = 0.42, batch loss = 0.24 (34.9 examples/sec; 0.229 sec/batch; 15h:01m:33s remains)
INFO - root - 2017-12-16 20:42:49.270462: step 96790, loss = 0.52, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 14h:20m:01s remains)
INFO - root - 2017-12-16 20:42:51.512326: step 96800, loss = 0.45, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 14h:39m:35s remains)
INFO - root - 2017-12-16 20:42:53.872675: step 96810, loss = 0.46, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 14h:30m:18s remains)
INFO - root - 2017-12-16 20:42:56.083164: step 96820, loss = 0.51, batch loss = 0.33 (34.6 examples/sec; 0.231 sec/batch; 15h:07m:23s remains)
INFO - root - 2017-12-16 20:42:58.303297: step 96830, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 14h:42m:48s remains)
INFO - root - 2017-12-16 20:43:00.542166: step 96840, loss = 0.53, batch loss = 0.35 (34.8 examples/sec; 0.230 sec/batch; 15h:02m:33s remains)
INFO - root - 2017-12-16 20:43:02.759793: step 96850, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 15h:01m:20s remains)
INFO - root - 2017-12-16 20:43:05.035517: step 96860, loss = 0.43, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 14h:15m:23s remains)
INFO - root - 2017-12-16 20:43:07.277244: step 96870, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 14h:34m:50s remains)
INFO - root - 2017-12-16 20:43:09.584602: step 96880, loss = 0.49, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 14h:17m:23s remains)
INFO - root - 2017-12-16 20:43:11.813934: step 96890, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.223 sec/batch; 14h:37m:27s remains)
INFO - root - 2017-12-16 20:43:14.031377: step 96900, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 14h:23m:15s remains)
INFO - root - 2017-12-16 20:43:16.343506: step 96910, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 14h:18m:54s remains)
INFO - root - 2017-12-16 20:43:18.611079: step 96920, loss = 0.52, batch loss = 0.34 (34.4 examples/sec; 0.232 sec/batch; 15h:12m:30s remains)
INFO - root - 2017-12-16 20:43:20.846062: step 96930, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 14h:42m:57s remains)
INFO - root - 2017-12-16 20:43:23.078078: step 96940, loss = 0.57, batch loss = 0.39 (36.8 examples/sec; 0.217 sec/batch; 14h:12m:25s remains)
INFO - root - 2017-12-16 20:43:25.310298: step 96950, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 14h:01m:33s remains)
INFO - root - 2017-12-16 20:43:27.528156: step 96960, loss = 0.54, batch loss = 0.36 (36.8 examples/sec; 0.217 sec/batch; 14h:13m:32s remains)
INFO - root - 2017-12-16 20:43:29.743693: step 96970, loss = 0.54, batch loss = 0.36 (34.4 examples/sec; 0.232 sec/batch; 15h:12m:06s remains)
INFO - root - 2017-12-16 20:43:31.986545: step 96980, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 14h:30m:45s remains)
INFO - root - 2017-12-16 20:43:34.229400: step 96990, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 14h:17m:52s remains)
INFO - root - 2017-12-16 20:43:36.504699: step 97000, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 14h:25m:51s remains)
INFO - root - 2017-12-16 20:43:38.835505: step 97010, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.228 sec/batch; 14h:53m:10s remains)
INFO - root - 2017-12-16 20:43:41.055848: step 97020, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 14h:23m:58s remains)
INFO - root - 2017-12-16 20:43:43.246833: step 97030, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 14h:13m:55s remains)
INFO - root - 2017-12-16 20:43:45.500444: step 97040, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 14h:49m:14s remains)
INFO - root - 2017-12-16 20:43:47.751746: step 97050, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 15h:00m:54s remains)
INFO - root - 2017-12-16 20:43:49.970803: step 97060, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 14h:33m:45s remains)
INFO - root - 2017-12-16 20:43:52.207194: step 97070, loss = 0.49, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 14h:12m:06s remains)
INFO - root - 2017-12-16 20:43:54.484607: step 97080, loss = 0.53, batch loss = 0.35 (35.3 examples/sec; 0.227 sec/batch; 14h:49m:48s remains)
INFO - root - 2017-12-16 20:43:56.774969: step 97090, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 14h:20m:45s remains)
INFO - root - 2017-12-16 20:43:58.966892: step 97100, loss = 0.47, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 14h:19m:05s remains)
INFO - root - 2017-12-16 20:44:01.308454: step 97110, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 14h:20m:52s remains)
INFO - root - 2017-12-16 20:44:03.559314: step 97120, loss = 0.50, batch loss = 0.32 (35.0 examples/sec; 0.228 sec/batch; 14h:55m:49s remains)
INFO - root - 2017-12-16 20:44:05.809665: step 97130, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 14h:39m:11s remains)
INFO - root - 2017-12-16 20:44:08.040031: step 97140, loss = 0.44, batch loss = 0.26 (37.7 examples/sec; 0.212 sec/batch; 13h:52m:07s remains)
INFO - root - 2017-12-16 20:44:10.233795: step 97150, loss = 0.50, batch loss = 0.33 (36.6 examples/sec; 0.218 sec/batch; 14h:16m:53s remains)
INFO - root - 2017-12-16 20:44:12.460709: step 97160, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 14h:15m:26s remains)
INFO - root - 2017-12-16 20:44:14.678778: step 97170, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 14h:30m:41s remains)
INFO - root - 2017-12-16 20:44:16.926304: step 97180, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 14h:52m:06s remains)
INFO - root - 2017-12-16 20:44:19.182151: step 97190, loss = 0.52, batch loss = 0.34 (34.3 examples/sec; 0.233 sec/batch; 15h:15m:42s remains)
INFO - root - 2017-12-16 20:44:21.432176: step 97200, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 14h:50m:41s remains)
INFO - root - 2017-12-16 20:44:23.783870: step 97210, loss = 0.58, batch loss = 0.40 (36.9 examples/sec; 0.217 sec/batch; 14h:11m:12s remains)
INFO - root - 2017-12-16 20:44:26.009629: step 97220, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 14h:10m:13s remains)
INFO - root - 2017-12-16 20:44:28.178931: step 97230, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 14h:15m:19s remains)
INFO - root - 2017-12-16 20:44:30.432701: step 97240, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 14h:23m:32s remains)
INFO - root - 2017-12-16 20:44:32.611851: step 97250, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 14h:02m:24s remains)
INFO - root - 2017-12-16 20:44:34.834908: step 97260, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 14h:10m:02s remains)
INFO - root - 2017-12-16 20:44:37.081087: step 97270, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 14h:40m:25s remains)
INFO - root - 2017-12-16 20:44:39.322274: step 97280, loss = 0.50, batch loss = 0.32 (34.2 examples/sec; 0.234 sec/batch; 15h:16m:56s remains)
INFO - root - 2017-12-16 20:44:41.552554: step 97290, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 14h:37m:52s remains)
INFO - root - 2017-12-16 20:44:43.766740: step 97300, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 14h:27m:12s remains)
INFO - root - 2017-12-16 20:44:46.123544: step 97310, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 14h:44m:16s remains)
INFO - root - 2017-12-16 20:44:48.360154: step 97320, loss = 0.54, batch loss = 0.36 (34.1 examples/sec; 0.235 sec/batch; 15h:19m:55s remains)
INFO - root - 2017-12-16 20:44:50.577823: step 97330, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 14h:20m:58s remains)
INFO - root - 2017-12-16 20:44:52.802456: step 97340, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 14h:30m:28s remains)
INFO - root - 2017-12-16 20:44:55.042662: step 97350, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 14h:06m:00s remains)
INFO - root - 2017-12-16 20:44:57.293582: step 97360, loss = 0.51, batch loss = 0.33 (34.5 examples/sec; 0.232 sec/batch; 15h:09m:07s remains)
INFO - root - 2017-12-16 20:44:59.527529: step 97370, loss = 0.53, batch loss = 0.35 (35.2 examples/sec; 0.227 sec/batch; 14h:51m:01s remains)
INFO - root - 2017-12-16 20:45:01.726227: step 97380, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 14h:19m:03s remains)
INFO - root - 2017-12-16 20:45:03.944909: step 97390, loss = 0.45, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 14h:15m:55s remains)
INFO - root - 2017-12-16 20:45:06.182159: step 97400, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 15h:01m:48s remains)
INFO - root - 2017-12-16 20:45:08.561280: step 97410, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 14h:50m:30s remains)
INFO - root - 2017-12-16 20:45:10.774451: step 97420, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 13h:54m:13s remains)
INFO - root - 2017-12-16 20:45:12.961836: step 97430, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 14h:08m:28s remains)
INFO - root - 2017-12-16 20:45:15.172430: step 97440, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 14h:48m:00s remains)
INFO - root - 2017-12-16 20:45:17.414029: step 97450, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 14h:17m:04s remains)
INFO - root - 2017-12-16 20:45:19.641085: step 97460, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 14h:44m:51s remains)
INFO - root - 2017-12-16 20:45:21.874112: step 97470, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 14h:01m:23s remains)
INFO - root - 2017-12-16 20:45:24.181734: step 97480, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 14h:28m:30s remains)
INFO - root - 2017-12-16 20:45:26.401814: step 97490, loss = 0.52, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 13h:58m:41s remains)
INFO - root - 2017-12-16 20:45:28.623619: step 97500, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 14h:12m:46s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-97500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-97500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 20:45:31.725149: step 97510, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 14h:15m:19s remains)
INFO - root - 2017-12-16 20:45:33.953505: step 97520, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 14h:30m:49s remains)
INFO - root - 2017-12-16 20:45:36.161415: step 97530, loss = 0.54, batch loss = 0.37 (37.0 examples/sec; 0.216 sec/batch; 14h:06m:50s remains)
INFO - root - 2017-12-16 20:45:38.413616: step 97540, loss = 0.51, batch loss = 0.33 (34.4 examples/sec; 0.232 sec/batch; 15h:09m:51s remains)
INFO - root - 2017-12-16 20:45:40.635003: step 97550, loss = 0.50, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 15h:01m:25s remains)
INFO - root - 2017-12-16 20:45:42.882406: step 97560, loss = 0.47, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 15h:16m:58s remains)
INFO - root - 2017-12-16 20:45:45.110500: step 97570, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 14h:14m:12s remains)
INFO - root - 2017-12-16 20:45:47.369773: step 97580, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 14h:24m:50s remains)
INFO - root - 2017-12-16 20:45:49.634770: step 97590, loss = 0.43, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 14h:24m:17s remains)
INFO - root - 2017-12-16 20:45:51.827333: step 97600, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 14h:01m:05s remains)
INFO - root - 2017-12-16 20:45:54.207643: step 97610, loss = 0.58, batch loss = 0.40 (35.2 examples/sec; 0.227 sec/batch; 14h:48m:59s remains)
INFO - root - 2017-12-16 20:45:56.438826: step 97620, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 14h:21m:28s remains)
INFO - root - 2017-12-16 20:45:58.667316: step 97630, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 14h:26m:44s remains)
INFO - root - 2017-12-16 20:46:00.882617: step 97640, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.215 sec/batch; 14h:03m:17s remains)
INFO - root - 2017-12-16 20:46:03.100621: step 97650, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 14h:06m:48s remains)
INFO - root - 2017-12-16 20:46:05.351629: step 97660, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 14h:27m:54s remains)
INFO - root - 2017-12-16 20:46:07.552502: step 97670, loss = 0.53, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 14h:15m:33s remains)
INFO - root - 2017-12-16 20:46:09.753238: step 97680, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 14h:34m:30s remains)
INFO - root - 2017-12-16 20:46:11.976324: step 97690, loss = 0.47, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 14h:03m:50s remains)
INFO - root - 2017-12-16 20:46:14.161171: step 97700, loss = 0.50, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 14h:04m:49s remains)
INFO - root - 2017-12-16 20:46:16.568092: step 97710, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 14h:28m:05s remains)
INFO - root - 2017-12-16 20:46:18.790082: step 97720, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 14h:18m:57s remains)
INFO - root - 2017-12-16 20:46:20.993142: step 97730, loss = 0.54, batch loss = 0.36 (36.8 examples/sec; 0.218 sec/batch; 14h:11m:14s remains)
INFO - root - 2017-12-16 20:46:23.227107: step 97740, loss = 0.47, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 14h:41m:42s remains)
INFO - root - 2017-12-16 20:46:25.438424: step 97750, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.214 sec/batch; 13h:55m:40s remains)
INFO - root - 2017-12-16 20:46:27.629357: step 97760, loss = 0.52, batch loss = 0.34 (37.7 examples/sec; 0.212 sec/batch; 13h:50m:10s remains)
INFO - root - 2017-12-16 20:46:29.866279: step 97770, loss = 0.46, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 14h:10m:36s remains)
INFO - root - 2017-12-16 20:46:32.074139: step 97780, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 13h:57m:50s remains)
INFO - root - 2017-12-16 20:46:34.249123: step 97790, loss = 0.51, batch loss = 0.33 (37.7 examples/sec; 0.212 sec/batch; 13h:49m:09s remains)
INFO - root - 2017-12-16 20:46:36.484023: step 97800, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.221 sec/batch; 14h:22m:37s remains)
INFO - root - 2017-12-16 20:46:38.820598: step 97810, loss = 0.53, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 14h:37m:11s remains)
INFO - root - 2017-12-16 20:46:41.060970: step 97820, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 14h:24m:53s remains)
INFO - root - 2017-12-16 20:46:43.312326: step 97830, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 14h:39m:35s remains)
INFO - root - 2017-12-16 20:46:45.555228: step 97840, loss = 0.48, batch loss = 0.30 (34.1 examples/sec; 0.234 sec/batch; 15h:16m:42s remains)
INFO - root - 2017-12-16 20:46:47.747082: step 97850, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 14h:26m:27s remains)
INFO - root - 2017-12-16 20:46:50.016542: step 97860, loss = 0.49, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 14h:34m:22s remains)
INFO - root - 2017-12-16 20:46:52.268718: step 97870, loss = 0.50, batch loss = 0.33 (34.7 examples/sec; 0.230 sec/batch; 15h:00m:39s remains)
INFO - root - 2017-12-16 20:46:54.476205: step 97880, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 14h:19m:48s remains)
INFO - root - 2017-12-16 20:46:56.733331: step 97890, loss = 0.52, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 14h:48m:41s remains)
INFO - root - 2017-12-16 20:46:58.932387: step 97900, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 14h:13m:28s remains)
INFO - root - 2017-12-16 20:47:01.333563: step 97910, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 14h:42m:09s remains)
INFO - root - 2017-12-16 20:47:03.557441: step 97920, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 14h:28m:23s remains)
INFO - root - 2017-12-16 20:47:05.819396: step 97930, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 14h:48m:42s remains)
INFO - root - 2017-12-16 20:47:08.052027: step 97940, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 14h:24m:32s remains)
INFO - root - 2017-12-16 20:47:10.275759: step 97950, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 14h:29m:30s remains)
INFO - root - 2017-12-16 20:47:12.481259: step 97960, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 14h:09m:24s remains)
INFO - root - 2017-12-16 20:47:14.705757: step 97970, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 14h:28m:43s remains)
INFO - root - 2017-12-16 20:47:16.938051: step 97980, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 14h:11m:12s remains)
INFO - root - 2017-12-16 20:47:19.159445: step 97990, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.230 sec/batch; 15h:00m:10s remains)
INFO - root - 2017-12-16 20:47:21.384058: step 98000, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 14h:55m:17s remains)
INFO - root - 2017-12-16 20:47:23.766017: step 98010, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 14h:08m:52s remains)
INFO - root - 2017-12-16 20:47:26.021521: step 98020, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 14h:27m:31s remains)
INFO - root - 2017-12-16 20:47:28.217433: step 98030, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 14h:06m:52s remains)
INFO - root - 2017-12-16 20:47:30.420573: step 98040, loss = 0.55, batch loss = 0.37 (35.7 examples/sec; 0.224 sec/batch; 14h:35m:56s remains)
INFO - root - 2017-12-16 20:47:32.608156: step 98050, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 14h:15m:10s remains)
INFO - root - 2017-12-16 20:47:34.829601: step 98060, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 14h:38m:55s remains)
INFO - root - 2017-12-16 20:47:37.080045: step 98070, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 14h:26m:16s remains)
INFO - root - 2017-12-16 20:47:39.290833: step 98080, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 14h:04m:07s remains)
INFO - root - 2017-12-16 20:47:41.523552: step 98090, loss = 0.48, batch loss = 0.30 (34.7 examples/sec; 0.231 sec/batch; 15h:01m:02s remains)
INFO - root - 2017-12-16 20:47:43.740784: step 98100, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 14h:07m:14s remains)
INFO - root - 2017-12-16 20:47:46.041279: step 98110, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 14h:04m:39s remains)
INFO - root - 2017-12-16 20:47:48.249923: step 98120, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 14h:56m:20s remains)
INFO - root - 2017-12-16 20:47:50.450804: step 98130, loss = 0.51, batch loss = 0.34 (37.6 examples/sec; 0.213 sec/batch; 13h:51m:59s remains)
INFO - root - 2017-12-16 20:47:52.678118: step 98140, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 14h:06m:08s remains)
INFO - root - 2017-12-16 20:47:54.914605: step 98150, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 14h:26m:31s remains)
INFO - root - 2017-12-16 20:47:57.168537: step 98160, loss = 0.54, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 14h:20m:28s remains)
INFO - root - 2017-12-16 20:47:59.362528: step 98170, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 14h:33m:57s remains)
INFO - root - 2017-12-16 20:48:01.586054: step 98180, loss = 0.48, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 14h:20m:04s remains)
INFO - root - 2017-12-16 20:48:03.822450: step 98190, loss = 0.41, batch loss = 0.23 (36.3 examples/sec; 0.220 sec/batch; 14h:20m:24s remains)
INFO - root - 2017-12-16 20:48:06.072223: step 98200, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 14h:11m:56s remains)
INFO - root - 2017-12-16 20:48:08.485242: step 98210, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 14h:11m:09s remains)
INFO - root - 2017-12-16 20:48:10.720936: step 98220, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 14h:46m:49s remains)
INFO - root - 2017-12-16 20:48:12.966339: step 98230, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 14h:45m:05s remains)
INFO - root - 2017-12-16 20:48:15.173061: step 98240, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 14h:32m:54s remains)
INFO - root - 2017-12-16 20:48:17.410501: step 98250, loss = 0.53, batch loss = 0.36 (35.5 examples/sec; 0.225 sec/batch; 14h:39m:11s remains)
INFO - root - 2017-12-16 20:48:19.611779: step 98260, loss = 0.44, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 14h:05m:30s remains)
INFO - root - 2017-12-16 20:48:21.797495: step 98270, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 14h:12m:12s remains)
INFO - root - 2017-12-16 20:48:24.007654: step 98280, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.224 sec/batch; 14h:33m:18s remains)
INFO - root - 2017-12-16 20:48:26.228317: step 98290, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 14h:49m:39s remains)
INFO - root - 2017-12-16 20:48:28.474610: step 98300, loss = 0.58, batch loss = 0.40 (35.7 examples/sec; 0.224 sec/batch; 14h:34m:18s remains)
INFO - root - 2017-12-16 20:48:30.816072: step 98310, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 14h:01m:40s remains)
INFO - root - 2017-12-16 20:48:33.014232: step 98320, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 13h:55m:03s remains)
INFO - root - 2017-12-16 20:48:35.248586: step 98330, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 14h:08m:29s remains)
INFO - root - 2017-12-16 20:48:37.492292: step 98340, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 14h:50m:21s remains)
INFO - root - 2017-12-16 20:48:39.755473: step 98350, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 14h:47m:16s remains)
INFO - root - 2017-12-16 20:48:41.989677: step 98360, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 14h:21m:49s remains)
INFO - root - 2017-12-16 20:48:44.188274: step 98370, loss = 0.61, batch loss = 0.43 (36.2 examples/sec; 0.221 sec/batch; 14h:22m:09s remains)
INFO - root - 2017-12-16 20:48:46.413300: step 98380, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 14h:13m:11s remains)
INFO - root - 2017-12-16 20:48:48.617026: step 98390, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 14h:13m:23s remains)
INFO - root - 2017-12-16 20:48:50.832564: step 98400, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 14h:45m:54s remains)
INFO - root - 2017-12-16 20:48:53.181103: step 98410, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 14h:17m:54s remains)
INFO - root - 2017-12-16 20:48:55.358921: step 98420, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 14h:05m:36s remains)
INFO - root - 2017-12-16 20:48:57.567262: step 98430, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 14h:19m:35s remains)
INFO - root - 2017-12-16 20:48:59.753653: step 98440, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 13h:46m:14s remains)
INFO - root - 2017-12-16 20:49:01.943798: step 98450, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 14h:26m:25s remains)
INFO - root - 2017-12-16 20:49:04.143042: step 98460, loss = 0.58, batch loss = 0.40 (34.2 examples/sec; 0.234 sec/batch; 15h:11m:06s remains)
INFO - root - 2017-12-16 20:49:06.338565: step 98470, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 14h:08m:11s remains)
INFO - root - 2017-12-16 20:49:08.594976: step 98480, loss = 0.58, batch loss = 0.40 (36.0 examples/sec; 0.222 sec/batch; 14h:25m:51s remains)
INFO - root - 2017-12-16 20:49:10.800617: step 98490, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 13h:51m:14s remains)
INFO - root - 2017-12-16 20:49:13.063833: step 98500, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 14h:27m:36s remains)
INFO - root - 2017-12-16 20:49:15.373649: step 98510, loss = 0.49, batch loss = 0.31 (37.8 examples/sec; 0.212 sec/batch; 13h:45m:48s remains)
INFO - root - 2017-12-16 20:49:17.593606: step 98520, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 14h:11m:48s remains)
INFO - root - 2017-12-16 20:49:19.778932: step 98530, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 14h:34m:03s remains)
INFO - root - 2017-12-16 20:49:22.007637: step 98540, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 13h:56m:33s remains)
INFO - root - 2017-12-16 20:49:24.215637: step 98550, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 14h:35m:45s remains)
INFO - root - 2017-12-16 20:49:26.426653: step 98560, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 14h:39m:20s remains)
INFO - root - 2017-12-16 20:49:28.675502: step 98570, loss = 0.56, batch loss = 0.38 (34.2 examples/sec; 0.234 sec/batch; 15h:11m:56s remains)
INFO - root - 2017-12-16 20:49:30.905903: step 98580, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 14h:01m:36s remains)
INFO - root - 2017-12-16 20:49:33.142868: step 98590, loss = 0.44, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 14h:38m:10s remains)
INFO - root - 2017-12-16 20:49:35.384012: step 98600, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.224 sec/batch; 14h:35m:03s remains)
INFO - root - 2017-12-16 20:49:37.704477: step 98610, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 14h:37m:49s remains)
INFO - root - 2017-12-16 20:49:39.858807: step 98620, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 13h:57m:21s remains)
INFO - root - 2017-12-16 20:49:42.039473: step 98630, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 14h:02m:03s remains)
INFO - root - 2017-12-16 20:49:44.249120: step 98640, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.233 sec/batch; 15h:07m:11s remains)
INFO - root - 2017-12-16 20:49:46.433576: step 98650, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 14h:13m:46s remains)
INFO - root - 2017-12-16 20:49:48.640554: step 98660, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 14h:05m:50s remains)
INFO - root - 2017-12-16 20:49:50.856718: step 98670, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 14h:48m:05s remains)
INFO - root - 2017-12-16 20:49:53.084618: step 98680, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 14h:36m:15s remains)
INFO - root - 2017-12-16 20:49:55.303134: step 98690, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 14h:38m:53s remains)
INFO - root - 2017-12-16 20:49:57.542178: step 98700, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 14h:38m:29s remains)
INFO - root - 2017-12-16 20:49:59.872331: step 98710, loss = 0.44, batch loss = 0.26 (37.7 examples/sec; 0.212 sec/batch; 13h:47m:53s remains)
INFO - root - 2017-12-16 20:50:02.092245: step 98720, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 14h:47m:06s remains)
INFO - root - 2017-12-16 20:50:04.282139: step 98730, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 14h:34m:06s remains)
INFO - root - 2017-12-16 20:50:06.487374: step 98740, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 14h:22m:15s remains)
INFO - root - 2017-12-16 20:50:08.733018: step 98750, loss = 0.55, batch loss = 0.37 (35.3 examples/sec; 0.226 sec/batch; 14h:42m:12s remains)
INFO - root - 2017-12-16 20:50:10.947812: step 98760, loss = 0.46, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 13h:50m:54s remains)
INFO - root - 2017-12-16 20:50:13.147016: step 98770, loss = 0.55, batch loss = 0.37 (35.0 examples/sec; 0.229 sec/batch; 14h:51m:00s remains)
INFO - root - 2017-12-16 20:50:15.319825: step 98780, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 14h:13m:32s remains)
INFO - root - 2017-12-16 20:50:17.523956: step 98790, loss = 0.43, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 13h:48m:24s remains)
INFO - root - 2017-12-16 20:50:19.735912: step 98800, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 14h:40m:46s remains)
INFO - root - 2017-12-16 20:50:22.087179: step 98810, loss = 0.42, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 14h:09m:18s remains)
INFO - root - 2017-12-16 20:50:24.317900: step 98820, loss = 0.49, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 14h:17m:24s remains)
INFO - root - 2017-12-16 20:50:26.533605: step 98830, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 14h:26m:43s remains)
INFO - root - 2017-12-16 20:50:28.760869: step 98840, loss = 0.52, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 13h:53m:53s remains)
INFO - root - 2017-12-16 20:50:30.946367: step 98850, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 14h:23m:27s remains)
INFO - root - 2017-12-16 20:50:33.130943: step 98860, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 14h:09m:01s remains)
INFO - root - 2017-12-16 20:50:35.311453: step 98870, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.215 sec/batch; 13h:58m:50s remains)
INFO - root - 2017-12-16 20:50:37.514925: step 98880, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 14h:37m:27s remains)
INFO - root - 2017-12-16 20:50:39.719485: step 98890, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 13h:57m:09s remains)
INFO - root - 2017-12-16 20:50:41.893975: step 98900, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 13h:56m:35s remains)
INFO - root - 2017-12-16 20:50:44.268131: step 98910, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 14h:27m:32s remains)
INFO - root - 2017-12-16 20:50:46.504623: step 98920, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 13h:55m:43s remains)
INFO - root - 2017-12-16 20:50:48.719059: step 98930, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 14h:46m:10s remains)
INFO - root - 2017-12-16 20:50:50.945613: step 98940, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 14h:25m:13s remains)
INFO - root - 2017-12-16 20:50:53.178444: step 98950, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 14h:10m:19s remains)
INFO - root - 2017-12-16 20:50:55.397206: step 98960, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 14h:02m:28s remains)
INFO - root - 2017-12-16 20:50:57.619361: step 98970, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 14h:02m:53s remains)
INFO - root - 2017-12-16 20:50:59.809052: step 98980, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 14h:30m:40s remains)
INFO - root - 2017-12-16 20:51:02.021300: step 98990, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 14h:03m:51s remains)
INFO - root - 2017-12-16 20:51:04.232095: step 99000, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 14h:05m:23s remains)
INFO - root - 2017-12-16 20:51:06.592201: step 99010, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 14h:45m:06s remains)
INFO - root - 2017-12-16 20:51:08.823032: step 99020, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 14h:11m:53s remains)
INFO - root - 2017-12-16 20:51:11.027788: step 99030, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 14h:29m:02s remains)
INFO - root - 2017-12-16 20:51:13.252135: step 99040, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 14h:46m:35s remains)
INFO - root - 2017-12-16 20:51:15.456999: step 99050, loss = 0.47, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 13h:57m:00s remains)
INFO - root - 2017-12-16 20:51:17.659295: step 99060, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 14h:31m:14s remains)
INFO - root - 2017-12-16 20:51:19.865274: step 99070, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 14h:51m:04s remains)
INFO - root - 2017-12-16 20:51:22.102154: step 99080, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 14h:15m:38s remains)
INFO - root - 2017-12-16 20:51:24.338838: step 99090, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 14h:08m:22s remains)
INFO - root - 2017-12-16 20:51:26.534468: step 99100, loss = 0.42, batch loss = 0.24 (34.2 examples/sec; 0.234 sec/batch; 15h:08m:38s remains)
INFO - root - 2017-12-16 20:51:28.847167: step 99110, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 14h:11m:44s remains)
INFO - root - 2017-12-16 20:51:31.091236: step 99120, loss = 0.54, batch loss = 0.37 (37.5 examples/sec; 0.213 sec/batch; 13h:49m:48s remains)
INFO - root - 2017-12-16 20:51:33.285358: step 99130, loss = 0.43, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 13h:52m:48s remains)
INFO - root - 2017-12-16 20:51:35.482658: step 99140, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 14h:18m:14s remains)
INFO - root - 2017-12-16 20:51:37.708362: step 99150, loss = 0.41, batch loss = 0.23 (35.8 examples/sec; 0.224 sec/batch; 14h:29m:55s remains)
INFO - root - 2017-12-16 20:51:39.932482: step 99160, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 14h:00m:32s remains)
INFO - root - 2017-12-16 20:51:42.128034: step 99170, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 14h:14m:21s remains)
INFO - root - 2017-12-16 20:51:44.342442: step 99180, loss = 0.44, batch loss = 0.26 (32.5 examples/sec; 0.246 sec/batch; 15h:55m:46s remains)
INFO - root - 2017-12-16 20:51:46.560992: step 99190, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 14h:18m:36s remains)
INFO - root - 2017-12-16 20:51:48.754900: step 99200, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 14h:16m:09s remains)
INFO - root - 2017-12-16 20:51:51.110025: step 99210, loss = 0.49, batch loss = 0.31 (33.8 examples/sec; 0.237 sec/batch; 15h:20m:59s remains)
INFO - root - 2017-12-16 20:51:53.291866: step 99220, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 13h:59m:51s remains)
INFO - root - 2017-12-16 20:51:55.489585: step 99230, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 14h:13m:53s remains)
INFO - root - 2017-12-16 20:51:57.684777: step 99240, loss = 0.43, batch loss = 0.25 (37.0 examples/sec; 0.216 sec/batch; 14h:01m:02s remains)
INFO - root - 2017-12-16 20:51:59.878197: step 99250, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 13h:58m:55s remains)
INFO - root - 2017-12-16 20:52:02.138607: step 99260, loss = 0.56, batch loss = 0.38 (35.5 examples/sec; 0.226 sec/batch; 14h:36m:52s remains)
INFO - root - 2017-12-16 20:52:04.388464: step 99270, loss = 0.45, batch loss = 0.27 (33.7 examples/sec; 0.237 sec/batch; 15h:23m:10s remains)
INFO - root - 2017-12-16 20:52:06.572766: step 99280, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 13h:57m:40s remains)
INFO - root - 2017-12-16 20:52:08.818592: step 99290, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 14h:36m:26s remains)
INFO - root - 2017-12-16 20:52:11.018716: step 99300, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 13h:53m:49s remains)
INFO - root - 2017-12-16 20:52:13.385658: step 99310, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 14h:06m:23s remains)
INFO - root - 2017-12-16 20:52:15.595189: step 99320, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 14h:07m:34s remains)
INFO - root - 2017-12-16 20:52:17.815608: step 99330, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 14h:14m:50s remains)
INFO - root - 2017-12-16 20:52:20.015284: step 99340, loss = 0.42, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 14h:34m:01s remains)
INFO - root - 2017-12-16 20:52:22.222900: step 99350, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:25m:46s remains)
INFO - root - 2017-12-16 20:52:24.456923: step 99360, loss = 0.45, batch loss = 0.27 (34.7 examples/sec; 0.231 sec/batch; 14h:56m:52s remains)
INFO - root - 2017-12-16 20:52:26.649668: step 99370, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 14h:06m:06s remains)
INFO - root - 2017-12-16 20:52:28.860952: step 99380, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.223 sec/batch; 14h:24m:36s remains)
INFO - root - 2017-12-16 20:52:31.079094: step 99390, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 14h:33m:23s remains)
INFO - root - 2017-12-16 20:52:33.250180: step 99400, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 14h:17m:01s remains)
INFO - root - 2017-12-16 20:52:35.577147: step 99410, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 14h:11m:06s remains)
INFO - root - 2017-12-16 20:52:37.818516: step 99420, loss = 0.51, batch loss = 0.33 (35.0 examples/sec; 0.228 sec/batch; 14h:47m:14s remains)
INFO - root - 2017-12-16 20:52:40.058626: step 99430, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 14h:18m:24s remains)
INFO - root - 2017-12-16 20:52:42.282678: step 99440, loss = 0.47, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 14h:09m:05s remains)
INFO - root - 2017-12-16 20:52:44.474922: step 99450, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 13h:55m:50s remains)
INFO - root - 2017-12-16 20:52:46.700100: step 99460, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 14h:22m:37s remains)
INFO - root - 2017-12-16 20:52:48.925976: step 99470, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 13h:51m:32s remains)
INFO - root - 2017-12-16 20:52:51.119224: step 99480, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 14h:04m:22s remains)
INFO - root - 2017-12-16 20:52:53.343983: step 99490, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 14h:09m:50s remains)
INFO - root - 2017-12-16 20:52:55.539552: step 99500, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 13h:52m:12s remains)
INFO - root - 2017-12-16 20:52:57.908042: step 99510, loss = 0.50, batch loss = 0.32 (33.7 examples/sec; 0.237 sec/batch; 15h:21m:08s remains)
INFO - root - 2017-12-16 20:53:00.106024: step 99520, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 14h:11m:47s remains)
INFO - root - 2017-12-16 20:53:02.308032: step 99530, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 14h:49m:24s remains)
INFO - root - 2017-12-16 20:53:04.520541: step 99540, loss = 0.59, batch loss = 0.41 (35.4 examples/sec; 0.226 sec/batch; 14h:37m:04s remains)
INFO - root - 2017-12-16 20:53:06.742484: step 99550, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 14h:00m:10s remains)
INFO - root - 2017-12-16 20:53:08.967306: step 99560, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 13h:44m:51s remains)
INFO - root - 2017-12-16 20:53:11.206266: step 99570, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 13h:57m:45s remains)
INFO - root - 2017-12-16 20:53:13.428557: step 99580, loss = 0.49, batch loss = 0.31 (34.5 examples/sec; 0.232 sec/batch; 14h:59m:38s remains)
INFO - root - 2017-12-16 20:53:15.650555: step 99590, loss = 0.47, batch loss = 0.29 (33.8 examples/sec; 0.237 sec/batch; 15h:19m:32s remains)
INFO - root - 2017-12-16 20:53:17.864675: step 99600, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 14h:48m:40s remains)
INFO - root - 2017-12-16 20:53:20.157762: step 99610, loss = 0.44, batch loss = 0.26 (37.8 examples/sec; 0.211 sec/batch; 13h:40m:47s remains)
INFO - root - 2017-12-16 20:53:22.349339: step 99620, loss = 0.43, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 14h:22m:57s remains)
INFO - root - 2017-12-16 20:53:24.566402: step 99630, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 14h:04m:56s remains)
INFO - root - 2017-12-16 20:53:26.755797: step 99640, loss = 0.47, batch loss = 0.30 (37.5 examples/sec; 0.214 sec/batch; 13h:48m:53s remains)
INFO - root - 2017-12-16 20:53:28.947051: step 99650, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 14h:03m:01s remains)
INFO - root - 2017-12-16 20:53:31.181405: step 99660, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 14h:52m:30s remains)
INFO - root - 2017-12-16 20:53:33.374962: step 99670, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 13h:50m:46s remains)
INFO - root - 2017-12-16 20:53:35.612245: step 99680, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 14h:08m:10s remains)
INFO - root - 2017-12-16 20:53:37.861489: step 99690, loss = 0.51, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 14h:52m:21s remains)
INFO - root - 2017-12-16 20:53:40.064518: step 99700, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 14h:14m:34s remains)
INFO - root - 2017-12-16 20:53:42.366188: step 99710, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 14h:01m:10s remains)
INFO - root - 2017-12-16 20:53:44.566390: step 99720, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 13h:49m:36s remains)
INFO - root - 2017-12-16 20:53:46.783961: step 99730, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 14h:15m:09s remains)
INFO - root - 2017-12-16 20:53:48.980867: step 99740, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 14h:27m:21s remains)
INFO - root - 2017-12-16 20:53:51.178693: step 99750, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 14h:18m:23s remains)
INFO - root - 2017-12-16 20:53:53.429573: step 99760, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 14h:47m:58s remains)
INFO - root - 2017-12-16 20:53:55.640463: step 99770, loss = 0.55, batch loss = 0.37 (35.6 examples/sec; 0.225 sec/batch; 14h:31m:44s remains)
INFO - root - 2017-12-16 20:53:57.821903: step 99780, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 13h:58m:56s remains)
INFO - root - 2017-12-16 20:53:59.992923: step 99790, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 13h:46m:33s remains)
INFO - root - 2017-12-16 20:54:02.169261: step 99800, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 13h:54m:36s remains)
INFO - root - 2017-12-16 20:54:04.499843: step 99810, loss = 0.46, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 14h:05m:57s remains)
INFO - root - 2017-12-16 20:54:06.704235: step 99820, loss = 0.43, batch loss = 0.25 (37.5 examples/sec; 0.213 sec/batch; 13h:47m:30s remains)
INFO - root - 2017-12-16 20:54:08.911164: step 99830, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 14h:05m:59s remains)
INFO - root - 2017-12-16 20:54:11.112994: step 99840, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 14h:16m:05s remains)
INFO - root - 2017-12-16 20:54:13.331511: step 99850, loss = 0.49, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 14h:11m:19s remains)
INFO - root - 2017-12-16 20:54:15.500521: step 99860, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.223 sec/batch; 14h:22m:43s remains)
INFO - root - 2017-12-16 20:54:17.688670: step 99870, loss = 0.48, batch loss = 0.30 (37.9 examples/sec; 0.211 sec/batch; 13h:39m:15s remains)
INFO - root - 2017-12-16 20:54:19.890050: step 99880, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 14h:13m:14s remains)
INFO - root - 2017-12-16 20:54:22.103865: step 99890, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 14h:19m:53s remains)
INFO - root - 2017-12-16 20:54:24.305504: step 99900, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 14h:50m:48s remains)
INFO - root - 2017-12-16 20:54:26.648250: step 99910, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 13h:57m:10s remains)
INFO - root - 2017-12-16 20:54:28.858537: step 99920, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 14h:14m:36s remains)
INFO - root - 2017-12-16 20:54:31.074985: step 99930, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 14h:38m:44s remains)
INFO - root - 2017-12-16 20:54:33.312934: step 99940, loss = 0.45, batch loss = 0.27 (34.1 examples/sec; 0.235 sec/batch; 15h:10m:14s remains)
INFO - root - 2017-12-16 20:54:35.524823: step 99950, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 14h:00m:40s remains)
INFO - root - 2017-12-16 20:54:37.730673: step 99960, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.218 sec/batch; 14h:06m:30s remains)
INFO - root - 2017-12-16 20:54:39.998734: step 99970, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 14h:00m:09s remains)
INFO - root - 2017-12-16 20:54:42.234905: step 99980, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 14h:47m:53s remains)
INFO - root - 2017-12-16 20:54:44.462575: step 99990, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 14h:32m:59s remains)
INFO - root - 2017-12-16 20:54:46.647474: step 100000, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 14h:09m:50s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-100000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-100000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 20:54:49.406763: step 100010, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 14h:21m:10s remains)
INFO - root - 2017-12-16 20:54:51.619952: step 100020, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 14h:59m:12s remains)
INFO - root - 2017-12-16 20:54:53.802318: step 100030, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 14h:05m:23s remains)
INFO - root - 2017-12-16 20:54:56.025380: step 100040, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 13h:58m:20s remains)
INFO - root - 2017-12-16 20:54:58.195541: step 100050, loss = 0.45, batch loss = 0.28 (37.8 examples/sec; 0.211 sec/batch; 13h:39m:02s remains)
INFO - root - 2017-12-16 20:55:00.399489: step 100060, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 14h:15m:12s remains)
INFO - root - 2017-12-16 20:55:02.586313: step 100070, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 14h:26m:12s remains)
INFO - root - 2017-12-16 20:55:04.801423: step 100080, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 14h:07m:54s remains)
INFO - root - 2017-12-16 20:55:07.031996: step 100090, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 14h:02m:18s remains)
INFO - root - 2017-12-16 20:55:09.253877: step 100100, loss = 0.55, batch loss = 0.38 (36.5 examples/sec; 0.219 sec/batch; 14h:08m:19s remains)
INFO - root - 2017-12-16 20:55:11.573814: step 100110, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 14h:36m:18s remains)
INFO - root - 2017-12-16 20:55:13.784113: step 100120, loss = 0.45, batch loss = 0.27 (37.8 examples/sec; 0.212 sec/batch; 13h:40m:23s remains)
INFO - root - 2017-12-16 20:55:15.986868: step 100130, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 13h:49m:19s remains)
INFO - root - 2017-12-16 20:55:18.186136: step 100140, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 14h:11m:49s remains)
INFO - root - 2017-12-16 20:55:20.391753: step 100150, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 14h:04m:40s remains)
INFO - root - 2017-12-16 20:55:22.655741: step 100160, loss = 0.45, batch loss = 0.27 (30.3 examples/sec; 0.264 sec/batch; 17h:01m:05s remains)
INFO - root - 2017-12-16 20:55:24.950559: step 100170, loss = 0.42, batch loss = 0.24 (35.2 examples/sec; 0.227 sec/batch; 14h:40m:18s remains)
INFO - root - 2017-12-16 20:55:27.169751: step 100180, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 14h:50m:05s remains)
INFO - root - 2017-12-16 20:55:29.380149: step 100190, loss = 0.46, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 14h:06m:06s remains)
INFO - root - 2017-12-16 20:55:31.568120: step 100200, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 14h:04m:15s remains)
INFO - root - 2017-12-16 20:55:33.943301: step 100210, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 14h:07m:38s remains)
INFO - root - 2017-12-16 20:55:36.120630: step 100220, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 14h:13m:53s remains)
INFO - root - 2017-12-16 20:55:38.351310: step 100230, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 14h:00m:49s remains)
INFO - root - 2017-12-16 20:55:40.540633: step 100240, loss = 0.45, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 14h:27m:16s remains)
INFO - root - 2017-12-16 20:55:42.737789: step 100250, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.215 sec/batch; 13h:54m:00s remains)
INFO - root - 2017-12-16 20:55:44.938139: step 100260, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 13h:51m:53s remains)
INFO - root - 2017-12-16 20:55:47.117465: step 100270, loss = 0.55, batch loss = 0.38 (37.6 examples/sec; 0.213 sec/batch; 13h:43m:36s remains)
INFO - root - 2017-12-16 20:55:49.330213: step 100280, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 14h:32m:22s remains)
INFO - root - 2017-12-16 20:55:51.544446: step 100290, loss = 0.52, batch loss = 0.34 (37.5 examples/sec; 0.214 sec/batch; 13h:46m:34s remains)
INFO - root - 2017-12-16 20:55:53.825036: step 100300, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 14h:22m:01s remains)
INFO - root - 2017-12-16 20:55:56.130683: step 100310, loss = 0.50, batch loss = 0.32 (37.8 examples/sec; 0.212 sec/batch; 13h:39m:14s remains)
INFO - root - 2017-12-16 20:55:58.330295: step 100320, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 14h:36m:48s remains)
INFO - root - 2017-12-16 20:56:00.514259: step 100330, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 13h:51m:37s remains)
INFO - root - 2017-12-16 20:56:02.692119: step 100340, loss = 0.46, batch loss = 0.28 (38.0 examples/sec; 0.211 sec/batch; 13h:34m:59s remains)
INFO - root - 2017-12-16 20:56:04.933161: step 100350, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 14h:34m:36s remains)
INFO - root - 2017-12-16 20:56:07.129364: step 100360, loss = 0.57, batch loss = 0.39 (36.0 examples/sec; 0.222 sec/batch; 14h:19m:42s remains)
INFO - root - 2017-12-16 20:56:09.347911: step 100370, loss = 0.53, batch loss = 0.36 (36.4 examples/sec; 0.220 sec/batch; 14h:10m:13s remains)
INFO - root - 2017-12-16 20:56:11.600894: step 100380, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 14h:34m:53s remains)
INFO - root - 2017-12-16 20:56:13.771929: step 100390, loss = 0.56, batch loss = 0.39 (37.8 examples/sec; 0.212 sec/batch; 13h:39m:12s remains)
INFO - root - 2017-12-16 20:56:15.960040: step 100400, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 14h:18m:51s remains)
INFO - root - 2017-12-16 20:56:18.276363: step 100410, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 14h:07m:30s remains)
INFO - root - 2017-12-16 20:56:20.513123: step 100420, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 14h:28m:59s remains)
INFO - root - 2017-12-16 20:56:22.755935: step 100430, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 14h:02m:22s remains)
INFO - root - 2017-12-16 20:56:24.950123: step 100440, loss = 0.47, batch loss = 0.30 (34.0 examples/sec; 0.235 sec/batch; 15h:08m:57s remains)
INFO - root - 2017-12-16 20:56:27.184087: step 100450, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 14h:25m:00s remains)
INFO - root - 2017-12-16 20:56:29.404416: step 100460, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 14h:19m:16s remains)
INFO - root - 2017-12-16 20:56:31.612451: step 100470, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 14h:11m:17s remains)
INFO - root - 2017-12-16 20:56:33.798613: step 100480, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 14h:15m:34s remains)
INFO - root - 2017-12-16 20:56:36.003011: step 100490, loss = 0.43, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 13h:57m:57s remains)
INFO - root - 2017-12-16 20:56:38.204296: step 100500, loss = 0.59, batch loss = 0.41 (34.2 examples/sec; 0.234 sec/batch; 15h:03m:26s remains)
INFO - root - 2017-12-16 20:56:40.583700: step 100510, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 14h:31m:39s remains)
INFO - root - 2017-12-16 20:56:42.851875: step 100520, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 14h:36m:36s remains)
INFO - root - 2017-12-16 20:56:45.095833: step 100530, loss = 0.46, batch loss = 0.29 (34.6 examples/sec; 0.231 sec/batch; 14h:53m:00s remains)
INFO - root - 2017-12-16 20:56:47.288548: step 100540, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 14h:40m:34s remains)
INFO - root - 2017-12-16 20:56:49.528573: step 100550, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 14h:15m:22s remains)
INFO - root - 2017-12-16 20:56:51.722248: step 100560, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 14h:22m:27s remains)
INFO - root - 2017-12-16 20:56:53.947395: step 100570, loss = 0.45, batch loss = 0.27 (34.6 examples/sec; 0.231 sec/batch; 14h:54m:51s remains)
INFO - root - 2017-12-16 20:56:56.156450: step 100580, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 14h:31m:00s remains)
INFO - root - 2017-12-16 20:56:58.368517: step 100590, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 14h:20m:50s remains)
INFO - root - 2017-12-16 20:57:00.547400: step 100600, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 14h:13m:30s remains)
INFO - root - 2017-12-16 20:57:02.863384: step 100610, loss = 0.44, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 13h:49m:34s remains)
INFO - root - 2017-12-16 20:57:05.058587: step 100620, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 14h:18m:54s remains)
INFO - root - 2017-12-16 20:57:07.274853: step 100630, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 14h:05m:29s remains)
INFO - root - 2017-12-16 20:57:09.493704: step 100640, loss = 0.58, batch loss = 0.40 (35.6 examples/sec; 0.225 sec/batch; 14h:28m:40s remains)
INFO - root - 2017-12-16 20:57:11.712643: step 100650, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 14h:00m:12s remains)
INFO - root - 2017-12-16 20:57:13.899577: step 100660, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 14h:03m:52s remains)
INFO - root - 2017-12-16 20:57:16.131646: step 100670, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 14h:21m:33s remains)
INFO - root - 2017-12-16 20:57:18.338105: step 100680, loss = 0.55, batch loss = 0.37 (36.9 examples/sec; 0.217 sec/batch; 13h:56m:43s remains)
INFO - root - 2017-12-16 20:57:20.552169: step 100690, loss = 0.55, batch loss = 0.37 (35.3 examples/sec; 0.227 sec/batch; 14h:35m:48s remains)
INFO - root - 2017-12-16 20:57:22.763866: step 100700, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 14h:32m:00s remains)
INFO - root - 2017-12-16 20:57:25.086515: step 100710, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.224 sec/batch; 14h:26m:55s remains)
INFO - root - 2017-12-16 20:57:27.310216: step 100720, loss = 0.61, batch loss = 0.43 (36.3 examples/sec; 0.220 sec/batch; 14h:11m:34s remains)
INFO - root - 2017-12-16 20:57:29.516294: step 100730, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 14h:11m:09s remains)
INFO - root - 2017-12-16 20:57:31.740957: step 100740, loss = 0.42, batch loss = 0.24 (36.6 examples/sec; 0.219 sec/batch; 14h:04m:07s remains)
INFO - root - 2017-12-16 20:57:33.945420: step 100750, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 14h:08m:48s remains)
INFO - root - 2017-12-16 20:57:36.130094: step 100760, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 14h:20m:03s remains)
INFO - root - 2017-12-16 20:57:38.376399: step 100770, loss = 0.52, batch loss = 0.34 (34.8 examples/sec; 0.230 sec/batch; 14h:48m:27s remains)
INFO - root - 2017-12-16 20:57:40.593641: step 100780, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 14h:19m:38s remains)
INFO - root - 2017-12-16 20:57:42.838279: step 100790, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 14h:47m:43s remains)
INFO - root - 2017-12-16 20:57:45.043787: step 100800, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 13h:50m:54s remains)
INFO - root - 2017-12-16 20:57:47.385847: step 100810, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 13h:49m:57s remains)
INFO - root - 2017-12-16 20:57:49.572691: step 100820, loss = 0.57, batch loss = 0.39 (35.6 examples/sec; 0.225 sec/batch; 14h:28m:24s remains)
INFO - root - 2017-12-16 20:57:51.775177: step 100830, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 14h:44m:21s remains)
INFO - root - 2017-12-16 20:57:54.014113: step 100840, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 14h:18m:04s remains)
INFO - root - 2017-12-16 20:57:56.198591: step 100850, loss = 0.54, batch loss = 0.36 (37.2 examples/sec; 0.215 sec/batch; 13h:50m:07s remains)
INFO - root - 2017-12-16 20:57:58.403910: step 100860, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 14h:15m:30s remains)
INFO - root - 2017-12-16 20:58:00.663656: step 100870, loss = 0.50, batch loss = 0.32 (33.1 examples/sec; 0.241 sec/batch; 15h:31m:49s remains)
INFO - root - 2017-12-16 20:58:02.908455: step 100880, loss = 0.55, batch loss = 0.37 (35.0 examples/sec; 0.228 sec/batch; 14h:41m:26s remains)
INFO - root - 2017-12-16 20:58:05.134314: step 100890, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 14h:05m:02s remains)
INFO - root - 2017-12-16 20:58:07.314275: step 100900, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 14h:00m:25s remains)
INFO - root - 2017-12-16 20:58:09.675099: step 100910, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 14h:27m:28s remains)
INFO - root - 2017-12-16 20:58:11.884454: step 100920, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 14h:30m:47s remains)
INFO - root - 2017-12-16 20:58:14.078279: step 100930, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 13h:44m:28s remains)
INFO - root - 2017-12-16 20:58:16.285824: step 100940, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 14h:11m:51s remains)
INFO - root - 2017-12-16 20:58:18.474236: step 100950, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:19m:57s remains)
INFO - root - 2017-12-16 20:58:20.709064: step 100960, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 14h:31m:09s remains)
INFO - root - 2017-12-16 20:58:22.958123: step 100970, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:18m:51s remains)
INFO - root - 2017-12-16 20:58:25.156203: step 100980, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 14h:31m:16s remains)
INFO - root - 2017-12-16 20:58:27.381906: step 100990, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 14h:29m:56s remains)
INFO - root - 2017-12-16 20:58:29.572315: step 101000, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 14h:16m:12s remains)
INFO - root - 2017-12-16 20:58:31.949155: step 101010, loss = 0.54, batch loss = 0.36 (34.9 examples/sec; 0.229 sec/batch; 14h:44m:32s remains)
INFO - root - 2017-12-16 20:58:34.155086: step 101020, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 14h:13m:39s remains)
INFO - root - 2017-12-16 20:58:36.351734: step 101030, loss = 0.46, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 14h:13m:43s remains)
INFO - root - 2017-12-16 20:58:38.558013: step 101040, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.215 sec/batch; 13h:48m:24s remains)
INFO - root - 2017-12-16 20:58:40.762425: step 101050, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 14h:41m:39s remains)
INFO - root - 2017-12-16 20:58:42.988323: step 101060, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 14h:26m:35s remains)
INFO - root - 2017-12-16 20:58:45.235901: step 101070, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 14h:30m:53s remains)
INFO - root - 2017-12-16 20:58:47.477233: step 101080, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 14h:23m:15s remains)
INFO - root - 2017-12-16 20:58:49.710127: step 101090, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 14h:23m:29s remains)
INFO - root - 2017-12-16 20:58:51.917286: step 101100, loss = 0.54, batch loss = 0.36 (37.3 examples/sec; 0.214 sec/batch; 13h:46m:18s remains)
INFO - root - 2017-12-16 20:58:54.329869: step 101110, loss = 0.50, batch loss = 0.32 (32.9 examples/sec; 0.243 sec/batch; 15h:38m:34s remains)
INFO - root - 2017-12-16 20:58:56.540503: step 101120, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 13h:53m:01s remains)
INFO - root - 2017-12-16 20:58:58.729938: step 101130, loss = 0.43, batch loss = 0.25 (34.4 examples/sec; 0.232 sec/batch; 14h:55m:32s remains)
INFO - root - 2017-12-16 20:59:00.954914: step 101140, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 13h:56m:36s remains)
INFO - root - 2017-12-16 20:59:03.179797: step 101150, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 13h:48m:46s remains)
INFO - root - 2017-12-16 20:59:05.397325: step 101160, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 13h:54m:31s remains)
INFO - root - 2017-12-16 20:59:07.637207: step 101170, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 14h:35m:21s remains)
INFO - root - 2017-12-16 20:59:09.839135: step 101180, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 14h:13m:20s remains)
INFO - root - 2017-12-16 20:59:12.052522: step 101190, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 13h:54m:46s remains)
INFO - root - 2017-12-16 20:59:14.283989: step 101200, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 14h:05m:58s remains)
INFO - root - 2017-12-16 20:59:16.629037: step 101210, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 14h:12m:42s remains)
INFO - root - 2017-12-16 20:59:18.840308: step 101220, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 13h:45m:44s remains)
INFO - root - 2017-12-16 20:59:21.083414: step 101230, loss = 0.58, batch loss = 0.40 (36.3 examples/sec; 0.221 sec/batch; 14h:10m:19s remains)
INFO - root - 2017-12-16 20:59:23.280842: step 101240, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 13h:59m:15s remains)
INFO - root - 2017-12-16 20:59:25.509274: step 101250, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 13h:54m:01s remains)
INFO - root - 2017-12-16 20:59:27.732949: step 101260, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 14h:14m:59s remains)
INFO - root - 2017-12-16 20:59:29.951952: step 101270, loss = 0.55, batch loss = 0.37 (35.5 examples/sec; 0.225 sec/batch; 14h:28m:17s remains)
INFO - root - 2017-12-16 20:59:32.158327: step 101280, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 13h:46m:22s remains)
INFO - root - 2017-12-16 20:59:34.364120: step 101290, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 13h:54m:27s remains)
INFO - root - 2017-12-16 20:59:36.579120: step 101300, loss = 0.44, batch loss = 0.26 (33.6 examples/sec; 0.238 sec/batch; 15h:17m:10s remains)
INFO - root - 2017-12-16 20:59:38.967863: step 101310, loss = 0.51, batch loss = 0.33 (34.5 examples/sec; 0.232 sec/batch; 14h:53m:48s remains)
INFO - root - 2017-12-16 20:59:41.205441: step 101320, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 14h:26m:32s remains)
INFO - root - 2017-12-16 20:59:43.435294: step 101330, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 14h:43m:15s remains)
INFO - root - 2017-12-16 20:59:45.649818: step 101340, loss = 0.59, batch loss = 0.41 (36.3 examples/sec; 0.220 sec/batch; 14h:08m:46s remains)
INFO - root - 2017-12-16 20:59:47.866125: step 101350, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 14h:11m:54s remains)
INFO - root - 2017-12-16 20:59:50.088452: step 101360, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 14h:10m:50s remains)
INFO - root - 2017-12-16 20:59:52.317753: step 101370, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 14h:13m:20s remains)
INFO - root - 2017-12-16 20:59:54.572904: step 101380, loss = 0.45, batch loss = 0.27 (33.7 examples/sec; 0.237 sec/batch; 15h:14m:01s remains)
INFO - root - 2017-12-16 20:59:56.790622: step 101390, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 14h:17m:10s remains)
INFO - root - 2017-12-16 20:59:59.006454: step 101400, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 14h:25m:34s remains)
INFO - root - 2017-12-16 21:00:01.339881: step 101410, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 13h:49m:41s remains)
INFO - root - 2017-12-16 21:00:03.538525: step 101420, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.224 sec/batch; 14h:21m:17s remains)
INFO - root - 2017-12-16 21:00:05.738261: step 101430, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 14h:42m:10s remains)
INFO - root - 2017-12-16 21:00:07.954079: step 101440, loss = 0.45, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 14h:01m:22s remains)
INFO - root - 2017-12-16 21:00:10.180405: step 101450, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 14h:15m:07s remains)
INFO - root - 2017-12-16 21:00:12.370067: step 101460, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 14h:05m:18s remains)
INFO - root - 2017-12-16 21:00:14.565347: step 101470, loss = 0.48, batch loss = 0.30 (38.0 examples/sec; 0.211 sec/batch; 13h:30m:47s remains)
INFO - root - 2017-12-16 21:00:16.791838: step 101480, loss = 0.57, batch loss = 0.39 (36.1 examples/sec; 0.221 sec/batch; 14h:12m:34s remains)
INFO - root - 2017-12-16 21:00:18.978936: step 101490, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 13h:57m:00s remains)
INFO - root - 2017-12-16 21:00:21.174471: step 101500, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:17m:25s remains)
INFO - root - 2017-12-16 21:00:23.610248: step 101510, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:18m:34s remains)
INFO - root - 2017-12-16 21:00:25.809419: step 101520, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 14h:14m:14s remains)
INFO - root - 2017-12-16 21:00:28.047730: step 101530, loss = 0.53, batch loss = 0.35 (34.7 examples/sec; 0.231 sec/batch; 14h:48m:23s remains)
INFO - root - 2017-12-16 21:00:30.242513: step 101540, loss = 0.51, batch loss = 0.34 (34.8 examples/sec; 0.230 sec/batch; 14h:43m:41s remains)
INFO - root - 2017-12-16 21:00:32.479538: step 101550, loss = 0.50, batch loss = 0.32 (34.6 examples/sec; 0.231 sec/batch; 14h:50m:33s remains)
INFO - root - 2017-12-16 21:00:34.694861: step 101560, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 14h:13m:22s remains)
INFO - root - 2017-12-16 21:00:36.937326: step 101570, loss = 0.55, batch loss = 0.37 (36.8 examples/sec; 0.217 sec/batch; 13h:56m:25s remains)
INFO - root - 2017-12-16 21:00:39.159135: step 101580, loss = 0.47, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 14h:32m:14s remains)
INFO - root - 2017-12-16 21:00:41.391110: step 101590, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 14h:02m:17s remains)
INFO - root - 2017-12-16 21:00:43.662230: step 101600, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 14h:37m:14s remains)
INFO - root - 2017-12-16 21:00:45.995515: step 101610, loss = 0.47, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 14h:01m:30s remains)
INFO - root - 2017-12-16 21:00:48.186592: step 101620, loss = 0.45, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 13h:43m:42s remains)
INFO - root - 2017-12-16 21:00:50.403061: step 101630, loss = 0.56, batch loss = 0.38 (36.5 examples/sec; 0.219 sec/batch; 14h:03m:15s remains)
INFO - root - 2017-12-16 21:00:52.643392: step 101640, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.215 sec/batch; 13h:49m:07s remains)
INFO - root - 2017-12-16 21:00:54.854906: step 101650, loss = 0.55, batch loss = 0.37 (37.4 examples/sec; 0.214 sec/batch; 13h:44m:04s remains)
INFO - root - 2017-12-16 21:00:57.088586: step 101660, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.218 sec/batch; 13h:57m:23s remains)
INFO - root - 2017-12-16 21:00:59.279757: step 101670, loss = 0.54, batch loss = 0.37 (34.0 examples/sec; 0.236 sec/batch; 15h:06m:24s remains)
INFO - root - 2017-12-16 21:01:01.501170: step 101680, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 14h:04m:05s remains)
INFO - root - 2017-12-16 21:01:03.702879: step 101690, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 14h:00m:36s remains)
INFO - root - 2017-12-16 21:01:05.882625: step 101700, loss = 0.46, batch loss = 0.28 (37.7 examples/sec; 0.212 sec/batch; 13h:37m:15s remains)
INFO - root - 2017-12-16 21:01:08.209430: step 101710, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 13h:54m:07s remains)
INFO - root - 2017-12-16 21:01:10.418540: step 101720, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 14h:51m:04s remains)
INFO - root - 2017-12-16 21:01:12.640190: step 101730, loss = 0.47, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 14h:03m:05s remains)
INFO - root - 2017-12-16 21:01:14.840099: step 101740, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 13h:51m:09s remains)
INFO - root - 2017-12-16 21:01:17.115262: step 101750, loss = 0.48, batch loss = 0.30 (32.8 examples/sec; 0.244 sec/batch; 15h:36m:52s remains)
INFO - root - 2017-12-16 21:01:19.360327: step 101760, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 14h:02m:49s remains)
INFO - root - 2017-12-16 21:01:21.557510: step 101770, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 13h:45m:23s remains)
INFO - root - 2017-12-16 21:01:23.767857: step 101780, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 13h:54m:00s remains)
INFO - root - 2017-12-16 21:01:25.984556: step 101790, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 14h:28m:11s remains)
INFO - root - 2017-12-16 21:01:28.204810: step 101800, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 13h:54m:10s remains)
INFO - root - 2017-12-16 21:01:30.565833: step 101810, loss = 0.55, batch loss = 0.37 (35.9 examples/sec; 0.223 sec/batch; 14h:16m:34s remains)
INFO - root - 2017-12-16 21:01:32.766733: step 101820, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 13h:49m:26s remains)
INFO - root - 2017-12-16 21:01:34.993804: step 101830, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 13h:54m:26s remains)
INFO - root - 2017-12-16 21:01:37.209474: step 101840, loss = 0.56, batch loss = 0.38 (37.5 examples/sec; 0.213 sec/batch; 13h:39m:23s remains)
INFO - root - 2017-12-16 21:01:39.421500: step 101850, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 13h:54m:18s remains)
INFO - root - 2017-12-16 21:01:41.626822: step 101860, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 14h:20m:20s remains)
INFO - root - 2017-12-16 21:01:43.846693: step 101870, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 14h:05m:03s remains)
INFO - root - 2017-12-16 21:01:46.061015: step 101880, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 13h:55m:23s remains)
INFO - root - 2017-12-16 21:01:48.264740: step 101890, loss = 0.44, batch loss = 0.26 (35.0 examples/sec; 0.228 sec/batch; 14h:37m:39s remains)
INFO - root - 2017-12-16 21:01:50.476278: step 101900, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 14h:02m:14s remains)
INFO - root - 2017-12-16 21:01:52.817927: step 101910, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 14h:17m:51s remains)
INFO - root - 2017-12-16 21:01:55.023403: step 101920, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 14h:06m:34s remains)
INFO - root - 2017-12-16 21:01:57.251622: step 101930, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 13h:55m:03s remains)
INFO - root - 2017-12-16 21:01:59.456956: step 101940, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 13h:58m:57s remains)
INFO - root - 2017-12-16 21:02:01.671532: step 101950, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 13h:47m:18s remains)
INFO - root - 2017-12-16 21:02:03.882486: step 101960, loss = 0.43, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 14h:19m:37s remains)
INFO - root - 2017-12-16 21:02:06.128720: step 101970, loss = 0.50, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 13h:57m:40s remains)
INFO - root - 2017-12-16 21:02:08.342006: step 101980, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 14h:08m:12s remains)
INFO - root - 2017-12-16 21:02:10.554431: step 101990, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 14h:04m:31s remains)
INFO - root - 2017-12-16 21:02:12.740648: step 102000, loss = 0.45, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:16m:59s remains)
INFO - root - 2017-12-16 21:02:15.060607: step 102010, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 14h:02m:22s remains)
INFO - root - 2017-12-16 21:02:17.297024: step 102020, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 13h:59m:21s remains)
INFO - root - 2017-12-16 21:02:19.509865: step 102030, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 14h:00m:32s remains)
INFO - root - 2017-12-16 21:02:21.743222: step 102040, loss = 0.49, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 13h:54m:11s remains)
INFO - root - 2017-12-16 21:02:23.983633: step 102050, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 13h:56m:52s remains)
INFO - root - 2017-12-16 21:02:26.170700: step 102060, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 13h:43m:32s remains)
INFO - root - 2017-12-16 21:02:28.358528: step 102070, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 14h:10m:43s remains)
INFO - root - 2017-12-16 21:02:30.585741: step 102080, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 14h:35m:32s remains)
INFO - root - 2017-12-16 21:02:32.753080: step 102090, loss = 0.55, batch loss = 0.38 (36.8 examples/sec; 0.217 sec/batch; 13h:53m:50s remains)
INFO - root - 2017-12-16 21:02:34.966087: step 102100, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 14h:24m:02s remains)
INFO - root - 2017-12-16 21:02:37.287192: step 102110, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 14h:13m:41s remains)
INFO - root - 2017-12-16 21:02:39.539143: step 102120, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 13h:50m:30s remains)
INFO - root - 2017-12-16 21:02:41.779396: step 102130, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 14h:09m:45s remains)
INFO - root - 2017-12-16 21:02:43.992195: step 102140, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 13h:48m:33s remains)
INFO - root - 2017-12-16 21:02:46.198420: step 102150, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 13h:47m:30s remains)
INFO - root - 2017-12-16 21:02:48.398446: step 102160, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 13h:50m:25s remains)
INFO - root - 2017-12-16 21:02:50.623070: step 102170, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 13h:58m:01s remains)
INFO - root - 2017-12-16 21:02:52.866123: step 102180, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 14h:22m:24s remains)
INFO - root - 2017-12-16 21:02:55.093211: step 102190, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 13h:40m:44s remains)
INFO - root - 2017-12-16 21:02:57.312745: step 102200, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 13h:45m:46s remains)
INFO - root - 2017-12-16 21:02:59.712493: step 102210, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 14h:01m:50s remains)
INFO - root - 2017-12-16 21:03:01.928105: step 102220, loss = 0.48, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 14h:39m:12s remains)
INFO - root - 2017-12-16 21:03:04.151325: step 102230, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 13h:44m:27s remains)
INFO - root - 2017-12-16 21:03:06.373535: step 102240, loss = 0.57, batch loss = 0.39 (35.8 examples/sec; 0.224 sec/batch; 14h:18m:22s remains)
INFO - root - 2017-12-16 21:03:08.604491: step 102250, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 14h:09m:58s remains)
INFO - root - 2017-12-16 21:03:10.809330: step 102260, loss = 0.50, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 13h:51m:32s remains)
INFO - root - 2017-12-16 21:03:13.046895: step 102270, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 14h:22m:53s remains)
INFO - root - 2017-12-16 21:03:15.291870: step 102280, loss = 0.54, batch loss = 0.36 (35.2 examples/sec; 0.227 sec/batch; 14h:32m:28s remains)
INFO - root - 2017-12-16 21:03:17.443977: step 102290, loss = 0.55, batch loss = 0.37 (37.3 examples/sec; 0.214 sec/batch; 13h:41m:57s remains)
INFO - root - 2017-12-16 21:03:19.684657: step 102300, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 13h:49m:46s remains)
INFO - root - 2017-12-16 21:03:22.075853: step 102310, loss = 0.41, batch loss = 0.23 (37.1 examples/sec; 0.216 sec/batch; 13h:48m:10s remains)
INFO - root - 2017-12-16 21:03:24.298736: step 102320, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 13h:35m:17s remains)
INFO - root - 2017-12-16 21:03:26.494405: step 102330, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 14h:12m:05s remains)
INFO - root - 2017-12-16 21:03:28.686956: step 102340, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 14h:03m:05s remains)
INFO - root - 2017-12-16 21:03:30.891590: step 102350, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 14h:05m:06s remains)
INFO - root - 2017-12-16 21:03:33.096369: step 102360, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 14h:18m:52s remains)
INFO - root - 2017-12-16 21:03:35.285901: step 102370, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 13h:50m:39s remains)
INFO - root - 2017-12-16 21:03:37.496525: step 102380, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.215 sec/batch; 13h:46m:13s remains)
INFO - root - 2017-12-16 21:03:39.704461: step 102390, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 13h:57m:10s remains)
INFO - root - 2017-12-16 21:03:41.948371: step 102400, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 14h:19m:12s remains)
INFO - root - 2017-12-16 21:03:44.320097: step 102410, loss = 0.51, batch loss = 0.33 (35.2 examples/sec; 0.228 sec/batch; 14h:32m:41s remains)
INFO - root - 2017-12-16 21:03:46.521289: step 102420, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 14h:03m:15s remains)
INFO - root - 2017-12-16 21:03:48.746333: step 102430, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 13h:56m:57s remains)
INFO - root - 2017-12-16 21:03:50.945783: step 102440, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 13h:54m:46s remains)
INFO - root - 2017-12-16 21:03:53.136633: step 102450, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.224 sec/batch; 14h:20m:40s remains)
INFO - root - 2017-12-16 21:03:55.337491: step 102460, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 14h:37m:55s remains)
INFO - root - 2017-12-16 21:03:57.551927: step 102470, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 14h:08m:34s remains)
INFO - root - 2017-12-16 21:03:59.755606: step 102480, loss = 0.55, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 14h:02m:15s remains)
INFO - root - 2017-12-16 21:04:01.967271: step 102490, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 14h:25m:08s remains)
INFO - root - 2017-12-16 21:04:04.161503: step 102500, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 13h:44m:04s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-102500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-102500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 21:04:07.126311: step 102510, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 14h:21m:36s remains)
INFO - root - 2017-12-16 21:04:09.344459: step 102520, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 13h:48m:19s remains)
INFO - root - 2017-12-16 21:04:11.544777: step 102530, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 13h:46m:34s remains)
INFO - root - 2017-12-16 21:04:13.737263: step 102540, loss = 0.52, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 14h:06m:07s remains)
INFO - root - 2017-12-16 21:04:15.901912: step 102550, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.211 sec/batch; 13h:30m:05s remains)
INFO - root - 2017-12-16 21:04:18.077443: step 102560, loss = 0.51, batch loss = 0.33 (38.1 examples/sec; 0.210 sec/batch; 13h:25m:30s remains)
INFO - root - 2017-12-16 21:04:20.239102: step 102570, loss = 0.56, batch loss = 0.38 (37.1 examples/sec; 0.216 sec/batch; 13h:47m:07s remains)
INFO - root - 2017-12-16 21:04:22.467862: step 102580, loss = 0.49, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 13h:49m:16s remains)
INFO - root - 2017-12-16 21:04:24.718190: step 102590, loss = 0.48, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 14h:07m:18s remains)
INFO - root - 2017-12-16 21:04:26.944262: step 102600, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 14h:32m:20s remains)
INFO - root - 2017-12-16 21:04:29.295571: step 102610, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 13h:56m:00s remains)
INFO - root - 2017-12-16 21:04:31.475738: step 102620, loss = 0.54, batch loss = 0.36 (37.2 examples/sec; 0.215 sec/batch; 13h:43m:45s remains)
INFO - root - 2017-12-16 21:04:33.687868: step 102630, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 14h:32m:26s remains)
INFO - root - 2017-12-16 21:04:35.910198: step 102640, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 14h:19m:09s remains)
INFO - root - 2017-12-16 21:04:38.163883: step 102650, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 14h:21m:42s remains)
INFO - root - 2017-12-16 21:04:40.378851: step 102660, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 14h:07m:01s remains)
INFO - root - 2017-12-16 21:04:42.566736: step 102670, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 14h:14m:31s remains)
INFO - root - 2017-12-16 21:04:44.807997: step 102680, loss = 0.51, batch loss = 0.33 (33.7 examples/sec; 0.237 sec/batch; 15h:09m:07s remains)
INFO - root - 2017-12-16 21:04:47.006012: step 102690, loss = 0.48, batch loss = 0.30 (37.9 examples/sec; 0.211 sec/batch; 13h:28m:53s remains)
INFO - root - 2017-12-16 21:04:49.228096: step 102700, loss = 0.46, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 13h:35m:25s remains)
INFO - root - 2017-12-16 21:04:51.603005: step 102710, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 14h:01m:47s remains)
INFO - root - 2017-12-16 21:04:53.828677: step 102720, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 14h:48m:58s remains)
INFO - root - 2017-12-16 21:04:56.072424: step 102730, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 14h:02m:23s remains)
INFO - root - 2017-12-16 21:04:58.282658: step 102740, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 14h:03m:33s remains)
INFO - root - 2017-12-16 21:05:00.497004: step 102750, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 13h:54m:21s remains)
INFO - root - 2017-12-16 21:05:02.717456: step 102760, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 14h:38m:26s remains)
INFO - root - 2017-12-16 21:05:04.936261: step 102770, loss = 0.42, batch loss = 0.24 (36.4 examples/sec; 0.220 sec/batch; 14h:01m:17s remains)
INFO - root - 2017-12-16 21:05:07.171547: step 102780, loss = 0.47, batch loss = 0.29 (33.6 examples/sec; 0.238 sec/batch; 15h:10m:51s remains)
INFO - root - 2017-12-16 21:05:09.410570: step 102790, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.226 sec/batch; 14h:26m:56s remains)
INFO - root - 2017-12-16 21:05:11.640510: step 102800, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 14h:04m:24s remains)
INFO - root - 2017-12-16 21:05:13.969224: step 102810, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 14h:38m:52s remains)
INFO - root - 2017-12-16 21:05:16.192209: step 102820, loss = 0.53, batch loss = 0.36 (36.8 examples/sec; 0.217 sec/batch; 13h:51m:06s remains)
INFO - root - 2017-12-16 21:05:18.399170: step 102830, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 13h:54m:24s remains)
INFO - root - 2017-12-16 21:05:20.597851: step 102840, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 14h:03m:27s remains)
INFO - root - 2017-12-16 21:05:22.829412: step 102850, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 14h:21m:08s remains)
INFO - root - 2017-12-16 21:05:25.035057: step 102860, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 13h:41m:26s remains)
INFO - root - 2017-12-16 21:05:27.243662: step 102870, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 14h:17m:31s remains)
INFO - root - 2017-12-16 21:05:29.457850: step 102880, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 14h:00m:27s remains)
INFO - root - 2017-12-16 21:05:31.688302: step 102890, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.232 sec/batch; 14h:49m:14s remains)
INFO - root - 2017-12-16 21:05:33.893732: step 102900, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 13h:44m:11s remains)
INFO - root - 2017-12-16 21:05:36.212083: step 102910, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 14h:02m:24s remains)
INFO - root - 2017-12-16 21:05:38.426066: step 102920, loss = 0.44, batch loss = 0.26 (33.3 examples/sec; 0.240 sec/batch; 15h:19m:00s remains)
INFO - root - 2017-12-16 21:05:40.614147: step 102930, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 13h:43m:53s remains)
INFO - root - 2017-12-16 21:05:42.839968: step 102940, loss = 0.44, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 14h:06m:11s remains)
INFO - root - 2017-12-16 21:05:45.046250: step 102950, loss = 0.42, batch loss = 0.24 (37.4 examples/sec; 0.214 sec/batch; 13h:37m:26s remains)
INFO - root - 2017-12-16 21:05:47.243025: step 102960, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 14h:08m:22s remains)
INFO - root - 2017-12-16 21:05:49.464496: step 102970, loss = 0.45, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 14h:16m:04s remains)
INFO - root - 2017-12-16 21:05:51.666075: step 102980, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 13h:57m:14s remains)
INFO - root - 2017-12-16 21:05:53.890141: step 102990, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 14h:16m:33s remains)
INFO - root - 2017-12-16 21:05:56.097280: step 103000, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 13h:57m:43s remains)
INFO - root - 2017-12-16 21:05:58.462866: step 103010, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 13h:35m:40s remains)
INFO - root - 2017-12-16 21:06:00.673462: step 103020, loss = 0.52, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 13h:37m:41s remains)
INFO - root - 2017-12-16 21:06:02.857478: step 103030, loss = 0.45, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 13h:51m:04s remains)
INFO - root - 2017-12-16 21:06:05.083822: step 103040, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 13h:56m:35s remains)
INFO - root - 2017-12-16 21:06:07.301904: step 103050, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 14h:37m:31s remains)
INFO - root - 2017-12-16 21:06:09.541629: step 103060, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 14h:15m:50s remains)
INFO - root - 2017-12-16 21:06:11.747166: step 103070, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 13h:31m:28s remains)
INFO - root - 2017-12-16 21:06:13.944144: step 103080, loss = 0.53, batch loss = 0.35 (37.9 examples/sec; 0.211 sec/batch; 13h:26m:17s remains)
INFO - root - 2017-12-16 21:06:16.149959: step 103090, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 13h:44m:22s remains)
INFO - root - 2017-12-16 21:06:18.354287: step 103100, loss = 0.47, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 14h:13m:35s remains)
INFO - root - 2017-12-16 21:06:20.700488: step 103110, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 13h:50m:16s remains)
INFO - root - 2017-12-16 21:06:22.942206: step 103120, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 14h:43m:43s remains)
INFO - root - 2017-12-16 21:06:25.168406: step 103130, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 14h:19m:30s remains)
INFO - root - 2017-12-16 21:06:27.380272: step 103140, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 14h:02m:13s remains)
INFO - root - 2017-12-16 21:06:29.589641: step 103150, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 14h:36m:29s remains)
INFO - root - 2017-12-16 21:06:31.805595: step 103160, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 13h:47m:26s remains)
INFO - root - 2017-12-16 21:06:34.076330: step 103170, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 13h:59m:34s remains)
INFO - root - 2017-12-16 21:06:36.327695: step 103180, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 14h:42m:18s remains)
INFO - root - 2017-12-16 21:06:38.543223: step 103190, loss = 0.50, batch loss = 0.32 (39.2 examples/sec; 0.204 sec/batch; 12h:59m:34s remains)
INFO - root - 2017-12-16 21:06:40.785116: step 103200, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 14h:00m:45s remains)
INFO - root - 2017-12-16 21:06:43.119908: step 103210, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 13h:54m:07s remains)
INFO - root - 2017-12-16 21:06:45.314491: step 103220, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 13h:48m:45s remains)
INFO - root - 2017-12-16 21:06:47.540019: step 103230, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 14h:11m:09s remains)
INFO - root - 2017-12-16 21:06:49.792766: step 103240, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 14h:06m:47s remains)
INFO - root - 2017-12-16 21:06:52.020025: step 103250, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.226 sec/batch; 14h:25m:00s remains)
INFO - root - 2017-12-16 21:06:54.298218: step 103260, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 13h:58m:12s remains)
INFO - root - 2017-12-16 21:06:56.535740: step 103270, loss = 0.47, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 14h:27m:58s remains)
INFO - root - 2017-12-16 21:06:58.782867: step 103280, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 13h:46m:25s remains)
INFO - root - 2017-12-16 21:07:00.989699: step 103290, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 13h:44m:12s remains)
INFO - root - 2017-12-16 21:07:03.211709: step 103300, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 14h:08m:16s remains)
INFO - root - 2017-12-16 21:07:05.538774: step 103310, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 14h:05m:55s remains)
INFO - root - 2017-12-16 21:07:07.730713: step 103320, loss = 0.56, batch loss = 0.38 (36.7 examples/sec; 0.218 sec/batch; 13h:51m:31s remains)
INFO - root - 2017-12-16 21:07:09.961889: step 103330, loss = 0.47, batch loss = 0.29 (34.3 examples/sec; 0.233 sec/batch; 14h:49m:41s remains)
INFO - root - 2017-12-16 21:07:12.168584: step 103340, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 13h:43m:21s remains)
INFO - root - 2017-12-16 21:07:14.416501: step 103350, loss = 0.45, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 14h:15m:30s remains)
INFO - root - 2017-12-16 21:07:16.595115: step 103360, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 13h:28m:57s remains)
INFO - root - 2017-12-16 21:07:18.798209: step 103370, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 13h:38m:38s remains)
INFO - root - 2017-12-16 21:07:20.981182: step 103380, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 14h:06m:01s remains)
INFO - root - 2017-12-16 21:07:23.230346: step 103390, loss = 0.53, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 14h:18m:40s remains)
INFO - root - 2017-12-16 21:07:25.451721: step 103400, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 14h:04m:18s remains)
INFO - root - 2017-12-16 21:07:27.766801: step 103410, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.226 sec/batch; 14h:21m:34s remains)
INFO - root - 2017-12-16 21:07:30.022057: step 103420, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 14h:21m:22s remains)
INFO - root - 2017-12-16 21:07:32.281984: step 103430, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 13h:40m:57s remains)
INFO - root - 2017-12-16 21:07:34.479073: step 103440, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 13h:52m:53s remains)
INFO - root - 2017-12-16 21:07:36.685910: step 103450, loss = 0.53, batch loss = 0.36 (35.8 examples/sec; 0.223 sec/batch; 14h:12m:48s remains)
INFO - root - 2017-12-16 21:07:38.916100: step 103460, loss = 0.55, batch loss = 0.37 (34.9 examples/sec; 0.229 sec/batch; 14h:35m:05s remains)
INFO - root - 2017-12-16 21:07:41.110276: step 103470, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 14h:04m:20s remains)
INFO - root - 2017-12-16 21:07:43.323874: step 103480, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 14h:02m:00s remains)
INFO - root - 2017-12-16 21:07:45.505478: step 103490, loss = 0.51, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 13h:50m:06s remains)
INFO - root - 2017-12-16 21:07:47.691587: step 103500, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 13h:43m:35s remains)
INFO - root - 2017-12-16 21:07:50.035269: step 103510, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 14h:36m:54s remains)
INFO - root - 2017-12-16 21:07:52.242241: step 103520, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 13h:37m:08s remains)
INFO - root - 2017-12-16 21:07:54.453491: step 103530, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 13h:48m:47s remains)
INFO - root - 2017-12-16 21:07:56.651551: step 103540, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 14h:30m:41s remains)
INFO - root - 2017-12-16 21:07:58.844567: step 103550, loss = 0.46, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 13h:30m:42s remains)
INFO - root - 2017-12-16 21:08:01.049596: step 103560, loss = 0.44, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 13h:32m:24s remains)
INFO - root - 2017-12-16 21:08:03.290818: step 103570, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 13h:55m:13s remains)
INFO - root - 2017-12-16 21:08:05.546887: step 103580, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 13h:43m:41s remains)
INFO - root - 2017-12-16 21:08:07.742001: step 103590, loss = 0.56, batch loss = 0.38 (35.8 examples/sec; 0.223 sec/batch; 14h:12m:33s remains)
INFO - root - 2017-12-16 21:08:09.978388: step 103600, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 14h:16m:33s remains)
INFO - root - 2017-12-16 21:08:12.333820: step 103610, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 14h:21m:59s remains)
INFO - root - 2017-12-16 21:08:14.536600: step 103620, loss = 0.57, batch loss = 0.39 (36.4 examples/sec; 0.220 sec/batch; 13h:57m:27s remains)
INFO - root - 2017-12-16 21:08:16.707646: step 103630, loss = 0.50, batch loss = 0.32 (38.0 examples/sec; 0.210 sec/batch; 13h:22m:48s remains)
INFO - root - 2017-12-16 21:08:18.890241: step 103640, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 13h:54m:33s remains)
INFO - root - 2017-12-16 21:08:21.079262: step 103650, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 14h:05m:54s remains)
INFO - root - 2017-12-16 21:08:23.307352: step 103660, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 13h:53m:24s remains)
INFO - root - 2017-12-16 21:08:25.513550: step 103670, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 13h:58m:46s remains)
INFO - root - 2017-12-16 21:08:27.731545: step 103680, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:09m:27s remains)
INFO - root - 2017-12-16 21:08:29.942102: step 103690, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.216 sec/batch; 13h:42m:44s remains)
INFO - root - 2017-12-16 21:08:32.171789: step 103700, loss = 0.54, batch loss = 0.36 (35.5 examples/sec; 0.225 sec/batch; 14h:19m:01s remains)
INFO - root - 2017-12-16 21:08:34.501963: step 103710, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 13h:38m:10s remains)
INFO - root - 2017-12-16 21:08:36.739204: step 103720, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 14h:00m:57s remains)
INFO - root - 2017-12-16 21:08:38.944268: step 103730, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 13h:44m:26s remains)
INFO - root - 2017-12-16 21:08:41.150572: step 103740, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.231 sec/batch; 14h:39m:39s remains)
INFO - root - 2017-12-16 21:08:43.373667: step 103750, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 13h:44m:46s remains)
INFO - root - 2017-12-16 21:08:45.593612: step 103760, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 14h:02m:32s remains)
INFO - root - 2017-12-16 21:08:47.827968: step 103770, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 14h:26m:17s remains)
INFO - root - 2017-12-16 21:08:50.065706: step 103780, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 13h:54m:14s remains)
INFO - root - 2017-12-16 21:08:52.251428: step 103790, loss = 0.47, batch loss = 0.30 (37.8 examples/sec; 0.212 sec/batch; 13h:26m:48s remains)
INFO - root - 2017-12-16 21:08:54.453782: step 103800, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 14h:19m:32s remains)
INFO - root - 2017-12-16 21:08:56.778541: step 103810, loss = 0.61, batch loss = 0.43 (36.0 examples/sec; 0.223 sec/batch; 14h:08m:08s remains)
INFO - root - 2017-12-16 21:08:58.992414: step 103820, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 13h:40m:01s remains)
INFO - root - 2017-12-16 21:09:01.249257: step 103830, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 14h:24m:49s remains)
INFO - root - 2017-12-16 21:09:03.473888: step 103840, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 14h:16m:12s remains)
INFO - root - 2017-12-16 21:09:05.706577: step 103850, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 14h:27m:52s remains)
INFO - root - 2017-12-16 21:09:07.952553: step 103860, loss = 0.52, batch loss = 0.34 (33.7 examples/sec; 0.237 sec/batch; 15h:04m:52s remains)
INFO - root - 2017-12-16 21:09:10.167399: step 103870, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 14h:18m:16s remains)
INFO - root - 2017-12-16 21:09:12.380607: step 103880, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 14h:20m:15s remains)
INFO - root - 2017-12-16 21:09:14.608148: step 103890, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 14h:10m:48s remains)
INFO - root - 2017-12-16 21:09:16.844948: step 103900, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 13h:35m:18s remains)
INFO - root - 2017-12-16 21:09:19.174956: step 103910, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 13h:51m:17s remains)
INFO - root - 2017-12-16 21:09:21.362432: step 103920, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 13h:54m:40s remains)
INFO - root - 2017-12-16 21:09:23.603988: step 103930, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 14h:04m:03s remains)
INFO - root - 2017-12-16 21:09:25.827037: step 103940, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 14h:13m:51s remains)
INFO - root - 2017-12-16 21:09:28.020666: step 103950, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 14h:02m:58s remains)
INFO - root - 2017-12-16 21:09:30.219375: step 103960, loss = 0.44, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 14h:13m:15s remains)
INFO - root - 2017-12-16 21:09:32.415834: step 103970, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 14h:00m:02s remains)
INFO - root - 2017-12-16 21:09:34.628026: step 103980, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 13h:32m:15s remains)
INFO - root - 2017-12-16 21:09:36.841058: step 103990, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 14h:14m:31s remains)
INFO - root - 2017-12-16 21:09:39.065438: step 104000, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 13h:38m:09s remains)
INFO - root - 2017-12-16 21:09:41.368971: step 104010, loss = 0.48, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 13h:54m:00s remains)
INFO - root - 2017-12-16 21:09:43.592251: step 104020, loss = 0.56, batch loss = 0.38 (36.2 examples/sec; 0.221 sec/batch; 14h:02m:25s remains)
INFO - root - 2017-12-16 21:09:45.804751: step 104030, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 14h:16m:38s remains)
INFO - root - 2017-12-16 21:09:48.002216: step 104040, loss = 0.50, batch loss = 0.32 (37.8 examples/sec; 0.212 sec/batch; 13h:26m:31s remains)
INFO - root - 2017-12-16 21:09:50.235787: step 104050, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.221 sec/batch; 13h:59m:42s remains)
INFO - root - 2017-12-16 21:09:52.447587: step 104060, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 13h:50m:41s remains)
INFO - root - 2017-12-16 21:09:54.655958: step 104070, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 14h:16m:19s remains)
INFO - root - 2017-12-16 21:09:56.859245: step 104080, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 14h:06m:19s remains)
INFO - root - 2017-12-16 21:09:59.102119: step 104090, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 13h:52m:36s remains)
INFO - root - 2017-12-16 21:10:01.300481: step 104100, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 13h:49m:10s remains)
INFO - root - 2017-12-16 21:10:03.672704: step 104110, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 14h:04m:27s remains)
INFO - root - 2017-12-16 21:10:05.875175: step 104120, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 13h:48m:17s remains)
INFO - root - 2017-12-16 21:10:08.113388: step 104130, loss = 0.47, batch loss = 0.29 (34.3 examples/sec; 0.233 sec/batch; 14h:48m:27s remains)
INFO - root - 2017-12-16 21:10:10.351477: step 104140, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 14h:04m:01s remains)
INFO - root - 2017-12-16 21:10:12.590225: step 104150, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 14h:23m:34s remains)
INFO - root - 2017-12-16 21:10:14.856467: step 104160, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 14h:16m:47s remains)
INFO - root - 2017-12-16 21:10:17.106112: step 104170, loss = 0.41, batch loss = 0.23 (35.7 examples/sec; 0.224 sec/batch; 14h:13m:14s remains)
INFO - root - 2017-12-16 21:10:19.332349: step 104180, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 14h:09m:23s remains)
INFO - root - 2017-12-16 21:10:21.523367: step 104190, loss = 0.58, batch loss = 0.40 (36.3 examples/sec; 0.220 sec/batch; 13h:58m:37s remains)
INFO - root - 2017-12-16 21:10:23.803553: step 104200, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 14h:09m:44s remains)
INFO - root - 2017-12-16 21:10:26.166546: step 104210, loss = 0.43, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 14h:14m:36s remains)
INFO - root - 2017-12-16 21:10:28.422663: step 104220, loss = 0.52, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 14h:25m:13s remains)
INFO - root - 2017-12-16 21:10:30.652767: step 104230, loss = 0.50, batch loss = 0.32 (37.9 examples/sec; 0.211 sec/batch; 13h:23m:26s remains)
INFO - root - 2017-12-16 21:10:32.884622: step 104240, loss = 0.50, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 14h:32m:04s remains)
INFO - root - 2017-12-16 21:10:35.082465: step 104250, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 13h:37m:32s remains)
INFO - root - 2017-12-16 21:10:37.307337: step 104260, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 13h:49m:35s remains)
INFO - root - 2017-12-16 21:10:39.525007: step 104270, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 13h:42m:45s remains)
INFO - root - 2017-12-16 21:10:41.746688: step 104280, loss = 0.46, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 14h:21m:40s remains)
INFO - root - 2017-12-16 21:10:43.995189: step 104290, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 14h:12m:44s remains)
INFO - root - 2017-12-16 21:10:46.205028: step 104300, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 13h:42m:55s remains)
INFO - root - 2017-12-16 21:10:48.557513: step 104310, loss = 0.45, batch loss = 0.27 (34.7 examples/sec; 0.231 sec/batch; 14h:37m:51s remains)
INFO - root - 2017-12-16 21:10:50.799291: step 104320, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 13h:36m:52s remains)
INFO - root - 2017-12-16 21:10:53.032839: step 104330, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 13h:47m:09s remains)
INFO - root - 2017-12-16 21:10:55.246966: step 104340, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 13h:37m:46s remains)
INFO - root - 2017-12-16 21:10:57.501709: step 104350, loss = 0.49, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 13h:50m:58s remains)
INFO - root - 2017-12-16 21:10:59.692612: step 104360, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 13h:30m:19s remains)
INFO - root - 2017-12-16 21:11:01.900707: step 104370, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 13h:34m:21s remains)
INFO - root - 2017-12-16 21:11:04.155571: step 104380, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 14h:03m:41s remains)
INFO - root - 2017-12-16 21:11:06.377035: step 104390, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 13h:46m:24s remains)
INFO - root - 2017-12-16 21:11:08.604157: step 104400, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 13h:45m:10s remains)
INFO - root - 2017-12-16 21:11:10.951998: step 104410, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 14h:22m:27s remains)
INFO - root - 2017-12-16 21:11:13.158161: step 104420, loss = 0.49, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 13h:34m:04s remains)
INFO - root - 2017-12-16 21:11:15.393151: step 104430, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.228 sec/batch; 14h:28m:07s remains)
INFO - root - 2017-12-16 21:11:17.583343: step 104440, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 14h:07m:07s remains)
INFO - root - 2017-12-16 21:11:19.800371: step 104450, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 14h:02m:13s remains)
INFO - root - 2017-12-16 21:11:22.013276: step 104460, loss = 0.44, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 14h:00m:55s remains)
INFO - root - 2017-12-16 21:11:24.191751: step 104470, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 13h:57m:51s remains)
INFO - root - 2017-12-16 21:11:26.413338: step 104480, loss = 0.51, batch loss = 0.33 (37.5 examples/sec; 0.213 sec/batch; 13h:29m:41s remains)
INFO - root - 2017-12-16 21:11:28.630000: step 104490, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 13h:37m:13s remains)
INFO - root - 2017-12-16 21:11:30.832439: step 104500, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 13h:42m:21s remains)
INFO - root - 2017-12-16 21:11:33.166446: step 104510, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 13h:41m:08s remains)
INFO - root - 2017-12-16 21:11:35.371695: step 104520, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 14h:06m:06s remains)
INFO - root - 2017-12-16 21:11:37.599421: step 104530, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.233 sec/batch; 14h:44m:13s remains)
INFO - root - 2017-12-16 21:11:39.788179: step 104540, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 14h:03m:32s remains)
INFO - root - 2017-12-16 21:11:41.977601: step 104550, loss = 0.53, batch loss = 0.36 (37.1 examples/sec; 0.216 sec/batch; 13h:39m:46s remains)
INFO - root - 2017-12-16 21:11:44.148999: step 104560, loss = 0.45, batch loss = 0.27 (38.1 examples/sec; 0.210 sec/batch; 13h:18m:10s remains)
INFO - root - 2017-12-16 21:11:46.396513: step 104570, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 14h:19m:20s remains)
INFO - root - 2017-12-16 21:11:48.623963: step 104580, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 14h:21m:58s remains)
INFO - root - 2017-12-16 21:11:50.857664: step 104590, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 13h:59m:10s remains)
INFO - root - 2017-12-16 21:11:53.096523: step 104600, loss = 0.45, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 13h:57m:02s remains)
INFO - root - 2017-12-16 21:11:55.448735: step 104610, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 14h:01m:10s remains)
INFO - root - 2017-12-16 21:11:57.658335: step 104620, loss = 0.44, batch loss = 0.26 (34.7 examples/sec; 0.231 sec/batch; 14h:36m:22s remains)
INFO - root - 2017-12-16 21:11:59.855782: step 104630, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 14h:16m:38s remains)
INFO - root - 2017-12-16 21:12:02.069340: step 104640, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:07m:12s remains)
INFO - root - 2017-12-16 21:12:04.287286: step 104650, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 13h:56m:38s remains)
INFO - root - 2017-12-16 21:12:06.454428: step 104660, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.218 sec/batch; 13h:49m:25s remains)
INFO - root - 2017-12-16 21:12:08.706850: step 104670, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 14h:08m:51s remains)
INFO - root - 2017-12-16 21:12:10.955676: step 104680, loss = 0.53, batch loss = 0.35 (35.4 examples/sec; 0.226 sec/batch; 14h:17m:23s remains)
INFO - root - 2017-12-16 21:12:13.157175: step 104690, loss = 0.57, batch loss = 0.39 (36.3 examples/sec; 0.220 sec/batch; 13h:56m:13s remains)
INFO - root - 2017-12-16 21:12:15.390469: step 104700, loss = 0.42, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 13h:58m:14s remains)
INFO - root - 2017-12-16 21:12:17.737459: step 104710, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 14h:11m:04s remains)
INFO - root - 2017-12-16 21:12:19.949066: step 104720, loss = 0.46, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 14h:44m:17s remains)
INFO - root - 2017-12-16 21:12:22.194204: step 104730, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 13h:57m:17s remains)
INFO - root - 2017-12-16 21:12:24.403640: step 104740, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 13h:55m:08s remains)
INFO - root - 2017-12-16 21:12:26.617218: step 104750, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 14h:12m:40s remains)
INFO - root - 2017-12-16 21:12:28.831019: step 104760, loss = 0.50, batch loss = 0.33 (36.6 examples/sec; 0.218 sec/batch; 13h:49m:09s remains)
INFO - root - 2017-12-16 21:12:31.009513: step 104770, loss = 0.50, batch loss = 0.33 (37.6 examples/sec; 0.213 sec/batch; 13h:26m:41s remains)
INFO - root - 2017-12-16 21:12:33.200804: step 104780, loss = 0.44, batch loss = 0.26 (34.7 examples/sec; 0.231 sec/batch; 14h:35m:04s remains)
INFO - root - 2017-12-16 21:12:35.372330: step 104790, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 14h:08m:39s remains)
INFO - root - 2017-12-16 21:12:37.581554: step 104800, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 13h:56m:43s remains)
INFO - root - 2017-12-16 21:12:39.930131: step 104810, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 13h:33m:45s remains)
INFO - root - 2017-12-16 21:12:42.125794: step 104820, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.218 sec/batch; 13h:45m:24s remains)
INFO - root - 2017-12-16 21:12:44.330533: step 104830, loss = 0.42, batch loss = 0.24 (36.9 examples/sec; 0.217 sec/batch; 13h:42m:11s remains)
INFO - root - 2017-12-16 21:12:46.532031: step 104840, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 13h:54m:23s remains)
INFO - root - 2017-12-16 21:12:48.742268: step 104850, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 14h:16m:57s remains)
INFO - root - 2017-12-16 21:12:50.915449: step 104860, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 13h:36m:35s remains)
INFO - root - 2017-12-16 21:12:53.115640: step 104870, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 14h:13m:45s remains)
INFO - root - 2017-12-16 21:12:55.322835: step 104880, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 13h:57m:18s remains)
INFO - root - 2017-12-16 21:12:57.545261: step 104890, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 13h:41m:46s remains)
INFO - root - 2017-12-16 21:12:59.793074: step 104900, loss = 0.47, batch loss = 0.29 (34.1 examples/sec; 0.235 sec/batch; 14h:50m:55s remains)
INFO - root - 2017-12-16 21:13:02.141316: step 104910, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 13h:49m:26s remains)
INFO - root - 2017-12-16 21:13:04.371122: step 104920, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 14h:12m:14s remains)
INFO - root - 2017-12-16 21:13:06.602289: step 104930, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 14h:06m:07s remains)
INFO - root - 2017-12-16 21:13:08.816219: step 104940, loss = 0.42, batch loss = 0.25 (34.1 examples/sec; 0.234 sec/batch; 14h:48m:37s remains)
INFO - root - 2017-12-16 21:13:11.054118: step 104950, loss = 0.41, batch loss = 0.23 (35.8 examples/sec; 0.223 sec/batch; 14h:06m:58s remains)
INFO - root - 2017-12-16 21:13:13.252893: step 104960, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 14h:21m:50s remains)
INFO - root - 2017-12-16 21:13:15.454781: step 104970, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 13h:50m:10s remains)
INFO - root - 2017-12-16 21:13:17.673744: step 104980, loss = 0.51, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 14h:21m:34s remains)
INFO - root - 2017-12-16 21:13:19.891335: step 104990, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 13h:41m:02s remains)
INFO - root - 2017-12-16 21:13:22.106773: step 105000, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 13h:51m:23s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-105000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-105000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 21:13:24.917949: step 105010, loss = 0.51, batch loss = 0.33 (37.9 examples/sec; 0.211 sec/batch; 13h:19m:46s remains)
INFO - root - 2017-12-16 21:13:27.118801: step 105020, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 14h:05m:41s remains)
INFO - root - 2017-12-16 21:13:29.301393: step 105030, loss = 0.55, batch loss = 0.37 (36.0 examples/sec; 0.222 sec/batch; 14h:02m:56s remains)
INFO - root - 2017-12-16 21:13:31.488652: step 105040, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 13h:38m:40s remains)
INFO - root - 2017-12-16 21:13:33.727041: step 105050, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 13h:58m:40s remains)
INFO - root - 2017-12-16 21:13:35.922984: step 105060, loss = 0.47, batch loss = 0.29 (33.4 examples/sec; 0.239 sec/batch; 15h:07m:33s remains)
INFO - root - 2017-12-16 21:13:38.150342: step 105070, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 14h:06m:54s remains)
INFO - root - 2017-12-16 21:13:40.345766: step 105080, loss = 0.54, batch loss = 0.36 (37.4 examples/sec; 0.214 sec/batch; 13h:30m:53s remains)
INFO - root - 2017-12-16 21:13:42.539978: step 105090, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 13h:52m:16s remains)
INFO - root - 2017-12-16 21:13:44.701661: step 105100, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 13h:41m:22s remains)
INFO - root - 2017-12-16 21:13:47.038209: step 105110, loss = 0.48, batch loss = 0.30 (34.3 examples/sec; 0.233 sec/batch; 14h:43m:35s remains)
INFO - root - 2017-12-16 21:13:49.260439: step 105120, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 13h:42m:10s remains)
INFO - root - 2017-12-16 21:13:51.472470: step 105130, loss = 0.45, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 13h:48m:18s remains)
INFO - root - 2017-12-16 21:13:53.656481: step 105140, loss = 0.53, batch loss = 0.35 (35.8 examples/sec; 0.224 sec/batch; 14h:06m:58s remains)
INFO - root - 2017-12-16 21:13:55.859975: step 105150, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 13h:59m:57s remains)
INFO - root - 2017-12-16 21:13:58.078457: step 105160, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 13h:39m:21s remains)
INFO - root - 2017-12-16 21:14:00.287779: step 105170, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 13h:44m:27s remains)
INFO - root - 2017-12-16 21:14:02.509312: step 105180, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 13h:45m:32s remains)
INFO - root - 2017-12-16 21:14:04.760608: step 105190, loss = 0.44, batch loss = 0.26 (33.9 examples/sec; 0.236 sec/batch; 14h:54m:13s remains)
INFO - root - 2017-12-16 21:14:06.973643: step 105200, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 14h:08m:50s remains)
INFO - root - 2017-12-16 21:14:09.297440: step 105210, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 13h:59m:36s remains)
INFO - root - 2017-12-16 21:14:11.546403: step 105220, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 13h:55m:59s remains)
INFO - root - 2017-12-16 21:14:13.786353: step 105230, loss = 0.50, batch loss = 0.32 (34.3 examples/sec; 0.233 sec/batch; 14h:43m:07s remains)
INFO - root - 2017-12-16 21:14:16.010800: step 105240, loss = 0.45, batch loss = 0.27 (33.7 examples/sec; 0.237 sec/batch; 14h:58m:49s remains)
INFO - root - 2017-12-16 21:14:18.228012: step 105250, loss = 0.44, batch loss = 0.26 (34.1 examples/sec; 0.234 sec/batch; 14h:47m:19s remains)
INFO - root - 2017-12-16 21:14:20.461920: step 105260, loss = 0.45, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 14h:10m:34s remains)
INFO - root - 2017-12-16 21:14:22.726980: step 105270, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 13h:38m:28s remains)
INFO - root - 2017-12-16 21:14:24.939506: step 105280, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 13h:56m:46s remains)
INFO - root - 2017-12-16 21:14:27.184092: step 105290, loss = 0.46, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 14h:03m:32s remains)
INFO - root - 2017-12-16 21:14:29.416628: step 105300, loss = 0.49, batch loss = 0.31 (34.7 examples/sec; 0.230 sec/batch; 14h:31m:48s remains)
INFO - root - 2017-12-16 21:14:31.721726: step 105310, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 14h:01m:23s remains)
INFO - root - 2017-12-16 21:14:33.938367: step 105320, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 14h:11m:30s remains)
INFO - root - 2017-12-16 21:14:36.147074: step 105330, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 13h:43m:36s remains)
INFO - root - 2017-12-16 21:14:38.362435: step 105340, loss = 0.42, batch loss = 0.24 (35.8 examples/sec; 0.224 sec/batch; 14h:06m:27s remains)
INFO - root - 2017-12-16 21:14:40.592793: step 105350, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 13h:40m:33s remains)
INFO - root - 2017-12-16 21:14:42.785936: step 105360, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 14h:06m:36s remains)
INFO - root - 2017-12-16 21:14:44.981201: step 105370, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 14h:10m:39s remains)
INFO - root - 2017-12-16 21:14:47.168191: step 105380, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 13h:53m:25s remains)
INFO - root - 2017-12-16 21:14:49.366024: step 105390, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 14h:06m:15s remains)
INFO - root - 2017-12-16 21:14:51.590217: step 105400, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 13h:37m:57s remains)
INFO - root - 2017-12-16 21:14:53.970917: step 105410, loss = 0.49, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 14h:22m:18s remains)
INFO - root - 2017-12-16 21:14:56.208512: step 105420, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 13h:51m:08s remains)
INFO - root - 2017-12-16 21:14:58.396021: step 105430, loss = 0.44, batch loss = 0.26 (37.5 examples/sec; 0.213 sec/batch; 13h:26m:23s remains)
INFO - root - 2017-12-16 21:15:00.601908: step 105440, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 14h:31m:09s remains)
INFO - root - 2017-12-16 21:15:02.834606: step 105450, loss = 0.48, batch loss = 0.30 (34.2 examples/sec; 0.234 sec/batch; 14h:44m:36s remains)
INFO - root - 2017-12-16 21:15:05.073714: step 105460, loss = 0.51, batch loss = 0.33 (34.6 examples/sec; 0.231 sec/batch; 14h:33m:42s remains)
INFO - root - 2017-12-16 21:15:07.319108: step 105470, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 14h:25m:35s remains)
INFO - root - 2017-12-16 21:15:09.609142: step 105480, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 13h:55m:05s remains)
INFO - root - 2017-12-16 21:15:11.815569: step 105490, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 13h:54m:08s remains)
INFO - root - 2017-12-16 21:15:14.026761: step 105500, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 14h:02m:24s remains)
INFO - root - 2017-12-16 21:15:16.365994: step 105510, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 13h:43m:53s remains)
INFO - root - 2017-12-16 21:15:18.559891: step 105520, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 14h:08m:21s remains)
INFO - root - 2017-12-16 21:15:20.763293: step 105530, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 14h:07m:24s remains)
INFO - root - 2017-12-16 21:15:22.961254: step 105540, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 13h:39m:00s remains)
INFO - root - 2017-12-16 21:15:25.179273: step 105550, loss = 0.48, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 14h:11m:38s remains)
INFO - root - 2017-12-16 21:15:27.440620: step 105560, loss = 0.46, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 13h:41m:30s remains)
INFO - root - 2017-12-16 21:15:29.619565: step 105570, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 14h:07m:18s remains)
INFO - root - 2017-12-16 21:15:31.872137: step 105580, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 14h:20m:51s remains)
INFO - root - 2017-12-16 21:15:34.107042: step 105590, loss = 0.53, batch loss = 0.35 (35.8 examples/sec; 0.224 sec/batch; 14h:05m:53s remains)
INFO - root - 2017-12-16 21:15:36.321112: step 105600, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 14h:03m:36s remains)
INFO - root - 2017-12-16 21:15:38.694872: step 105610, loss = 0.49, batch loss = 0.31 (34.5 examples/sec; 0.232 sec/batch; 14h:37m:44s remains)
INFO - root - 2017-12-16 21:15:40.921019: step 105620, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 14h:07m:40s remains)
INFO - root - 2017-12-16 21:15:43.144696: step 105630, loss = 0.53, batch loss = 0.35 (35.5 examples/sec; 0.225 sec/batch; 14h:11m:29s remains)
INFO - root - 2017-12-16 21:15:45.404926: step 105640, loss = 0.42, batch loss = 0.24 (35.1 examples/sec; 0.228 sec/batch; 14h:22m:26s remains)
INFO - root - 2017-12-16 21:15:47.617154: step 105650, loss = 0.43, batch loss = 0.25 (33.2 examples/sec; 0.241 sec/batch; 15h:10m:10s remains)
INFO - root - 2017-12-16 21:15:49.821285: step 105660, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 14h:06m:03s remains)
INFO - root - 2017-12-16 21:15:52.008318: step 105670, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 14h:03m:25s remains)
INFO - root - 2017-12-16 21:15:54.232844: step 105680, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 13h:43m:46s remains)
INFO - root - 2017-12-16 21:15:56.424297: step 105690, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 14h:25m:08s remains)
INFO - root - 2017-12-16 21:15:58.644956: step 105700, loss = 0.50, batch loss = 0.32 (34.6 examples/sec; 0.231 sec/batch; 14h:32m:54s remains)
INFO - root - 2017-12-16 21:16:01.047220: step 105710, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 14h:13m:23s remains)
INFO - root - 2017-12-16 21:16:03.248844: step 105720, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 13h:40m:06s remains)
INFO - root - 2017-12-16 21:16:05.476327: step 105730, loss = 0.55, batch loss = 0.37 (35.8 examples/sec; 0.224 sec/batch; 14h:05m:28s remains)
INFO - root - 2017-12-16 21:16:07.699630: step 105740, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 13h:53m:12s remains)
INFO - root - 2017-12-16 21:16:09.893215: step 105750, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 13h:21m:26s remains)
INFO - root - 2017-12-16 21:16:12.105565: step 105760, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 14h:10m:27s remains)
INFO - root - 2017-12-16 21:16:14.308597: step 105770, loss = 0.54, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 14h:03m:07s remains)
INFO - root - 2017-12-16 21:16:16.508366: step 105780, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 13h:56m:02s remains)
INFO - root - 2017-12-16 21:16:18.713840: step 105790, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 13h:39m:03s remains)
INFO - root - 2017-12-16 21:16:20.916516: step 105800, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 13h:29m:14s remains)
INFO - root - 2017-12-16 21:16:23.313286: step 105810, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 13h:56m:15s remains)
INFO - root - 2017-12-16 21:16:25.496037: step 105820, loss = 0.49, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 13h:32m:50s remains)
INFO - root - 2017-12-16 21:16:27.678921: step 105830, loss = 0.41, batch loss = 0.24 (36.3 examples/sec; 0.220 sec/batch; 13h:51m:45s remains)
INFO - root - 2017-12-16 21:16:29.893106: step 105840, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 13h:35m:30s remains)
INFO - root - 2017-12-16 21:16:32.097844: step 105850, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 13h:39m:39s remains)
INFO - root - 2017-12-16 21:16:34.295671: step 105860, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 13h:40m:21s remains)
INFO - root - 2017-12-16 21:16:36.578861: step 105870, loss = 0.52, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 14h:19m:46s remains)
INFO - root - 2017-12-16 21:16:38.789976: step 105880, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 13h:55m:30s remains)
INFO - root - 2017-12-16 21:16:41.013487: step 105890, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.230 sec/batch; 14h:30m:00s remains)
INFO - root - 2017-12-16 21:16:43.201774: step 105900, loss = 0.51, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 13h:42m:35s remains)
INFO - root - 2017-12-16 21:16:45.541660: step 105910, loss = 0.48, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 14h:03m:35s remains)
INFO - root - 2017-12-16 21:16:47.795442: step 105920, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 14h:04m:53s remains)
INFO - root - 2017-12-16 21:16:50.002224: step 105930, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 13h:42m:02s remains)
INFO - root - 2017-12-16 21:16:52.224412: step 105940, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.226 sec/batch; 14h:11m:33s remains)
INFO - root - 2017-12-16 21:16:54.393666: step 105950, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 13h:21m:31s remains)
INFO - root - 2017-12-16 21:16:56.572180: step 105960, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 13h:36m:47s remains)
INFO - root - 2017-12-16 21:16:58.784563: step 105970, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 13h:35m:24s remains)
INFO - root - 2017-12-16 21:17:01.001147: step 105980, loss = 0.49, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 14h:09m:07s remains)
INFO - root - 2017-12-16 21:17:03.197735: step 105990, loss = 0.53, batch loss = 0.35 (35.8 examples/sec; 0.223 sec/batch; 14h:02m:43s remains)
INFO - root - 2017-12-16 21:17:05.440733: step 106000, loss = 0.51, batch loss = 0.33 (34.4 examples/sec; 0.233 sec/batch; 14h:37m:48s remains)
INFO - root - 2017-12-16 21:17:07.771886: step 106010, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 13h:54m:49s remains)
INFO - root - 2017-12-16 21:17:09.963528: step 106020, loss = 0.53, batch loss = 0.35 (35.5 examples/sec; 0.226 sec/batch; 14h:11m:42s remains)
INFO - root - 2017-12-16 21:17:12.180112: step 106030, loss = 0.51, batch loss = 0.33 (35.1 examples/sec; 0.228 sec/batch; 14h:20m:49s remains)
INFO - root - 2017-12-16 21:17:14.404061: step 106040, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 14h:02m:08s remains)
INFO - root - 2017-12-16 21:17:16.623775: step 106050, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 13h:59m:14s remains)
INFO - root - 2017-12-16 21:17:18.846873: step 106060, loss = 0.53, batch loss = 0.36 (36.2 examples/sec; 0.221 sec/batch; 13h:52m:54s remains)
INFO - root - 2017-12-16 21:17:21.048101: step 106070, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 13h:36m:02s remains)
INFO - root - 2017-12-16 21:17:23.253382: step 106080, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 13h:36m:46s remains)
INFO - root - 2017-12-16 21:17:25.482262: step 106090, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.226 sec/batch; 14h:11m:16s remains)
INFO - root - 2017-12-16 21:17:27.687906: step 106100, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 14h:01m:03s remains)
INFO - root - 2017-12-16 21:17:30.004934: step 106110, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 13h:39m:07s remains)
INFO - root - 2017-12-16 21:17:32.220800: step 106120, loss = 0.41, batch loss = 0.23 (35.3 examples/sec; 0.226 sec/batch; 14h:14m:03s remains)
INFO - root - 2017-12-16 21:17:34.466827: step 106130, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 13h:58m:43s remains)
INFO - root - 2017-12-16 21:17:36.671920: step 106140, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 14h:14m:25s remains)
INFO - root - 2017-12-16 21:17:38.909387: step 106150, loss = 0.47, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 13h:37m:05s remains)
INFO - root - 2017-12-16 21:17:41.139711: step 106160, loss = 0.54, batch loss = 0.36 (37.3 examples/sec; 0.214 sec/batch; 13h:28m:35s remains)
INFO - root - 2017-12-16 21:17:43.350891: step 106170, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 13h:43m:13s remains)
INFO - root - 2017-12-16 21:17:45.552807: step 106180, loss = 0.46, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 13h:54m:25s remains)
INFO - root - 2017-12-16 21:17:47.743617: step 106190, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 13h:58m:31s remains)
INFO - root - 2017-12-16 21:17:49.963080: step 106200, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 13h:40m:24s remains)
INFO - root - 2017-12-16 21:17:52.329486: step 106210, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 13h:34m:33s remains)
INFO - root - 2017-12-16 21:17:54.556134: step 106220, loss = 0.47, batch loss = 0.29 (34.6 examples/sec; 0.231 sec/batch; 14h:32m:07s remains)
INFO - root - 2017-12-16 21:17:56.758892: step 106230, loss = 0.53, batch loss = 0.35 (37.1 examples/sec; 0.216 sec/batch; 13h:33m:02s remains)
INFO - root - 2017-12-16 21:17:58.961155: step 106240, loss = 0.54, batch loss = 0.36 (34.8 examples/sec; 0.230 sec/batch; 14h:26m:48s remains)
INFO - root - 2017-12-16 21:18:01.200897: step 106250, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 14h:02m:13s remains)
INFO - root - 2017-12-16 21:18:03.429731: step 106260, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 13h:59m:38s remains)
INFO - root - 2017-12-16 21:18:05.680576: step 106270, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 14h:19m:46s remains)
INFO - root - 2017-12-16 21:18:07.893364: step 106280, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 13h:59m:47s remains)
INFO - root - 2017-12-16 21:18:10.151626: step 106290, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 13h:47m:33s remains)
INFO - root - 2017-12-16 21:18:12.402813: step 106300, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 13h:48m:47s remains)
INFO - root - 2017-12-16 21:18:14.775004: step 106310, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 13h:43m:55s remains)
INFO - root - 2017-12-16 21:18:17.020033: step 106320, loss = 0.56, batch loss = 0.38 (33.8 examples/sec; 0.237 sec/batch; 14h:52m:47s remains)
INFO - root - 2017-12-16 21:18:19.243922: step 106330, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 13h:32m:13s remains)
INFO - root - 2017-12-16 21:18:21.483495: step 106340, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 14h:18m:51s remains)
INFO - root - 2017-12-16 21:18:23.720043: step 106350, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 13h:46m:32s remains)
INFO - root - 2017-12-16 21:18:25.920481: step 106360, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 13h:54m:38s remains)
INFO - root - 2017-12-16 21:18:28.146483: step 106370, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 13h:39m:01s remains)
INFO - root - 2017-12-16 21:18:30.337879: step 106380, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 13h:30m:32s remains)
INFO - root - 2017-12-16 21:18:32.528457: step 106390, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 13h:59m:33s remains)
INFO - root - 2017-12-16 21:18:34.703342: step 106400, loss = 0.52, batch loss = 0.34 (37.3 examples/sec; 0.215 sec/batch; 13h:28m:50s remains)
INFO - root - 2017-12-16 21:18:36.989503: step 106410, loss = 0.44, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 13h:19m:34s remains)
INFO - root - 2017-12-16 21:18:39.188744: step 106420, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 13h:51m:23s remains)
INFO - root - 2017-12-16 21:18:41.370094: step 106430, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 13h:28m:24s remains)
INFO - root - 2017-12-16 21:18:43.564104: step 106440, loss = 0.62, batch loss = 0.44 (35.8 examples/sec; 0.224 sec/batch; 14h:02m:26s remains)
INFO - root - 2017-12-16 21:18:45.792405: step 106450, loss = 0.53, batch loss = 0.35 (37.1 examples/sec; 0.216 sec/batch; 13h:33m:17s remains)
INFO - root - 2017-12-16 21:18:47.974245: step 106460, loss = 0.53, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 13h:49m:20s remains)
INFO - root - 2017-12-16 21:18:50.200979: step 106470, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 14h:17m:57s remains)
INFO - root - 2017-12-16 21:18:52.390643: step 106480, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 13h:52m:38s remains)
INFO - root - 2017-12-16 21:18:54.575863: step 106490, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 13h:30m:29s remains)
INFO - root - 2017-12-16 21:18:56.761469: step 106500, loss = 0.49, batch loss = 0.31 (34.5 examples/sec; 0.232 sec/batch; 14h:34m:12s remains)
INFO - root - 2017-12-16 21:18:59.114364: step 106510, loss = 0.56, batch loss = 0.38 (35.8 examples/sec; 0.224 sec/batch; 14h:02m:46s remains)
INFO - root - 2017-12-16 21:19:01.301182: step 106520, loss = 0.42, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 13h:40m:19s remains)
INFO - root - 2017-12-16 21:19:03.515570: step 106530, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 13h:45m:57s remains)
INFO - root - 2017-12-16 21:19:05.734712: step 106540, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 13h:16m:59s remains)
INFO - root - 2017-12-16 21:19:07.954076: step 106550, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 14h:03m:33s remains)
INFO - root - 2017-12-16 21:19:10.143339: step 106560, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 13h:23m:23s remains)
INFO - root - 2017-12-16 21:19:12.357011: step 106570, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 13h:41m:13s remains)
INFO - root - 2017-12-16 21:19:14.534937: step 106580, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 13h:43m:33s remains)
INFO - root - 2017-12-16 21:19:16.774708: step 106590, loss = 0.60, batch loss = 0.42 (36.6 examples/sec; 0.219 sec/batch; 13h:43m:24s remains)
INFO - root - 2017-12-16 21:19:18.959530: step 106600, loss = 0.48, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 13h:41m:02s remains)
INFO - root - 2017-12-16 21:19:21.296549: step 106610, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 13h:43m:49s remains)
INFO - root - 2017-12-16 21:19:23.468490: step 106620, loss = 0.51, batch loss = 0.33 (35.0 examples/sec; 0.229 sec/batch; 14h:21m:10s remains)
INFO - root - 2017-12-16 21:19:25.639463: step 106630, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 13h:45m:10s remains)
INFO - root - 2017-12-16 21:19:27.844750: step 106640, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 13h:51m:50s remains)
INFO - root - 2017-12-16 21:19:30.046586: step 106650, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 13h:38m:12s remains)
INFO - root - 2017-12-16 21:19:32.242990: step 106660, loss = 0.50, batch loss = 0.32 (37.8 examples/sec; 0.212 sec/batch; 13h:17m:35s remains)
INFO - root - 2017-12-16 21:19:34.457506: step 106670, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 13h:41m:27s remains)
INFO - root - 2017-12-16 21:19:36.678104: step 106680, loss = 0.50, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 13h:52m:20s remains)
INFO - root - 2017-12-16 21:19:38.880940: step 106690, loss = 0.46, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 14h:00m:26s remains)
INFO - root - 2017-12-16 21:19:41.107719: step 106700, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 14h:13m:54s remains)
INFO - root - 2017-12-16 21:19:43.474588: step 106710, loss = 0.58, batch loss = 0.40 (36.7 examples/sec; 0.218 sec/batch; 13h:41m:10s remains)
INFO - root - 2017-12-16 21:19:45.719880: step 106720, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 13h:46m:04s remains)
INFO - root - 2017-12-16 21:19:47.914675: step 106730, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 13h:29m:57s remains)
INFO - root - 2017-12-16 21:19:50.141309: step 106740, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 14h:13m:40s remains)
INFO - root - 2017-12-16 21:19:52.367475: step 106750, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 14h:09m:36s remains)
INFO - root - 2017-12-16 21:19:54.607934: step 106760, loss = 0.52, batch loss = 0.35 (35.0 examples/sec; 0.229 sec/batch; 14h:20m:11s remains)
INFO - root - 2017-12-16 21:19:56.822500: step 106770, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 13h:33m:26s remains)
INFO - root - 2017-12-16 21:19:59.017992: step 106780, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 13h:35m:57s remains)
INFO - root - 2017-12-16 21:20:01.208280: step 106790, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 14h:31m:48s remains)
INFO - root - 2017-12-16 21:20:03.414173: step 106800, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 13h:42m:51s remains)
INFO - root - 2017-12-16 21:20:05.744577: step 106810, loss = 0.45, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 14h:14m:06s remains)
INFO - root - 2017-12-16 21:20:07.991934: step 106820, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 13h:58m:38s remains)
INFO - root - 2017-12-16 21:20:10.199977: step 106830, loss = 0.59, batch loss = 0.41 (37.1 examples/sec; 0.216 sec/batch; 13h:31m:00s remains)
INFO - root - 2017-12-16 21:20:12.431291: step 106840, loss = 0.53, batch loss = 0.35 (35.4 examples/sec; 0.226 sec/batch; 14h:09m:32s remains)
INFO - root - 2017-12-16 21:20:14.675636: step 106850, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 13h:50m:17s remains)
INFO - root - 2017-12-16 21:20:16.910562: step 106860, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 13h:41m:43s remains)
INFO - root - 2017-12-16 21:20:19.132142: step 106870, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 13h:48m:31s remains)
INFO - root - 2017-12-16 21:20:21.383437: step 106880, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 13h:57m:28s remains)
INFO - root - 2017-12-16 21:20:23.578365: step 106890, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.219 sec/batch; 13h:45m:17s remains)
INFO - root - 2017-12-16 21:20:25.765766: step 106900, loss = 0.42, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 13h:28m:31s remains)
INFO - root - 2017-12-16 21:20:28.131610: step 106910, loss = 0.51, batch loss = 0.33 (34.9 examples/sec; 0.229 sec/batch; 14h:21m:21s remains)
INFO - root - 2017-12-16 21:20:30.390119: step 106920, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 13h:43m:13s remains)
INFO - root - 2017-12-16 21:20:32.625091: step 106930, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 14h:02m:27s remains)
INFO - root - 2017-12-16 21:20:34.821587: step 106940, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.216 sec/batch; 13h:31m:01s remains)
INFO - root - 2017-12-16 21:20:37.005062: step 106950, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 13h:33m:45s remains)
INFO - root - 2017-12-16 21:20:39.212326: step 106960, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 13h:34m:20s remains)
INFO - root - 2017-12-16 21:20:41.406857: step 106970, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 13h:55m:25s remains)
INFO - root - 2017-12-16 21:20:43.619391: step 106980, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 13h:47m:11s remains)
INFO - root - 2017-12-16 21:20:45.889589: step 106990, loss = 0.53, batch loss = 0.36 (33.9 examples/sec; 0.236 sec/batch; 14h:47m:52s remains)
INFO - root - 2017-12-16 21:20:48.126925: step 107000, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 14h:10m:01s remains)
INFO - root - 2017-12-16 21:20:50.511794: step 107010, loss = 0.46, batch loss = 0.28 (34.0 examples/sec; 0.235 sec/batch; 14h:43m:38s remains)
INFO - root - 2017-12-16 21:20:52.725183: step 107020, loss = 0.47, batch loss = 0.29 (33.4 examples/sec; 0.239 sec/batch; 14h:59m:52s remains)
INFO - root - 2017-12-16 21:20:54.976345: step 107030, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 14h:12m:27s remains)
INFO - root - 2017-12-16 21:20:57.195841: step 107040, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 13h:48m:27s remains)
INFO - root - 2017-12-16 21:20:59.415179: step 107050, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 13h:45m:00s remains)
INFO - root - 2017-12-16 21:21:01.625457: step 107060, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 13h:40m:46s remains)
INFO - root - 2017-12-16 21:21:03.848680: step 107070, loss = 0.42, batch loss = 0.24 (35.6 examples/sec; 0.225 sec/batch; 14h:04m:57s remains)
INFO - root - 2017-12-16 21:21:06.057982: step 107080, loss = 0.53, batch loss = 0.35 (35.8 examples/sec; 0.224 sec/batch; 14h:00m:31s remains)
INFO - root - 2017-12-16 21:21:08.284013: step 107090, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 13h:56m:51s remains)
INFO - root - 2017-12-16 21:21:10.474356: step 107100, loss = 0.45, batch loss = 0.28 (37.7 examples/sec; 0.212 sec/batch; 13h:17m:54s remains)
INFO - root - 2017-12-16 21:21:12.834850: step 107110, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 14h:20m:36s remains)
INFO - root - 2017-12-16 21:21:15.026323: step 107120, loss = 0.46, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 13h:32m:40s remains)
INFO - root - 2017-12-16 21:21:17.242224: step 107130, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 14h:16m:09s remains)
INFO - root - 2017-12-16 21:21:19.453544: step 107140, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 13h:57m:08s remains)
INFO - root - 2017-12-16 21:21:21.707011: step 107150, loss = 0.49, batch loss = 0.31 (34.2 examples/sec; 0.234 sec/batch; 14h:38m:02s remains)
INFO - root - 2017-12-16 21:21:23.973348: step 107160, loss = 0.55, batch loss = 0.37 (37.3 examples/sec; 0.215 sec/batch; 13h:26m:12s remains)
INFO - root - 2017-12-16 21:21:26.171367: step 107170, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 14h:03m:59s remains)
INFO - root - 2017-12-16 21:21:28.387986: step 107180, loss = 0.44, batch loss = 0.26 (34.2 examples/sec; 0.234 sec/batch; 14h:38m:26s remains)
INFO - root - 2017-12-16 21:21:30.646903: step 107190, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 13h:48m:13s remains)
INFO - root - 2017-12-16 21:21:32.847392: step 107200, loss = 0.47, batch loss = 0.30 (37.9 examples/sec; 0.211 sec/batch; 13h:13m:17s remains)
INFO - root - 2017-12-16 21:21:35.152552: step 107210, loss = 0.58, batch loss = 0.40 (36.0 examples/sec; 0.222 sec/batch; 13h:55m:22s remains)
INFO - root - 2017-12-16 21:21:37.383551: step 107220, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 13h:31m:21s remains)
INFO - root - 2017-12-16 21:21:39.622262: step 107230, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 13h:35m:58s remains)
INFO - root - 2017-12-16 21:21:41.831607: step 107240, loss = 0.46, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 13h:56m:41s remains)
INFO - root - 2017-12-16 21:21:44.023329: step 107250, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 13h:27m:37s remains)
INFO - root - 2017-12-16 21:21:46.219147: step 107260, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 13h:22m:19s remains)
INFO - root - 2017-12-16 21:21:48.401242: step 107270, loss = 0.54, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 13h:55m:40s remains)
INFO - root - 2017-12-16 21:21:50.631126: step 107280, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.223 sec/batch; 13h:55m:13s remains)
INFO - root - 2017-12-16 21:21:52.850981: step 107290, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 13h:43m:21s remains)
INFO - root - 2017-12-16 21:21:55.082115: step 107300, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.215 sec/batch; 13h:28m:38s remains)
INFO - root - 2017-12-16 21:21:57.432993: step 107310, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 13h:31m:38s remains)
INFO - root - 2017-12-16 21:21:59.670864: step 107320, loss = 0.46, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 13h:57m:25s remains)
INFO - root - 2017-12-16 21:22:01.881996: step 107330, loss = 0.46, batch loss = 0.29 (36.4 examples/sec; 0.219 sec/batch; 13h:43m:43s remains)
INFO - root - 2017-12-16 21:22:04.069310: step 107340, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 13h:55m:28s remains)
INFO - root - 2017-12-16 21:22:06.310641: step 107350, loss = 0.48, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 13h:49m:30s remains)
INFO - root - 2017-12-16 21:22:08.540491: step 107360, loss = 0.57, batch loss = 0.39 (35.8 examples/sec; 0.224 sec/batch; 13h:58m:39s remains)
INFO - root - 2017-12-16 21:22:10.762126: step 107370, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 13h:59m:22s remains)
INFO - root - 2017-12-16 21:22:12.992025: step 107380, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 13h:16m:53s remains)
INFO - root - 2017-12-16 21:22:15.202195: step 107390, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 13h:19m:50s remains)
INFO - root - 2017-12-16 21:22:17.430222: step 107400, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 13h:31m:24s remains)
INFO - root - 2017-12-16 21:22:19.730291: step 107410, loss = 0.53, batch loss = 0.35 (37.5 examples/sec; 0.213 sec/batch; 13h:20m:54s remains)
INFO - root - 2017-12-16 21:22:21.938166: step 107420, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 13h:20m:30s remains)
INFO - root - 2017-12-16 21:22:24.151033: step 107430, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 13h:27m:45s remains)
INFO - root - 2017-12-16 21:22:26.389039: step 107440, loss = 0.53, batch loss = 0.35 (35.3 examples/sec; 0.226 sec/batch; 14h:08m:54s remains)
INFO - root - 2017-12-16 21:22:28.622593: step 107450, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 13h:26m:05s remains)
INFO - root - 2017-12-16 21:22:30.841081: step 107460, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 13h:50m:21s remains)
INFO - root - 2017-12-16 21:22:33.060737: step 107470, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 13h:55m:32s remains)
INFO - root - 2017-12-16 21:22:35.249024: step 107480, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 13h:35m:41s remains)
INFO - root - 2017-12-16 21:22:37.454682: step 107490, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 13h:32m:27s remains)
INFO - root - 2017-12-16 21:22:39.693607: step 107500, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 13h:48m:58s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-107500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-107500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 21:22:42.496850: step 107510, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 13h:17m:32s remains)
INFO - root - 2017-12-16 21:22:44.713262: step 107520, loss = 0.45, batch loss = 0.27 (32.8 examples/sec; 0.244 sec/batch; 15h:14m:58s remains)
INFO - root - 2017-12-16 21:22:46.954416: step 107530, loss = 0.44, batch loss = 0.27 (34.8 examples/sec; 0.230 sec/batch; 14h:22m:52s remains)
INFO - root - 2017-12-16 21:22:49.183320: step 107540, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 14h:28m:51s remains)
INFO - root - 2017-12-16 21:22:51.391745: step 107550, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 13h:38m:58s remains)
INFO - root - 2017-12-16 21:22:53.566735: step 107560, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 14h:00m:31s remains)
INFO - root - 2017-12-16 21:22:55.763914: step 107570, loss = 0.43, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 13h:41m:45s remains)
INFO - root - 2017-12-16 21:22:58.001210: step 107580, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 13h:25m:40s remains)
INFO - root - 2017-12-16 21:23:00.225518: step 107590, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 14h:14m:02s remains)
INFO - root - 2017-12-16 21:23:02.448921: step 107600, loss = 0.44, batch loss = 0.26 (34.6 examples/sec; 0.231 sec/batch; 14h:25m:43s remains)
INFO - root - 2017-12-16 21:23:04.816037: step 107610, loss = 0.57, batch loss = 0.39 (36.6 examples/sec; 0.218 sec/batch; 13h:38m:10s remains)
INFO - root - 2017-12-16 21:23:07.033760: step 107620, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 13h:57m:41s remains)
INFO - root - 2017-12-16 21:23:09.310972: step 107630, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 13h:52m:13s remains)
INFO - root - 2017-12-16 21:23:11.547053: step 107640, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 14h:14m:03s remains)
INFO - root - 2017-12-16 21:23:13.748539: step 107650, loss = 0.53, batch loss = 0.35 (37.8 examples/sec; 0.212 sec/batch; 13h:13m:49s remains)
INFO - root - 2017-12-16 21:23:15.978812: step 107660, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 14h:06m:06s remains)
INFO - root - 2017-12-16 21:23:18.215436: step 107670, loss = 0.46, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 14h:32m:46s remains)
INFO - root - 2017-12-16 21:23:20.464447: step 107680, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 14h:06m:43s remains)
INFO - root - 2017-12-16 21:23:22.673864: step 107690, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.223 sec/batch; 13h:53m:46s remains)
INFO - root - 2017-12-16 21:23:24.916137: step 107700, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 13h:15m:17s remains)
INFO - root - 2017-12-16 21:23:27.269602: step 107710, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 13h:51m:12s remains)
INFO - root - 2017-12-16 21:23:29.516367: step 107720, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 14h:02m:58s remains)
INFO - root - 2017-12-16 21:23:31.729186: step 107730, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 13h:33m:57s remains)
INFO - root - 2017-12-16 21:23:33.942778: step 107740, loss = 0.52, batch loss = 0.35 (35.1 examples/sec; 0.228 sec/batch; 14h:14m:56s remains)
INFO - root - 2017-12-16 21:23:36.201253: step 107750, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 13h:44m:22s remains)
INFO - root - 2017-12-16 21:23:38.426602: step 107760, loss = 0.52, batch loss = 0.34 (34.9 examples/sec; 0.229 sec/batch; 14h:19m:00s remains)
INFO - root - 2017-12-16 21:23:40.673245: step 107770, loss = 0.54, batch loss = 0.36 (34.9 examples/sec; 0.229 sec/batch; 14h:18m:05s remains)
INFO - root - 2017-12-16 21:23:42.875045: step 107780, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 13h:54m:11s remains)
INFO - root - 2017-12-16 21:23:45.105128: step 107790, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 13h:45m:28s remains)
INFO - root - 2017-12-16 21:23:47.321792: step 107800, loss = 0.54, batch loss = 0.36 (36.1 examples/sec; 0.221 sec/batch; 13h:48m:51s remains)
INFO - root - 2017-12-16 21:23:49.660307: step 107810, loss = 0.64, batch loss = 0.46 (37.1 examples/sec; 0.216 sec/batch; 13h:27m:28s remains)
INFO - root - 2017-12-16 21:23:51.869766: step 107820, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 13h:54m:09s remains)
INFO - root - 2017-12-16 21:23:54.098214: step 107830, loss = 0.55, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 13h:43m:13s remains)
INFO - root - 2017-12-16 21:23:56.291844: step 107840, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 13h:23m:06s remains)
INFO - root - 2017-12-16 21:23:58.486303: step 107850, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 13h:53m:20s remains)
INFO - root - 2017-12-16 21:24:00.743666: step 107860, loss = 0.55, batch loss = 0.37 (34.2 examples/sec; 0.234 sec/batch; 14h:35m:12s remains)
INFO - root - 2017-12-16 21:24:02.969171: step 107870, loss = 0.43, batch loss = 0.26 (34.6 examples/sec; 0.231 sec/batch; 14h:25m:43s remains)
INFO - root - 2017-12-16 21:24:05.179252: step 107880, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 14h:08m:25s remains)
INFO - root - 2017-12-16 21:24:07.383452: step 107890, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 13h:42m:45s remains)
INFO - root - 2017-12-16 21:24:09.627334: step 107900, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 14h:12m:52s remains)
INFO - root - 2017-12-16 21:24:11.986444: step 107910, loss = 0.50, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 14h:20m:19s remains)
INFO - root - 2017-12-16 21:24:14.217375: step 107920, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 14h:16m:08s remains)
INFO - root - 2017-12-16 21:24:16.436071: step 107930, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 13h:29m:40s remains)
INFO - root - 2017-12-16 21:24:18.662256: step 107940, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 13h:31m:00s remains)
INFO - root - 2017-12-16 21:24:20.917639: step 107950, loss = 0.45, batch loss = 0.27 (33.1 examples/sec; 0.242 sec/batch; 15h:05m:07s remains)
INFO - root - 2017-12-16 21:24:23.125848: step 107960, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 13h:50m:13s remains)
INFO - root - 2017-12-16 21:24:25.371610: step 107970, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 13h:54m:51s remains)
INFO - root - 2017-12-16 21:24:27.606876: step 107980, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 13h:48m:17s remains)
INFO - root - 2017-12-16 21:24:29.812057: step 107990, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 13h:41m:55s remains)
INFO - root - 2017-12-16 21:24:32.060037: step 108000, loss = 0.50, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 13h:31m:02s remains)
INFO - root - 2017-12-16 21:24:34.430723: step 108010, loss = 0.54, batch loss = 0.36 (34.3 examples/sec; 0.233 sec/batch; 14h:33m:18s remains)
INFO - root - 2017-12-16 21:24:36.658762: step 108020, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 14h:06m:24s remains)
INFO - root - 2017-12-16 21:24:38.916230: step 108030, loss = 0.53, batch loss = 0.36 (35.6 examples/sec; 0.225 sec/batch; 13h:59m:58s remains)
INFO - root - 2017-12-16 21:24:41.135890: step 108040, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 13h:28m:26s remains)
INFO - root - 2017-12-16 21:24:43.381949: step 108050, loss = 0.50, batch loss = 0.33 (36.6 examples/sec; 0.218 sec/batch; 13h:36m:45s remains)
INFO - root - 2017-12-16 21:24:45.591362: step 108060, loss = 0.56, batch loss = 0.38 (34.4 examples/sec; 0.232 sec/batch; 14h:29m:08s remains)
INFO - root - 2017-12-16 21:24:47.823363: step 108070, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 13h:12m:49s remains)
INFO - root - 2017-12-16 21:24:50.046608: step 108080, loss = 0.43, batch loss = 0.25 (35.2 examples/sec; 0.227 sec/batch; 14h:10m:22s remains)
INFO - root - 2017-12-16 21:24:52.284585: step 108090, loss = 0.54, batch loss = 0.37 (33.2 examples/sec; 0.241 sec/batch; 15h:00m:34s remains)
INFO - root - 2017-12-16 21:24:54.524260: step 108100, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 13h:45m:05s remains)
INFO - root - 2017-12-16 21:24:56.898608: step 108110, loss = 0.45, batch loss = 0.27 (33.7 examples/sec; 0.237 sec/batch; 14h:48m:08s remains)
INFO - root - 2017-12-16 21:24:59.156245: step 108120, loss = 0.46, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 13h:34m:20s remains)
INFO - root - 2017-12-16 21:25:01.339005: step 108130, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 13h:33m:30s remains)
INFO - root - 2017-12-16 21:25:03.547165: step 108140, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 13h:46m:25s remains)
INFO - root - 2017-12-16 21:25:05.785707: step 108150, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 14h:04m:56s remains)
INFO - root - 2017-12-16 21:25:08.033459: step 108160, loss = 0.50, batch loss = 0.33 (33.9 examples/sec; 0.236 sec/batch; 14h:42m:46s remains)
INFO - root - 2017-12-16 21:25:10.268264: step 108170, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 13h:47m:00s remains)
INFO - root - 2017-12-16 21:25:12.490618: step 108180, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 13h:32m:17s remains)
INFO - root - 2017-12-16 21:25:14.668478: step 108190, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 14h:03m:13s remains)
INFO - root - 2017-12-16 21:25:16.935851: step 108200, loss = 0.44, batch loss = 0.26 (32.9 examples/sec; 0.243 sec/batch; 15h:08m:22s remains)
INFO - root - 2017-12-16 21:25:19.258489: step 108210, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 13h:50m:11s remains)
INFO - root - 2017-12-16 21:25:21.517583: step 108220, loss = 0.53, batch loss = 0.35 (37.1 examples/sec; 0.216 sec/batch; 13h:26m:19s remains)
INFO - root - 2017-12-16 21:25:23.768591: step 108230, loss = 0.47, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 13h:52m:33s remains)
INFO - root - 2017-12-16 21:25:26.015293: step 108240, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 14h:27m:22s remains)
INFO - root - 2017-12-16 21:25:28.255791: step 108250, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 13h:28m:59s remains)
INFO - root - 2017-12-16 21:25:30.495466: step 108260, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 14h:06m:49s remains)
INFO - root - 2017-12-16 21:25:32.698897: step 108270, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 14h:00m:16s remains)
INFO - root - 2017-12-16 21:25:34.939952: step 108280, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 13h:27m:45s remains)
INFO - root - 2017-12-16 21:25:37.191931: step 108290, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 13h:22m:15s remains)
INFO - root - 2017-12-16 21:25:39.439508: step 108300, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 13h:57m:04s remains)
INFO - root - 2017-12-16 21:25:41.788239: step 108310, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 13h:56m:18s remains)
INFO - root - 2017-12-16 21:25:44.055905: step 108320, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 14h:04m:34s remains)
INFO - root - 2017-12-16 21:25:46.284206: step 108330, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 13h:35m:23s remains)
INFO - root - 2017-12-16 21:25:48.475642: step 108340, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 13h:15m:26s remains)
INFO - root - 2017-12-16 21:25:50.712922: step 108350, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 13h:24m:02s remains)
INFO - root - 2017-12-16 21:25:52.907001: step 108360, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 13h:35m:15s remains)
INFO - root - 2017-12-16 21:25:55.134522: step 108370, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 13h:39m:15s remains)
INFO - root - 2017-12-16 21:25:57.350526: step 108380, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.221 sec/batch; 13h:44m:06s remains)
INFO - root - 2017-12-16 21:25:59.567080: step 108390, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 13h:25m:46s remains)
INFO - root - 2017-12-16 21:26:01.807842: step 108400, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 13h:58m:00s remains)
INFO - root - 2017-12-16 21:26:04.177983: step 108410, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 13h:36m:56s remains)
INFO - root - 2017-12-16 21:26:06.403973: step 108420, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 13h:45m:20s remains)
INFO - root - 2017-12-16 21:26:08.633484: step 108430, loss = 0.42, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 13h:57m:45s remains)
INFO - root - 2017-12-16 21:26:10.846592: step 108440, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 13h:39m:57s remains)
INFO - root - 2017-12-16 21:26:13.082226: step 108450, loss = 0.63, batch loss = 0.45 (36.3 examples/sec; 0.220 sec/batch; 13h:42m:23s remains)
INFO - root - 2017-12-16 21:26:15.326139: step 108460, loss = 0.54, batch loss = 0.36 (35.5 examples/sec; 0.225 sec/batch; 14h:00m:53s remains)
INFO - root - 2017-12-16 21:26:17.548922: step 108470, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 13h:45m:55s remains)
INFO - root - 2017-12-16 21:26:19.736720: step 108480, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 14h:05m:02s remains)
INFO - root - 2017-12-16 21:26:21.969432: step 108490, loss = 0.52, batch loss = 0.34 (33.8 examples/sec; 0.236 sec/batch; 14h:42m:40s remains)
INFO - root - 2017-12-16 21:26:24.209199: step 108500, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 13h:23m:53s remains)
INFO - root - 2017-12-16 21:26:26.553121: step 108510, loss = 0.49, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 13h:46m:10s remains)
INFO - root - 2017-12-16 21:26:28.774564: step 108520, loss = 0.59, batch loss = 0.41 (35.0 examples/sec; 0.229 sec/batch; 14h:13m:04s remains)
INFO - root - 2017-12-16 21:26:30.966766: step 108530, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 13h:41m:38s remains)
INFO - root - 2017-12-16 21:26:33.176150: step 108540, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 13h:45m:16s remains)
INFO - root - 2017-12-16 21:26:35.400572: step 108550, loss = 0.47, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 13h:52m:45s remains)
INFO - root - 2017-12-16 21:26:37.653098: step 108560, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 14h:14m:35s remains)
INFO - root - 2017-12-16 21:26:39.919132: step 108570, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 13h:36m:11s remains)
INFO - root - 2017-12-16 21:26:42.158474: step 108580, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 13h:37m:56s remains)
INFO - root - 2017-12-16 21:26:44.375413: step 108590, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 14h:14m:41s remains)
INFO - root - 2017-12-16 21:26:46.590924: step 108600, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 13h:28m:44s remains)
INFO - root - 2017-12-16 21:26:48.979977: step 108610, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 13h:42m:01s remains)
INFO - root - 2017-12-16 21:26:51.176491: step 108620, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 13h:23m:47s remains)
INFO - root - 2017-12-16 21:26:53.386414: step 108630, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 13h:33m:28s remains)
INFO - root - 2017-12-16 21:26:55.602330: step 108640, loss = 0.51, batch loss = 0.33 (34.0 examples/sec; 0.235 sec/batch; 14h:38m:16s remains)
INFO - root - 2017-12-16 21:26:57.827625: step 108650, loss = 0.50, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 13h:27m:15s remains)
INFO - root - 2017-12-16 21:27:00.039743: step 108660, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 13h:41m:03s remains)
INFO - root - 2017-12-16 21:27:02.242297: step 108670, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 14h:15m:17s remains)
INFO - root - 2017-12-16 21:27:04.496663: step 108680, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 14h:18m:15s remains)
INFO - root - 2017-12-16 21:27:06.736299: step 108690, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 13h:44m:49s remains)
INFO - root - 2017-12-16 21:27:08.975217: step 108700, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.218 sec/batch; 13h:34m:48s remains)
INFO - root - 2017-12-16 21:27:11.325037: step 108710, loss = 0.43, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 13h:18m:39s remains)
INFO - root - 2017-12-16 21:27:13.555106: step 108720, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 13h:57m:34s remains)
INFO - root - 2017-12-16 21:27:15.776821: step 108730, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 13h:49m:58s remains)
INFO - root - 2017-12-16 21:27:18.027922: step 108740, loss = 0.43, batch loss = 0.25 (34.1 examples/sec; 0.235 sec/batch; 14h:35m:37s remains)
INFO - root - 2017-12-16 21:27:20.249229: step 108750, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 13h:43m:53s remains)
INFO - root - 2017-12-16 21:27:22.462405: step 108760, loss = 0.47, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 13h:30m:59s remains)
INFO - root - 2017-12-16 21:27:24.678381: step 108770, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 13h:39m:43s remains)
INFO - root - 2017-12-16 21:27:26.924620: step 108780, loss = 0.47, batch loss = 0.29 (33.8 examples/sec; 0.237 sec/batch; 14h:42m:45s remains)
INFO - root - 2017-12-16 21:27:29.153303: step 108790, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 13h:48m:53s remains)
INFO - root - 2017-12-16 21:27:31.398964: step 108800, loss = 0.41, batch loss = 0.23 (36.3 examples/sec; 0.221 sec/batch; 13h:42m:15s remains)
INFO - root - 2017-12-16 21:27:33.798135: step 108810, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 14h:05m:35s remains)
INFO - root - 2017-12-16 21:27:36.047985: step 108820, loss = 0.52, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 14h:09m:41s remains)
INFO - root - 2017-12-16 21:27:38.308288: step 108830, loss = 0.51, batch loss = 0.33 (34.4 examples/sec; 0.232 sec/batch; 14h:26m:21s remains)
INFO - root - 2017-12-16 21:27:40.555800: step 108840, loss = 0.50, batch loss = 0.33 (33.8 examples/sec; 0.236 sec/batch; 14h:41m:17s remains)
INFO - root - 2017-12-16 21:27:42.763196: step 108850, loss = 0.48, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 13h:25m:23s remains)
INFO - root - 2017-12-16 21:27:44.962902: step 108860, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 13h:22m:11s remains)
INFO - root - 2017-12-16 21:27:47.168183: step 108870, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 13h:17m:46s remains)
INFO - root - 2017-12-16 21:27:49.389930: step 108880, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 13h:36m:38s remains)
INFO - root - 2017-12-16 21:27:51.596268: step 108890, loss = 0.44, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 14h:14m:38s remains)
INFO - root - 2017-12-16 21:27:53.867849: step 108900, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 13h:39m:34s remains)
INFO - root - 2017-12-16 21:27:56.229849: step 108910, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 13h:33m:05s remains)
INFO - root - 2017-12-16 21:27:58.435645: step 108920, loss = 0.54, batch loss = 0.36 (37.3 examples/sec; 0.215 sec/batch; 13h:20m:10s remains)
INFO - root - 2017-12-16 21:28:00.671304: step 108930, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 13h:49m:53s remains)
INFO - root - 2017-12-16 21:28:02.874499: step 108940, loss = 0.41, batch loss = 0.24 (36.9 examples/sec; 0.217 sec/batch; 13h:27m:13s remains)
INFO - root - 2017-12-16 21:28:05.096247: step 108950, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 13h:24m:15s remains)
INFO - root - 2017-12-16 21:28:07.350223: step 108960, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.233 sec/batch; 14h:26m:23s remains)
INFO - root - 2017-12-16 21:28:09.551404: step 108970, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 13h:26m:14s remains)
INFO - root - 2017-12-16 21:28:11.742618: step 108980, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 13h:15m:17s remains)
INFO - root - 2017-12-16 21:28:13.960278: step 108990, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 13h:54m:20s remains)
INFO - root - 2017-12-16 21:28:16.167274: step 109000, loss = 0.42, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 13h:43m:12s remains)
INFO - root - 2017-12-16 21:28:18.501361: step 109010, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 13h:39m:43s remains)
INFO - root - 2017-12-16 21:28:20.707806: step 109020, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 13h:15m:05s remains)
INFO - root - 2017-12-16 21:28:22.952244: step 109030, loss = 0.51, batch loss = 0.33 (34.0 examples/sec; 0.236 sec/batch; 14h:37m:37s remains)
INFO - root - 2017-12-16 21:28:25.228226: step 109040, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 13h:29m:58s remains)
INFO - root - 2017-12-16 21:28:27.449906: step 109050, loss = 0.55, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 13h:40m:44s remains)
INFO - root - 2017-12-16 21:28:29.644127: step 109060, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 14h:13m:58s remains)
INFO - root - 2017-12-16 21:28:31.891303: step 109070, loss = 0.50, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 14h:13m:05s remains)
INFO - root - 2017-12-16 21:28:34.098585: step 109080, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 13h:50m:54s remains)
INFO - root - 2017-12-16 21:28:36.294512: step 109090, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 13h:40m:04s remains)
INFO - root - 2017-12-16 21:28:38.541318: step 109100, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 13h:53m:42s remains)
INFO - root - 2017-12-16 21:28:40.900854: step 109110, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 13h:40m:38s remains)
INFO - root - 2017-12-16 21:28:43.110778: step 109120, loss = 0.47, batch loss = 0.29 (32.7 examples/sec; 0.245 sec/batch; 15h:11m:00s remains)
INFO - root - 2017-12-16 21:28:45.332635: step 109130, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 13h:11m:09s remains)
INFO - root - 2017-12-16 21:28:47.545958: step 109140, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 14h:15m:48s remains)
INFO - root - 2017-12-16 21:28:49.754292: step 109150, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 13h:38m:37s remains)
INFO - root - 2017-12-16 21:28:51.960090: step 109160, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 13h:38m:24s remains)
INFO - root - 2017-12-16 21:28:54.175965: step 109170, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 14h:15m:51s remains)
INFO - root - 2017-12-16 21:28:56.412658: step 109180, loss = 0.45, batch loss = 0.27 (34.6 examples/sec; 0.231 sec/batch; 14h:21m:14s remains)
INFO - root - 2017-12-16 21:28:58.662607: step 109190, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 13h:53m:13s remains)
INFO - root - 2017-12-16 21:29:00.867241: step 109200, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 13h:24m:44s remains)
INFO - root - 2017-12-16 21:29:03.196733: step 109210, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 13h:16m:14s remains)
INFO - root - 2017-12-16 21:29:05.400650: step 109220, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 14h:01m:38s remains)
INFO - root - 2017-12-16 21:29:07.605501: step 109230, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 14h:03m:52s remains)
INFO - root - 2017-12-16 21:29:09.843976: step 109240, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 13h:46m:37s remains)
INFO - root - 2017-12-16 21:29:12.090728: step 109250, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 13h:12m:30s remains)
INFO - root - 2017-12-16 21:29:14.311225: step 109260, loss = 0.42, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 13h:52m:47s remains)
INFO - root - 2017-12-16 21:29:16.531207: step 109270, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 13h:25m:35s remains)
INFO - root - 2017-12-16 21:29:18.781925: step 109280, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.226 sec/batch; 14h:02m:38s remains)
INFO - root - 2017-12-16 21:29:21.009375: step 109290, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 13h:39m:33s remains)
INFO - root - 2017-12-16 21:29:23.229970: step 109300, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 13h:42m:42s remains)
INFO - root - 2017-12-16 21:29:25.616897: step 109310, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 13h:52m:43s remains)
INFO - root - 2017-12-16 21:29:27.865205: step 109320, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.228 sec/batch; 14h:06m:17s remains)
INFO - root - 2017-12-16 21:29:30.111833: step 109330, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 14h:01m:32s remains)
INFO - root - 2017-12-16 21:29:32.332524: step 109340, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 13h:15m:09s remains)
INFO - root - 2017-12-16 21:29:34.580194: step 109350, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 13h:43m:28s remains)
INFO - root - 2017-12-16 21:29:36.845678: step 109360, loss = 0.47, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 14h:09m:08s remains)
INFO - root - 2017-12-16 21:29:39.095931: step 109370, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 13h:52m:12s remains)
INFO - root - 2017-12-16 21:29:41.320759: step 109380, loss = 0.54, batch loss = 0.36 (36.8 examples/sec; 0.218 sec/batch; 13h:28m:52s remains)
INFO - root - 2017-12-16 21:29:43.548707: step 109390, loss = 0.46, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 14h:27m:05s remains)
INFO - root - 2017-12-16 21:29:45.783834: step 109400, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 14h:00m:10s remains)
INFO - root - 2017-12-16 21:29:48.109722: step 109410, loss = 0.48, batch loss = 0.31 (37.8 examples/sec; 0.212 sec/batch; 13h:07m:49s remains)
INFO - root - 2017-12-16 21:29:50.307786: step 109420, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 13h:41m:19s remains)
INFO - root - 2017-12-16 21:29:52.509333: step 109430, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 13h:43m:21s remains)
INFO - root - 2017-12-16 21:29:54.747224: step 109440, loss = 0.54, batch loss = 0.36 (37.9 examples/sec; 0.211 sec/batch; 13h:03m:54s remains)
INFO - root - 2017-12-16 21:29:56.953534: step 109450, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 13h:29m:24s remains)
INFO - root - 2017-12-16 21:29:59.158022: step 109460, loss = 0.47, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 14h:22m:49s remains)
INFO - root - 2017-12-16 21:30:01.334977: step 109470, loss = 0.55, batch loss = 0.37 (37.4 examples/sec; 0.214 sec/batch; 13h:14m:07s remains)
INFO - root - 2017-12-16 21:30:03.600767: step 109480, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 14h:01m:32s remains)
INFO - root - 2017-12-16 21:30:05.823366: step 109490, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 13h:34m:59s remains)
INFO - root - 2017-12-16 21:30:08.030554: step 109500, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 13h:51m:09s remains)
INFO - root - 2017-12-16 21:30:10.413502: step 109510, loss = 0.45, batch loss = 0.28 (32.9 examples/sec; 0.243 sec/batch; 15h:04m:23s remains)
INFO - root - 2017-12-16 21:30:12.658476: step 109520, loss = 0.51, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 14h:13m:57s remains)
INFO - root - 2017-12-16 21:30:14.871452: step 109530, loss = 0.51, batch loss = 0.33 (35.0 examples/sec; 0.229 sec/batch; 14h:09m:54s remains)
INFO - root - 2017-12-16 21:30:17.068054: step 109540, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 13h:17m:02s remains)
INFO - root - 2017-12-16 21:30:19.321096: step 109550, loss = 0.42, batch loss = 0.24 (36.1 examples/sec; 0.221 sec/batch; 13h:42m:43s remains)
INFO - root - 2017-12-16 21:30:21.587104: step 109560, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 13h:48m:00s remains)
INFO - root - 2017-12-16 21:30:23.828004: step 109570, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 13h:08m:19s remains)
INFO - root - 2017-12-16 21:30:26.050296: step 109580, loss = 0.54, batch loss = 0.36 (36.0 examples/sec; 0.222 sec/batch; 13h:46m:04s remains)
INFO - root - 2017-12-16 21:30:28.268976: step 109590, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 13h:48m:11s remains)
INFO - root - 2017-12-16 21:30:30.514791: step 109600, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 13h:51m:30s remains)
INFO - root - 2017-12-16 21:30:32.839149: step 109610, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 13h:30m:10s remains)
INFO - root - 2017-12-16 21:30:35.031944: step 109620, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.226 sec/batch; 14h:01m:08s remains)
INFO - root - 2017-12-16 21:30:37.245755: step 109630, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 13h:38m:48s remains)
INFO - root - 2017-12-16 21:30:39.465372: step 109640, loss = 0.56, batch loss = 0.38 (36.4 examples/sec; 0.220 sec/batch; 13h:37m:17s remains)
INFO - root - 2017-12-16 21:30:41.691586: step 109650, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 13h:41m:07s remains)
INFO - root - 2017-12-16 21:30:43.906400: step 109660, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.224 sec/batch; 13h:53m:39s remains)
INFO - root - 2017-12-16 21:30:46.087629: step 109670, loss = 0.42, batch loss = 0.24 (36.0 examples/sec; 0.222 sec/batch; 13h:45m:36s remains)
INFO - root - 2017-12-16 21:30:48.315625: step 109680, loss = 0.50, batch loss = 0.32 (34.4 examples/sec; 0.233 sec/batch; 14h:23m:50s remains)
INFO - root - 2017-12-16 21:30:50.508888: step 109690, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 13h:18m:43s remains)
INFO - root - 2017-12-16 21:30:52.731214: step 109700, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 13h:39m:51s remains)
INFO - root - 2017-12-16 21:30:55.111948: step 109710, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 14h:03m:39s remains)
INFO - root - 2017-12-16 21:30:57.338146: step 109720, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 13h:40m:21s remains)
INFO - root - 2017-12-16 21:30:59.539510: step 109730, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 13h:15m:47s remains)
INFO - root - 2017-12-16 21:31:01.753880: step 109740, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 13h:58m:09s remains)
INFO - root - 2017-12-16 21:31:03.982535: step 109750, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 13h:51m:39s remains)
INFO - root - 2017-12-16 21:31:06.221861: step 109760, loss = 0.46, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 13h:16m:10s remains)
INFO - root - 2017-12-16 21:31:08.484067: step 109770, loss = 0.53, batch loss = 0.35 (35.1 examples/sec; 0.228 sec/batch; 14h:06m:29s remains)
INFO - root - 2017-12-16 21:31:10.723892: step 109780, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 13h:13m:20s remains)
INFO - root - 2017-12-16 21:31:12.921647: step 109790, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 13h:24m:34s remains)
INFO - root - 2017-12-16 21:31:15.146222: step 109800, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 13h:23m:21s remains)
INFO - root - 2017-12-16 21:31:17.518382: step 109810, loss = 0.47, batch loss = 0.29 (32.8 examples/sec; 0.244 sec/batch; 15h:04m:13s remains)
INFO - root - 2017-12-16 21:31:19.720720: step 109820, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 13h:39m:49s remains)
INFO - root - 2017-12-16 21:31:21.953164: step 109830, loss = 0.46, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 13h:39m:36s remains)
INFO - root - 2017-12-16 21:31:24.174949: step 109840, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 13h:42m:47s remains)
INFO - root - 2017-12-16 21:31:26.371184: step 109850, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 13h:15m:41s remains)
INFO - root - 2017-12-16 21:31:28.614603: step 109860, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 14h:00m:54s remains)
INFO - root - 2017-12-16 21:31:30.856923: step 109870, loss = 0.53, batch loss = 0.36 (36.2 examples/sec; 0.221 sec/batch; 13h:40m:41s remains)
INFO - root - 2017-12-16 21:31:33.088838: step 109880, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 14h:20m:50s remains)
INFO - root - 2017-12-16 21:31:35.334351: step 109890, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 13h:28m:58s remains)
INFO - root - 2017-12-16 21:31:37.545836: step 109900, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 13h:23m:00s remains)
INFO - root - 2017-12-16 21:31:39.890942: step 109910, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 13h:41m:27s remains)
INFO - root - 2017-12-16 21:31:42.113701: step 109920, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 13h:47m:29s remains)
INFO - root - 2017-12-16 21:31:44.326591: step 109930, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 13h:42m:43s remains)
INFO - root - 2017-12-16 21:31:46.555875: step 109940, loss = 0.48, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 13h:32m:58s remains)
INFO - root - 2017-12-16 21:31:48.775267: step 109950, loss = 0.46, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 14h:11m:56s remains)
INFO - root - 2017-12-16 21:31:51.048112: step 109960, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 13h:57m:41s remains)
INFO - root - 2017-12-16 21:31:53.277556: step 109970, loss = 0.51, batch loss = 0.34 (34.6 examples/sec; 0.231 sec/batch; 14h:17m:44s remains)
INFO - root - 2017-12-16 21:31:55.523472: step 109980, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 13h:48m:47s remains)
INFO - root - 2017-12-16 21:31:57.764874: step 109990, loss = 0.50, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 14h:11m:26s remains)
INFO - root - 2017-12-16 21:31:59.987868: step 110000, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 13h:38m:29s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-110000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-110000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 21:32:02.939545: step 110010, loss = 0.43, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 13h:34m:08s remains)
INFO - root - 2017-12-16 21:32:05.170730: step 110020, loss = 0.43, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 13h:22m:32s remains)
INFO - root - 2017-12-16 21:32:07.385403: step 110030, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 13h:32m:55s remains)
INFO - root - 2017-12-16 21:32:09.591492: step 110040, loss = 0.41, batch loss = 0.23 (35.7 examples/sec; 0.224 sec/batch; 13h:49m:43s remains)
INFO - root - 2017-12-16 21:32:11.865925: step 110050, loss = 0.49, batch loss = 0.31 (33.9 examples/sec; 0.236 sec/batch; 14h:35m:38s remains)
INFO - root - 2017-12-16 21:32:14.081321: step 110060, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 13h:36m:02s remains)
INFO - root - 2017-12-16 21:32:16.317683: step 110070, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 13h:52m:29s remains)
INFO - root - 2017-12-16 21:32:18.550572: step 110080, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 13h:47m:39s remains)
INFO - root - 2017-12-16 21:32:20.729827: step 110090, loss = 0.47, batch loss = 0.30 (38.4 examples/sec; 0.208 sec/batch; 12h:51m:40s remains)
INFO - root - 2017-12-16 21:32:22.938062: step 110100, loss = 0.42, batch loss = 0.24 (35.4 examples/sec; 0.226 sec/batch; 13h:56m:50s remains)
INFO - root - 2017-12-16 21:32:25.256921: step 110110, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 13h:12m:30s remains)
INFO - root - 2017-12-16 21:32:27.478749: step 110120, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 13h:50m:00s remains)
INFO - root - 2017-12-16 21:32:29.685787: step 110130, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 13h:29m:36s remains)
INFO - root - 2017-12-16 21:32:31.922642: step 110140, loss = 0.47, batch loss = 0.29 (33.4 examples/sec; 0.240 sec/batch; 14h:48m:01s remains)
INFO - root - 2017-12-16 21:32:34.135899: step 110150, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 13h:09m:22s remains)
INFO - root - 2017-12-16 21:32:36.394095: step 110160, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 13h:38m:19s remains)
INFO - root - 2017-12-16 21:32:38.645156: step 110170, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 13h:29m:11s remains)
INFO - root - 2017-12-16 21:32:40.881355: step 110180, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 13h:49m:37s remains)
INFO - root - 2017-12-16 21:32:43.096958: step 110190, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 13h:36m:15s remains)
INFO - root - 2017-12-16 21:32:45.307261: step 110200, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 13h:36m:24s remains)
INFO - root - 2017-12-16 21:32:47.705235: step 110210, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 13h:31m:41s remains)
INFO - root - 2017-12-16 21:32:49.919443: step 110220, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 13h:47m:44s remains)
INFO - root - 2017-12-16 21:32:52.142367: step 110230, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 13h:20m:31s remains)
INFO - root - 2017-12-16 21:32:54.359194: step 110240, loss = 0.53, batch loss = 0.35 (35.3 examples/sec; 0.227 sec/batch; 13h:59m:17s remains)
INFO - root - 2017-12-16 21:32:56.576089: step 110250, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 13h:35m:51s remains)
INFO - root - 2017-12-16 21:32:58.784692: step 110260, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 13h:24m:26s remains)
INFO - root - 2017-12-16 21:33:00.980691: step 110270, loss = 0.44, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 13h:34m:31s remains)
INFO - root - 2017-12-16 21:33:03.205442: step 110280, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 14h:14m:00s remains)
INFO - root - 2017-12-16 21:33:05.395061: step 110290, loss = 0.49, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 13h:31m:09s remains)
INFO - root - 2017-12-16 21:33:07.676791: step 110300, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 13h:46m:35s remains)
INFO - root - 2017-12-16 21:33:10.051870: step 110310, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 13h:33m:26s remains)
INFO - root - 2017-12-16 21:33:12.265258: step 110320, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 13h:22m:53s remains)
INFO - root - 2017-12-16 21:33:14.493819: step 110330, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 13h:45m:20s remains)
INFO - root - 2017-12-16 21:33:16.697168: step 110340, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 13h:19m:04s remains)
INFO - root - 2017-12-16 21:33:18.916152: step 110350, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 13h:55m:14s remains)
INFO - root - 2017-12-16 21:33:21.138056: step 110360, loss = 0.45, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 13h:13m:39s remains)
INFO - root - 2017-12-16 21:33:23.342204: step 110370, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 13h:33m:14s remains)
INFO - root - 2017-12-16 21:33:25.605106: step 110380, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 13h:46m:37s remains)
INFO - root - 2017-12-16 21:33:27.814482: step 110390, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 13h:32m:40s remains)
INFO - root - 2017-12-16 21:33:30.059810: step 110400, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 14h:11m:39s remains)
INFO - root - 2017-12-16 21:33:32.415052: step 110410, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 13h:32m:57s remains)
INFO - root - 2017-12-16 21:33:34.659964: step 110420, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 13h:33m:50s remains)
INFO - root - 2017-12-16 21:33:36.887777: step 110430, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 13h:54m:58s remains)
INFO - root - 2017-12-16 21:33:39.097239: step 110440, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 13h:32m:54s remains)
INFO - root - 2017-12-16 21:33:41.317985: step 110450, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 13h:09m:35s remains)
INFO - root - 2017-12-16 21:33:43.534375: step 110460, loss = 0.54, batch loss = 0.36 (36.8 examples/sec; 0.218 sec/batch; 13h:25m:27s remains)
INFO - root - 2017-12-16 21:33:45.737006: step 110470, loss = 0.46, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 14h:22m:14s remains)
INFO - root - 2017-12-16 21:33:47.959652: step 110480, loss = 0.55, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 13h:38m:27s remains)
INFO - root - 2017-12-16 21:33:50.182089: step 110490, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 13h:51m:21s remains)
INFO - root - 2017-12-16 21:33:52.412412: step 110500, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.229 sec/batch; 14h:05m:58s remains)
INFO - root - 2017-12-16 21:33:54.789474: step 110510, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 13h:24m:54s remains)
INFO - root - 2017-12-16 21:33:57.003854: step 110520, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 13h:31m:10s remains)
INFO - root - 2017-12-16 21:33:59.263816: step 110530, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 13h:49m:56s remains)
INFO - root - 2017-12-16 21:34:01.471858: step 110540, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 13h:08m:31s remains)
INFO - root - 2017-12-16 21:34:03.708026: step 110550, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 13h:58m:05s remains)
INFO - root - 2017-12-16 21:34:05.947975: step 110560, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 13h:21m:35s remains)
INFO - root - 2017-12-16 21:34:08.216388: step 110570, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 13h:40m:41s remains)
INFO - root - 2017-12-16 21:34:10.436315: step 110580, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 14h:03m:33s remains)
INFO - root - 2017-12-16 21:34:12.622120: step 110590, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 13h:18m:35s remains)
INFO - root - 2017-12-16 21:34:14.855574: step 110600, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.215 sec/batch; 13h:14m:14s remains)
INFO - root - 2017-12-16 21:34:17.245949: step 110610, loss = 0.47, batch loss = 0.29 (33.3 examples/sec; 0.241 sec/batch; 14h:49m:29s remains)
INFO - root - 2017-12-16 21:34:19.495967: step 110620, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 13h:17m:40s remains)
INFO - root - 2017-12-16 21:34:21.735917: step 110630, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 13h:58m:43s remains)
INFO - root - 2017-12-16 21:34:23.962483: step 110640, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 13h:41m:24s remains)
INFO - root - 2017-12-16 21:34:26.176674: step 110650, loss = 0.47, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 14h:25m:28s remains)
INFO - root - 2017-12-16 21:34:28.408117: step 110660, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 13h:32m:59s remains)
INFO - root - 2017-12-16 21:34:30.614501: step 110670, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 13h:38m:05s remains)
INFO - root - 2017-12-16 21:34:32.795979: step 110680, loss = 0.58, batch loss = 0.40 (37.6 examples/sec; 0.213 sec/batch; 13h:06m:17s remains)
INFO - root - 2017-12-16 21:34:35.030925: step 110690, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 13h:44m:53s remains)
INFO - root - 2017-12-16 21:34:37.258141: step 110700, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 13h:22m:14s remains)
INFO - root - 2017-12-16 21:34:39.647123: step 110710, loss = 0.47, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 13h:52m:44s remains)
INFO - root - 2017-12-16 21:34:41.854688: step 110720, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 13h:12m:17s remains)
INFO - root - 2017-12-16 21:34:44.055987: step 110730, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 13h:21m:23s remains)
INFO - root - 2017-12-16 21:34:46.248394: step 110740, loss = 0.54, batch loss = 0.36 (35.2 examples/sec; 0.227 sec/batch; 13h:58m:58s remains)
INFO - root - 2017-12-16 21:34:48.481226: step 110750, loss = 0.52, batch loss = 0.34 (34.2 examples/sec; 0.234 sec/batch; 14h:25m:36s remains)
INFO - root - 2017-12-16 21:34:50.713455: step 110760, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 13h:36m:17s remains)
INFO - root - 2017-12-16 21:34:52.945378: step 110770, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 13h:47m:51s remains)
INFO - root - 2017-12-16 21:34:55.167938: step 110780, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 13h:50m:26s remains)
INFO - root - 2017-12-16 21:34:57.377543: step 110790, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 13h:19m:01s remains)
INFO - root - 2017-12-16 21:34:59.599770: step 110800, loss = 0.48, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 13h:29m:41s remains)
INFO - root - 2017-12-16 21:35:01.988302: step 110810, loss = 0.52, batch loss = 0.34 (35.0 examples/sec; 0.229 sec/batch; 14h:04m:17s remains)
INFO - root - 2017-12-16 21:35:04.204880: step 110820, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 13h:29m:46s remains)
INFO - root - 2017-12-16 21:35:06.438447: step 110830, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 13h:27m:01s remains)
INFO - root - 2017-12-16 21:35:08.657334: step 110840, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 13h:54m:29s remains)
INFO - root - 2017-12-16 21:35:10.855138: step 110850, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 13h:12m:00s remains)
INFO - root - 2017-12-16 21:35:13.074608: step 110860, loss = 0.43, batch loss = 0.26 (37.5 examples/sec; 0.213 sec/batch; 13h:08m:17s remains)
INFO - root - 2017-12-16 21:35:15.333016: step 110870, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 13h:51m:02s remains)
INFO - root - 2017-12-16 21:35:17.509651: step 110880, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 13h:11m:29s remains)
INFO - root - 2017-12-16 21:35:19.759784: step 110890, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.224 sec/batch; 13h:49m:09s remains)
INFO - root - 2017-12-16 21:35:21.991351: step 110900, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 13h:22m:46s remains)
INFO - root - 2017-12-16 21:35:24.348751: step 110910, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 13h:26m:07s remains)
INFO - root - 2017-12-16 21:35:26.605974: step 110920, loss = 0.42, batch loss = 0.25 (33.9 examples/sec; 0.236 sec/batch; 14h:32m:37s remains)
INFO - root - 2017-12-16 21:35:28.889893: step 110930, loss = 0.49, batch loss = 0.31 (34.4 examples/sec; 0.232 sec/batch; 14h:18m:08s remains)
INFO - root - 2017-12-16 21:35:31.087724: step 110940, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 13h:46m:20s remains)
INFO - root - 2017-12-16 21:35:33.292858: step 110950, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 14h:17m:06s remains)
INFO - root - 2017-12-16 21:35:35.475918: step 110960, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 13h:12m:38s remains)
INFO - root - 2017-12-16 21:35:37.727739: step 110970, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.232 sec/batch; 14h:18m:11s remains)
INFO - root - 2017-12-16 21:35:39.926078: step 110980, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 13h:19m:51s remains)
INFO - root - 2017-12-16 21:35:42.156054: step 110990, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 13h:29m:24s remains)
INFO - root - 2017-12-16 21:35:44.394900: step 111000, loss = 0.55, batch loss = 0.37 (34.8 examples/sec; 0.230 sec/batch; 14h:09m:09s remains)
INFO - root - 2017-12-16 21:35:46.789136: step 111010, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 13h:44m:06s remains)
INFO - root - 2017-12-16 21:35:48.990430: step 111020, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 13h:29m:46s remains)
INFO - root - 2017-12-16 21:35:51.243330: step 111030, loss = 0.53, batch loss = 0.35 (34.7 examples/sec; 0.231 sec/batch; 14h:10m:53s remains)
INFO - root - 2017-12-16 21:35:53.495307: step 111040, loss = 0.46, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 14h:23m:10s remains)
INFO - root - 2017-12-16 21:35:55.701433: step 111050, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 13h:14m:21s remains)
INFO - root - 2017-12-16 21:35:57.939852: step 111060, loss = 0.56, batch loss = 0.38 (35.9 examples/sec; 0.223 sec/batch; 13h:42m:53s remains)
INFO - root - 2017-12-16 21:36:00.184036: step 111070, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 13h:38m:31s remains)
INFO - root - 2017-12-16 21:36:02.449467: step 111080, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 13h:16m:48s remains)
INFO - root - 2017-12-16 21:36:04.714341: step 111090, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 13h:51m:28s remains)
INFO - root - 2017-12-16 21:36:06.921231: step 111100, loss = 0.53, batch loss = 0.35 (35.0 examples/sec; 0.229 sec/batch; 14h:04m:11s remains)
INFO - root - 2017-12-16 21:36:09.307053: step 111110, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 13h:24m:20s remains)
INFO - root - 2017-12-16 21:36:11.515197: step 111120, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 13h:49m:08s remains)
INFO - root - 2017-12-16 21:36:13.754248: step 111130, loss = 0.47, batch loss = 0.29 (33.8 examples/sec; 0.237 sec/batch; 14h:34m:05s remains)
INFO - root - 2017-12-16 21:36:15.979081: step 111140, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 13h:06m:53s remains)
INFO - root - 2017-12-16 21:36:18.184597: step 111150, loss = 0.49, batch loss = 0.31 (38.2 examples/sec; 0.209 sec/batch; 12h:51m:38s remains)
INFO - root - 2017-12-16 21:36:20.359374: step 111160, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 13h:22m:47s remains)
INFO - root - 2017-12-16 21:36:22.596229: step 111170, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 13h:26m:47s remains)
INFO - root - 2017-12-16 21:36:24.803937: step 111180, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 13h:27m:33s remains)
INFO - root - 2017-12-16 21:36:27.022925: step 111190, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 13h:28m:18s remains)
INFO - root - 2017-12-16 21:36:29.262793: step 111200, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 14h:14m:30s remains)
INFO - root - 2017-12-16 21:36:31.673050: step 111210, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 13h:46m:29s remains)
INFO - root - 2017-12-16 21:36:33.885868: step 111220, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 13h:54m:01s remains)
INFO - root - 2017-12-16 21:36:36.075897: step 111230, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 13h:41m:58s remains)
INFO - root - 2017-12-16 21:36:38.291968: step 111240, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 13h:27m:05s remains)
INFO - root - 2017-12-16 21:36:40.539265: step 111250, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 13h:30m:51s remains)
INFO - root - 2017-12-16 21:36:42.736789: step 111260, loss = 0.48, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 13h:23m:04s remains)
INFO - root - 2017-12-16 21:36:44.984932: step 111270, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 13h:49m:01s remains)
INFO - root - 2017-12-16 21:36:47.205488: step 111280, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 13h:32m:49s remains)
INFO - root - 2017-12-16 21:36:49.392766: step 111290, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 13h:29m:40s remains)
INFO - root - 2017-12-16 21:36:51.588072: step 111300, loss = 0.50, batch loss = 0.32 (34.2 examples/sec; 0.234 sec/batch; 14h:23m:09s remains)
INFO - root - 2017-12-16 21:36:53.946539: step 111310, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 13h:24m:04s remains)
INFO - root - 2017-12-16 21:36:56.148751: step 111320, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 13h:24m:30s remains)
INFO - root - 2017-12-16 21:36:58.390782: step 111330, loss = 0.53, batch loss = 0.35 (35.4 examples/sec; 0.226 sec/batch; 13h:53m:27s remains)
INFO - root - 2017-12-16 21:37:00.625687: step 111340, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 13h:33m:33s remains)
INFO - root - 2017-12-16 21:37:02.881076: step 111350, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 13h:54m:06s remains)
INFO - root - 2017-12-16 21:37:05.089863: step 111360, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 13h:41m:11s remains)
INFO - root - 2017-12-16 21:37:07.325904: step 111370, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 13h:47m:30s remains)
INFO - root - 2017-12-16 21:37:09.538373: step 111380, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 13h:08m:37s remains)
INFO - root - 2017-12-16 21:37:11.754879: step 111390, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 13h:54m:52s remains)
INFO - root - 2017-12-16 21:37:13.999664: step 111400, loss = 0.45, batch loss = 0.27 (34.1 examples/sec; 0.235 sec/batch; 14h:25m:45s remains)
INFO - root - 2017-12-16 21:37:16.354521: step 111410, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 13h:44m:58s remains)
INFO - root - 2017-12-16 21:37:18.607735: step 111420, loss = 0.52, batch loss = 0.34 (33.8 examples/sec; 0.237 sec/batch; 14h:32m:54s remains)
INFO - root - 2017-12-16 21:37:20.824130: step 111430, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 13h:19m:33s remains)
INFO - root - 2017-12-16 21:37:23.025316: step 111440, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 13h:27m:48s remains)
INFO - root - 2017-12-16 21:37:25.268001: step 111450, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 13h:31m:31s remains)
INFO - root - 2017-12-16 21:37:27.531848: step 111460, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 13h:27m:56s remains)
INFO - root - 2017-12-16 21:37:29.716026: step 111470, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 13h:42m:01s remains)
INFO - root - 2017-12-16 21:37:31.903914: step 111480, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 13h:15m:58s remains)
INFO - root - 2017-12-16 21:37:34.148217: step 111490, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 14h:06m:11s remains)
INFO - root - 2017-12-16 21:37:36.341253: step 111500, loss = 0.56, batch loss = 0.38 (36.0 examples/sec; 0.222 sec/batch; 13h:37m:24s remains)
INFO - root - 2017-12-16 21:37:38.688158: step 111510, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 13h:55m:18s remains)
INFO - root - 2017-12-16 21:37:40.896918: step 111520, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 13h:46m:10s remains)
INFO - root - 2017-12-16 21:37:43.145632: step 111530, loss = 0.50, batch loss = 0.33 (36.3 examples/sec; 0.221 sec/batch; 13h:32m:34s remains)
INFO - root - 2017-12-16 21:37:45.348932: step 111540, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 13h:47m:04s remains)
INFO - root - 2017-12-16 21:37:47.565699: step 111550, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 13h:50m:19s remains)
INFO - root - 2017-12-16 21:37:49.800153: step 111560, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 13h:51m:51s remains)
INFO - root - 2017-12-16 21:37:52.018255: step 111570, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 13h:14m:58s remains)
INFO - root - 2017-12-16 21:37:54.230561: step 111580, loss = 0.53, batch loss = 0.35 (35.3 examples/sec; 0.227 sec/batch; 13h:55m:23s remains)
INFO - root - 2017-12-16 21:37:56.432639: step 111590, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 13h:45m:37s remains)
INFO - root - 2017-12-16 21:37:58.650552: step 111600, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 13h:38m:51s remains)
INFO - root - 2017-12-16 21:38:01.015158: step 111610, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 13h:33m:25s remains)
INFO - root - 2017-12-16 21:38:03.214715: step 111620, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 13h:29m:51s remains)
INFO - root - 2017-12-16 21:38:05.432642: step 111630, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 13h:49m:10s remains)
INFO - root - 2017-12-16 21:38:07.645716: step 111640, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 13h:15m:33s remains)
INFO - root - 2017-12-16 21:38:09.869602: step 111650, loss = 0.46, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 13h:35m:38s remains)
INFO - root - 2017-12-16 21:38:12.042407: step 111660, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 13h:27m:44s remains)
INFO - root - 2017-12-16 21:38:14.237190: step 111670, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 13h:25m:16s remains)
INFO - root - 2017-12-16 21:38:16.418640: step 111680, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 13h:37m:44s remains)
INFO - root - 2017-12-16 21:38:18.633247: step 111690, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 13h:40m:50s remains)
INFO - root - 2017-12-16 21:38:20.804256: step 111700, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 13h:34m:48s remains)
INFO - root - 2017-12-16 21:38:23.164368: step 111710, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 13h:07m:28s remains)
INFO - root - 2017-12-16 21:38:25.375725: step 111720, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 13h:09m:49s remains)
INFO - root - 2017-12-16 21:38:27.614932: step 111730, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 13h:51m:04s remains)
INFO - root - 2017-12-16 21:38:29.815711: step 111740, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 13h:11m:08s remains)
INFO - root - 2017-12-16 21:38:32.008961: step 111750, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.233 sec/batch; 14h:16m:03s remains)
INFO - root - 2017-12-16 21:38:34.216672: step 111760, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.215 sec/batch; 13h:12m:26s remains)
INFO - root - 2017-12-16 21:38:36.419350: step 111770, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 13h:02m:25s remains)
INFO - root - 2017-12-16 21:38:38.635463: step 111780, loss = 0.54, batch loss = 0.36 (35.5 examples/sec; 0.225 sec/batch; 13h:48m:23s remains)
INFO - root - 2017-12-16 21:38:40.858904: step 111790, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 13h:27m:01s remains)
INFO - root - 2017-12-16 21:38:43.051049: step 111800, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 13h:14m:10s remains)
INFO - root - 2017-12-16 21:38:45.371365: step 111810, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 13h:13m:37s remains)
INFO - root - 2017-12-16 21:38:47.562691: step 111820, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 13h:38m:13s remains)
INFO - root - 2017-12-16 21:38:49.727117: step 111830, loss = 0.52, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 13h:06m:12s remains)
INFO - root - 2017-12-16 21:38:51.978504: step 111840, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 13h:38m:14s remains)
INFO - root - 2017-12-16 21:38:54.186054: step 111850, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 13h:28m:08s remains)
INFO - root - 2017-12-16 21:38:56.389374: step 111860, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 13h:31m:07s remains)
INFO - root - 2017-12-16 21:38:58.603989: step 111870, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 13h:20m:57s remains)
INFO - root - 2017-12-16 21:39:00.820962: step 111880, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 13h:20m:59s remains)
INFO - root - 2017-12-16 21:39:03.026532: step 111890, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 13h:25m:17s remains)
INFO - root - 2017-12-16 21:39:05.247190: step 111900, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 13h:47m:33s remains)
INFO - root - 2017-12-16 21:39:07.568102: step 111910, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 13h:05m:49s remains)
INFO - root - 2017-12-16 21:39:09.799210: step 111920, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 14h:04m:17s remains)
INFO - root - 2017-12-16 21:39:11.982076: step 111930, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 13h:20m:29s remains)
INFO - root - 2017-12-16 21:39:14.165940: step 111940, loss = 0.41, batch loss = 0.23 (36.4 examples/sec; 0.220 sec/batch; 13h:27m:05s remains)
INFO - root - 2017-12-16 21:39:16.343404: step 111950, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 13h:35m:57s remains)
INFO - root - 2017-12-16 21:39:18.572264: step 111960, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 13h:30m:27s remains)
INFO - root - 2017-12-16 21:39:20.787241: step 111970, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 13h:09m:47s remains)
INFO - root - 2017-12-16 21:39:23.005080: step 111980, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 13h:57m:36s remains)
INFO - root - 2017-12-16 21:39:25.221862: step 111990, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 13h:28m:32s remains)
INFO - root - 2017-12-16 21:39:27.406918: step 112000, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 13h:04m:02s remains)
INFO - root - 2017-12-16 21:39:29.738782: step 112010, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 13h:56m:51s remains)
INFO - root - 2017-12-16 21:39:31.984116: step 112020, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 13h:26m:49s remains)
INFO - root - 2017-12-16 21:39:34.185529: step 112030, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 13h:16m:36s remains)
INFO - root - 2017-12-16 21:39:36.367989: step 112040, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 13h:35m:49s remains)
INFO - root - 2017-12-16 21:39:38.595223: step 112050, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 13h:13m:27s remains)
INFO - root - 2017-12-16 21:39:40.809560: step 112060, loss = 0.44, batch loss = 0.26 (38.4 examples/sec; 0.209 sec/batch; 12h:46m:10s remains)
INFO - root - 2017-12-16 21:39:43.068100: step 112070, loss = 0.49, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 13h:22m:49s remains)
INFO - root - 2017-12-16 21:39:45.280831: step 112080, loss = 0.53, batch loss = 0.35 (35.8 examples/sec; 0.223 sec/batch; 13h:39m:57s remains)
INFO - root - 2017-12-16 21:39:47.462407: step 112090, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 13h:13m:55s remains)
INFO - root - 2017-12-16 21:39:49.702153: step 112100, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 13h:58m:10s remains)
INFO - root - 2017-12-16 21:39:52.068762: step 112110, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 13h:37m:11s remains)
INFO - root - 2017-12-16 21:39:54.287893: step 112120, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 13h:17m:33s remains)
INFO - root - 2017-12-16 21:39:56.470284: step 112130, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 13h:22m:22s remains)
INFO - root - 2017-12-16 21:39:58.684677: step 112140, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 13h:41m:06s remains)
INFO - root - 2017-12-16 21:40:00.926023: step 112150, loss = 0.51, batch loss = 0.33 (33.4 examples/sec; 0.239 sec/batch; 14h:38m:57s remains)
INFO - root - 2017-12-16 21:40:03.133725: step 112160, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 13h:37m:58s remains)
INFO - root - 2017-12-16 21:40:05.368265: step 112170, loss = 0.47, batch loss = 0.29 (38.0 examples/sec; 0.211 sec/batch; 12h:53m:36s remains)
INFO - root - 2017-12-16 21:40:07.597502: step 112180, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 13h:16m:10s remains)
INFO - root - 2017-12-16 21:40:09.830324: step 112190, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 14h:11m:52s remains)
INFO - root - 2017-12-16 21:40:12.021320: step 112200, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 12h:59m:12s remains)
INFO - root - 2017-12-16 21:40:14.320535: step 112210, loss = 0.52, batch loss = 0.34 (37.6 examples/sec; 0.213 sec/batch; 13h:00m:26s remains)
INFO - root - 2017-12-16 21:40:16.498701: step 112220, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 13h:15m:04s remains)
INFO - root - 2017-12-16 21:40:18.694404: step 112230, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 13h:21m:16s remains)
INFO - root - 2017-12-16 21:40:20.939396: step 112240, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 13h:23m:35s remains)
INFO - root - 2017-12-16 21:40:23.162552: step 112250, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 14h:07m:38s remains)
INFO - root - 2017-12-16 21:40:25.372806: step 112260, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 13h:05m:09s remains)
INFO - root - 2017-12-16 21:40:27.591546: step 112270, loss = 0.50, batch loss = 0.32 (34.7 examples/sec; 0.230 sec/batch; 14h:05m:49s remains)
INFO - root - 2017-12-16 21:40:29.849559: step 112280, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 13h:33m:37s remains)
INFO - root - 2017-12-16 21:40:32.059433: step 112290, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 13h:23m:05s remains)
INFO - root - 2017-12-16 21:40:34.275238: step 112300, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 13h:20m:38s remains)
INFO - root - 2017-12-16 21:40:36.634241: step 112310, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 13h:26m:27s remains)
INFO - root - 2017-12-16 21:40:38.845441: step 112320, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 13h:44m:35s remains)
INFO - root - 2017-12-16 21:40:41.024267: step 112330, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 13h:33m:57s remains)
INFO - root - 2017-12-16 21:40:43.222415: step 112340, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.228 sec/batch; 13h:58m:05s remains)
INFO - root - 2017-12-16 21:40:45.474897: step 112350, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 13h:20m:24s remains)
INFO - root - 2017-12-16 21:40:47.680326: step 112360, loss = 0.46, batch loss = 0.28 (38.0 examples/sec; 0.210 sec/batch; 12h:51m:44s remains)
INFO - root - 2017-12-16 21:40:49.861855: step 112370, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 13h:30m:06s remains)
INFO - root - 2017-12-16 21:40:52.039743: step 112380, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 13h:12m:35s remains)
INFO - root - 2017-12-16 21:40:54.279709: step 112390, loss = 0.50, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 13h:19m:47s remains)
INFO - root - 2017-12-16 21:40:56.499983: step 112400, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 13h:31m:38s remains)
INFO - root - 2017-12-16 21:40:58.896471: step 112410, loss = 0.46, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 13h:14m:13s remains)
INFO - root - 2017-12-16 21:41:01.109898: step 112420, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 13h:27m:20s remains)
INFO - root - 2017-12-16 21:41:03.347716: step 112430, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 13h:26m:37s remains)
INFO - root - 2017-12-16 21:41:05.555679: step 112440, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 13h:24m:49s remains)
INFO - root - 2017-12-16 21:41:07.769459: step 112450, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 13h:18m:09s remains)
INFO - root - 2017-12-16 21:41:09.942820: step 112460, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 13h:04m:56s remains)
INFO - root - 2017-12-16 21:41:12.173187: step 112470, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 13h:44m:46s remains)
INFO - root - 2017-12-16 21:41:14.383671: step 112480, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 13h:28m:12s remains)
INFO - root - 2017-12-16 21:41:16.644489: step 112490, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 13h:36m:54s remains)
INFO - root - 2017-12-16 21:41:18.879048: step 112500, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 13h:51m:06s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-112500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-112500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 21:41:21.717284: step 112510, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.218 sec/batch; 13h:20m:49s remains)
INFO - root - 2017-12-16 21:41:23.933817: step 112520, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 13h:29m:33s remains)
INFO - root - 2017-12-16 21:41:26.160734: step 112530, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 13h:44m:43s remains)
INFO - root - 2017-12-16 21:41:28.386391: step 112540, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 13h:27m:34s remains)
INFO - root - 2017-12-16 21:41:30.583811: step 112550, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 13h:51m:05s remains)
INFO - root - 2017-12-16 21:41:32.812251: step 112560, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 14h:02m:31s remains)
INFO - root - 2017-12-16 21:41:34.978373: step 112570, loss = 0.44, batch loss = 0.27 (37.6 examples/sec; 0.213 sec/batch; 13h:00m:54s remains)
INFO - root - 2017-12-16 21:41:37.193455: step 112580, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 13h:19m:40s remains)
INFO - root - 2017-12-16 21:41:39.391936: step 112590, loss = 0.42, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 13h:50m:49s remains)
INFO - root - 2017-12-16 21:41:41.627780: step 112600, loss = 0.49, batch loss = 0.31 (34.7 examples/sec; 0.231 sec/batch; 14h:04m:58s remains)
INFO - root - 2017-12-16 21:41:43.964174: step 112610, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 13h:08m:45s remains)
INFO - root - 2017-12-16 21:41:46.210374: step 112620, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 13h:41m:52s remains)
INFO - root - 2017-12-16 21:41:48.410023: step 112630, loss = 0.55, batch loss = 0.37 (37.2 examples/sec; 0.215 sec/batch; 13h:07m:10s remains)
INFO - root - 2017-12-16 21:41:50.586754: step 112640, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 13h:07m:04s remains)
INFO - root - 2017-12-16 21:41:52.824112: step 112650, loss = 0.44, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 13h:29m:48s remains)
INFO - root - 2017-12-16 21:41:55.033855: step 112660, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 13h:17m:47s remains)
INFO - root - 2017-12-16 21:41:57.222010: step 112670, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 13h:08m:37s remains)
INFO - root - 2017-12-16 21:41:59.407074: step 112680, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 13h:33m:42s remains)
INFO - root - 2017-12-16 21:42:01.607819: step 112690, loss = 0.47, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 13h:06m:58s remains)
INFO - root - 2017-12-16 21:42:03.792810: step 112700, loss = 0.41, batch loss = 0.23 (36.8 examples/sec; 0.217 sec/batch; 13h:15m:35s remains)
INFO - root - 2017-12-16 21:42:06.119489: step 112710, loss = 0.59, batch loss = 0.41 (36.3 examples/sec; 0.220 sec/batch; 13h:26m:52s remains)
INFO - root - 2017-12-16 21:42:08.326952: step 112720, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 13h:36m:05s remains)
INFO - root - 2017-12-16 21:42:10.550794: step 112730, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 13h:25m:37s remains)
INFO - root - 2017-12-16 21:42:12.746777: step 112740, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 13h:33m:01s remains)
INFO - root - 2017-12-16 21:42:14.973350: step 112750, loss = 0.47, batch loss = 0.29 (34.0 examples/sec; 0.235 sec/batch; 14h:21m:09s remains)
INFO - root - 2017-12-16 21:42:17.186822: step 112760, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 13h:45m:18s remains)
INFO - root - 2017-12-16 21:42:19.398457: step 112770, loss = 0.44, batch loss = 0.27 (34.1 examples/sec; 0.234 sec/batch; 14h:18m:07s remains)
INFO - root - 2017-12-16 21:42:21.622433: step 112780, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 13h:16m:57s remains)
INFO - root - 2017-12-16 21:42:23.863182: step 112790, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 13h:31m:52s remains)
INFO - root - 2017-12-16 21:42:26.085445: step 112800, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 13h:15m:55s remains)
INFO - root - 2017-12-16 21:42:28.477667: step 112810, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 13h:35m:15s remains)
INFO - root - 2017-12-16 21:42:30.654978: step 112820, loss = 0.46, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 13h:00m:37s remains)
INFO - root - 2017-12-16 21:42:32.889668: step 112830, loss = 0.41, batch loss = 0.23 (35.2 examples/sec; 0.227 sec/batch; 13h:52m:42s remains)
INFO - root - 2017-12-16 21:42:35.098635: step 112840, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 13h:13m:49s remains)
INFO - root - 2017-12-16 21:42:37.334224: step 112850, loss = 0.53, batch loss = 0.35 (35.5 examples/sec; 0.225 sec/batch; 13h:43m:52s remains)
INFO - root - 2017-12-16 21:42:39.522034: step 112860, loss = 0.49, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 13h:18m:01s remains)
INFO - root - 2017-12-16 21:42:41.753187: step 112870, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 13h:48m:12s remains)
INFO - root - 2017-12-16 21:42:43.985450: step 112880, loss = 0.42, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 13h:28m:27s remains)
INFO - root - 2017-12-16 21:42:46.193286: step 112890, loss = 0.46, batch loss = 0.28 (33.2 examples/sec; 0.241 sec/batch; 14h:42m:14s remains)
INFO - root - 2017-12-16 21:42:48.426876: step 112900, loss = 0.50, batch loss = 0.33 (35.5 examples/sec; 0.226 sec/batch; 13h:45m:22s remains)
INFO - root - 2017-12-16 21:42:50.757863: step 112910, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 13h:23m:41s remains)
INFO - root - 2017-12-16 21:42:52.963226: step 112920, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 13h:24m:04s remains)
INFO - root - 2017-12-16 21:42:55.179296: step 112930, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 13h:15m:17s remains)
INFO - root - 2017-12-16 21:42:57.383091: step 112940, loss = 0.46, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 13h:39m:57s remains)
INFO - root - 2017-12-16 21:42:59.614338: step 112950, loss = 0.41, batch loss = 0.24 (37.3 examples/sec; 0.215 sec/batch; 13h:05m:41s remains)
INFO - root - 2017-12-16 21:43:01.824584: step 112960, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 13h:27m:59s remains)
INFO - root - 2017-12-16 21:43:04.040080: step 112970, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.228 sec/batch; 13h:55m:22s remains)
INFO - root - 2017-12-16 21:43:06.219616: step 112980, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 13h:34m:59s remains)
INFO - root - 2017-12-16 21:43:08.486100: step 112990, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.231 sec/batch; 14h:03m:33s remains)
INFO - root - 2017-12-16 21:43:10.737726: step 113000, loss = 0.46, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 13h:37m:58s remains)
INFO - root - 2017-12-16 21:43:13.079311: step 113010, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 13h:27m:17s remains)
INFO - root - 2017-12-16 21:43:15.331265: step 113020, loss = 0.53, batch loss = 0.35 (35.2 examples/sec; 0.227 sec/batch; 13h:50m:18s remains)
INFO - root - 2017-12-16 21:43:17.539727: step 113030, loss = 0.49, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 13h:31m:34s remains)
INFO - root - 2017-12-16 21:43:19.749695: step 113040, loss = 0.51, batch loss = 0.33 (33.5 examples/sec; 0.239 sec/batch; 14h:32m:54s remains)
INFO - root - 2017-12-16 21:43:21.976633: step 113050, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 13h:48m:15s remains)
INFO - root - 2017-12-16 21:43:24.184333: step 113060, loss = 0.61, batch loss = 0.43 (37.0 examples/sec; 0.216 sec/batch; 13h:11m:40s remains)
INFO - root - 2017-12-16 21:43:26.414665: step 113070, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 13h:29m:23s remains)
INFO - root - 2017-12-16 21:43:28.665770: step 113080, loss = 0.54, batch loss = 0.36 (35.1 examples/sec; 0.228 sec/batch; 13h:53m:59s remains)
INFO - root - 2017-12-16 21:43:30.872243: step 113090, loss = 0.57, batch loss = 0.39 (36.6 examples/sec; 0.219 sec/batch; 13h:19m:18s remains)
INFO - root - 2017-12-16 21:43:33.098768: step 113100, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 13h:33m:20s remains)
INFO - root - 2017-12-16 21:43:35.466301: step 113110, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 13h:49m:26s remains)
INFO - root - 2017-12-16 21:43:37.650500: step 113120, loss = 0.52, batch loss = 0.34 (35.2 examples/sec; 0.228 sec/batch; 13h:52m:04s remains)
INFO - root - 2017-12-16 21:43:39.858745: step 113130, loss = 0.51, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 13h:31m:02s remains)
INFO - root - 2017-12-16 21:43:42.039701: step 113140, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 13h:10m:59s remains)
INFO - root - 2017-12-16 21:43:44.229885: step 113150, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 13h:11m:55s remains)
INFO - root - 2017-12-16 21:43:46.471569: step 113160, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 13h:28m:25s remains)
INFO - root - 2017-12-16 21:43:48.695123: step 113170, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 13h:46m:36s remains)
INFO - root - 2017-12-16 21:43:50.916251: step 113180, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 13h:42m:26s remains)
INFO - root - 2017-12-16 21:43:53.125732: step 113190, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 13h:13m:57s remains)
INFO - root - 2017-12-16 21:43:55.377960: step 113200, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 13h:17m:54s remains)
INFO - root - 2017-12-16 21:43:57.685752: step 113210, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 13h:19m:50s remains)
INFO - root - 2017-12-16 21:43:59.903524: step 113220, loss = 0.44, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 12h:57m:50s remains)
INFO - root - 2017-12-16 21:44:02.128792: step 113230, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 13h:06m:00s remains)
INFO - root - 2017-12-16 21:44:04.347917: step 113240, loss = 0.45, batch loss = 0.27 (34.2 examples/sec; 0.234 sec/batch; 14h:14m:06s remains)
INFO - root - 2017-12-16 21:44:06.582982: step 113250, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 13h:23m:31s remains)
INFO - root - 2017-12-16 21:44:08.841627: step 113260, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 13h:51m:40s remains)
INFO - root - 2017-12-16 21:44:11.072588: step 113270, loss = 0.50, batch loss = 0.32 (34.0 examples/sec; 0.235 sec/batch; 14h:19m:36s remains)
INFO - root - 2017-12-16 21:44:13.248423: step 113280, loss = 0.43, batch loss = 0.25 (37.5 examples/sec; 0.214 sec/batch; 13h:00m:14s remains)
INFO - root - 2017-12-16 21:44:15.473591: step 113290, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 13h:12m:10s remains)
INFO - root - 2017-12-16 21:44:17.718854: step 113300, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 13h:13m:38s remains)
INFO - root - 2017-12-16 21:44:20.047673: step 113310, loss = 0.53, batch loss = 0.35 (37.6 examples/sec; 0.212 sec/batch; 12h:56m:16s remains)
INFO - root - 2017-12-16 21:44:22.259053: step 113320, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 13h:04m:30s remains)
INFO - root - 2017-12-16 21:44:24.505633: step 113330, loss = 0.60, batch loss = 0.42 (36.6 examples/sec; 0.218 sec/batch; 13h:17m:24s remains)
INFO - root - 2017-12-16 21:44:26.763957: step 113340, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 12h:57m:26s remains)
INFO - root - 2017-12-16 21:44:28.982136: step 113350, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 13h:29m:15s remains)
INFO - root - 2017-12-16 21:44:31.192121: step 113360, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 13h:59m:54s remains)
INFO - root - 2017-12-16 21:44:33.426001: step 113370, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 13h:24m:25s remains)
INFO - root - 2017-12-16 21:44:35.637038: step 113380, loss = 0.42, batch loss = 0.25 (37.6 examples/sec; 0.213 sec/batch; 12h:56m:11s remains)
INFO - root - 2017-12-16 21:44:37.877389: step 113390, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 13h:13m:14s remains)
INFO - root - 2017-12-16 21:44:40.087032: step 113400, loss = 0.57, batch loss = 0.39 (36.3 examples/sec; 0.220 sec/batch; 13h:24m:30s remains)
INFO - root - 2017-12-16 21:44:42.402936: step 113410, loss = 0.56, batch loss = 0.38 (37.1 examples/sec; 0.216 sec/batch; 13h:07m:47s remains)
INFO - root - 2017-12-16 21:44:44.611374: step 113420, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 13h:11m:15s remains)
INFO - root - 2017-12-16 21:44:46.841942: step 113430, loss = 0.42, batch loss = 0.24 (37.0 examples/sec; 0.216 sec/batch; 13h:09m:20s remains)
INFO - root - 2017-12-16 21:44:49.069344: step 113440, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 13h:27m:50s remains)
INFO - root - 2017-12-16 21:44:51.322938: step 113450, loss = 0.43, batch loss = 0.25 (34.6 examples/sec; 0.231 sec/batch; 14h:04m:52s remains)
INFO - root - 2017-12-16 21:44:53.537291: step 113460, loss = 0.49, batch loss = 0.32 (37.1 examples/sec; 0.215 sec/batch; 13h:06m:11s remains)
INFO - root - 2017-12-16 21:44:55.735994: step 113470, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 13h:11m:27s remains)
INFO - root - 2017-12-16 21:44:57.968941: step 113480, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 13h:36m:15s remains)
INFO - root - 2017-12-16 21:45:00.192045: step 113490, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 13h:38m:24s remains)
INFO - root - 2017-12-16 21:45:02.418859: step 113500, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 13h:55m:19s remains)
INFO - root - 2017-12-16 21:45:04.755276: step 113510, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 13h:35m:04s remains)
INFO - root - 2017-12-16 21:45:07.024865: step 113520, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 13h:33m:09s remains)
INFO - root - 2017-12-16 21:45:09.261720: step 113530, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 13h:24m:08s remains)
INFO - root - 2017-12-16 21:45:11.480944: step 113540, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 13h:25m:30s remains)
INFO - root - 2017-12-16 21:45:13.683922: step 113550, loss = 0.47, batch loss = 0.29 (37.9 examples/sec; 0.211 sec/batch; 12h:51m:06s remains)
INFO - root - 2017-12-16 21:45:15.935697: step 113560, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 13h:14m:09s remains)
INFO - root - 2017-12-16 21:45:18.163870: step 113570, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 13h:32m:37s remains)
INFO - root - 2017-12-16 21:45:20.418632: step 113580, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 13h:41m:16s remains)
INFO - root - 2017-12-16 21:45:22.629718: step 113590, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 13h:47m:57s remains)
INFO - root - 2017-12-16 21:45:24.864123: step 113600, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 13h:27m:07s remains)
INFO - root - 2017-12-16 21:45:27.225193: step 113610, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 13h:25m:05s remains)
INFO - root - 2017-12-16 21:45:29.430387: step 113620, loss = 0.42, batch loss = 0.24 (36.5 examples/sec; 0.219 sec/batch; 13h:18m:58s remains)
INFO - root - 2017-12-16 21:45:31.634805: step 113630, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 13h:13m:04s remains)
INFO - root - 2017-12-16 21:45:33.881379: step 113640, loss = 0.53, batch loss = 0.35 (35.4 examples/sec; 0.226 sec/batch; 13h:43m:16s remains)
INFO - root - 2017-12-16 21:45:36.072722: step 113650, loss = 0.53, batch loss = 0.36 (37.1 examples/sec; 0.216 sec/batch; 13h:07m:30s remains)
INFO - root - 2017-12-16 21:45:38.328429: step 113660, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 13h:28m:38s remains)
INFO - root - 2017-12-16 21:45:40.556284: step 113670, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 13h:19m:58s remains)
INFO - root - 2017-12-16 21:45:42.755148: step 113680, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 13h:29m:15s remains)
INFO - root - 2017-12-16 21:45:44.974232: step 113690, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 13h:18m:26s remains)
INFO - root - 2017-12-16 21:45:47.176860: step 113700, loss = 0.50, batch loss = 0.33 (35.6 examples/sec; 0.224 sec/batch; 13h:38m:20s remains)
INFO - root - 2017-12-16 21:45:49.522232: step 113710, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.228 sec/batch; 13h:53m:13s remains)
INFO - root - 2017-12-16 21:45:51.734191: step 113720, loss = 0.46, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 12h:54m:04s remains)
INFO - root - 2017-12-16 21:45:53.951117: step 113730, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 13h:28m:43s remains)
INFO - root - 2017-12-16 21:45:56.176555: step 113740, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 13h:24m:40s remains)
INFO - root - 2017-12-16 21:45:58.378824: step 113750, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 13h:28m:59s remains)
INFO - root - 2017-12-16 21:46:00.605490: step 113760, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 13h:16m:13s remains)
INFO - root - 2017-12-16 21:46:02.813372: step 113770, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.219 sec/batch; 13h:20m:07s remains)
INFO - root - 2017-12-16 21:46:04.995663: step 113780, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 13h:25m:11s remains)
INFO - root - 2017-12-16 21:46:07.205542: step 113790, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 13h:43m:07s remains)
INFO - root - 2017-12-16 21:46:09.449930: step 113800, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 13h:16m:26s remains)
INFO - root - 2017-12-16 21:46:11.789426: step 113810, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 13h:33m:09s remains)
INFO - root - 2017-12-16 21:46:14.027103: step 113820, loss = 0.54, batch loss = 0.36 (34.4 examples/sec; 0.232 sec/batch; 14h:06m:29s remains)
INFO - root - 2017-12-16 21:46:16.208977: step 113830, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 13h:14m:50s remains)
INFO - root - 2017-12-16 21:46:18.411247: step 113840, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 13h:22m:34s remains)
INFO - root - 2017-12-16 21:46:20.623015: step 113850, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 13h:40m:15s remains)
INFO - root - 2017-12-16 21:46:22.863536: step 113860, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.214 sec/batch; 13h:00m:40s remains)
INFO - root - 2017-12-16 21:46:25.110755: step 113870, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 13h:16m:30s remains)
INFO - root - 2017-12-16 21:46:27.358054: step 113880, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 13h:09m:45s remains)
INFO - root - 2017-12-16 21:46:29.559688: step 113890, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 13h:40m:58s remains)
INFO - root - 2017-12-16 21:46:31.782014: step 113900, loss = 0.48, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 13h:14m:08s remains)
INFO - root - 2017-12-16 21:46:34.121629: step 113910, loss = 0.52, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 13h:06m:55s remains)
INFO - root - 2017-12-16 21:46:36.291015: step 113920, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 13h:18m:56s remains)
INFO - root - 2017-12-16 21:46:38.503045: step 113930, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 13h:25m:13s remains)
INFO - root - 2017-12-16 21:46:40.790815: step 113940, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 13h:36m:23s remains)
INFO - root - 2017-12-16 21:46:42.974731: step 113950, loss = 0.47, batch loss = 0.29 (37.9 examples/sec; 0.211 sec/batch; 12h:48m:14s remains)
INFO - root - 2017-12-16 21:46:45.213979: step 113960, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 13h:36m:22s remains)
INFO - root - 2017-12-16 21:46:47.447359: step 113970, loss = 0.41, batch loss = 0.23 (34.7 examples/sec; 0.230 sec/batch; 13h:59m:23s remains)
INFO - root - 2017-12-16 21:46:49.670323: step 113980, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 13h:14m:53s remains)
INFO - root - 2017-12-16 21:46:51.878976: step 113990, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 13h:05m:25s remains)
INFO - root - 2017-12-16 21:46:54.086052: step 114000, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 13h:11m:17s remains)
INFO - root - 2017-12-16 21:46:56.429509: step 114010, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 13h:40m:33s remains)
INFO - root - 2017-12-16 21:46:58.657601: step 114020, loss = 0.41, batch loss = 0.23 (36.8 examples/sec; 0.217 sec/batch; 13h:11m:28s remains)
INFO - root - 2017-12-16 21:47:00.853573: step 114030, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 13h:12m:43s remains)
INFO - root - 2017-12-16 21:47:03.089663: step 114040, loss = 0.49, batch loss = 0.31 (33.9 examples/sec; 0.236 sec/batch; 14h:19m:38s remains)
INFO - root - 2017-12-16 21:47:05.289109: step 114050, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 13h:28m:30s remains)
INFO - root - 2017-12-16 21:47:07.470097: step 114060, loss = 0.52, batch loss = 0.34 (33.2 examples/sec; 0.241 sec/batch; 14h:37m:34s remains)
INFO - root - 2017-12-16 21:47:09.677663: step 114070, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 13h:15m:03s remains)
INFO - root - 2017-12-16 21:47:11.889036: step 114080, loss = 0.50, batch loss = 0.32 (37.5 examples/sec; 0.213 sec/batch; 12h:56m:03s remains)
INFO - root - 2017-12-16 21:47:14.111933: step 114090, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 13h:10m:31s remains)
INFO - root - 2017-12-16 21:47:16.305162: step 114100, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 12h:58m:23s remains)
INFO - root - 2017-12-16 21:47:18.652149: step 114110, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 13h:05m:33s remains)
INFO - root - 2017-12-16 21:47:20.894311: step 114120, loss = 0.56, batch loss = 0.38 (37.0 examples/sec; 0.216 sec/batch; 13h:05m:55s remains)
INFO - root - 2017-12-16 21:47:23.112688: step 114130, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 13h:00m:24s remains)
INFO - root - 2017-12-16 21:47:25.336227: step 114140, loss = 0.48, batch loss = 0.31 (37.1 examples/sec; 0.215 sec/batch; 13h:04m:04s remains)
INFO - root - 2017-12-16 21:47:27.531819: step 114150, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 13h:14m:48s remains)
INFO - root - 2017-12-16 21:47:29.721179: step 114160, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 13h:09m:32s remains)
INFO - root - 2017-12-16 21:47:31.985314: step 114170, loss = 0.56, batch loss = 0.38 (36.2 examples/sec; 0.221 sec/batch; 13h:25m:16s remains)
INFO - root - 2017-12-16 21:47:34.226240: step 114180, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 13h:47m:26s remains)
INFO - root - 2017-12-16 21:47:36.429713: step 114190, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 13h:38m:37s remains)
INFO - root - 2017-12-16 21:47:38.693590: step 114200, loss = 0.46, batch loss = 0.28 (34.0 examples/sec; 0.236 sec/batch; 14h:17m:09s remains)
INFO - root - 2017-12-16 21:47:41.116262: step 114210, loss = 0.46, batch loss = 0.28 (34.4 examples/sec; 0.232 sec/batch; 14h:05m:43s remains)
INFO - root - 2017-12-16 21:47:43.363185: step 114220, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.226 sec/batch; 13h:40m:22s remains)
INFO - root - 2017-12-16 21:47:45.576030: step 114230, loss = 0.48, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 13h:15m:43s remains)
INFO - root - 2017-12-16 21:47:47.834853: step 114240, loss = 0.49, batch loss = 0.32 (34.2 examples/sec; 0.234 sec/batch; 14h:11m:42s remains)
INFO - root - 2017-12-16 21:47:50.056342: step 114250, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 13h:48m:42s remains)
INFO - root - 2017-12-16 21:47:52.284645: step 114260, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 13h:20m:05s remains)
INFO - root - 2017-12-16 21:47:54.481338: step 114270, loss = 0.45, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 13h:42m:36s remains)
INFO - root - 2017-12-16 21:47:56.719765: step 114280, loss = 0.47, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 13h:30m:29s remains)
INFO - root - 2017-12-16 21:47:58.914680: step 114290, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 13h:28m:34s remains)
INFO - root - 2017-12-16 21:48:01.135322: step 114300, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 13h:20m:08s remains)
INFO - root - 2017-12-16 21:48:03.524484: step 114310, loss = 0.48, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 13h:12m:09s remains)
INFO - root - 2017-12-16 21:48:05.784991: step 114320, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 13h:27m:43s remains)
INFO - root - 2017-12-16 21:48:07.999385: step 114330, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 13h:33m:09s remains)
INFO - root - 2017-12-16 21:48:10.241484: step 114340, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 13h:22m:25s remains)
INFO - root - 2017-12-16 21:48:12.426663: step 114350, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 13h:31m:25s remains)
INFO - root - 2017-12-16 21:48:14.692125: step 114360, loss = 0.48, batch loss = 0.31 (34.5 examples/sec; 0.232 sec/batch; 14h:03m:44s remains)
INFO - root - 2017-12-16 21:48:16.905656: step 114370, loss = 0.45, batch loss = 0.27 (37.6 examples/sec; 0.213 sec/batch; 12h:54m:23s remains)
INFO - root - 2017-12-16 21:48:19.182816: step 114380, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.228 sec/batch; 13h:50m:37s remains)
INFO - root - 2017-12-16 21:48:21.441028: step 114390, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 13h:43m:50s remains)
INFO - root - 2017-12-16 21:48:23.699760: step 114400, loss = 0.53, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 13h:34m:59s remains)
INFO - root - 2017-12-16 21:48:26.060279: step 114410, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 13h:34m:06s remains)
INFO - root - 2017-12-16 21:48:28.296130: step 114420, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.221 sec/batch; 13h:22m:06s remains)
INFO - root - 2017-12-16 21:48:30.507964: step 114430, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 13h:38m:04s remains)
INFO - root - 2017-12-16 21:48:32.747179: step 114440, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.226 sec/batch; 13h:42m:53s remains)
INFO - root - 2017-12-16 21:48:34.964635: step 114450, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 13h:31m:53s remains)
INFO - root - 2017-12-16 21:48:37.162875: step 114460, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 13h:00m:49s remains)
INFO - root - 2017-12-16 21:48:39.393238: step 114470, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 13h:41m:38s remains)
INFO - root - 2017-12-16 21:48:41.616088: step 114480, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.215 sec/batch; 13h:02m:41s remains)
INFO - root - 2017-12-16 21:48:43.820144: step 114490, loss = 0.42, batch loss = 0.24 (35.4 examples/sec; 0.226 sec/batch; 13h:40m:34s remains)
INFO - root - 2017-12-16 21:48:46.030755: step 114500, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.214 sec/batch; 12h:55m:51s remains)
INFO - root - 2017-12-16 21:48:48.360744: step 114510, loss = 0.45, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 12h:54m:01s remains)
INFO - root - 2017-12-16 21:48:50.616569: step 114520, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 13h:39m:30s remains)
INFO - root - 2017-12-16 21:48:52.840785: step 114530, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 13h:28m:09s remains)
INFO - root - 2017-12-16 21:48:55.025096: step 114540, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 13h:25m:56s remains)
INFO - root - 2017-12-16 21:48:57.217872: step 114550, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 13h:07m:53s remains)
INFO - root - 2017-12-16 21:48:59.413639: step 114560, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 13h:11m:54s remains)
INFO - root - 2017-12-16 21:49:01.607100: step 114570, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 12h:52m:54s remains)
INFO - root - 2017-12-16 21:49:03.825214: step 114580, loss = 0.56, batch loss = 0.38 (36.9 examples/sec; 0.217 sec/batch; 13h:07m:50s remains)
INFO - root - 2017-12-16 21:49:06.096320: step 114590, loss = 0.56, batch loss = 0.38 (36.4 examples/sec; 0.220 sec/batch; 13h:17m:54s remains)
INFO - root - 2017-12-16 21:49:08.292946: step 114600, loss = 0.52, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 13h:00m:56s remains)
INFO - root - 2017-12-16 21:49:10.639197: step 114610, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 13h:00m:54s remains)
INFO - root - 2017-12-16 21:49:12.861822: step 114620, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 13h:07m:54s remains)
INFO - root - 2017-12-16 21:49:15.070378: step 114630, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 13h:16m:52s remains)
INFO - root - 2017-12-16 21:49:17.278499: step 114640, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 13h:00m:32s remains)
INFO - root - 2017-12-16 21:49:19.502992: step 114650, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 13h:38m:53s remains)
INFO - root - 2017-12-16 21:49:21.669324: step 114660, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 13h:01m:45s remains)
INFO - root - 2017-12-16 21:49:23.878056: step 114670, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 13h:12m:08s remains)
INFO - root - 2017-12-16 21:49:26.104589: step 114680, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 13h:31m:04s remains)
INFO - root - 2017-12-16 21:49:28.296137: step 114690, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.215 sec/batch; 12h:59m:24s remains)
INFO - root - 2017-12-16 21:49:30.493331: step 114700, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 13h:00m:14s remains)
INFO - root - 2017-12-16 21:49:32.810556: step 114710, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 13h:29m:50s remains)
INFO - root - 2017-12-16 21:49:34.979166: step 114720, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.214 sec/batch; 12h:55m:00s remains)
INFO - root - 2017-12-16 21:49:37.246737: step 114730, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 13h:16m:12s remains)
INFO - root - 2017-12-16 21:49:39.487848: step 114740, loss = 0.50, batch loss = 0.32 (33.7 examples/sec; 0.237 sec/batch; 14h:21m:39s remains)
INFO - root - 2017-12-16 21:49:41.713974: step 114750, loss = 0.42, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 13h:16m:09s remains)
INFO - root - 2017-12-16 21:49:43.933334: step 114760, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 13h:20m:21s remains)
INFO - root - 2017-12-16 21:49:46.161666: step 114770, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 13h:48m:14s remains)
INFO - root - 2017-12-16 21:49:48.407187: step 114780, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 13h:04m:25s remains)
INFO - root - 2017-12-16 21:49:50.603511: step 114790, loss = 0.45, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 13h:08m:03s remains)
INFO - root - 2017-12-16 21:49:52.807147: step 114800, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 13h:18m:59s remains)
INFO - root - 2017-12-16 21:49:55.163698: step 114810, loss = 0.50, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 13h:51m:05s remains)
INFO - root - 2017-12-16 21:49:57.387319: step 114820, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 13h:42m:30s remains)
INFO - root - 2017-12-16 21:49:59.591956: step 114830, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 13h:46m:55s remains)
INFO - root - 2017-12-16 21:50:01.797331: step 114840, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 13h:02m:49s remains)
INFO - root - 2017-12-16 21:50:03.984316: step 114850, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 13h:24m:03s remains)
INFO - root - 2017-12-16 21:50:06.178407: step 114860, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 12h:58m:30s remains)
INFO - root - 2017-12-16 21:50:08.454613: step 114870, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 13h:51m:57s remains)
INFO - root - 2017-12-16 21:50:10.697839: step 114880, loss = 0.52, batch loss = 0.34 (34.9 examples/sec; 0.229 sec/batch; 13h:51m:14s remains)
INFO - root - 2017-12-16 21:50:12.894934: step 114890, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 13h:36m:27s remains)
INFO - root - 2017-12-16 21:50:15.133930: step 114900, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 13h:00m:28s remains)
INFO - root - 2017-12-16 21:50:17.492070: step 114910, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 13h:23m:47s remains)
INFO - root - 2017-12-16 21:50:19.723753: step 114920, loss = 0.48, batch loss = 0.31 (35.0 examples/sec; 0.229 sec/batch; 13h:49m:40s remains)
INFO - root - 2017-12-16 21:50:21.925742: step 114930, loss = 0.41, batch loss = 0.24 (36.5 examples/sec; 0.219 sec/batch; 13h:15m:27s remains)
INFO - root - 2017-12-16 21:50:24.150082: step 114940, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 13h:28m:16s remains)
INFO - root - 2017-12-16 21:50:26.381360: step 114950, loss = 0.53, batch loss = 0.35 (32.2 examples/sec; 0.248 sec/batch; 15h:00m:42s remains)
INFO - root - 2017-12-16 21:50:28.610751: step 114960, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 13h:35m:04s remains)
INFO - root - 2017-12-16 21:50:30.812913: step 114970, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 12h:59m:40s remains)
INFO - root - 2017-12-16 21:50:33.046219: step 114980, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 13h:18m:20s remains)
INFO - root - 2017-12-16 21:50:35.278617: step 114990, loss = 0.42, batch loss = 0.24 (35.2 examples/sec; 0.227 sec/batch; 13h:42m:52s remains)
INFO - root - 2017-12-16 21:50:37.501505: step 115000, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 13h:44m:33s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-115000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-115000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 21:50:40.641353: step 115010, loss = 0.51, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 13h:46m:28s remains)
INFO - root - 2017-12-16 21:50:42.852035: step 115020, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 13h:15m:05s remains)
INFO - root - 2017-12-16 21:50:45.086954: step 115030, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 13h:43m:50s remains)
INFO - root - 2017-12-16 21:50:47.344673: step 115040, loss = 0.54, batch loss = 0.36 (34.8 examples/sec; 0.230 sec/batch; 13h:52m:35s remains)
INFO - root - 2017-12-16 21:50:49.596741: step 115050, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 13h:48m:27s remains)
INFO - root - 2017-12-16 21:50:51.829594: step 115060, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 13h:25m:49s remains)
INFO - root - 2017-12-16 21:50:54.098538: step 115070, loss = 0.46, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 13h:05m:21s remains)
INFO - root - 2017-12-16 21:50:56.328248: step 115080, loss = 0.45, batch loss = 0.27 (34.2 examples/sec; 0.234 sec/batch; 14h:08m:28s remains)
INFO - root - 2017-12-16 21:50:58.536563: step 115090, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 13h:35m:18s remains)
INFO - root - 2017-12-16 21:51:00.749994: step 115100, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 13h:45m:48s remains)
INFO - root - 2017-12-16 21:51:03.101614: step 115110, loss = 0.50, batch loss = 0.32 (35.0 examples/sec; 0.228 sec/batch; 13h:47m:39s remains)
INFO - root - 2017-12-16 21:51:05.319161: step 115120, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 13h:25m:49s remains)
INFO - root - 2017-12-16 21:51:07.538092: step 115130, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 12h:56m:02s remains)
INFO - root - 2017-12-16 21:51:09.763602: step 115140, loss = 0.42, batch loss = 0.24 (33.7 examples/sec; 0.237 sec/batch; 14h:20m:14s remains)
INFO - root - 2017-12-16 21:51:11.996683: step 115150, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.218 sec/batch; 13h:11m:18s remains)
INFO - root - 2017-12-16 21:51:14.241212: step 115160, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 13h:23m:34s remains)
INFO - root - 2017-12-16 21:51:16.457804: step 115170, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 13h:23m:54s remains)
INFO - root - 2017-12-16 21:51:18.671530: step 115180, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 13h:32m:23s remains)
INFO - root - 2017-12-16 21:51:20.887883: step 115190, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 13h:14m:13s remains)
INFO - root - 2017-12-16 21:51:23.136088: step 115200, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 13h:38m:57s remains)
INFO - root - 2017-12-16 21:51:25.494390: step 115210, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 13h:02m:33s remains)
INFO - root - 2017-12-16 21:51:27.722398: step 115220, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 13h:28m:04s remains)
INFO - root - 2017-12-16 21:51:29.976182: step 115230, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 13h:35m:10s remains)
INFO - root - 2017-12-16 21:51:32.195407: step 115240, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 13h:27m:18s remains)
INFO - root - 2017-12-16 21:51:34.416013: step 115250, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.214 sec/batch; 12h:53m:11s remains)
INFO - root - 2017-12-16 21:51:36.629164: step 115260, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 13h:24m:45s remains)
INFO - root - 2017-12-16 21:51:38.846287: step 115270, loss = 0.55, batch loss = 0.37 (36.1 examples/sec; 0.221 sec/batch; 13h:21m:49s remains)
INFO - root - 2017-12-16 21:51:41.034002: step 115280, loss = 0.51, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 13h:11m:59s remains)
INFO - root - 2017-12-16 21:51:43.214106: step 115290, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 13h:29m:44s remains)
INFO - root - 2017-12-16 21:51:45.396448: step 115300, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 13h:15m:53s remains)
INFO - root - 2017-12-16 21:51:47.767480: step 115310, loss = 0.44, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 13h:31m:44s remains)
INFO - root - 2017-12-16 21:51:50.008755: step 115320, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 13h:26m:09s remains)
INFO - root - 2017-12-16 21:51:52.217315: step 115330, loss = 0.55, batch loss = 0.37 (38.1 examples/sec; 0.210 sec/batch; 12h:40m:29s remains)
INFO - root - 2017-12-16 21:51:54.450632: step 115340, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 12h:58m:20s remains)
INFO - root - 2017-12-16 21:51:56.676174: step 115350, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 13h:06m:03s remains)
INFO - root - 2017-12-16 21:51:58.894954: step 115360, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 13h:22m:02s remains)
INFO - root - 2017-12-16 21:52:01.122079: step 115370, loss = 0.44, batch loss = 0.26 (33.2 examples/sec; 0.241 sec/batch; 14h:33m:02s remains)
INFO - root - 2017-12-16 21:52:03.355096: step 115380, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 13h:04m:12s remains)
INFO - root - 2017-12-16 21:52:05.589704: step 115390, loss = 0.48, batch loss = 0.30 (34.0 examples/sec; 0.235 sec/batch; 14h:10m:21s remains)
INFO - root - 2017-12-16 21:52:07.806816: step 115400, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 13h:28m:31s remains)
INFO - root - 2017-12-16 21:52:10.175818: step 115410, loss = 0.45, batch loss = 0.28 (33.9 examples/sec; 0.236 sec/batch; 14h:13m:10s remains)
INFO - root - 2017-12-16 21:52:12.385782: step 115420, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 13h:20m:54s remains)
INFO - root - 2017-12-16 21:52:14.559559: step 115430, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 13h:06m:24s remains)
INFO - root - 2017-12-16 21:52:16.777349: step 115440, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 13h:23m:21s remains)
INFO - root - 2017-12-16 21:52:18.976122: step 115450, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 13h:40m:49s remains)
INFO - root - 2017-12-16 21:52:21.201173: step 115460, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 13h:45m:08s remains)
INFO - root - 2017-12-16 21:52:23.427134: step 115470, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 13h:36m:41s remains)
INFO - root - 2017-12-16 21:52:25.621674: step 115480, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 13h:02m:52s remains)
INFO - root - 2017-12-16 21:52:27.842259: step 115490, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 13h:08m:54s remains)
INFO - root - 2017-12-16 21:52:30.071323: step 115500, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 13h:33m:14s remains)
INFO - root - 2017-12-16 21:52:32.421063: step 115510, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 13h:14m:55s remains)
INFO - root - 2017-12-16 21:52:34.614628: step 115520, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 13h:11m:44s remains)
INFO - root - 2017-12-16 21:52:36.824435: step 115530, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 12h:54m:40s remains)
INFO - root - 2017-12-16 21:52:39.059703: step 115540, loss = 0.42, batch loss = 0.24 (37.5 examples/sec; 0.213 sec/batch; 12h:51m:30s remains)
INFO - root - 2017-12-16 21:52:41.242086: step 115550, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 13h:23m:14s remains)
INFO - root - 2017-12-16 21:52:43.424304: step 115560, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 13h:03m:01s remains)
INFO - root - 2017-12-16 21:52:45.634429: step 115570, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 13h:38m:29s remains)
INFO - root - 2017-12-16 21:52:47.868057: step 115580, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 13h:15m:57s remains)
INFO - root - 2017-12-16 21:52:50.101488: step 115590, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 13h:29m:08s remains)
INFO - root - 2017-12-16 21:52:52.305384: step 115600, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 13h:27m:14s remains)
INFO - root - 2017-12-16 21:52:54.638735: step 115610, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 13h:15m:18s remains)
INFO - root - 2017-12-16 21:52:56.846108: step 115620, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 13h:08m:49s remains)
INFO - root - 2017-12-16 21:52:59.052811: step 115630, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 13h:48m:37s remains)
INFO - root - 2017-12-16 21:53:01.265486: step 115640, loss = 0.54, batch loss = 0.36 (35.1 examples/sec; 0.228 sec/batch; 13h:44m:47s remains)
INFO - root - 2017-12-16 21:53:03.469029: step 115650, loss = 0.48, batch loss = 0.30 (33.5 examples/sec; 0.239 sec/batch; 14h:24m:22s remains)
INFO - root - 2017-12-16 21:53:05.718778: step 115660, loss = 0.44, batch loss = 0.26 (34.7 examples/sec; 0.231 sec/batch; 13h:53m:23s remains)
INFO - root - 2017-12-16 21:53:07.981324: step 115670, loss = 0.44, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 13h:12m:19s remains)
INFO - root - 2017-12-16 21:53:10.211081: step 115680, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 12h:59m:26s remains)
INFO - root - 2017-12-16 21:53:12.430801: step 115690, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 13h:12m:44s remains)
INFO - root - 2017-12-16 21:53:14.620415: step 115700, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 13h:35m:18s remains)
INFO - root - 2017-12-16 21:53:16.997533: step 115710, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 13h:23m:25s remains)
INFO - root - 2017-12-16 21:53:19.222082: step 115720, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 13h:00m:23s remains)
INFO - root - 2017-12-16 21:53:21.482263: step 115730, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 12h:59m:21s remains)
INFO - root - 2017-12-16 21:53:23.691869: step 115740, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 13h:40m:24s remains)
INFO - root - 2017-12-16 21:53:25.871465: step 115750, loss = 0.45, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 12h:51m:05s remains)
INFO - root - 2017-12-16 21:53:28.097632: step 115760, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 13h:06m:00s remains)
INFO - root - 2017-12-16 21:53:30.313560: step 115770, loss = 0.52, batch loss = 0.34 (37.5 examples/sec; 0.213 sec/batch; 12h:50m:16s remains)
INFO - root - 2017-12-16 21:53:32.554742: step 115780, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 13h:06m:22s remains)
INFO - root - 2017-12-16 21:53:34.733318: step 115790, loss = 0.47, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 13h:04m:58s remains)
INFO - root - 2017-12-16 21:53:36.977778: step 115800, loss = 0.58, batch loss = 0.41 (35.9 examples/sec; 0.223 sec/batch; 13h:25m:05s remains)
INFO - root - 2017-12-16 21:53:39.342534: step 115810, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 13h:17m:23s remains)
INFO - root - 2017-12-16 21:53:41.577048: step 115820, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.215 sec/batch; 12h:58m:00s remains)
INFO - root - 2017-12-16 21:53:43.814282: step 115830, loss = 0.45, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 13h:04m:48s remains)
INFO - root - 2017-12-16 21:53:46.041789: step 115840, loss = 0.48, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 13h:01m:41s remains)
INFO - root - 2017-12-16 21:53:48.259489: step 115850, loss = 0.46, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 13h:01m:38s remains)
INFO - root - 2017-12-16 21:53:50.478488: step 115860, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 12h:51m:42s remains)
INFO - root - 2017-12-16 21:53:52.709039: step 115870, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 13h:25m:16s remains)
INFO - root - 2017-12-16 21:53:54.917133: step 115880, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 13h:05m:03s remains)
INFO - root - 2017-12-16 21:53:57.126540: step 115890, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 13h:47m:58s remains)
INFO - root - 2017-12-16 21:53:59.311852: step 115900, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 13h:03m:05s remains)
INFO - root - 2017-12-16 21:54:01.680577: step 115910, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 13h:07m:21s remains)
INFO - root - 2017-12-16 21:54:03.878886: step 115920, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 13h:24m:19s remains)
INFO - root - 2017-12-16 21:54:06.108928: step 115930, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 13h:01m:31s remains)
INFO - root - 2017-12-16 21:54:08.364639: step 115940, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 13h:43m:23s remains)
INFO - root - 2017-12-16 21:54:10.619345: step 115950, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 13h:56m:15s remains)
INFO - root - 2017-12-16 21:54:12.813334: step 115960, loss = 0.46, batch loss = 0.28 (32.6 examples/sec; 0.246 sec/batch; 14h:46m:32s remains)
INFO - root - 2017-12-16 21:54:15.054636: step 115970, loss = 0.50, batch loss = 0.32 (32.3 examples/sec; 0.248 sec/batch; 14h:55m:06s remains)
INFO - root - 2017-12-16 21:54:17.316618: step 115980, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 13h:14m:05s remains)
INFO - root - 2017-12-16 21:54:19.498519: step 115990, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 13h:41m:58s remains)
INFO - root - 2017-12-16 21:54:21.716064: step 116000, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 13h:14m:28s remains)
INFO - root - 2017-12-16 21:54:24.108403: step 116010, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 12h:49m:28s remains)
INFO - root - 2017-12-16 21:54:26.304367: step 116020, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 12h:59m:14s remains)
INFO - root - 2017-12-16 21:54:28.525737: step 116030, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 13h:26m:31s remains)
INFO - root - 2017-12-16 21:54:30.732185: step 116040, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 13h:33m:07s remains)
INFO - root - 2017-12-16 21:54:32.962374: step 116050, loss = 0.49, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 13h:30m:08s remains)
INFO - root - 2017-12-16 21:54:35.170433: step 116060, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 12h:52m:27s remains)
INFO - root - 2017-12-16 21:54:37.352630: step 116070, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 13h:09m:43s remains)
INFO - root - 2017-12-16 21:54:39.547799: step 116080, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 12h:56m:41s remains)
INFO - root - 2017-12-16 21:54:41.716274: step 116090, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 12h:49m:17s remains)
INFO - root - 2017-12-16 21:54:43.909729: step 116100, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 13h:20m:32s remains)
INFO - root - 2017-12-16 21:54:46.272190: step 116110, loss = 0.50, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 13h:11m:46s remains)
INFO - root - 2017-12-16 21:54:48.491260: step 116120, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 13h:21m:56s remains)
INFO - root - 2017-12-16 21:54:50.683725: step 116130, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 13h:19m:15s remains)
INFO - root - 2017-12-16 21:54:52.878300: step 116140, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 13h:04m:22s remains)
INFO - root - 2017-12-16 21:54:55.094099: step 116150, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 12h:54m:04s remains)
INFO - root - 2017-12-16 21:54:57.281385: step 116160, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 13h:10m:17s remains)
INFO - root - 2017-12-16 21:54:59.470195: step 116170, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 13h:11m:03s remains)
INFO - root - 2017-12-16 21:55:01.657097: step 116180, loss = 0.54, batch loss = 0.36 (37.2 examples/sec; 0.215 sec/batch; 12h:55m:08s remains)
INFO - root - 2017-12-16 21:55:03.861266: step 116190, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 13h:14m:40s remains)
INFO - root - 2017-12-16 21:55:06.101739: step 116200, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 13h:47m:53s remains)
INFO - root - 2017-12-16 21:55:08.434946: step 116210, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 13h:22m:44s remains)
INFO - root - 2017-12-16 21:55:10.664044: step 116220, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 13h:35m:35s remains)
INFO - root - 2017-12-16 21:55:12.874178: step 116230, loss = 0.46, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 13h:24m:33s remains)
INFO - root - 2017-12-16 21:55:15.067588: step 116240, loss = 0.45, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 13h:26m:45s remains)
INFO - root - 2017-12-16 21:55:17.271837: step 116250, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 13h:08m:03s remains)
INFO - root - 2017-12-16 21:55:19.520180: step 116260, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 13h:42m:04s remains)
INFO - root - 2017-12-16 21:55:21.742637: step 116270, loss = 0.61, batch loss = 0.43 (35.8 examples/sec; 0.224 sec/batch; 13h:25m:37s remains)
INFO - root - 2017-12-16 21:55:24.001774: step 116280, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 13h:12m:58s remains)
INFO - root - 2017-12-16 21:55:26.201494: step 116290, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 12h:43m:29s remains)
INFO - root - 2017-12-16 21:55:28.431527: step 116300, loss = 0.45, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 13h:03m:21s remains)
INFO - root - 2017-12-16 21:55:30.764548: step 116310, loss = 0.46, batch loss = 0.28 (33.7 examples/sec; 0.238 sec/batch; 14h:16m:22s remains)
INFO - root - 2017-12-16 21:55:32.949478: step 116320, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 13h:11m:38s remains)
INFO - root - 2017-12-16 21:55:35.161052: step 116330, loss = 0.43, batch loss = 0.25 (34.5 examples/sec; 0.232 sec/batch; 13h:56m:27s remains)
INFO - root - 2017-12-16 21:55:37.387101: step 116340, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 13h:20m:29s remains)
INFO - root - 2017-12-16 21:55:39.608921: step 116350, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 13h:27m:49s remains)
INFO - root - 2017-12-16 21:55:41.803273: step 116360, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 13h:01m:52s remains)
INFO - root - 2017-12-16 21:55:44.019940: step 116370, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 13h:05m:13s remains)
INFO - root - 2017-12-16 21:55:46.239227: step 116380, loss = 0.43, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 12h:55m:19s remains)
INFO - root - 2017-12-16 21:55:48.473198: step 116390, loss = 0.47, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 13h:20m:38s remains)
INFO - root - 2017-12-16 21:55:50.689084: step 116400, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 13h:18m:41s remains)
INFO - root - 2017-12-16 21:55:53.024728: step 116410, loss = 0.55, batch loss = 0.37 (37.3 examples/sec; 0.214 sec/batch; 12h:51m:41s remains)
INFO - root - 2017-12-16 21:55:55.243743: step 116420, loss = 0.48, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 13h:08m:32s remains)
INFO - root - 2017-12-16 21:55:57.441443: step 116430, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 13h:07m:17s remains)
INFO - root - 2017-12-16 21:55:59.620320: step 116440, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 13h:10m:16s remains)
INFO - root - 2017-12-16 21:56:01.860632: step 116450, loss = 0.57, batch loss = 0.40 (34.2 examples/sec; 0.234 sec/batch; 14h:01m:07s remains)
INFO - root - 2017-12-16 21:56:04.070362: step 116460, loss = 0.50, batch loss = 0.32 (37.9 examples/sec; 0.211 sec/batch; 12h:39m:16s remains)
INFO - root - 2017-12-16 21:56:06.248990: step 116470, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 12h:59m:41s remains)
INFO - root - 2017-12-16 21:56:08.486029: step 116480, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 13h:35m:50s remains)
INFO - root - 2017-12-16 21:56:10.667112: step 116490, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 13h:23m:58s remains)
INFO - root - 2017-12-16 21:56:12.922027: step 116500, loss = 0.43, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 13h:15m:41s remains)
INFO - root - 2017-12-16 21:56:15.232290: step 116510, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 13h:05m:20s remains)
INFO - root - 2017-12-16 21:56:17.390830: step 116520, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 13h:01m:15s remains)
INFO - root - 2017-12-16 21:56:19.567825: step 116530, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 13h:30m:56s remains)
INFO - root - 2017-12-16 21:56:21.828203: step 116540, loss = 0.42, batch loss = 0.24 (35.2 examples/sec; 0.227 sec/batch; 13h:37m:27s remains)
INFO - root - 2017-12-16 21:56:24.006918: step 116550, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 13h:18m:54s remains)
INFO - root - 2017-12-16 21:56:26.243823: step 116560, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 13h:17m:34s remains)
INFO - root - 2017-12-16 21:56:28.434775: step 116570, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 12h:59m:17s remains)
INFO - root - 2017-12-16 21:56:30.625407: step 116580, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.224 sec/batch; 13h:25m:02s remains)
INFO - root - 2017-12-16 21:56:32.828566: step 116590, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 13h:14m:19s remains)
INFO - root - 2017-12-16 21:56:35.046615: step 116600, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 13h:19m:53s remains)
INFO - root - 2017-12-16 21:56:37.426515: step 116610, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 13h:11m:03s remains)
INFO - root - 2017-12-16 21:56:39.632578: step 116620, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.218 sec/batch; 13h:02m:56s remains)
INFO - root - 2017-12-16 21:56:41.798457: step 116630, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 13h:09m:09s remains)
INFO - root - 2017-12-16 21:56:43.963111: step 116640, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 12h:57m:18s remains)
INFO - root - 2017-12-16 21:56:46.142799: step 116650, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 13h:21m:43s remains)
INFO - root - 2017-12-16 21:56:48.350380: step 116660, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.219 sec/batch; 13h:09m:32s remains)
INFO - root - 2017-12-16 21:56:50.592242: step 116670, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 13h:36m:48s remains)
INFO - root - 2017-12-16 21:56:52.835017: step 116680, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 13h:15m:16s remains)
INFO - root - 2017-12-16 21:56:55.084698: step 116690, loss = 0.54, batch loss = 0.36 (35.4 examples/sec; 0.226 sec/batch; 13h:32m:40s remains)
INFO - root - 2017-12-16 21:56:57.302402: step 116700, loss = 0.52, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 12h:49m:17s remains)
INFO - root - 2017-12-16 21:56:59.605850: step 116710, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 13h:17m:31s remains)
INFO - root - 2017-12-16 21:57:01.817425: step 116720, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 13h:16m:46s remains)
INFO - root - 2017-12-16 21:57:04.026425: step 116730, loss = 0.44, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 13h:05m:53s remains)
INFO - root - 2017-12-16 21:57:06.251685: step 116740, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 13h:29m:56s remains)
INFO - root - 2017-12-16 21:57:08.489656: step 116750, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 12h:59m:27s remains)
INFO - root - 2017-12-16 21:57:10.685852: step 116760, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 13h:16m:53s remains)
INFO - root - 2017-12-16 21:57:12.877996: step 116770, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 13h:29m:46s remains)
INFO - root - 2017-12-16 21:57:15.082530: step 116780, loss = 0.44, batch loss = 0.26 (34.7 examples/sec; 0.230 sec/batch; 13h:47m:46s remains)
INFO - root - 2017-12-16 21:57:17.306192: step 116790, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 13h:09m:20s remains)
INFO - root - 2017-12-16 21:57:19.514244: step 116800, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 13h:00m:52s remains)
INFO - root - 2017-12-16 21:57:21.851713: step 116810, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 13h:33m:25s remains)
INFO - root - 2017-12-16 21:57:24.063369: step 116820, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 13h:11m:07s remains)
INFO - root - 2017-12-16 21:57:26.271154: step 116830, loss = 0.52, batch loss = 0.34 (37.6 examples/sec; 0.213 sec/batch; 12h:44m:06s remains)
INFO - root - 2017-12-16 21:57:28.499833: step 116840, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 13h:04m:29s remains)
INFO - root - 2017-12-16 21:57:30.708278: step 116850, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 13h:12m:24s remains)
INFO - root - 2017-12-16 21:57:32.887947: step 116860, loss = 0.50, batch loss = 0.32 (37.7 examples/sec; 0.212 sec/batch; 12h:41m:50s remains)
INFO - root - 2017-12-16 21:57:35.094306: step 116870, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.221 sec/batch; 13h:15m:25s remains)
INFO - root - 2017-12-16 21:57:37.290290: step 116880, loss = 0.45, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 13h:05m:01s remains)
INFO - root - 2017-12-16 21:57:39.473596: step 116890, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 13h:05m:03s remains)
INFO - root - 2017-12-16 21:57:41.668380: step 116900, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 13h:33m:08s remains)
INFO - root - 2017-12-16 21:57:44.026006: step 116910, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 13h:27m:42s remains)
INFO - root - 2017-12-16 21:57:46.227997: step 116920, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 13h:02m:24s remains)
INFO - root - 2017-12-16 21:57:48.503110: step 116930, loss = 0.49, batch loss = 0.32 (34.3 examples/sec; 0.233 sec/batch; 13h:58m:20s remains)
INFO - root - 2017-12-16 21:57:50.705312: step 116940, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 13h:08m:00s remains)
INFO - root - 2017-12-16 21:57:52.903934: step 116950, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 13h:27m:02s remains)
INFO - root - 2017-12-16 21:57:55.095694: step 116960, loss = 0.51, batch loss = 0.34 (37.3 examples/sec; 0.214 sec/batch; 12h:49m:49s remains)
INFO - root - 2017-12-16 21:57:57.301808: step 116970, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 13h:25m:52s remains)
INFO - root - 2017-12-16 21:57:59.532936: step 116980, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 13h:11m:55s remains)
INFO - root - 2017-12-16 21:58:01.759006: step 116990, loss = 0.41, batch loss = 0.23 (34.6 examples/sec; 0.231 sec/batch; 13h:51m:29s remains)
INFO - root - 2017-12-16 21:58:03.947049: step 117000, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.221 sec/batch; 13h:14m:57s remains)
INFO - root - 2017-12-16 21:58:06.305944: step 117010, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 13h:24m:26s remains)
INFO - root - 2017-12-16 21:58:08.528141: step 117020, loss = 0.44, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 13h:42m:14s remains)
INFO - root - 2017-12-16 21:58:10.785458: step 117030, loss = 0.52, batch loss = 0.34 (35.2 examples/sec; 0.228 sec/batch; 13h:37m:17s remains)
INFO - root - 2017-12-16 21:58:13.016206: step 117040, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.218 sec/batch; 13h:01m:11s remains)
INFO - root - 2017-12-16 21:58:15.202073: step 117050, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 12h:57m:22s remains)
INFO - root - 2017-12-16 21:58:17.385730: step 117060, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 12h:55m:48s remains)
INFO - root - 2017-12-16 21:58:19.591916: step 117070, loss = 0.48, batch loss = 0.30 (34.2 examples/sec; 0.234 sec/batch; 14h:00m:25s remains)
INFO - root - 2017-12-16 21:58:21.831639: step 117080, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 13h:16m:04s remains)
INFO - root - 2017-12-16 21:58:24.067119: step 117090, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 13h:13m:08s remains)
INFO - root - 2017-12-16 21:58:26.287004: step 117100, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 13h:37m:05s remains)
INFO - root - 2017-12-16 21:58:28.640259: step 117110, loss = 0.45, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 12h:50m:43s remains)
INFO - root - 2017-12-16 21:58:30.835053: step 117120, loss = 0.43, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 13h:33m:55s remains)
INFO - root - 2017-12-16 21:58:33.021479: step 117130, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 13h:20m:05s remains)
INFO - root - 2017-12-16 21:58:35.238956: step 117140, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 13h:36m:58s remains)
INFO - root - 2017-12-16 21:58:37.472351: step 117150, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 13h:26m:31s remains)
INFO - root - 2017-12-16 21:58:39.715439: step 117160, loss = 0.45, batch loss = 0.27 (34.2 examples/sec; 0.234 sec/batch; 13h:58m:40s remains)
INFO - root - 2017-12-16 21:58:41.924410: step 117170, loss = 0.47, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 13h:05m:49s remains)
INFO - root - 2017-12-16 21:58:44.132677: step 117180, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 13h:10m:43s remains)
INFO - root - 2017-12-16 21:58:46.348236: step 117190, loss = 0.42, batch loss = 0.25 (34.3 examples/sec; 0.233 sec/batch; 13h:55m:54s remains)
INFO - root - 2017-12-16 21:58:48.561220: step 117200, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 13h:12m:41s remains)
INFO - root - 2017-12-16 21:58:50.867501: step 117210, loss = 0.45, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 12h:50m:55s remains)
INFO - root - 2017-12-16 21:58:53.048207: step 117220, loss = 0.45, batch loss = 0.27 (34.0 examples/sec; 0.235 sec/batch; 14h:03m:48s remains)
INFO - root - 2017-12-16 21:58:55.279860: step 117230, loss = 0.43, batch loss = 0.25 (37.0 examples/sec; 0.216 sec/batch; 12h:55m:54s remains)
INFO - root - 2017-12-16 21:58:57.538592: step 117240, loss = 0.55, batch loss = 0.37 (35.5 examples/sec; 0.226 sec/batch; 13h:29m:26s remains)
INFO - root - 2017-12-16 21:58:59.743614: step 117250, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 13h:23m:53s remains)
INFO - root - 2017-12-16 21:59:01.989085: step 117260, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 13h:26m:08s remains)
INFO - root - 2017-12-16 21:59:04.178234: step 117270, loss = 0.44, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 12h:44m:02s remains)
INFO - root - 2017-12-16 21:59:06.380249: step 117280, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 13h:11m:45s remains)
INFO - root - 2017-12-16 21:59:08.601949: step 117290, loss = 0.55, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 13h:10m:06s remains)
INFO - root - 2017-12-16 21:59:10.826778: step 117300, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 13h:10m:42s remains)
INFO - root - 2017-12-16 21:59:13.215785: step 117310, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 13h:19m:48s remains)
INFO - root - 2017-12-16 21:59:15.439983: step 117320, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 13h:02m:28s remains)
INFO - root - 2017-12-16 21:59:17.665789: step 117330, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 12h:55m:11s remains)
INFO - root - 2017-12-16 21:59:19.897115: step 117340, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 13h:12m:36s remains)
INFO - root - 2017-12-16 21:59:22.077264: step 117350, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 13h:11m:56s remains)
INFO - root - 2017-12-16 21:59:24.280476: step 117360, loss = 0.45, batch loss = 0.27 (34.2 examples/sec; 0.234 sec/batch; 13h:58m:23s remains)
INFO - root - 2017-12-16 21:59:26.516894: step 117370, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 13h:21m:26s remains)
INFO - root - 2017-12-16 21:59:28.714791: step 117380, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 13h:02m:17s remains)
INFO - root - 2017-12-16 21:59:30.914825: step 117390, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 12h:45m:16s remains)
INFO - root - 2017-12-16 21:59:33.127883: step 117400, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 13h:01m:08s remains)
INFO - root - 2017-12-16 21:59:35.456873: step 117410, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 13h:06m:14s remains)
INFO - root - 2017-12-16 21:59:37.695744: step 117420, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 12h:51m:34s remains)
INFO - root - 2017-12-16 21:59:39.868815: step 117430, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 13h:12m:34s remains)
INFO - root - 2017-12-16 21:59:42.071737: step 117440, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 13h:07m:09s remains)
INFO - root - 2017-12-16 21:59:44.275043: step 117450, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 12h:57m:59s remains)
INFO - root - 2017-12-16 21:59:46.455107: step 117460, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 12h:55m:47s remains)
INFO - root - 2017-12-16 21:59:48.696108: step 117470, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 13h:20m:11s remains)
INFO - root - 2017-12-16 21:59:50.934515: step 117480, loss = 0.49, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 13h:27m:04s remains)
INFO - root - 2017-12-16 21:59:53.161963: step 117490, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 12h:53m:59s remains)
INFO - root - 2017-12-16 21:59:55.367162: step 117500, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 13h:08m:23s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-117500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-117500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 21:59:58.055343: step 117510, loss = 0.62, batch loss = 0.44 (37.1 examples/sec; 0.216 sec/batch; 12h:53m:20s remains)
INFO - root - 2017-12-16 22:00:00.241477: step 117520, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 13h:21m:45s remains)
INFO - root - 2017-12-16 22:00:02.447109: step 117530, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 12h:53m:00s remains)
INFO - root - 2017-12-16 22:00:04.697951: step 117540, loss = 0.47, batch loss = 0.29 (34.6 examples/sec; 0.231 sec/batch; 13h:47m:19s remains)
INFO - root - 2017-12-16 22:00:06.920775: step 117550, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 12h:55m:27s remains)
INFO - root - 2017-12-16 22:00:09.143279: step 117560, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 13h:05m:55s remains)
INFO - root - 2017-12-16 22:00:11.404169: step 117570, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.233 sec/batch; 13h:53m:39s remains)
INFO - root - 2017-12-16 22:00:13.637476: step 117580, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.215 sec/batch; 12h:49m:15s remains)
INFO - root - 2017-12-16 22:00:15.809877: step 117590, loss = 0.51, batch loss = 0.33 (37.8 examples/sec; 0.211 sec/batch; 12h:37m:27s remains)
INFO - root - 2017-12-16 22:00:17.982076: step 117600, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 12h:53m:49s remains)
INFO - root - 2017-12-16 22:00:20.339863: step 117610, loss = 0.50, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 13h:10m:56s remains)
INFO - root - 2017-12-16 22:00:22.554593: step 117620, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 13h:17m:24s remains)
INFO - root - 2017-12-16 22:00:24.756742: step 117630, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 12h:50m:31s remains)
INFO - root - 2017-12-16 22:00:26.994476: step 117640, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 13h:00m:55s remains)
INFO - root - 2017-12-16 22:00:29.230921: step 117650, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.228 sec/batch; 13h:37m:31s remains)
INFO - root - 2017-12-16 22:00:31.443136: step 117660, loss = 0.51, batch loss = 0.34 (34.4 examples/sec; 0.233 sec/batch; 13h:52m:33s remains)
INFO - root - 2017-12-16 22:00:33.682371: step 117670, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 13h:41m:28s remains)
INFO - root - 2017-12-16 22:00:35.880046: step 117680, loss = 0.42, batch loss = 0.25 (35.8 examples/sec; 0.224 sec/batch; 13h:21m:01s remains)
INFO - root - 2017-12-16 22:00:38.074468: step 117690, loss = 0.56, batch loss = 0.38 (36.6 examples/sec; 0.218 sec/batch; 13h:01m:43s remains)
INFO - root - 2017-12-16 22:00:40.286708: step 117700, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 12h:55m:46s remains)
INFO - root - 2017-12-16 22:00:42.638011: step 117710, loss = 0.42, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 12h:57m:02s remains)
INFO - root - 2017-12-16 22:00:44.817427: step 117720, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 12h:58m:20s remains)
INFO - root - 2017-12-16 22:00:47.048826: step 117730, loss = 0.52, batch loss = 0.34 (33.6 examples/sec; 0.238 sec/batch; 14h:11m:27s remains)
INFO - root - 2017-12-16 22:00:49.269821: step 117740, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 13h:04m:21s remains)
INFO - root - 2017-12-16 22:00:51.487621: step 117750, loss = 0.41, batch loss = 0.23 (36.2 examples/sec; 0.221 sec/batch; 13h:11m:08s remains)
INFO - root - 2017-12-16 22:00:53.675703: step 117760, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 13h:15m:18s remains)
INFO - root - 2017-12-16 22:00:55.888528: step 117770, loss = 0.61, batch loss = 0.43 (35.3 examples/sec; 0.227 sec/batch; 13h:31m:15s remains)
INFO - root - 2017-12-16 22:00:58.084225: step 117780, loss = 0.53, batch loss = 0.36 (36.4 examples/sec; 0.220 sec/batch; 13h:05m:44s remains)
INFO - root - 2017-12-16 22:01:00.281685: step 117790, loss = 0.52, batch loss = 0.34 (35.0 examples/sec; 0.229 sec/batch; 13h:37m:54s remains)
INFO - root - 2017-12-16 22:01:02.482602: step 117800, loss = 0.55, batch loss = 0.37 (35.0 examples/sec; 0.228 sec/batch; 13h:37m:35s remains)
INFO - root - 2017-12-16 22:01:04.876119: step 117810, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 13h:08m:09s remains)
INFO - root - 2017-12-16 22:01:07.096041: step 117820, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 13h:25m:07s remains)
INFO - root - 2017-12-16 22:01:09.335511: step 117830, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 13h:16m:31s remains)
INFO - root - 2017-12-16 22:01:11.548181: step 117840, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 12h:55m:27s remains)
INFO - root - 2017-12-16 22:01:13.745183: step 117850, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 13h:19m:52s remains)
INFO - root - 2017-12-16 22:01:15.963128: step 117860, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 13h:36m:33s remains)
INFO - root - 2017-12-16 22:01:18.177805: step 117870, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 13h:27m:53s remains)
INFO - root - 2017-12-16 22:01:20.424912: step 117880, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 13h:30m:39s remains)
INFO - root - 2017-12-16 22:01:22.623214: step 117890, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 13h:08m:18s remains)
INFO - root - 2017-12-16 22:01:24.839511: step 117900, loss = 0.44, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 13h:20m:51s remains)
INFO - root - 2017-12-16 22:01:27.207438: step 117910, loss = 0.57, batch loss = 0.39 (35.6 examples/sec; 0.225 sec/batch; 13h:23m:07s remains)
INFO - root - 2017-12-16 22:01:29.456796: step 117920, loss = 0.50, batch loss = 0.33 (37.5 examples/sec; 0.213 sec/batch; 12h:42m:58s remains)
INFO - root - 2017-12-16 22:01:31.662863: step 117930, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 13h:08m:24s remains)
INFO - root - 2017-12-16 22:01:33.873801: step 117940, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 12h:54m:52s remains)
INFO - root - 2017-12-16 22:01:36.111125: step 117950, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 12h:41m:32s remains)
INFO - root - 2017-12-16 22:01:38.303375: step 117960, loss = 0.57, batch loss = 0.39 (37.0 examples/sec; 0.216 sec/batch; 12h:52m:26s remains)
INFO - root - 2017-12-16 22:01:40.493770: step 117970, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 13h:23m:13s remains)
INFO - root - 2017-12-16 22:01:42.685768: step 117980, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 13h:25m:45s remains)
INFO - root - 2017-12-16 22:01:44.893490: step 117990, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 13h:38m:11s remains)
INFO - root - 2017-12-16 22:01:47.086336: step 118000, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 12h:47m:03s remains)
INFO - root - 2017-12-16 22:01:49.428474: step 118010, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 13h:15m:14s remains)
INFO - root - 2017-12-16 22:01:51.646876: step 118020, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 12h:50m:20s remains)
INFO - root - 2017-12-16 22:01:53.856600: step 118030, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 13h:35m:27s remains)
INFO - root - 2017-12-16 22:01:56.056140: step 118040, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 13h:18m:37s remains)
INFO - root - 2017-12-16 22:01:58.287049: step 118050, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 13h:09m:01s remains)
INFO - root - 2017-12-16 22:02:00.511000: step 118060, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 13h:03m:40s remains)
INFO - root - 2017-12-16 22:02:02.720567: step 118070, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 13h:25m:51s remains)
INFO - root - 2017-12-16 22:02:04.972728: step 118080, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 13h:06m:24s remains)
INFO - root - 2017-12-16 22:02:07.171083: step 118090, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 13h:16m:43s remains)
INFO - root - 2017-12-16 22:02:09.418996: step 118100, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 12h:57m:55s remains)
INFO - root - 2017-12-16 22:02:11.742299: step 118110, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 13h:03m:49s remains)
INFO - root - 2017-12-16 22:02:13.955344: step 118120, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 12h:50m:23s remains)
INFO - root - 2017-12-16 22:02:16.132810: step 118130, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 13h:00m:13s remains)
INFO - root - 2017-12-16 22:02:18.341113: step 118140, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 13h:40m:44s remains)
INFO - root - 2017-12-16 22:02:20.505743: step 118150, loss = 0.48, batch loss = 0.31 (38.6 examples/sec; 0.207 sec/batch; 12h:20m:06s remains)
INFO - root - 2017-12-16 22:02:22.690129: step 118160, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 13h:05m:47s remains)
INFO - root - 2017-12-16 22:02:24.896661: step 118170, loss = 0.56, batch loss = 0.38 (37.4 examples/sec; 0.214 sec/batch; 12h:44m:48s remains)
INFO - root - 2017-12-16 22:02:27.089327: step 118180, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 13h:03m:11s remains)
INFO - root - 2017-12-16 22:02:29.359523: step 118190, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 12h:57m:22s remains)
INFO - root - 2017-12-16 22:02:31.570254: step 118200, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 13h:27m:44s remains)
INFO - root - 2017-12-16 22:02:33.923317: step 118210, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 13h:13m:39s remains)
INFO - root - 2017-12-16 22:02:36.096998: step 118220, loss = 0.47, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 12h:49m:35s remains)
INFO - root - 2017-12-16 22:02:38.316405: step 118230, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 12h:45m:38s remains)
INFO - root - 2017-12-16 22:02:40.535806: step 118240, loss = 0.61, batch loss = 0.43 (35.2 examples/sec; 0.227 sec/batch; 13h:31m:33s remains)
INFO - root - 2017-12-16 22:02:42.746192: step 118250, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 13h:07m:39s remains)
INFO - root - 2017-12-16 22:02:44.971133: step 118260, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 13h:01m:30s remains)
INFO - root - 2017-12-16 22:02:47.177231: step 118270, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 13h:28m:50s remains)
INFO - root - 2017-12-16 22:02:49.406116: step 118280, loss = 0.47, batch loss = 0.29 (34.4 examples/sec; 0.233 sec/batch; 13h:51m:15s remains)
INFO - root - 2017-12-16 22:02:51.626328: step 118290, loss = 0.46, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 12h:50m:57s remains)
INFO - root - 2017-12-16 22:02:53.851971: step 118300, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 13h:01m:08s remains)
INFO - root - 2017-12-16 22:02:56.222224: step 118310, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 13h:06m:59s remains)
INFO - root - 2017-12-16 22:02:58.394378: step 118320, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 12h:50m:26s remains)
INFO - root - 2017-12-16 22:03:00.605299: step 118330, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 12h:53m:21s remains)
INFO - root - 2017-12-16 22:03:02.835335: step 118340, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 13h:29m:59s remains)
INFO - root - 2017-12-16 22:03:05.057427: step 118350, loss = 0.57, batch loss = 0.39 (36.7 examples/sec; 0.218 sec/batch; 12h:57m:03s remains)
INFO - root - 2017-12-16 22:03:07.271355: step 118360, loss = 0.49, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 12h:53m:43s remains)
INFO - root - 2017-12-16 22:03:09.496627: step 118370, loss = 0.44, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 13h:09m:32s remains)
INFO - root - 2017-12-16 22:03:11.680746: step 118380, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 12h:54m:40s remains)
INFO - root - 2017-12-16 22:03:13.875884: step 118390, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 12h:50m:58s remains)
INFO - root - 2017-12-16 22:03:16.114411: step 118400, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 13h:08m:06s remains)
INFO - root - 2017-12-16 22:03:18.447893: step 118410, loss = 0.48, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 13h:12m:34s remains)
INFO - root - 2017-12-16 22:03:20.636663: step 118420, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 13h:27m:12s remains)
INFO - root - 2017-12-16 22:03:22.843959: step 118430, loss = 0.52, batch loss = 0.35 (35.5 examples/sec; 0.225 sec/batch; 13h:23m:12s remains)
INFO - root - 2017-12-16 22:03:25.052813: step 118440, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 13h:22m:48s remains)
INFO - root - 2017-12-16 22:03:27.279221: step 118450, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 12h:57m:37s remains)
INFO - root - 2017-12-16 22:03:29.451962: step 118460, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 12h:43m:40s remains)
INFO - root - 2017-12-16 22:03:31.688356: step 118470, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 13h:18m:46s remains)
INFO - root - 2017-12-16 22:03:33.867788: step 118480, loss = 0.50, batch loss = 0.32 (38.2 examples/sec; 0.209 sec/batch; 12h:26m:57s remains)
INFO - root - 2017-12-16 22:03:36.058570: step 118490, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 13h:21m:11s remains)
INFO - root - 2017-12-16 22:03:38.285456: step 118500, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 13h:37m:12s remains)
INFO - root - 2017-12-16 22:03:40.606483: step 118510, loss = 0.56, batch loss = 0.38 (36.3 examples/sec; 0.221 sec/batch; 13h:06m:54s remains)
INFO - root - 2017-12-16 22:03:42.789731: step 118520, loss = 0.44, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 12h:52m:48s remains)
INFO - root - 2017-12-16 22:03:45.002864: step 118530, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 13h:02m:14s remains)
INFO - root - 2017-12-16 22:03:47.237926: step 118540, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 13h:15m:59s remains)
INFO - root - 2017-12-16 22:03:49.467412: step 118550, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 13h:07m:46s remains)
INFO - root - 2017-12-16 22:03:51.652777: step 118560, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 13h:19m:07s remains)
INFO - root - 2017-12-16 22:03:53.889026: step 118570, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 13h:03m:46s remains)
INFO - root - 2017-12-16 22:03:56.051191: step 118580, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 13h:13m:27s remains)
INFO - root - 2017-12-16 22:03:58.235657: step 118590, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.218 sec/batch; 12h:58m:21s remains)
INFO - root - 2017-12-16 22:04:00.453963: step 118600, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 13h:10m:35s remains)
INFO - root - 2017-12-16 22:04:02.819717: step 118610, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 13h:06m:02s remains)
INFO - root - 2017-12-16 22:04:05.047717: step 118620, loss = 0.53, batch loss = 0.35 (35.4 examples/sec; 0.226 sec/batch; 13h:25m:56s remains)
INFO - root - 2017-12-16 22:04:07.249551: step 118630, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 13h:06m:30s remains)
INFO - root - 2017-12-16 22:04:09.438530: step 118640, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 12h:57m:34s remains)
INFO - root - 2017-12-16 22:04:11.653057: step 118650, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 13h:01m:28s remains)
INFO - root - 2017-12-16 22:04:13.837668: step 118660, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 12h:52m:39s remains)
INFO - root - 2017-12-16 22:04:16.075512: step 118670, loss = 0.56, batch loss = 0.38 (36.1 examples/sec; 0.221 sec/batch; 13h:08m:45s remains)
INFO - root - 2017-12-16 22:04:18.267215: step 118680, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 13h:05m:27s remains)
INFO - root - 2017-12-16 22:04:20.464616: step 118690, loss = 0.47, batch loss = 0.29 (33.9 examples/sec; 0.236 sec/batch; 14h:01m:32s remains)
INFO - root - 2017-12-16 22:04:22.676300: step 118700, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 13h:21m:30s remains)
INFO - root - 2017-12-16 22:04:25.031671: step 118710, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 13h:05m:07s remains)
INFO - root - 2017-12-16 22:04:27.237759: step 118720, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 13h:14m:29s remains)
INFO - root - 2017-12-16 22:04:29.430833: step 118730, loss = 0.47, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 12h:37m:32s remains)
INFO - root - 2017-12-16 22:04:31.622373: step 118740, loss = 0.52, batch loss = 0.34 (34.8 examples/sec; 0.230 sec/batch; 13h:40m:06s remains)
INFO - root - 2017-12-16 22:04:33.811228: step 118750, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 12h:43m:04s remains)
INFO - root - 2017-12-16 22:04:35.993767: step 118760, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 13h:05m:53s remains)
INFO - root - 2017-12-16 22:04:38.213120: step 118770, loss = 0.45, batch loss = 0.27 (33.8 examples/sec; 0.237 sec/batch; 14h:04m:02s remains)
INFO - root - 2017-12-16 22:04:40.416715: step 118780, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 13h:09m:12s remains)
INFO - root - 2017-12-16 22:04:42.636515: step 118790, loss = 0.48, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 12h:50m:51s remains)
INFO - root - 2017-12-16 22:04:44.824079: step 118800, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 12h:39m:04s remains)
INFO - root - 2017-12-16 22:04:47.152753: step 118810, loss = 0.52, batch loss = 0.35 (35.5 examples/sec; 0.225 sec/batch; 13h:22m:34s remains)
INFO - root - 2017-12-16 22:04:49.381193: step 118820, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 13h:12m:21s remains)
INFO - root - 2017-12-16 22:04:51.577073: step 118830, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 12h:58m:12s remains)
INFO - root - 2017-12-16 22:04:53.809782: step 118840, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 12h:34m:23s remains)
INFO - root - 2017-12-16 22:04:56.012392: step 118850, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 12h:49m:20s remains)
INFO - root - 2017-12-16 22:04:58.233091: step 118860, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 13h:26m:41s remains)
INFO - root - 2017-12-16 22:05:00.436886: step 118870, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 12h:34m:09s remains)
INFO - root - 2017-12-16 22:05:02.624070: step 118880, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.215 sec/batch; 12h:46m:58s remains)
INFO - root - 2017-12-16 22:05:04.788662: step 118890, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 13h:20m:58s remains)
INFO - root - 2017-12-16 22:05:06.991019: step 118900, loss = 0.55, batch loss = 0.37 (34.9 examples/sec; 0.229 sec/batch; 13h:35m:19s remains)
INFO - root - 2017-12-16 22:05:09.347136: step 118910, loss = 0.55, batch loss = 0.37 (35.2 examples/sec; 0.227 sec/batch; 13h:29m:15s remains)
INFO - root - 2017-12-16 22:05:11.550543: step 118920, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 12h:39m:56s remains)
INFO - root - 2017-12-16 22:05:13.765968: step 118930, loss = 0.41, batch loss = 0.24 (36.5 examples/sec; 0.219 sec/batch; 13h:00m:25s remains)
INFO - root - 2017-12-16 22:05:15.988659: step 118940, loss = 0.44, batch loss = 0.27 (37.1 examples/sec; 0.215 sec/batch; 12h:46m:34s remains)
INFO - root - 2017-12-16 22:05:18.196311: step 118950, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 13h:07m:31s remains)
INFO - root - 2017-12-16 22:05:20.404342: step 118960, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 13h:35m:57s remains)
INFO - root - 2017-12-16 22:05:22.589886: step 118970, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 13h:01m:36s remains)
INFO - root - 2017-12-16 22:05:24.812198: step 118980, loss = 0.52, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 13h:06m:19s remains)
INFO - root - 2017-12-16 22:05:27.037949: step 118990, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 13h:05m:31s remains)
INFO - root - 2017-12-16 22:05:29.259699: step 119000, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 13h:00m:21s remains)
INFO - root - 2017-12-16 22:05:31.604516: step 119010, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 12h:48m:57s remains)
INFO - root - 2017-12-16 22:05:33.800307: step 119020, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 12h:58m:21s remains)
INFO - root - 2017-12-16 22:05:35.996108: step 119030, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 13h:20m:39s remains)
INFO - root - 2017-12-16 22:05:38.218964: step 119040, loss = 0.45, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 12h:51m:56s remains)
INFO - root - 2017-12-16 22:05:40.417770: step 119050, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 13h:02m:41s remains)
INFO - root - 2017-12-16 22:05:42.655649: step 119060, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 13h:29m:04s remains)
INFO - root - 2017-12-16 22:05:44.896587: step 119070, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 13h:15m:38s remains)
INFO - root - 2017-12-16 22:05:47.124371: step 119080, loss = 0.46, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 12h:45m:38s remains)
INFO - root - 2017-12-16 22:05:49.359299: step 119090, loss = 0.47, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 13h:28m:09s remains)
INFO - root - 2017-12-16 22:05:51.572708: step 119100, loss = 0.54, batch loss = 0.36 (36.4 examples/sec; 0.220 sec/batch; 13h:02m:16s remains)
INFO - root - 2017-12-16 22:05:53.856842: step 119110, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 12h:55m:27s remains)
INFO - root - 2017-12-16 22:05:56.061796: step 119120, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 13h:12m:07s remains)
INFO - root - 2017-12-16 22:05:58.269441: step 119130, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 13h:38m:34s remains)
INFO - root - 2017-12-16 22:06:00.470050: step 119140, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 13h:04m:59s remains)
INFO - root - 2017-12-16 22:06:02.698836: step 119150, loss = 0.51, batch loss = 0.33 (33.5 examples/sec; 0.239 sec/batch; 14h:10m:07s remains)
INFO - root - 2017-12-16 22:06:04.932885: step 119160, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 13h:14m:16s remains)
INFO - root - 2017-12-16 22:06:07.152238: step 119170, loss = 0.55, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 12h:59m:21s remains)
INFO - root - 2017-12-16 22:06:09.380128: step 119180, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 12h:52m:19s remains)
INFO - root - 2017-12-16 22:06:11.606829: step 119190, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 13h:12m:02s remains)
INFO - root - 2017-12-16 22:06:13.844972: step 119200, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 13h:14m:51s remains)
INFO - root - 2017-12-16 22:06:16.227505: step 119210, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 13h:22m:09s remains)
INFO - root - 2017-12-16 22:06:18.464994: step 119220, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 13h:04m:31s remains)
INFO - root - 2017-12-16 22:06:20.665765: step 119230, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 13h:01m:10s remains)
INFO - root - 2017-12-16 22:06:22.902629: step 119240, loss = 0.49, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 12h:59m:27s remains)
INFO - root - 2017-12-16 22:06:25.119938: step 119250, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 13h:13m:53s remains)
INFO - root - 2017-12-16 22:06:27.392778: step 119260, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 13h:44m:11s remains)
INFO - root - 2017-12-16 22:06:29.601640: step 119270, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 13h:24m:30s remains)
INFO - root - 2017-12-16 22:06:31.782894: step 119280, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 12h:56m:51s remains)
INFO - root - 2017-12-16 22:06:34.016480: step 119290, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 12h:45m:23s remains)
INFO - root - 2017-12-16 22:06:36.241546: step 119300, loss = 0.52, batch loss = 0.34 (34.0 examples/sec; 0.235 sec/batch; 13h:54m:53s remains)
INFO - root - 2017-12-16 22:06:38.591517: step 119310, loss = 0.44, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 12h:53m:08s remains)
INFO - root - 2017-12-16 22:06:40.815475: step 119320, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 13h:10m:01s remains)
INFO - root - 2017-12-16 22:06:43.031822: step 119330, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 12h:47m:42s remains)
INFO - root - 2017-12-16 22:06:45.241946: step 119340, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 13h:13m:28s remains)
INFO - root - 2017-12-16 22:06:47.430498: step 119350, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.230 sec/batch; 13h:38m:24s remains)
INFO - root - 2017-12-16 22:06:49.656043: step 119360, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.229 sec/batch; 13h:32m:40s remains)
INFO - root - 2017-12-16 22:06:51.866183: step 119370, loss = 0.42, batch loss = 0.24 (35.9 examples/sec; 0.223 sec/batch; 13h:10m:50s remains)
INFO - root - 2017-12-16 22:06:54.076412: step 119380, loss = 0.44, batch loss = 0.26 (33.3 examples/sec; 0.241 sec/batch; 14h:14m:31s remains)
INFO - root - 2017-12-16 22:06:56.278660: step 119390, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 13h:04m:14s remains)
INFO - root - 2017-12-16 22:06:58.538717: step 119400, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 12h:55m:48s remains)
INFO - root - 2017-12-16 22:07:00.850214: step 119410, loss = 0.54, batch loss = 0.36 (35.2 examples/sec; 0.227 sec/batch; 13h:26m:59s remains)
INFO - root - 2017-12-16 22:07:03.054340: step 119420, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 13h:06m:38s remains)
INFO - root - 2017-12-16 22:07:05.278343: step 119430, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 13h:24m:52s remains)
INFO - root - 2017-12-16 22:07:07.524485: step 119440, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 13h:30m:23s remains)
INFO - root - 2017-12-16 22:07:09.742996: step 119450, loss = 0.45, batch loss = 0.27 (37.6 examples/sec; 0.213 sec/batch; 12h:36m:25s remains)
INFO - root - 2017-12-16 22:07:11.969148: step 119460, loss = 0.47, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 13h:08m:29s remains)
INFO - root - 2017-12-16 22:07:14.174061: step 119470, loss = 0.45, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 12h:58m:44s remains)
INFO - root - 2017-12-16 22:07:16.381677: step 119480, loss = 0.46, batch loss = 0.28 (32.8 examples/sec; 0.244 sec/batch; 14h:26m:04s remains)
INFO - root - 2017-12-16 22:07:18.598726: step 119490, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 13h:02m:39s remains)
INFO - root - 2017-12-16 22:07:20.868009: step 119500, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 13h:07m:27s remains)
INFO - root - 2017-12-16 22:07:23.161229: step 119510, loss = 0.53, batch loss = 0.36 (37.8 examples/sec; 0.211 sec/batch; 12h:30m:23s remains)
INFO - root - 2017-12-16 22:07:25.368252: step 119520, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 12h:43m:54s remains)
INFO - root - 2017-12-16 22:07:27.575328: step 119530, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 12h:58m:15s remains)
INFO - root - 2017-12-16 22:07:29.790826: step 119540, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 12h:42m:47s remains)
INFO - root - 2017-12-16 22:07:32.001998: step 119550, loss = 0.44, batch loss = 0.26 (37.7 examples/sec; 0.212 sec/batch; 12h:33m:19s remains)
INFO - root - 2017-12-16 22:07:34.195018: step 119560, loss = 0.54, batch loss = 0.36 (37.3 examples/sec; 0.214 sec/batch; 12h:40m:17s remains)
INFO - root - 2017-12-16 22:07:36.411018: step 119570, loss = 0.42, batch loss = 0.24 (35.9 examples/sec; 0.223 sec/batch; 13h:10m:22s remains)
INFO - root - 2017-12-16 22:07:38.694408: step 119580, loss = 0.50, batch loss = 0.32 (33.6 examples/sec; 0.238 sec/batch; 14h:04m:16s remains)
INFO - root - 2017-12-16 22:07:40.931324: step 119590, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 13h:17m:44s remains)
INFO - root - 2017-12-16 22:07:43.150570: step 119600, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 12h:54m:51s remains)
INFO - root - 2017-12-16 22:07:45.494667: step 119610, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 13h:21m:10s remains)
INFO - root - 2017-12-16 22:07:47.717542: step 119620, loss = 0.41, batch loss = 0.24 (36.4 examples/sec; 0.220 sec/batch; 12h:58m:54s remains)
INFO - root - 2017-12-16 22:07:49.912892: step 119630, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 12h:51m:39s remains)
INFO - root - 2017-12-16 22:07:52.116590: step 119640, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 12h:44m:17s remains)
INFO - root - 2017-12-16 22:07:54.351490: step 119650, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.223 sec/batch; 13h:12m:36s remains)
INFO - root - 2017-12-16 22:07:56.611821: step 119660, loss = 0.58, batch loss = 0.40 (35.6 examples/sec; 0.225 sec/batch; 13h:16m:38s remains)
INFO - root - 2017-12-16 22:07:58.813337: step 119670, loss = 0.55, batch loss = 0.37 (35.9 examples/sec; 0.223 sec/batch; 13h:10m:59s remains)
INFO - root - 2017-12-16 22:08:01.020463: step 119680, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 12h:48m:14s remains)
INFO - root - 2017-12-16 22:08:03.291451: step 119690, loss = 0.45, batch loss = 0.27 (33.9 examples/sec; 0.236 sec/batch; 13h:56m:40s remains)
INFO - root - 2017-12-16 22:08:05.491677: step 119700, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 13h:01m:21s remains)
INFO - root - 2017-12-16 22:08:07.833635: step 119710, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 13h:01m:11s remains)
INFO - root - 2017-12-16 22:08:10.055762: step 119720, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 13h:12m:00s remains)
INFO - root - 2017-12-16 22:08:12.284005: step 119730, loss = 0.52, batch loss = 0.34 (34.9 examples/sec; 0.229 sec/batch; 13h:33m:14s remains)
INFO - root - 2017-12-16 22:08:14.500163: step 119740, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 12h:50m:00s remains)
INFO - root - 2017-12-16 22:08:16.713235: step 119750, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 12h:54m:50s remains)
INFO - root - 2017-12-16 22:08:18.901289: step 119760, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 12h:52m:04s remains)
INFO - root - 2017-12-16 22:08:21.149288: step 119770, loss = 0.43, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 13h:20m:33s remains)
INFO - root - 2017-12-16 22:08:23.332533: step 119780, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 12h:42m:59s remains)
INFO - root - 2017-12-16 22:08:25.537238: step 119790, loss = 0.57, batch loss = 0.39 (37.6 examples/sec; 0.213 sec/batch; 12h:34m:55s remains)
INFO - root - 2017-12-16 22:08:27.736292: step 119800, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 13h:06m:24s remains)
INFO - root - 2017-12-16 22:08:30.109759: step 119810, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 13h:13m:12s remains)
INFO - root - 2017-12-16 22:08:32.355858: step 119820, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 13h:02m:16s remains)
INFO - root - 2017-12-16 22:08:34.581726: step 119830, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 12h:55m:23s remains)
INFO - root - 2017-12-16 22:08:36.836346: step 119840, loss = 0.43, batch loss = 0.25 (35.0 examples/sec; 0.228 sec/batch; 13h:29m:44s remains)
INFO - root - 2017-12-16 22:08:39.068656: step 119850, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 12h:58m:17s remains)
INFO - root - 2017-12-16 22:08:41.287746: step 119860, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 13h:11m:33s remains)
INFO - root - 2017-12-16 22:08:43.483263: step 119870, loss = 0.45, batch loss = 0.27 (33.3 examples/sec; 0.240 sec/batch; 14h:10m:21s remains)
INFO - root - 2017-12-16 22:08:45.723663: step 119880, loss = 0.45, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 13h:22m:47s remains)
INFO - root - 2017-12-16 22:08:47.965943: step 119890, loss = 0.61, batch loss = 0.43 (36.5 examples/sec; 0.219 sec/batch; 12h:55m:45s remains)
INFO - root - 2017-12-16 22:08:50.186851: step 119900, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 12h:54m:49s remains)
INFO - root - 2017-12-16 22:08:52.598973: step 119910, loss = 0.47, batch loss = 0.29 (33.9 examples/sec; 0.236 sec/batch; 13h:55m:28s remains)
INFO - root - 2017-12-16 22:08:54.801460: step 119920, loss = 0.48, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 12h:49m:30s remains)
INFO - root - 2017-12-16 22:08:57.036428: step 119930, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 13h:12m:14s remains)
INFO - root - 2017-12-16 22:08:59.272339: step 119940, loss = 0.44, batch loss = 0.26 (33.9 examples/sec; 0.236 sec/batch; 13h:56m:42s remains)
INFO - root - 2017-12-16 22:09:01.506792: step 119950, loss = 0.45, batch loss = 0.27 (34.2 examples/sec; 0.234 sec/batch; 13h:48m:06s remains)
INFO - root - 2017-12-16 22:09:03.733509: step 119960, loss = 0.52, batch loss = 0.34 (35.0 examples/sec; 0.228 sec/batch; 13h:28m:40s remains)
INFO - root - 2017-12-16 22:09:05.927741: step 119970, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.211 sec/batch; 12h:29m:05s remains)
INFO - root - 2017-12-16 22:09:08.155426: step 119980, loss = 0.48, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 12h:39m:19s remains)
INFO - root - 2017-12-16 22:09:10.401705: step 119990, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.226 sec/batch; 13h:22m:04s remains)
INFO - root - 2017-12-16 22:09:12.596052: step 120000, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 12h:50m:51s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-120000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-120000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 22:09:15.556468: step 120010, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 12h:52m:57s remains)
INFO - root - 2017-12-16 22:09:17.751281: step 120020, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 12h:38m:42s remains)
INFO - root - 2017-12-16 22:09:20.002842: step 120030, loss = 0.55, batch loss = 0.37 (35.3 examples/sec; 0.227 sec/batch; 13h:22m:16s remains)
INFO - root - 2017-12-16 22:09:22.224028: step 120040, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 13h:31m:39s remains)
INFO - root - 2017-12-16 22:09:24.430627: step 120050, loss = 0.42, batch loss = 0.24 (37.5 examples/sec; 0.214 sec/batch; 12h:36m:00s remains)
INFO - root - 2017-12-16 22:09:26.683381: step 120060, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 13h:12m:12s remains)
INFO - root - 2017-12-16 22:09:28.908287: step 120070, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 13h:09m:20s remains)
INFO - root - 2017-12-16 22:09:31.112738: step 120080, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.228 sec/batch; 13h:28m:07s remains)
INFO - root - 2017-12-16 22:09:33.348693: step 120090, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 13h:17m:27s remains)
INFO - root - 2017-12-16 22:09:35.538708: step 120100, loss = 0.43, batch loss = 0.25 (37.0 examples/sec; 0.216 sec/batch; 12h:45m:43s remains)
INFO - root - 2017-12-16 22:09:37.866818: step 120110, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 12h:47m:12s remains)
INFO - root - 2017-12-16 22:09:40.114687: step 120120, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.221 sec/batch; 13h:03m:29s remains)
INFO - root - 2017-12-16 22:09:42.313115: step 120130, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 12h:58m:42s remains)
INFO - root - 2017-12-16 22:09:44.540071: step 120140, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 13h:26m:28s remains)
INFO - root - 2017-12-16 22:09:46.752297: step 120150, loss = 0.42, batch loss = 0.24 (35.6 examples/sec; 0.225 sec/batch; 13h:14m:44s remains)
INFO - root - 2017-12-16 22:09:48.977126: step 120160, loss = 0.62, batch loss = 0.44 (36.4 examples/sec; 0.220 sec/batch; 12h:57m:04s remains)
INFO - root - 2017-12-16 22:09:51.187800: step 120170, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 12h:55m:37s remains)
INFO - root - 2017-12-16 22:09:53.384366: step 120180, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 13h:01m:27s remains)
INFO - root - 2017-12-16 22:09:55.600872: step 120190, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 12h:52m:45s remains)
INFO - root - 2017-12-16 22:09:57.838864: step 120200, loss = 0.54, batch loss = 0.36 (36.1 examples/sec; 0.222 sec/batch; 13h:04m:07s remains)
INFO - root - 2017-12-16 22:10:00.145308: step 120210, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 12h:37m:46s remains)
INFO - root - 2017-12-16 22:10:02.353732: step 120220, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 12h:44m:40s remains)
INFO - root - 2017-12-16 22:10:04.563122: step 120230, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.221 sec/batch; 13h:03m:25s remains)
INFO - root - 2017-12-16 22:10:06.781231: step 120240, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 13h:22m:51s remains)
INFO - root - 2017-12-16 22:10:09.056215: step 120250, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.228 sec/batch; 13h:28m:05s remains)
INFO - root - 2017-12-16 22:10:11.235784: step 120260, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 13h:09m:48s remains)
INFO - root - 2017-12-16 22:10:13.438043: step 120270, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 13h:03m:23s remains)
INFO - root - 2017-12-16 22:10:15.619533: step 120280, loss = 0.46, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 13h:18m:25s remains)
INFO - root - 2017-12-16 22:10:17.833246: step 120290, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 13h:04m:54s remains)
INFO - root - 2017-12-16 22:10:20.038254: step 120300, loss = 0.56, batch loss = 0.38 (35.0 examples/sec; 0.229 sec/batch; 13h:28m:32s remains)
INFO - root - 2017-12-16 22:10:22.448037: step 120310, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 13h:03m:26s remains)
INFO - root - 2017-12-16 22:10:24.654161: step 120320, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 12h:52m:53s remains)
INFO - root - 2017-12-16 22:10:26.906699: step 120330, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 13h:08m:18s remains)
INFO - root - 2017-12-16 22:10:29.109476: step 120340, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 12h:47m:37s remains)
INFO - root - 2017-12-16 22:10:31.336780: step 120350, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 13h:05m:14s remains)
INFO - root - 2017-12-16 22:10:33.553282: step 120360, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 13h:08m:56s remains)
INFO - root - 2017-12-16 22:10:35.775188: step 120370, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.226 sec/batch; 13h:20m:41s remains)
INFO - root - 2017-12-16 22:10:38.002769: step 120380, loss = 0.47, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 13h:46m:29s remains)
INFO - root - 2017-12-16 22:10:40.242490: step 120390, loss = 0.50, batch loss = 0.32 (33.0 examples/sec; 0.242 sec/batch; 14h:16m:02s remains)
INFO - root - 2017-12-16 22:10:42.441253: step 120400, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 12h:48m:14s remains)
INFO - root - 2017-12-16 22:10:44.763335: step 120410, loss = 0.52, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 13h:26m:09s remains)
INFO - root - 2017-12-16 22:10:46.984085: step 120420, loss = 0.55, batch loss = 0.37 (37.0 examples/sec; 0.216 sec/batch; 12h:44m:45s remains)
INFO - root - 2017-12-16 22:10:49.178880: step 120430, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 13h:19m:47s remains)
INFO - root - 2017-12-16 22:10:51.396035: step 120440, loss = 0.55, batch loss = 0.37 (37.3 examples/sec; 0.214 sec/batch; 12h:37m:31s remains)
INFO - root - 2017-12-16 22:10:53.634857: step 120450, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 12h:56m:43s remains)
INFO - root - 2017-12-16 22:10:55.879110: step 120460, loss = 0.47, batch loss = 0.29 (33.1 examples/sec; 0.242 sec/batch; 14h:13m:57s remains)
INFO - root - 2017-12-16 22:10:58.094149: step 120470, loss = 0.42, batch loss = 0.24 (36.1 examples/sec; 0.221 sec/batch; 13h:02m:04s remains)
INFO - root - 2017-12-16 22:11:00.304691: step 120480, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 12h:52m:31s remains)
INFO - root - 2017-12-16 22:11:02.537522: step 120490, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 13h:21m:52s remains)
INFO - root - 2017-12-16 22:11:04.747234: step 120500, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 13h:09m:15s remains)
INFO - root - 2017-12-16 22:11:07.090165: step 120510, loss = 0.53, batch loss = 0.35 (35.3 examples/sec; 0.227 sec/batch; 13h:21m:10s remains)
INFO - root - 2017-12-16 22:11:09.296550: step 120520, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 13h:19m:19s remains)
INFO - root - 2017-12-16 22:11:11.500380: step 120530, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 12h:36m:45s remains)
INFO - root - 2017-12-16 22:11:13.678741: step 120540, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 12h:51m:33s remains)
INFO - root - 2017-12-16 22:11:15.884536: step 120550, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 13h:06m:19s remains)
INFO - root - 2017-12-16 22:11:18.106611: step 120560, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 12h:57m:20s remains)
INFO - root - 2017-12-16 22:11:20.314716: step 120570, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.215 sec/batch; 12h:40m:56s remains)
INFO - root - 2017-12-16 22:11:22.540320: step 120580, loss = 0.58, batch loss = 0.40 (35.3 examples/sec; 0.227 sec/batch; 13h:20m:22s remains)
INFO - root - 2017-12-16 22:11:24.798389: step 120590, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 12h:41m:26s remains)
INFO - root - 2017-12-16 22:11:26.982109: step 120600, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 13h:02m:22s remains)
INFO - root - 2017-12-16 22:11:29.335356: step 120610, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 13h:03m:44s remains)
INFO - root - 2017-12-16 22:11:31.580642: step 120620, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 13h:14m:28s remains)
INFO - root - 2017-12-16 22:11:33.792517: step 120630, loss = 0.50, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 13h:08m:52s remains)
INFO - root - 2017-12-16 22:11:36.069176: step 120640, loss = 0.54, batch loss = 0.36 (34.6 examples/sec; 0.231 sec/batch; 13h:36m:46s remains)
INFO - root - 2017-12-16 22:11:38.291209: step 120650, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.228 sec/batch; 13h:25m:58s remains)
INFO - root - 2017-12-16 22:11:40.514010: step 120660, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 13h:08m:13s remains)
INFO - root - 2017-12-16 22:11:42.751406: step 120670, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 12h:59m:46s remains)
INFO - root - 2017-12-16 22:11:44.995401: step 120680, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.228 sec/batch; 13h:26m:20s remains)
INFO - root - 2017-12-16 22:11:47.234640: step 120690, loss = 0.41, batch loss = 0.23 (36.3 examples/sec; 0.221 sec/batch; 12h:58m:58s remains)
INFO - root - 2017-12-16 22:11:49.413690: step 120700, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.215 sec/batch; 12h:37m:34s remains)
INFO - root - 2017-12-16 22:11:51.758338: step 120710, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 12h:50m:00s remains)
INFO - root - 2017-12-16 22:11:53.992105: step 120720, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 12h:52m:49s remains)
INFO - root - 2017-12-16 22:11:56.196437: step 120730, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 12h:43m:23s remains)
INFO - root - 2017-12-16 22:11:58.396450: step 120740, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 12h:45m:57s remains)
INFO - root - 2017-12-16 22:12:00.585235: step 120750, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 12h:53m:46s remains)
INFO - root - 2017-12-16 22:12:02.777630: step 120760, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 13h:05m:36s remains)
INFO - root - 2017-12-16 22:12:05.029635: step 120770, loss = 0.47, batch loss = 0.29 (33.8 examples/sec; 0.237 sec/batch; 13h:55m:34s remains)
INFO - root - 2017-12-16 22:12:07.286808: step 120780, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 13h:23m:37s remains)
INFO - root - 2017-12-16 22:12:09.531067: step 120790, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 13h:22m:32s remains)
INFO - root - 2017-12-16 22:12:11.717728: step 120800, loss = 0.50, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 12h:44m:45s remains)
INFO - root - 2017-12-16 22:12:14.050614: step 120810, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 12h:37m:23s remains)
INFO - root - 2017-12-16 22:12:16.266732: step 120820, loss = 0.50, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 13h:09m:22s remains)
INFO - root - 2017-12-16 22:12:18.533701: step 120830, loss = 0.44, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 13h:17m:14s remains)
INFO - root - 2017-12-16 22:12:20.738671: step 120840, loss = 0.56, batch loss = 0.38 (36.6 examples/sec; 0.219 sec/batch; 12h:51m:16s remains)
INFO - root - 2017-12-16 22:12:22.974262: step 120850, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 12h:54m:01s remains)
INFO - root - 2017-12-16 22:12:25.154185: step 120860, loss = 0.57, batch loss = 0.39 (37.7 examples/sec; 0.212 sec/batch; 12h:27m:58s remains)
INFO - root - 2017-12-16 22:12:27.381525: step 120870, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 13h:12m:10s remains)
INFO - root - 2017-12-16 22:12:29.599461: step 120880, loss = 0.46, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 12h:45m:03s remains)
INFO - root - 2017-12-16 22:12:31.786918: step 120890, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 13h:01m:40s remains)
INFO - root - 2017-12-16 22:12:34.020299: step 120900, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 12h:48m:11s remains)
INFO - root - 2017-12-16 22:12:36.314840: step 120910, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 12h:45m:17s remains)
INFO - root - 2017-12-16 22:12:38.534743: step 120920, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 12h:43m:17s remains)
INFO - root - 2017-12-16 22:12:40.775486: step 120930, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 13h:10m:49s remains)
INFO - root - 2017-12-16 22:12:43.002226: step 120940, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.221 sec/batch; 13h:00m:52s remains)
INFO - root - 2017-12-16 22:12:45.225434: step 120950, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 13h:12m:16s remains)
INFO - root - 2017-12-16 22:12:47.455524: step 120960, loss = 0.52, batch loss = 0.34 (37.3 examples/sec; 0.215 sec/batch; 12h:36m:17s remains)
INFO - root - 2017-12-16 22:12:49.669349: step 120970, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 13h:03m:23s remains)
INFO - root - 2017-12-16 22:12:51.910236: step 120980, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.231 sec/batch; 13h:34m:04s remains)
INFO - root - 2017-12-16 22:12:54.144248: step 120990, loss = 0.42, batch loss = 0.24 (34.4 examples/sec; 0.232 sec/batch; 13h:38m:47s remains)
INFO - root - 2017-12-16 22:12:56.358382: step 121000, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 12h:56m:28s remains)
INFO - root - 2017-12-16 22:12:58.696286: step 121010, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 12h:41m:40s remains)
INFO - root - 2017-12-16 22:13:00.934566: step 121020, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 13h:02m:19s remains)
INFO - root - 2017-12-16 22:13:03.155064: step 121030, loss = 0.48, batch loss = 0.30 (33.7 examples/sec; 0.237 sec/batch; 13h:56m:33s remains)
INFO - root - 2017-12-16 22:13:05.390663: step 121040, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 13h:17m:12s remains)
INFO - root - 2017-12-16 22:13:07.586433: step 121050, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 12h:51m:21s remains)
INFO - root - 2017-12-16 22:13:09.822274: step 121060, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 13h:29m:47s remains)
INFO - root - 2017-12-16 22:13:12.085236: step 121070, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.218 sec/batch; 12h:49m:39s remains)
INFO - root - 2017-12-16 22:13:14.282717: step 121080, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 12h:56m:29s remains)
INFO - root - 2017-12-16 22:13:16.482605: step 121090, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 12h:58m:56s remains)
INFO - root - 2017-12-16 22:13:18.676312: step 121100, loss = 0.55, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 12h:58m:45s remains)
INFO - root - 2017-12-16 22:13:21.015109: step 121110, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 12h:52m:48s remains)
INFO - root - 2017-12-16 22:13:23.217511: step 121120, loss = 0.55, batch loss = 0.37 (34.9 examples/sec; 0.229 sec/batch; 13h:27m:07s remains)
INFO - root - 2017-12-16 22:13:25.408520: step 121130, loss = 0.48, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 12h:53m:55s remains)
INFO - root - 2017-12-16 22:13:27.628453: step 121140, loss = 0.59, batch loss = 0.41 (36.3 examples/sec; 0.220 sec/batch; 12h:55m:39s remains)
INFO - root - 2017-12-16 22:13:29.854462: step 121150, loss = 0.47, batch loss = 0.29 (34.4 examples/sec; 0.232 sec/batch; 13h:38m:44s remains)
INFO - root - 2017-12-16 22:13:32.074361: step 121160, loss = 0.55, batch loss = 0.37 (37.0 examples/sec; 0.216 sec/batch; 12h:41m:01s remains)
INFO - root - 2017-12-16 22:13:34.330208: step 121170, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 13h:01m:46s remains)
INFO - root - 2017-12-16 22:13:36.570528: step 121180, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 12h:50m:24s remains)
INFO - root - 2017-12-16 22:13:38.756331: step 121190, loss = 0.52, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 13h:01m:45s remains)
INFO - root - 2017-12-16 22:13:40.997282: step 121200, loss = 0.48, batch loss = 0.30 (33.8 examples/sec; 0.237 sec/batch; 13h:53m:10s remains)
INFO - root - 2017-12-16 22:13:43.364982: step 121210, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 12h:54m:33s remains)
INFO - root - 2017-12-16 22:13:45.553357: step 121220, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 12h:52m:36s remains)
INFO - root - 2017-12-16 22:13:47.787248: step 121230, loss = 0.49, batch loss = 0.32 (34.7 examples/sec; 0.230 sec/batch; 13h:31m:05s remains)
INFO - root - 2017-12-16 22:13:50.042967: step 121240, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 12h:31m:27s remains)
INFO - root - 2017-12-16 22:13:52.233462: step 121250, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 12h:44m:58s remains)
INFO - root - 2017-12-16 22:13:54.476143: step 121260, loss = 0.48, batch loss = 0.30 (34.3 examples/sec; 0.233 sec/batch; 13h:40m:45s remains)
INFO - root - 2017-12-16 22:13:56.711671: step 121270, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.226 sec/batch; 13h:17m:16s remains)
INFO - root - 2017-12-16 22:13:58.915491: step 121280, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.214 sec/batch; 12h:31m:40s remains)
INFO - root - 2017-12-16 22:14:01.121344: step 121290, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 13h:06m:22s remains)
INFO - root - 2017-12-16 22:14:03.334847: step 121300, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 13h:24m:39s remains)
INFO - root - 2017-12-16 22:14:05.695197: step 121310, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 12h:56m:51s remains)
INFO - root - 2017-12-16 22:14:07.888961: step 121320, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 13h:12m:18s remains)
INFO - root - 2017-12-16 22:14:10.125952: step 121330, loss = 0.47, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 12h:42m:39s remains)
INFO - root - 2017-12-16 22:14:12.324032: step 121340, loss = 0.43, batch loss = 0.25 (37.3 examples/sec; 0.214 sec/batch; 12h:34m:48s remains)
INFO - root - 2017-12-16 22:14:14.533241: step 121350, loss = 0.47, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 12h:37m:00s remains)
INFO - root - 2017-12-16 22:14:16.765334: step 121360, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 13h:03m:42s remains)
INFO - root - 2017-12-16 22:14:19.009839: step 121370, loss = 0.45, batch loss = 0.27 (33.8 examples/sec; 0.237 sec/batch; 13h:53m:39s remains)
INFO - root - 2017-12-16 22:14:21.263790: step 121380, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 12h:43m:42s remains)
INFO - root - 2017-12-16 22:14:23.497355: step 121390, loss = 0.59, batch loss = 0.41 (35.8 examples/sec; 0.223 sec/batch; 13h:05m:33s remains)
INFO - root - 2017-12-16 22:14:25.707088: step 121400, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 13h:03m:24s remains)
INFO - root - 2017-12-16 22:14:28.014708: step 121410, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 12h:40m:37s remains)
INFO - root - 2017-12-16 22:14:30.246290: step 121420, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 12h:40m:41s remains)
INFO - root - 2017-12-16 22:14:32.463803: step 121430, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 13h:03m:29s remains)
INFO - root - 2017-12-16 22:14:34.675335: step 121440, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 12h:58m:13s remains)
INFO - root - 2017-12-16 22:14:36.896160: step 121450, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 12h:55m:51s remains)
INFO - root - 2017-12-16 22:14:39.145633: step 121460, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 12h:41m:36s remains)
INFO - root - 2017-12-16 22:14:41.349959: step 121470, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 13h:06m:14s remains)
INFO - root - 2017-12-16 22:14:43.603076: step 121480, loss = 0.54, batch loss = 0.36 (35.0 examples/sec; 0.228 sec/batch; 13h:23m:35s remains)
INFO - root - 2017-12-16 22:14:45.811836: step 121490, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 13h:05m:07s remains)
INFO - root - 2017-12-16 22:14:48.029750: step 121500, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 12h:56m:35s remains)
INFO - root - 2017-12-16 22:14:50.316375: step 121510, loss = 0.52, batch loss = 0.34 (37.8 examples/sec; 0.212 sec/batch; 12h:25m:01s remains)
INFO - root - 2017-12-16 22:14:52.524692: step 121520, loss = 0.48, batch loss = 0.31 (34.2 examples/sec; 0.234 sec/batch; 13h:43m:07s remains)
INFO - root - 2017-12-16 22:14:54.738992: step 121530, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 12h:55m:06s remains)
INFO - root - 2017-12-16 22:14:56.947745: step 121540, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 12h:33m:17s remains)
INFO - root - 2017-12-16 22:14:59.174867: step 121550, loss = 0.43, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 13h:16m:44s remains)
INFO - root - 2017-12-16 22:15:01.377868: step 121560, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 12h:55m:55s remains)
INFO - root - 2017-12-16 22:15:03.621607: step 121570, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 13h:07m:26s remains)
INFO - root - 2017-12-16 22:15:05.838254: step 121580, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 12h:44m:31s remains)
INFO - root - 2017-12-16 22:15:08.053230: step 121590, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 12h:50m:43s remains)
INFO - root - 2017-12-16 22:15:10.235822: step 121600, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 13h:02m:35s remains)
INFO - root - 2017-12-16 22:15:12.567452: step 121610, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 12h:47m:26s remains)
INFO - root - 2017-12-16 22:15:14.818797: step 121620, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 12h:51m:43s remains)
INFO - root - 2017-12-16 22:15:17.037213: step 121630, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 13h:09m:49s remains)
INFO - root - 2017-12-16 22:15:19.223056: step 121640, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 12h:44m:13s remains)
INFO - root - 2017-12-16 22:15:21.412312: step 121650, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 12h:31m:25s remains)
INFO - root - 2017-12-16 22:15:23.643309: step 121660, loss = 0.52, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 13h:20m:16s remains)
INFO - root - 2017-12-16 22:15:25.870691: step 121670, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 13h:13m:05s remains)
INFO - root - 2017-12-16 22:15:28.087226: step 121680, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 13h:00m:41s remains)
INFO - root - 2017-12-16 22:15:30.304479: step 121690, loss = 0.41, batch loss = 0.23 (36.9 examples/sec; 0.217 sec/batch; 12h:40m:55s remains)
INFO - root - 2017-12-16 22:15:32.524962: step 121700, loss = 0.42, batch loss = 0.24 (37.2 examples/sec; 0.215 sec/batch; 12h:35m:36s remains)
INFO - root - 2017-12-16 22:15:34.832656: step 121710, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 12h:34m:47s remains)
INFO - root - 2017-12-16 22:15:37.010204: step 121720, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 12h:45m:31s remains)
INFO - root - 2017-12-16 22:15:39.219382: step 121730, loss = 0.47, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 12h:24m:41s remains)
INFO - root - 2017-12-16 22:15:41.433893: step 121740, loss = 0.47, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 13h:40m:40s remains)
INFO - root - 2017-12-16 22:15:43.643904: step 121750, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 12h:58m:49s remains)
INFO - root - 2017-12-16 22:15:45.852850: step 121760, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 13h:09m:52s remains)
INFO - root - 2017-12-16 22:15:48.052362: step 121770, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 12h:47m:52s remains)
INFO - root - 2017-12-16 22:15:50.265748: step 121780, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.215 sec/batch; 12h:33m:54s remains)
INFO - root - 2017-12-16 22:15:52.465375: step 121790, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 12h:38m:48s remains)
INFO - root - 2017-12-16 22:15:54.691494: step 121800, loss = 0.52, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 13h:07m:13s remains)
INFO - root - 2017-12-16 22:15:57.000609: step 121810, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 12h:45m:52s remains)
INFO - root - 2017-12-16 22:15:59.187311: step 121820, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 12h:46m:49s remains)
INFO - root - 2017-12-16 22:16:01.411211: step 121830, loss = 0.49, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 13h:03m:07s remains)
INFO - root - 2017-12-16 22:16:03.667490: step 121840, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 12h:50m:53s remains)
INFO - root - 2017-12-16 22:16:05.891844: step 121850, loss = 0.45, batch loss = 0.27 (34.8 examples/sec; 0.230 sec/batch; 13h:27m:52s remains)
INFO - root - 2017-12-16 22:16:08.114349: step 121860, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 12h:59m:50s remains)
INFO - root - 2017-12-16 22:16:10.314720: step 121870, loss = 0.44, batch loss = 0.26 (38.0 examples/sec; 0.211 sec/batch; 12h:19m:03s remains)
INFO - root - 2017-12-16 22:16:12.524870: step 121880, loss = 0.54, batch loss = 0.36 (37.2 examples/sec; 0.215 sec/batch; 12h:34m:01s remains)
INFO - root - 2017-12-16 22:16:14.703984: step 121890, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 13h:04m:40s remains)
INFO - root - 2017-12-16 22:16:16.900801: step 121900, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 13h:07m:10s remains)
INFO - root - 2017-12-16 22:16:19.227641: step 121910, loss = 0.46, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 13h:12m:15s remains)
INFO - root - 2017-12-16 22:16:21.456447: step 121920, loss = 0.50, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 12h:34m:47s remains)
INFO - root - 2017-12-16 22:16:23.676408: step 121930, loss = 0.45, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 13h:01m:15s remains)
INFO - root - 2017-12-16 22:16:25.866562: step 121940, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 12h:49m:04s remains)
INFO - root - 2017-12-16 22:16:28.082783: step 121950, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 12h:43m:20s remains)
INFO - root - 2017-12-16 22:16:30.275063: step 121960, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 12h:52m:35s remains)
INFO - root - 2017-12-16 22:16:32.490241: step 121970, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 13h:04m:27s remains)
INFO - root - 2017-12-16 22:16:34.687797: step 121980, loss = 0.52, batch loss = 0.34 (37.3 examples/sec; 0.214 sec/batch; 12h:31m:40s remains)
INFO - root - 2017-12-16 22:16:36.904489: step 121990, loss = 0.49, batch loss = 0.31 (33.8 examples/sec; 0.237 sec/batch; 13h:50m:42s remains)
INFO - root - 2017-12-16 22:16:39.152469: step 122000, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 12h:25m:04s remains)
INFO - root - 2017-12-16 22:16:41.470507: step 122010, loss = 0.44, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 13h:05m:59s remains)
INFO - root - 2017-12-16 22:16:43.671759: step 122020, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.221 sec/batch; 12h:53m:35s remains)
INFO - root - 2017-12-16 22:16:45.903946: step 122030, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 12h:48m:24s remains)
INFO - root - 2017-12-16 22:16:48.103229: step 122040, loss = 0.55, batch loss = 0.38 (35.2 examples/sec; 0.227 sec/batch; 13h:16m:08s remains)
INFO - root - 2017-12-16 22:16:50.307524: step 122050, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 12h:37m:05s remains)
INFO - root - 2017-12-16 22:16:52.538845: step 122060, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 12h:58m:31s remains)
INFO - root - 2017-12-16 22:16:54.748359: step 122070, loss = 0.49, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 12h:24m:26s remains)
INFO - root - 2017-12-16 22:16:56.968509: step 122080, loss = 0.49, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 13h:05m:56s remains)
INFO - root - 2017-12-16 22:16:59.194094: step 122090, loss = 0.51, batch loss = 0.34 (35.3 examples/sec; 0.226 sec/batch; 13h:14m:11s remains)
INFO - root - 2017-12-16 22:17:01.386341: step 122100, loss = 0.47, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 12h:52m:02s remains)
INFO - root - 2017-12-16 22:17:03.728563: step 122110, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.215 sec/batch; 12h:32m:51s remains)
INFO - root - 2017-12-16 22:17:05.931820: step 122120, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 12h:33m:09s remains)
INFO - root - 2017-12-16 22:17:08.131852: step 122130, loss = 0.54, batch loss = 0.37 (35.7 examples/sec; 0.224 sec/batch; 13h:04m:58s remains)
INFO - root - 2017-12-16 22:17:10.348910: step 122140, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 12h:51m:45s remains)
INFO - root - 2017-12-16 22:17:12.597981: step 122150, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 12h:56m:38s remains)
INFO - root - 2017-12-16 22:17:14.796836: step 122160, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 12h:23m:43s remains)
INFO - root - 2017-12-16 22:17:17.005036: step 122170, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 12h:52m:02s remains)
INFO - root - 2017-12-16 22:17:19.186816: step 122180, loss = 0.45, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 12h:28m:51s remains)
INFO - root - 2017-12-16 22:17:21.406227: step 122190, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 12h:43m:51s remains)
INFO - root - 2017-12-16 22:17:23.622280: step 122200, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 13h:17m:15s remains)
INFO - root - 2017-12-16 22:17:25.928375: step 122210, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 12h:38m:31s remains)
INFO - root - 2017-12-16 22:17:28.149886: step 122220, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.232 sec/batch; 13h:34m:22s remains)
INFO - root - 2017-12-16 22:17:30.396097: step 122230, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 12h:44m:57s remains)
INFO - root - 2017-12-16 22:17:32.621347: step 122240, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 12h:47m:16s remains)
INFO - root - 2017-12-16 22:17:34.824587: step 122250, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 12h:49m:01s remains)
INFO - root - 2017-12-16 22:17:37.044735: step 122260, loss = 0.44, batch loss = 0.27 (36.0 examples/sec; 0.223 sec/batch; 12h:59m:44s remains)
INFO - root - 2017-12-16 22:17:39.285390: step 122270, loss = 0.48, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 12h:50m:38s remains)
INFO - root - 2017-12-16 22:17:41.494752: step 122280, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 12h:30m:46s remains)
INFO - root - 2017-12-16 22:17:43.700085: step 122290, loss = 0.49, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 12h:53m:37s remains)
INFO - root - 2017-12-16 22:17:45.902930: step 122300, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 12h:56m:55s remains)
INFO - root - 2017-12-16 22:17:48.188145: step 122310, loss = 0.55, batch loss = 0.37 (36.8 examples/sec; 0.217 sec/batch; 12h:41m:52s remains)
INFO - root - 2017-12-16 22:17:50.388298: step 122320, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 13h:02m:11s remains)
INFO - root - 2017-12-16 22:17:52.551114: step 122330, loss = 0.50, batch loss = 0.32 (37.7 examples/sec; 0.212 sec/batch; 12h:23m:11s remains)
INFO - root - 2017-12-16 22:17:54.768597: step 122340, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 12h:45m:16s remains)
INFO - root - 2017-12-16 22:17:56.947072: step 122350, loss = 0.44, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 12h:44m:28s remains)
INFO - root - 2017-12-16 22:17:59.148956: step 122360, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 12h:46m:05s remains)
INFO - root - 2017-12-16 22:18:01.341383: step 122370, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 12h:44m:48s remains)
INFO - root - 2017-12-16 22:18:03.534991: step 122380, loss = 0.49, batch loss = 0.31 (34.4 examples/sec; 0.232 sec/batch; 13h:33m:26s remains)
INFO - root - 2017-12-16 22:18:05.708226: step 122390, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 12h:49m:55s remains)
INFO - root - 2017-12-16 22:18:07.927624: step 122400, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 12h:28m:09s remains)
INFO - root - 2017-12-16 22:18:10.220527: step 122410, loss = 0.47, batch loss = 0.29 (34.0 examples/sec; 0.235 sec/batch; 13h:44m:13s remains)
INFO - root - 2017-12-16 22:18:12.422934: step 122420, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 12h:57m:09s remains)
INFO - root - 2017-12-16 22:18:14.608668: step 122430, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 12h:38m:18s remains)
INFO - root - 2017-12-16 22:18:16.791346: step 122440, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 12h:50m:25s remains)
INFO - root - 2017-12-16 22:18:18.998101: step 122450, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 12h:53m:53s remains)
INFO - root - 2017-12-16 22:18:21.217340: step 122460, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 13h:10m:49s remains)
INFO - root - 2017-12-16 22:18:23.406662: step 122470, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.223 sec/batch; 13h:01m:53s remains)
INFO - root - 2017-12-16 22:18:25.604269: step 122480, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 12h:41m:31s remains)
INFO - root - 2017-12-16 22:18:27.779479: step 122490, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 12h:27m:10s remains)
INFO - root - 2017-12-16 22:18:29.981266: step 122500, loss = 0.50, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 13h:02m:05s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-122500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-122500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 22:18:32.762039: step 122510, loss = 0.46, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 12h:50m:56s remains)
INFO - root - 2017-12-16 22:18:34.932842: step 122520, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.215 sec/batch; 12h:33m:43s remains)
INFO - root - 2017-12-16 22:18:37.165094: step 122530, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 12h:57m:53s remains)
INFO - root - 2017-12-16 22:18:39.434461: step 122540, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 12h:44m:43s remains)
INFO - root - 2017-12-16 22:18:41.668661: step 122550, loss = 0.52, batch loss = 0.34 (37.7 examples/sec; 0.212 sec/batch; 12h:22m:35s remains)
INFO - root - 2017-12-16 22:18:43.887392: step 122560, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 12h:47m:23s remains)
INFO - root - 2017-12-16 22:18:46.095083: step 122570, loss = 0.46, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 12h:51m:04s remains)
INFO - root - 2017-12-16 22:18:48.312710: step 122580, loss = 0.48, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 12h:56m:58s remains)
INFO - root - 2017-12-16 22:18:50.530394: step 122590, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 12h:30m:26s remains)
INFO - root - 2017-12-16 22:18:52.691541: step 122600, loss = 0.48, batch loss = 0.30 (37.9 examples/sec; 0.211 sec/batch; 12h:19m:09s remains)
INFO - root - 2017-12-16 22:18:55.022202: step 122610, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 12h:52m:13s remains)
INFO - root - 2017-12-16 22:18:57.210677: step 122620, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 12h:25m:45s remains)
INFO - root - 2017-12-16 22:18:59.417500: step 122630, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 12h:37m:47s remains)
INFO - root - 2017-12-16 22:19:01.640913: step 122640, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 13h:05m:23s remains)
INFO - root - 2017-12-16 22:19:03.865027: step 122650, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 12h:49m:49s remains)
INFO - root - 2017-12-16 22:19:06.056944: step 122660, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 12h:32m:56s remains)
INFO - root - 2017-12-16 22:19:08.286537: step 122670, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 12h:50m:42s remains)
INFO - root - 2017-12-16 22:19:10.512746: step 122680, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 12h:37m:20s remains)
INFO - root - 2017-12-16 22:19:12.757475: step 122690, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 12h:40m:44s remains)
INFO - root - 2017-12-16 22:19:14.958144: step 122700, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 12h:39m:41s remains)
INFO - root - 2017-12-16 22:19:17.306823: step 122710, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 12h:48m:33s remains)
INFO - root - 2017-12-16 22:19:19.536146: step 122720, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 12h:38m:52s remains)
INFO - root - 2017-12-16 22:19:21.737613: step 122730, loss = 0.47, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 12h:27m:57s remains)
INFO - root - 2017-12-16 22:19:23.984684: step 122740, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 13h:06m:06s remains)
INFO - root - 2017-12-16 22:19:26.187463: step 122750, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 12h:54m:44s remains)
INFO - root - 2017-12-16 22:19:28.399781: step 122760, loss = 0.41, batch loss = 0.23 (36.1 examples/sec; 0.222 sec/batch; 12h:55m:08s remains)
INFO - root - 2017-12-16 22:19:30.604048: step 122770, loss = 0.52, batch loss = 0.34 (37.9 examples/sec; 0.211 sec/batch; 12h:17m:11s remains)
INFO - root - 2017-12-16 22:19:32.876692: step 122780, loss = 0.46, batch loss = 0.28 (33.1 examples/sec; 0.242 sec/batch; 14h:04m:41s remains)
INFO - root - 2017-12-16 22:19:35.094318: step 122790, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 12h:36m:08s remains)
INFO - root - 2017-12-16 22:19:37.285554: step 122800, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 13h:30m:36s remains)
INFO - root - 2017-12-16 22:19:39.627976: step 122810, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 12h:50m:21s remains)
INFO - root - 2017-12-16 22:19:41.865377: step 122820, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 13h:09m:28s remains)
INFO - root - 2017-12-16 22:19:44.088253: step 122830, loss = 0.44, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 12h:56m:01s remains)
INFO - root - 2017-12-16 22:19:46.306840: step 122840, loss = 0.51, batch loss = 0.33 (34.9 examples/sec; 0.229 sec/batch; 13h:20m:52s remains)
INFO - root - 2017-12-16 22:19:48.529799: step 122850, loss = 0.55, batch loss = 0.37 (34.5 examples/sec; 0.232 sec/batch; 13h:30m:25s remains)
INFO - root - 2017-12-16 22:19:50.722647: step 122860, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 12h:49m:59s remains)
INFO - root - 2017-12-16 22:19:52.907426: step 122870, loss = 0.49, batch loss = 0.31 (37.9 examples/sec; 0.211 sec/batch; 12h:17m:31s remains)
INFO - root - 2017-12-16 22:19:55.140230: step 122880, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 12h:57m:06s remains)
INFO - root - 2017-12-16 22:19:57.346976: step 122890, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 12h:59m:03s remains)
INFO - root - 2017-12-16 22:19:59.608865: step 122900, loss = 0.50, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 13h:23m:05s remains)
INFO - root - 2017-12-16 22:20:01.907075: step 122910, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 12h:59m:01s remains)
INFO - root - 2017-12-16 22:20:04.123727: step 122920, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 12h:42m:34s remains)
INFO - root - 2017-12-16 22:20:06.340068: step 122930, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 12h:55m:14s remains)
INFO - root - 2017-12-16 22:20:08.515634: step 122940, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 12h:30m:47s remains)
INFO - root - 2017-12-16 22:20:10.740449: step 122950, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 12h:54m:37s remains)
INFO - root - 2017-12-16 22:20:12.950828: step 122960, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 12h:49m:53s remains)
INFO - root - 2017-12-16 22:20:15.162282: step 122970, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 12h:37m:44s remains)
INFO - root - 2017-12-16 22:20:17.363384: step 122980, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 12h:55m:02s remains)
INFO - root - 2017-12-16 22:20:19.542398: step 122990, loss = 0.48, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 12h:43m:22s remains)
INFO - root - 2017-12-16 22:20:21.729892: step 123000, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 12h:41m:01s remains)
INFO - root - 2017-12-16 22:20:24.068087: step 123010, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 13h:04m:47s remains)
INFO - root - 2017-12-16 22:20:26.284103: step 123020, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 12h:55m:18s remains)
INFO - root - 2017-12-16 22:20:28.481331: step 123030, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 12h:58m:55s remains)
INFO - root - 2017-12-16 22:20:30.720207: step 123040, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 13h:13m:05s remains)
INFO - root - 2017-12-16 22:20:32.950344: step 123050, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 13h:02m:06s remains)
INFO - root - 2017-12-16 22:20:35.152925: step 123060, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 12h:54m:49s remains)
INFO - root - 2017-12-16 22:20:37.340002: step 123070, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 12h:56m:32s remains)
INFO - root - 2017-12-16 22:20:39.539643: step 123080, loss = 0.55, batch loss = 0.37 (36.1 examples/sec; 0.222 sec/batch; 12h:54m:16s remains)
INFO - root - 2017-12-16 22:20:41.782824: step 123090, loss = 0.55, batch loss = 0.37 (35.6 examples/sec; 0.225 sec/batch; 13h:04m:21s remains)
INFO - root - 2017-12-16 22:20:44.013872: step 123100, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 13h:26m:34s remains)
INFO - root - 2017-12-16 22:20:46.331089: step 123110, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 12h:32m:42s remains)
INFO - root - 2017-12-16 22:20:48.536548: step 123120, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 13h:00m:28s remains)
INFO - root - 2017-12-16 22:20:50.753669: step 123130, loss = 0.41, batch loss = 0.23 (35.4 examples/sec; 0.226 sec/batch; 13h:08m:58s remains)
INFO - root - 2017-12-16 22:20:52.928244: step 123140, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 12h:34m:34s remains)
INFO - root - 2017-12-16 22:20:55.156589: step 123150, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 12h:59m:43s remains)
INFO - root - 2017-12-16 22:20:57.375983: step 123160, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 12h:40m:09s remains)
INFO - root - 2017-12-16 22:20:59.591590: step 123170, loss = 0.47, batch loss = 0.29 (34.6 examples/sec; 0.231 sec/batch; 13h:27m:30s remains)
INFO - root - 2017-12-16 22:21:01.803583: step 123180, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 12h:31m:12s remains)
INFO - root - 2017-12-16 22:21:04.047463: step 123190, loss = 0.48, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 12h:42m:48s remains)
INFO - root - 2017-12-16 22:21:06.277399: step 123200, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.224 sec/batch; 13h:02m:51s remains)
INFO - root - 2017-12-16 22:21:08.620985: step 123210, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 13h:08m:40s remains)
INFO - root - 2017-12-16 22:21:10.794455: step 123220, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.214 sec/batch; 12h:24m:46s remains)
INFO - root - 2017-12-16 22:21:12.998334: step 123230, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 12h:35m:56s remains)
INFO - root - 2017-12-16 22:21:15.222835: step 123240, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 12h:53m:38s remains)
INFO - root - 2017-12-16 22:21:17.457344: step 123250, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 12h:53m:44s remains)
INFO - root - 2017-12-16 22:21:19.651607: step 123260, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 12h:45m:19s remains)
INFO - root - 2017-12-16 22:21:21.870524: step 123270, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 12h:30m:47s remains)
INFO - root - 2017-12-16 22:21:24.105010: step 123280, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 12h:25m:13s remains)
INFO - root - 2017-12-16 22:21:26.326823: step 123290, loss = 0.52, batch loss = 0.35 (34.0 examples/sec; 0.235 sec/batch; 13h:40m:29s remains)
INFO - root - 2017-12-16 22:21:28.562418: step 123300, loss = 0.42, batch loss = 0.24 (34.8 examples/sec; 0.230 sec/batch; 13h:20m:28s remains)
INFO - root - 2017-12-16 22:21:30.891182: step 123310, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 12h:58m:33s remains)
INFO - root - 2017-12-16 22:21:33.071809: step 123320, loss = 0.43, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 12h:42m:30s remains)
INFO - root - 2017-12-16 22:21:35.291938: step 123330, loss = 0.51, batch loss = 0.33 (35.0 examples/sec; 0.228 sec/batch; 13h:16m:12s remains)
INFO - root - 2017-12-16 22:21:37.547646: step 123340, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 13h:02m:50s remains)
INFO - root - 2017-12-16 22:21:39.780971: step 123350, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 12h:34m:29s remains)
INFO - root - 2017-12-16 22:21:42.003388: step 123360, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 12h:42m:55s remains)
INFO - root - 2017-12-16 22:21:44.284428: step 123370, loss = 0.51, batch loss = 0.34 (33.8 examples/sec; 0.237 sec/batch; 13h:45m:21s remains)
INFO - root - 2017-12-16 22:21:46.526349: step 123380, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 12h:51m:02s remains)
INFO - root - 2017-12-16 22:21:48.689500: step 123390, loss = 0.43, batch loss = 0.26 (38.3 examples/sec; 0.209 sec/batch; 12h:07m:36s remains)
INFO - root - 2017-12-16 22:21:50.892713: step 123400, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 13h:09m:25s remains)
INFO - root - 2017-12-16 22:21:53.257092: step 123410, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 13h:09m:32s remains)
INFO - root - 2017-12-16 22:21:55.491456: step 123420, loss = 0.46, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 13h:10m:14s remains)
INFO - root - 2017-12-16 22:21:57.734200: step 123430, loss = 0.50, batch loss = 0.32 (33.0 examples/sec; 0.243 sec/batch; 14h:05m:12s remains)
INFO - root - 2017-12-16 22:21:59.933573: step 123440, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 12h:53m:45s remains)
INFO - root - 2017-12-16 22:22:02.127471: step 123450, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 12h:42m:55s remains)
INFO - root - 2017-12-16 22:22:04.369309: step 123460, loss = 0.55, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 12h:45m:58s remains)
INFO - root - 2017-12-16 22:22:06.567353: step 123470, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 12h:39m:03s remains)
INFO - root - 2017-12-16 22:22:08.776479: step 123480, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 12h:38m:19s remains)
INFO - root - 2017-12-16 22:22:11.002147: step 123490, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 12h:40m:25s remains)
INFO - root - 2017-12-16 22:22:13.201458: step 123500, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.219 sec/batch; 12h:42m:13s remains)
INFO - root - 2017-12-16 22:22:15.546428: step 123510, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 12h:43m:57s remains)
INFO - root - 2017-12-16 22:22:17.775535: step 123520, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 12h:42m:59s remains)
INFO - root - 2017-12-16 22:22:20.017697: step 123530, loss = 0.49, batch loss = 0.31 (34.0 examples/sec; 0.235 sec/batch; 13h:39m:36s remains)
INFO - root - 2017-12-16 22:22:22.239368: step 123540, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 12h:29m:34s remains)
INFO - root - 2017-12-16 22:22:24.486755: step 123550, loss = 0.42, batch loss = 0.24 (34.8 examples/sec; 0.230 sec/batch; 13h:19m:59s remains)
INFO - root - 2017-12-16 22:22:26.747654: step 123560, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 13h:12m:46s remains)
INFO - root - 2017-12-16 22:22:28.932434: step 123570, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 12h:43m:51s remains)
INFO - root - 2017-12-16 22:22:31.139094: step 123580, loss = 0.60, batch loss = 0.42 (35.7 examples/sec; 0.224 sec/batch; 12h:59m:27s remains)
INFO - root - 2017-12-16 22:22:33.354992: step 123590, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 12h:59m:25s remains)
INFO - root - 2017-12-16 22:22:35.581259: step 123600, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 13h:02m:51s remains)
INFO - root - 2017-12-16 22:22:37.972378: step 123610, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 12h:57m:37s remains)
INFO - root - 2017-12-16 22:22:40.167704: step 123620, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 12h:28m:16s remains)
INFO - root - 2017-12-16 22:22:42.394979: step 123630, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 12h:30m:30s remains)
INFO - root - 2017-12-16 22:22:44.578704: step 123640, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 12h:35m:35s remains)
INFO - root - 2017-12-16 22:22:46.744573: step 123650, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 12h:24m:32s remains)
INFO - root - 2017-12-16 22:22:48.946412: step 123660, loss = 0.43, batch loss = 0.25 (35.0 examples/sec; 0.229 sec/batch; 13h:15m:42s remains)
INFO - root - 2017-12-16 22:22:51.171190: step 123670, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 12h:54m:23s remains)
INFO - root - 2017-12-16 22:22:53.381318: step 123680, loss = 0.47, batch loss = 0.29 (34.3 examples/sec; 0.233 sec/batch; 13h:31m:43s remains)
INFO - root - 2017-12-16 22:22:55.598820: step 123690, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 12h:39m:37s remains)
INFO - root - 2017-12-16 22:22:57.824126: step 123700, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 12h:28m:21s remains)
INFO - root - 2017-12-16 22:23:00.146505: step 123710, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 12h:28m:50s remains)
INFO - root - 2017-12-16 22:23:02.342527: step 123720, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 12h:44m:08s remains)
INFO - root - 2017-12-16 22:23:04.568453: step 123730, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 12h:44m:05s remains)
INFO - root - 2017-12-16 22:23:06.781643: step 123740, loss = 0.55, batch loss = 0.37 (36.0 examples/sec; 0.222 sec/batch; 12h:52m:14s remains)
INFO - root - 2017-12-16 22:23:08.983009: step 123750, loss = 0.52, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 12h:50m:43s remains)
INFO - root - 2017-12-16 22:23:11.202016: step 123760, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.228 sec/batch; 13h:11m:45s remains)
INFO - root - 2017-12-16 22:23:13.396378: step 123770, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 12h:53m:32s remains)
INFO - root - 2017-12-16 22:23:15.612354: step 123780, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 12h:56m:01s remains)
INFO - root - 2017-12-16 22:23:17.833392: step 123790, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 12h:57m:30s remains)
INFO - root - 2017-12-16 22:23:20.041411: step 123800, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.228 sec/batch; 13h:14m:32s remains)
INFO - root - 2017-12-16 22:23:22.357219: step 123810, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 12h:30m:38s remains)
INFO - root - 2017-12-16 22:23:24.604594: step 123820, loss = 0.44, batch loss = 0.26 (35.0 examples/sec; 0.229 sec/batch; 13h:15m:23s remains)
INFO - root - 2017-12-16 22:23:26.821777: step 123830, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 12h:41m:49s remains)
INFO - root - 2017-12-16 22:23:29.030586: step 123840, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.218 sec/batch; 12h:39m:44s remains)
INFO - root - 2017-12-16 22:23:31.215368: step 123850, loss = 0.52, batch loss = 0.34 (37.5 examples/sec; 0.213 sec/batch; 12h:21m:31s remains)
INFO - root - 2017-12-16 22:23:33.402866: step 123860, loss = 0.49, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 12h:33m:03s remains)
INFO - root - 2017-12-16 22:23:35.654463: step 123870, loss = 0.46, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 13h:00m:51s remains)
INFO - root - 2017-12-16 22:23:37.843648: step 123880, loss = 0.43, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 12h:41m:33s remains)
INFO - root - 2017-12-16 22:23:40.043370: step 123890, loss = 0.52, batch loss = 0.34 (38.0 examples/sec; 0.210 sec/batch; 12h:11m:21s remains)
INFO - root - 2017-12-16 22:23:42.276620: step 123900, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 13h:00m:54s remains)
INFO - root - 2017-12-16 22:23:44.670616: step 123910, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.216 sec/batch; 12h:29m:30s remains)
INFO - root - 2017-12-16 22:23:46.879927: step 123920, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.216 sec/batch; 12h:30m:19s remains)
INFO - root - 2017-12-16 22:23:49.105282: step 123930, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 12h:50m:59s remains)
INFO - root - 2017-12-16 22:23:51.351433: step 123940, loss = 0.54, batch loss = 0.36 (35.5 examples/sec; 0.226 sec/batch; 13h:04m:19s remains)
INFO - root - 2017-12-16 22:23:53.541876: step 123950, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 12h:32m:14s remains)
INFO - root - 2017-12-16 22:23:55.764877: step 123960, loss = 0.42, batch loss = 0.25 (35.2 examples/sec; 0.228 sec/batch; 13h:10m:52s remains)
INFO - root - 2017-12-16 22:23:57.993119: step 123970, loss = 0.45, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 13h:07m:55s remains)
INFO - root - 2017-12-16 22:24:00.229929: step 123980, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 12h:46m:50s remains)
INFO - root - 2017-12-16 22:24:02.454219: step 123990, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 13h:00m:35s remains)
INFO - root - 2017-12-16 22:24:04.696247: step 124000, loss = 0.56, batch loss = 0.38 (36.5 examples/sec; 0.219 sec/batch; 12h:42m:08s remains)
INFO - root - 2017-12-16 22:24:07.066478: step 124010, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.228 sec/batch; 13h:10m:42s remains)
INFO - root - 2017-12-16 22:24:09.277457: step 124020, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 12h:43m:19s remains)
INFO - root - 2017-12-16 22:24:11.467061: step 124030, loss = 0.48, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 12h:52m:54s remains)
INFO - root - 2017-12-16 22:24:13.675424: step 124040, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 12h:37m:46s remains)
INFO - root - 2017-12-16 22:24:15.849642: step 124050, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 12h:27m:44s remains)
INFO - root - 2017-12-16 22:24:18.050152: step 124060, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 13h:05m:49s remains)
INFO - root - 2017-12-16 22:24:20.251666: step 124070, loss = 0.42, batch loss = 0.24 (36.0 examples/sec; 0.222 sec/batch; 12h:51m:03s remains)
INFO - root - 2017-12-16 22:24:22.441860: step 124080, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 12h:42m:32s remains)
INFO - root - 2017-12-16 22:24:24.696929: step 124090, loss = 0.48, batch loss = 0.30 (34.7 examples/sec; 0.231 sec/batch; 13h:21m:40s remains)
INFO - root - 2017-12-16 22:24:26.948043: step 124100, loss = 0.55, batch loss = 0.37 (33.1 examples/sec; 0.242 sec/batch; 14h:00m:30s remains)
INFO - root - 2017-12-16 22:24:29.275375: step 124110, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 12h:42m:02s remains)
INFO - root - 2017-12-16 22:24:31.498908: step 124120, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.215 sec/batch; 12h:28m:21s remains)
INFO - root - 2017-12-16 22:24:33.734703: step 124130, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 12h:39m:24s remains)
INFO - root - 2017-12-16 22:24:35.972097: step 124140, loss = 0.49, batch loss = 0.31 (33.0 examples/sec; 0.243 sec/batch; 14h:02m:48s remains)
INFO - root - 2017-12-16 22:24:38.181874: step 124150, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 12h:27m:02s remains)
INFO - root - 2017-12-16 22:24:40.424994: step 124160, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 12h:42m:02s remains)
INFO - root - 2017-12-16 22:24:42.642421: step 124170, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 12h:55m:58s remains)
INFO - root - 2017-12-16 22:24:44.872430: step 124180, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 13h:00m:55s remains)
INFO - root - 2017-12-16 22:24:47.128715: step 124190, loss = 0.46, batch loss = 0.29 (33.9 examples/sec; 0.236 sec/batch; 13h:39m:07s remains)
INFO - root - 2017-12-16 22:24:49.364424: step 124200, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 12h:40m:11s remains)
INFO - root - 2017-12-16 22:24:51.675136: step 124210, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 12h:30m:34s remains)
INFO - root - 2017-12-16 22:24:53.886939: step 124220, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 13h:11m:36s remains)
INFO - root - 2017-12-16 22:24:56.134676: step 124230, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 12h:48m:51s remains)
INFO - root - 2017-12-16 22:24:58.361016: step 124240, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 12h:53m:32s remains)
INFO - root - 2017-12-16 22:25:00.628453: step 124250, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.219 sec/batch; 12h:41m:48s remains)
INFO - root - 2017-12-16 22:25:02.847188: step 124260, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 13h:03m:43s remains)
INFO - root - 2017-12-16 22:25:05.066376: step 124270, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 12h:46m:08s remains)
INFO - root - 2017-12-16 22:25:07.256475: step 124280, loss = 0.47, batch loss = 0.30 (37.5 examples/sec; 0.214 sec/batch; 12h:21m:15s remains)
INFO - root - 2017-12-16 22:25:09.466660: step 124290, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 12h:36m:44s remains)
INFO - root - 2017-12-16 22:25:11.657365: step 124300, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 12h:29m:13s remains)
INFO - root - 2017-12-16 22:25:14.030759: step 124310, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 13h:02m:13s remains)
INFO - root - 2017-12-16 22:25:16.246117: step 124320, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 12h:26m:28s remains)
INFO - root - 2017-12-16 22:25:18.471628: step 124330, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 12h:53m:55s remains)
INFO - root - 2017-12-16 22:25:20.681439: step 124340, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 12h:49m:03s remains)
INFO - root - 2017-12-16 22:25:22.915926: step 124350, loss = 0.53, batch loss = 0.35 (37.4 examples/sec; 0.214 sec/batch; 12h:22m:00s remains)
INFO - root - 2017-12-16 22:25:25.143483: step 124360, loss = 0.56, batch loss = 0.38 (33.7 examples/sec; 0.237 sec/batch; 13h:43m:47s remains)
INFO - root - 2017-12-16 22:25:27.367124: step 124370, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 12h:41m:53s remains)
INFO - root - 2017-12-16 22:25:29.559881: step 124380, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 12h:36m:19s remains)
INFO - root - 2017-12-16 22:25:31.774516: step 124390, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 12h:42m:27s remains)
INFO - root - 2017-12-16 22:25:34.014380: step 124400, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 12h:48m:52s remains)
INFO - root - 2017-12-16 22:25:36.331503: step 124410, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 12h:18m:26s remains)
INFO - root - 2017-12-16 22:25:38.580029: step 124420, loss = 0.51, batch loss = 0.33 (34.5 examples/sec; 0.232 sec/batch; 13h:23m:09s remains)
INFO - root - 2017-12-16 22:25:40.811246: step 124430, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 12h:42m:54s remains)
INFO - root - 2017-12-16 22:25:43.022024: step 124440, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 12h:32m:00s remains)
INFO - root - 2017-12-16 22:25:45.233344: step 124450, loss = 0.53, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 12h:59m:58s remains)
INFO - root - 2017-12-16 22:25:47.432606: step 124460, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 13h:11m:20s remains)
INFO - root - 2017-12-16 22:25:49.652720: step 124470, loss = 0.48, batch loss = 0.30 (34.7 examples/sec; 0.231 sec/batch; 13h:20m:11s remains)
INFO - root - 2017-12-16 22:25:51.874789: step 124480, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 12h:35m:25s remains)
INFO - root - 2017-12-16 22:25:54.093137: step 124490, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 12h:38m:24s remains)
INFO - root - 2017-12-16 22:25:56.299747: step 124500, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 13h:09m:41s remains)
INFO - root - 2017-12-16 22:25:58.698093: step 124510, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 12h:35m:06s remains)
INFO - root - 2017-12-16 22:26:00.943351: step 124520, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 12h:54m:06s remains)
INFO - root - 2017-12-16 22:26:03.191812: step 124530, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 12h:46m:23s remains)
INFO - root - 2017-12-16 22:26:05.395748: step 124540, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 12h:34m:09s remains)
INFO - root - 2017-12-16 22:26:07.656420: step 124550, loss = 0.54, batch loss = 0.36 (35.0 examples/sec; 0.228 sec/batch; 13h:11m:48s remains)
INFO - root - 2017-12-16 22:26:09.908943: step 124560, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 12h:40m:29s remains)
INFO - root - 2017-12-16 22:26:12.123739: step 124570, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 13h:08m:12s remains)
INFO - root - 2017-12-16 22:26:14.378490: step 124580, loss = 0.61, batch loss = 0.43 (33.6 examples/sec; 0.238 sec/batch; 13h:45m:44s remains)
INFO - root - 2017-12-16 22:26:16.630556: step 124590, loss = 0.42, batch loss = 0.24 (34.8 examples/sec; 0.230 sec/batch; 13h:16m:09s remains)
INFO - root - 2017-12-16 22:26:18.844271: step 124600, loss = 0.44, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 12h:53m:31s remains)
INFO - root - 2017-12-16 22:26:21.188927: step 124610, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 12h:35m:33s remains)
INFO - root - 2017-12-16 22:26:23.399944: step 124620, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 12h:25m:41s remains)
INFO - root - 2017-12-16 22:26:25.689696: step 124630, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.233 sec/batch; 13h:25m:42s remains)
INFO - root - 2017-12-16 22:26:27.882905: step 124640, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 12h:39m:23s remains)
INFO - root - 2017-12-16 22:26:30.092094: step 124650, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 12h:52m:51s remains)
INFO - root - 2017-12-16 22:26:32.298213: step 124660, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 12h:32m:42s remains)
INFO - root - 2017-12-16 22:26:34.525853: step 124670, loss = 0.46, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 12h:34m:59s remains)
INFO - root - 2017-12-16 22:26:36.740026: step 124680, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 12h:28m:10s remains)
INFO - root - 2017-12-16 22:26:38.987970: step 124690, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 12h:59m:31s remains)
INFO - root - 2017-12-16 22:26:41.213653: step 124700, loss = 0.46, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 12h:28m:02s remains)
INFO - root - 2017-12-16 22:26:43.540915: step 124710, loss = 0.44, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 12h:52m:32s remains)
INFO - root - 2017-12-16 22:26:45.748472: step 124720, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 12h:36m:02s remains)
INFO - root - 2017-12-16 22:26:47.958345: step 124730, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 12h:51m:05s remains)
INFO - root - 2017-12-16 22:26:50.156232: step 124740, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 12h:40m:52s remains)
INFO - root - 2017-12-16 22:26:52.383097: step 124750, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 12h:52m:27s remains)
INFO - root - 2017-12-16 22:26:54.654706: step 124760, loss = 0.51, batch loss = 0.33 (34.6 examples/sec; 0.231 sec/batch; 13h:21m:02s remains)
INFO - root - 2017-12-16 22:26:56.879638: step 124770, loss = 0.57, batch loss = 0.39 (37.0 examples/sec; 0.216 sec/batch; 12h:28m:19s remains)
INFO - root - 2017-12-16 22:26:59.096315: step 124780, loss = 0.44, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 12h:59m:05s remains)
INFO - root - 2017-12-16 22:27:01.306646: step 124790, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 12h:42m:08s remains)
INFO - root - 2017-12-16 22:27:03.528675: step 124800, loss = 0.55, batch loss = 0.37 (37.3 examples/sec; 0.214 sec/batch; 12h:22m:00s remains)
INFO - root - 2017-12-16 22:27:05.864980: step 124810, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 12h:44m:36s remains)
INFO - root - 2017-12-16 22:27:08.131453: step 124820, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 12h:50m:24s remains)
INFO - root - 2017-12-16 22:27:10.371728: step 124830, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 12h:57m:32s remains)
INFO - root - 2017-12-16 22:27:12.557196: step 124840, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 12h:27m:29s remains)
INFO - root - 2017-12-16 22:27:14.780084: step 124850, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 13h:16m:18s remains)
INFO - root - 2017-12-16 22:27:16.977607: step 124860, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 12h:37m:50s remains)
INFO - root - 2017-12-16 22:27:19.194268: step 124870, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 12h:34m:40s remains)
INFO - root - 2017-12-16 22:27:21.399583: step 124880, loss = 0.43, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 12h:26m:09s remains)
INFO - root - 2017-12-16 22:27:23.589109: step 124890, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 12h:42m:32s remains)
INFO - root - 2017-12-16 22:27:25.759506: step 124900, loss = 0.51, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 12h:27m:18s remains)
INFO - root - 2017-12-16 22:27:28.073783: step 124910, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 12h:22m:34s remains)
INFO - root - 2017-12-16 22:27:30.321682: step 124920, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 12h:33m:37s remains)
INFO - root - 2017-12-16 22:27:32.520418: step 124930, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 12h:39m:55s remains)
INFO - root - 2017-12-16 22:27:34.741793: step 124940, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 12h:30m:34s remains)
INFO - root - 2017-12-16 22:27:36.922838: step 124950, loss = 0.58, batch loss = 0.40 (37.0 examples/sec; 0.216 sec/batch; 12h:28m:32s remains)
INFO - root - 2017-12-16 22:27:39.140053: step 124960, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 12h:34m:00s remains)
INFO - root - 2017-12-16 22:27:41.351706: step 124970, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 13h:07m:46s remains)
INFO - root - 2017-12-16 22:27:43.537010: step 124980, loss = 0.49, batch loss = 0.32 (37.6 examples/sec; 0.213 sec/batch; 12h:16m:17s remains)
INFO - root - 2017-12-16 22:27:45.715542: step 124990, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 12h:41m:37s remains)
INFO - root - 2017-12-16 22:27:47.899695: step 125000, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 12h:33m:34s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-125000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-125000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 22:27:50.645483: step 125010, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 12h:53m:20s remains)
INFO - root - 2017-12-16 22:27:52.807626: step 125020, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 12h:21m:44s remains)
INFO - root - 2017-12-16 22:27:54.973119: step 125030, loss = 0.58, batch loss = 0.40 (37.8 examples/sec; 0.212 sec/batch; 12h:11m:32s remains)
INFO - root - 2017-12-16 22:27:57.158928: step 125040, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 12h:31m:48s remains)
INFO - root - 2017-12-16 22:27:59.354638: step 125050, loss = 0.47, batch loss = 0.29 (38.3 examples/sec; 0.209 sec/batch; 12h:01m:44s remains)
INFO - root - 2017-12-16 22:28:01.538538: step 125060, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.215 sec/batch; 12h:24m:59s remains)
INFO - root - 2017-12-16 22:28:03.711420: step 125070, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 12h:46m:59s remains)
INFO - root - 2017-12-16 22:28:05.934693: step 125080, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 12h:31m:13s remains)
INFO - root - 2017-12-16 22:28:08.132266: step 125090, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 12h:40m:19s remains)
INFO - root - 2017-12-16 22:28:10.361424: step 125100, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 12h:53m:36s remains)
INFO - root - 2017-12-16 22:28:12.697578: step 125110, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 12h:42m:01s remains)
INFO - root - 2017-12-16 22:28:14.943606: step 125120, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 12h:45m:14s remains)
INFO - root - 2017-12-16 22:28:17.140852: step 125130, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 12h:32m:09s remains)
INFO - root - 2017-12-16 22:28:19.405965: step 125140, loss = 0.43, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 12h:23m:39s remains)
INFO - root - 2017-12-16 22:28:21.610955: step 125150, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 12h:58m:08s remains)
INFO - root - 2017-12-16 22:28:23.838969: step 125160, loss = 0.53, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 12h:55m:15s remains)
INFO - root - 2017-12-16 22:28:26.066821: step 125170, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 12h:30m:08s remains)
INFO - root - 2017-12-16 22:28:28.282210: step 125180, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 12h:29m:23s remains)
INFO - root - 2017-12-16 22:28:30.468447: step 125190, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 12h:34m:49s remains)
INFO - root - 2017-12-16 22:28:32.660545: step 125200, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 13h:15m:00s remains)
INFO - root - 2017-12-16 22:28:34.988361: step 125210, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 12h:32m:17s remains)
INFO - root - 2017-12-16 22:28:37.201575: step 125220, loss = 0.56, batch loss = 0.38 (36.5 examples/sec; 0.219 sec/batch; 12h:37m:24s remains)
INFO - root - 2017-12-16 22:28:39.424122: step 125230, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 12h:21m:08s remains)
INFO - root - 2017-12-16 22:28:41.639878: step 125240, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 12h:20m:20s remains)
INFO - root - 2017-12-16 22:28:43.846404: step 125250, loss = 0.56, batch loss = 0.38 (36.2 examples/sec; 0.221 sec/batch; 12h:43m:50s remains)
INFO - root - 2017-12-16 22:28:46.035131: step 125260, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 12h:58m:21s remains)
INFO - root - 2017-12-16 22:28:48.211420: step 125270, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 12h:18m:28s remains)
INFO - root - 2017-12-16 22:28:50.380975: step 125280, loss = 0.42, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 12h:31m:03s remains)
INFO - root - 2017-12-16 22:28:52.576421: step 125290, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 12h:54m:46s remains)
INFO - root - 2017-12-16 22:28:54.773918: step 125300, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 13h:07m:30s remains)
INFO - root - 2017-12-16 22:28:57.093548: step 125310, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 12h:26m:12s remains)
INFO - root - 2017-12-16 22:28:59.314123: step 125320, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 12h:36m:58s remains)
INFO - root - 2017-12-16 22:29:01.526649: step 125330, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 12h:49m:49s remains)
INFO - root - 2017-12-16 22:29:03.742200: step 125340, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 12h:24m:47s remains)
INFO - root - 2017-12-16 22:29:05.919970: step 125350, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 12h:38m:19s remains)
INFO - root - 2017-12-16 22:29:08.122081: step 125360, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 12h:34m:37s remains)
INFO - root - 2017-12-16 22:29:10.320101: step 125370, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.218 sec/batch; 12h:33m:33s remains)
INFO - root - 2017-12-16 22:29:12.497491: step 125380, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 12h:27m:48s remains)
INFO - root - 2017-12-16 22:29:14.731902: step 125390, loss = 0.49, batch loss = 0.31 (34.7 examples/sec; 0.230 sec/batch; 13h:15m:09s remains)
INFO - root - 2017-12-16 22:29:16.993839: step 125400, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 12h:34m:17s remains)
INFO - root - 2017-12-16 22:29:19.315380: step 125410, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 12h:55m:19s remains)
INFO - root - 2017-12-16 22:29:21.538371: step 125420, loss = 0.54, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 12h:39m:59s remains)
INFO - root - 2017-12-16 22:29:23.754710: step 125430, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 12h:11m:55s remains)
INFO - root - 2017-12-16 22:29:25.976144: step 125440, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 12h:51m:01s remains)
INFO - root - 2017-12-16 22:29:28.177399: step 125450, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 12h:46m:45s remains)
INFO - root - 2017-12-16 22:29:30.370440: step 125460, loss = 0.45, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 12h:40m:35s remains)
INFO - root - 2017-12-16 22:29:32.580939: step 125470, loss = 0.47, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 12h:26m:36s remains)
INFO - root - 2017-12-16 22:29:34.805954: step 125480, loss = 0.50, batch loss = 0.33 (34.0 examples/sec; 0.235 sec/batch; 13h:31m:38s remains)
INFO - root - 2017-12-16 22:29:37.005365: step 125490, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 12h:34m:43s remains)
INFO - root - 2017-12-16 22:29:39.194222: step 125500, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 12h:19m:39s remains)
INFO - root - 2017-12-16 22:29:41.537394: step 125510, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 12h:28m:39s remains)
INFO - root - 2017-12-16 22:29:43.720988: step 125520, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 12h:47m:03s remains)
INFO - root - 2017-12-16 22:29:45.921662: step 125530, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 12h:44m:31s remains)
INFO - root - 2017-12-16 22:29:48.137634: step 125540, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 12h:44m:47s remains)
INFO - root - 2017-12-16 22:29:50.279426: step 125550, loss = 0.48, batch loss = 0.30 (38.3 examples/sec; 0.209 sec/batch; 11h:59m:50s remains)
INFO - root - 2017-12-16 22:29:52.460061: step 125560, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 12h:25m:56s remains)
INFO - root - 2017-12-16 22:29:54.663881: step 125570, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 13h:20m:15s remains)
INFO - root - 2017-12-16 22:29:56.899805: step 125580, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 12h:45m:02s remains)
INFO - root - 2017-12-16 22:29:59.113066: step 125590, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 12h:52m:55s remains)
INFO - root - 2017-12-16 22:30:01.303472: step 125600, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 12h:35m:51s remains)
INFO - root - 2017-12-16 22:30:03.631040: step 125610, loss = 0.55, batch loss = 0.37 (35.5 examples/sec; 0.226 sec/batch; 12h:57m:34s remains)
INFO - root - 2017-12-16 22:30:05.828186: step 125620, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 12h:44m:28s remains)
INFO - root - 2017-12-16 22:30:08.070178: step 125630, loss = 0.46, batch loss = 0.28 (34.4 examples/sec; 0.233 sec/batch; 13h:22m:11s remains)
INFO - root - 2017-12-16 22:30:10.317899: step 125640, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 12h:28m:39s remains)
INFO - root - 2017-12-16 22:30:12.518387: step 125650, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 12h:34m:46s remains)
INFO - root - 2017-12-16 22:30:14.704616: step 125660, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 12h:35m:35s remains)
INFO - root - 2017-12-16 22:30:16.897044: step 125670, loss = 0.53, batch loss = 0.36 (35.4 examples/sec; 0.226 sec/batch; 12h:59m:30s remains)
INFO - root - 2017-12-16 22:30:19.134497: step 125680, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 12h:46m:41s remains)
INFO - root - 2017-12-16 22:30:21.344332: step 125690, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 12h:23m:03s remains)
INFO - root - 2017-12-16 22:30:23.535831: step 125700, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 12h:52m:12s remains)
INFO - root - 2017-12-16 22:30:25.868597: step 125710, loss = 0.52, batch loss = 0.34 (34.1 examples/sec; 0.234 sec/batch; 13h:28m:08s remains)
INFO - root - 2017-12-16 22:30:28.059259: step 125720, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.223 sec/batch; 12h:46m:50s remains)
INFO - root - 2017-12-16 22:30:30.322815: step 125730, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 12h:23m:56s remains)
INFO - root - 2017-12-16 22:30:32.537641: step 125740, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 12h:58m:21s remains)
INFO - root - 2017-12-16 22:30:34.746968: step 125750, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 12h:49m:13s remains)
INFO - root - 2017-12-16 22:30:36.957587: step 125760, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 12h:59m:27s remains)
INFO - root - 2017-12-16 22:30:39.196621: step 125770, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 12h:51m:06s remains)
INFO - root - 2017-12-16 22:30:41.400136: step 125780, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 12h:18m:55s remains)
INFO - root - 2017-12-16 22:30:43.574588: step 125790, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 12h:57m:11s remains)
INFO - root - 2017-12-16 22:30:45.747446: step 125800, loss = 0.51, batch loss = 0.34 (37.7 examples/sec; 0.212 sec/batch; 12h:11m:03s remains)
INFO - root - 2017-12-16 22:30:48.049306: step 125810, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 12h:24m:58s remains)
INFO - root - 2017-12-16 22:30:50.260556: step 125820, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 12h:37m:29s remains)
INFO - root - 2017-12-16 22:30:52.455618: step 125830, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 12h:23m:07s remains)
INFO - root - 2017-12-16 22:30:54.659671: step 125840, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 12h:45m:42s remains)
INFO - root - 2017-12-16 22:30:56.886609: step 125850, loss = 0.55, batch loss = 0.37 (36.0 examples/sec; 0.222 sec/batch; 12h:45m:20s remains)
INFO - root - 2017-12-16 22:30:59.097403: step 125860, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 12h:15m:11s remains)
INFO - root - 2017-12-16 22:31:01.273828: step 125870, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 12h:34m:09s remains)
INFO - root - 2017-12-16 22:31:03.499888: step 125880, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 12h:24m:40s remains)
INFO - root - 2017-12-16 22:31:05.712336: step 125890, loss = 0.43, batch loss = 0.26 (34.4 examples/sec; 0.232 sec/batch; 13h:20m:07s remains)
INFO - root - 2017-12-16 22:31:07.937774: step 125900, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 12h:59m:07s remains)
INFO - root - 2017-12-16 22:31:10.287872: step 125910, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 13h:00m:01s remains)
INFO - root - 2017-12-16 22:31:12.485357: step 125920, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 12h:47m:17s remains)
INFO - root - 2017-12-16 22:31:14.744002: step 125930, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.233 sec/batch; 13h:21m:25s remains)
INFO - root - 2017-12-16 22:31:16.945534: step 125940, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 12h:39m:25s remains)
INFO - root - 2017-12-16 22:31:19.142920: step 125950, loss = 0.57, batch loss = 0.39 (37.3 examples/sec; 0.214 sec/batch; 12h:17m:24s remains)
INFO - root - 2017-12-16 22:31:21.358400: step 125960, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 12h:58m:41s remains)
INFO - root - 2017-12-16 22:31:23.588355: step 125970, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 12h:22m:56s remains)
INFO - root - 2017-12-16 22:31:25.821499: step 125980, loss = 0.50, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 12h:36m:49s remains)
INFO - root - 2017-12-16 22:31:28.028353: step 125990, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 12h:45m:23s remains)
INFO - root - 2017-12-16 22:31:30.216377: step 126000, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 12h:52m:59s remains)
INFO - root - 2017-12-16 22:31:32.563961: step 126010, loss = 0.44, batch loss = 0.26 (34.1 examples/sec; 0.234 sec/batch; 13h:26m:53s remains)
INFO - root - 2017-12-16 22:31:34.789289: step 126020, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.221 sec/batch; 12h:41m:57s remains)
INFO - root - 2017-12-16 22:31:37.006607: step 126030, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 12h:33m:58s remains)
INFO - root - 2017-12-16 22:31:39.206367: step 126040, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.221 sec/batch; 12h:39m:20s remains)
INFO - root - 2017-12-16 22:31:41.441920: step 126050, loss = 0.44, batch loss = 0.27 (35.2 examples/sec; 0.228 sec/batch; 13h:02m:53s remains)
INFO - root - 2017-12-16 22:31:43.652613: step 126060, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 12h:28m:13s remains)
INFO - root - 2017-12-16 22:31:45.906431: step 126070, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 12h:26m:26s remains)
INFO - root - 2017-12-16 22:31:48.115215: step 126080, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 12h:29m:02s remains)
INFO - root - 2017-12-16 22:31:50.301452: step 126090, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 12h:22m:34s remains)
INFO - root - 2017-12-16 22:31:52.494416: step 126100, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 12h:27m:05s remains)
INFO - root - 2017-12-16 22:31:54.850000: step 126110, loss = 0.47, batch loss = 0.29 (34.4 examples/sec; 0.232 sec/batch; 13h:19m:39s remains)
INFO - root - 2017-12-16 22:31:57.043818: step 126120, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 12h:11m:05s remains)
INFO - root - 2017-12-16 22:31:59.247929: step 126130, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 12h:17m:31s remains)
INFO - root - 2017-12-16 22:32:01.457693: step 126140, loss = 0.46, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 12h:40m:08s remains)
INFO - root - 2017-12-16 22:32:03.674944: step 126150, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 12h:55m:49s remains)
INFO - root - 2017-12-16 22:32:05.903174: step 126160, loss = 0.45, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 12h:27m:28s remains)
INFO - root - 2017-12-16 22:32:08.131112: step 126170, loss = 0.58, batch loss = 0.40 (34.7 examples/sec; 0.230 sec/batch; 13h:12m:00s remains)
INFO - root - 2017-12-16 22:32:10.356144: step 126180, loss = 0.47, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 12h:09m:20s remains)
INFO - root - 2017-12-16 22:32:12.598334: step 126190, loss = 0.58, batch loss = 0.40 (33.6 examples/sec; 0.238 sec/batch; 13h:39m:24s remains)
INFO - root - 2017-12-16 22:32:14.824666: step 126200, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.226 sec/batch; 12h:58m:44s remains)
INFO - root - 2017-12-16 22:32:17.165661: step 126210, loss = 0.45, batch loss = 0.27 (33.2 examples/sec; 0.241 sec/batch; 13h:49m:00s remains)
INFO - root - 2017-12-16 22:32:19.409369: step 126220, loss = 0.50, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 13h:09m:26s remains)
INFO - root - 2017-12-16 22:32:21.595835: step 126230, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 12h:45m:58s remains)
INFO - root - 2017-12-16 22:32:23.765413: step 126240, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 12h:22m:17s remains)
INFO - root - 2017-12-16 22:32:25.941987: step 126250, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 12h:27m:41s remains)
INFO - root - 2017-12-16 22:32:28.138053: step 126260, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 12h:44m:09s remains)
INFO - root - 2017-12-16 22:32:30.339740: step 126270, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 12h:15m:18s remains)
INFO - root - 2017-12-16 22:32:32.535702: step 126280, loss = 0.49, batch loss = 0.31 (37.8 examples/sec; 0.212 sec/batch; 12h:08m:10s remains)
INFO - root - 2017-12-16 22:32:34.729971: step 126290, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.223 sec/batch; 12h:47m:41s remains)
INFO - root - 2017-12-16 22:32:36.922216: step 126300, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 12h:40m:55s remains)
INFO - root - 2017-12-16 22:32:39.282078: step 126310, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 12h:30m:32s remains)
INFO - root - 2017-12-16 22:32:41.475533: step 126320, loss = 0.47, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 12h:33m:34s remains)
INFO - root - 2017-12-16 22:32:43.693376: step 126330, loss = 0.52, batch loss = 0.34 (35.0 examples/sec; 0.229 sec/batch; 13h:06m:09s remains)
INFO - root - 2017-12-16 22:32:45.918082: step 126340, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 13h:10m:42s remains)
INFO - root - 2017-12-16 22:32:48.105213: step 126350, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 12h:46m:09s remains)
INFO - root - 2017-12-16 22:32:50.280959: step 126360, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 12h:25m:12s remains)
INFO - root - 2017-12-16 22:32:52.478424: step 126370, loss = 0.54, batch loss = 0.36 (35.6 examples/sec; 0.225 sec/batch; 12h:52m:27s remains)
INFO - root - 2017-12-16 22:32:54.701496: step 126380, loss = 0.53, batch loss = 0.35 (35.6 examples/sec; 0.224 sec/batch; 12h:51m:03s remains)
INFO - root - 2017-12-16 22:32:56.941963: step 126390, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 12h:25m:01s remains)
INFO - root - 2017-12-16 22:32:59.158574: step 126400, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 12h:40m:23s remains)
INFO - root - 2017-12-16 22:33:01.533012: step 126410, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 13h:08m:32s remains)
INFO - root - 2017-12-16 22:33:03.730782: step 126420, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 12h:33m:48s remains)
INFO - root - 2017-12-16 22:33:05.964408: step 126430, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 12h:56m:35s remains)
INFO - root - 2017-12-16 22:33:08.174461: step 126440, loss = 0.54, batch loss = 0.36 (36.1 examples/sec; 0.221 sec/batch; 12h:40m:05s remains)
INFO - root - 2017-12-16 22:33:10.403253: step 126450, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 12h:20m:17s remains)
INFO - root - 2017-12-16 22:33:12.614721: step 126460, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 12h:43m:00s remains)
INFO - root - 2017-12-16 22:33:14.834523: step 126470, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 12h:16m:23s remains)
INFO - root - 2017-12-16 22:33:17.015301: step 126480, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 12h:20m:22s remains)
INFO - root - 2017-12-16 22:33:19.228090: step 126490, loss = 0.57, batch loss = 0.40 (37.1 examples/sec; 0.216 sec/batch; 12h:21m:21s remains)
INFO - root - 2017-12-16 22:33:21.445823: step 126500, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 12h:55m:17s remains)
INFO - root - 2017-12-16 22:33:23.767326: step 126510, loss = 0.59, batch loss = 0.41 (37.5 examples/sec; 0.214 sec/batch; 12h:13m:06s remains)
INFO - root - 2017-12-16 22:33:26.022868: step 126520, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 12h:29m:48s remains)
INFO - root - 2017-12-16 22:33:28.272244: step 126530, loss = 0.47, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 12h:33m:17s remains)
INFO - root - 2017-12-16 22:33:30.478897: step 126540, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 12h:21m:33s remains)
INFO - root - 2017-12-16 22:33:32.701798: step 126550, loss = 0.44, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 12h:13m:47s remains)
INFO - root - 2017-12-16 22:33:34.886384: step 126560, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 12h:33m:47s remains)
INFO - root - 2017-12-16 22:33:37.071877: step 126570, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 12h:30m:00s remains)
INFO - root - 2017-12-16 22:33:39.288297: step 126580, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 12h:21m:52s remains)
INFO - root - 2017-12-16 22:33:41.514091: step 126590, loss = 0.45, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 12h:45m:26s remains)
INFO - root - 2017-12-16 22:33:43.742830: step 126600, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 12h:44m:34s remains)
INFO - root - 2017-12-16 22:33:46.062556: step 126610, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.232 sec/batch; 13h:14m:28s remains)
INFO - root - 2017-12-16 22:33:48.288912: step 126620, loss = 0.52, batch loss = 0.34 (34.4 examples/sec; 0.232 sec/batch; 13h:16m:53s remains)
INFO - root - 2017-12-16 22:33:50.478936: step 126630, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 12h:32m:11s remains)
INFO - root - 2017-12-16 22:33:52.682815: step 126640, loss = 0.57, batch loss = 0.39 (35.4 examples/sec; 0.226 sec/batch; 12h:54m:34s remains)
INFO - root - 2017-12-16 22:33:54.914124: step 126650, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 13h:09m:13s remains)
INFO - root - 2017-12-16 22:33:57.091580: step 126660, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 12h:27m:05s remains)
INFO - root - 2017-12-16 22:33:59.289927: step 126670, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 12h:22m:19s remains)
INFO - root - 2017-12-16 22:34:01.508974: step 126680, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 12h:54m:49s remains)
INFO - root - 2017-12-16 22:34:03.731129: step 126690, loss = 0.45, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 12h:14m:17s remains)
INFO - root - 2017-12-16 22:34:05.925580: step 126700, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 12h:44m:34s remains)
INFO - root - 2017-12-16 22:34:08.258956: step 126710, loss = 0.48, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 12h:58m:28s remains)
INFO - root - 2017-12-16 22:34:10.479116: step 126720, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 12h:35m:06s remains)
INFO - root - 2017-12-16 22:34:12.676948: step 126730, loss = 0.54, batch loss = 0.36 (34.6 examples/sec; 0.231 sec/batch; 13h:12m:00s remains)
INFO - root - 2017-12-16 22:34:14.890350: step 126740, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 12h:31m:44s remains)
INFO - root - 2017-12-16 22:34:17.108267: step 126750, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 12h:45m:34s remains)
INFO - root - 2017-12-16 22:34:19.307338: step 126760, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 12h:25m:02s remains)
INFO - root - 2017-12-16 22:34:21.489510: step 126770, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.224 sec/batch; 12h:46m:25s remains)
INFO - root - 2017-12-16 22:34:23.749405: step 126780, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 12h:48m:26s remains)
INFO - root - 2017-12-16 22:34:25.946048: step 126790, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 12h:35m:03s remains)
INFO - root - 2017-12-16 22:34:28.153839: step 126800, loss = 0.46, batch loss = 0.28 (38.5 examples/sec; 0.208 sec/batch; 11h:52m:48s remains)
INFO - root - 2017-12-16 22:34:30.518806: step 126810, loss = 0.55, batch loss = 0.37 (37.1 examples/sec; 0.216 sec/batch; 12h:19m:30s remains)
INFO - root - 2017-12-16 22:34:32.722421: step 126820, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 12h:46m:49s remains)
INFO - root - 2017-12-16 22:34:34.944879: step 126830, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 12h:23m:06s remains)
INFO - root - 2017-12-16 22:34:37.180946: step 126840, loss = 0.54, batch loss = 0.36 (37.0 examples/sec; 0.216 sec/batch; 12h:22m:05s remains)
INFO - root - 2017-12-16 22:34:39.405533: step 126850, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 13h:07m:41s remains)
INFO - root - 2017-12-16 22:34:41.607883: step 126860, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 12h:12m:55s remains)
INFO - root - 2017-12-16 22:34:43.826907: step 126870, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 12h:20m:13s remains)
INFO - root - 2017-12-16 22:34:46.063216: step 126880, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 12h:26m:16s remains)
INFO - root - 2017-12-16 22:34:48.270522: step 126890, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 12h:59m:59s remains)
INFO - root - 2017-12-16 22:34:50.494486: step 126900, loss = 0.55, batch loss = 0.37 (37.3 examples/sec; 0.214 sec/batch; 12h:14m:56s remains)
INFO - root - 2017-12-16 22:34:52.856418: step 126910, loss = 0.49, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 12h:30m:26s remains)
INFO - root - 2017-12-16 22:34:55.084431: step 126920, loss = 0.43, batch loss = 0.25 (33.7 examples/sec; 0.237 sec/batch; 13h:33m:10s remains)
INFO - root - 2017-12-16 22:34:57.315219: step 126930, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 12h:45m:42s remains)
INFO - root - 2017-12-16 22:34:59.579744: step 126940, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 12h:20m:04s remains)
INFO - root - 2017-12-16 22:35:01.785500: step 126950, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 12h:25m:23s remains)
INFO - root - 2017-12-16 22:35:03.984893: step 126960, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 12h:45m:35s remains)
INFO - root - 2017-12-16 22:35:06.192058: step 126970, loss = 0.49, batch loss = 0.32 (34.6 examples/sec; 0.231 sec/batch; 13h:10m:56s remains)
INFO - root - 2017-12-16 22:35:08.404653: step 126980, loss = 0.48, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 12h:40m:19s remains)
INFO - root - 2017-12-16 22:35:10.596789: step 126990, loss = 0.48, batch loss = 0.30 (38.0 examples/sec; 0.211 sec/batch; 12h:01m:19s remains)
INFO - root - 2017-12-16 22:35:12.817599: step 127000, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 12h:37m:57s remains)
INFO - root - 2017-12-16 22:35:15.176907: step 127010, loss = 0.46, batch loss = 0.28 (34.1 examples/sec; 0.235 sec/batch; 13h:23m:36s remains)
INFO - root - 2017-12-16 22:35:17.410237: step 127020, loss = 0.50, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 13h:07m:03s remains)
INFO - root - 2017-12-16 22:35:19.590105: step 127030, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 12h:16m:05s remains)
INFO - root - 2017-12-16 22:35:21.838334: step 127040, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 12h:51m:43s remains)
INFO - root - 2017-12-16 22:35:24.049621: step 127050, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 12h:22m:26s remains)
INFO - root - 2017-12-16 22:35:26.269149: step 127060, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 12h:09m:04s remains)
INFO - root - 2017-12-16 22:35:28.498321: step 127070, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 12h:49m:02s remains)
INFO - root - 2017-12-16 22:35:30.715636: step 127080, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 12h:27m:33s remains)
INFO - root - 2017-12-16 22:35:32.950817: step 127090, loss = 0.56, batch loss = 0.38 (35.3 examples/sec; 0.226 sec/batch; 12h:54m:48s remains)
INFO - root - 2017-12-16 22:35:35.182234: step 127100, loss = 0.55, batch loss = 0.37 (38.3 examples/sec; 0.209 sec/batch; 11h:55m:53s remains)
INFO - root - 2017-12-16 22:35:37.568365: step 127110, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.226 sec/batch; 12h:51m:59s remains)
INFO - root - 2017-12-16 22:35:39.746497: step 127120, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 12h:14m:48s remains)
INFO - root - 2017-12-16 22:35:41.998859: step 127130, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 12h:41m:51s remains)
INFO - root - 2017-12-16 22:35:44.180524: step 127140, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 12h:14m:40s remains)
INFO - root - 2017-12-16 22:35:46.371618: step 127150, loss = 0.46, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 12h:52m:18s remains)
INFO - root - 2017-12-16 22:35:48.595663: step 127160, loss = 0.51, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 12h:30m:16s remains)
INFO - root - 2017-12-16 22:35:50.775663: step 127170, loss = 0.51, batch loss = 0.34 (37.6 examples/sec; 0.213 sec/batch; 12h:07m:35s remains)
INFO - root - 2017-12-16 22:35:52.984699: step 127180, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 12h:44m:21s remains)
INFO - root - 2017-12-16 22:35:55.184682: step 127190, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 12h:32m:18s remains)
INFO - root - 2017-12-16 22:35:57.415901: step 127200, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 12h:32m:24s remains)
INFO - root - 2017-12-16 22:35:59.788260: step 127210, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 12h:42m:26s remains)
INFO - root - 2017-12-16 22:36:01.982422: step 127220, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.226 sec/batch; 12h:54m:19s remains)
INFO - root - 2017-12-16 22:36:04.256879: step 127230, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 12h:54m:11s remains)
INFO - root - 2017-12-16 22:36:06.492861: step 127240, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 12h:45m:54s remains)
INFO - root - 2017-12-16 22:36:08.699541: step 127250, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 12h:11m:42s remains)
INFO - root - 2017-12-16 22:36:10.920193: step 127260, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 12h:38m:36s remains)
INFO - root - 2017-12-16 22:36:13.130725: step 127270, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 12h:45m:45s remains)
INFO - root - 2017-12-16 22:36:15.330808: step 127280, loss = 0.45, batch loss = 0.27 (34.8 examples/sec; 0.230 sec/batch; 13h:07m:12s remains)
INFO - root - 2017-12-16 22:36:17.548739: step 127290, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 12h:29m:57s remains)
INFO - root - 2017-12-16 22:36:19.845611: step 127300, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 12h:35m:08s remains)
INFO - root - 2017-12-16 22:36:22.160841: step 127310, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 12h:17m:58s remains)
INFO - root - 2017-12-16 22:36:24.377967: step 127320, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 12h:34m:56s remains)
INFO - root - 2017-12-16 22:36:26.587515: step 127330, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 12h:23m:36s remains)
INFO - root - 2017-12-16 22:36:28.808373: step 127340, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 12h:26m:15s remains)
INFO - root - 2017-12-16 22:36:31.029113: step 127350, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 12h:29m:06s remains)
INFO - root - 2017-12-16 22:36:33.242226: step 127360, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 12h:42m:03s remains)
INFO - root - 2017-12-16 22:36:35.482647: step 127370, loss = 0.50, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 13h:06m:44s remains)
INFO - root - 2017-12-16 22:36:37.710472: step 127380, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 12h:38m:11s remains)
INFO - root - 2017-12-16 22:36:39.967429: step 127390, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 12h:32m:11s remains)
INFO - root - 2017-12-16 22:36:42.172320: step 127400, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 12h:41m:56s remains)
INFO - root - 2017-12-16 22:36:44.525282: step 127410, loss = 0.56, batch loss = 0.38 (36.3 examples/sec; 0.221 sec/batch; 12h:34m:20s remains)
INFO - root - 2017-12-16 22:36:46.735886: step 127420, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 12h:57m:35s remains)
INFO - root - 2017-12-16 22:36:48.930574: step 127430, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 12h:37m:17s remains)
INFO - root - 2017-12-16 22:36:51.140652: step 127440, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 12h:20m:40s remains)
INFO - root - 2017-12-16 22:36:53.383335: step 127450, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 12h:56m:17s remains)
INFO - root - 2017-12-16 22:36:55.575052: step 127460, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 12h:23m:33s remains)
INFO - root - 2017-12-16 22:36:57.813828: step 127470, loss = 0.45, batch loss = 0.27 (34.7 examples/sec; 0.230 sec/batch; 13h:07m:05s remains)
INFO - root - 2017-12-16 22:37:00.026392: step 127480, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 12h:29m:34s remains)
INFO - root - 2017-12-16 22:37:02.257659: step 127490, loss = 0.56, batch loss = 0.38 (36.9 examples/sec; 0.217 sec/batch; 12h:20m:07s remains)
INFO - root - 2017-12-16 22:37:04.473425: step 127500, loss = 0.47, batch loss = 0.29 (34.3 examples/sec; 0.233 sec/batch; 13h:16m:08s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-127500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-127500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 22:37:07.482427: step 127510, loss = 0.55, batch loss = 0.37 (36.1 examples/sec; 0.222 sec/batch; 12h:37m:40s remains)
INFO - root - 2017-12-16 22:37:09.690668: step 127520, loss = 0.54, batch loss = 0.36 (37.0 examples/sec; 0.216 sec/batch; 12h:17m:47s remains)
INFO - root - 2017-12-16 22:37:11.871088: step 127530, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 12h:14m:57s remains)
INFO - root - 2017-12-16 22:37:14.119787: step 127540, loss = 0.48, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 12h:20m:05s remains)
INFO - root - 2017-12-16 22:37:16.312832: step 127550, loss = 0.48, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 12h:08m:00s remains)
INFO - root - 2017-12-16 22:37:18.521040: step 127560, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 13h:02m:55s remains)
INFO - root - 2017-12-16 22:37:20.768007: step 127570, loss = 0.52, batch loss = 0.34 (33.8 examples/sec; 0.236 sec/batch; 13h:27m:28s remains)
INFO - root - 2017-12-16 22:37:22.982852: step 127580, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 12h:24m:03s remains)
INFO - root - 2017-12-16 22:37:25.197585: step 127590, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 12h:39m:04s remains)
INFO - root - 2017-12-16 22:37:27.434553: step 127600, loss = 0.45, batch loss = 0.27 (33.9 examples/sec; 0.236 sec/batch; 13h:26m:08s remains)
INFO - root - 2017-12-16 22:37:29.785887: step 127610, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 12h:40m:33s remains)
INFO - root - 2017-12-16 22:37:31.981975: step 127620, loss = 0.44, batch loss = 0.27 (34.0 examples/sec; 0.235 sec/batch; 13h:23m:25s remains)
INFO - root - 2017-12-16 22:37:34.220048: step 127630, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 13h:11m:38s remains)
INFO - root - 2017-12-16 22:37:36.439600: step 127640, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 12h:19m:48s remains)
INFO - root - 2017-12-16 22:37:38.642750: step 127650, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 12h:33m:51s remains)
INFO - root - 2017-12-16 22:37:40.846127: step 127660, loss = 0.54, batch loss = 0.36 (38.6 examples/sec; 0.207 sec/batch; 11h:48m:15s remains)
INFO - root - 2017-12-16 22:37:43.085011: step 127670, loss = 0.50, batch loss = 0.32 (33.7 examples/sec; 0.237 sec/batch; 13h:30m:45s remains)
INFO - root - 2017-12-16 22:37:45.313250: step 127680, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 12h:34m:12s remains)
INFO - root - 2017-12-16 22:37:47.537785: step 127690, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 12h:22m:47s remains)
INFO - root - 2017-12-16 22:37:49.719306: step 127700, loss = 0.48, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 12h:35m:30s remains)
INFO - root - 2017-12-16 22:37:52.060319: step 127710, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 12h:08m:24s remains)
INFO - root - 2017-12-16 22:37:54.265865: step 127720, loss = 0.55, batch loss = 0.37 (36.6 examples/sec; 0.218 sec/batch; 12h:25m:21s remains)
INFO - root - 2017-12-16 22:37:56.490390: step 127730, loss = 0.59, batch loss = 0.41 (36.7 examples/sec; 0.218 sec/batch; 12h:23m:25s remains)
INFO - root - 2017-12-16 22:37:58.685509: step 127740, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 12h:38m:40s remains)
INFO - root - 2017-12-16 22:38:00.936012: step 127750, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 12h:28m:12s remains)
INFO - root - 2017-12-16 22:38:03.110972: step 127760, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 12h:52m:10s remains)
INFO - root - 2017-12-16 22:38:05.367917: step 127770, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 12h:22m:34s remains)
INFO - root - 2017-12-16 22:38:07.576597: step 127780, loss = 0.45, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 13h:07m:10s remains)
INFO - root - 2017-12-16 22:38:09.820706: step 127790, loss = 0.43, batch loss = 0.25 (34.6 examples/sec; 0.232 sec/batch; 13h:09m:50s remains)
INFO - root - 2017-12-16 22:38:12.050776: step 127800, loss = 0.54, batch loss = 0.36 (35.6 examples/sec; 0.225 sec/batch; 12h:46m:38s remains)
INFO - root - 2017-12-16 22:38:14.423798: step 127810, loss = 0.44, batch loss = 0.26 (31.7 examples/sec; 0.252 sec/batch; 14h:19m:56s remains)
INFO - root - 2017-12-16 22:38:16.639678: step 127820, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 12h:20m:04s remains)
INFO - root - 2017-12-16 22:38:18.811037: step 127830, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 12h:17m:19s remains)
INFO - root - 2017-12-16 22:38:21.005126: step 127840, loss = 0.51, batch loss = 0.33 (38.4 examples/sec; 0.208 sec/batch; 11h:50m:03s remains)
INFO - root - 2017-12-16 22:38:23.193835: step 127850, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 12h:39m:17s remains)
INFO - root - 2017-12-16 22:38:25.423140: step 127860, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 12h:24m:54s remains)
INFO - root - 2017-12-16 22:38:27.628697: step 127870, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.221 sec/batch; 12h:35m:03s remains)
INFO - root - 2017-12-16 22:38:29.866229: step 127880, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 12h:44m:49s remains)
INFO - root - 2017-12-16 22:38:32.074083: step 127890, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 12h:31m:45s remains)
INFO - root - 2017-12-16 22:38:34.237737: step 127900, loss = 0.44, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 12h:05m:10s remains)
INFO - root - 2017-12-16 22:38:36.591212: step 127910, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 12h:33m:17s remains)
INFO - root - 2017-12-16 22:38:38.829659: step 127920, loss = 0.53, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 12h:40m:35s remains)
INFO - root - 2017-12-16 22:38:41.102293: step 127930, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 12h:28m:13s remains)
INFO - root - 2017-12-16 22:38:43.306145: step 127940, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 12h:37m:56s remains)
INFO - root - 2017-12-16 22:38:45.493806: step 127950, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 12h:22m:10s remains)
INFO - root - 2017-12-16 22:38:47.728585: step 127960, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 12h:23m:13s remains)
INFO - root - 2017-12-16 22:38:49.925729: step 127970, loss = 0.57, batch loss = 0.40 (36.9 examples/sec; 0.217 sec/batch; 12h:18m:30s remains)
INFO - root - 2017-12-16 22:38:52.130170: step 127980, loss = 0.46, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 12h:25m:18s remains)
INFO - root - 2017-12-16 22:38:54.326841: step 127990, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 12h:40m:55s remains)
INFO - root - 2017-12-16 22:38:56.534963: step 128000, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 12h:15m:39s remains)
INFO - root - 2017-12-16 22:38:58.900730: step 128010, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 12h:13m:31s remains)
INFO - root - 2017-12-16 22:39:01.104322: step 128020, loss = 0.55, batch loss = 0.37 (34.9 examples/sec; 0.229 sec/batch; 13h:01m:25s remains)
INFO - root - 2017-12-16 22:39:03.307830: step 128030, loss = 0.50, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 12h:44m:07s remains)
INFO - root - 2017-12-16 22:39:05.538198: step 128040, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 12h:52m:25s remains)
INFO - root - 2017-12-16 22:39:07.736352: step 128050, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 12h:15m:45s remains)
INFO - root - 2017-12-16 22:39:09.919260: step 128060, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 12h:20m:46s remains)
INFO - root - 2017-12-16 22:39:12.127941: step 128070, loss = 0.45, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 12h:39m:56s remains)
INFO - root - 2017-12-16 22:39:14.316969: step 128080, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 12h:25m:45s remains)
INFO - root - 2017-12-16 22:39:16.514038: step 128090, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 12h:28m:13s remains)
INFO - root - 2017-12-16 22:39:18.734706: step 128100, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 12h:36m:14s remains)
INFO - root - 2017-12-16 22:39:21.073498: step 128110, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 12h:08m:10s remains)
INFO - root - 2017-12-16 22:39:23.268854: step 128120, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 12h:46m:37s remains)
INFO - root - 2017-12-16 22:39:25.509546: step 128130, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.230 sec/batch; 13h:04m:59s remains)
INFO - root - 2017-12-16 22:39:27.704095: step 128140, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 12h:22m:11s remains)
INFO - root - 2017-12-16 22:39:29.903894: step 128150, loss = 0.45, batch loss = 0.27 (37.6 examples/sec; 0.213 sec/batch; 12h:05m:25s remains)
INFO - root - 2017-12-16 22:39:32.120568: step 128160, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 12h:27m:04s remains)
INFO - root - 2017-12-16 22:39:34.318610: step 128170, loss = 0.53, batch loss = 0.36 (37.4 examples/sec; 0.214 sec/batch; 12h:08m:48s remains)
INFO - root - 2017-12-16 22:39:36.511041: step 128180, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 12h:30m:53s remains)
INFO - root - 2017-12-16 22:39:38.751975: step 128190, loss = 0.42, batch loss = 0.24 (36.0 examples/sec; 0.222 sec/batch; 12h:35m:54s remains)
INFO - root - 2017-12-16 22:39:40.955820: step 128200, loss = 0.44, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 12h:42m:17s remains)
INFO - root - 2017-12-16 22:39:43.310357: step 128210, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 12h:21m:31s remains)
INFO - root - 2017-12-16 22:39:45.545037: step 128220, loss = 0.45, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 12h:16m:59s remains)
INFO - root - 2017-12-16 22:39:47.771930: step 128230, loss = 0.50, batch loss = 0.32 (38.0 examples/sec; 0.211 sec/batch; 11h:56m:55s remains)
INFO - root - 2017-12-16 22:39:50.003200: step 128240, loss = 0.42, batch loss = 0.24 (36.9 examples/sec; 0.217 sec/batch; 12h:17m:40s remains)
INFO - root - 2017-12-16 22:39:52.206709: step 128250, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 12h:31m:34s remains)
INFO - root - 2017-12-16 22:39:54.441457: step 128260, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 13h:08m:11s remains)
INFO - root - 2017-12-16 22:39:56.641239: step 128270, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.223 sec/batch; 12h:37m:23s remains)
INFO - root - 2017-12-16 22:39:58.837258: step 128280, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 12h:05m:53s remains)
INFO - root - 2017-12-16 22:40:01.082288: step 128290, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 12h:18m:02s remains)
INFO - root - 2017-12-16 22:40:03.324736: step 128300, loss = 0.47, batch loss = 0.29 (33.1 examples/sec; 0.241 sec/batch; 13h:41m:45s remains)
INFO - root - 2017-12-16 22:40:05.661788: step 128310, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 12h:35m:18s remains)
INFO - root - 2017-12-16 22:40:07.899166: step 128320, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 12h:34m:05s remains)
INFO - root - 2017-12-16 22:40:10.076684: step 128330, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 12h:21m:54s remains)
INFO - root - 2017-12-16 22:40:12.302301: step 128340, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 12h:36m:14s remains)
INFO - root - 2017-12-16 22:40:14.512115: step 128350, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 12h:27m:38s remains)
INFO - root - 2017-12-16 22:40:16.708275: step 128360, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 12h:21m:07s remains)
INFO - root - 2017-12-16 22:40:18.901684: step 128370, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 12h:20m:05s remains)
INFO - root - 2017-12-16 22:40:21.143280: step 128380, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 12h:18m:05s remains)
INFO - root - 2017-12-16 22:40:23.329983: step 128390, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.218 sec/batch; 12h:20m:18s remains)
INFO - root - 2017-12-16 22:40:25.528980: step 128400, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 12h:28m:48s remains)
INFO - root - 2017-12-16 22:40:27.882845: step 128410, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 12h:54m:58s remains)
INFO - root - 2017-12-16 22:40:30.090651: step 128420, loss = 0.44, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 12h:41m:49s remains)
INFO - root - 2017-12-16 22:40:32.325648: step 128430, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 12h:42m:57s remains)
INFO - root - 2017-12-16 22:40:34.556946: step 128440, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 12h:41m:03s remains)
INFO - root - 2017-12-16 22:40:36.757032: step 128450, loss = 0.42, batch loss = 0.24 (37.3 examples/sec; 0.215 sec/batch; 12h:10m:21s remains)
INFO - root - 2017-12-16 22:40:38.968711: step 128460, loss = 0.43, batch loss = 0.25 (34.9 examples/sec; 0.229 sec/batch; 12h:58m:51s remains)
INFO - root - 2017-12-16 22:40:41.206574: step 128470, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 12h:27m:52s remains)
INFO - root - 2017-12-16 22:40:43.417273: step 128480, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 12h:34m:10s remains)
INFO - root - 2017-12-16 22:40:45.602111: step 128490, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 12h:19m:03s remains)
INFO - root - 2017-12-16 22:40:47.815554: step 128500, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 12h:52m:07s remains)
INFO - root - 2017-12-16 22:40:50.190870: step 128510, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 12h:38m:40s remains)
INFO - root - 2017-12-16 22:40:52.398356: step 128520, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 12h:27m:08s remains)
INFO - root - 2017-12-16 22:40:54.592689: step 128530, loss = 0.45, batch loss = 0.27 (37.8 examples/sec; 0.212 sec/batch; 12h:00m:08s remains)
INFO - root - 2017-12-16 22:40:56.815303: step 128540, loss = 0.42, batch loss = 0.24 (36.8 examples/sec; 0.217 sec/batch; 12h:19m:10s remains)
INFO - root - 2017-12-16 22:40:59.048393: step 128550, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 12h:15m:04s remains)
INFO - root - 2017-12-16 22:41:01.268644: step 128560, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 12h:32m:42s remains)
INFO - root - 2017-12-16 22:41:03.508928: step 128570, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.215 sec/batch; 12h:12m:09s remains)
INFO - root - 2017-12-16 22:41:05.738291: step 128580, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 12h:26m:34s remains)
INFO - root - 2017-12-16 22:41:07.972190: step 128590, loss = 0.48, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 12h:48m:36s remains)
INFO - root - 2017-12-16 22:41:10.157100: step 128600, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 12h:52m:50s remains)
INFO - root - 2017-12-16 22:41:12.480278: step 128610, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 12h:18m:57s remains)
INFO - root - 2017-12-16 22:41:14.695172: step 128620, loss = 0.50, batch loss = 0.32 (33.9 examples/sec; 0.236 sec/batch; 13h:22m:20s remains)
INFO - root - 2017-12-16 22:41:16.932176: step 128630, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 12h:25m:42s remains)
INFO - root - 2017-12-16 22:41:19.117396: step 128640, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 12h:04m:23s remains)
INFO - root - 2017-12-16 22:41:21.379548: step 128650, loss = 0.46, batch loss = 0.29 (33.6 examples/sec; 0.238 sec/batch; 13h:29m:35s remains)
INFO - root - 2017-12-16 22:41:23.661245: step 128660, loss = 0.50, batch loss = 0.32 (34.6 examples/sec; 0.231 sec/batch; 13h:05m:03s remains)
INFO - root - 2017-12-16 22:41:25.873317: step 128670, loss = 0.47, batch loss = 0.29 (33.4 examples/sec; 0.240 sec/batch; 13h:33m:59s remains)
INFO - root - 2017-12-16 22:41:28.108148: step 128680, loss = 0.46, batch loss = 0.29 (34.7 examples/sec; 0.230 sec/batch; 13h:02m:20s remains)
INFO - root - 2017-12-16 22:41:30.372847: step 128690, loss = 0.44, batch loss = 0.26 (33.1 examples/sec; 0.242 sec/batch; 13h:41m:16s remains)
INFO - root - 2017-12-16 22:41:32.583557: step 128700, loss = 0.46, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 12h:12m:44s remains)
INFO - root - 2017-12-16 22:41:34.941434: step 128710, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 12h:21m:05s remains)
INFO - root - 2017-12-16 22:41:37.146994: step 128720, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 12h:25m:37s remains)
INFO - root - 2017-12-16 22:41:39.405548: step 128730, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 12h:03m:52s remains)
INFO - root - 2017-12-16 22:41:41.612344: step 128740, loss = 0.58, batch loss = 0.40 (36.3 examples/sec; 0.220 sec/batch; 12h:27m:48s remains)
INFO - root - 2017-12-16 22:41:43.835218: step 128750, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 12h:31m:49s remains)
INFO - root - 2017-12-16 22:41:46.066188: step 128760, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 12h:12m:29s remains)
INFO - root - 2017-12-16 22:41:48.292153: step 128770, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 12h:47m:28s remains)
INFO - root - 2017-12-16 22:41:50.510938: step 128780, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 12h:29m:54s remains)
INFO - root - 2017-12-16 22:41:52.718379: step 128790, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 13h:04m:16s remains)
INFO - root - 2017-12-16 22:41:54.982718: step 128800, loss = 0.46, batch loss = 0.28 (32.6 examples/sec; 0.245 sec/batch; 13h:52m:53s remains)
INFO - root - 2017-12-16 22:41:57.366455: step 128810, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 12h:16m:04s remains)
INFO - root - 2017-12-16 22:41:59.570386: step 128820, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 12h:07m:59s remains)
INFO - root - 2017-12-16 22:42:01.828170: step 128830, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 12h:41m:38s remains)
INFO - root - 2017-12-16 22:42:04.019259: step 128840, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 12h:14m:12s remains)
INFO - root - 2017-12-16 22:42:06.268209: step 128850, loss = 0.48, batch loss = 0.30 (33.2 examples/sec; 0.241 sec/batch; 13h:37m:13s remains)
INFO - root - 2017-12-16 22:42:08.520144: step 128860, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 12h:43m:08s remains)
INFO - root - 2017-12-16 22:42:10.694510: step 128870, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 12h:14m:56s remains)
INFO - root - 2017-12-16 22:42:12.921815: step 128880, loss = 0.42, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 12h:39m:58s remains)
INFO - root - 2017-12-16 22:42:15.152038: step 128890, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 12h:12m:20s remains)
INFO - root - 2017-12-16 22:42:17.343584: step 128900, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.224 sec/batch; 12h:41m:33s remains)
INFO - root - 2017-12-16 22:42:19.733047: step 128910, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 12h:42m:00s remains)
INFO - root - 2017-12-16 22:42:21.959638: step 128920, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 12h:45m:35s remains)
INFO - root - 2017-12-16 22:42:24.149525: step 128930, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 12h:25m:37s remains)
INFO - root - 2017-12-16 22:42:26.358191: step 128940, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 12h:29m:03s remains)
INFO - root - 2017-12-16 22:42:28.598835: step 128950, loss = 0.51, batch loss = 0.33 (35.2 examples/sec; 0.227 sec/batch; 12h:50m:27s remains)
INFO - root - 2017-12-16 22:42:30.830494: step 128960, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 12h:37m:36s remains)
INFO - root - 2017-12-16 22:42:33.048327: step 128970, loss = 0.48, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 12h:38m:47s remains)
INFO - root - 2017-12-16 22:42:35.265445: step 128980, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.230 sec/batch; 13h:01m:25s remains)
INFO - root - 2017-12-16 22:42:37.477004: step 128990, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 12h:48m:35s remains)
INFO - root - 2017-12-16 22:42:39.694755: step 129000, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 12h:24m:06s remains)
INFO - root - 2017-12-16 22:42:42.045267: step 129010, loss = 0.55, batch loss = 0.37 (35.4 examples/sec; 0.226 sec/batch; 12h:45m:46s remains)
INFO - root - 2017-12-16 22:42:44.255844: step 129020, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 11h:57m:35s remains)
INFO - root - 2017-12-16 22:42:46.493489: step 129030, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 12h:31m:22s remains)
INFO - root - 2017-12-16 22:42:48.733187: step 129040, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 12h:31m:50s remains)
INFO - root - 2017-12-16 22:42:50.984554: step 129050, loss = 0.51, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 12h:15m:30s remains)
INFO - root - 2017-12-16 22:42:53.215348: step 129060, loss = 0.46, batch loss = 0.29 (35.3 examples/sec; 0.226 sec/batch; 12h:47m:44s remains)
INFO - root - 2017-12-16 22:42:55.454482: step 129070, loss = 0.54, batch loss = 0.36 (36.1 examples/sec; 0.222 sec/batch; 12h:32m:16s remains)
INFO - root - 2017-12-16 22:42:57.683557: step 129080, loss = 0.49, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 12h:52m:12s remains)
INFO - root - 2017-12-16 22:42:59.892956: step 129090, loss = 0.54, batch loss = 0.36 (34.1 examples/sec; 0.234 sec/batch; 13h:14m:14s remains)
INFO - root - 2017-12-16 22:43:02.113124: step 129100, loss = 0.45, batch loss = 0.27 (34.3 examples/sec; 0.233 sec/batch; 13h:10m:21s remains)
INFO - root - 2017-12-16 22:43:04.502459: step 129110, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 12h:05m:23s remains)
INFO - root - 2017-12-16 22:43:06.738563: step 129120, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 13h:02m:56s remains)
INFO - root - 2017-12-16 22:43:08.979030: step 129130, loss = 0.44, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 12h:37m:39s remains)
INFO - root - 2017-12-16 22:43:11.206881: step 129140, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.228 sec/batch; 12h:53m:51s remains)
INFO - root - 2017-12-16 22:43:13.445020: step 129150, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 12h:32m:34s remains)
INFO - root - 2017-12-16 22:43:15.671903: step 129160, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 12h:42m:51s remains)
INFO - root - 2017-12-16 22:43:17.918175: step 129170, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 12h:19m:18s remains)
INFO - root - 2017-12-16 22:43:20.115056: step 129180, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 12h:42m:36s remains)
INFO - root - 2017-12-16 22:43:22.297578: step 129190, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 12h:18m:41s remains)
INFO - root - 2017-12-16 22:43:24.548008: step 129200, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 12h:35m:40s remains)
INFO - root - 2017-12-16 22:43:26.899622: step 129210, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 12h:26m:57s remains)
INFO - root - 2017-12-16 22:43:29.112216: step 129220, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 12h:31m:55s remains)
INFO - root - 2017-12-16 22:43:31.311858: step 129230, loss = 0.53, batch loss = 0.35 (37.1 examples/sec; 0.215 sec/batch; 12h:09m:46s remains)
INFO - root - 2017-12-16 22:43:33.504728: step 129240, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 12h:26m:22s remains)
INFO - root - 2017-12-16 22:43:35.703945: step 129250, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.232 sec/batch; 13h:06m:49s remains)
INFO - root - 2017-12-16 22:43:37.890302: step 129260, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 12h:42m:51s remains)
INFO - root - 2017-12-16 22:43:40.088588: step 129270, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 12h:20m:21s remains)
INFO - root - 2017-12-16 22:43:42.328635: step 129280, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 12h:42m:29s remains)
INFO - root - 2017-12-16 22:43:44.564982: step 129290, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 12h:30m:50s remains)
INFO - root - 2017-12-16 22:43:46.776316: step 129300, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 12h:26m:56s remains)
INFO - root - 2017-12-16 22:43:49.112398: step 129310, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 12h:50m:15s remains)
INFO - root - 2017-12-16 22:43:51.296559: step 129320, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 12h:18m:26s remains)
INFO - root - 2017-12-16 22:43:53.524787: step 129330, loss = 0.42, batch loss = 0.24 (36.0 examples/sec; 0.222 sec/batch; 12h:32m:41s remains)
INFO - root - 2017-12-16 22:43:55.736920: step 129340, loss = 0.57, batch loss = 0.40 (33.6 examples/sec; 0.238 sec/batch; 13h:27m:19s remains)
INFO - root - 2017-12-16 22:43:57.982993: step 129350, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 12h:51m:22s remains)
INFO - root - 2017-12-16 22:44:00.235581: step 129360, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 12h:30m:04s remains)
INFO - root - 2017-12-16 22:44:02.480143: step 129370, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 12h:44m:35s remains)
INFO - root - 2017-12-16 22:44:04.787231: step 129380, loss = 0.50, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 12h:44m:42s remains)
INFO - root - 2017-12-16 22:44:06.988765: step 129390, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 12h:24m:01s remains)
INFO - root - 2017-12-16 22:44:09.190902: step 129400, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 12h:02m:26s remains)
INFO - root - 2017-12-16 22:44:11.514943: step 129410, loss = 0.46, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 12h:23m:43s remains)
INFO - root - 2017-12-16 22:44:13.764154: step 129420, loss = 0.47, batch loss = 0.29 (32.8 examples/sec; 0.244 sec/batch; 13h:46m:13s remains)
INFO - root - 2017-12-16 22:44:15.987200: step 129430, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 12h:36m:29s remains)
INFO - root - 2017-12-16 22:44:18.226113: step 129440, loss = 0.48, batch loss = 0.31 (35.6 examples/sec; 0.224 sec/batch; 12h:39m:32s remains)
INFO - root - 2017-12-16 22:44:20.406394: step 129450, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 12h:01m:07s remains)
INFO - root - 2017-12-16 22:44:22.629086: step 129460, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 12h:25m:24s remains)
INFO - root - 2017-12-16 22:44:24.835498: step 129470, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 12h:22m:06s remains)
INFO - root - 2017-12-16 22:44:27.047891: step 129480, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 12h:18m:32s remains)
INFO - root - 2017-12-16 22:44:29.236640: step 129490, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 12h:05m:30s remains)
INFO - root - 2017-12-16 22:44:31.477761: step 129500, loss = 0.62, batch loss = 0.44 (36.4 examples/sec; 0.220 sec/batch; 12h:23m:46s remains)
INFO - root - 2017-12-16 22:44:33.870610: step 129510, loss = 0.51, batch loss = 0.33 (34.3 examples/sec; 0.233 sec/batch; 13h:08m:12s remains)
INFO - root - 2017-12-16 22:44:36.063917: step 129520, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 12h:24m:18s remains)
INFO - root - 2017-12-16 22:44:38.287187: step 129530, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 12h:37m:45s remains)
INFO - root - 2017-12-16 22:44:40.511957: step 129540, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 12h:08m:54s remains)
INFO - root - 2017-12-16 22:44:42.735644: step 129550, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 12h:04m:06s remains)
INFO - root - 2017-12-16 22:44:44.948790: step 129560, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 12h:56m:33s remains)
INFO - root - 2017-12-16 22:44:47.190823: step 129570, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 12h:40m:25s remains)
INFO - root - 2017-12-16 22:44:49.393161: step 129580, loss = 0.52, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 12h:03m:20s remains)
INFO - root - 2017-12-16 22:44:51.601724: step 129590, loss = 0.42, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 12h:04m:13s remains)
INFO - root - 2017-12-16 22:44:53.829167: step 129600, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 12h:28m:55s remains)
INFO - root - 2017-12-16 22:44:56.188567: step 129610, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.226 sec/batch; 12h:45m:36s remains)
INFO - root - 2017-12-16 22:44:58.407962: step 129620, loss = 0.49, batch loss = 0.31 (33.5 examples/sec; 0.239 sec/batch; 13h:27m:49s remains)
INFO - root - 2017-12-16 22:45:00.635062: step 129630, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 12h:35m:30s remains)
INFO - root - 2017-12-16 22:45:02.876463: step 129640, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 12h:42m:54s remains)
INFO - root - 2017-12-16 22:45:05.072467: step 129650, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 12h:14m:51s remains)
INFO - root - 2017-12-16 22:45:07.275818: step 129660, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 12h:17m:16s remains)
INFO - root - 2017-12-16 22:45:09.445800: step 129670, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.233 sec/batch; 13h:07m:13s remains)
INFO - root - 2017-12-16 22:45:11.616298: step 129680, loss = 0.56, batch loss = 0.38 (36.6 examples/sec; 0.219 sec/batch; 12h:19m:43s remains)
INFO - root - 2017-12-16 22:45:13.827381: step 129690, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 12h:43m:00s remains)
INFO - root - 2017-12-16 22:45:16.074255: step 129700, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 12h:07m:29s remains)
INFO - root - 2017-12-16 22:45:18.426698: step 129710, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 12h:14m:44s remains)
INFO - root - 2017-12-16 22:45:20.646815: step 129720, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 12h:44m:14s remains)
INFO - root - 2017-12-16 22:45:22.852160: step 129730, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 12h:07m:45s remains)
INFO - root - 2017-12-16 22:45:25.062664: step 129740, loss = 0.56, batch loss = 0.38 (36.6 examples/sec; 0.219 sec/batch; 12h:18m:41s remains)
INFO - root - 2017-12-16 22:45:27.259047: step 129750, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 12h:30m:29s remains)
INFO - root - 2017-12-16 22:45:29.515632: step 129760, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 12h:14m:18s remains)
INFO - root - 2017-12-16 22:45:31.714876: step 129770, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 12h:11m:51s remains)
INFO - root - 2017-12-16 22:45:33.914739: step 129780, loss = 0.52, batch loss = 0.34 (37.3 examples/sec; 0.215 sec/batch; 12h:05m:36s remains)
INFO - root - 2017-12-16 22:45:36.119500: step 129790, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 12h:17m:10s remains)
INFO - root - 2017-12-16 22:45:38.341936: step 129800, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 12h:01m:46s remains)
INFO - root - 2017-12-16 22:45:40.699543: step 129810, loss = 0.49, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 12h:08m:06s remains)
INFO - root - 2017-12-16 22:45:42.923157: step 129820, loss = 0.53, batch loss = 0.35 (35.5 examples/sec; 0.225 sec/batch; 12h:40m:34s remains)
INFO - root - 2017-12-16 22:45:45.156536: step 129830, loss = 0.45, batch loss = 0.27 (32.9 examples/sec; 0.243 sec/batch; 13h:40m:44s remains)
INFO - root - 2017-12-16 22:45:47.339776: step 129840, loss = 0.55, batch loss = 0.37 (36.9 examples/sec; 0.217 sec/batch; 12h:12m:54s remains)
INFO - root - 2017-12-16 22:45:49.531329: step 129850, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 12h:10m:46s remains)
INFO - root - 2017-12-16 22:45:51.774174: step 129860, loss = 0.47, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 12h:15m:00s remains)
INFO - root - 2017-12-16 22:45:53.990111: step 129870, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 12h:23m:38s remains)
INFO - root - 2017-12-16 22:45:56.227632: step 129880, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 12h:35m:34s remains)
INFO - root - 2017-12-16 22:45:58.478246: step 129890, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 12h:26m:17s remains)
INFO - root - 2017-12-16 22:46:00.706164: step 129900, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 12h:43m:49s remains)
INFO - root - 2017-12-16 22:46:03.098224: step 129910, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 12h:28m:14s remains)
INFO - root - 2017-12-16 22:46:05.283065: step 129920, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 12h:33m:34s remains)
INFO - root - 2017-12-16 22:46:07.528686: step 129930, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 12h:36m:35s remains)
INFO - root - 2017-12-16 22:46:09.747769: step 129940, loss = 0.46, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 12h:09m:43s remains)
INFO - root - 2017-12-16 22:46:11.971607: step 129950, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 12h:38m:08s remains)
INFO - root - 2017-12-16 22:46:14.203880: step 129960, loss = 0.56, batch loss = 0.38 (33.6 examples/sec; 0.238 sec/batch; 13h:24m:45s remains)
INFO - root - 2017-12-16 22:46:16.424463: step 129970, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 12h:16m:07s remains)
INFO - root - 2017-12-16 22:46:18.634977: step 129980, loss = 0.49, batch loss = 0.31 (33.8 examples/sec; 0.237 sec/batch; 13h:19m:19s remains)
INFO - root - 2017-12-16 22:46:20.848576: step 129990, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 12h:16m:45s remains)
INFO - root - 2017-12-16 22:46:23.052419: step 130000, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 12h:18m:26s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-130000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-130000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 22:46:25.854425: step 130010, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 12h:14m:05s remains)
INFO - root - 2017-12-16 22:46:28.044058: step 130020, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 12h:04m:51s remains)
INFO - root - 2017-12-16 22:46:30.226580: step 130030, loss = 0.43, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 12h:02m:02s remains)
INFO - root - 2017-12-16 22:46:32.433057: step 130040, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 12h:03m:27s remains)
INFO - root - 2017-12-16 22:46:34.650056: step 130050, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 12h:18m:47s remains)
INFO - root - 2017-12-16 22:46:36.876917: step 130060, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 12h:29m:45s remains)
INFO - root - 2017-12-16 22:46:39.121699: step 130070, loss = 0.48, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 12h:49m:48s remains)
INFO - root - 2017-12-16 22:46:41.371866: step 130080, loss = 0.53, batch loss = 0.35 (35.4 examples/sec; 0.226 sec/batch; 12h:41m:25s remains)
INFO - root - 2017-12-16 22:46:43.620833: step 130090, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 12h:15m:35s remains)
INFO - root - 2017-12-16 22:46:45.864674: step 130100, loss = 0.48, batch loss = 0.30 (34.2 examples/sec; 0.234 sec/batch; 13h:08m:23s remains)
INFO - root - 2017-12-16 22:46:48.209369: step 130110, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 12h:51m:07s remains)
INFO - root - 2017-12-16 22:46:50.416511: step 130120, loss = 0.47, batch loss = 0.29 (33.9 examples/sec; 0.236 sec/batch; 13h:15m:55s remains)
INFO - root - 2017-12-16 22:46:52.631868: step 130130, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 12h:32m:26s remains)
INFO - root - 2017-12-16 22:46:54.862248: step 130140, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 12h:26m:34s remains)
INFO - root - 2017-12-16 22:46:57.080951: step 130150, loss = 0.54, batch loss = 0.36 (37.2 examples/sec; 0.215 sec/batch; 12h:05m:37s remains)
INFO - root - 2017-12-16 22:46:59.263130: step 130160, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 12h:10m:22s remains)
INFO - root - 2017-12-16 22:47:01.457759: step 130170, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 12h:10m:34s remains)
INFO - root - 2017-12-16 22:47:03.626036: step 130180, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 12h:11m:12s remains)
INFO - root - 2017-12-16 22:47:05.852262: step 130190, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 12h:31m:49s remains)
INFO - root - 2017-12-16 22:47:08.056552: step 130200, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 12h:12m:50s remains)
INFO - root - 2017-12-16 22:47:10.413389: step 130210, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 12h:18m:04s remains)
INFO - root - 2017-12-16 22:47:12.630384: step 130220, loss = 0.52, batch loss = 0.34 (34.2 examples/sec; 0.234 sec/batch; 13h:09m:26s remains)
INFO - root - 2017-12-16 22:47:14.903723: step 130230, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.226 sec/batch; 12h:40m:15s remains)
INFO - root - 2017-12-16 22:47:17.134971: step 130240, loss = 0.48, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 12h:37m:50s remains)
INFO - root - 2017-12-16 22:47:19.364783: step 130250, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 12h:20m:44s remains)
INFO - root - 2017-12-16 22:47:21.571482: step 130260, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 12h:16m:40s remains)
INFO - root - 2017-12-16 22:47:23.784038: step 130270, loss = 0.46, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 12h:40m:42s remains)
INFO - root - 2017-12-16 22:47:26.022799: step 130280, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 12h:55m:26s remains)
INFO - root - 2017-12-16 22:47:28.221566: step 130290, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 12h:43m:57s remains)
INFO - root - 2017-12-16 22:47:30.441349: step 130300, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 12h:27m:33s remains)
INFO - root - 2017-12-16 22:47:32.750122: step 130310, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 12h:35m:46s remains)
INFO - root - 2017-12-16 22:47:34.967408: step 130320, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 12h:33m:37s remains)
INFO - root - 2017-12-16 22:47:37.210573: step 130330, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 12h:39m:01s remains)
INFO - root - 2017-12-16 22:47:39.455981: step 130340, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 12h:16m:22s remains)
INFO - root - 2017-12-16 22:47:41.699554: step 130350, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 12h:10m:43s remains)
INFO - root - 2017-12-16 22:47:43.896587: step 130360, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 12h:41m:00s remains)
INFO - root - 2017-12-16 22:47:46.126219: step 130370, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 12h:06m:04s remains)
INFO - root - 2017-12-16 22:47:48.367099: step 130380, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 12h:31m:00s remains)
INFO - root - 2017-12-16 22:47:50.574964: step 130390, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 12h:42m:04s remains)
INFO - root - 2017-12-16 22:47:52.782548: step 130400, loss = 0.57, batch loss = 0.39 (35.2 examples/sec; 0.227 sec/batch; 12h:44m:42s remains)
INFO - root - 2017-12-16 22:47:55.087258: step 130410, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 12h:27m:50s remains)
INFO - root - 2017-12-16 22:47:57.299868: step 130420, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.214 sec/batch; 11h:59m:17s remains)
INFO - root - 2017-12-16 22:47:59.497652: step 130430, loss = 0.47, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 12h:08m:42s remains)
INFO - root - 2017-12-16 22:48:01.692869: step 130440, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 12h:30m:03s remains)
INFO - root - 2017-12-16 22:48:03.926848: step 130450, loss = 0.42, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 12h:28m:48s remains)
INFO - root - 2017-12-16 22:48:06.161584: step 130460, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 12h:28m:27s remains)
INFO - root - 2017-12-16 22:48:08.406111: step 130470, loss = 0.48, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 12h:18m:01s remains)
INFO - root - 2017-12-16 22:48:10.617465: step 130480, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 12h:06m:58s remains)
INFO - root - 2017-12-16 22:48:12.828980: step 130490, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 12h:25m:47s remains)
INFO - root - 2017-12-16 22:48:15.067702: step 130500, loss = 0.45, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 12h:39m:57s remains)
INFO - root - 2017-12-16 22:48:17.421282: step 130510, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 12h:50m:51s remains)
INFO - root - 2017-12-16 22:48:19.646804: step 130520, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 12h:30m:37s remains)
INFO - root - 2017-12-16 22:48:21.899901: step 130530, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 12h:50m:46s remains)
INFO - root - 2017-12-16 22:48:24.133638: step 130540, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 12h:53m:00s remains)
INFO - root - 2017-12-16 22:48:26.359943: step 130550, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 12h:37m:28s remains)
INFO - root - 2017-12-16 22:48:28.554456: step 130560, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 12h:11m:18s remains)
INFO - root - 2017-12-16 22:48:30.743425: step 130570, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 12h:13m:47s remains)
INFO - root - 2017-12-16 22:48:32.957515: step 130580, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 12h:36m:45s remains)
INFO - root - 2017-12-16 22:48:35.207124: step 130590, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 12h:37m:58s remains)
INFO - root - 2017-12-16 22:48:37.425354: step 130600, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 12h:30m:53s remains)
INFO - root - 2017-12-16 22:48:39.783057: step 130610, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 12h:28m:04s remains)
INFO - root - 2017-12-16 22:48:42.003521: step 130620, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 12h:18m:20s remains)
INFO - root - 2017-12-16 22:48:44.266054: step 130630, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.228 sec/batch; 12h:48m:20s remains)
INFO - root - 2017-12-16 22:48:46.480572: step 130640, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 12h:05m:11s remains)
INFO - root - 2017-12-16 22:48:48.711016: step 130650, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 12h:29m:29s remains)
INFO - root - 2017-12-16 22:48:50.956077: step 130660, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 12h:43m:15s remains)
INFO - root - 2017-12-16 22:48:53.177804: step 130670, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 12h:21m:46s remains)
INFO - root - 2017-12-16 22:48:55.410115: step 130680, loss = 0.44, batch loss = 0.27 (34.8 examples/sec; 0.230 sec/batch; 12h:52m:12s remains)
INFO - root - 2017-12-16 22:48:57.645328: step 130690, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 12h:33m:41s remains)
INFO - root - 2017-12-16 22:48:59.838442: step 130700, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 11h:58m:41s remains)
INFO - root - 2017-12-16 22:49:02.222573: step 130710, loss = 0.56, batch loss = 0.38 (33.7 examples/sec; 0.238 sec/batch; 13h:18m:47s remains)
INFO - root - 2017-12-16 22:49:04.482962: step 130720, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 12h:13m:52s remains)
INFO - root - 2017-12-16 22:49:06.702153: step 130730, loss = 0.55, batch loss = 0.37 (35.1 examples/sec; 0.228 sec/batch; 12h:46m:20s remains)
INFO - root - 2017-12-16 22:49:08.900342: step 130740, loss = 0.59, batch loss = 0.41 (37.6 examples/sec; 0.213 sec/batch; 11h:55m:37s remains)
INFO - root - 2017-12-16 22:49:11.180983: step 130750, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 12h:14m:20s remains)
INFO - root - 2017-12-16 22:49:13.408323: step 130760, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 12h:06m:49s remains)
INFO - root - 2017-12-16 22:49:15.598682: step 130770, loss = 0.47, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 12h:12m:52s remains)
INFO - root - 2017-12-16 22:49:17.792224: step 130780, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 12h:17m:09s remains)
INFO - root - 2017-12-16 22:49:20.031221: step 130790, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 12h:40m:31s remains)
INFO - root - 2017-12-16 22:49:22.292645: step 130800, loss = 0.52, batch loss = 0.34 (33.4 examples/sec; 0.239 sec/batch; 13h:24m:33s remains)
INFO - root - 2017-12-16 22:49:24.718587: step 130810, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 12h:25m:40s remains)
INFO - root - 2017-12-16 22:49:26.910535: step 130820, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 12h:16m:33s remains)
INFO - root - 2017-12-16 22:49:29.083343: step 130830, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 12h:01m:50s remains)
INFO - root - 2017-12-16 22:49:31.312173: step 130840, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 12h:44m:12s remains)
INFO - root - 2017-12-16 22:49:33.542051: step 130850, loss = 0.47, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 12h:17m:57s remains)
INFO - root - 2017-12-16 22:49:35.800628: step 130860, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 12h:29m:09s remains)
INFO - root - 2017-12-16 22:49:38.000895: step 130870, loss = 0.39, batch loss = 0.21 (37.7 examples/sec; 0.212 sec/batch; 11h:53m:36s remains)
INFO - root - 2017-12-16 22:49:40.238890: step 130880, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 12h:13m:27s remains)
INFO - root - 2017-12-16 22:49:42.466557: step 130890, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 12h:33m:09s remains)
INFO - root - 2017-12-16 22:49:44.710041: step 130900, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 12h:35m:39s remains)
INFO - root - 2017-12-16 22:49:47.064168: step 130910, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 12h:10m:26s remains)
INFO - root - 2017-12-16 22:49:49.293366: step 130920, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.223 sec/batch; 12h:27m:34s remains)
INFO - root - 2017-12-16 22:49:51.554046: step 130930, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 12h:22m:48s remains)
INFO - root - 2017-12-16 22:49:53.813949: step 130940, loss = 0.48, batch loss = 0.30 (34.7 examples/sec; 0.230 sec/batch; 12h:53m:34s remains)
INFO - root - 2017-12-16 22:49:56.040376: step 130950, loss = 0.50, batch loss = 0.32 (34.4 examples/sec; 0.232 sec/batch; 13h:00m:31s remains)
INFO - root - 2017-12-16 22:49:58.267439: step 130960, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 12h:25m:52s remains)
INFO - root - 2017-12-16 22:50:00.483380: step 130970, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 12h:38m:16s remains)
INFO - root - 2017-12-16 22:50:02.739425: step 130980, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 12h:45m:29s remains)
INFO - root - 2017-12-16 22:50:04.939580: step 130990, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 11h:59m:17s remains)
INFO - root - 2017-12-16 22:50:07.149985: step 131000, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 12h:39m:35s remains)
INFO - root - 2017-12-16 22:50:09.499439: step 131010, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 12h:37m:02s remains)
INFO - root - 2017-12-16 22:50:11.700361: step 131020, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 12h:02m:29s remains)
INFO - root - 2017-12-16 22:50:13.898902: step 131030, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 12h:05m:11s remains)
INFO - root - 2017-12-16 22:50:16.095417: step 131040, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 12h:44m:56s remains)
INFO - root - 2017-12-16 22:50:18.333484: step 131050, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 12h:25m:16s remains)
INFO - root - 2017-12-16 22:50:20.543407: step 131060, loss = 0.45, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 12h:14m:01s remains)
INFO - root - 2017-12-16 22:50:22.762198: step 131070, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 12h:49m:17s remains)
INFO - root - 2017-12-16 22:50:25.000653: step 131080, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.224 sec/batch; 12h:33m:38s remains)
INFO - root - 2017-12-16 22:50:27.243257: step 131090, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 12h:40m:32s remains)
INFO - root - 2017-12-16 22:50:29.491070: step 131100, loss = 0.46, batch loss = 0.28 (34.5 examples/sec; 0.232 sec/batch; 12h:57m:48s remains)
INFO - root - 2017-12-16 22:50:31.829666: step 131110, loss = 0.43, batch loss = 0.25 (37.3 examples/sec; 0.215 sec/batch; 12h:00m:35s remains)
INFO - root - 2017-12-16 22:50:34.023734: step 131120, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 12h:16m:29s remains)
INFO - root - 2017-12-16 22:50:36.227360: step 131130, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 12h:05m:35s remains)
INFO - root - 2017-12-16 22:50:38.489264: step 131140, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 12h:27m:48s remains)
INFO - root - 2017-12-16 22:50:40.675496: step 131150, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 12h:20m:24s remains)
INFO - root - 2017-12-16 22:50:42.888451: step 131160, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 12h:21m:59s remains)
INFO - root - 2017-12-16 22:50:45.098939: step 131170, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 11h:53m:38s remains)
INFO - root - 2017-12-16 22:50:47.315354: step 131180, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 12h:21m:38s remains)
INFO - root - 2017-12-16 22:50:49.539034: step 131190, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.228 sec/batch; 12h:43m:37s remains)
INFO - root - 2017-12-16 22:50:51.788167: step 131200, loss = 0.60, batch loss = 0.43 (36.6 examples/sec; 0.219 sec/batch; 12h:13m:19s remains)
INFO - root - 2017-12-16 22:50:54.151069: step 131210, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 12h:10m:05s remains)
INFO - root - 2017-12-16 22:50:56.372947: step 131220, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 12h:09m:41s remains)
INFO - root - 2017-12-16 22:50:58.590284: step 131230, loss = 0.53, batch loss = 0.36 (35.0 examples/sec; 0.228 sec/batch; 12h:46m:11s remains)
INFO - root - 2017-12-16 22:51:00.801758: step 131240, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 12h:09m:02s remains)
INFO - root - 2017-12-16 22:51:03.002009: step 131250, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.221 sec/batch; 12h:22m:54s remains)
INFO - root - 2017-12-16 22:51:05.236526: step 131260, loss = 0.55, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 12h:14m:51s remains)
INFO - root - 2017-12-16 22:51:07.425767: step 131270, loss = 0.57, batch loss = 0.39 (36.7 examples/sec; 0.218 sec/batch; 12h:11m:56s remains)
INFO - root - 2017-12-16 22:51:09.680135: step 131280, loss = 0.53, batch loss = 0.35 (33.4 examples/sec; 0.239 sec/batch; 13h:22m:26s remains)
INFO - root - 2017-12-16 22:51:11.917958: step 131290, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 12h:11m:44s remains)
INFO - root - 2017-12-16 22:51:14.118594: step 131300, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 12h:16m:24s remains)
INFO - root - 2017-12-16 22:51:16.448398: step 131310, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 12h:25m:22s remains)
INFO - root - 2017-12-16 22:51:18.645339: step 131320, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.223 sec/batch; 12h:26m:04s remains)
INFO - root - 2017-12-16 22:51:20.903876: step 131330, loss = 0.48, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 12h:14m:07s remains)
INFO - root - 2017-12-16 22:51:23.121931: step 131340, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 12h:06m:19s remains)
INFO - root - 2017-12-16 22:51:25.334259: step 131350, loss = 0.55, batch loss = 0.37 (35.9 examples/sec; 0.223 sec/batch; 12h:26m:47s remains)
INFO - root - 2017-12-16 22:51:27.577257: step 131360, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 12h:38m:00s remains)
INFO - root - 2017-12-16 22:51:29.769162: step 131370, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 12h:34m:22s remains)
INFO - root - 2017-12-16 22:51:31.971654: step 131380, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 12h:24m:48s remains)
INFO - root - 2017-12-16 22:51:34.155620: step 131390, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 11h:57m:10s remains)
INFO - root - 2017-12-16 22:51:36.398515: step 131400, loss = 0.49, batch loss = 0.31 (33.8 examples/sec; 0.236 sec/batch; 13h:12m:14s remains)
INFO - root - 2017-12-16 22:51:38.744319: step 131410, loss = 0.41, batch loss = 0.23 (37.0 examples/sec; 0.216 sec/batch; 12h:04m:36s remains)
INFO - root - 2017-12-16 22:51:40.925286: step 131420, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 12h:22m:34s remains)
INFO - root - 2017-12-16 22:51:43.144819: step 131430, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 12h:09m:04s remains)
INFO - root - 2017-12-16 22:51:45.312854: step 131440, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 11h:48m:59s remains)
INFO - root - 2017-12-16 22:51:47.528487: step 131450, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 12h:14m:15s remains)
INFO - root - 2017-12-16 22:51:49.736098: step 131460, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 12h:06m:39s remains)
INFO - root - 2017-12-16 22:51:51.913941: step 131470, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 12h:25m:55s remains)
INFO - root - 2017-12-16 22:51:54.141658: step 131480, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 12h:13m:15s remains)
INFO - root - 2017-12-16 22:51:56.342034: step 131490, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 12h:08m:08s remains)
INFO - root - 2017-12-16 22:51:58.541560: step 131500, loss = 0.52, batch loss = 0.34 (37.6 examples/sec; 0.213 sec/batch; 11h:53m:20s remains)
INFO - root - 2017-12-16 22:52:00.922173: step 131510, loss = 0.56, batch loss = 0.38 (36.7 examples/sec; 0.218 sec/batch; 12h:10m:17s remains)
INFO - root - 2017-12-16 22:52:03.122770: step 131520, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 12h:14m:41s remains)
INFO - root - 2017-12-16 22:52:05.298430: step 131530, loss = 0.46, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 12h:10m:22s remains)
INFO - root - 2017-12-16 22:52:07.496294: step 131540, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 12h:36m:26s remains)
INFO - root - 2017-12-16 22:52:09.720967: step 131550, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 12h:04m:13s remains)
INFO - root - 2017-12-16 22:52:11.925584: step 131560, loss = 0.53, batch loss = 0.35 (37.7 examples/sec; 0.212 sec/batch; 11h:51m:01s remains)
INFO - root - 2017-12-16 22:52:14.130054: step 131570, loss = 0.51, batch loss = 0.33 (37.5 examples/sec; 0.214 sec/batch; 11h:55m:20s remains)
INFO - root - 2017-12-16 22:52:16.316942: step 131580, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 12h:25m:31s remains)
INFO - root - 2017-12-16 22:52:18.488655: step 131590, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 12h:14m:18s remains)
INFO - root - 2017-12-16 22:52:20.679297: step 131600, loss = 0.55, batch loss = 0.37 (37.4 examples/sec; 0.214 sec/batch; 11h:56m:14s remains)
INFO - root - 2017-12-16 22:52:23.017565: step 131610, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 12h:06m:25s remains)
INFO - root - 2017-12-16 22:52:25.240978: step 131620, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 12h:50m:30s remains)
INFO - root - 2017-12-16 22:52:27.443687: step 131630, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 12h:36m:39s remains)
INFO - root - 2017-12-16 22:52:29.636066: step 131640, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 12h:09m:06s remains)
INFO - root - 2017-12-16 22:52:31.835632: step 131650, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 12h:25m:26s remains)
INFO - root - 2017-12-16 22:52:34.058022: step 131660, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 12h:23m:06s remains)
INFO - root - 2017-12-16 22:52:36.253488: step 131670, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 12h:20m:33s remains)
INFO - root - 2017-12-16 22:52:38.453367: step 131680, loss = 0.42, batch loss = 0.24 (35.3 examples/sec; 0.227 sec/batch; 12h:38m:33s remains)
INFO - root - 2017-12-16 22:52:40.681428: step 131690, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 12h:43m:01s remains)
INFO - root - 2017-12-16 22:52:42.868544: step 131700, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 12h:10m:01s remains)
INFO - root - 2017-12-16 22:52:45.193798: step 131710, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 11h:55m:56s remains)
INFO - root - 2017-12-16 22:52:47.373296: step 131720, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 12h:05m:05s remains)
INFO - root - 2017-12-16 22:52:49.597545: step 131730, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 12h:21m:05s remains)
INFO - root - 2017-12-16 22:52:51.793715: step 131740, loss = 0.53, batch loss = 0.35 (37.5 examples/sec; 0.213 sec/batch; 11h:54m:00s remains)
INFO - root - 2017-12-16 22:52:53.989631: step 131750, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 12h:48m:05s remains)
INFO - root - 2017-12-16 22:52:56.212088: step 131760, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 12h:17m:56s remains)
INFO - root - 2017-12-16 22:52:58.410885: step 131770, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 12h:01m:21s remains)
INFO - root - 2017-12-16 22:53:00.596410: step 131780, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 12h:07m:54s remains)
INFO - root - 2017-12-16 22:53:02.798150: step 131790, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 12h:01m:18s remains)
INFO - root - 2017-12-16 22:53:05.003083: step 131800, loss = 0.43, batch loss = 0.25 (33.9 examples/sec; 0.236 sec/batch; 13h:08m:40s remains)
INFO - root - 2017-12-16 22:53:07.307274: step 131810, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 12h:03m:11s remains)
INFO - root - 2017-12-16 22:53:09.526581: step 131820, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 12h:24m:36s remains)
INFO - root - 2017-12-16 22:53:11.720976: step 131830, loss = 0.42, batch loss = 0.24 (37.5 examples/sec; 0.213 sec/batch; 11h:53m:48s remains)
INFO - root - 2017-12-16 22:53:13.916656: step 131840, loss = 0.53, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 12h:29m:11s remains)
INFO - root - 2017-12-16 22:53:16.093994: step 131850, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 12h:09m:10s remains)
INFO - root - 2017-12-16 22:53:18.261580: step 131860, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 12h:04m:28s remains)
INFO - root - 2017-12-16 22:53:20.459044: step 131870, loss = 0.45, batch loss = 0.27 (34.7 examples/sec; 0.231 sec/batch; 12h:51m:14s remains)
INFO - root - 2017-12-16 22:53:22.654483: step 131880, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 12h:12m:03s remains)
INFO - root - 2017-12-16 22:53:24.927273: step 131890, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 12h:18m:23s remains)
INFO - root - 2017-12-16 22:53:27.131464: step 131900, loss = 0.47, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 12h:18m:29s remains)
INFO - root - 2017-12-16 22:53:29.460795: step 131910, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 12h:04m:51s remains)
INFO - root - 2017-12-16 22:53:31.664477: step 131920, loss = 0.54, batch loss = 0.36 (37.1 examples/sec; 0.216 sec/batch; 12h:00m:25s remains)
INFO - root - 2017-12-16 22:53:33.835224: step 131930, loss = 0.52, batch loss = 0.34 (37.7 examples/sec; 0.212 sec/batch; 11h:49m:13s remains)
INFO - root - 2017-12-16 22:53:36.042777: step 131940, loss = 0.45, batch loss = 0.27 (37.8 examples/sec; 0.211 sec/batch; 11h:46m:44s remains)
INFO - root - 2017-12-16 22:53:38.270317: step 131950, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 12h:13m:45s remains)
INFO - root - 2017-12-16 22:53:40.450803: step 131960, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 12h:13m:15s remains)
INFO - root - 2017-12-16 22:53:42.675037: step 131970, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 12h:20m:51s remains)
INFO - root - 2017-12-16 22:53:44.856947: step 131980, loss = 0.52, batch loss = 0.35 (37.8 examples/sec; 0.212 sec/batch; 11h:47m:55s remains)
INFO - root - 2017-12-16 22:53:47.038535: step 131990, loss = 0.45, batch loss = 0.27 (34.4 examples/sec; 0.232 sec/batch; 12h:56m:12s remains)
INFO - root - 2017-12-16 22:53:49.267807: step 132000, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 12h:15m:42s remains)
INFO - root - 2017-12-16 22:53:51.627052: step 132010, loss = 0.50, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 12h:08m:08s remains)
INFO - root - 2017-12-16 22:53:53.868377: step 132020, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 12h:39m:06s remains)
INFO - root - 2017-12-16 22:53:56.072308: step 132030, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 12h:15m:19s remains)
INFO - root - 2017-12-16 22:53:58.271580: step 132040, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.228 sec/batch; 12h:42m:45s remains)
INFO - root - 2017-12-16 22:54:00.481221: step 132050, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 12h:10m:04s remains)
INFO - root - 2017-12-16 22:54:02.694689: step 132060, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 12h:20m:28s remains)
INFO - root - 2017-12-16 22:54:04.927273: step 132070, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 12h:38m:00s remains)
INFO - root - 2017-12-16 22:54:07.121764: step 132080, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 11h:59m:00s remains)
INFO - root - 2017-12-16 22:54:09.381948: step 132090, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 12h:25m:00s remains)
INFO - root - 2017-12-16 22:54:11.640140: step 132100, loss = 0.62, batch loss = 0.44 (35.8 examples/sec; 0.223 sec/batch; 12h:26m:20s remains)
INFO - root - 2017-12-16 22:54:13.966616: step 132110, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.214 sec/batch; 11h:53m:11s remains)
INFO - root - 2017-12-16 22:54:16.165156: step 132120, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 12h:52m:41s remains)
INFO - root - 2017-12-16 22:54:18.398538: step 132130, loss = 0.55, batch loss = 0.37 (34.7 examples/sec; 0.230 sec/batch; 12h:48m:55s remains)
INFO - root - 2017-12-16 22:54:20.642307: step 132140, loss = 0.53, batch loss = 0.35 (35.5 examples/sec; 0.225 sec/batch; 12h:32m:03s remains)
INFO - root - 2017-12-16 22:54:22.871930: step 132150, loss = 0.52, batch loss = 0.34 (35.0 examples/sec; 0.229 sec/batch; 12h:44m:13s remains)
INFO - root - 2017-12-16 22:54:25.085401: step 132160, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 12h:40m:27s remains)
INFO - root - 2017-12-16 22:54:27.294364: step 132170, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 12h:15m:15s remains)
INFO - root - 2017-12-16 22:54:29.537426: step 132180, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.231 sec/batch; 12h:51m:56s remains)
INFO - root - 2017-12-16 22:54:31.753091: step 132190, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 12h:28m:47s remains)
INFO - root - 2017-12-16 22:54:33.981411: step 132200, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 11h:55m:32s remains)
INFO - root - 2017-12-16 22:54:36.296974: step 132210, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 12h:01m:35s remains)
INFO - root - 2017-12-16 22:54:38.512396: step 132220, loss = 0.42, batch loss = 0.24 (37.6 examples/sec; 0.213 sec/batch; 11h:50m:35s remains)
INFO - root - 2017-12-16 22:54:40.729426: step 132230, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 11h:52m:37s remains)
INFO - root - 2017-12-16 22:54:42.950810: step 132240, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 12h:39m:39s remains)
INFO - root - 2017-12-16 22:54:45.129900: step 132250, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 11h:50m:16s remains)
INFO - root - 2017-12-16 22:54:47.398273: step 132260, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 12h:37m:26s remains)
INFO - root - 2017-12-16 22:54:49.609833: step 132270, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 12h:05m:26s remains)
INFO - root - 2017-12-16 22:54:51.837195: step 132280, loss = 0.45, batch loss = 0.27 (33.3 examples/sec; 0.240 sec/batch; 13h:21m:22s remains)
INFO - root - 2017-12-16 22:54:54.084348: step 132290, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 12h:09m:38s remains)
INFO - root - 2017-12-16 22:54:56.285054: step 132300, loss = 0.57, batch loss = 0.39 (35.3 examples/sec; 0.226 sec/batch; 12h:35m:35s remains)
INFO - root - 2017-12-16 22:54:58.631415: step 132310, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 12h:42m:34s remains)
INFO - root - 2017-12-16 22:55:00.845796: step 132320, loss = 0.51, batch loss = 0.33 (35.2 examples/sec; 0.227 sec/batch; 12h:37m:17s remains)
INFO - root - 2017-12-16 22:55:03.034744: step 132330, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 12h:14m:28s remains)
INFO - root - 2017-12-16 22:55:05.211581: step 132340, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 12h:13m:39s remains)
INFO - root - 2017-12-16 22:55:07.418145: step 132350, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 12h:28m:24s remains)
INFO - root - 2017-12-16 22:55:09.627493: step 132360, loss = 0.51, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 12h:40m:19s remains)
INFO - root - 2017-12-16 22:55:11.871262: step 132370, loss = 0.55, batch loss = 0.37 (36.8 examples/sec; 0.217 sec/batch; 12h:04m:29s remains)
INFO - root - 2017-12-16 22:55:14.116924: step 132380, loss = 0.46, batch loss = 0.28 (34.1 examples/sec; 0.235 sec/batch; 13h:02m:32s remains)
INFO - root - 2017-12-16 22:55:16.300073: step 132390, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 11h:55m:39s remains)
INFO - root - 2017-12-16 22:55:18.507843: step 132400, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 12h:39m:41s remains)
INFO - root - 2017-12-16 22:55:20.872448: step 132410, loss = 0.59, batch loss = 0.42 (37.1 examples/sec; 0.216 sec/batch; 11h:58m:48s remains)
INFO - root - 2017-12-16 22:55:23.111291: step 132420, loss = 0.46, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 12h:57m:02s remains)
INFO - root - 2017-12-16 22:55:25.315269: step 132430, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 12h:06m:17s remains)
INFO - root - 2017-12-16 22:55:27.531977: step 132440, loss = 0.70, batch loss = 0.52 (35.2 examples/sec; 0.227 sec/batch; 12h:37m:18s remains)
INFO - root - 2017-12-16 22:55:29.788513: step 132450, loss = 0.43, batch loss = 0.25 (34.6 examples/sec; 0.231 sec/batch; 12h:51m:20s remains)
INFO - root - 2017-12-16 22:55:31.983282: step 132460, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 12h:23m:34s remains)
INFO - root - 2017-12-16 22:55:34.171567: step 132470, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 12h:08m:59s remains)
INFO - root - 2017-12-16 22:55:36.403484: step 132480, loss = 0.54, batch loss = 0.36 (37.0 examples/sec; 0.216 sec/batch; 11h:59m:57s remains)
INFO - root - 2017-12-16 22:55:38.632391: step 132490, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 12h:17m:19s remains)
INFO - root - 2017-12-16 22:55:40.853791: step 132500, loss = 0.49, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 12h:27m:48s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-132500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-132500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 22:55:43.828836: step 132510, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 12h:04m:44s remains)
INFO - root - 2017-12-16 22:55:46.081810: step 132520, loss = 0.51, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 12h:26m:29s remains)
INFO - root - 2017-12-16 22:55:48.289815: step 132530, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 12h:07m:09s remains)
INFO - root - 2017-12-16 22:55:50.508102: step 132540, loss = 0.46, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 11h:47m:40s remains)
INFO - root - 2017-12-16 22:55:52.703785: step 132550, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 11h:47m:25s remains)
INFO - root - 2017-12-16 22:55:54.931033: step 132560, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 12h:18m:25s remains)
INFO - root - 2017-12-16 22:55:57.141914: step 132570, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 12h:15m:06s remains)
INFO - root - 2017-12-16 22:55:59.350379: step 132580, loss = 0.57, batch loss = 0.39 (36.3 examples/sec; 0.220 sec/batch; 12h:14m:16s remains)
INFO - root - 2017-12-16 22:56:01.585821: step 132590, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 12h:16m:25s remains)
INFO - root - 2017-12-16 22:56:03.831756: step 132600, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.232 sec/batch; 12h:54m:35s remains)
INFO - root - 2017-12-16 22:56:06.193948: step 132610, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 12h:05m:47s remains)
INFO - root - 2017-12-16 22:56:08.390829: step 132620, loss = 0.43, batch loss = 0.25 (35.2 examples/sec; 0.227 sec/batch; 12h:37m:08s remains)
INFO - root - 2017-12-16 22:56:10.637744: step 132630, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.229 sec/batch; 12h:41m:32s remains)
INFO - root - 2017-12-16 22:56:12.849069: step 132640, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 11h:58m:08s remains)
INFO - root - 2017-12-16 22:56:15.059038: step 132650, loss = 0.44, batch loss = 0.26 (35.0 examples/sec; 0.228 sec/batch; 12h:40m:42s remains)
INFO - root - 2017-12-16 22:56:17.322577: step 132660, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.232 sec/batch; 12h:54m:04s remains)
INFO - root - 2017-12-16 22:56:19.538267: step 132670, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 12h:03m:43s remains)
INFO - root - 2017-12-16 22:56:21.747421: step 132680, loss = 0.48, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 12h:20m:39s remains)
INFO - root - 2017-12-16 22:56:24.002150: step 132690, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 12h:14m:06s remains)
INFO - root - 2017-12-16 22:56:26.237118: step 132700, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 12h:07m:07s remains)
INFO - root - 2017-12-16 22:56:28.615658: step 132710, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 12h:28m:00s remains)
INFO - root - 2017-12-16 22:56:30.838384: step 132720, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 12h:25m:07s remains)
INFO - root - 2017-12-16 22:56:33.080956: step 132730, loss = 0.55, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 12h:09m:57s remains)
INFO - root - 2017-12-16 22:56:35.309688: step 132740, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 12h:11m:24s remains)
INFO - root - 2017-12-16 22:56:37.535828: step 132750, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 12h:05m:41s remains)
INFO - root - 2017-12-16 22:56:39.748884: step 132760, loss = 0.64, batch loss = 0.46 (35.6 examples/sec; 0.224 sec/batch; 12h:27m:07s remains)
INFO - root - 2017-12-16 22:56:42.019900: step 132770, loss = 0.49, batch loss = 0.32 (31.9 examples/sec; 0.251 sec/batch; 13h:55m:26s remains)
INFO - root - 2017-12-16 22:56:44.207665: step 132780, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 12h:00m:50s remains)
INFO - root - 2017-12-16 22:56:46.455641: step 132790, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 12h:38m:35s remains)
INFO - root - 2017-12-16 22:56:48.695926: step 132800, loss = 0.49, batch loss = 0.32 (35.0 examples/sec; 0.229 sec/batch; 12h:40m:41s remains)
INFO - root - 2017-12-16 22:56:51.049440: step 132810, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 12h:17m:26s remains)
INFO - root - 2017-12-16 22:56:53.294679: step 132820, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 12h:24m:52s remains)
INFO - root - 2017-12-16 22:56:55.478013: step 132830, loss = 0.45, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 12h:06m:29s remains)
INFO - root - 2017-12-16 22:56:57.700806: step 132840, loss = 0.43, batch loss = 0.25 (34.7 examples/sec; 0.230 sec/batch; 12h:46m:48s remains)
INFO - root - 2017-12-16 22:56:59.932741: step 132850, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 12h:45m:10s remains)
INFO - root - 2017-12-16 22:57:02.173629: step 132860, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 12h:36m:42s remains)
INFO - root - 2017-12-16 22:57:04.425758: step 132870, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 12h:09m:13s remains)
INFO - root - 2017-12-16 22:57:06.650480: step 132880, loss = 0.49, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 11h:46m:53s remains)
INFO - root - 2017-12-16 22:57:08.866907: step 132890, loss = 0.50, batch loss = 0.32 (37.6 examples/sec; 0.213 sec/batch; 11h:48m:21s remains)
INFO - root - 2017-12-16 22:57:11.062498: step 132900, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 12h:12m:02s remains)
INFO - root - 2017-12-16 22:57:13.443085: step 132910, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 12h:21m:28s remains)
INFO - root - 2017-12-16 22:57:15.668132: step 132920, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 12h:08m:24s remains)
INFO - root - 2017-12-16 22:57:17.876781: step 132930, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 12h:23m:53s remains)
INFO - root - 2017-12-16 22:57:20.110080: step 132940, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 11h:47m:14s remains)
INFO - root - 2017-12-16 22:57:22.320392: step 132950, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.221 sec/batch; 12h:16m:17s remains)
INFO - root - 2017-12-16 22:57:24.494658: step 132960, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 12h:03m:57s remains)
INFO - root - 2017-12-16 22:57:26.695701: step 132970, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 11h:53m:20s remains)
INFO - root - 2017-12-16 22:57:28.876976: step 132980, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 12h:19m:29s remains)
INFO - root - 2017-12-16 22:57:31.102644: step 132990, loss = 0.47, batch loss = 0.29 (34.0 examples/sec; 0.235 sec/batch; 13h:01m:59s remains)
INFO - root - 2017-12-16 22:57:33.311166: step 133000, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 12h:21m:39s remains)
INFO - root - 2017-12-16 22:57:35.626864: step 133010, loss = 0.51, batch loss = 0.33 (35.0 examples/sec; 0.229 sec/batch; 12h:40m:12s remains)
INFO - root - 2017-12-16 22:57:37.839697: step 133020, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 12h:17m:56s remains)
INFO - root - 2017-12-16 22:57:40.017628: step 133030, loss = 0.55, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 12h:08m:53s remains)
INFO - root - 2017-12-16 22:57:42.204104: step 133040, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 12h:28m:16s remains)
INFO - root - 2017-12-16 22:57:44.396958: step 133050, loss = 0.55, batch loss = 0.37 (36.6 examples/sec; 0.219 sec/batch; 12h:06m:57s remains)
INFO - root - 2017-12-16 22:57:46.576630: step 133060, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 12h:32m:02s remains)
INFO - root - 2017-12-16 22:57:48.777104: step 133070, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 12h:18m:41s remains)
INFO - root - 2017-12-16 22:57:50.973361: step 133080, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 12h:41m:19s remains)
INFO - root - 2017-12-16 22:57:53.198671: step 133090, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 12h:01m:38s remains)
INFO - root - 2017-12-16 22:57:55.426938: step 133100, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 12h:14m:22s remains)
INFO - root - 2017-12-16 22:57:57.760052: step 133110, loss = 0.44, batch loss = 0.26 (38.1 examples/sec; 0.210 sec/batch; 11h:37m:09s remains)
INFO - root - 2017-12-16 22:57:59.933112: step 133120, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 11h:57m:44s remains)
INFO - root - 2017-12-16 22:58:02.141769: step 133130, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 12h:04m:44s remains)
INFO - root - 2017-12-16 22:58:04.366221: step 133140, loss = 0.42, batch loss = 0.24 (37.3 examples/sec; 0.215 sec/batch; 11h:52m:53s remains)
INFO - root - 2017-12-16 22:58:06.570433: step 133150, loss = 0.57, batch loss = 0.39 (37.2 examples/sec; 0.215 sec/batch; 11h:53m:33s remains)
INFO - root - 2017-12-16 22:58:08.807758: step 133160, loss = 0.42, batch loss = 0.24 (37.2 examples/sec; 0.215 sec/batch; 11h:55m:25s remains)
INFO - root - 2017-12-16 22:58:11.021629: step 133170, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 12h:07m:33s remains)
INFO - root - 2017-12-16 22:58:13.214260: step 133180, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 12h:20m:03s remains)
INFO - root - 2017-12-16 22:58:15.432170: step 133190, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 12h:07m:20s remains)
INFO - root - 2017-12-16 22:58:17.672599: step 133200, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 12h:22m:09s remains)
INFO - root - 2017-12-16 22:58:20.029822: step 133210, loss = 0.56, batch loss = 0.38 (37.4 examples/sec; 0.214 sec/batch; 11h:50m:49s remains)
INFO - root - 2017-12-16 22:58:22.230080: step 133220, loss = 0.52, batch loss = 0.34 (34.3 examples/sec; 0.233 sec/batch; 12h:53m:40s remains)
INFO - root - 2017-12-16 22:58:24.454122: step 133230, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 11h:46m:55s remains)
INFO - root - 2017-12-16 22:58:26.657693: step 133240, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 12h:12m:54s remains)
INFO - root - 2017-12-16 22:58:28.876922: step 133250, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 12h:11m:15s remains)
INFO - root - 2017-12-16 22:58:31.104395: step 133260, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 12h:23m:11s remains)
INFO - root - 2017-12-16 22:58:33.325242: step 133270, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 12h:34m:50s remains)
INFO - root - 2017-12-16 22:58:35.536735: step 133280, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 12h:26m:55s remains)
INFO - root - 2017-12-16 22:58:37.743744: step 133290, loss = 0.42, batch loss = 0.25 (34.9 examples/sec; 0.229 sec/batch; 12h:41m:20s remains)
INFO - root - 2017-12-16 22:58:40.000067: step 133300, loss = 0.42, batch loss = 0.24 (33.7 examples/sec; 0.237 sec/batch; 13h:07m:07s remains)
INFO - root - 2017-12-16 22:58:42.326935: step 133310, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 12h:04m:15s remains)
INFO - root - 2017-12-16 22:58:44.550440: step 133320, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 12h:05m:56s remains)
INFO - root - 2017-12-16 22:58:46.781968: step 133330, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 12h:11m:54s remains)
INFO - root - 2017-12-16 22:58:49.002834: step 133340, loss = 0.46, batch loss = 0.29 (35.3 examples/sec; 0.226 sec/batch; 12h:31m:23s remains)
INFO - root - 2017-12-16 22:58:51.222766: step 133350, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 12h:02m:27s remains)
INFO - root - 2017-12-16 22:58:53.423484: step 133360, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 12h:00m:32s remains)
INFO - root - 2017-12-16 22:58:55.601067: step 133370, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 11h:49m:56s remains)
INFO - root - 2017-12-16 22:58:57.813413: step 133380, loss = 0.44, batch loss = 0.26 (33.8 examples/sec; 0.237 sec/batch; 13h:05m:31s remains)
INFO - root - 2017-12-16 22:59:00.066976: step 133390, loss = 0.43, batch loss = 0.25 (35.1 examples/sec; 0.228 sec/batch; 12h:37m:15s remains)
INFO - root - 2017-12-16 22:59:02.247300: step 133400, loss = 0.47, batch loss = 0.29 (37.9 examples/sec; 0.211 sec/batch; 11h:41m:02s remains)
INFO - root - 2017-12-16 22:59:04.650225: step 133410, loss = 0.52, batch loss = 0.34 (34.6 examples/sec; 0.231 sec/batch; 12h:47m:38s remains)
INFO - root - 2017-12-16 22:59:06.876190: step 133420, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 11h:50m:56s remains)
INFO - root - 2017-12-16 22:59:09.122462: step 133430, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 12h:08m:03s remains)
INFO - root - 2017-12-16 22:59:11.335389: step 133440, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 12h:28m:21s remains)
INFO - root - 2017-12-16 22:59:13.591062: step 133450, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 12h:32m:28s remains)
INFO - root - 2017-12-16 22:59:15.811648: step 133460, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 12h:17m:22s remains)
INFO - root - 2017-12-16 22:59:18.022097: step 133470, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 12h:02m:43s remains)
INFO - root - 2017-12-16 22:59:20.244820: step 133480, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 12h:18m:13s remains)
INFO - root - 2017-12-16 22:59:22.475831: step 133490, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 11h:55m:00s remains)
INFO - root - 2017-12-16 22:59:24.691537: step 133500, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 12h:14m:31s remains)
INFO - root - 2017-12-16 22:59:27.022771: step 133510, loss = 0.41, batch loss = 0.23 (36.5 examples/sec; 0.219 sec/batch; 12h:06m:16s remains)
INFO - root - 2017-12-16 22:59:29.267437: step 133520, loss = 0.43, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 12h:42m:58s remains)
INFO - root - 2017-12-16 22:59:31.455115: step 133530, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 12h:00m:49s remains)
INFO - root - 2017-12-16 22:59:33.644437: step 133540, loss = 0.56, batch loss = 0.39 (35.9 examples/sec; 0.223 sec/batch; 12h:18m:12s remains)
INFO - root - 2017-12-16 22:59:35.850500: step 133550, loss = 0.55, batch loss = 0.38 (35.6 examples/sec; 0.225 sec/batch; 12h:26m:01s remains)
INFO - root - 2017-12-16 22:59:38.077575: step 133560, loss = 0.42, batch loss = 0.24 (36.5 examples/sec; 0.219 sec/batch; 12h:06m:28s remains)
INFO - root - 2017-12-16 22:59:40.312574: step 133570, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 12h:16m:09s remains)
INFO - root - 2017-12-16 22:59:42.526211: step 133580, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 12h:10m:21s remains)
INFO - root - 2017-12-16 22:59:44.738589: step 133590, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 12h:03m:20s remains)
INFO - root - 2017-12-16 22:59:46.938392: step 133600, loss = 0.57, batch loss = 0.39 (37.4 examples/sec; 0.214 sec/batch; 11h:48m:43s remains)
INFO - root - 2017-12-16 22:59:49.322962: step 133610, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.224 sec/batch; 12h:24m:04s remains)
INFO - root - 2017-12-16 22:59:51.549101: step 133620, loss = 0.52, batch loss = 0.35 (35.5 examples/sec; 0.225 sec/batch; 12h:26m:49s remains)
INFO - root - 2017-12-16 22:59:53.787189: step 133630, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 11h:52m:30s remains)
INFO - root - 2017-12-16 22:59:56.017626: step 133640, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 12h:26m:28s remains)
INFO - root - 2017-12-16 22:59:58.225828: step 133650, loss = 0.51, batch loss = 0.33 (37.8 examples/sec; 0.212 sec/batch; 11h:41m:40s remains)
INFO - root - 2017-12-16 23:00:00.453171: step 133660, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 11h:56m:39s remains)
INFO - root - 2017-12-16 23:00:02.661178: step 133670, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 12h:01m:53s remains)
INFO - root - 2017-12-16 23:00:04.905037: step 133680, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 12h:30m:21s remains)
INFO - root - 2017-12-16 23:00:07.122273: step 133690, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 12h:21m:43s remains)
INFO - root - 2017-12-16 23:00:09.339172: step 133700, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 12h:19m:32s remains)
INFO - root - 2017-12-16 23:00:11.658767: step 133710, loss = 0.56, batch loss = 0.38 (36.4 examples/sec; 0.220 sec/batch; 12h:07m:46s remains)
INFO - root - 2017-12-16 23:00:13.866115: step 133720, loss = 0.44, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 11h:48m:23s remains)
INFO - root - 2017-12-16 23:00:16.068523: step 133730, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 12h:02m:09s remains)
INFO - root - 2017-12-16 23:00:18.339410: step 133740, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 12h:32m:25s remains)
INFO - root - 2017-12-16 23:00:20.554457: step 133750, loss = 0.45, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 12h:06m:44s remains)
INFO - root - 2017-12-16 23:00:22.761330: step 133760, loss = 0.40, batch loss = 0.22 (37.9 examples/sec; 0.211 sec/batch; 11h:38m:37s remains)
INFO - root - 2017-12-16 23:00:24.988411: step 133770, loss = 0.47, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 12h:03m:33s remains)
INFO - root - 2017-12-16 23:00:27.200062: step 133780, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 12h:12m:37s remains)
INFO - root - 2017-12-16 23:00:29.404946: step 133790, loss = 0.49, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 12h:34m:27s remains)
INFO - root - 2017-12-16 23:00:31.624701: step 133800, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 12h:21m:52s remains)
INFO - root - 2017-12-16 23:00:34.028026: step 133810, loss = 0.47, batch loss = 0.29 (33.7 examples/sec; 0.238 sec/batch; 13h:06m:58s remains)
INFO - root - 2017-12-16 23:00:36.248759: step 133820, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 11h:52m:51s remains)
INFO - root - 2017-12-16 23:00:38.429902: step 133830, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 12h:00m:23s remains)
INFO - root - 2017-12-16 23:00:40.665585: step 133840, loss = 0.46, batch loss = 0.28 (33.4 examples/sec; 0.240 sec/batch; 13h:14m:09s remains)
INFO - root - 2017-12-16 23:00:42.887771: step 133850, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 12h:15m:10s remains)
INFO - root - 2017-12-16 23:00:45.106714: step 133860, loss = 0.54, batch loss = 0.36 (36.4 examples/sec; 0.220 sec/batch; 12h:07m:54s remains)
INFO - root - 2017-12-16 23:00:47.278480: step 133870, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 12h:11m:09s remains)
INFO - root - 2017-12-16 23:00:49.477536: step 133880, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 12h:06m:31s remains)
INFO - root - 2017-12-16 23:00:51.675935: step 133890, loss = 0.44, batch loss = 0.26 (37.7 examples/sec; 0.212 sec/batch; 11h:42m:33s remains)
INFO - root - 2017-12-16 23:00:53.925432: step 133900, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 11h:57m:33s remains)
INFO - root - 2017-12-16 23:00:56.239009: step 133910, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 11h:49m:16s remains)
INFO - root - 2017-12-16 23:00:58.472422: step 133920, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 11h:54m:29s remains)
INFO - root - 2017-12-16 23:01:00.729748: step 133930, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 12h:14m:07s remains)
INFO - root - 2017-12-16 23:01:02.932438: step 133940, loss = 0.51, batch loss = 0.33 (38.6 examples/sec; 0.207 sec/batch; 11h:26m:33s remains)
INFO - root - 2017-12-16 23:01:05.141086: step 133950, loss = 0.54, batch loss = 0.36 (37.5 examples/sec; 0.213 sec/batch; 11h:46m:14s remains)
INFO - root - 2017-12-16 23:01:07.364073: step 133960, loss = 0.47, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 12h:08m:32s remains)
INFO - root - 2017-12-16 23:01:09.564179: step 133970, loss = 0.55, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 12h:04m:29s remains)
INFO - root - 2017-12-16 23:01:11.770096: step 133980, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 12h:37m:22s remains)
INFO - root - 2017-12-16 23:01:13.981721: step 133990, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 12h:23m:20s remains)
INFO - root - 2017-12-16 23:01:16.214119: step 134000, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 12h:07m:43s remains)
INFO - root - 2017-12-16 23:01:18.547403: step 134010, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 12h:04m:12s remains)
INFO - root - 2017-12-16 23:01:20.753262: step 134020, loss = 0.42, batch loss = 0.24 (36.1 examples/sec; 0.221 sec/batch; 12h:12m:04s remains)
INFO - root - 2017-12-16 23:01:22.947630: step 134030, loss = 0.42, batch loss = 0.24 (36.9 examples/sec; 0.217 sec/batch; 11h:56m:20s remains)
INFO - root - 2017-12-16 23:01:25.168543: step 134040, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 12h:38m:08s remains)
INFO - root - 2017-12-16 23:01:27.407772: step 134050, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 12h:11m:47s remains)
INFO - root - 2017-12-16 23:01:29.646504: step 134060, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 12h:24m:00s remains)
INFO - root - 2017-12-16 23:01:31.843739: step 134070, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 12h:20m:57s remains)
INFO - root - 2017-12-16 23:01:34.043355: step 134080, loss = 0.52, batch loss = 0.34 (37.6 examples/sec; 0.213 sec/batch; 11h:44m:19s remains)
INFO - root - 2017-12-16 23:01:36.244745: step 134090, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 11h:48m:51s remains)
INFO - root - 2017-12-16 23:01:38.484990: step 134100, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 11h:48m:35s remains)
INFO - root - 2017-12-16 23:01:40.841459: step 134110, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 11h:58m:43s remains)
INFO - root - 2017-12-16 23:01:43.078776: step 134120, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 12h:18m:50s remains)
INFO - root - 2017-12-16 23:01:45.281912: step 134130, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 12h:14m:35s remains)
INFO - root - 2017-12-16 23:01:47.484705: step 134140, loss = 0.53, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 12h:23m:34s remains)
INFO - root - 2017-12-16 23:01:49.717629: step 134150, loss = 0.55, batch loss = 0.38 (35.9 examples/sec; 0.223 sec/batch; 12h:15m:49s remains)
INFO - root - 2017-12-16 23:01:51.916352: step 134160, loss = 0.53, batch loss = 0.35 (34.9 examples/sec; 0.229 sec/batch; 12h:37m:04s remains)
INFO - root - 2017-12-16 23:01:54.162484: step 134170, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 12h:07m:24s remains)
INFO - root - 2017-12-16 23:01:56.355491: step 134180, loss = 0.45, batch loss = 0.27 (37.8 examples/sec; 0.212 sec/batch; 11h:39m:38s remains)
INFO - root - 2017-12-16 23:01:58.616602: step 134190, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 12h:17m:36s remains)
INFO - root - 2017-12-16 23:02:00.781873: step 134200, loss = 0.49, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 11h:41m:42s remains)
INFO - root - 2017-12-16 23:02:03.159855: step 134210, loss = 0.42, batch loss = 0.24 (35.4 examples/sec; 0.226 sec/batch; 12h:27m:11s remains)
INFO - root - 2017-12-16 23:02:05.371778: step 134220, loss = 0.45, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 11h:58m:02s remains)
INFO - root - 2017-12-16 23:02:07.624343: step 134230, loss = 0.50, batch loss = 0.33 (34.9 examples/sec; 0.229 sec/batch; 12h:36m:44s remains)
INFO - root - 2017-12-16 23:02:09.815917: step 134240, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 12h:30m:40s remains)
INFO - root - 2017-12-16 23:02:12.059395: step 134250, loss = 0.44, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 12h:14m:31s remains)
INFO - root - 2017-12-16 23:02:14.328238: step 134260, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 11h:58m:11s remains)
INFO - root - 2017-12-16 23:02:16.528103: step 134270, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.221 sec/batch; 12h:11m:23s remains)
INFO - root - 2017-12-16 23:02:18.722753: step 134280, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 12h:01m:40s remains)
INFO - root - 2017-12-16 23:02:20.918518: step 134290, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 12h:08m:22s remains)
INFO - root - 2017-12-16 23:02:23.157181: step 134300, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 11h:56m:51s remains)
INFO - root - 2017-12-16 23:02:25.572798: step 134310, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 11h:58m:47s remains)
INFO - root - 2017-12-16 23:02:27.798727: step 134320, loss = 0.53, batch loss = 0.36 (34.2 examples/sec; 0.234 sec/batch; 12h:52m:06s remains)
INFO - root - 2017-12-16 23:02:30.013740: step 134330, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 12h:16m:19s remains)
INFO - root - 2017-12-16 23:02:32.215465: step 134340, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 12h:12m:38s remains)
INFO - root - 2017-12-16 23:02:34.403602: step 134350, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 11h:54m:54s remains)
INFO - root - 2017-12-16 23:02:36.610987: step 134360, loss = 0.54, batch loss = 0.36 (37.6 examples/sec; 0.213 sec/batch; 11h:42m:21s remains)
INFO - root - 2017-12-16 23:02:38.830272: step 134370, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 11h:50m:11s remains)
INFO - root - 2017-12-16 23:02:41.012478: step 134380, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 11h:47m:11s remains)
INFO - root - 2017-12-16 23:02:43.203579: step 134390, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 12h:08m:21s remains)
INFO - root - 2017-12-16 23:02:45.397497: step 134400, loss = 0.46, batch loss = 0.28 (38.2 examples/sec; 0.209 sec/batch; 11h:31m:35s remains)
INFO - root - 2017-12-16 23:02:47.722520: step 134410, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 12h:10m:29s remains)
INFO - root - 2017-12-16 23:02:49.908161: step 134420, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 12h:24m:37s remains)
INFO - root - 2017-12-16 23:02:52.134604: step 134430, loss = 0.48, batch loss = 0.30 (33.6 examples/sec; 0.238 sec/batch; 13h:05m:11s remains)
INFO - root - 2017-12-16 23:02:54.361810: step 134440, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 11h:46m:30s remains)
INFO - root - 2017-12-16 23:02:56.581320: step 134450, loss = 0.43, batch loss = 0.25 (37.0 examples/sec; 0.216 sec/batch; 11h:54m:23s remains)
INFO - root - 2017-12-16 23:02:58.776088: step 134460, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 12h:32m:30s remains)
INFO - root - 2017-12-16 23:03:00.984874: step 134470, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 12h:06m:00s remains)
INFO - root - 2017-12-16 23:03:03.213762: step 134480, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 11h:53m:46s remains)
INFO - root - 2017-12-16 23:03:05.432798: step 134490, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 12h:13m:56s remains)
INFO - root - 2017-12-16 23:03:07.655709: step 134500, loss = 0.45, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 12h:00m:44s remains)
INFO - root - 2017-12-16 23:03:10.005520: step 134510, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 12h:18m:44s remains)
INFO - root - 2017-12-16 23:03:12.219382: step 134520, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 12h:05m:49s remains)
INFO - root - 2017-12-16 23:03:14.412272: step 134530, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 11h:57m:08s remains)
INFO - root - 2017-12-16 23:03:16.607954: step 134540, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 12h:00m:51s remains)
INFO - root - 2017-12-16 23:03:18.805303: step 134550, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 12h:03m:39s remains)
INFO - root - 2017-12-16 23:03:21.049769: step 134560, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 12h:15m:35s remains)
INFO - root - 2017-12-16 23:03:23.274093: step 134570, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 11h:58m:01s remains)
INFO - root - 2017-12-16 23:03:25.501829: step 134580, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 12h:05m:51s remains)
INFO - root - 2017-12-16 23:03:27.709483: step 134590, loss = 0.53, batch loss = 0.35 (35.8 examples/sec; 0.223 sec/batch; 12h:16m:09s remains)
INFO - root - 2017-12-16 23:03:29.920674: step 134600, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 12h:21m:19s remains)
INFO - root - 2017-12-16 23:03:32.244646: step 134610, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 12h:19m:44s remains)
INFO - root - 2017-12-16 23:03:34.454826: step 134620, loss = 0.42, batch loss = 0.24 (35.1 examples/sec; 0.228 sec/batch; 12h:32m:28s remains)
INFO - root - 2017-12-16 23:03:36.650917: step 134630, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 12h:27m:09s remains)
INFO - root - 2017-12-16 23:03:38.888694: step 134640, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 11h:59m:37s remains)
INFO - root - 2017-12-16 23:03:41.107351: step 134650, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 12h:08m:26s remains)
INFO - root - 2017-12-16 23:03:43.317420: step 134660, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 12h:06m:24s remains)
INFO - root - 2017-12-16 23:03:45.517880: step 134670, loss = 0.60, batch loss = 0.42 (37.5 examples/sec; 0.214 sec/batch; 11h:44m:09s remains)
INFO - root - 2017-12-16 23:03:47.704438: step 134680, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 12h:24m:02s remains)
INFO - root - 2017-12-16 23:03:49.898288: step 134690, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 12h:19m:01s remains)
INFO - root - 2017-12-16 23:03:52.116695: step 134700, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 11h:56m:59s remains)
INFO - root - 2017-12-16 23:03:54.471124: step 134710, loss = 0.47, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 11h:40m:41s remains)
INFO - root - 2017-12-16 23:03:56.684634: step 134720, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 12h:03m:56s remains)
INFO - root - 2017-12-16 23:03:58.902088: step 134730, loss = 0.46, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 11h:53m:13s remains)
INFO - root - 2017-12-16 23:04:01.127113: step 134740, loss = 0.47, batch loss = 0.29 (34.6 examples/sec; 0.231 sec/batch; 12h:42m:47s remains)
INFO - root - 2017-12-16 23:04:03.359712: step 134750, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 11h:54m:31s remains)
INFO - root - 2017-12-16 23:04:05.541356: step 134760, loss = 0.49, batch loss = 0.31 (38.0 examples/sec; 0.211 sec/batch; 11h:34m:08s remains)
INFO - root - 2017-12-16 23:04:07.747717: step 134770, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 12h:24m:25s remains)
INFO - root - 2017-12-16 23:04:09.980798: step 134780, loss = 0.44, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 12h:14m:52s remains)
INFO - root - 2017-12-16 23:04:12.191315: step 134790, loss = 0.42, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 12h:18m:37s remains)
INFO - root - 2017-12-16 23:04:14.423356: step 134800, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 12h:02m:49s remains)
INFO - root - 2017-12-16 23:04:16.762349: step 134810, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 11h:56m:19s remains)
INFO - root - 2017-12-16 23:04:19.007384: step 134820, loss = 0.52, batch loss = 0.34 (34.8 examples/sec; 0.230 sec/batch; 12h:37m:07s remains)
INFO - root - 2017-12-16 23:04:21.248692: step 134830, loss = 0.42, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 12h:07m:50s remains)
INFO - root - 2017-12-16 23:04:23.492153: step 134840, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 12h:29m:56s remains)
INFO - root - 2017-12-16 23:04:25.688658: step 134850, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 11h:39m:47s remains)
INFO - root - 2017-12-16 23:04:27.908036: step 134860, loss = 0.48, batch loss = 0.30 (33.3 examples/sec; 0.240 sec/batch; 13h:11m:16s remains)
INFO - root - 2017-12-16 23:04:30.139532: step 134870, loss = 0.46, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 11h:47m:13s remains)
INFO - root - 2017-12-16 23:04:32.327621: step 134880, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 11h:48m:49s remains)
INFO - root - 2017-12-16 23:04:34.525075: step 134890, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 12h:37m:58s remains)
INFO - root - 2017-12-16 23:04:36.754219: step 134900, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 12h:09m:54s remains)
INFO - root - 2017-12-16 23:04:39.133972: step 134910, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 11h:58m:16s remains)
INFO - root - 2017-12-16 23:04:41.402921: step 134920, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 12h:10m:01s remains)
INFO - root - 2017-12-16 23:04:43.597131: step 134930, loss = 0.52, batch loss = 0.34 (37.3 examples/sec; 0.214 sec/batch; 11h:45m:49s remains)
INFO - root - 2017-12-16 23:04:45.786727: step 134940, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 12h:03m:35s remains)
INFO - root - 2017-12-16 23:04:48.004445: step 134950, loss = 0.54, batch loss = 0.36 (36.1 examples/sec; 0.221 sec/batch; 12h:08m:42s remains)
INFO - root - 2017-12-16 23:04:50.209155: step 134960, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 12h:20m:06s remains)
INFO - root - 2017-12-16 23:04:52.463011: step 134970, loss = 0.49, batch loss = 0.32 (34.7 examples/sec; 0.230 sec/batch; 12h:38m:02s remains)
INFO - root - 2017-12-16 23:04:54.699584: step 134980, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 11h:50m:33s remains)
INFO - root - 2017-12-16 23:04:56.924817: step 134990, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 11h:44m:16s remains)
INFO - root - 2017-12-16 23:04:59.116741: step 135000, loss = 0.47, batch loss = 0.30 (37.8 examples/sec; 0.212 sec/batch; 11h:36m:56s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-135000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-135000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 23:05:01.916423: step 135010, loss = 0.48, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 12h:14m:14s remains)
INFO - root - 2017-12-16 23:05:04.108866: step 135020, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 11h:56m:58s remains)
INFO - root - 2017-12-16 23:05:06.338877: step 135030, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 11h:52m:31s remains)
INFO - root - 2017-12-16 23:05:08.582526: step 135040, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 12h:02m:41s remains)
INFO - root - 2017-12-16 23:05:10.838755: step 135050, loss = 0.41, batch loss = 0.23 (35.3 examples/sec; 0.227 sec/batch; 12h:26m:37s remains)
INFO - root - 2017-12-16 23:05:13.040007: step 135060, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 11h:48m:06s remains)
INFO - root - 2017-12-16 23:05:15.254876: step 135070, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 12h:01m:34s remains)
INFO - root - 2017-12-16 23:05:17.486304: step 135080, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 12h:17m:13s remains)
INFO - root - 2017-12-16 23:05:19.731819: step 135090, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 12h:00m:57s remains)
INFO - root - 2017-12-16 23:05:21.932386: step 135100, loss = 0.49, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 12h:15m:44s remains)
INFO - root - 2017-12-16 23:05:24.268498: step 135110, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 11h:52m:49s remains)
INFO - root - 2017-12-16 23:05:26.483149: step 135120, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.224 sec/batch; 12h:18m:19s remains)
INFO - root - 2017-12-16 23:05:28.709789: step 135130, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 12h:19m:30s remains)
INFO - root - 2017-12-16 23:05:30.944605: step 135140, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 12h:09m:40s remains)
INFO - root - 2017-12-16 23:05:33.188570: step 135150, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 11h:54m:17s remains)
INFO - root - 2017-12-16 23:05:35.392053: step 135160, loss = 0.48, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 11h:58m:28s remains)
INFO - root - 2017-12-16 23:05:37.624852: step 135170, loss = 0.52, batch loss = 0.34 (33.6 examples/sec; 0.238 sec/batch; 13h:02m:20s remains)
INFO - root - 2017-12-16 23:05:39.857755: step 135180, loss = 0.44, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 12h:09m:23s remains)
INFO - root - 2017-12-16 23:05:42.088937: step 135190, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.224 sec/batch; 12h:18m:02s remains)
INFO - root - 2017-12-16 23:05:44.277168: step 135200, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 11h:54m:52s remains)
INFO - root - 2017-12-16 23:05:46.651830: step 135210, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 12h:21m:58s remains)
INFO - root - 2017-12-16 23:05:48.858218: step 135220, loss = 0.44, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 11h:46m:00s remains)
INFO - root - 2017-12-16 23:05:51.078379: step 135230, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 12h:25m:22s remains)
INFO - root - 2017-12-16 23:05:53.317841: step 135240, loss = 0.54, batch loss = 0.36 (38.0 examples/sec; 0.211 sec/batch; 11h:32m:33s remains)
INFO - root - 2017-12-16 23:05:55.498572: step 135250, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 11h:56m:34s remains)
INFO - root - 2017-12-16 23:05:57.710100: step 135260, loss = 0.45, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 12h:14m:24s remains)
INFO - root - 2017-12-16 23:05:59.933195: step 135270, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 11h:51m:38s remains)
INFO - root - 2017-12-16 23:06:02.136048: step 135280, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.228 sec/batch; 12h:27m:56s remains)
INFO - root - 2017-12-16 23:06:04.342638: step 135290, loss = 0.50, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 11h:52m:18s remains)
INFO - root - 2017-12-16 23:06:06.568947: step 135300, loss = 0.43, batch loss = 0.25 (33.3 examples/sec; 0.240 sec/batch; 13h:08m:58s remains)
INFO - root - 2017-12-16 23:06:08.923048: step 135310, loss = 0.54, batch loss = 0.37 (36.7 examples/sec; 0.218 sec/batch; 11h:56m:56s remains)
INFO - root - 2017-12-16 23:06:11.144937: step 135320, loss = 0.57, batch loss = 0.39 (35.5 examples/sec; 0.225 sec/batch; 12h:20m:38s remains)
INFO - root - 2017-12-16 23:06:13.338168: step 135330, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 11h:59m:00s remains)
INFO - root - 2017-12-16 23:06:15.548935: step 135340, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.215 sec/batch; 11h:47m:46s remains)
INFO - root - 2017-12-16 23:06:17.751123: step 135350, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 12h:16m:21s remains)
INFO - root - 2017-12-16 23:06:19.959925: step 135360, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 11h:55m:38s remains)
INFO - root - 2017-12-16 23:06:22.169317: step 135370, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 12h:07m:16s remains)
INFO - root - 2017-12-16 23:06:24.396106: step 135380, loss = 0.53, batch loss = 0.35 (33.8 examples/sec; 0.237 sec/batch; 12h:58m:23s remains)
INFO - root - 2017-12-16 23:06:26.582146: step 135390, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 12h:11m:40s remains)
INFO - root - 2017-12-16 23:06:28.770494: step 135400, loss = 0.42, batch loss = 0.24 (36.3 examples/sec; 0.220 sec/batch; 12h:03m:43s remains)
INFO - root - 2017-12-16 23:06:31.140526: step 135410, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 12h:33m:41s remains)
INFO - root - 2017-12-16 23:06:33.340028: step 135420, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 12h:06m:08s remains)
INFO - root - 2017-12-16 23:06:35.569782: step 135430, loss = 0.48, batch loss = 0.30 (34.2 examples/sec; 0.234 sec/batch; 12h:47m:53s remains)
INFO - root - 2017-12-16 23:06:37.777651: step 135440, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 12h:02m:23s remains)
INFO - root - 2017-12-16 23:06:40.027812: step 135450, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 11h:49m:11s remains)
INFO - root - 2017-12-16 23:06:42.242958: step 135460, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 12h:07m:09s remains)
INFO - root - 2017-12-16 23:06:44.450587: step 135470, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 12h:21m:51s remains)
INFO - root - 2017-12-16 23:06:46.691288: step 135480, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 11h:56m:19s remains)
INFO - root - 2017-12-16 23:06:48.913513: step 135490, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 12h:12m:20s remains)
INFO - root - 2017-12-16 23:06:51.116367: step 135500, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:50m:35s remains)
INFO - root - 2017-12-16 23:06:53.463857: step 135510, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 12h:15m:50s remains)
INFO - root - 2017-12-16 23:06:55.647515: step 135520, loss = 0.43, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 11h:41m:40s remains)
INFO - root - 2017-12-16 23:06:57.845412: step 135530, loss = 0.52, batch loss = 0.34 (34.1 examples/sec; 0.235 sec/batch; 12h:50m:41s remains)
INFO - root - 2017-12-16 23:07:00.062257: step 135540, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 12h:13m:02s remains)
INFO - root - 2017-12-16 23:07:02.305918: step 135550, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 12h:16m:16s remains)
INFO - root - 2017-12-16 23:07:04.484946: step 135560, loss = 0.62, batch loss = 0.44 (37.4 examples/sec; 0.214 sec/batch; 11h:42m:06s remains)
INFO - root - 2017-12-16 23:07:06.666443: step 135570, loss = 0.50, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 11h:54m:15s remains)
INFO - root - 2017-12-16 23:07:08.866863: step 135580, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 12h:00m:58s remains)
INFO - root - 2017-12-16 23:07:11.139796: step 135590, loss = 0.55, batch loss = 0.37 (33.8 examples/sec; 0.237 sec/batch; 12h:56m:56s remains)
INFO - root - 2017-12-16 23:07:13.379766: step 135600, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 12h:04m:24s remains)
INFO - root - 2017-12-16 23:07:15.743936: step 135610, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 12h:18m:21s remains)
INFO - root - 2017-12-16 23:07:17.971523: step 135620, loss = 0.49, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 12h:06m:31s remains)
INFO - root - 2017-12-16 23:07:20.160392: step 135630, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 12h:07m:57s remains)
INFO - root - 2017-12-16 23:07:22.362655: step 135640, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 12h:10m:14s remains)
INFO - root - 2017-12-16 23:07:24.592860: step 135650, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 11h:43m:47s remains)
INFO - root - 2017-12-16 23:07:26.821685: step 135660, loss = 0.57, batch loss = 0.39 (36.6 examples/sec; 0.219 sec/batch; 11h:57m:52s remains)
INFO - root - 2017-12-16 23:07:29.013361: step 135670, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 11h:42m:13s remains)
INFO - root - 2017-12-16 23:07:31.255239: step 135680, loss = 0.45, batch loss = 0.27 (33.8 examples/sec; 0.237 sec/batch; 12h:56m:00s remains)
INFO - root - 2017-12-16 23:07:33.467934: step 135690, loss = 0.48, batch loss = 0.30 (34.3 examples/sec; 0.233 sec/batch; 12h:44m:25s remains)
INFO - root - 2017-12-16 23:07:35.693406: step 135700, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.228 sec/batch; 12h:26m:20s remains)
INFO - root - 2017-12-16 23:07:38.025669: step 135710, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.221 sec/batch; 12h:03m:48s remains)
INFO - root - 2017-12-16 23:07:40.246112: step 135720, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 12h:20m:03s remains)
INFO - root - 2017-12-16 23:07:42.468763: step 135730, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 12h:21m:45s remains)
INFO - root - 2017-12-16 23:07:44.694629: step 135740, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 11h:54m:08s remains)
INFO - root - 2017-12-16 23:07:46.908672: step 135750, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 11h:49m:43s remains)
INFO - root - 2017-12-16 23:07:49.121072: step 135760, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 12h:04m:20s remains)
INFO - root - 2017-12-16 23:07:51.301159: step 135770, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 11h:54m:44s remains)
INFO - root - 2017-12-16 23:07:53.550838: step 135780, loss = 0.49, batch loss = 0.31 (34.0 examples/sec; 0.235 sec/batch; 12h:50m:54s remains)
INFO - root - 2017-12-16 23:07:55.768542: step 135790, loss = 0.52, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 12h:11m:24s remains)
INFO - root - 2017-12-16 23:07:58.016001: step 135800, loss = 0.47, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 12h:03m:33s remains)
INFO - root - 2017-12-16 23:08:00.365452: step 135810, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 12h:07m:12s remains)
INFO - root - 2017-12-16 23:08:02.624105: step 135820, loss = 0.52, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 12h:26m:18s remains)
INFO - root - 2017-12-16 23:08:04.847479: step 135830, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 12h:27m:18s remains)
INFO - root - 2017-12-16 23:08:07.051808: step 135840, loss = 0.46, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 11h:41m:43s remains)
INFO - root - 2017-12-16 23:08:09.270705: step 135850, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.228 sec/batch; 12h:28m:41s remains)
INFO - root - 2017-12-16 23:08:11.485339: step 135860, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 11h:52m:26s remains)
INFO - root - 2017-12-16 23:08:13.710333: step 135870, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.226 sec/batch; 12h:19m:00s remains)
INFO - root - 2017-12-16 23:08:15.915603: step 135880, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 12h:12m:55s remains)
INFO - root - 2017-12-16 23:08:18.167473: step 135890, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 12h:05m:30s remains)
INFO - root - 2017-12-16 23:08:20.382508: step 135900, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 12h:13m:20s remains)
INFO - root - 2017-12-16 23:08:22.702615: step 135910, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 12h:17m:58s remains)
INFO - root - 2017-12-16 23:08:24.950498: step 135920, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.230 sec/batch; 12h:34m:43s remains)
INFO - root - 2017-12-16 23:08:27.172766: step 135930, loss = 0.53, batch loss = 0.35 (34.7 examples/sec; 0.230 sec/batch; 12h:34m:25s remains)
INFO - root - 2017-12-16 23:08:29.391843: step 135940, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 12h:18m:14s remains)
INFO - root - 2017-12-16 23:08:31.630520: step 135950, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 12h:19m:01s remains)
INFO - root - 2017-12-16 23:08:33.845959: step 135960, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 12h:04m:00s remains)
INFO - root - 2017-12-16 23:08:36.081232: step 135970, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 11h:57m:05s remains)
INFO - root - 2017-12-16 23:08:38.313353: step 135980, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 12h:14m:55s remains)
INFO - root - 2017-12-16 23:08:40.524185: step 135990, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 12h:01m:33s remains)
INFO - root - 2017-12-16 23:08:42.743510: step 136000, loss = 0.47, batch loss = 0.29 (33.8 examples/sec; 0.237 sec/batch; 12h:55m:34s remains)
INFO - root - 2017-12-16 23:08:45.067864: step 136010, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 11h:59m:13s remains)
INFO - root - 2017-12-16 23:08:47.276147: step 136020, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 11h:59m:20s remains)
INFO - root - 2017-12-16 23:08:49.457236: step 136030, loss = 0.44, batch loss = 0.26 (34.1 examples/sec; 0.235 sec/batch; 12h:48m:58s remains)
INFO - root - 2017-12-16 23:08:51.689091: step 136040, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 12h:06m:47s remains)
INFO - root - 2017-12-16 23:08:53.885940: step 136050, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 11h:46m:40s remains)
INFO - root - 2017-12-16 23:08:56.126109: step 136060, loss = 0.46, batch loss = 0.29 (34.4 examples/sec; 0.233 sec/batch; 12h:41m:24s remains)
INFO - root - 2017-12-16 23:08:58.337732: step 136070, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 11h:55m:55s remains)
INFO - root - 2017-12-16 23:09:00.528808: step 136080, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 12h:00m:45s remains)
INFO - root - 2017-12-16 23:09:02.710878: step 136090, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 11h:45m:31s remains)
INFO - root - 2017-12-16 23:09:04.915303: step 136100, loss = 0.55, batch loss = 0.37 (37.5 examples/sec; 0.213 sec/batch; 11h:38m:50s remains)
INFO - root - 2017-12-16 23:09:07.240746: step 136110, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 12h:01m:08s remains)
INFO - root - 2017-12-16 23:09:09.471518: step 136120, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 11h:54m:16s remains)
INFO - root - 2017-12-16 23:09:11.688375: step 136130, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 11h:56m:54s remains)
INFO - root - 2017-12-16 23:09:13.890813: step 136140, loss = 0.44, batch loss = 0.26 (34.2 examples/sec; 0.234 sec/batch; 12h:44m:35s remains)
INFO - root - 2017-12-16 23:09:16.095085: step 136150, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 11h:55m:36s remains)
INFO - root - 2017-12-16 23:09:18.317709: step 136160, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 12h:01m:30s remains)
INFO - root - 2017-12-16 23:09:20.528670: step 136170, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 11h:46m:30s remains)
INFO - root - 2017-12-16 23:09:22.749477: step 136180, loss = 0.55, batch loss = 0.37 (35.8 examples/sec; 0.223 sec/batch; 12h:10m:32s remains)
INFO - root - 2017-12-16 23:09:24.946235: step 136190, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 12h:10m:10s remains)
INFO - root - 2017-12-16 23:09:27.138459: step 136200, loss = 0.52, batch loss = 0.35 (36.4 examples/sec; 0.219 sec/batch; 11h:58m:04s remains)
INFO - root - 2017-12-16 23:09:29.483528: step 136210, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 12h:32m:50s remains)
INFO - root - 2017-12-16 23:09:31.691711: step 136220, loss = 0.42, batch loss = 0.24 (34.8 examples/sec; 0.230 sec/batch; 12h:31m:42s remains)
INFO - root - 2017-12-16 23:09:33.905078: step 136230, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 12h:18m:35s remains)
INFO - root - 2017-12-16 23:09:36.120938: step 136240, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 12h:27m:33s remains)
INFO - root - 2017-12-16 23:09:38.346226: step 136250, loss = 0.52, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 12h:09m:35s remains)
INFO - root - 2017-12-16 23:09:40.581472: step 136260, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 12h:12m:47s remains)
INFO - root - 2017-12-16 23:09:42.798961: step 136270, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 12h:28m:56s remains)
INFO - root - 2017-12-16 23:09:45.030789: step 136280, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 11h:53m:37s remains)
INFO - root - 2017-12-16 23:09:47.241068: step 136290, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:47m:22s remains)
INFO - root - 2017-12-16 23:09:49.476846: step 136300, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 12h:14m:51s remains)
INFO - root - 2017-12-16 23:09:51.867798: step 136310, loss = 0.44, batch loss = 0.26 (33.8 examples/sec; 0.236 sec/batch; 12h:52m:53s remains)
INFO - root - 2017-12-16 23:09:54.107354: step 136320, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 12h:14m:07s remains)
INFO - root - 2017-12-16 23:09:56.329900: step 136330, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 12h:12m:45s remains)
INFO - root - 2017-12-16 23:09:58.543667: step 136340, loss = 0.56, batch loss = 0.38 (36.4 examples/sec; 0.220 sec/batch; 11h:58m:25s remains)
INFO - root - 2017-12-16 23:10:00.789261: step 136350, loss = 0.43, batch loss = 0.25 (34.9 examples/sec; 0.229 sec/batch; 12h:29m:21s remains)
INFO - root - 2017-12-16 23:10:02.974670: step 136360, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 12h:14m:14s remains)
INFO - root - 2017-12-16 23:10:05.198508: step 136370, loss = 0.56, batch loss = 0.38 (35.4 examples/sec; 0.226 sec/batch; 12h:19m:25s remains)
INFO - root - 2017-12-16 23:10:07.408642: step 136380, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 11h:56m:03s remains)
INFO - root - 2017-12-16 23:10:09.603929: step 136390, loss = 0.48, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 12h:05m:22s remains)
INFO - root - 2017-12-16 23:10:11.801614: step 136400, loss = 0.53, batch loss = 0.35 (37.4 examples/sec; 0.214 sec/batch; 11h:38m:12s remains)
INFO - root - 2017-12-16 23:10:14.115093: step 136410, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 12h:07m:19s remains)
INFO - root - 2017-12-16 23:10:16.344266: step 136420, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 11h:53m:15s remains)
INFO - root - 2017-12-16 23:10:18.593792: step 136430, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 12h:13m:07s remains)
INFO - root - 2017-12-16 23:10:20.827640: step 136440, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 11h:47m:44s remains)
INFO - root - 2017-12-16 23:10:23.039397: step 136450, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 11h:41m:22s remains)
INFO - root - 2017-12-16 23:10:25.232622: step 136460, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 11h:41m:08s remains)
INFO - root - 2017-12-16 23:10:27.442395: step 136470, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 12h:02m:05s remains)
INFO - root - 2017-12-16 23:10:29.653196: step 136480, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 11h:45m:03s remains)
INFO - root - 2017-12-16 23:10:31.850308: step 136490, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 11h:56m:22s remains)
INFO - root - 2017-12-16 23:10:34.093087: step 136500, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 12h:17m:50s remains)
INFO - root - 2017-12-16 23:10:36.467794: step 136510, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 12h:16m:39s remains)
INFO - root - 2017-12-16 23:10:38.668247: step 136520, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 11h:48m:08s remains)
INFO - root - 2017-12-16 23:10:40.865981: step 136530, loss = 0.40, batch loss = 0.22 (37.4 examples/sec; 0.214 sec/batch; 11h:38m:00s remains)
INFO - root - 2017-12-16 23:10:43.052229: step 136540, loss = 0.61, batch loss = 0.43 (34.6 examples/sec; 0.232 sec/batch; 12h:36m:05s remains)
INFO - root - 2017-12-16 23:10:45.239545: step 136550, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 11h:43m:30s remains)
INFO - root - 2017-12-16 23:10:47.427802: step 136560, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 11h:52m:18s remains)
INFO - root - 2017-12-16 23:10:49.631816: step 136570, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 11h:53m:45s remains)
INFO - root - 2017-12-16 23:10:51.797984: step 136580, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 12h:09m:02s remains)
INFO - root - 2017-12-16 23:10:54.008777: step 136590, loss = 0.46, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 12h:08m:58s remains)
INFO - root - 2017-12-16 23:10:56.226362: step 136600, loss = 0.43, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 12h:25m:05s remains)
INFO - root - 2017-12-16 23:10:58.595853: step 136610, loss = 0.41, batch loss = 0.23 (36.2 examples/sec; 0.221 sec/batch; 12h:01m:40s remains)
INFO - root - 2017-12-16 23:11:00.795744: step 136620, loss = 0.47, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 12h:18m:36s remains)
INFO - root - 2017-12-16 23:11:02.996937: step 136630, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:45m:29s remains)
INFO - root - 2017-12-16 23:11:05.185772: step 136640, loss = 0.46, batch loss = 0.28 (38.1 examples/sec; 0.210 sec/batch; 11h:24m:36s remains)
INFO - root - 2017-12-16 23:11:07.453815: step 136650, loss = 0.43, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 12h:00m:46s remains)
INFO - root - 2017-12-16 23:11:09.661745: step 136660, loss = 0.46, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 11h:41m:35s remains)
INFO - root - 2017-12-16 23:11:11.853924: step 136670, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 12h:07m:13s remains)
INFO - root - 2017-12-16 23:11:14.036916: step 136680, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 11h:43m:33s remains)
INFO - root - 2017-12-16 23:11:16.224901: step 136690, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 11h:46m:54s remains)
INFO - root - 2017-12-16 23:11:18.433073: step 136700, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 12h:10m:25s remains)
INFO - root - 2017-12-16 23:11:20.771826: step 136710, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 12h:30m:29s remains)
INFO - root - 2017-12-16 23:11:23.001814: step 136720, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 12h:24m:08s remains)
INFO - root - 2017-12-16 23:11:25.210712: step 136730, loss = 0.52, batch loss = 0.34 (33.6 examples/sec; 0.238 sec/batch; 12h:57m:24s remains)
INFO - root - 2017-12-16 23:11:27.426251: step 136740, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 12h:00m:49s remains)
INFO - root - 2017-12-16 23:11:29.650549: step 136750, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 12h:00m:04s remains)
INFO - root - 2017-12-16 23:11:31.844187: step 136760, loss = 0.45, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 12h:04m:53s remains)
INFO - root - 2017-12-16 23:11:34.064021: step 136770, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 11h:42m:00s remains)
INFO - root - 2017-12-16 23:11:36.286326: step 136780, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 11h:49m:50s remains)
INFO - root - 2017-12-16 23:11:38.474707: step 136790, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 11h:56m:01s remains)
INFO - root - 2017-12-16 23:11:40.648688: step 136800, loss = 0.51, batch loss = 0.33 (38.5 examples/sec; 0.208 sec/batch; 11h:18m:04s remains)
INFO - root - 2017-12-16 23:11:42.942530: step 136810, loss = 0.55, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 12h:00m:56s remains)
INFO - root - 2017-12-16 23:11:45.167422: step 136820, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 12h:01m:05s remains)
INFO - root - 2017-12-16 23:11:47.409535: step 136830, loss = 0.47, batch loss = 0.29 (38.1 examples/sec; 0.210 sec/batch; 11h:24m:30s remains)
INFO - root - 2017-12-16 23:11:49.629944: step 136840, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 11h:31m:41s remains)
INFO - root - 2017-12-16 23:11:51.820265: step 136850, loss = 0.53, batch loss = 0.35 (37.4 examples/sec; 0.214 sec/batch; 11h:38m:11s remains)
INFO - root - 2017-12-16 23:11:54.004435: step 136860, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 11h:59m:03s remains)
INFO - root - 2017-12-16 23:11:56.192472: step 136870, loss = 0.56, batch loss = 0.38 (37.1 examples/sec; 0.216 sec/batch; 11h:43m:17s remains)
INFO - root - 2017-12-16 23:11:58.392942: step 136880, loss = 0.48, batch loss = 0.30 (33.4 examples/sec; 0.240 sec/batch; 13h:02m:04s remains)
INFO - root - 2017-12-16 23:12:00.613490: step 136890, loss = 0.49, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 12h:12m:25s remains)
INFO - root - 2017-12-16 23:12:02.796043: step 136900, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 11h:49m:23s remains)
INFO - root - 2017-12-16 23:12:05.111305: step 136910, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 11h:45m:59s remains)
INFO - root - 2017-12-16 23:12:07.340989: step 136920, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 11h:51m:30s remains)
INFO - root - 2017-12-16 23:12:09.612241: step 136930, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.230 sec/batch; 12h:30m:42s remains)
INFO - root - 2017-12-16 23:12:11.828511: step 136940, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 12h:02m:38s remains)
INFO - root - 2017-12-16 23:12:14.050122: step 136950, loss = 0.47, batch loss = 0.29 (33.6 examples/sec; 0.238 sec/batch; 12h:55m:05s remains)
INFO - root - 2017-12-16 23:12:16.244359: step 136960, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 12h:20m:24s remains)
INFO - root - 2017-12-16 23:12:18.449719: step 136970, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:43m:41s remains)
INFO - root - 2017-12-16 23:12:20.645701: step 136980, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 12h:18m:43s remains)
INFO - root - 2017-12-16 23:12:22.848781: step 136990, loss = 0.50, batch loss = 0.32 (38.4 examples/sec; 0.209 sec/batch; 11h:19m:41s remains)
INFO - root - 2017-12-16 23:12:25.094738: step 137000, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 12h:17m:05s remains)
INFO - root - 2017-12-16 23:12:27.440846: step 137010, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.230 sec/batch; 12h:30m:51s remains)
INFO - root - 2017-12-16 23:12:29.633553: step 137020, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 11h:50m:17s remains)
INFO - root - 2017-12-16 23:12:31.866911: step 137030, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 11h:45m:31s remains)
INFO - root - 2017-12-16 23:12:34.047800: step 137040, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 11h:55m:42s remains)
INFO - root - 2017-12-16 23:12:36.244386: step 137050, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 11h:43m:44s remains)
INFO - root - 2017-12-16 23:12:38.482688: step 137060, loss = 0.44, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 12h:05m:48s remains)
INFO - root - 2017-12-16 23:12:40.702262: step 137070, loss = 0.50, batch loss = 0.32 (37.9 examples/sec; 0.211 sec/batch; 11h:28m:05s remains)
INFO - root - 2017-12-16 23:12:42.940651: step 137080, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 12h:03m:19s remains)
INFO - root - 2017-12-16 23:12:45.140215: step 137090, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 12h:00m:27s remains)
INFO - root - 2017-12-16 23:12:47.319192: step 137100, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 12h:03m:59s remains)
INFO - root - 2017-12-16 23:12:49.664495: step 137110, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 11h:54m:31s remains)
INFO - root - 2017-12-16 23:12:51.868331: step 137120, loss = 0.50, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 11h:41m:47s remains)
INFO - root - 2017-12-16 23:12:54.090712: step 137130, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 12h:02m:58s remains)
INFO - root - 2017-12-16 23:12:56.305993: step 137140, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 11h:55m:20s remains)
INFO - root - 2017-12-16 23:12:58.484816: step 137150, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 11h:53m:43s remains)
INFO - root - 2017-12-16 23:13:00.646358: step 137160, loss = 0.45, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 11h:50m:32s remains)
INFO - root - 2017-12-16 23:13:02.853007: step 137170, loss = 0.53, batch loss = 0.35 (38.1 examples/sec; 0.210 sec/batch; 11h:23m:30s remains)
INFO - root - 2017-12-16 23:13:05.047295: step 137180, loss = 0.47, batch loss = 0.29 (38.2 examples/sec; 0.209 sec/batch; 11h:21m:36s remains)
INFO - root - 2017-12-16 23:13:07.301750: step 137190, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 11h:59m:00s remains)
INFO - root - 2017-12-16 23:13:09.523216: step 137200, loss = 0.49, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 11h:45m:44s remains)
INFO - root - 2017-12-16 23:13:11.880506: step 137210, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 12h:17m:17s remains)
INFO - root - 2017-12-16 23:13:14.061386: step 137220, loss = 0.52, batch loss = 0.34 (37.5 examples/sec; 0.214 sec/batch; 11h:35m:15s remains)
INFO - root - 2017-12-16 23:13:16.263127: step 137230, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.211 sec/batch; 11h:27m:59s remains)
INFO - root - 2017-12-16 23:13:18.466131: step 137240, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 11h:45m:01s remains)
INFO - root - 2017-12-16 23:13:20.650491: step 137250, loss = 0.54, batch loss = 0.36 (36.8 examples/sec; 0.218 sec/batch; 11h:47m:59s remains)
INFO - root - 2017-12-16 23:13:22.871562: step 137260, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 12h:07m:00s remains)
INFO - root - 2017-12-16 23:13:25.085480: step 137270, loss = 0.41, batch loss = 0.23 (36.8 examples/sec; 0.217 sec/batch; 11h:46m:40s remains)
INFO - root - 2017-12-16 23:13:27.292023: step 137280, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 11h:59m:20s remains)
INFO - root - 2017-12-16 23:13:29.467479: step 137290, loss = 0.44, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 11h:32m:29s remains)
INFO - root - 2017-12-16 23:13:31.661326: step 137300, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 11h:47m:56s remains)
INFO - root - 2017-12-16 23:13:33.995042: step 137310, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.229 sec/batch; 12h:23m:34s remains)
INFO - root - 2017-12-16 23:13:36.228213: step 137320, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 12h:10m:59s remains)
INFO - root - 2017-12-16 23:13:38.429190: step 137330, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 12h:08m:22s remains)
INFO - root - 2017-12-16 23:13:40.661030: step 137340, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 11h:51m:11s remains)
INFO - root - 2017-12-16 23:13:42.865641: step 137350, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 11h:41m:52s remains)
INFO - root - 2017-12-16 23:13:45.095139: step 137360, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.221 sec/batch; 12h:00m:18s remains)
INFO - root - 2017-12-16 23:13:47.278728: step 137370, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 11h:36m:16s remains)
INFO - root - 2017-12-16 23:13:49.509835: step 137380, loss = 0.51, batch loss = 0.33 (34.9 examples/sec; 0.230 sec/batch; 12h:26m:25s remains)
INFO - root - 2017-12-16 23:13:51.723562: step 137390, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 12h:05m:26s remains)
INFO - root - 2017-12-16 23:13:53.954911: step 137400, loss = 0.50, batch loss = 0.33 (34.6 examples/sec; 0.231 sec/batch; 12h:32m:36s remains)
INFO - root - 2017-12-16 23:13:56.282379: step 137410, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 11h:32m:11s remains)
INFO - root - 2017-12-16 23:13:58.491177: step 137420, loss = 0.48, batch loss = 0.30 (34.3 examples/sec; 0.233 sec/batch; 12h:38m:30s remains)
INFO - root - 2017-12-16 23:14:00.670337: step 137430, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.215 sec/batch; 11h:37m:52s remains)
INFO - root - 2017-12-16 23:14:02.896167: step 137440, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 12h:04m:06s remains)
INFO - root - 2017-12-16 23:14:05.121277: step 137450, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 12h:10m:40s remains)
INFO - root - 2017-12-16 23:14:07.341894: step 137460, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 11h:59m:22s remains)
INFO - root - 2017-12-16 23:14:09.582790: step 137470, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 11h:50m:34s remains)
INFO - root - 2017-12-16 23:14:11.754790: step 137480, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:41m:54s remains)
INFO - root - 2017-12-16 23:14:13.986769: step 137490, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 11h:41m:01s remains)
INFO - root - 2017-12-16 23:14:16.159042: step 137500, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 11h:37m:31s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-137500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-137500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 23:14:19.170282: step 137510, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 12h:13m:04s remains)
INFO - root - 2017-12-16 23:14:21.443801: step 137520, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 11h:43m:57s remains)
INFO - root - 2017-12-16 23:14:23.657249: step 137530, loss = 0.55, batch loss = 0.37 (37.2 examples/sec; 0.215 sec/batch; 11h:38m:51s remains)
INFO - root - 2017-12-16 23:14:25.851995: step 137540, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 12h:08m:21s remains)
INFO - root - 2017-12-16 23:14:28.054712: step 137550, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 11h:56m:06s remains)
INFO - root - 2017-12-16 23:14:30.242397: step 137560, loss = 0.42, batch loss = 0.24 (36.5 examples/sec; 0.219 sec/batch; 11h:52m:13s remains)
INFO - root - 2017-12-16 23:14:32.442366: step 137570, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 11h:50m:30s remains)
INFO - root - 2017-12-16 23:14:34.691068: step 137580, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 12h:11m:53s remains)
INFO - root - 2017-12-16 23:14:36.886536: step 137590, loss = 0.48, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 12h:14m:45s remains)
INFO - root - 2017-12-16 23:14:39.102057: step 137600, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 12h:17m:53s remains)
INFO - root - 2017-12-16 23:14:41.459815: step 137610, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 11h:51m:40s remains)
INFO - root - 2017-12-16 23:14:43.652345: step 137620, loss = 0.46, batch loss = 0.28 (34.4 examples/sec; 0.233 sec/batch; 12h:35m:12s remains)
INFO - root - 2017-12-16 23:14:45.854780: step 137630, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 12h:06m:26s remains)
INFO - root - 2017-12-16 23:14:48.047994: step 137640, loss = 0.48, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 11h:58m:25s remains)
INFO - root - 2017-12-16 23:14:50.269372: step 137650, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 11h:48m:17s remains)
INFO - root - 2017-12-16 23:14:52.515638: step 137660, loss = 0.46, batch loss = 0.28 (34.2 examples/sec; 0.234 sec/batch; 12h:39m:35s remains)
INFO - root - 2017-12-16 23:14:54.742014: step 137670, loss = 0.54, batch loss = 0.37 (35.7 examples/sec; 0.224 sec/batch; 12h:07m:29s remains)
INFO - root - 2017-12-16 23:14:56.963095: step 137680, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 11h:47m:24s remains)
INFO - root - 2017-12-16 23:14:59.152358: step 137690, loss = 0.43, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 12h:07m:12s remains)
INFO - root - 2017-12-16 23:15:01.356972: step 137700, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 11h:53m:43s remains)
INFO - root - 2017-12-16 23:15:03.688518: step 137710, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 12h:07m:10s remains)
INFO - root - 2017-12-16 23:15:05.876229: step 137720, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 11h:31m:16s remains)
INFO - root - 2017-12-16 23:15:08.112825: step 137730, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 11h:42m:17s remains)
INFO - root - 2017-12-16 23:15:10.309331: step 137740, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 11h:31m:41s remains)
INFO - root - 2017-12-16 23:15:12.514181: step 137750, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 11h:43m:44s remains)
INFO - root - 2017-12-16 23:15:14.694890: step 137760, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 12h:00m:46s remains)
INFO - root - 2017-12-16 23:15:16.883685: step 137770, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 11h:47m:02s remains)
INFO - root - 2017-12-16 23:15:19.074242: step 137780, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 11h:51m:16s remains)
INFO - root - 2017-12-16 23:15:21.262733: step 137790, loss = 0.47, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 11h:36m:28s remains)
INFO - root - 2017-12-16 23:15:23.510265: step 137800, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 12h:23m:14s remains)
INFO - root - 2017-12-16 23:15:25.830629: step 137810, loss = 0.41, batch loss = 0.23 (37.1 examples/sec; 0.216 sec/batch; 11h:40m:14s remains)
INFO - root - 2017-12-16 23:15:28.072927: step 137820, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 12h:11m:22s remains)
INFO - root - 2017-12-16 23:15:30.304093: step 137830, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 11h:36m:06s remains)
INFO - root - 2017-12-16 23:15:32.496634: step 137840, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 11h:37m:00s remains)
INFO - root - 2017-12-16 23:15:34.658294: step 137850, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 11h:30m:51s remains)
INFO - root - 2017-12-16 23:15:36.842511: step 137860, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 11h:28m:28s remains)
INFO - root - 2017-12-16 23:15:39.074354: step 137870, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 11h:34m:10s remains)
INFO - root - 2017-12-16 23:15:41.302830: step 137880, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 11h:41m:18s remains)
INFO - root - 2017-12-16 23:15:43.503227: step 137890, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 11h:51m:57s remains)
INFO - root - 2017-12-16 23:15:45.700304: step 137900, loss = 0.44, batch loss = 0.27 (37.8 examples/sec; 0.212 sec/batch; 11h:26m:21s remains)
INFO - root - 2017-12-16 23:15:48.053219: step 137910, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 12h:07m:26s remains)
INFO - root - 2017-12-16 23:15:50.268206: step 137920, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 12h:05m:40s remains)
INFO - root - 2017-12-16 23:15:52.487895: step 137930, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.215 sec/batch; 11h:36m:10s remains)
INFO - root - 2017-12-16 23:15:54.754860: step 137940, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 11h:46m:42s remains)
INFO - root - 2017-12-16 23:15:56.904170: step 137950, loss = 0.49, batch loss = 0.32 (37.5 examples/sec; 0.213 sec/batch; 11h:31m:24s remains)
INFO - root - 2017-12-16 23:15:59.125418: step 137960, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 11h:50m:24s remains)
INFO - root - 2017-12-16 23:16:01.299368: step 137970, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 12h:02m:36s remains)
INFO - root - 2017-12-16 23:16:03.553884: step 137980, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 12h:10m:26s remains)
INFO - root - 2017-12-16 23:16:05.801754: step 137990, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 12h:09m:16s remains)
INFO - root - 2017-12-16 23:16:08.069647: step 138000, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 12h:09m:52s remains)
INFO - root - 2017-12-16 23:16:10.420166: step 138010, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 11h:58m:59s remains)
INFO - root - 2017-12-16 23:16:12.626091: step 138020, loss = 0.45, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 12h:14m:32s remains)
INFO - root - 2017-12-16 23:16:14.827277: step 138030, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 11h:51m:30s remains)
INFO - root - 2017-12-16 23:16:17.061327: step 138040, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 11h:39m:11s remains)
INFO - root - 2017-12-16 23:16:19.233330: step 138050, loss = 0.51, batch loss = 0.33 (37.5 examples/sec; 0.213 sec/batch; 11h:30m:38s remains)
INFO - root - 2017-12-16 23:16:21.413860: step 138060, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 11h:36m:17s remains)
INFO - root - 2017-12-16 23:16:23.679432: step 138070, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 12h:01m:09s remains)
INFO - root - 2017-12-16 23:16:25.887678: step 138080, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 11h:52m:01s remains)
INFO - root - 2017-12-16 23:16:28.067565: step 138090, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 11h:33m:36s remains)
INFO - root - 2017-12-16 23:16:30.271480: step 138100, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 11h:40m:25s remains)
INFO - root - 2017-12-16 23:16:32.632661: step 138110, loss = 0.51, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 11h:53m:46s remains)
INFO - root - 2017-12-16 23:16:34.839273: step 138120, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 11h:41m:26s remains)
INFO - root - 2017-12-16 23:16:37.024197: step 138130, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 11h:53m:23s remains)
INFO - root - 2017-12-16 23:16:39.266480: step 138140, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 11h:50m:25s remains)
INFO - root - 2017-12-16 23:16:41.514454: step 138150, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 11h:59m:55s remains)
INFO - root - 2017-12-16 23:16:43.719544: step 138160, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 12h:06m:19s remains)
INFO - root - 2017-12-16 23:16:45.918841: step 138170, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 11h:49m:11s remains)
INFO - root - 2017-12-16 23:16:48.131636: step 138180, loss = 0.42, batch loss = 0.24 (36.5 examples/sec; 0.219 sec/batch; 11h:49m:15s remains)
INFO - root - 2017-12-16 23:16:50.325268: step 138190, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 11h:47m:14s remains)
INFO - root - 2017-12-16 23:16:52.541921: step 138200, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 11h:36m:15s remains)
INFO - root - 2017-12-16 23:16:54.848901: step 138210, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 12h:02m:13s remains)
INFO - root - 2017-12-16 23:16:57.048977: step 138220, loss = 0.45, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 11h:38m:07s remains)
INFO - root - 2017-12-16 23:16:59.255923: step 138230, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:39m:25s remains)
INFO - root - 2017-12-16 23:17:01.457055: step 138240, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 11h:47m:43s remains)
INFO - root - 2017-12-16 23:17:03.638585: step 138250, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 11h:50m:24s remains)
INFO - root - 2017-12-16 23:17:05.816446: step 138260, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 11h:48m:38s remains)
INFO - root - 2017-12-16 23:17:08.073491: step 138270, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.229 sec/batch; 12h:20m:10s remains)
INFO - root - 2017-12-16 23:17:10.287237: step 138280, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 11h:33m:35s remains)
INFO - root - 2017-12-16 23:17:12.505298: step 138290, loss = 0.50, batch loss = 0.33 (34.4 examples/sec; 0.232 sec/batch; 12h:32m:31s remains)
INFO - root - 2017-12-16 23:17:14.754624: step 138300, loss = 0.47, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 11h:51m:13s remains)
INFO - root - 2017-12-16 23:17:17.079384: step 138310, loss = 0.51, batch loss = 0.33 (38.1 examples/sec; 0.210 sec/batch; 11h:20m:18s remains)
INFO - root - 2017-12-16 23:17:19.331623: step 138320, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 11h:52m:25s remains)
INFO - root - 2017-12-16 23:17:21.508044: step 138330, loss = 0.45, batch loss = 0.27 (38.1 examples/sec; 0.210 sec/batch; 11h:20m:14s remains)
INFO - root - 2017-12-16 23:17:23.740112: step 138340, loss = 0.42, batch loss = 0.24 (34.4 examples/sec; 0.233 sec/batch; 12h:32m:26s remains)
INFO - root - 2017-12-16 23:17:25.968567: step 138350, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 11h:32m:06s remains)
INFO - root - 2017-12-16 23:17:28.160697: step 138360, loss = 0.49, batch loss = 0.31 (37.8 examples/sec; 0.212 sec/batch; 11h:25m:37s remains)
INFO - root - 2017-12-16 23:17:30.409557: step 138370, loss = 0.54, batch loss = 0.36 (35.5 examples/sec; 0.225 sec/batch; 12h:09m:27s remains)
INFO - root - 2017-12-16 23:17:32.636659: step 138380, loss = 0.52, batch loss = 0.34 (34.7 examples/sec; 0.230 sec/batch; 12h:25m:17s remains)
INFO - root - 2017-12-16 23:17:34.835056: step 138390, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 11h:38m:14s remains)
INFO - root - 2017-12-16 23:17:37.068590: step 138400, loss = 0.52, batch loss = 0.35 (37.3 examples/sec; 0.215 sec/batch; 11h:34m:33s remains)
INFO - root - 2017-12-16 23:17:39.393352: step 138410, loss = 0.50, batch loss = 0.33 (37.5 examples/sec; 0.213 sec/batch; 11h:29m:47s remains)
INFO - root - 2017-12-16 23:17:41.632793: step 138420, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 11h:53m:44s remains)
INFO - root - 2017-12-16 23:17:43.846919: step 138430, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 12h:02m:58s remains)
INFO - root - 2017-12-16 23:17:46.043986: step 138440, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 11h:49m:44s remains)
INFO - root - 2017-12-16 23:17:48.289229: step 138450, loss = 0.43, batch loss = 0.25 (34.8 examples/sec; 0.230 sec/batch; 12h:23m:37s remains)
INFO - root - 2017-12-16 23:17:50.556682: step 138460, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 11h:57m:06s remains)
INFO - root - 2017-12-16 23:17:52.779538: step 138470, loss = 0.53, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 11h:45m:50s remains)
INFO - root - 2017-12-16 23:17:54.956735: step 138480, loss = 0.47, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 11h:28m:57s remains)
INFO - root - 2017-12-16 23:17:57.163980: step 138490, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 11h:47m:22s remains)
INFO - root - 2017-12-16 23:17:59.451646: step 138500, loss = 0.41, batch loss = 0.23 (35.3 examples/sec; 0.227 sec/batch; 12h:13m:24s remains)
INFO - root - 2017-12-16 23:18:01.786798: step 138510, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 11h:33m:17s remains)
INFO - root - 2017-12-16 23:18:04.007743: step 138520, loss = 0.44, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 12h:29m:33s remains)
INFO - root - 2017-12-16 23:18:06.196635: step 138530, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:38m:15s remains)
INFO - root - 2017-12-16 23:18:08.403769: step 138540, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 12h:06m:09s remains)
INFO - root - 2017-12-16 23:18:10.625147: step 138550, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 12h:01m:34s remains)
INFO - root - 2017-12-16 23:18:12.865044: step 138560, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 11h:54m:45s remains)
INFO - root - 2017-12-16 23:18:15.070470: step 138570, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 11h:45m:39s remains)
INFO - root - 2017-12-16 23:18:17.248934: step 138580, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 11h:51m:04s remains)
INFO - root - 2017-12-16 23:18:19.424092: step 138590, loss = 0.46, batch loss = 0.28 (33.8 examples/sec; 0.236 sec/batch; 12h:43m:53s remains)
INFO - root - 2017-12-16 23:18:21.660910: step 138600, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 12h:06m:07s remains)
INFO - root - 2017-12-16 23:18:24.031425: step 138610, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 12h:04m:12s remains)
INFO - root - 2017-12-16 23:18:26.273383: step 138620, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 12h:01m:36s remains)
INFO - root - 2017-12-16 23:18:28.483560: step 138630, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 11h:46m:53s remains)
INFO - root - 2017-12-16 23:18:30.712094: step 138640, loss = 0.57, batch loss = 0.39 (34.4 examples/sec; 0.233 sec/batch; 12h:31m:13s remains)
INFO - root - 2017-12-16 23:18:32.941661: step 138650, loss = 0.56, batch loss = 0.38 (35.4 examples/sec; 0.226 sec/batch; 12h:10m:51s remains)
INFO - root - 2017-12-16 23:18:35.180302: step 138660, loss = 0.51, batch loss = 0.33 (34.1 examples/sec; 0.234 sec/batch; 12h:37m:25s remains)
INFO - root - 2017-12-16 23:18:37.388853: step 138670, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 11h:41m:01s remains)
INFO - root - 2017-12-16 23:18:39.586371: step 138680, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 12h:01m:33s remains)
INFO - root - 2017-12-16 23:18:41.768625: step 138690, loss = 0.50, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 11h:40m:22s remains)
INFO - root - 2017-12-16 23:18:44.011900: step 138700, loss = 0.45, batch loss = 0.27 (34.2 examples/sec; 0.234 sec/batch; 12h:36m:08s remains)
INFO - root - 2017-12-16 23:18:46.355306: step 138710, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 11h:42m:43s remains)
INFO - root - 2017-12-16 23:18:48.606475: step 138720, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 12h:11m:36s remains)
INFO - root - 2017-12-16 23:18:50.835129: step 138730, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 11h:33m:38s remains)
INFO - root - 2017-12-16 23:18:53.059310: step 138740, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 12h:20m:55s remains)
INFO - root - 2017-12-16 23:18:55.295773: step 138750, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 11h:35m:12s remains)
INFO - root - 2017-12-16 23:18:57.501873: step 138760, loss = 0.45, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 11h:55m:15s remains)
INFO - root - 2017-12-16 23:18:59.723280: step 138770, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 11h:59m:14s remains)
INFO - root - 2017-12-16 23:19:01.948509: step 138780, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 11h:54m:19s remains)
INFO - root - 2017-12-16 23:19:04.171381: step 138790, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 11h:43m:50s remains)
INFO - root - 2017-12-16 23:19:06.348211: step 138800, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:37m:36s remains)
INFO - root - 2017-12-16 23:19:08.696717: step 138810, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 12h:07m:09s remains)
INFO - root - 2017-12-16 23:19:10.945156: step 138820, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 12h:01m:27s remains)
INFO - root - 2017-12-16 23:19:13.149593: step 138830, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 12h:08m:57s remains)
INFO - root - 2017-12-16 23:19:15.354490: step 138840, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 11h:34m:46s remains)
INFO - root - 2017-12-16 23:19:17.552990: step 138850, loss = 0.54, batch loss = 0.36 (36.0 examples/sec; 0.222 sec/batch; 11h:57m:35s remains)
INFO - root - 2017-12-16 23:19:19.785597: step 138860, loss = 0.44, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 11h:42m:27s remains)
INFO - root - 2017-12-16 23:19:22.010413: step 138870, loss = 0.55, batch loss = 0.37 (34.8 examples/sec; 0.230 sec/batch; 12h:22m:10s remains)
INFO - root - 2017-12-16 23:19:24.210056: step 138880, loss = 0.44, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 12h:15m:00s remains)
INFO - root - 2017-12-16 23:19:26.435473: step 138890, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 11h:48m:51s remains)
INFO - root - 2017-12-16 23:19:28.682750: step 138900, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 12h:11m:49s remains)
INFO - root - 2017-12-16 23:19:31.020631: step 138910, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 11h:44m:54s remains)
INFO - root - 2017-12-16 23:19:33.275282: step 138920, loss = 0.45, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 11h:42m:34s remains)
INFO - root - 2017-12-16 23:19:35.488661: step 138930, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.215 sec/batch; 11h:32m:06s remains)
INFO - root - 2017-12-16 23:19:37.688627: step 138940, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 12h:00m:19s remains)
INFO - root - 2017-12-16 23:19:39.902456: step 138950, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 12h:27m:50s remains)
INFO - root - 2017-12-16 23:19:42.111255: step 138960, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 11h:37m:05s remains)
INFO - root - 2017-12-16 23:19:44.331255: step 138970, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 12h:11m:10s remains)
INFO - root - 2017-12-16 23:19:46.589209: step 138980, loss = 0.52, batch loss = 0.34 (34.5 examples/sec; 0.232 sec/batch; 12h:27m:47s remains)
INFO - root - 2017-12-16 23:19:48.825356: step 138990, loss = 0.47, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 12h:05m:23s remains)
INFO - root - 2017-12-16 23:19:51.064012: step 139000, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 11h:29m:03s remains)
INFO - root - 2017-12-16 23:19:53.419320: step 139010, loss = 0.43, batch loss = 0.25 (34.0 examples/sec; 0.236 sec/batch; 12h:39m:53s remains)
INFO - root - 2017-12-16 23:19:55.619809: step 139020, loss = 0.45, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 11h:46m:00s remains)
INFO - root - 2017-12-16 23:19:57.833693: step 139030, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 11h:46m:10s remains)
INFO - root - 2017-12-16 23:20:00.039376: step 139040, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 11h:51m:34s remains)
INFO - root - 2017-12-16 23:20:02.256093: step 139050, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 11h:28m:49s remains)
INFO - root - 2017-12-16 23:20:04.473428: step 139060, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 12h:03m:57s remains)
INFO - root - 2017-12-16 23:20:06.703406: step 139070, loss = 0.44, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 12h:03m:55s remains)
INFO - root - 2017-12-16 23:20:08.892029: step 139080, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:37m:52s remains)
INFO - root - 2017-12-16 23:20:11.067158: step 139090, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 11h:44m:35s remains)
INFO - root - 2017-12-16 23:20:13.265503: step 139100, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 11h:47m:23s remains)
INFO - root - 2017-12-16 23:20:15.644133: step 139110, loss = 0.55, batch loss = 0.37 (35.4 examples/sec; 0.226 sec/batch; 12h:08m:18s remains)
INFO - root - 2017-12-16 23:20:17.887991: step 139120, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.228 sec/batch; 12h:16m:19s remains)
INFO - root - 2017-12-16 23:20:20.129098: step 139130, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 11h:59m:20s remains)
INFO - root - 2017-12-16 23:20:22.376964: step 139140, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 12h:08m:23s remains)
INFO - root - 2017-12-16 23:20:24.605110: step 139150, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 11h:58m:02s remains)
INFO - root - 2017-12-16 23:20:26.805327: step 139160, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 11h:52m:04s remains)
INFO - root - 2017-12-16 23:20:29.012359: step 139170, loss = 0.41, batch loss = 0.23 (36.4 examples/sec; 0.220 sec/batch; 11h:47m:20s remains)
INFO - root - 2017-12-16 23:20:31.238685: step 139180, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 11h:34m:20s remains)
INFO - root - 2017-12-16 23:20:33.427393: step 139190, loss = 0.48, batch loss = 0.31 (37.8 examples/sec; 0.212 sec/batch; 11h:21m:38s remains)
INFO - root - 2017-12-16 23:20:35.632261: step 139200, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 11h:58m:28s remains)
INFO - root - 2017-12-16 23:20:37.948598: step 139210, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.223 sec/batch; 11h:59m:42s remains)
INFO - root - 2017-12-16 23:20:40.156401: step 139220, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 11h:44m:31s remains)
INFO - root - 2017-12-16 23:20:42.368687: step 139230, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 12h:02m:44s remains)
INFO - root - 2017-12-16 23:20:44.575215: step 139240, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 11h:47m:17s remains)
INFO - root - 2017-12-16 23:20:46.755847: step 139250, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 11h:44m:23s remains)
INFO - root - 2017-12-16 23:20:48.976201: step 139260, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 11h:42m:00s remains)
INFO - root - 2017-12-16 23:20:51.175517: step 139270, loss = 0.57, batch loss = 0.39 (36.2 examples/sec; 0.221 sec/batch; 11h:51m:11s remains)
INFO - root - 2017-12-16 23:20:53.381506: step 139280, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 11h:47m:27s remains)
INFO - root - 2017-12-16 23:20:55.588561: step 139290, loss = 0.58, batch loss = 0.40 (35.2 examples/sec; 0.227 sec/batch; 12h:11m:04s remains)
INFO - root - 2017-12-16 23:20:57.805921: step 139300, loss = 0.47, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 11h:50m:08s remains)
INFO - root - 2017-12-16 23:21:00.163028: step 139310, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 11h:59m:44s remains)
INFO - root - 2017-12-16 23:21:02.388626: step 139320, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 12h:13m:52s remains)
INFO - root - 2017-12-16 23:21:04.622079: step 139330, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.230 sec/batch; 12h:21m:50s remains)
INFO - root - 2017-12-16 23:21:06.853278: step 139340, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 12h:04m:37s remains)
INFO - root - 2017-12-16 23:21:09.062903: step 139350, loss = 0.50, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 11h:47m:39s remains)
INFO - root - 2017-12-16 23:21:11.247271: step 139360, loss = 0.55, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 11h:48m:27s remains)
INFO - root - 2017-12-16 23:21:13.466094: step 139370, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 11h:45m:27s remains)
INFO - root - 2017-12-16 23:21:15.676970: step 139380, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 11h:35m:49s remains)
INFO - root - 2017-12-16 23:21:17.888365: step 139390, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 11h:44m:13s remains)
INFO - root - 2017-12-16 23:21:20.120609: step 139400, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 11h:37m:23s remains)
INFO - root - 2017-12-16 23:21:22.482542: step 139410, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 12h:12m:48s remains)
INFO - root - 2017-12-16 23:21:24.720281: step 139420, loss = 0.53, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 12h:00m:51s remains)
INFO - root - 2017-12-16 23:21:26.955920: step 139430, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 12h:25m:24s remains)
INFO - root - 2017-12-16 23:21:29.167899: step 139440, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 11h:59m:26s remains)
INFO - root - 2017-12-16 23:21:31.399959: step 139450, loss = 0.51, batch loss = 0.33 (34.2 examples/sec; 0.234 sec/batch; 12h:32m:10s remains)
INFO - root - 2017-12-16 23:21:33.644657: step 139460, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 11h:52m:39s remains)
INFO - root - 2017-12-16 23:21:35.830258: step 139470, loss = 0.50, batch loss = 0.32 (37.9 examples/sec; 0.211 sec/batch; 11h:19m:20s remains)
INFO - root - 2017-12-16 23:21:38.036913: step 139480, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 11h:48m:25s remains)
INFO - root - 2017-12-16 23:21:40.269097: step 139490, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 12h:00m:51s remains)
INFO - root - 2017-12-16 23:21:42.502968: step 139500, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 11h:40m:16s remains)
INFO - root - 2017-12-16 23:21:44.845356: step 139510, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 11h:41m:30s remains)
INFO - root - 2017-12-16 23:21:47.078674: step 139520, loss = 0.44, batch loss = 0.27 (37.8 examples/sec; 0.212 sec/batch; 11h:20m:28s remains)
INFO - root - 2017-12-16 23:21:49.278319: step 139530, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 11h:45m:40s remains)
INFO - root - 2017-12-16 23:21:51.500263: step 139540, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 12h:17m:05s remains)
INFO - root - 2017-12-16 23:21:53.730502: step 139550, loss = 0.57, batch loss = 0.39 (34.7 examples/sec; 0.231 sec/batch; 12h:22m:08s remains)
INFO - root - 2017-12-16 23:21:55.957415: step 139560, loss = 0.49, batch loss = 0.32 (37.6 examples/sec; 0.213 sec/batch; 11h:23m:59s remains)
INFO - root - 2017-12-16 23:21:58.129999: step 139570, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 11h:40m:13s remains)
INFO - root - 2017-12-16 23:22:00.296640: step 139580, loss = 0.55, batch loss = 0.37 (36.3 examples/sec; 0.221 sec/batch; 11h:49m:09s remains)
INFO - root - 2017-12-16 23:22:02.511472: step 139590, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 12h:00m:41s remains)
INFO - root - 2017-12-16 23:22:04.741734: step 139600, loss = 0.55, batch loss = 0.37 (35.3 examples/sec; 0.227 sec/batch; 12h:09m:22s remains)
INFO - root - 2017-12-16 23:22:07.112348: step 139610, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.219 sec/batch; 11h:45m:38s remains)
INFO - root - 2017-12-16 23:22:09.347914: step 139620, loss = 0.47, batch loss = 0.29 (34.1 examples/sec; 0.235 sec/batch; 12h:35m:13s remains)
INFO - root - 2017-12-16 23:22:11.551376: step 139630, loss = 0.43, batch loss = 0.25 (37.9 examples/sec; 0.211 sec/batch; 11h:17m:38s remains)
INFO - root - 2017-12-16 23:22:13.758262: step 139640, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 11h:40m:11s remains)
INFO - root - 2017-12-16 23:22:15.962367: step 139650, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.229 sec/batch; 12h:15m:33s remains)
INFO - root - 2017-12-16 23:22:18.169940: step 139660, loss = 0.56, batch loss = 0.38 (37.1 examples/sec; 0.215 sec/batch; 11h:32m:35s remains)
INFO - root - 2017-12-16 23:22:20.359497: step 139670, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 11h:46m:57s remains)
INFO - root - 2017-12-16 23:22:22.572204: step 139680, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 11h:57m:22s remains)
INFO - root - 2017-12-16 23:22:24.771781: step 139690, loss = 0.47, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 11h:41m:09s remains)
INFO - root - 2017-12-16 23:22:26.992474: step 139700, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 11h:45m:47s remains)
INFO - root - 2017-12-16 23:22:29.300850: step 139710, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 11h:27m:53s remains)
INFO - root - 2017-12-16 23:22:31.499413: step 139720, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 11h:50m:49s remains)
INFO - root - 2017-12-16 23:22:33.675683: step 139730, loss = 0.48, batch loss = 0.31 (37.1 examples/sec; 0.215 sec/batch; 11h:31m:54s remains)
INFO - root - 2017-12-16 23:22:35.891875: step 139740, loss = 0.51, batch loss = 0.33 (37.7 examples/sec; 0.212 sec/batch; 11h:22m:21s remains)
INFO - root - 2017-12-16 23:22:38.144800: step 139750, loss = 0.47, batch loss = 0.30 (34.3 examples/sec; 0.233 sec/batch; 12h:28m:23s remains)
INFO - root - 2017-12-16 23:22:40.368893: step 139760, loss = 0.47, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 11h:41m:24s remains)
INFO - root - 2017-12-16 23:22:42.619575: step 139770, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 11h:56m:33s remains)
INFO - root - 2017-12-16 23:22:44.852772: step 139780, loss = 0.43, batch loss = 0.26 (35.0 examples/sec; 0.229 sec/batch; 12h:14m:20s remains)
INFO - root - 2017-12-16 23:22:47.093890: step 139790, loss = 0.55, batch loss = 0.38 (35.6 examples/sec; 0.224 sec/batch; 12h:00m:48s remains)
INFO - root - 2017-12-16 23:22:49.320504: step 139800, loss = 0.51, batch loss = 0.34 (35.0 examples/sec; 0.228 sec/batch; 12h:13m:42s remains)
INFO - root - 2017-12-16 23:22:51.715769: step 139810, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 12h:24m:10s remains)
INFO - root - 2017-12-16 23:22:53.933646: step 139820, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 11h:30m:32s remains)
INFO - root - 2017-12-16 23:22:56.132659: step 139830, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 11h:51m:57s remains)
INFO - root - 2017-12-16 23:22:58.369359: step 139840, loss = 0.50, batch loss = 0.32 (32.6 examples/sec; 0.245 sec/batch; 13h:07m:44s remains)
INFO - root - 2017-12-16 23:23:00.588323: step 139850, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 11h:31m:25s remains)
INFO - root - 2017-12-16 23:23:02.792281: step 139860, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 11h:49m:50s remains)
INFO - root - 2017-12-16 23:23:05.030162: step 139870, loss = 0.54, batch loss = 0.36 (34.9 examples/sec; 0.229 sec/batch; 12h:14m:53s remains)
INFO - root - 2017-12-16 23:23:07.208194: step 139880, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 11h:59m:01s remains)
INFO - root - 2017-12-16 23:23:09.439259: step 139890, loss = 0.50, batch loss = 0.33 (37.5 examples/sec; 0.214 sec/batch; 11h:25m:37s remains)
INFO - root - 2017-12-16 23:23:11.672912: step 139900, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 11h:36m:14s remains)
INFO - root - 2017-12-16 23:23:13.997305: step 139910, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 11h:50m:56s remains)
INFO - root - 2017-12-16 23:23:16.226143: step 139920, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 11h:45m:48s remains)
INFO - root - 2017-12-16 23:23:18.438049: step 139930, loss = 0.47, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 11h:48m:30s remains)
INFO - root - 2017-12-16 23:23:20.681938: step 139940, loss = 0.46, batch loss = 0.28 (33.3 examples/sec; 0.241 sec/batch; 12h:52m:03s remains)
INFO - root - 2017-12-16 23:23:22.892455: step 139950, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 11h:24m:52s remains)
INFO - root - 2017-12-16 23:23:25.122132: step 139960, loss = 0.56, batch loss = 0.38 (36.6 examples/sec; 0.219 sec/batch; 11h:41m:44s remains)
INFO - root - 2017-12-16 23:23:27.333871: step 139970, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 11h:36m:31s remains)
INFO - root - 2017-12-16 23:23:29.545886: step 139980, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 11h:43m:54s remains)
INFO - root - 2017-12-16 23:23:31.778047: step 139990, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 11h:53m:44s remains)
INFO - root - 2017-12-16 23:23:34.014594: step 140000, loss = 0.45, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 11h:51m:23s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-140000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-140000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 23:23:36.836169: step 140010, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.218 sec/batch; 11h:38m:20s remains)
INFO - root - 2017-12-16 23:23:39.045029: step 140020, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.214 sec/batch; 11h:25m:12s remains)
INFO - root - 2017-12-16 23:23:41.301034: step 140030, loss = 0.53, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 11h:43m:41s remains)
INFO - root - 2017-12-16 23:23:43.499810: step 140040, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 11h:39m:26s remains)
INFO - root - 2017-12-16 23:23:45.727458: step 140050, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 11h:42m:27s remains)
INFO - root - 2017-12-16 23:23:47.906701: step 140060, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 11h:39m:34s remains)
INFO - root - 2017-12-16 23:23:50.105134: step 140070, loss = 0.45, batch loss = 0.27 (33.5 examples/sec; 0.238 sec/batch; 12h:44m:50s remains)
INFO - root - 2017-12-16 23:23:52.329201: step 140080, loss = 0.51, batch loss = 0.34 (37.7 examples/sec; 0.212 sec/batch; 11h:21m:21s remains)
INFO - root - 2017-12-16 23:23:54.531881: step 140090, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 11h:40m:10s remains)
INFO - root - 2017-12-16 23:23:56.743343: step 140100, loss = 0.55, batch loss = 0.37 (37.4 examples/sec; 0.214 sec/batch; 11h:25m:33s remains)
INFO - root - 2017-12-16 23:23:59.099437: step 140110, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 11h:41m:58s remains)
INFO - root - 2017-12-16 23:24:01.321415: step 140120, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 11h:49m:14s remains)
INFO - root - 2017-12-16 23:24:03.540831: step 140130, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 11h:35m:46s remains)
INFO - root - 2017-12-16 23:24:05.788488: step 140140, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 11h:31m:43s remains)
INFO - root - 2017-12-16 23:24:07.989844: step 140150, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 11h:40m:51s remains)
INFO - root - 2017-12-16 23:24:10.181919: step 140160, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 11h:38m:48s remains)
INFO - root - 2017-12-16 23:24:12.386197: step 140170, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 11h:57m:40s remains)
INFO - root - 2017-12-16 23:24:14.600117: step 140180, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 12h:10m:10s remains)
INFO - root - 2017-12-16 23:24:16.819478: step 140190, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 11h:31m:38s remains)
INFO - root - 2017-12-16 23:24:19.003472: step 140200, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 11h:54m:08s remains)
INFO - root - 2017-12-16 23:24:21.355830: step 140210, loss = 0.61, batch loss = 0.43 (36.3 examples/sec; 0.220 sec/batch; 11h:45m:53s remains)
INFO - root - 2017-12-16 23:24:23.559283: step 140220, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 11h:52m:40s remains)
INFO - root - 2017-12-16 23:24:25.764094: step 140230, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 11h:35m:25s remains)
INFO - root - 2017-12-16 23:24:27.967025: step 140240, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 11h:25m:44s remains)
INFO - root - 2017-12-16 23:24:30.161173: step 140250, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 11h:34m:46s remains)
INFO - root - 2017-12-16 23:24:32.361341: step 140260, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:32m:17s remains)
INFO - root - 2017-12-16 23:24:34.564440: step 140270, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 11h:51m:55s remains)
INFO - root - 2017-12-16 23:24:36.769462: step 140280, loss = 0.56, batch loss = 0.38 (36.8 examples/sec; 0.217 sec/batch; 11h:36m:38s remains)
INFO - root - 2017-12-16 23:24:38.967036: step 140290, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 11h:37m:53s remains)
INFO - root - 2017-12-16 23:24:41.147787: step 140300, loss = 0.49, batch loss = 0.31 (37.8 examples/sec; 0.212 sec/batch; 11h:17m:40s remains)
INFO - root - 2017-12-16 23:24:43.474629: step 140310, loss = 0.49, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 11h:49m:16s remains)
INFO - root - 2017-12-16 23:24:45.714632: step 140320, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 12h:06m:36s remains)
INFO - root - 2017-12-16 23:24:47.917652: step 140330, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 11h:27m:47s remains)
INFO - root - 2017-12-16 23:24:50.156155: step 140340, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 11h:28m:21s remains)
INFO - root - 2017-12-16 23:24:52.372965: step 140350, loss = 0.58, batch loss = 0.40 (34.0 examples/sec; 0.235 sec/batch; 12h:33m:50s remains)
INFO - root - 2017-12-16 23:24:54.552424: step 140360, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 12h:05m:53s remains)
INFO - root - 2017-12-16 23:24:56.818647: step 140370, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 11h:36m:55s remains)
INFO - root - 2017-12-16 23:24:59.054486: step 140380, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 11h:55m:38s remains)
INFO - root - 2017-12-16 23:25:01.279488: step 140390, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 12h:22m:17s remains)
INFO - root - 2017-12-16 23:25:03.459229: step 140400, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 11h:31m:00s remains)
INFO - root - 2017-12-16 23:25:05.819488: step 140410, loss = 0.51, batch loss = 0.33 (34.9 examples/sec; 0.229 sec/batch; 12h:14m:10s remains)
INFO - root - 2017-12-16 23:25:08.038835: step 140420, loss = 0.53, batch loss = 0.35 (35.8 examples/sec; 0.223 sec/batch; 11h:55m:05s remains)
INFO - root - 2017-12-16 23:25:10.246292: step 140430, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 11h:26m:41s remains)
INFO - root - 2017-12-16 23:25:12.496919: step 140440, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 11h:32m:44s remains)
INFO - root - 2017-12-16 23:25:14.722066: step 140450, loss = 0.54, batch loss = 0.36 (35.5 examples/sec; 0.225 sec/batch; 12h:01m:31s remains)
INFO - root - 2017-12-16 23:25:16.934356: step 140460, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 11h:36m:32s remains)
INFO - root - 2017-12-16 23:25:19.142911: step 140470, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 11h:55m:07s remains)
INFO - root - 2017-12-16 23:25:21.334972: step 140480, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 12h:00m:09s remains)
INFO - root - 2017-12-16 23:25:23.559133: step 140490, loss = 0.47, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 12h:15m:57s remains)
INFO - root - 2017-12-16 23:25:25.793559: step 140500, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 11h:47m:03s remains)
INFO - root - 2017-12-16 23:25:28.125757: step 140510, loss = 0.52, batch loss = 0.34 (34.9 examples/sec; 0.229 sec/batch; 12h:13m:34s remains)
INFO - root - 2017-12-16 23:25:30.349404: step 140520, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 11h:57m:35s remains)
INFO - root - 2017-12-16 23:25:32.580684: step 140530, loss = 0.46, batch loss = 0.28 (34.4 examples/sec; 0.233 sec/batch; 12h:25m:01s remains)
INFO - root - 2017-12-16 23:25:34.787358: step 140540, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 11h:44m:18s remains)
INFO - root - 2017-12-16 23:25:36.998595: step 140550, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 11h:41m:48s remains)
INFO - root - 2017-12-16 23:25:39.226003: step 140560, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 11h:55m:21s remains)
INFO - root - 2017-12-16 23:25:41.472930: step 140570, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 12h:21m:20s remains)
INFO - root - 2017-12-16 23:25:43.710579: step 140580, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 11h:58m:20s remains)
INFO - root - 2017-12-16 23:25:45.904391: step 140590, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 11h:54m:41s remains)
INFO - root - 2017-12-16 23:25:48.124208: step 140600, loss = 0.45, batch loss = 0.27 (33.7 examples/sec; 0.237 sec/batch; 12h:38m:45s remains)
INFO - root - 2017-12-16 23:25:50.494595: step 140610, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 11h:55m:30s remains)
INFO - root - 2017-12-16 23:25:52.720101: step 140620, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 11h:44m:08s remains)
INFO - root - 2017-12-16 23:25:54.951733: step 140630, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 11h:51m:06s remains)
INFO - root - 2017-12-16 23:25:57.159778: step 140640, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 11h:35m:17s remains)
INFO - root - 2017-12-16 23:25:59.393234: step 140650, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 11h:39m:51s remains)
INFO - root - 2017-12-16 23:26:01.614545: step 140660, loss = 0.48, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 11h:39m:18s remains)
INFO - root - 2017-12-16 23:26:03.795809: step 140670, loss = 0.48, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 11h:41m:51s remains)
INFO - root - 2017-12-16 23:26:05.998099: step 140680, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 11h:35m:47s remains)
INFO - root - 2017-12-16 23:26:08.219018: step 140690, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 12h:04m:42s remains)
INFO - root - 2017-12-16 23:26:10.408504: step 140700, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 11h:30m:52s remains)
INFO - root - 2017-12-16 23:26:12.739411: step 140710, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 11h:43m:03s remains)
INFO - root - 2017-12-16 23:26:14.962878: step 140720, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 12h:11m:42s remains)
INFO - root - 2017-12-16 23:26:17.190402: step 140730, loss = 0.50, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 12h:12m:06s remains)
INFO - root - 2017-12-16 23:26:19.384005: step 140740, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 11h:33m:41s remains)
INFO - root - 2017-12-16 23:26:21.617277: step 140750, loss = 0.49, batch loss = 0.31 (37.9 examples/sec; 0.211 sec/batch; 11h:15m:13s remains)
INFO - root - 2017-12-16 23:26:23.841616: step 140760, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 11h:40m:15s remains)
INFO - root - 2017-12-16 23:26:26.079444: step 140770, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 11h:47m:08s remains)
INFO - root - 2017-12-16 23:26:28.330117: step 140780, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 11h:40m:22s remains)
INFO - root - 2017-12-16 23:26:30.555174: step 140790, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 11h:41m:21s remains)
INFO - root - 2017-12-16 23:26:32.762959: step 140800, loss = 0.48, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 11h:58m:45s remains)
INFO - root - 2017-12-16 23:26:35.077427: step 140810, loss = 0.50, batch loss = 0.32 (33.8 examples/sec; 0.237 sec/batch; 12h:36m:26s remains)
INFO - root - 2017-12-16 23:26:37.301867: step 140820, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 11h:34m:55s remains)
INFO - root - 2017-12-16 23:26:39.488087: step 140830, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.215 sec/batch; 11h:27m:59s remains)
INFO - root - 2017-12-16 23:26:41.689645: step 140840, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 11h:29m:57s remains)
INFO - root - 2017-12-16 23:26:43.939559: step 140850, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 11h:38m:18s remains)
INFO - root - 2017-12-16 23:26:46.144847: step 140860, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 11h:51m:19s remains)
INFO - root - 2017-12-16 23:26:48.370915: step 140870, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.223 sec/batch; 11h:52m:52s remains)
INFO - root - 2017-12-16 23:26:50.562361: step 140880, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 11h:49m:00s remains)
INFO - root - 2017-12-16 23:26:52.784645: step 140890, loss = 0.43, batch loss = 0.25 (35.1 examples/sec; 0.228 sec/batch; 12h:07m:01s remains)
INFO - root - 2017-12-16 23:26:54.991668: step 140900, loss = 0.46, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 12h:04m:04s remains)
INFO - root - 2017-12-16 23:26:57.318080: step 140910, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 11h:55m:59s remains)
INFO - root - 2017-12-16 23:26:59.557434: step 140920, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 12h:06m:57s remains)
INFO - root - 2017-12-16 23:27:01.776013: step 140930, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 11h:24m:35s remains)
INFO - root - 2017-12-16 23:27:03.963611: step 140940, loss = 0.51, batch loss = 0.33 (37.6 examples/sec; 0.213 sec/batch; 11h:18m:57s remains)
INFO - root - 2017-12-16 23:27:06.204218: step 140950, loss = 0.47, batch loss = 0.29 (33.8 examples/sec; 0.237 sec/batch; 12h:35m:04s remains)
INFO - root - 2017-12-16 23:27:08.391583: step 140960, loss = 0.44, batch loss = 0.26 (37.7 examples/sec; 0.212 sec/batch; 11h:17m:14s remains)
INFO - root - 2017-12-16 23:27:10.589844: step 140970, loss = 0.43, batch loss = 0.25 (37.0 examples/sec; 0.216 sec/batch; 11h:30m:31s remains)
INFO - root - 2017-12-16 23:27:12.808697: step 140980, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 11h:28m:51s remains)
INFO - root - 2017-12-16 23:27:15.026555: step 140990, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 11h:52m:53s remains)
INFO - root - 2017-12-16 23:27:17.228880: step 141000, loss = 0.49, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 11h:32m:03s remains)
INFO - root - 2017-12-16 23:27:19.533436: step 141010, loss = 0.43, batch loss = 0.25 (37.0 examples/sec; 0.216 sec/batch; 11h:30m:40s remains)
INFO - root - 2017-12-16 23:27:21.729921: step 141020, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 11h:28m:29s remains)
INFO - root - 2017-12-16 23:27:23.944520: step 141030, loss = 0.51, batch loss = 0.33 (35.2 examples/sec; 0.227 sec/batch; 12h:05m:11s remains)
INFO - root - 2017-12-16 23:27:26.126095: step 141040, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 11h:26m:35s remains)
INFO - root - 2017-12-16 23:27:28.306294: step 141050, loss = 0.54, batch loss = 0.36 (37.4 examples/sec; 0.214 sec/batch; 11h:22m:43s remains)
INFO - root - 2017-12-16 23:27:30.522378: step 141060, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 11h:29m:09s remains)
INFO - root - 2017-12-16 23:27:32.716902: step 141070, loss = 0.46, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 11h:46m:34s remains)
INFO - root - 2017-12-16 23:27:34.922068: step 141080, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 11h:36m:58s remains)
INFO - root - 2017-12-16 23:27:37.152896: step 141090, loss = 0.48, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 11h:32m:17s remains)
INFO - root - 2017-12-16 23:27:39.387948: step 141100, loss = 0.47, batch loss = 0.29 (34.4 examples/sec; 0.232 sec/batch; 12h:20m:55s remains)
INFO - root - 2017-12-16 23:27:41.739255: step 141110, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 11h:37m:05s remains)
INFO - root - 2017-12-16 23:27:43.967116: step 141120, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 11h:39m:32s remains)
INFO - root - 2017-12-16 23:27:46.161719: step 141130, loss = 0.50, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 11h:39m:25s remains)
INFO - root - 2017-12-16 23:27:48.369100: step 141140, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 11h:59m:54s remains)
INFO - root - 2017-12-16 23:27:50.561960: step 141150, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 12h:16m:37s remains)
INFO - root - 2017-12-16 23:27:52.768176: step 141160, loss = 0.45, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 12h:02m:01s remains)
INFO - root - 2017-12-16 23:27:54.997562: step 141170, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 11h:35m:37s remains)
INFO - root - 2017-12-16 23:27:57.205967: step 141180, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 12h:02m:19s remains)
INFO - root - 2017-12-16 23:27:59.430825: step 141190, loss = 0.49, batch loss = 0.32 (34.0 examples/sec; 0.235 sec/batch; 12h:30m:36s remains)
INFO - root - 2017-12-16 23:28:01.717297: step 141200, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 11h:52m:25s remains)
INFO - root - 2017-12-16 23:28:04.080063: step 141210, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 11h:35m:27s remains)
INFO - root - 2017-12-16 23:28:06.259677: step 141220, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 11h:43m:23s remains)
INFO - root - 2017-12-16 23:28:08.494775: step 141230, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:29m:26s remains)
INFO - root - 2017-12-16 23:28:10.702975: step 141240, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.224 sec/batch; 11h:55m:27s remains)
INFO - root - 2017-12-16 23:28:12.884291: step 141250, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 11h:41m:28s remains)
INFO - root - 2017-12-16 23:28:15.088077: step 141260, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.221 sec/batch; 11h:45m:31s remains)
INFO - root - 2017-12-16 23:28:17.296584: step 141270, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 11h:49m:44s remains)
INFO - root - 2017-12-16 23:28:19.519068: step 141280, loss = 0.44, batch loss = 0.27 (34.4 examples/sec; 0.232 sec/batch; 12h:20m:10s remains)
INFO - root - 2017-12-16 23:28:21.749857: step 141290, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 11h:33m:57s remains)
INFO - root - 2017-12-16 23:28:23.975562: step 141300, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:28m:49s remains)
INFO - root - 2017-12-16 23:28:26.299066: step 141310, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 11h:39m:49s remains)
INFO - root - 2017-12-16 23:28:28.497386: step 141320, loss = 0.47, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 11h:26m:53s remains)
INFO - root - 2017-12-16 23:28:30.731312: step 141330, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 11h:54m:26s remains)
INFO - root - 2017-12-16 23:28:32.949765: step 141340, loss = 0.44, batch loss = 0.26 (34.6 examples/sec; 0.231 sec/batch; 12h:17m:25s remains)
INFO - root - 2017-12-16 23:28:35.180544: step 141350, loss = 0.50, batch loss = 0.32 (34.7 examples/sec; 0.231 sec/batch; 12h:15m:17s remains)
INFO - root - 2017-12-16 23:28:37.417346: step 141360, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 11h:55m:37s remains)
INFO - root - 2017-12-16 23:28:39.637330: step 141370, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 11h:47m:53s remains)
INFO - root - 2017-12-16 23:28:41.840897: step 141380, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 11h:35m:06s remains)
INFO - root - 2017-12-16 23:28:44.067868: step 141390, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 12h:02m:58s remains)
INFO - root - 2017-12-16 23:28:46.291991: step 141400, loss = 0.43, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 11h:57m:03s remains)
INFO - root - 2017-12-16 23:28:48.664910: step 141410, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 11h:58m:07s remains)
INFO - root - 2017-12-16 23:28:50.857221: step 141420, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 11h:34m:38s remains)
INFO - root - 2017-12-16 23:28:53.078908: step 141430, loss = 0.42, batch loss = 0.24 (36.3 examples/sec; 0.220 sec/batch; 11h:40m:59s remains)
INFO - root - 2017-12-16 23:28:55.326315: step 141440, loss = 0.52, batch loss = 0.35 (35.0 examples/sec; 0.228 sec/batch; 12h:06m:49s remains)
INFO - root - 2017-12-16 23:28:57.558186: step 141450, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 11h:59m:05s remains)
INFO - root - 2017-12-16 23:28:59.770669: step 141460, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 11h:40m:51s remains)
INFO - root - 2017-12-16 23:29:02.005964: step 141470, loss = 0.50, batch loss = 0.32 (37.6 examples/sec; 0.213 sec/batch; 11h:17m:38s remains)
INFO - root - 2017-12-16 23:29:04.221589: step 141480, loss = 0.43, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 11h:57m:07s remains)
INFO - root - 2017-12-16 23:29:06.450937: step 141490, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 11h:57m:03s remains)
INFO - root - 2017-12-16 23:29:08.675753: step 141500, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 11h:36m:59s remains)
INFO - root - 2017-12-16 23:29:11.006044: step 141510, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 11h:39m:32s remains)
INFO - root - 2017-12-16 23:29:13.190456: step 141520, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 11h:29m:05s remains)
INFO - root - 2017-12-16 23:29:15.403374: step 141530, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 11h:42m:07s remains)
INFO - root - 2017-12-16 23:29:17.645193: step 141540, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 11h:42m:19s remains)
INFO - root - 2017-12-16 23:29:19.866791: step 141550, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.226 sec/batch; 12h:00m:42s remains)
INFO - root - 2017-12-16 23:29:22.086574: step 141560, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 11h:35m:14s remains)
INFO - root - 2017-12-16 23:29:24.280449: step 141570, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 11h:29m:53s remains)
INFO - root - 2017-12-16 23:29:26.461624: step 141580, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 11h:42m:24s remains)
INFO - root - 2017-12-16 23:29:28.701155: step 141590, loss = 0.42, batch loss = 0.24 (36.8 examples/sec; 0.217 sec/batch; 11h:31m:53s remains)
INFO - root - 2017-12-16 23:29:30.912794: step 141600, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 11h:55m:31s remains)
INFO - root - 2017-12-16 23:29:33.285324: step 141610, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.218 sec/batch; 11h:34m:32s remains)
INFO - root - 2017-12-16 23:29:35.515480: step 141620, loss = 0.50, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 12h:10m:56s remains)
INFO - root - 2017-12-16 23:29:37.702100: step 141630, loss = 0.51, batch loss = 0.33 (39.3 examples/sec; 0.204 sec/batch; 10h:48m:22s remains)
INFO - root - 2017-12-16 23:29:39.947731: step 141640, loss = 0.52, batch loss = 0.34 (34.2 examples/sec; 0.234 sec/batch; 12h:24m:29s remains)
INFO - root - 2017-12-16 23:29:42.172713: step 141650, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 11h:45m:46s remains)
INFO - root - 2017-12-16 23:29:44.371924: step 141660, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 11h:52m:38s remains)
INFO - root - 2017-12-16 23:29:46.630246: step 141670, loss = 0.55, batch loss = 0.37 (34.3 examples/sec; 0.233 sec/batch; 12h:22m:27s remains)
INFO - root - 2017-12-16 23:29:48.862694: step 141680, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 12h:04m:44s remains)
INFO - root - 2017-12-16 23:29:51.096152: step 141690, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 11h:44m:35s remains)
INFO - root - 2017-12-16 23:29:53.304931: step 141700, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 11h:58m:58s remains)
INFO - root - 2017-12-16 23:29:55.700954: step 141710, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 11h:35m:22s remains)
INFO - root - 2017-12-16 23:29:57.898789: step 141720, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 11h:40m:35s remains)
INFO - root - 2017-12-16 23:30:00.082170: step 141730, loss = 0.53, batch loss = 0.36 (35.3 examples/sec; 0.227 sec/batch; 12h:00m:11s remains)
INFO - root - 2017-12-16 23:30:02.308740: step 141740, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 12h:01m:06s remains)
INFO - root - 2017-12-16 23:30:04.511404: step 141750, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 11h:37m:55s remains)
INFO - root - 2017-12-16 23:30:06.736527: step 141760, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.215 sec/batch; 11h:24m:54s remains)
INFO - root - 2017-12-16 23:30:08.947756: step 141770, loss = 0.54, batch loss = 0.36 (37.4 examples/sec; 0.214 sec/batch; 11h:19m:17s remains)
INFO - root - 2017-12-16 23:30:11.177138: step 141780, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 11h:23m:19s remains)
INFO - root - 2017-12-16 23:30:13.397953: step 141790, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 11h:52m:57s remains)
INFO - root - 2017-12-16 23:30:15.607109: step 141800, loss = 0.55, batch loss = 0.37 (34.2 examples/sec; 0.234 sec/batch; 12h:24m:23s remains)
INFO - root - 2017-12-16 23:30:17.972297: step 141810, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 11h:44m:17s remains)
INFO - root - 2017-12-16 23:30:20.177557: step 141820, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 11h:50m:39s remains)
INFO - root - 2017-12-16 23:30:22.393322: step 141830, loss = 0.43, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 11h:33m:32s remains)
INFO - root - 2017-12-16 23:30:24.584990: step 141840, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 11h:57m:36s remains)
INFO - root - 2017-12-16 23:30:26.810602: step 141850, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 11h:27m:26s remains)
INFO - root - 2017-12-16 23:30:29.045605: step 141860, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 11h:48m:58s remains)
INFO - root - 2017-12-16 23:30:31.217047: step 141870, loss = 0.48, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 11h:33m:37s remains)
INFO - root - 2017-12-16 23:30:33.405436: step 141880, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 11h:34m:21s remains)
INFO - root - 2017-12-16 23:30:35.630327: step 141890, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 12h:07m:36s remains)
INFO - root - 2017-12-16 23:30:37.856530: step 141900, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 11h:56m:32s remains)
INFO - root - 2017-12-16 23:30:40.214526: step 141910, loss = 0.53, batch loss = 0.35 (34.5 examples/sec; 0.232 sec/batch; 12h:16m:14s remains)
INFO - root - 2017-12-16 23:30:42.449203: step 141920, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.216 sec/batch; 11h:25m:44s remains)
INFO - root - 2017-12-16 23:30:44.657315: step 141930, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 11h:43m:41s remains)
INFO - root - 2017-12-16 23:30:46.883001: step 141940, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 11h:45m:19s remains)
INFO - root - 2017-12-16 23:30:49.090850: step 141950, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 11h:25m:45s remains)
INFO - root - 2017-12-16 23:30:51.288200: step 141960, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 11h:34m:10s remains)
INFO - root - 2017-12-16 23:30:53.531961: step 141970, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 12h:00m:20s remains)
INFO - root - 2017-12-16 23:30:55.737434: step 141980, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 11h:23m:23s remains)
INFO - root - 2017-12-16 23:30:57.975902: step 141990, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 11h:38m:29s remains)
INFO - root - 2017-12-16 23:31:00.199704: step 142000, loss = 0.40, batch loss = 0.22 (36.6 examples/sec; 0.219 sec/batch; 11h:34m:43s remains)
INFO - root - 2017-12-16 23:31:02.546558: step 142010, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 11h:21m:51s remains)
INFO - root - 2017-12-16 23:31:04.774336: step 142020, loss = 0.44, batch loss = 0.26 (34.5 examples/sec; 0.232 sec/batch; 12h:15m:43s remains)
INFO - root - 2017-12-16 23:31:07.003023: step 142030, loss = 0.57, batch loss = 0.40 (36.2 examples/sec; 0.221 sec/batch; 11h:41m:09s remains)
INFO - root - 2017-12-16 23:31:09.233888: step 142040, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 12h:01m:23s remains)
INFO - root - 2017-12-16 23:31:11.439300: step 142050, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 11h:23m:39s remains)
INFO - root - 2017-12-16 23:31:13.666485: step 142060, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 11h:32m:18s remains)
INFO - root - 2017-12-16 23:31:15.874797: step 142070, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 11h:40m:21s remains)
INFO - root - 2017-12-16 23:31:18.088138: step 142080, loss = 0.46, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 11h:53m:40s remains)
INFO - root - 2017-12-16 23:31:20.269624: step 142090, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 11h:39m:05s remains)
INFO - root - 2017-12-16 23:31:22.488133: step 142100, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 11h:32m:13s remains)
INFO - root - 2017-12-16 23:31:24.854453: step 142110, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.224 sec/batch; 11h:52m:15s remains)
INFO - root - 2017-12-16 23:31:27.087962: step 142120, loss = 0.47, batch loss = 0.29 (34.0 examples/sec; 0.235 sec/batch; 12h:26m:06s remains)
INFO - root - 2017-12-16 23:31:29.318985: step 142130, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 11h:35m:52s remains)
INFO - root - 2017-12-16 23:31:31.521904: step 142140, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 11h:39m:20s remains)
INFO - root - 2017-12-16 23:31:33.712486: step 142150, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 11h:59m:45s remains)
INFO - root - 2017-12-16 23:31:35.940888: step 142160, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 11h:35m:19s remains)
INFO - root - 2017-12-16 23:31:38.149953: step 142170, loss = 0.46, batch loss = 0.28 (33.9 examples/sec; 0.236 sec/batch; 12h:28m:06s remains)
INFO - root - 2017-12-16 23:31:40.402915: step 142180, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 11h:37m:43s remains)
INFO - root - 2017-12-16 23:31:42.599507: step 142190, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 11h:56m:42s remains)
INFO - root - 2017-12-16 23:31:44.843705: step 142200, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.215 sec/batch; 11h:20m:55s remains)
INFO - root - 2017-12-16 23:31:47.218214: step 142210, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 11h:31m:36s remains)
INFO - root - 2017-12-16 23:31:49.458470: step 142220, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 11h:36m:41s remains)
INFO - root - 2017-12-16 23:31:51.651264: step 142230, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 11h:41m:45s remains)
INFO - root - 2017-12-16 23:31:53.887196: step 142240, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 11h:29m:18s remains)
INFO - root - 2017-12-16 23:31:56.130401: step 142250, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 11h:42m:37s remains)
INFO - root - 2017-12-16 23:31:58.385703: step 142260, loss = 0.44, batch loss = 0.26 (34.2 examples/sec; 0.234 sec/batch; 12h:21m:16s remains)
INFO - root - 2017-12-16 23:32:00.593579: step 142270, loss = 0.55, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 11h:37m:12s remains)
INFO - root - 2017-12-16 23:32:02.849649: step 142280, loss = 0.46, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 11h:46m:44s remains)
INFO - root - 2017-12-16 23:32:05.101513: step 142290, loss = 0.54, batch loss = 0.37 (35.7 examples/sec; 0.224 sec/batch; 11h:50m:09s remains)
INFO - root - 2017-12-16 23:32:07.323533: step 142300, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 11h:43m:45s remains)
INFO - root - 2017-12-16 23:32:09.661989: step 142310, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 11h:26m:03s remains)
INFO - root - 2017-12-16 23:32:11.859729: step 142320, loss = 0.45, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 11h:57m:08s remains)
INFO - root - 2017-12-16 23:32:14.102959: step 142330, loss = 0.49, batch loss = 0.32 (35.0 examples/sec; 0.228 sec/batch; 12h:03m:46s remains)
INFO - root - 2017-12-16 23:32:16.293799: step 142340, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 11h:46m:55s remains)
INFO - root - 2017-12-16 23:32:18.503666: step 142350, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 11h:35m:44s remains)
INFO - root - 2017-12-16 23:32:20.723163: step 142360, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.226 sec/batch; 11h:57m:36s remains)
INFO - root - 2017-12-16 23:32:22.911552: step 142370, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 11h:41m:10s remains)
INFO - root - 2017-12-16 23:32:25.127480: step 142380, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 11h:37m:20s remains)
INFO - root - 2017-12-16 23:32:27.348439: step 142390, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 11h:32m:53s remains)
INFO - root - 2017-12-16 23:32:29.569763: step 142400, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 11h:37m:33s remains)
INFO - root - 2017-12-16 23:32:31.914627: step 142410, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 11h:51m:54s remains)
INFO - root - 2017-12-16 23:32:34.130787: step 142420, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 11h:51m:56s remains)
INFO - root - 2017-12-16 23:32:36.349334: step 142430, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 11h:32m:04s remains)
INFO - root - 2017-12-16 23:32:38.539940: step 142440, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 11h:20m:20s remains)
INFO - root - 2017-12-16 23:32:40.744661: step 142450, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 11h:17m:38s remains)
INFO - root - 2017-12-16 23:32:42.905187: step 142460, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 11h:13m:58s remains)
INFO - root - 2017-12-16 23:32:45.089446: step 142470, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 11h:25m:27s remains)
INFO - root - 2017-12-16 23:32:47.345111: step 142480, loss = 0.53, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 11h:51m:47s remains)
INFO - root - 2017-12-16 23:32:49.546727: step 142490, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 11h:46m:02s remains)
INFO - root - 2017-12-16 23:32:51.710627: step 142500, loss = 0.54, batch loss = 0.37 (37.8 examples/sec; 0.212 sec/batch; 11h:10m:54s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-142500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-142500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 23:32:54.567673: step 142510, loss = 0.56, batch loss = 0.38 (36.0 examples/sec; 0.222 sec/batch; 11h:44m:32s remains)
INFO - root - 2017-12-16 23:32:56.759336: step 142520, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 11h:23m:51s remains)
INFO - root - 2017-12-16 23:32:58.940116: step 142530, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 11h:40m:13s remains)
INFO - root - 2017-12-16 23:33:01.144237: step 142540, loss = 0.54, batch loss = 0.36 (34.8 examples/sec; 0.230 sec/batch; 12h:07m:27s remains)
INFO - root - 2017-12-16 23:33:03.397012: step 142550, loss = 0.48, batch loss = 0.30 (33.6 examples/sec; 0.238 sec/batch; 12h:33m:32s remains)
INFO - root - 2017-12-16 23:33:05.633576: step 142560, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 11h:25m:36s remains)
INFO - root - 2017-12-16 23:33:07.925289: step 142570, loss = 0.50, batch loss = 0.32 (37.7 examples/sec; 0.212 sec/batch; 11h:12m:06s remains)
INFO - root - 2017-12-16 23:33:10.087176: step 142580, loss = 0.57, batch loss = 0.39 (36.7 examples/sec; 0.218 sec/batch; 11h:30m:12s remains)
INFO - root - 2017-12-16 23:33:12.264947: step 142590, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 11h:25m:27s remains)
INFO - root - 2017-12-16 23:33:14.471757: step 142600, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 11h:25m:23s remains)
INFO - root - 2017-12-16 23:33:16.794894: step 142610, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 11h:36m:03s remains)
INFO - root - 2017-12-16 23:33:18.975774: step 142620, loss = 0.57, batch loss = 0.39 (36.9 examples/sec; 0.217 sec/batch; 11h:25m:28s remains)
INFO - root - 2017-12-16 23:33:21.158348: step 142630, loss = 0.45, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 11h:16m:44s remains)
INFO - root - 2017-12-16 23:33:23.374237: step 142640, loss = 0.50, batch loss = 0.32 (34.2 examples/sec; 0.234 sec/batch; 12h:19m:22s remains)
INFO - root - 2017-12-16 23:33:25.618601: step 142650, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 11h:31m:37s remains)
INFO - root - 2017-12-16 23:33:27.792303: step 142660, loss = 0.43, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 11h:37m:36s remains)
INFO - root - 2017-12-16 23:33:30.025288: step 142670, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 11h:44m:39s remains)
INFO - root - 2017-12-16 23:33:32.206627: step 142680, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 11h:20m:29s remains)
INFO - root - 2017-12-16 23:33:34.443867: step 142690, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 11h:28m:11s remains)
INFO - root - 2017-12-16 23:33:36.651403: step 142700, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 11h:29m:51s remains)
INFO - root - 2017-12-16 23:33:38.963758: step 142710, loss = 0.57, batch loss = 0.39 (35.3 examples/sec; 0.227 sec/batch; 11h:56m:38s remains)
INFO - root - 2017-12-16 23:33:41.183629: step 142720, loss = 0.52, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 11h:29m:38s remains)
INFO - root - 2017-12-16 23:33:43.412763: step 142730, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 11h:42m:48s remains)
INFO - root - 2017-12-16 23:33:45.597312: step 142740, loss = 0.55, batch loss = 0.37 (36.8 examples/sec; 0.217 sec/batch; 11h:26m:41s remains)
INFO - root - 2017-12-16 23:33:47.800101: step 142750, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 11h:34m:28s remains)
INFO - root - 2017-12-16 23:33:50.019295: step 142760, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.221 sec/batch; 11h:37m:37s remains)
INFO - root - 2017-12-16 23:33:52.231868: step 142770, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 11h:46m:40s remains)
INFO - root - 2017-12-16 23:33:54.442962: step 142780, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 11h:33m:26s remains)
INFO - root - 2017-12-16 23:33:56.632932: step 142790, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 11h:20m:15s remains)
INFO - root - 2017-12-16 23:33:58.845256: step 142800, loss = 0.49, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 11h:23m:26s remains)
INFO - root - 2017-12-16 23:34:01.189780: step 142810, loss = 0.59, batch loss = 0.41 (34.6 examples/sec; 0.231 sec/batch; 12h:11m:36s remains)
INFO - root - 2017-12-16 23:34:03.413347: step 142820, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 11h:54m:28s remains)
INFO - root - 2017-12-16 23:34:05.621991: step 142830, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 11h:26m:14s remains)
INFO - root - 2017-12-16 23:34:07.850521: step 142840, loss = 0.43, batch loss = 0.25 (34.2 examples/sec; 0.234 sec/batch; 12h:19m:39s remains)
INFO - root - 2017-12-16 23:34:10.059106: step 142850, loss = 0.47, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 11h:35m:42s remains)
INFO - root - 2017-12-16 23:34:12.289680: step 142860, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 11h:40m:09s remains)
INFO - root - 2017-12-16 23:34:14.507034: step 142870, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 11h:42m:05s remains)
INFO - root - 2017-12-16 23:34:16.680073: step 142880, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 11h:40m:22s remains)
INFO - root - 2017-12-16 23:34:18.840071: step 142890, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 11h:28m:38s remains)
INFO - root - 2017-12-16 23:34:21.051983: step 142900, loss = 0.55, batch loss = 0.37 (36.1 examples/sec; 0.222 sec/batch; 11h:40m:28s remains)
INFO - root - 2017-12-16 23:34:23.459263: step 142910, loss = 0.62, batch loss = 0.44 (35.7 examples/sec; 0.224 sec/batch; 11h:48m:27s remains)
INFO - root - 2017-12-16 23:34:25.648390: step 142920, loss = 0.43, batch loss = 0.25 (37.3 examples/sec; 0.214 sec/batch; 11h:16m:47s remains)
INFO - root - 2017-12-16 23:34:27.824117: step 142930, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 11h:51m:15s remains)
INFO - root - 2017-12-16 23:34:30.010924: step 142940, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 11h:48m:12s remains)
INFO - root - 2017-12-16 23:34:32.228098: step 142950, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 11h:44m:00s remains)
INFO - root - 2017-12-16 23:34:34.444735: step 142960, loss = 0.46, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 11h:52m:56s remains)
INFO - root - 2017-12-16 23:34:36.642903: step 142970, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 11h:40m:51s remains)
INFO - root - 2017-12-16 23:34:38.867456: step 142980, loss = 0.50, batch loss = 0.32 (38.0 examples/sec; 0.211 sec/batch; 11h:05m:45s remains)
INFO - root - 2017-12-16 23:34:41.043555: step 142990, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 11h:32m:21s remains)
INFO - root - 2017-12-16 23:34:43.185910: step 143000, loss = 0.46, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 11h:17m:31s remains)
INFO - root - 2017-12-16 23:34:45.507221: step 143010, loss = 0.48, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 11h:36m:27s remains)
INFO - root - 2017-12-16 23:34:47.696295: step 143020, loss = 0.48, batch loss = 0.30 (37.8 examples/sec; 0.212 sec/batch; 11h:09m:05s remains)
INFO - root - 2017-12-16 23:34:49.912633: step 143030, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 11h:41m:15s remains)
INFO - root - 2017-12-16 23:34:52.088689: step 143040, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 11h:16m:18s remains)
INFO - root - 2017-12-16 23:34:54.297081: step 143050, loss = 0.44, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 11h:21m:10s remains)
INFO - root - 2017-12-16 23:34:56.493649: step 143060, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 11h:32m:31s remains)
INFO - root - 2017-12-16 23:34:58.713267: step 143070, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 11h:47m:42s remains)
INFO - root - 2017-12-16 23:35:00.919574: step 143080, loss = 0.44, batch loss = 0.27 (34.3 examples/sec; 0.233 sec/batch; 12h:15m:42s remains)
INFO - root - 2017-12-16 23:35:03.112239: step 143090, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 11h:29m:18s remains)
INFO - root - 2017-12-16 23:35:05.320335: step 143100, loss = 0.49, batch loss = 0.31 (34.1 examples/sec; 0.235 sec/batch; 12h:21m:34s remains)
INFO - root - 2017-12-16 23:35:07.639580: step 143110, loss = 0.45, batch loss = 0.27 (33.8 examples/sec; 0.237 sec/batch; 12h:27m:08s remains)
INFO - root - 2017-12-16 23:35:09.851547: step 143120, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 11h:34m:33s remains)
INFO - root - 2017-12-16 23:35:12.042436: step 143130, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 11h:31m:37s remains)
INFO - root - 2017-12-16 23:35:14.244779: step 143140, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 12h:03m:36s remains)
INFO - root - 2017-12-16 23:35:16.476114: step 143150, loss = 0.47, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 11h:49m:29s remains)
INFO - root - 2017-12-16 23:35:18.670291: step 143160, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 11h:18m:23s remains)
INFO - root - 2017-12-16 23:35:20.904469: step 143170, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 11h:15m:11s remains)
INFO - root - 2017-12-16 23:35:23.088141: step 143180, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 11h:49m:11s remains)
INFO - root - 2017-12-16 23:35:25.275629: step 143190, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 11h:28m:02s remains)
INFO - root - 2017-12-16 23:35:27.482377: step 143200, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.224 sec/batch; 11h:48m:00s remains)
INFO - root - 2017-12-16 23:35:29.793182: step 143210, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 11h:10m:40s remains)
INFO - root - 2017-12-16 23:35:32.015961: step 143220, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 11h:13m:17s remains)
INFO - root - 2017-12-16 23:35:34.220826: step 143230, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 11h:17m:02s remains)
INFO - root - 2017-12-16 23:35:36.458681: step 143240, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 11h:38m:30s remains)
INFO - root - 2017-12-16 23:35:38.686913: step 143250, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 11h:26m:01s remains)
INFO - root - 2017-12-16 23:35:40.874560: step 143260, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 11h:21m:30s remains)
INFO - root - 2017-12-16 23:35:43.089375: step 143270, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 11h:27m:44s remains)
INFO - root - 2017-12-16 23:35:45.289826: step 143280, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 11h:27m:31s remains)
INFO - root - 2017-12-16 23:35:47.515646: step 143290, loss = 0.51, batch loss = 0.33 (34.9 examples/sec; 0.229 sec/batch; 12h:03m:03s remains)
INFO - root - 2017-12-16 23:35:49.706116: step 143300, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 11h:29m:40s remains)
INFO - root - 2017-12-16 23:35:52.043146: step 143310, loss = 0.57, batch loss = 0.39 (36.4 examples/sec; 0.220 sec/batch; 11h:32m:23s remains)
INFO - root - 2017-12-16 23:35:54.279248: step 143320, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 11h:22m:01s remains)
INFO - root - 2017-12-16 23:35:56.494015: step 143330, loss = 0.50, batch loss = 0.32 (34.2 examples/sec; 0.234 sec/batch; 12h:17m:20s remains)
INFO - root - 2017-12-16 23:35:58.683182: step 143340, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:21m:54s remains)
INFO - root - 2017-12-16 23:36:00.893202: step 143350, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 11h:50m:37s remains)
INFO - root - 2017-12-16 23:36:03.113223: step 143360, loss = 0.54, batch loss = 0.36 (36.0 examples/sec; 0.222 sec/batch; 11h:41m:22s remains)
INFO - root - 2017-12-16 23:36:05.316183: step 143370, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 11h:40m:57s remains)
INFO - root - 2017-12-16 23:36:07.558151: step 143380, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 11h:45m:57s remains)
INFO - root - 2017-12-16 23:36:09.790074: step 143390, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 11h:35m:31s remains)
INFO - root - 2017-12-16 23:36:12.002496: step 143400, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 11h:42m:30s remains)
INFO - root - 2017-12-16 23:36:14.336219: step 143410, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 11h:26m:12s remains)
INFO - root - 2017-12-16 23:36:16.566597: step 143420, loss = 0.45, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 11h:07m:28s remains)
INFO - root - 2017-12-16 23:36:18.766382: step 143430, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.224 sec/batch; 11h:44m:30s remains)
INFO - root - 2017-12-16 23:36:20.984436: step 143440, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 11h:45m:06s remains)
INFO - root - 2017-12-16 23:36:23.193965: step 143450, loss = 0.47, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 11h:25m:28s remains)
INFO - root - 2017-12-16 23:36:25.418084: step 143460, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 11h:27m:58s remains)
INFO - root - 2017-12-16 23:36:27.636108: step 143470, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 11h:15m:48s remains)
INFO - root - 2017-12-16 23:36:29.842296: step 143480, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.215 sec/batch; 11h:18m:39s remains)
INFO - root - 2017-12-16 23:36:32.072324: step 143490, loss = 0.45, batch loss = 0.27 (37.8 examples/sec; 0.211 sec/batch; 11h:06m:12s remains)
INFO - root - 2017-12-16 23:36:34.270093: step 143500, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 11h:22m:29s remains)
INFO - root - 2017-12-16 23:36:36.618344: step 143510, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 11h:39m:59s remains)
INFO - root - 2017-12-16 23:36:38.842693: step 143520, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 11h:27m:54s remains)
INFO - root - 2017-12-16 23:36:41.042945: step 143530, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.211 sec/batch; 11h:06m:06s remains)
INFO - root - 2017-12-16 23:36:43.273733: step 143540, loss = 0.43, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 11h:53m:52s remains)
INFO - root - 2017-12-16 23:36:45.500658: step 143550, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 11h:26m:01s remains)
INFO - root - 2017-12-16 23:36:47.757110: step 143560, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 11h:31m:58s remains)
INFO - root - 2017-12-16 23:36:49.946317: step 143570, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 11h:19m:37s remains)
INFO - root - 2017-12-16 23:36:52.161659: step 143580, loss = 0.42, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 11h:38m:03s remains)
INFO - root - 2017-12-16 23:36:54.360572: step 143590, loss = 0.54, batch loss = 0.36 (36.4 examples/sec; 0.220 sec/batch; 11h:32m:55s remains)
INFO - root - 2017-12-16 23:36:56.589801: step 143600, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 11h:36m:50s remains)
INFO - root - 2017-12-16 23:36:58.899387: step 143610, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 11h:16m:23s remains)
INFO - root - 2017-12-16 23:37:01.090532: step 143620, loss = 0.47, batch loss = 0.29 (38.0 examples/sec; 0.210 sec/batch; 11h:02m:24s remains)
INFO - root - 2017-12-16 23:37:03.289360: step 143630, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 11h:20m:36s remains)
INFO - root - 2017-12-16 23:37:05.484104: step 143640, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 11h:25m:16s remains)
INFO - root - 2017-12-16 23:37:07.726723: step 143650, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.226 sec/batch; 11h:49m:49s remains)
INFO - root - 2017-12-16 23:37:09.975359: step 143660, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 11h:30m:25s remains)
INFO - root - 2017-12-16 23:37:12.177358: step 143670, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 12h:02m:15s remains)
INFO - root - 2017-12-16 23:37:14.402272: step 143680, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 11h:42m:38s remains)
INFO - root - 2017-12-16 23:37:16.612973: step 143690, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 11h:34m:59s remains)
INFO - root - 2017-12-16 23:37:18.819915: step 143700, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 11h:47m:50s remains)
INFO - root - 2017-12-16 23:37:21.152876: step 143710, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 11h:14m:24s remains)
INFO - root - 2017-12-16 23:37:23.385879: step 143720, loss = 0.46, batch loss = 0.28 (33.5 examples/sec; 0.239 sec/batch; 12h:30m:55s remains)
INFO - root - 2017-12-16 23:37:25.638420: step 143730, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 11h:16m:26s remains)
INFO - root - 2017-12-16 23:37:27.839634: step 143740, loss = 0.48, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 11h:27m:53s remains)
INFO - root - 2017-12-16 23:37:30.060899: step 143750, loss = 0.54, batch loss = 0.36 (36.2 examples/sec; 0.221 sec/batch; 11h:35m:40s remains)
INFO - root - 2017-12-16 23:37:32.323456: step 143760, loss = 0.57, batch loss = 0.39 (37.4 examples/sec; 0.214 sec/batch; 11h:13m:06s remains)
INFO - root - 2017-12-16 23:37:34.514496: step 143770, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 11h:14m:52s remains)
INFO - root - 2017-12-16 23:37:36.724574: step 143780, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 11h:27m:29s remains)
INFO - root - 2017-12-16 23:37:38.940476: step 143790, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 11h:42m:29s remains)
INFO - root - 2017-12-16 23:37:41.173023: step 143800, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 11h:47m:44s remains)
INFO - root - 2017-12-16 23:37:43.499319: step 143810, loss = 0.50, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 11h:22m:00s remains)
INFO - root - 2017-12-16 23:37:45.696274: step 143820, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 11h:31m:34s remains)
INFO - root - 2017-12-16 23:37:47.899317: step 143830, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.230 sec/batch; 12h:01m:40s remains)
INFO - root - 2017-12-16 23:37:50.145371: step 143840, loss = 0.49, batch loss = 0.31 (34.4 examples/sec; 0.232 sec/batch; 12h:11m:00s remains)
INFO - root - 2017-12-16 23:37:52.359560: step 143850, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 11h:22m:26s remains)
INFO - root - 2017-12-16 23:37:54.560394: step 143860, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 11h:12m:20s remains)
INFO - root - 2017-12-16 23:37:56.787771: step 143870, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 11h:40m:28s remains)
INFO - root - 2017-12-16 23:37:58.989740: step 143880, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 11h:19m:14s remains)
INFO - root - 2017-12-16 23:38:01.220549: step 143890, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 11h:40m:00s remains)
INFO - root - 2017-12-16 23:38:03.431238: step 143900, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 11h:35m:19s remains)
INFO - root - 2017-12-16 23:38:05.785694: step 143910, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 11h:28m:56s remains)
INFO - root - 2017-12-16 23:38:08.001822: step 143920, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 11h:33m:46s remains)
INFO - root - 2017-12-16 23:38:10.193452: step 143930, loss = 0.49, batch loss = 0.31 (33.1 examples/sec; 0.242 sec/batch; 12h:39m:13s remains)
INFO - root - 2017-12-16 23:38:12.401580: step 143940, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 11h:40m:40s remains)
INFO - root - 2017-12-16 23:38:14.628099: step 143950, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 11h:54m:12s remains)
INFO - root - 2017-12-16 23:38:16.831763: step 143960, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 11h:15m:05s remains)
INFO - root - 2017-12-16 23:38:19.027738: step 143970, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 11h:17m:36s remains)
INFO - root - 2017-12-16 23:38:21.228091: step 143980, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 11h:18m:40s remains)
INFO - root - 2017-12-16 23:38:23.460296: step 143990, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 11h:10m:19s remains)
INFO - root - 2017-12-16 23:38:25.652448: step 144000, loss = 0.46, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 11h:31m:55s remains)
INFO - root - 2017-12-16 23:38:27.978441: step 144010, loss = 0.50, batch loss = 0.32 (37.7 examples/sec; 0.212 sec/batch; 11h:06m:01s remains)
INFO - root - 2017-12-16 23:38:30.181550: step 144020, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.219 sec/batch; 11h:27m:25s remains)
INFO - root - 2017-12-16 23:38:32.352983: step 144030, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 11h:46m:05s remains)
INFO - root - 2017-12-16 23:38:34.550946: step 144040, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 11h:24m:29s remains)
INFO - root - 2017-12-16 23:38:36.764707: step 144050, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 11h:52m:24s remains)
INFO - root - 2017-12-16 23:38:38.962104: step 144060, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 11h:38m:42s remains)
INFO - root - 2017-12-16 23:38:41.193185: step 144070, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 11h:20m:41s remains)
INFO - root - 2017-12-16 23:38:43.410089: step 144080, loss = 0.46, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 11h:12m:59s remains)
INFO - root - 2017-12-16 23:38:45.606015: step 144090, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 12h:01m:25s remains)
INFO - root - 2017-12-16 23:38:47.802576: step 144100, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 11h:26m:46s remains)
INFO - root - 2017-12-16 23:38:50.191003: step 144110, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 11h:31m:30s remains)
INFO - root - 2017-12-16 23:38:52.375536: step 144120, loss = 0.45, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 11h:21m:43s remains)
INFO - root - 2017-12-16 23:38:54.599951: step 144130, loss = 0.52, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 11h:36m:12s remains)
INFO - root - 2017-12-16 23:38:56.828590: step 144140, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 11h:08m:30s remains)
INFO - root - 2017-12-16 23:38:59.043314: step 144150, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 11h:15m:01s remains)
INFO - root - 2017-12-16 23:39:01.254881: step 144160, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 11h:24m:27s remains)
INFO - root - 2017-12-16 23:39:03.442143: step 144170, loss = 0.47, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 11h:22m:52s remains)
INFO - root - 2017-12-16 23:39:05.674565: step 144180, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 11h:26m:25s remains)
INFO - root - 2017-12-16 23:39:07.878046: step 144190, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 11h:36m:51s remains)
INFO - root - 2017-12-16 23:39:10.082941: step 144200, loss = 0.41, batch loss = 0.24 (35.5 examples/sec; 0.226 sec/batch; 11h:47m:44s remains)
INFO - root - 2017-12-16 23:39:12.428174: step 144210, loss = 0.60, batch loss = 0.42 (36.0 examples/sec; 0.222 sec/batch; 11h:37m:03s remains)
INFO - root - 2017-12-16 23:39:14.666760: step 144220, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 11h:43m:54s remains)
INFO - root - 2017-12-16 23:39:16.869349: step 144230, loss = 0.45, batch loss = 0.28 (37.7 examples/sec; 0.212 sec/batch; 11h:05m:07s remains)
INFO - root - 2017-12-16 23:39:19.080059: step 144240, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 11h:48m:06s remains)
INFO - root - 2017-12-16 23:39:21.278248: step 144250, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 11h:07m:08s remains)
INFO - root - 2017-12-16 23:39:23.534780: step 144260, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 11h:35m:36s remains)
INFO - root - 2017-12-16 23:39:25.756660: step 144270, loss = 0.50, batch loss = 0.32 (35.0 examples/sec; 0.228 sec/batch; 11h:56m:27s remains)
INFO - root - 2017-12-16 23:39:27.982375: step 144280, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 11h:18m:41s remains)
INFO - root - 2017-12-16 23:39:30.205686: step 144290, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 11h:36m:00s remains)
INFO - root - 2017-12-16 23:39:32.412884: step 144300, loss = 0.57, batch loss = 0.39 (36.5 examples/sec; 0.219 sec/batch; 11h:26m:46s remains)
INFO - root - 2017-12-16 23:39:34.765753: step 144310, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 11h:54m:52s remains)
INFO - root - 2017-12-16 23:39:37.008524: step 144320, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:18m:51s remains)
INFO - root - 2017-12-16 23:39:39.214317: step 144330, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 11h:26m:01s remains)
INFO - root - 2017-12-16 23:39:41.425891: step 144340, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.215 sec/batch; 11h:13m:05s remains)
INFO - root - 2017-12-16 23:39:43.640297: step 144350, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 11h:23m:35s remains)
INFO - root - 2017-12-16 23:39:45.862373: step 144360, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 11h:32m:43s remains)
INFO - root - 2017-12-16 23:39:48.067691: step 144370, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.229 sec/batch; 11h:56m:58s remains)
INFO - root - 2017-12-16 23:39:50.276885: step 144380, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 11h:27m:51s remains)
INFO - root - 2017-12-16 23:39:52.484013: step 144390, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 11h:26m:37s remains)
INFO - root - 2017-12-16 23:39:54.705340: step 144400, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 11h:22m:50s remains)
INFO - root - 2017-12-16 23:39:57.050011: step 144410, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 11h:34m:43s remains)
INFO - root - 2017-12-16 23:39:59.268626: step 144420, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 11h:19m:13s remains)
INFO - root - 2017-12-16 23:40:01.475912: step 144430, loss = 0.61, batch loss = 0.43 (36.6 examples/sec; 0.219 sec/batch; 11h:25m:59s remains)
INFO - root - 2017-12-16 23:40:03.705852: step 144440, loss = 0.42, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 11h:43m:12s remains)
INFO - root - 2017-12-16 23:40:05.929162: step 144450, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 11h:10m:25s remains)
INFO - root - 2017-12-16 23:40:08.145950: step 144460, loss = 0.47, batch loss = 0.29 (34.6 examples/sec; 0.231 sec/batch; 12h:04m:10s remains)
INFO - root - 2017-12-16 23:40:10.359838: step 144470, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 11h:26m:11s remains)
INFO - root - 2017-12-16 23:40:12.586291: step 144480, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 11h:13m:11s remains)
INFO - root - 2017-12-16 23:40:14.781427: step 144490, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 11h:21m:34s remains)
INFO - root - 2017-12-16 23:40:16.981523: step 144500, loss = 0.50, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 11h:30m:32s remains)
INFO - root - 2017-12-16 23:40:19.305482: step 144510, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 11h:34m:07s remains)
INFO - root - 2017-12-16 23:40:21.513701: step 144520, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 11h:34m:04s remains)
INFO - root - 2017-12-16 23:40:23.762012: step 144530, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 11h:39m:41s remains)
INFO - root - 2017-12-16 23:40:25.990181: step 144540, loss = 0.51, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 12h:00m:57s remains)
INFO - root - 2017-12-16 23:40:28.209508: step 144550, loss = 0.56, batch loss = 0.38 (34.3 examples/sec; 0.233 sec/batch; 12h:09m:56s remains)
INFO - root - 2017-12-16 23:40:30.417474: step 144560, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 11h:26m:25s remains)
INFO - root - 2017-12-16 23:40:32.620887: step 144570, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 11h:09m:22s remains)
INFO - root - 2017-12-16 23:40:34.832432: step 144580, loss = 0.48, batch loss = 0.30 (34.2 examples/sec; 0.234 sec/batch; 12h:12m:26s remains)
INFO - root - 2017-12-16 23:40:37.090455: step 144590, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 11h:21m:37s remains)
INFO - root - 2017-12-16 23:40:39.359057: step 144600, loss = 0.52, batch loss = 0.34 (34.7 examples/sec; 0.231 sec/batch; 12h:02m:02s remains)
INFO - root - 2017-12-16 23:40:41.707072: step 144610, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 11h:29m:55s remains)
INFO - root - 2017-12-16 23:40:43.911869: step 144620, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 11h:18m:19s remains)
INFO - root - 2017-12-16 23:40:46.131052: step 144630, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 11h:53m:31s remains)
INFO - root - 2017-12-16 23:40:48.395971: step 144640, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 11h:52m:55s remains)
INFO - root - 2017-12-16 23:40:50.607444: step 144650, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 11h:30m:41s remains)
INFO - root - 2017-12-16 23:40:52.835226: step 144660, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 11h:34m:50s remains)
INFO - root - 2017-12-16 23:40:55.046467: step 144670, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 11h:34m:11s remains)
INFO - root - 2017-12-16 23:40:57.295698: step 144680, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 11h:37m:35s remains)
INFO - root - 2017-12-16 23:40:59.529133: step 144690, loss = 0.52, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 11h:28m:20s remains)
INFO - root - 2017-12-16 23:41:01.784593: step 144700, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.233 sec/batch; 12h:08m:43s remains)
INFO - root - 2017-12-16 23:41:04.106177: step 144710, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 11h:30m:52s remains)
INFO - root - 2017-12-16 23:41:06.269780: step 144720, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 11h:25m:16s remains)
INFO - root - 2017-12-16 23:41:08.492771: step 144730, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 11h:09m:25s remains)
INFO - root - 2017-12-16 23:41:10.711506: step 144740, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 11h:49m:00s remains)
INFO - root - 2017-12-16 23:41:12.954971: step 144750, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 11h:17m:02s remains)
INFO - root - 2017-12-16 23:41:15.194102: step 144760, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 11h:18m:51s remains)
INFO - root - 2017-12-16 23:41:17.404764: step 144770, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 11h:18m:48s remains)
INFO - root - 2017-12-16 23:41:19.628946: step 144780, loss = 0.44, batch loss = 0.26 (37.7 examples/sec; 0.212 sec/batch; 11h:03m:13s remains)
INFO - root - 2017-12-16 23:41:21.842563: step 144790, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 11h:19m:58s remains)
INFO - root - 2017-12-16 23:41:24.077672: step 144800, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 12h:04m:54s remains)
INFO - root - 2017-12-16 23:41:26.420158: step 144810, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 11h:19m:16s remains)
INFO - root - 2017-12-16 23:41:28.603722: step 144820, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 11h:12m:39s remains)
INFO - root - 2017-12-16 23:41:30.824065: step 144830, loss = 0.42, batch loss = 0.24 (35.0 examples/sec; 0.229 sec/batch; 11h:55m:26s remains)
INFO - root - 2017-12-16 23:41:33.021523: step 144840, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 11h:23m:23s remains)
INFO - root - 2017-12-16 23:41:35.290327: step 144850, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 11h:55m:46s remains)
INFO - root - 2017-12-16 23:41:37.522769: step 144860, loss = 0.44, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 11h:47m:02s remains)
INFO - root - 2017-12-16 23:41:39.751262: step 144870, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 11h:45m:34s remains)
INFO - root - 2017-12-16 23:41:41.969375: step 144880, loss = 0.48, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 11h:40m:06s remains)
INFO - root - 2017-12-16 23:41:44.178164: step 144890, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 11h:13m:44s remains)
INFO - root - 2017-12-16 23:41:46.439642: step 144900, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 11h:32m:44s remains)
INFO - root - 2017-12-16 23:41:48.742888: step 144910, loss = 0.50, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 11h:25m:09s remains)
INFO - root - 2017-12-16 23:41:50.978335: step 144920, loss = 0.46, batch loss = 0.28 (33.7 examples/sec; 0.237 sec/batch; 12h:21m:04s remains)
INFO - root - 2017-12-16 23:41:53.151635: step 144930, loss = 0.44, batch loss = 0.26 (37.9 examples/sec; 0.211 sec/batch; 11h:00m:31s remains)
INFO - root - 2017-12-16 23:41:55.372211: step 144940, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 11h:23m:01s remains)
INFO - root - 2017-12-16 23:41:57.622565: step 144950, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 11h:20m:58s remains)
INFO - root - 2017-12-16 23:41:59.819829: step 144960, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 11h:24m:37s remains)
INFO - root - 2017-12-16 23:42:02.034413: step 144970, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 11h:29m:38s remains)
INFO - root - 2017-12-16 23:42:04.261343: step 144980, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 11h:22m:36s remains)
INFO - root - 2017-12-16 23:42:06.475507: step 144990, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 11h:20m:22s remains)
INFO - root - 2017-12-16 23:42:08.700965: step 145000, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 11h:30m:09s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-145000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-145000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 23:42:11.709818: step 145010, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 12h:02m:35s remains)
INFO - root - 2017-12-16 23:42:13.951514: step 145020, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 11h:23m:19s remains)
INFO - root - 2017-12-16 23:42:16.154791: step 145030, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 11h:19m:12s remains)
INFO - root - 2017-12-16 23:42:18.391167: step 145040, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.231 sec/batch; 12h:00m:36s remains)
INFO - root - 2017-12-16 23:42:20.593607: step 145050, loss = 0.43, batch loss = 0.25 (37.7 examples/sec; 0.212 sec/batch; 11h:02m:55s remains)
INFO - root - 2017-12-16 23:42:22.824157: step 145060, loss = 0.47, batch loss = 0.29 (34.3 examples/sec; 0.233 sec/batch; 12h:08m:29s remains)
INFO - root - 2017-12-16 23:42:25.038798: step 145070, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 11h:43m:05s remains)
INFO - root - 2017-12-16 23:42:27.233150: step 145080, loss = 0.53, batch loss = 0.35 (37.4 examples/sec; 0.214 sec/batch; 11h:08m:28s remains)
INFO - root - 2017-12-16 23:42:29.440101: step 145090, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 11h:14m:49s remains)
INFO - root - 2017-12-16 23:42:31.662880: step 145100, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 11h:09m:24s remains)
INFO - root - 2017-12-16 23:42:33.998990: step 145110, loss = 0.50, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 11h:16m:27s remains)
INFO - root - 2017-12-16 23:42:36.234643: step 145120, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 11h:37m:01s remains)
INFO - root - 2017-12-16 23:42:38.464372: step 145130, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 11h:34m:08s remains)
INFO - root - 2017-12-16 23:42:40.658249: step 145140, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 11h:23m:21s remains)
INFO - root - 2017-12-16 23:42:42.863402: step 145150, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 11h:18m:31s remains)
INFO - root - 2017-12-16 23:42:45.069514: step 145160, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 11h:23m:46s remains)
INFO - root - 2017-12-16 23:42:47.314331: step 145170, loss = 0.42, batch loss = 0.24 (37.3 examples/sec; 0.215 sec/batch; 11h:09m:58s remains)
INFO - root - 2017-12-16 23:42:49.525829: step 145180, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 11h:12m:04s remains)
INFO - root - 2017-12-16 23:42:51.724650: step 145190, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 11h:41m:37s remains)
INFO - root - 2017-12-16 23:42:53.931885: step 145200, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 11h:13m:27s remains)
INFO - root - 2017-12-16 23:42:56.279405: step 145210, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 11h:40m:06s remains)
INFO - root - 2017-12-16 23:42:58.492236: step 145220, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 11h:34m:56s remains)
INFO - root - 2017-12-16 23:43:00.698269: step 145230, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 11h:20m:21s remains)
INFO - root - 2017-12-16 23:43:02.896413: step 145240, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 11h:15m:59s remains)
INFO - root - 2017-12-16 23:43:05.121292: step 145250, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 11h:29m:12s remains)
INFO - root - 2017-12-16 23:43:07.305030: step 145260, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 11h:42m:15s remains)
INFO - root - 2017-12-16 23:43:09.502787: step 145270, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 11h:45m:16s remains)
INFO - root - 2017-12-16 23:43:11.714229: step 145280, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 11h:19m:20s remains)
INFO - root - 2017-12-16 23:43:13.946747: step 145290, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 11h:17m:05s remains)
INFO - root - 2017-12-16 23:43:16.160250: step 145300, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 11h:20m:56s remains)
INFO - root - 2017-12-16 23:43:18.466379: step 145310, loss = 0.45, batch loss = 0.27 (37.6 examples/sec; 0.213 sec/batch; 11h:03m:00s remains)
INFO - root - 2017-12-16 23:43:20.653428: step 145320, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 11h:34m:51s remains)
INFO - root - 2017-12-16 23:43:22.888809: step 145330, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 11h:30m:04s remains)
INFO - root - 2017-12-16 23:43:25.129199: step 145340, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 11h:20m:17s remains)
INFO - root - 2017-12-16 23:43:27.336405: step 145350, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 11h:15m:59s remains)
INFO - root - 2017-12-16 23:43:29.521915: step 145360, loss = 0.44, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 11h:23m:21s remains)
INFO - root - 2017-12-16 23:43:31.709939: step 145370, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 11h:16m:38s remains)
INFO - root - 2017-12-16 23:43:33.927712: step 145380, loss = 0.47, batch loss = 0.29 (38.0 examples/sec; 0.211 sec/batch; 10h:56m:42s remains)
INFO - root - 2017-12-16 23:43:36.149722: step 145390, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 11h:45m:35s remains)
INFO - root - 2017-12-16 23:43:38.405561: step 145400, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 11h:37m:16s remains)
INFO - root - 2017-12-16 23:43:40.734453: step 145410, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 11h:31m:58s remains)
INFO - root - 2017-12-16 23:43:42.969000: step 145420, loss = 0.47, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 11h:30m:29s remains)
INFO - root - 2017-12-16 23:43:45.191700: step 145430, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 11h:50m:39s remains)
INFO - root - 2017-12-16 23:43:47.401077: step 145440, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 11h:41m:24s remains)
INFO - root - 2017-12-16 23:43:49.597008: step 145450, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 11h:29m:39s remains)
INFO - root - 2017-12-16 23:43:51.836496: step 145460, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 11h:31m:58s remains)
INFO - root - 2017-12-16 23:43:54.061599: step 145470, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 11h:17m:56s remains)
INFO - root - 2017-12-16 23:43:56.292850: step 145480, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:13m:57s remains)
INFO - root - 2017-12-16 23:43:58.501296: step 145490, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 11h:07m:20s remains)
INFO - root - 2017-12-16 23:44:00.750523: step 145500, loss = 0.44, batch loss = 0.26 (35.0 examples/sec; 0.228 sec/batch; 11h:51m:27s remains)
INFO - root - 2017-12-16 23:44:03.076763: step 145510, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 11h:21m:23s remains)
INFO - root - 2017-12-16 23:44:05.301456: step 145520, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 11h:31m:09s remains)
INFO - root - 2017-12-16 23:44:07.516918: step 145530, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 11h:33m:11s remains)
INFO - root - 2017-12-16 23:44:09.723355: step 145540, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 11h:11m:37s remains)
INFO - root - 2017-12-16 23:44:11.944929: step 145550, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 11h:18m:16s remains)
INFO - root - 2017-12-16 23:44:14.119482: step 145560, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 11h:12m:24s remains)
INFO - root - 2017-12-16 23:44:16.303663: step 145570, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 11h:37m:28s remains)
INFO - root - 2017-12-16 23:44:18.524425: step 145580, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 11h:56m:42s remains)
INFO - root - 2017-12-16 23:44:20.723233: step 145590, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 11h:20m:32s remains)
INFO - root - 2017-12-16 23:44:22.929024: step 145600, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 12h:02m:52s remains)
INFO - root - 2017-12-16 23:44:25.256674: step 145610, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 11h:26m:08s remains)
INFO - root - 2017-12-16 23:44:27.498448: step 145620, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 11h:45m:02s remains)
INFO - root - 2017-12-16 23:44:29.711433: step 145630, loss = 0.48, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 11h:33m:56s remains)
INFO - root - 2017-12-16 23:44:31.917521: step 145640, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 11h:21m:07s remains)
INFO - root - 2017-12-16 23:44:34.116315: step 145650, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 11h:29m:29s remains)
INFO - root - 2017-12-16 23:44:36.338957: step 145660, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 11h:33m:07s remains)
INFO - root - 2017-12-16 23:44:38.549432: step 145670, loss = 0.58, batch loss = 0.40 (35.0 examples/sec; 0.228 sec/batch; 11h:51m:21s remains)
INFO - root - 2017-12-16 23:44:40.760227: step 145680, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 11h:27m:14s remains)
INFO - root - 2017-12-16 23:44:42.962035: step 145690, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 11h:21m:21s remains)
INFO - root - 2017-12-16 23:44:45.166685: step 145700, loss = 0.51, batch loss = 0.34 (37.3 examples/sec; 0.215 sec/batch; 11h:07m:53s remains)
INFO - root - 2017-12-16 23:44:47.541711: step 145710, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 11h:18m:34s remains)
INFO - root - 2017-12-16 23:44:49.726609: step 145720, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 11h:29m:37s remains)
INFO - root - 2017-12-16 23:44:51.908458: step 145730, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.214 sec/batch; 11h:07m:05s remains)
INFO - root - 2017-12-16 23:44:54.133386: step 145740, loss = 0.53, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 11h:38m:22s remains)
INFO - root - 2017-12-16 23:44:56.353520: step 145750, loss = 0.55, batch loss = 0.37 (35.8 examples/sec; 0.223 sec/batch; 11h:35m:36s remains)
INFO - root - 2017-12-16 23:44:58.570745: step 145760, loss = 0.45, batch loss = 0.27 (38.0 examples/sec; 0.210 sec/batch; 10h:55m:01s remains)
INFO - root - 2017-12-16 23:45:00.745374: step 145770, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 11h:21m:46s remains)
INFO - root - 2017-12-16 23:45:02.942398: step 145780, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 11h:16m:57s remains)
INFO - root - 2017-12-16 23:45:05.180732: step 145790, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 11h:20m:40s remains)
INFO - root - 2017-12-16 23:45:07.411967: step 145800, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 11h:13m:02s remains)
INFO - root - 2017-12-16 23:45:09.769878: step 145810, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 10h:59m:37s remains)
INFO - root - 2017-12-16 23:45:11.982456: step 145820, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 11h:32m:56s remains)
INFO - root - 2017-12-16 23:45:14.178159: step 145830, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 11h:49m:43s remains)
INFO - root - 2017-12-16 23:45:16.409064: step 145840, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 11h:24m:11s remains)
INFO - root - 2017-12-16 23:45:18.612177: step 145850, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 11h:19m:27s remains)
INFO - root - 2017-12-16 23:45:20.821345: step 145860, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 11h:16m:03s remains)
INFO - root - 2017-12-16 23:45:23.036392: step 145870, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 12h:01m:14s remains)
INFO - root - 2017-12-16 23:45:25.226227: step 145880, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 11h:40m:43s remains)
INFO - root - 2017-12-16 23:45:27.426469: step 145890, loss = 0.51, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 11h:14m:14s remains)
INFO - root - 2017-12-16 23:45:29.664174: step 145900, loss = 0.51, batch loss = 0.33 (34.0 examples/sec; 0.235 sec/batch; 12h:11m:08s remains)
INFO - root - 2017-12-16 23:45:32.058581: step 145910, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 11h:29m:31s remains)
INFO - root - 2017-12-16 23:45:34.280143: step 145920, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 11h:37m:33s remains)
INFO - root - 2017-12-16 23:45:36.512534: step 145930, loss = 0.49, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 11h:18m:53s remains)
INFO - root - 2017-12-16 23:45:38.729667: step 145940, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 11h:22m:12s remains)
INFO - root - 2017-12-16 23:45:40.945142: step 145950, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 11h:34m:48s remains)
INFO - root - 2017-12-16 23:45:43.134076: step 145960, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 11h:33m:54s remains)
INFO - root - 2017-12-16 23:45:45.390688: step 145970, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 11h:39m:27s remains)
INFO - root - 2017-12-16 23:45:47.621835: step 145980, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 11h:30m:25s remains)
INFO - root - 2017-12-16 23:45:49.848324: step 145990, loss = 0.53, batch loss = 0.35 (35.8 examples/sec; 0.224 sec/batch; 11h:34m:46s remains)
INFO - root - 2017-12-16 23:45:52.090105: step 146000, loss = 0.57, batch loss = 0.39 (34.9 examples/sec; 0.230 sec/batch; 11h:53m:23s remains)
INFO - root - 2017-12-16 23:45:54.474315: step 146010, loss = 0.44, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 11h:12m:44s remains)
INFO - root - 2017-12-16 23:45:56.713248: step 146020, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 11h:28m:17s remains)
INFO - root - 2017-12-16 23:45:58.945488: step 146030, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 11h:20m:11s remains)
INFO - root - 2017-12-16 23:46:01.146151: step 146040, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 11h:23m:18s remains)
INFO - root - 2017-12-16 23:46:03.317853: step 146050, loss = 0.50, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 11h:27m:54s remains)
INFO - root - 2017-12-16 23:46:05.539442: step 146060, loss = 0.50, batch loss = 0.32 (37.9 examples/sec; 0.211 sec/batch; 10h:56m:07s remains)
INFO - root - 2017-12-16 23:46:07.758330: step 146070, loss = 0.46, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 12h:04m:43s remains)
INFO - root - 2017-12-16 23:46:09.984022: step 146080, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 11h:05m:11s remains)
INFO - root - 2017-12-16 23:46:12.217547: step 146090, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 11h:28m:13s remains)
INFO - root - 2017-12-16 23:46:14.412803: step 146100, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 11h:40m:49s remains)
INFO - root - 2017-12-16 23:46:16.697300: step 146110, loss = 0.48, batch loss = 0.30 (38.1 examples/sec; 0.210 sec/batch; 10h:52m:19s remains)
INFO - root - 2017-12-16 23:46:18.878448: step 146120, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 11h:10m:27s remains)
INFO - root - 2017-12-16 23:46:21.115722: step 146130, loss = 0.46, batch loss = 0.28 (34.4 examples/sec; 0.232 sec/batch; 12h:01m:38s remains)
INFO - root - 2017-12-16 23:46:23.345454: step 146140, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 11h:18m:41s remains)
INFO - root - 2017-12-16 23:46:25.538276: step 146150, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 10h:56m:57s remains)
INFO - root - 2017-12-16 23:46:27.750400: step 146160, loss = 0.43, batch loss = 0.25 (34.6 examples/sec; 0.231 sec/batch; 11h:58m:35s remains)
INFO - root - 2017-12-16 23:46:29.954680: step 146170, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 11h:12m:19s remains)
INFO - root - 2017-12-16 23:46:32.171899: step 146180, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 11h:53m:27s remains)
INFO - root - 2017-12-16 23:46:34.356107: step 146190, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 11h:33m:05s remains)
INFO - root - 2017-12-16 23:46:36.570976: step 146200, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 11h:30m:04s remains)
INFO - root - 2017-12-16 23:46:38.956139: step 146210, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 11h:02m:07s remains)
INFO - root - 2017-12-16 23:46:41.138123: step 146220, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.216 sec/batch; 11h:09m:57s remains)
INFO - root - 2017-12-16 23:46:43.342109: step 146230, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 11h:08m:02s remains)
INFO - root - 2017-12-16 23:46:45.551746: step 146240, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 11h:36m:33s remains)
INFO - root - 2017-12-16 23:46:47.731458: step 146250, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 11h:12m:17s remains)
INFO - root - 2017-12-16 23:46:49.909971: step 146260, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 11h:28m:40s remains)
INFO - root - 2017-12-16 23:46:52.152192: step 146270, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.232 sec/batch; 12h:01m:15s remains)
INFO - root - 2017-12-16 23:46:54.389855: step 146280, loss = 0.47, batch loss = 0.29 (34.3 examples/sec; 0.233 sec/batch; 12h:03m:50s remains)
INFO - root - 2017-12-16 23:46:56.581394: step 146290, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 11h:12m:46s remains)
INFO - root - 2017-12-16 23:46:58.827057: step 146300, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 11h:23m:04s remains)
INFO - root - 2017-12-16 23:47:01.186399: step 146310, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 11h:23m:36s remains)
INFO - root - 2017-12-16 23:47:03.390930: step 146320, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 11h:41m:41s remains)
INFO - root - 2017-12-16 23:47:05.573809: step 146330, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 11h:38m:33s remains)
INFO - root - 2017-12-16 23:47:07.788333: step 146340, loss = 0.48, batch loss = 0.30 (33.9 examples/sec; 0.236 sec/batch; 12h:11m:42s remains)
INFO - root - 2017-12-16 23:47:10.024733: step 146350, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 11h:16m:39s remains)
INFO - root - 2017-12-16 23:47:12.234264: step 146360, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 11h:10m:17s remains)
INFO - root - 2017-12-16 23:47:14.447572: step 146370, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 11h:23m:15s remains)
INFO - root - 2017-12-16 23:47:16.683542: step 146380, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 11h:13m:16s remains)
INFO - root - 2017-12-16 23:47:18.917624: step 146390, loss = 0.46, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 11h:44m:56s remains)
INFO - root - 2017-12-16 23:47:21.134430: step 146400, loss = 0.52, batch loss = 0.35 (36.6 examples/sec; 0.218 sec/batch; 11h:17m:19s remains)
INFO - root - 2017-12-16 23:47:23.473693: step 146410, loss = 0.57, batch loss = 0.39 (36.3 examples/sec; 0.221 sec/batch; 11h:24m:10s remains)
INFO - root - 2017-12-16 23:47:25.659364: step 146420, loss = 0.43, batch loss = 0.25 (37.9 examples/sec; 0.211 sec/batch; 10h:54m:41s remains)
INFO - root - 2017-12-16 23:47:27.847736: step 146430, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.215 sec/batch; 11h:08m:16s remains)
INFO - root - 2017-12-16 23:47:30.065263: step 146440, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 11h:59m:36s remains)
INFO - root - 2017-12-16 23:47:32.281931: step 146450, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 11h:31m:04s remains)
INFO - root - 2017-12-16 23:47:34.469217: step 146460, loss = 0.42, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 11h:19m:12s remains)
INFO - root - 2017-12-16 23:47:36.708716: step 146470, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 11h:52m:07s remains)
INFO - root - 2017-12-16 23:47:38.945868: step 146480, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 11h:24m:13s remains)
INFO - root - 2017-12-16 23:47:41.168647: step 146490, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 11h:27m:07s remains)
INFO - root - 2017-12-16 23:47:43.358019: step 146500, loss = 0.58, batch loss = 0.40 (36.7 examples/sec; 0.218 sec/batch; 11h:16m:12s remains)
INFO - root - 2017-12-16 23:47:45.733999: step 146510, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 11h:42m:13s remains)
INFO - root - 2017-12-16 23:47:47.961354: step 146520, loss = 0.50, batch loss = 0.33 (33.8 examples/sec; 0.237 sec/batch; 12h:13m:23s remains)
INFO - root - 2017-12-16 23:47:50.161778: step 146530, loss = 0.51, batch loss = 0.33 (34.9 examples/sec; 0.229 sec/batch; 11h:51m:02s remains)
INFO - root - 2017-12-16 23:47:52.397051: step 146540, loss = 0.51, batch loss = 0.33 (34.4 examples/sec; 0.233 sec/batch; 12h:00m:56s remains)
INFO - root - 2017-12-16 23:47:54.607257: step 146550, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.224 sec/batch; 11h:35m:37s remains)
INFO - root - 2017-12-16 23:47:56.829077: step 146560, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 11h:25m:44s remains)
INFO - root - 2017-12-16 23:47:59.027521: step 146570, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 11h:05m:26s remains)
INFO - root - 2017-12-16 23:48:01.270779: step 146580, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 11h:29m:06s remains)
INFO - root - 2017-12-16 23:48:03.472566: step 146590, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 11h:39m:32s remains)
INFO - root - 2017-12-16 23:48:05.669365: step 146600, loss = 0.44, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 11h:32m:20s remains)
INFO - root - 2017-12-16 23:48:08.002980: step 146610, loss = 0.45, batch loss = 0.27 (34.7 examples/sec; 0.230 sec/batch; 11h:53m:17s remains)
INFO - root - 2017-12-16 23:48:10.213635: step 146620, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.224 sec/batch; 11h:35m:18s remains)
INFO - root - 2017-12-16 23:48:12.483293: step 146630, loss = 0.56, batch loss = 0.38 (33.9 examples/sec; 0.236 sec/batch; 12h:10m:58s remains)
INFO - root - 2017-12-16 23:48:14.660265: step 146640, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 11h:14m:28s remains)
INFO - root - 2017-12-16 23:48:16.887338: step 146650, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 11h:36m:49s remains)
INFO - root - 2017-12-16 23:48:19.156972: step 146660, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 11h:43m:06s remains)
INFO - root - 2017-12-16 23:48:21.347763: step 146670, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 10h:57m:16s remains)
INFO - root - 2017-12-16 23:48:23.602009: step 146680, loss = 0.52, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 11h:46m:48s remains)
INFO - root - 2017-12-16 23:48:25.821923: step 146690, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 11h:28m:55s remains)
INFO - root - 2017-12-16 23:48:28.047467: step 146700, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 11h:13m:35s remains)
INFO - root - 2017-12-16 23:48:30.389125: step 146710, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 11h:13m:53s remains)
INFO - root - 2017-12-16 23:48:32.588557: step 146720, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 11h:21m:38s remains)
INFO - root - 2017-12-16 23:48:34.750967: step 146730, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 11h:09m:08s remains)
INFO - root - 2017-12-16 23:48:36.967063: step 146740, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 11h:12m:49s remains)
INFO - root - 2017-12-16 23:48:39.183866: step 146750, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 11h:10m:37s remains)
INFO - root - 2017-12-16 23:48:41.371089: step 146760, loss = 0.48, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 11h:25m:17s remains)
INFO - root - 2017-12-16 23:48:43.616394: step 146770, loss = 0.55, batch loss = 0.37 (37.6 examples/sec; 0.213 sec/batch; 10h:59m:29s remains)
INFO - root - 2017-12-16 23:48:45.848413: step 146780, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 11h:16m:24s remains)
INFO - root - 2017-12-16 23:48:48.021104: step 146790, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 11h:23m:10s remains)
INFO - root - 2017-12-16 23:48:50.215928: step 146800, loss = 0.45, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 11h:34m:27s remains)
INFO - root - 2017-12-16 23:48:52.547739: step 146810, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 11h:43m:22s remains)
INFO - root - 2017-12-16 23:48:54.811633: step 146820, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 11h:56m:17s remains)
INFO - root - 2017-12-16 23:48:56.991150: step 146830, loss = 0.45, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 11h:30m:18s remains)
INFO - root - 2017-12-16 23:48:59.182484: step 146840, loss = 0.49, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 11h:05m:59s remains)
INFO - root - 2017-12-16 23:49:01.393940: step 146850, loss = 0.48, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 11h:04m:49s remains)
INFO - root - 2017-12-16 23:49:03.609208: step 146860, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 10h:59m:57s remains)
INFO - root - 2017-12-16 23:49:05.805066: step 146870, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 11h:02m:07s remains)
INFO - root - 2017-12-16 23:49:07.987567: step 146880, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 11h:33m:46s remains)
INFO - root - 2017-12-16 23:49:10.215398: step 146890, loss = 0.46, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 11h:18m:35s remains)
INFO - root - 2017-12-16 23:49:12.368890: step 146900, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 11h:08m:08s remains)
INFO - root - 2017-12-16 23:49:14.703489: step 146910, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 11h:19m:31s remains)
INFO - root - 2017-12-16 23:49:16.886875: step 146920, loss = 0.58, batch loss = 0.40 (36.8 examples/sec; 0.217 sec/batch; 11h:11m:37s remains)
INFO - root - 2017-12-16 23:49:19.086767: step 146930, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 11h:28m:56s remains)
INFO - root - 2017-12-16 23:49:21.296888: step 146940, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 11h:32m:41s remains)
INFO - root - 2017-12-16 23:49:23.507063: step 146950, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 11h:07m:55s remains)
INFO - root - 2017-12-16 23:49:25.759562: step 146960, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 11h:47m:05s remains)
INFO - root - 2017-12-16 23:49:27.964193: step 146970, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 11h:19m:43s remains)
INFO - root - 2017-12-16 23:49:30.156590: step 146980, loss = 0.59, batch loss = 0.41 (36.4 examples/sec; 0.220 sec/batch; 11h:19m:57s remains)
INFO - root - 2017-12-16 23:49:32.383261: step 146990, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 11h:18m:29s remains)
INFO - root - 2017-12-16 23:49:34.601088: step 147000, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 11h:21m:53s remains)
INFO - root - 2017-12-16 23:49:36.990210: step 147010, loss = 0.55, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 11h:17m:31s remains)
INFO - root - 2017-12-16 23:49:39.190150: step 147020, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 11h:50m:58s remains)
INFO - root - 2017-12-16 23:49:41.394430: step 147030, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 11h:16m:59s remains)
INFO - root - 2017-12-16 23:49:43.613013: step 147040, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 11h:36m:55s remains)
INFO - root - 2017-12-16 23:49:45.834825: step 147050, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 11h:23m:04s remains)
INFO - root - 2017-12-16 23:49:48.022907: step 147060, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 11h:26m:48s remains)
INFO - root - 2017-12-16 23:49:50.215416: step 147070, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:07m:36s remains)
INFO - root - 2017-12-16 23:49:52.455160: step 147080, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 11h:21m:33s remains)
INFO - root - 2017-12-16 23:49:54.677145: step 147090, loss = 0.54, batch loss = 0.36 (37.8 examples/sec; 0.212 sec/batch; 10h:53m:50s remains)
INFO - root - 2017-12-16 23:49:56.864454: step 147100, loss = 0.46, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 11h:11m:16s remains)
INFO - root - 2017-12-16 23:49:59.175204: step 147110, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 11h:24m:42s remains)
INFO - root - 2017-12-16 23:50:01.368006: step 147120, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 11h:34m:16s remains)
INFO - root - 2017-12-16 23:50:03.551965: step 147130, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 11h:14m:54s remains)
INFO - root - 2017-12-16 23:50:05.783989: step 147140, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 11h:34m:12s remains)
INFO - root - 2017-12-16 23:50:08.051689: step 147150, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 11h:04m:37s remains)
INFO - root - 2017-12-16 23:50:10.277319: step 147160, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 11h:26m:49s remains)
INFO - root - 2017-12-16 23:50:12.510574: step 147170, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 11h:32m:12s remains)
INFO - root - 2017-12-16 23:50:14.755949: step 147180, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 11h:11m:10s remains)
INFO - root - 2017-12-16 23:50:16.982895: step 147190, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 11h:27m:44s remains)
INFO - root - 2017-12-16 23:50:19.181282: step 147200, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 11h:40m:26s remains)
INFO - root - 2017-12-16 23:50:21.524426: step 147210, loss = 0.43, batch loss = 0.25 (37.3 examples/sec; 0.214 sec/batch; 11h:01m:29s remains)
INFO - root - 2017-12-16 23:50:23.778575: step 147220, loss = 0.42, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 11h:21m:55s remains)
INFO - root - 2017-12-16 23:50:26.030789: step 147230, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 11h:32m:39s remains)
INFO - root - 2017-12-16 23:50:28.223284: step 147240, loss = 0.50, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 11h:12m:54s remains)
INFO - root - 2017-12-16 23:50:30.443710: step 147250, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 11h:36m:01s remains)
INFO - root - 2017-12-16 23:50:32.676842: step 147260, loss = 0.46, batch loss = 0.29 (34.7 examples/sec; 0.230 sec/batch; 11h:50m:52s remains)
INFO - root - 2017-12-16 23:50:34.867681: step 147270, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 11h:05m:46s remains)
INFO - root - 2017-12-16 23:50:37.063581: step 147280, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 11h:26m:38s remains)
INFO - root - 2017-12-16 23:50:39.273798: step 147290, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 11h:04m:07s remains)
INFO - root - 2017-12-16 23:50:41.455406: step 147300, loss = 0.57, batch loss = 0.39 (36.5 examples/sec; 0.219 sec/batch; 11h:17m:22s remains)
INFO - root - 2017-12-16 23:50:43.804063: step 147310, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 11h:25m:31s remains)
INFO - root - 2017-12-16 23:50:46.012973: step 147320, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.221 sec/batch; 11h:23m:34s remains)
INFO - root - 2017-12-16 23:50:48.199640: step 147330, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 11h:15m:11s remains)
INFO - root - 2017-12-16 23:50:50.402032: step 147340, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 11h:09m:34s remains)
INFO - root - 2017-12-16 23:50:52.605279: step 147350, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 11h:22m:01s remains)
INFO - root - 2017-12-16 23:50:54.824006: step 147360, loss = 0.48, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 11h:01m:04s remains)
INFO - root - 2017-12-16 23:50:57.049044: step 147370, loss = 0.51, batch loss = 0.33 (35.1 examples/sec; 0.228 sec/batch; 11h:43m:01s remains)
INFO - root - 2017-12-16 23:50:59.241559: step 147380, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 11h:02m:50s remains)
INFO - root - 2017-12-16 23:51:01.507044: step 147390, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.216 sec/batch; 11h:04m:56s remains)
INFO - root - 2017-12-16 23:51:03.688949: step 147400, loss = 0.42, batch loss = 0.24 (36.9 examples/sec; 0.217 sec/batch; 11h:08m:06s remains)
INFO - root - 2017-12-16 23:51:06.026779: step 147410, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 11h:08m:02s remains)
INFO - root - 2017-12-16 23:51:08.258223: step 147420, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 11h:33m:45s remains)
INFO - root - 2017-12-16 23:51:10.433872: step 147430, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.223 sec/batch; 11h:28m:58s remains)
INFO - root - 2017-12-16 23:51:12.628843: step 147440, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 11h:20m:16s remains)
INFO - root - 2017-12-16 23:51:14.820503: step 147450, loss = 0.49, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 11h:11m:06s remains)
INFO - root - 2017-12-16 23:51:17.074561: step 147460, loss = 0.44, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 11h:30m:00s remains)
INFO - root - 2017-12-16 23:51:19.334261: step 147470, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.218 sec/batch; 11h:13m:43s remains)
INFO - root - 2017-12-16 23:51:21.601818: step 147480, loss = 0.43, batch loss = 0.25 (35.0 examples/sec; 0.228 sec/batch; 11h:44m:04s remains)
INFO - root - 2017-12-16 23:51:23.862360: step 147490, loss = 0.52, batch loss = 0.34 (33.1 examples/sec; 0.242 sec/batch; 12h:25m:33s remains)
INFO - root - 2017-12-16 23:51:26.064960: step 147500, loss = 0.53, batch loss = 0.35 (33.9 examples/sec; 0.236 sec/batch; 12h:08m:22s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-147500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-147500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-16 23:51:28.880566: step 147510, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 11h:01m:39s remains)
INFO - root - 2017-12-16 23:51:31.136182: step 147520, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 11h:26m:56s remains)
INFO - root - 2017-12-16 23:51:33.351726: step 147530, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 11h:07m:44s remains)
INFO - root - 2017-12-16 23:51:35.567418: step 147540, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 11h:18m:20s remains)
INFO - root - 2017-12-16 23:51:37.746549: step 147550, loss = 0.50, batch loss = 0.32 (37.5 examples/sec; 0.214 sec/batch; 10h:58m:12s remains)
INFO - root - 2017-12-16 23:51:39.963228: step 147560, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 11h:15m:25s remains)
INFO - root - 2017-12-16 23:51:42.160041: step 147570, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 11h:22m:20s remains)
INFO - root - 2017-12-16 23:51:44.368530: step 147580, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 11h:07m:48s remains)
INFO - root - 2017-12-16 23:51:46.534605: step 147590, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 11h:04m:36s remains)
INFO - root - 2017-12-16 23:51:48.747140: step 147600, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 11h:09m:49s remains)
INFO - root - 2017-12-16 23:51:51.085005: step 147610, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 11h:03m:16s remains)
INFO - root - 2017-12-16 23:51:53.313470: step 147620, loss = 0.41, batch loss = 0.23 (35.4 examples/sec; 0.226 sec/batch; 11h:36m:54s remains)
INFO - root - 2017-12-16 23:51:55.532350: step 147630, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 11h:21m:05s remains)
INFO - root - 2017-12-16 23:51:57.737072: step 147640, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 10h:53m:22s remains)
INFO - root - 2017-12-16 23:51:59.989605: step 147650, loss = 0.45, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 11h:27m:27s remains)
INFO - root - 2017-12-16 23:52:02.206354: step 147660, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 11h:35m:09s remains)
INFO - root - 2017-12-16 23:52:04.431876: step 147670, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 11h:11m:49s remains)
INFO - root - 2017-12-16 23:52:06.678215: step 147680, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 11h:24m:44s remains)
INFO - root - 2017-12-16 23:52:08.923149: step 147690, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 10h:59m:11s remains)
INFO - root - 2017-12-16 23:52:11.135762: step 147700, loss = 0.47, batch loss = 0.30 (35.8 examples/sec; 0.224 sec/batch; 11h:28m:42s remains)
INFO - root - 2017-12-16 23:52:13.464243: step 147710, loss = 0.42, batch loss = 0.24 (35.2 examples/sec; 0.227 sec/batch; 11h:39m:15s remains)
INFO - root - 2017-12-16 23:52:15.696231: step 147720, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 11h:13m:36s remains)
INFO - root - 2017-12-16 23:52:17.922265: step 147730, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.224 sec/batch; 11h:28m:27s remains)
INFO - root - 2017-12-16 23:52:20.113918: step 147740, loss = 0.52, batch loss = 0.34 (34.1 examples/sec; 0.235 sec/batch; 12h:03m:22s remains)
INFO - root - 2017-12-16 23:52:22.352163: step 147750, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 11h:10m:55s remains)
INFO - root - 2017-12-16 23:52:24.593640: step 147760, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 11h:24m:43s remains)
INFO - root - 2017-12-16 23:52:26.827242: step 147770, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 11h:41m:01s remains)
INFO - root - 2017-12-16 23:52:29.015361: step 147780, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 11h:18m:04s remains)
INFO - root - 2017-12-16 23:52:31.216072: step 147790, loss = 0.44, batch loss = 0.27 (33.6 examples/sec; 0.238 sec/batch; 12h:12m:25s remains)
INFO - root - 2017-12-16 23:52:33.479225: step 147800, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 11h:28m:17s remains)
INFO - root - 2017-12-16 23:52:35.794978: step 147810, loss = 0.44, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 11h:08m:47s remains)
INFO - root - 2017-12-16 23:52:38.005833: step 147820, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 11h:15m:20s remains)
INFO - root - 2017-12-16 23:52:40.207009: step 147830, loss = 0.48, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 10h:56m:14s remains)
INFO - root - 2017-12-16 23:52:42.414898: step 147840, loss = 0.42, batch loss = 0.24 (36.9 examples/sec; 0.217 sec/batch; 11h:07m:42s remains)
INFO - root - 2017-12-16 23:52:44.637297: step 147850, loss = 0.45, batch loss = 0.27 (38.0 examples/sec; 0.210 sec/batch; 10h:47m:15s remains)
INFO - root - 2017-12-16 23:52:46.882172: step 147860, loss = 0.49, batch loss = 0.31 (34.5 examples/sec; 0.232 sec/batch; 11h:53m:34s remains)
INFO - root - 2017-12-16 23:52:49.098809: step 147870, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 11h:23m:55s remains)
INFO - root - 2017-12-16 23:52:51.328262: step 147880, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 11h:35m:07s remains)
INFO - root - 2017-12-16 23:52:53.553299: step 147890, loss = 0.44, batch loss = 0.26 (34.7 examples/sec; 0.231 sec/batch; 11h:49m:32s remains)
INFO - root - 2017-12-16 23:52:55.763283: step 147900, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 10h:56m:45s remains)
INFO - root - 2017-12-16 23:52:58.137519: step 147910, loss = 0.42, batch loss = 0.24 (35.3 examples/sec; 0.227 sec/batch; 11h:36m:54s remains)
INFO - root - 2017-12-16 23:53:00.337813: step 147920, loss = 0.46, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 11h:25m:27s remains)
INFO - root - 2017-12-16 23:53:02.533136: step 147930, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 11h:27m:13s remains)
INFO - root - 2017-12-16 23:53:04.736587: step 147940, loss = 0.48, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 11h:21m:15s remains)
INFO - root - 2017-12-16 23:53:06.951188: step 147950, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 11h:05m:02s remains)
INFO - root - 2017-12-16 23:53:09.175703: step 147960, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 11h:11m:00s remains)
INFO - root - 2017-12-16 23:53:11.397858: step 147970, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 11h:35m:24s remains)
INFO - root - 2017-12-16 23:53:13.612796: step 147980, loss = 0.48, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 11h:20m:04s remains)
INFO - root - 2017-12-16 23:53:15.825399: step 147990, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 11h:14m:41s remains)
INFO - root - 2017-12-16 23:53:18.068730: step 148000, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 11h:40m:33s remains)
INFO - root - 2017-12-16 23:53:20.398953: step 148010, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 11h:06m:21s remains)
INFO - root - 2017-12-16 23:53:22.602969: step 148020, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 11h:34m:32s remains)
INFO - root - 2017-12-16 23:53:24.841987: step 148030, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 11h:14m:29s remains)
INFO - root - 2017-12-16 23:53:27.023997: step 148040, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 11h:01m:59s remains)
INFO - root - 2017-12-16 23:53:29.233740: step 148050, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 11h:08m:16s remains)
INFO - root - 2017-12-16 23:53:31.407082: step 148060, loss = 0.48, batch loss = 0.31 (37.8 examples/sec; 0.212 sec/batch; 10h:50m:23s remains)
INFO - root - 2017-12-16 23:53:33.599236: step 148070, loss = 0.44, batch loss = 0.26 (37.7 examples/sec; 0.212 sec/batch; 10h:52m:54s remains)
INFO - root - 2017-12-16 23:53:35.800761: step 148080, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.215 sec/batch; 10h:59m:57s remains)
INFO - root - 2017-12-16 23:53:38.028667: step 148090, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 11h:07m:01s remains)
INFO - root - 2017-12-16 23:53:40.259367: step 148100, loss = 0.47, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 11h:33m:21s remains)
INFO - root - 2017-12-16 23:53:42.589568: step 148110, loss = 0.48, batch loss = 0.30 (37.9 examples/sec; 0.211 sec/batch; 10h:48m:34s remains)
INFO - root - 2017-12-16 23:53:44.772765: step 148120, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 11h:16m:15s remains)
INFO - root - 2017-12-16 23:53:46.959135: step 148130, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 10h:51m:31s remains)
INFO - root - 2017-12-16 23:53:49.198719: step 148140, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 11h:34m:25s remains)
INFO - root - 2017-12-16 23:53:51.403267: step 148150, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 11h:19m:21s remains)
INFO - root - 2017-12-16 23:53:53.594094: step 148160, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 11h:16m:37s remains)
INFO - root - 2017-12-16 23:53:55.824901: step 148170, loss = 0.43, batch loss = 0.25 (34.8 examples/sec; 0.230 sec/batch; 11h:45m:23s remains)
INFO - root - 2017-12-16 23:53:58.064100: step 148180, loss = 0.50, batch loss = 0.32 (33.6 examples/sec; 0.238 sec/batch; 12h:11m:01s remains)
INFO - root - 2017-12-16 23:54:00.243949: step 148190, loss = 0.49, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 10h:51m:03s remains)
INFO - root - 2017-12-16 23:54:02.461017: step 148200, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 11h:18m:16s remains)
INFO - root - 2017-12-16 23:54:04.836635: step 148210, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 11h:23m:41s remains)
INFO - root - 2017-12-16 23:54:07.024149: step 148220, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 11h:21m:38s remains)
INFO - root - 2017-12-16 23:54:09.239809: step 148230, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 11h:13m:39s remains)
INFO - root - 2017-12-16 23:54:11.482444: step 148240, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 11h:30m:24s remains)
INFO - root - 2017-12-16 23:54:13.675328: step 148250, loss = 0.51, batch loss = 0.33 (37.5 examples/sec; 0.213 sec/batch; 10h:55m:03s remains)
INFO - root - 2017-12-16 23:54:15.935053: step 148260, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 11h:06m:13s remains)
INFO - root - 2017-12-16 23:54:18.165327: step 148270, loss = 0.55, batch loss = 0.37 (35.5 examples/sec; 0.225 sec/batch; 11h:31m:16s remains)
INFO - root - 2017-12-16 23:54:20.389881: step 148280, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 11h:28m:33s remains)
INFO - root - 2017-12-16 23:54:22.628212: step 148290, loss = 0.46, batch loss = 0.28 (33.9 examples/sec; 0.236 sec/batch; 12h:03m:31s remains)
INFO - root - 2017-12-16 23:54:24.880036: step 148300, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 11h:06m:08s remains)
INFO - root - 2017-12-16 23:54:27.234651: step 148310, loss = 0.60, batch loss = 0.42 (36.2 examples/sec; 0.221 sec/batch; 11h:17m:40s remains)
INFO - root - 2017-12-16 23:54:29.458115: step 148320, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 11h:00m:09s remains)
INFO - root - 2017-12-16 23:54:31.663653: step 148330, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 11h:27m:35s remains)
INFO - root - 2017-12-16 23:54:33.877380: step 148340, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 11h:12m:42s remains)
INFO - root - 2017-12-16 23:54:36.070330: step 148350, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 11h:21m:04s remains)
INFO - root - 2017-12-16 23:54:38.319777: step 148360, loss = 0.42, batch loss = 0.24 (37.2 examples/sec; 0.215 sec/batch; 10h:59m:57s remains)
INFO - root - 2017-12-16 23:54:40.515516: step 148370, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 10h:59m:45s remains)
INFO - root - 2017-12-16 23:54:42.750166: step 148380, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 11h:21m:35s remains)
INFO - root - 2017-12-16 23:54:44.944879: step 148390, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 11h:08m:42s remains)
INFO - root - 2017-12-16 23:54:47.154317: step 148400, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 10h:59m:44s remains)
INFO - root - 2017-12-16 23:54:49.510171: step 148410, loss = 0.50, batch loss = 0.32 (37.5 examples/sec; 0.213 sec/batch; 10h:54m:49s remains)
INFO - root - 2017-12-16 23:54:51.717978: step 148420, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 11h:13m:19s remains)
INFO - root - 2017-12-16 23:54:53.931399: step 148430, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 11h:10m:53s remains)
INFO - root - 2017-12-16 23:54:56.210061: step 148440, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 11h:32m:32s remains)
INFO - root - 2017-12-16 23:54:58.410406: step 148450, loss = 0.50, batch loss = 0.32 (35.0 examples/sec; 0.228 sec/batch; 11h:40m:38s remains)
INFO - root - 2017-12-16 23:55:00.664704: step 148460, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 11h:33m:30s remains)
INFO - root - 2017-12-16 23:55:02.889183: step 148470, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 11h:36m:09s remains)
INFO - root - 2017-12-16 23:55:05.085398: step 148480, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 11h:20m:19s remains)
INFO - root - 2017-12-16 23:55:07.289852: step 148490, loss = 0.55, batch loss = 0.38 (34.6 examples/sec; 0.231 sec/batch; 11h:48m:50s remains)
INFO - root - 2017-12-16 23:55:09.585529: step 148500, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 11h:36m:00s remains)
INFO - root - 2017-12-16 23:55:11.897910: step 148510, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 11h:03m:35s remains)
INFO - root - 2017-12-16 23:55:14.079640: step 148520, loss = 0.45, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 11h:19m:38s remains)
INFO - root - 2017-12-16 23:55:16.281845: step 148530, loss = 0.42, batch loss = 0.24 (36.9 examples/sec; 0.217 sec/batch; 11h:05m:10s remains)
INFO - root - 2017-12-16 23:55:18.491351: step 148540, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 11h:00m:00s remains)
INFO - root - 2017-12-16 23:55:20.696788: step 148550, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 11h:09m:21s remains)
INFO - root - 2017-12-16 23:55:22.926177: step 148560, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 11h:43m:30s remains)
INFO - root - 2017-12-16 23:55:25.144114: step 148570, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 11h:19m:48s remains)
INFO - root - 2017-12-16 23:55:27.352072: step 148580, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.221 sec/batch; 11h:16m:24s remains)
INFO - root - 2017-12-16 23:55:29.582911: step 148590, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.226 sec/batch; 11h:31m:12s remains)
INFO - root - 2017-12-16 23:55:31.779190: step 148600, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 10h:53m:28s remains)
INFO - root - 2017-12-16 23:55:34.133650: step 148610, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 11h:26m:38s remains)
INFO - root - 2017-12-16 23:55:36.349174: step 148620, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 11h:02m:21s remains)
INFO - root - 2017-12-16 23:55:38.599986: step 148630, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 11h:24m:15s remains)
INFO - root - 2017-12-16 23:55:40.823164: step 148640, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 11h:24m:21s remains)
INFO - root - 2017-12-16 23:55:43.074587: step 148650, loss = 0.49, batch loss = 0.31 (37.9 examples/sec; 0.211 sec/batch; 10h:47m:17s remains)
INFO - root - 2017-12-16 23:55:45.297258: step 148660, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 11h:14m:32s remains)
INFO - root - 2017-12-16 23:55:47.525547: step 148670, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 10h:57m:26s remains)
INFO - root - 2017-12-16 23:55:49.763827: step 148680, loss = 0.43, batch loss = 0.25 (33.8 examples/sec; 0.237 sec/batch; 12h:05m:06s remains)
INFO - root - 2017-12-16 23:55:51.990619: step 148690, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 11h:02m:41s remains)
INFO - root - 2017-12-16 23:55:54.199023: step 148700, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 11h:03m:05s remains)
INFO - root - 2017-12-16 23:55:56.594561: step 148710, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 11h:11m:50s remains)
INFO - root - 2017-12-16 23:55:58.818910: step 148720, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 11h:08m:32s remains)
INFO - root - 2017-12-16 23:56:01.028453: step 148730, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 11h:11m:15s remains)
INFO - root - 2017-12-16 23:56:03.320660: step 148740, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 11h:31m:14s remains)
INFO - root - 2017-12-16 23:56:05.553909: step 148750, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 11h:44m:40s remains)
INFO - root - 2017-12-16 23:56:07.794761: step 148760, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 11h:20m:14s remains)
INFO - root - 2017-12-16 23:56:10.024725: step 148770, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 11h:14m:47s remains)
INFO - root - 2017-12-16 23:56:12.232774: step 148780, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 11h:29m:14s remains)
INFO - root - 2017-12-16 23:56:14.447033: step 148790, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.232 sec/batch; 11h:48m:53s remains)
INFO - root - 2017-12-16 23:56:16.674350: step 148800, loss = 0.55, batch loss = 0.37 (34.7 examples/sec; 0.231 sec/batch; 11h:46m:25s remains)
INFO - root - 2017-12-16 23:56:19.045103: step 148810, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 11h:19m:43s remains)
INFO - root - 2017-12-16 23:56:21.309408: step 148820, loss = 0.48, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 11h:24m:57s remains)
INFO - root - 2017-12-16 23:56:23.560427: step 148830, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 11h:50m:16s remains)
INFO - root - 2017-12-16 23:56:25.748990: step 148840, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 10h:59m:01s remains)
INFO - root - 2017-12-16 23:56:27.968172: step 148850, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 11h:22m:02s remains)
INFO - root - 2017-12-16 23:56:30.178513: step 148860, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 11h:19m:07s remains)
INFO - root - 2017-12-16 23:56:32.379965: step 148870, loss = 0.46, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 11h:21m:08s remains)
INFO - root - 2017-12-16 23:56:34.588342: step 148880, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 11h:12m:49s remains)
INFO - root - 2017-12-16 23:56:36.810217: step 148890, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 11h:06m:56s remains)
INFO - root - 2017-12-16 23:56:38.978834: step 148900, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 11h:17m:14s remains)
INFO - root - 2017-12-16 23:56:41.345418: step 148910, loss = 0.44, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 11h:24m:39s remains)
INFO - root - 2017-12-16 23:56:43.553295: step 148920, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 11h:30m:28s remains)
INFO - root - 2017-12-16 23:56:45.754976: step 148930, loss = 0.42, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 11h:05m:13s remains)
INFO - root - 2017-12-16 23:56:48.002990: step 148940, loss = 0.45, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 11h:45m:58s remains)
INFO - root - 2017-12-16 23:56:50.204299: step 148950, loss = 0.60, batch loss = 0.42 (35.3 examples/sec; 0.226 sec/batch; 11h:32m:28s remains)
INFO - root - 2017-12-16 23:56:52.391781: step 148960, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 11h:00m:40s remains)
INFO - root - 2017-12-16 23:56:54.591626: step 148970, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.224 sec/batch; 11h:24m:00s remains)
INFO - root - 2017-12-16 23:56:56.808315: step 148980, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 11h:06m:32s remains)
INFO - root - 2017-12-16 23:56:59.020062: step 148990, loss = 0.51, batch loss = 0.33 (34.1 examples/sec; 0.235 sec/batch; 11h:57m:26s remains)
INFO - root - 2017-12-16 23:57:01.236333: step 149000, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 11h:03m:18s remains)
INFO - root - 2017-12-16 23:57:03.567345: step 149010, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.224 sec/batch; 11h:26m:22s remains)
INFO - root - 2017-12-16 23:57:05.812375: step 149020, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.226 sec/batch; 11h:29m:47s remains)
INFO - root - 2017-12-16 23:57:08.006917: step 149030, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 11h:12m:13s remains)
INFO - root - 2017-12-16 23:57:10.210918: step 149040, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 11h:13m:30s remains)
INFO - root - 2017-12-16 23:57:12.410452: step 149050, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 11h:31m:33s remains)
INFO - root - 2017-12-16 23:57:14.595910: step 149060, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 10h:50m:25s remains)
INFO - root - 2017-12-16 23:57:16.827927: step 149070, loss = 0.51, batch loss = 0.33 (34.6 examples/sec; 0.231 sec/batch; 11h:47m:14s remains)
INFO - root - 2017-12-16 23:57:19.065562: step 149080, loss = 0.51, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 11h:13m:16s remains)
INFO - root - 2017-12-16 23:57:21.266653: step 149090, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 11h:14m:36s remains)
INFO - root - 2017-12-16 23:57:23.537264: step 149100, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 11h:05m:11s remains)
INFO - root - 2017-12-16 23:57:25.872170: step 149110, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 11h:09m:18s remains)
INFO - root - 2017-12-16 23:57:28.085259: step 149120, loss = 0.48, batch loss = 0.30 (34.3 examples/sec; 0.233 sec/batch; 11h:53m:01s remains)
INFO - root - 2017-12-16 23:57:30.292378: step 149130, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 11h:12m:19s remains)
INFO - root - 2017-12-16 23:57:32.538577: step 149140, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 11h:11m:38s remains)
INFO - root - 2017-12-16 23:57:34.739007: step 149150, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 11h:02m:10s remains)
INFO - root - 2017-12-16 23:57:36.935338: step 149160, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 11h:07m:41s remains)
INFO - root - 2017-12-16 23:57:39.106898: step 149170, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 11h:00m:40s remains)
INFO - root - 2017-12-16 23:57:41.320589: step 149180, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.226 sec/batch; 11h:29m:21s remains)
INFO - root - 2017-12-16 23:57:43.566189: step 149190, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 11h:07m:51s remains)
INFO - root - 2017-12-16 23:57:45.756064: step 149200, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 11h:16m:22s remains)
INFO - root - 2017-12-16 23:57:48.114667: step 149210, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 11h:11m:21s remains)
INFO - root - 2017-12-16 23:57:50.303982: step 149220, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 11h:11m:31s remains)
INFO - root - 2017-12-16 23:57:52.511958: step 149230, loss = 0.55, batch loss = 0.37 (36.9 examples/sec; 0.217 sec/batch; 11h:02m:10s remains)
INFO - root - 2017-12-16 23:57:54.721627: step 149240, loss = 0.56, batch loss = 0.38 (37.4 examples/sec; 0.214 sec/batch; 10h:53m:11s remains)
INFO - root - 2017-12-16 23:57:56.946668: step 149250, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 11h:13m:15s remains)
INFO - root - 2017-12-16 23:57:59.187678: step 149260, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 10h:54m:27s remains)
INFO - root - 2017-12-16 23:58:01.412895: step 149270, loss = 0.42, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 11h:25m:08s remains)
INFO - root - 2017-12-16 23:58:03.603513: step 149280, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 11h:05m:19s remains)
INFO - root - 2017-12-16 23:58:05.770279: step 149290, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 11h:05m:25s remains)
INFO - root - 2017-12-16 23:58:07.981529: step 149300, loss = 0.47, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 11h:00m:09s remains)
INFO - root - 2017-12-16 23:58:10.341850: step 149310, loss = 0.53, batch loss = 0.36 (35.3 examples/sec; 0.226 sec/batch; 11h:31m:27s remains)
INFO - root - 2017-12-16 23:58:12.580039: step 149320, loss = 0.48, batch loss = 0.30 (37.8 examples/sec; 0.212 sec/batch; 10h:46m:55s remains)
INFO - root - 2017-12-16 23:58:14.787049: step 149330, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 11h:32m:13s remains)
INFO - root - 2017-12-16 23:58:16.984794: step 149340, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 11h:06m:06s remains)
INFO - root - 2017-12-16 23:58:19.199226: step 149350, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 10h:59m:52s remains)
INFO - root - 2017-12-16 23:58:21.413338: step 149360, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 11h:24m:44s remains)
INFO - root - 2017-12-16 23:58:23.613355: step 149370, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 11h:20m:08s remains)
INFO - root - 2017-12-16 23:58:25.801740: step 149380, loss = 0.49, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 11h:11m:10s remains)
INFO - root - 2017-12-16 23:58:28.019352: step 149390, loss = 0.49, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 10h:53m:43s remains)
INFO - root - 2017-12-16 23:58:30.253271: step 149400, loss = 0.56, batch loss = 0.39 (35.4 examples/sec; 0.226 sec/batch; 11h:29m:32s remains)
INFO - root - 2017-12-16 23:58:32.582391: step 149410, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 11h:02m:42s remains)
INFO - root - 2017-12-16 23:58:34.804477: step 149420, loss = 0.57, batch loss = 0.39 (36.6 examples/sec; 0.219 sec/batch; 11h:07m:02s remains)
INFO - root - 2017-12-16 23:58:37.016746: step 149430, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 10h:53m:53s remains)
INFO - root - 2017-12-16 23:58:39.226546: step 149440, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 11h:12m:28s remains)
INFO - root - 2017-12-16 23:58:41.445235: step 149450, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 11h:02m:13s remains)
INFO - root - 2017-12-16 23:58:43.631178: step 149460, loss = 0.51, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 10h:52m:02s remains)
INFO - root - 2017-12-16 23:58:45.836027: step 149470, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 11h:35m:52s remains)
INFO - root - 2017-12-16 23:58:48.040648: step 149480, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 11h:17m:41s remains)
INFO - root - 2017-12-16 23:58:50.245455: step 149490, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 11h:10m:38s remains)
INFO - root - 2017-12-16 23:58:52.448057: step 149500, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 11h:26m:15s remains)
INFO - root - 2017-12-16 23:58:54.828517: step 149510, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 11h:08m:12s remains)
INFO - root - 2017-12-16 23:58:57.036636: step 149520, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 11h:15m:54s remains)
INFO - root - 2017-12-16 23:58:59.260182: step 149530, loss = 0.46, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 11h:16m:05s remains)
INFO - root - 2017-12-16 23:59:01.422742: step 149540, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 11h:08m:53s remains)
INFO - root - 2017-12-16 23:59:03.605770: step 149550, loss = 0.54, batch loss = 0.36 (36.0 examples/sec; 0.222 sec/batch; 11h:17m:07s remains)
INFO - root - 2017-12-16 23:59:05.804058: step 149560, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 11h:08m:04s remains)
INFO - root - 2017-12-16 23:59:07.986746: step 149570, loss = 0.47, batch loss = 0.29 (37.9 examples/sec; 0.211 sec/batch; 10h:42m:49s remains)
INFO - root - 2017-12-16 23:59:10.210405: step 149580, loss = 0.48, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 11h:05m:15s remains)
INFO - root - 2017-12-16 23:59:12.451233: step 149590, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 11h:29m:45s remains)
INFO - root - 2017-12-16 23:59:14.679303: step 149600, loss = 0.42, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 11h:15m:48s remains)
INFO - root - 2017-12-16 23:59:17.026007: step 149610, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 11h:22m:14s remains)
INFO - root - 2017-12-16 23:59:19.224693: step 149620, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 10h:49m:42s remains)
INFO - root - 2017-12-16 23:59:21.395806: step 149630, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 11h:21m:24s remains)
INFO - root - 2017-12-16 23:59:23.606960: step 149640, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 11h:28m:37s remains)
INFO - root - 2017-12-16 23:59:25.818952: step 149650, loss = 0.43, batch loss = 0.25 (37.8 examples/sec; 0.212 sec/batch; 10h:44m:53s remains)
INFO - root - 2017-12-16 23:59:28.033357: step 149660, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 11h:23m:00s remains)
INFO - root - 2017-12-16 23:59:30.275661: step 149670, loss = 0.56, batch loss = 0.38 (37.2 examples/sec; 0.215 sec/batch; 10h:54m:39s remains)
INFO - root - 2017-12-16 23:59:32.465902: step 149680, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 11h:06m:04s remains)
INFO - root - 2017-12-16 23:59:34.663788: step 149690, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 11h:00m:58s remains)
INFO - root - 2017-12-16 23:59:36.864911: step 149700, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 10h:46m:20s remains)
INFO - root - 2017-12-16 23:59:39.226708: step 149710, loss = 0.52, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 11h:08m:18s remains)
INFO - root - 2017-12-16 23:59:41.454497: step 149720, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 11h:16m:12s remains)
INFO - root - 2017-12-16 23:59:43.671083: step 149730, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 11h:06m:42s remains)
INFO - root - 2017-12-16 23:59:45.865824: step 149740, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 11h:14m:37s remains)
INFO - root - 2017-12-16 23:59:48.087493: step 149750, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 11h:02m:44s remains)
INFO - root - 2017-12-16 23:59:50.327128: step 149760, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 11h:31m:41s remains)
INFO - root - 2017-12-16 23:59:52.568162: step 149770, loss = 0.45, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 11h:14m:22s remains)
INFO - root - 2017-12-16 23:59:54.763384: step 149780, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 11h:01m:15s remains)
INFO - root - 2017-12-16 23:59:56.940066: step 149790, loss = 0.55, batch loss = 0.38 (37.3 examples/sec; 0.215 sec/batch; 10h:53m:52s remains)
INFO - root - 2017-12-16 23:59:59.138492: step 149800, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.226 sec/batch; 11h:26m:55s remains)
INFO - root - 2017-12-17 00:00:01.439585: step 149810, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 11h:04m:02s remains)
INFO - root - 2017-12-17 00:00:03.623391: step 149820, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 10h:54m:14s remains)
INFO - root - 2017-12-17 00:00:05.821244: step 149830, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 11h:09m:49s remains)
INFO - root - 2017-12-17 00:00:08.048371: step 149840, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 11h:05m:39s remains)
INFO - root - 2017-12-17 00:00:10.278447: step 149850, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 10h:52m:16s remains)
INFO - root - 2017-12-17 00:00:12.465236: step 149860, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 11h:20m:18s remains)
INFO - root - 2017-12-17 00:00:14.677250: step 149870, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 10h:53m:33s remains)
INFO - root - 2017-12-17 00:00:16.912676: step 149880, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 11h:08m:22s remains)
INFO - root - 2017-12-17 00:00:19.100918: step 149890, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 11h:24m:30s remains)
INFO - root - 2017-12-17 00:00:21.321502: step 149900, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 11h:31m:09s remains)
INFO - root - 2017-12-17 00:00:23.675679: step 149910, loss = 0.50, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 10h:58m:28s remains)
INFO - root - 2017-12-17 00:00:25.948312: step 149920, loss = 0.61, batch loss = 0.43 (35.6 examples/sec; 0.225 sec/batch; 11h:23m:56s remains)
INFO - root - 2017-12-17 00:00:28.178533: step 149930, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 11h:13m:05s remains)
INFO - root - 2017-12-17 00:00:30.388325: step 149940, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 11h:23m:30s remains)
INFO - root - 2017-12-17 00:00:32.616924: step 149950, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 10h:58m:14s remains)
INFO - root - 2017-12-17 00:00:34.806175: step 149960, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 10h:56m:05s remains)
INFO - root - 2017-12-17 00:00:37.032619: step 149970, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.230 sec/batch; 11h:41m:01s remains)
INFO - root - 2017-12-17 00:00:39.229519: step 149980, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 11h:13m:12s remains)
INFO - root - 2017-12-17 00:00:41.464177: step 149990, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 11h:01m:51s remains)
INFO - root - 2017-12-17 00:00:43.683725: step 150000, loss = 0.59, batch loss = 0.41 (36.1 examples/sec; 0.222 sec/batch; 11h:14m:41s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-150000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-150000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 00:00:46.698844: step 150010, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 11h:24m:16s remains)
INFO - root - 2017-12-17 00:00:48.923210: step 150020, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.233 sec/batch; 11h:47m:35s remains)
INFO - root - 2017-12-17 00:00:51.157208: step 150030, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.228 sec/batch; 11h:34m:17s remains)
INFO - root - 2017-12-17 00:00:53.358467: step 150040, loss = 0.43, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 10h:51m:13s remains)
INFO - root - 2017-12-17 00:00:55.553703: step 150050, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 11h:07m:22s remains)
INFO - root - 2017-12-17 00:00:57.754769: step 150060, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 11h:19m:45s remains)
INFO - root - 2017-12-17 00:00:59.943402: step 150070, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 11h:12m:43s remains)
INFO - root - 2017-12-17 00:01:02.194604: step 150080, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 11h:16m:16s remains)
INFO - root - 2017-12-17 00:01:04.426346: step 150090, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.214 sec/batch; 10h:49m:23s remains)
INFO - root - 2017-12-17 00:01:06.650084: step 150100, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 10h:49m:51s remains)
INFO - root - 2017-12-17 00:01:09.043020: step 150110, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 11h:20m:05s remains)
INFO - root - 2017-12-17 00:01:11.262987: step 150120, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 11h:08m:59s remains)
INFO - root - 2017-12-17 00:01:13.490562: step 150130, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 11h:00m:18s remains)
INFO - root - 2017-12-17 00:01:15.682096: step 150140, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 11h:06m:57s remains)
INFO - root - 2017-12-17 00:01:17.930239: step 150150, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 11h:30m:54s remains)
INFO - root - 2017-12-17 00:01:20.137344: step 150160, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 10h:53m:23s remains)
INFO - root - 2017-12-17 00:01:22.375175: step 150170, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 11h:07m:07s remains)
INFO - root - 2017-12-17 00:01:24.621673: step 150180, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.219 sec/batch; 11h:06m:58s remains)
INFO - root - 2017-12-17 00:01:26.831243: step 150190, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 11h:29m:28s remains)
INFO - root - 2017-12-17 00:01:29.024594: step 150200, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 11h:17m:43s remains)
INFO - root - 2017-12-17 00:01:31.385968: step 150210, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 11h:14m:56s remains)
INFO - root - 2017-12-17 00:01:33.615087: step 150220, loss = 0.46, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 11h:28m:56s remains)
INFO - root - 2017-12-17 00:01:35.839410: step 150230, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.218 sec/batch; 11h:03m:15s remains)
INFO - root - 2017-12-17 00:01:38.055584: step 150240, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 11h:06m:15s remains)
INFO - root - 2017-12-17 00:01:40.289578: step 150250, loss = 0.43, batch loss = 0.26 (37.8 examples/sec; 0.212 sec/batch; 10h:42m:47s remains)
INFO - root - 2017-12-17 00:01:42.493642: step 150260, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 11h:13m:09s remains)
INFO - root - 2017-12-17 00:01:44.753585: step 150270, loss = 0.42, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 10h:53m:28s remains)
INFO - root - 2017-12-17 00:01:46.955199: step 150280, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 11h:00m:17s remains)
INFO - root - 2017-12-17 00:01:49.143100: step 150290, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 11h:22m:38s remains)
INFO - root - 2017-12-17 00:01:51.359972: step 150300, loss = 0.46, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 11h:30m:19s remains)
INFO - root - 2017-12-17 00:01:53.710255: step 150310, loss = 0.43, batch loss = 0.25 (37.3 examples/sec; 0.215 sec/batch; 10h:51m:28s remains)
INFO - root - 2017-12-17 00:01:55.967628: step 150320, loss = 0.50, batch loss = 0.32 (37.5 examples/sec; 0.213 sec/batch; 10h:47m:20s remains)
INFO - root - 2017-12-17 00:01:58.192992: step 150330, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 11h:19m:24s remains)
INFO - root - 2017-12-17 00:02:00.421716: step 150340, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 11h:02m:15s remains)
INFO - root - 2017-12-17 00:02:02.664223: step 150350, loss = 0.45, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 10h:45m:19s remains)
INFO - root - 2017-12-17 00:02:04.885371: step 150360, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 10h:51m:48s remains)
INFO - root - 2017-12-17 00:02:07.168692: step 150370, loss = 0.46, batch loss = 0.28 (29.9 examples/sec; 0.267 sec/batch; 13h:31m:13s remains)
INFO - root - 2017-12-17 00:02:09.399324: step 150380, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 11h:11m:36s remains)
INFO - root - 2017-12-17 00:02:11.592043: step 150390, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 11h:07m:14s remains)
INFO - root - 2017-12-17 00:02:13.777155: step 150400, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 10h:58m:49s remains)
INFO - root - 2017-12-17 00:02:16.160156: step 150410, loss = 0.58, batch loss = 0.40 (35.6 examples/sec; 0.225 sec/batch; 11h:22m:56s remains)
INFO - root - 2017-12-17 00:02:18.343858: step 150420, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 10h:58m:27s remains)
INFO - root - 2017-12-17 00:02:20.551332: step 150430, loss = 0.46, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 11h:07m:12s remains)
INFO - root - 2017-12-17 00:02:22.758598: step 150440, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 11h:26m:01s remains)
INFO - root - 2017-12-17 00:02:24.965466: step 150450, loss = 0.50, batch loss = 0.32 (37.7 examples/sec; 0.212 sec/batch; 10h:43m:41s remains)
INFO - root - 2017-12-17 00:02:27.160403: step 150460, loss = 0.59, batch loss = 0.41 (36.7 examples/sec; 0.218 sec/batch; 11h:01m:18s remains)
INFO - root - 2017-12-17 00:02:29.369732: step 150470, loss = 0.57, batch loss = 0.40 (36.2 examples/sec; 0.221 sec/batch; 11h:09m:59s remains)
INFO - root - 2017-12-17 00:02:31.561137: step 150480, loss = 0.51, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 11h:01m:18s remains)
INFO - root - 2017-12-17 00:02:33.759436: step 150490, loss = 0.44, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 10h:45m:55s remains)
INFO - root - 2017-12-17 00:02:35.985050: step 150500, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 11h:00m:32s remains)
INFO - root - 2017-12-17 00:02:38.290478: step 150510, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 11h:08m:11s remains)
INFO - root - 2017-12-17 00:02:40.477633: step 150520, loss = 0.47, batch loss = 0.29 (37.9 examples/sec; 0.211 sec/batch; 10h:40m:07s remains)
INFO - root - 2017-12-17 00:02:42.681102: step 150530, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 11h:04m:01s remains)
INFO - root - 2017-12-17 00:02:44.891973: step 150540, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 11h:28m:39s remains)
INFO - root - 2017-12-17 00:02:47.129022: step 150550, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 11h:10m:28s remains)
INFO - root - 2017-12-17 00:02:49.314545: step 150560, loss = 0.56, batch loss = 0.39 (36.1 examples/sec; 0.221 sec/batch; 11h:11m:13s remains)
INFO - root - 2017-12-17 00:02:51.548695: step 150570, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 11h:29m:41s remains)
INFO - root - 2017-12-17 00:02:53.786065: step 150580, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 11h:16m:54s remains)
INFO - root - 2017-12-17 00:02:55.987273: step 150590, loss = 0.48, batch loss = 0.30 (37.8 examples/sec; 0.211 sec/batch; 10h:41m:13s remains)
INFO - root - 2017-12-17 00:02:58.198826: step 150600, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 10h:44m:48s remains)
INFO - root - 2017-12-17 00:03:00.539586: step 150610, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 11h:21m:46s remains)
INFO - root - 2017-12-17 00:03:02.736636: step 150620, loss = 0.48, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 10h:45m:35s remains)
INFO - root - 2017-12-17 00:03:04.972459: step 150630, loss = 0.56, batch loss = 0.39 (36.1 examples/sec; 0.221 sec/batch; 11h:11m:19s remains)
INFO - root - 2017-12-17 00:03:07.193518: step 150640, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 10h:58m:19s remains)
INFO - root - 2017-12-17 00:03:09.398860: step 150650, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 11h:12m:23s remains)
INFO - root - 2017-12-17 00:03:11.657427: step 150660, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.229 sec/batch; 11h:32m:42s remains)
INFO - root - 2017-12-17 00:03:13.902178: step 150670, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.224 sec/batch; 11h:20m:17s remains)
INFO - root - 2017-12-17 00:03:16.115249: step 150680, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 11h:13m:42s remains)
INFO - root - 2017-12-17 00:03:18.375079: step 150690, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 11h:06m:28s remains)
INFO - root - 2017-12-17 00:03:20.587550: step 150700, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 11h:07m:29s remains)
INFO - root - 2017-12-17 00:03:22.946088: step 150710, loss = 0.48, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 10h:57m:14s remains)
INFO - root - 2017-12-17 00:03:25.177474: step 150720, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 11h:13m:35s remains)
INFO - root - 2017-12-17 00:03:27.379167: step 150730, loss = 0.44, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 10h:54m:05s remains)
INFO - root - 2017-12-17 00:03:29.594405: step 150740, loss = 0.47, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 11h:16m:13s remains)
INFO - root - 2017-12-17 00:03:31.788436: step 150750, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 11h:05m:48s remains)
INFO - root - 2017-12-17 00:03:34.014365: step 150760, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 10h:49m:49s remains)
INFO - root - 2017-12-17 00:03:36.241220: step 150770, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 11h:00m:04s remains)
INFO - root - 2017-12-17 00:03:38.461792: step 150780, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.226 sec/batch; 11h:25m:52s remains)
INFO - root - 2017-12-17 00:03:40.675107: step 150790, loss = 0.57, batch loss = 0.39 (35.9 examples/sec; 0.223 sec/batch; 11h:15m:17s remains)
INFO - root - 2017-12-17 00:03:42.845637: step 150800, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.218 sec/batch; 11h:01m:17s remains)
INFO - root - 2017-12-17 00:03:45.172781: step 150810, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 11h:27m:36s remains)
INFO - root - 2017-12-17 00:03:47.388464: step 150820, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 11h:14m:41s remains)
INFO - root - 2017-12-17 00:03:49.604305: step 150830, loss = 0.46, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 11h:22m:52s remains)
INFO - root - 2017-12-17 00:03:51.810672: step 150840, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 11h:05m:27s remains)
INFO - root - 2017-12-17 00:03:54.006868: step 150850, loss = 0.54, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 11h:13m:59s remains)
INFO - root - 2017-12-17 00:03:56.216670: step 150860, loss = 0.45, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 11h:02m:25s remains)
INFO - root - 2017-12-17 00:03:58.455382: step 150870, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 11h:03m:54s remains)
INFO - root - 2017-12-17 00:04:00.650959: step 150880, loss = 0.54, batch loss = 0.36 (35.2 examples/sec; 0.227 sec/batch; 11h:27m:11s remains)
INFO - root - 2017-12-17 00:04:02.853314: step 150890, loss = 0.45, batch loss = 0.27 (33.9 examples/sec; 0.236 sec/batch; 11h:55m:16s remains)
INFO - root - 2017-12-17 00:04:05.080196: step 150900, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 11h:30m:18s remains)
INFO - root - 2017-12-17 00:04:07.428751: step 150910, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.217 sec/batch; 10h:55m:15s remains)
INFO - root - 2017-12-17 00:04:09.661334: step 150920, loss = 0.59, batch loss = 0.41 (34.2 examples/sec; 0.234 sec/batch; 11h:47m:06s remains)
INFO - root - 2017-12-17 00:04:11.875638: step 150930, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 11h:11m:27s remains)
INFO - root - 2017-12-17 00:04:14.084263: step 150940, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.214 sec/batch; 10h:46m:06s remains)
INFO - root - 2017-12-17 00:04:16.310215: step 150950, loss = 0.45, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 11h:04m:18s remains)
INFO - root - 2017-12-17 00:04:18.495815: step 150960, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 10h:48m:45s remains)
INFO - root - 2017-12-17 00:04:20.692703: step 150970, loss = 0.51, batch loss = 0.33 (37.6 examples/sec; 0.213 sec/batch; 10h:43m:29s remains)
INFO - root - 2017-12-17 00:04:22.884472: step 150980, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 11h:09m:49s remains)
INFO - root - 2017-12-17 00:04:25.123121: step 150990, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 10h:49m:45s remains)
INFO - root - 2017-12-17 00:04:27.323525: step 151000, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 10h:48m:19s remains)
INFO - root - 2017-12-17 00:04:29.676329: step 151010, loss = 0.56, batch loss = 0.38 (33.4 examples/sec; 0.240 sec/batch; 12h:04m:46s remains)
INFO - root - 2017-12-17 00:04:31.895742: step 151020, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 11h:06m:31s remains)
INFO - root - 2017-12-17 00:04:34.129539: step 151030, loss = 0.53, batch loss = 0.35 (35.0 examples/sec; 0.229 sec/batch; 11h:31m:26s remains)
INFO - root - 2017-12-17 00:04:36.376600: step 151040, loss = 0.45, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 11h:11m:19s remains)
INFO - root - 2017-12-17 00:04:38.571487: step 151050, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 11h:18m:18s remains)
INFO - root - 2017-12-17 00:04:40.788376: step 151060, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 11h:09m:59s remains)
INFO - root - 2017-12-17 00:04:43.009287: step 151070, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.224 sec/batch; 11h:18m:35s remains)
INFO - root - 2017-12-17 00:04:45.198365: step 151080, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 10h:49m:40s remains)
INFO - root - 2017-12-17 00:04:47.367388: step 151090, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 11h:02m:46s remains)
INFO - root - 2017-12-17 00:04:49.550050: step 151100, loss = 0.52, batch loss = 0.34 (35.0 examples/sec; 0.228 sec/batch; 11h:30m:22s remains)
INFO - root - 2017-12-17 00:04:51.888361: step 151110, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 10h:54m:10s remains)
INFO - root - 2017-12-17 00:04:54.078496: step 151120, loss = 0.47, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 10h:48m:18s remains)
INFO - root - 2017-12-17 00:04:56.292647: step 151130, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 10h:58m:01s remains)
INFO - root - 2017-12-17 00:04:58.508439: step 151140, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.224 sec/batch; 11h:18m:28s remains)
INFO - root - 2017-12-17 00:05:00.710845: step 151150, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 11h:12m:00s remains)
INFO - root - 2017-12-17 00:05:02.931584: step 151160, loss = 0.53, batch loss = 0.35 (34.3 examples/sec; 0.233 sec/batch; 11h:44m:02s remains)
INFO - root - 2017-12-17 00:05:05.133255: step 151170, loss = 0.56, batch loss = 0.39 (36.5 examples/sec; 0.219 sec/batch; 11h:02m:05s remains)
INFO - root - 2017-12-17 00:05:07.336651: step 151180, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 11h:14m:48s remains)
INFO - root - 2017-12-17 00:05:09.581768: step 151190, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 11h:08m:44s remains)
INFO - root - 2017-12-17 00:05:11.790373: step 151200, loss = 0.46, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 10h:51m:36s remains)
INFO - root - 2017-12-17 00:05:14.116349: step 151210, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 10h:42m:55s remains)
INFO - root - 2017-12-17 00:05:16.342854: step 151220, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 10h:49m:43s remains)
INFO - root - 2017-12-17 00:05:18.576587: step 151230, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 11h:12m:57s remains)
INFO - root - 2017-12-17 00:05:20.782751: step 151240, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 10h:45m:32s remains)
INFO - root - 2017-12-17 00:05:22.983716: step 151250, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 10h:58m:45s remains)
INFO - root - 2017-12-17 00:05:25.169307: step 151260, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 10h:52m:01s remains)
INFO - root - 2017-12-17 00:05:27.345365: step 151270, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.224 sec/batch; 11h:17m:56s remains)
INFO - root - 2017-12-17 00:05:29.535362: step 151280, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 10h:57m:10s remains)
INFO - root - 2017-12-17 00:05:31.712490: step 151290, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 11h:16m:33s remains)
INFO - root - 2017-12-17 00:05:33.928159: step 151300, loss = 0.43, batch loss = 0.26 (37.7 examples/sec; 0.212 sec/batch; 10h:40m:02s remains)
INFO - root - 2017-12-17 00:05:36.269711: step 151310, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 11h:06m:25s remains)
INFO - root - 2017-12-17 00:05:38.456287: step 151320, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 10h:55m:38s remains)
INFO - root - 2017-12-17 00:05:40.681600: step 151330, loss = 0.46, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 10h:53m:22s remains)
INFO - root - 2017-12-17 00:05:42.895826: step 151340, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 11h:12m:25s remains)
INFO - root - 2017-12-17 00:05:45.116102: step 151350, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 11h:10m:57s remains)
INFO - root - 2017-12-17 00:05:47.317538: step 151360, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.221 sec/batch; 11h:05m:58s remains)
INFO - root - 2017-12-17 00:05:49.547873: step 151370, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 11h:07m:44s remains)
INFO - root - 2017-12-17 00:05:51.764516: step 151380, loss = 0.54, batch loss = 0.36 (34.8 examples/sec; 0.230 sec/batch; 11h:33m:16s remains)
INFO - root - 2017-12-17 00:05:54.017496: step 151390, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 11h:00m:08s remains)
INFO - root - 2017-12-17 00:05:56.211922: step 151400, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 11h:11m:34s remains)
INFO - root - 2017-12-17 00:05:58.531909: step 151410, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 11h:13m:05s remains)
INFO - root - 2017-12-17 00:06:00.727585: step 151420, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 10h:50m:54s remains)
INFO - root - 2017-12-17 00:06:02.951568: step 151430, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 11h:14m:48s remains)
INFO - root - 2017-12-17 00:06:05.176523: step 151440, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 10h:49m:03s remains)
INFO - root - 2017-12-17 00:06:07.403681: step 151450, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 10h:57m:57s remains)
INFO - root - 2017-12-17 00:06:09.584243: step 151460, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 11h:13m:01s remains)
INFO - root - 2017-12-17 00:06:11.797936: step 151470, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 10h:55m:49s remains)
INFO - root - 2017-12-17 00:06:13.975124: step 151480, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 11h:20m:11s remains)
INFO - root - 2017-12-17 00:06:16.171954: step 151490, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 11h:22m:31s remains)
INFO - root - 2017-12-17 00:06:18.376053: step 151500, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 10h:50m:58s remains)
INFO - root - 2017-12-17 00:06:20.716210: step 151510, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 11h:23m:39s remains)
INFO - root - 2017-12-17 00:06:22.927943: step 151520, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 11h:11m:32s remains)
INFO - root - 2017-12-17 00:06:25.186729: step 151530, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 11h:13m:23s remains)
INFO - root - 2017-12-17 00:06:27.447840: step 151540, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.231 sec/batch; 11h:36m:03s remains)
INFO - root - 2017-12-17 00:06:29.691119: step 151550, loss = 0.46, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 11h:26m:43s remains)
INFO - root - 2017-12-17 00:06:31.907652: step 151560, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 10h:53m:10s remains)
INFO - root - 2017-12-17 00:06:34.146941: step 151570, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 10h:48m:34s remains)
INFO - root - 2017-12-17 00:06:36.347963: step 151580, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 11h:23m:47s remains)
INFO - root - 2017-12-17 00:06:38.602739: step 151590, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 11h:00m:06s remains)
INFO - root - 2017-12-17 00:06:40.782281: step 151600, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 11h:06m:10s remains)
INFO - root - 2017-12-17 00:06:43.093381: step 151610, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 11h:08m:32s remains)
INFO - root - 2017-12-17 00:06:45.303321: step 151620, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 10h:53m:42s remains)
INFO - root - 2017-12-17 00:06:47.572467: step 151630, loss = 0.44, batch loss = 0.26 (34.7 examples/sec; 0.231 sec/batch; 11h:35m:10s remains)
INFO - root - 2017-12-17 00:06:49.802881: step 151640, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 11h:06m:53s remains)
INFO - root - 2017-12-17 00:06:51.993281: step 151650, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 11h:07m:41s remains)
INFO - root - 2017-12-17 00:06:54.170223: step 151660, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 10h:56m:34s remains)
INFO - root - 2017-12-17 00:06:56.379931: step 151670, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 11h:03m:59s remains)
INFO - root - 2017-12-17 00:06:58.598730: step 151680, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 11h:29m:01s remains)
INFO - root - 2017-12-17 00:07:00.825083: step 151690, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 11h:16m:54s remains)
INFO - root - 2017-12-17 00:07:03.009913: step 151700, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 11h:07m:16s remains)
INFO - root - 2017-12-17 00:07:05.375931: step 151710, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.232 sec/batch; 11h:37m:41s remains)
INFO - root - 2017-12-17 00:07:07.612773: step 151720, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 11h:02m:41s remains)
INFO - root - 2017-12-17 00:07:09.842201: step 151730, loss = 0.43, batch loss = 0.25 (37.7 examples/sec; 0.212 sec/batch; 10h:39m:09s remains)
INFO - root - 2017-12-17 00:07:12.082423: step 151740, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.223 sec/batch; 11h:12m:56s remains)
INFO - root - 2017-12-17 00:07:14.290188: step 151750, loss = 0.46, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 11h:08m:07s remains)
INFO - root - 2017-12-17 00:07:16.494618: step 151760, loss = 0.58, batch loss = 0.40 (36.5 examples/sec; 0.219 sec/batch; 11h:00m:47s remains)
INFO - root - 2017-12-17 00:07:18.676547: step 151770, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 11h:04m:43s remains)
INFO - root - 2017-12-17 00:07:20.881231: step 151780, loss = 0.43, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 11h:17m:45s remains)
INFO - root - 2017-12-17 00:07:23.118777: step 151790, loss = 0.53, batch loss = 0.36 (35.8 examples/sec; 0.224 sec/batch; 11h:13m:27s remains)
INFO - root - 2017-12-17 00:07:25.324460: step 151800, loss = 0.46, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 10h:44m:00s remains)
INFO - root - 2017-12-17 00:07:27.676256: step 151810, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 11h:12m:21s remains)
INFO - root - 2017-12-17 00:07:29.889519: step 151820, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 10h:42m:12s remains)
INFO - root - 2017-12-17 00:07:32.116917: step 151830, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 11h:04m:46s remains)
INFO - root - 2017-12-17 00:07:34.325501: step 151840, loss = 0.56, batch loss = 0.38 (37.2 examples/sec; 0.215 sec/batch; 10h:47m:44s remains)
INFO - root - 2017-12-17 00:07:36.554901: step 151850, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 11h:11m:11s remains)
INFO - root - 2017-12-17 00:07:38.770741: step 151860, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 10h:41m:01s remains)
INFO - root - 2017-12-17 00:07:40.998974: step 151870, loss = 0.46, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 11h:22m:32s remains)
INFO - root - 2017-12-17 00:07:43.209938: step 151880, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 10h:52m:45s remains)
INFO - root - 2017-12-17 00:07:45.433598: step 151890, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 11h:01m:49s remains)
INFO - root - 2017-12-17 00:07:47.609580: step 151900, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 11h:09m:06s remains)
INFO - root - 2017-12-17 00:07:49.941326: step 151910, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 10h:55m:29s remains)
INFO - root - 2017-12-17 00:07:52.149518: step 151920, loss = 0.61, batch loss = 0.43 (35.4 examples/sec; 0.226 sec/batch; 11h:20m:11s remains)
INFO - root - 2017-12-17 00:07:54.375487: step 151930, loss = 0.46, batch loss = 0.28 (34.5 examples/sec; 0.232 sec/batch; 11h:38m:39s remains)
INFO - root - 2017-12-17 00:07:56.587069: step 151940, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 10h:59m:57s remains)
INFO - root - 2017-12-17 00:07:58.804834: step 151950, loss = 0.55, batch loss = 0.37 (36.6 examples/sec; 0.218 sec/batch; 10h:57m:26s remains)
INFO - root - 2017-12-17 00:08:01.047250: step 151960, loss = 0.42, batch loss = 0.24 (33.8 examples/sec; 0.236 sec/batch; 11h:51m:16s remains)
INFO - root - 2017-12-17 00:08:03.273115: step 151970, loss = 0.55, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 11h:00m:17s remains)
INFO - root - 2017-12-17 00:08:05.464405: step 151980, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.224 sec/batch; 11h:15m:17s remains)
INFO - root - 2017-12-17 00:08:07.682732: step 151990, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 10h:51m:22s remains)
INFO - root - 2017-12-17 00:08:09.876582: step 152000, loss = 0.45, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 11h:00m:31s remains)
INFO - root - 2017-12-17 00:08:12.206480: step 152010, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 11h:10m:43s remains)
INFO - root - 2017-12-17 00:08:14.427766: step 152020, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 11h:11m:55s remains)
INFO - root - 2017-12-17 00:08:16.645469: step 152030, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 11h:05m:58s remains)
INFO - root - 2017-12-17 00:08:18.856931: step 152040, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 10h:48m:42s remains)
INFO - root - 2017-12-17 00:08:21.073787: step 152050, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 11h:20m:44s remains)
INFO - root - 2017-12-17 00:08:23.282475: step 152060, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 10h:51m:32s remains)
INFO - root - 2017-12-17 00:08:25.495307: step 152070, loss = 0.48, batch loss = 0.31 (34.0 examples/sec; 0.235 sec/batch; 11h:47m:00s remains)
INFO - root - 2017-12-17 00:08:27.709608: step 152080, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 10h:55m:24s remains)
INFO - root - 2017-12-17 00:08:29.909323: step 152090, loss = 0.54, batch loss = 0.36 (37.3 examples/sec; 0.215 sec/batch; 10h:45m:20s remains)
INFO - root - 2017-12-17 00:08:32.154267: step 152100, loss = 0.53, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 11h:16m:07s remains)
INFO - root - 2017-12-17 00:08:34.565786: step 152110, loss = 0.47, batch loss = 0.29 (33.9 examples/sec; 0.236 sec/batch; 11h:49m:29s remains)
INFO - root - 2017-12-17 00:08:36.781253: step 152120, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 11h:15m:29s remains)
INFO - root - 2017-12-17 00:08:38.988705: step 152130, loss = 0.56, batch loss = 0.38 (36.0 examples/sec; 0.222 sec/batch; 11h:08m:45s remains)
INFO - root - 2017-12-17 00:08:41.190224: step 152140, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 10h:52m:55s remains)
INFO - root - 2017-12-17 00:08:43.425980: step 152150, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 11h:01m:02s remains)
INFO - root - 2017-12-17 00:08:45.634758: step 152160, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 10h:55m:28s remains)
INFO - root - 2017-12-17 00:08:47.890690: step 152170, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 10h:57m:41s remains)
INFO - root - 2017-12-17 00:08:50.110853: step 152180, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 10h:54m:43s remains)
INFO - root - 2017-12-17 00:08:52.339920: step 152190, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 11h:05m:29s remains)
INFO - root - 2017-12-17 00:08:54.584557: step 152200, loss = 0.51, batch loss = 0.34 (34.7 examples/sec; 0.230 sec/batch; 11h:32m:04s remains)
INFO - root - 2017-12-17 00:08:56.928836: step 152210, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 11h:20m:42s remains)
INFO - root - 2017-12-17 00:08:59.130690: step 152220, loss = 0.47, batch loss = 0.30 (34.7 examples/sec; 0.230 sec/batch; 11h:31m:57s remains)
INFO - root - 2017-12-17 00:09:01.378305: step 152230, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 11h:24m:55s remains)
INFO - root - 2017-12-17 00:09:03.594638: step 152240, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 11h:07m:14s remains)
INFO - root - 2017-12-17 00:09:05.823983: step 152250, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 11h:09m:15s remains)
INFO - root - 2017-12-17 00:09:08.044925: step 152260, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 11h:16m:36s remains)
INFO - root - 2017-12-17 00:09:10.287735: step 152270, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 11h:21m:57s remains)
INFO - root - 2017-12-17 00:09:12.516576: step 152280, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 11h:00m:26s remains)
INFO - root - 2017-12-17 00:09:14.734364: step 152290, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 11h:18m:56s remains)
INFO - root - 2017-12-17 00:09:16.923393: step 152300, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 11h:03m:11s remains)
INFO - root - 2017-12-17 00:09:19.250898: step 152310, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 11h:34m:53s remains)
INFO - root - 2017-12-17 00:09:21.460534: step 152320, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 11h:28m:20s remains)
INFO - root - 2017-12-17 00:09:23.645586: step 152330, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 10h:53m:58s remains)
INFO - root - 2017-12-17 00:09:25.856896: step 152340, loss = 0.51, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 11h:08m:51s remains)
INFO - root - 2017-12-17 00:09:28.074926: step 152350, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 11h:09m:58s remains)
INFO - root - 2017-12-17 00:09:30.321257: step 152360, loss = 0.48, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 11h:11m:08s remains)
INFO - root - 2017-12-17 00:09:32.541204: step 152370, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 11h:00m:20s remains)
INFO - root - 2017-12-17 00:09:34.772705: step 152380, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.216 sec/batch; 10h:47m:22s remains)
INFO - root - 2017-12-17 00:09:36.991218: step 152390, loss = 0.43, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 11h:20m:35s remains)
INFO - root - 2017-12-17 00:09:39.191113: step 152400, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 10h:49m:59s remains)
INFO - root - 2017-12-17 00:09:41.519179: step 152410, loss = 0.49, batch loss = 0.31 (38.0 examples/sec; 0.211 sec/batch; 10h:31m:59s remains)
INFO - root - 2017-12-17 00:09:43.750116: step 152420, loss = 0.42, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 11h:03m:56s remains)
INFO - root - 2017-12-17 00:09:46.020421: step 152430, loss = 0.51, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 11h:06m:56s remains)
INFO - root - 2017-12-17 00:09:48.252260: step 152440, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 11h:15m:27s remains)
INFO - root - 2017-12-17 00:09:50.449506: step 152450, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 11h:00m:03s remains)
INFO - root - 2017-12-17 00:09:52.671350: step 152460, loss = 0.47, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 10h:58m:51s remains)
INFO - root - 2017-12-17 00:09:54.917815: step 152470, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 11h:16m:36s remains)
INFO - root - 2017-12-17 00:09:57.129186: step 152480, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 10h:49m:39s remains)
INFO - root - 2017-12-17 00:09:59.350173: step 152490, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 10h:59m:53s remains)
INFO - root - 2017-12-17 00:10:01.591137: step 152500, loss = 0.45, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 11h:09m:41s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-152500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-152500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 00:10:04.473528: step 152510, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 10h:49m:40s remains)
INFO - root - 2017-12-17 00:10:06.717148: step 152520, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 10h:57m:15s remains)
INFO - root - 2017-12-17 00:10:08.938968: step 152530, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 10h:59m:17s remains)
INFO - root - 2017-12-17 00:10:11.173211: step 152540, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 10h:34m:37s remains)
INFO - root - 2017-12-17 00:10:13.327096: step 152550, loss = 0.46, batch loss = 0.28 (37.9 examples/sec; 0.211 sec/batch; 10h:32m:57s remains)
INFO - root - 2017-12-17 00:10:15.532623: step 152560, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 11h:05m:50s remains)
INFO - root - 2017-12-17 00:10:17.754823: step 152570, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 11h:09m:43s remains)
INFO - root - 2017-12-17 00:10:19.994512: step 152580, loss = 0.64, batch loss = 0.46 (32.9 examples/sec; 0.243 sec/batch; 12h:09m:39s remains)
INFO - root - 2017-12-17 00:10:22.223042: step 152590, loss = 0.50, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 10h:47m:24s remains)
INFO - root - 2017-12-17 00:10:24.431556: step 152600, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 11h:12m:40s remains)
INFO - root - 2017-12-17 00:10:26.769537: step 152610, loss = 0.54, batch loss = 0.36 (36.4 examples/sec; 0.220 sec/batch; 10h:58m:07s remains)
INFO - root - 2017-12-17 00:10:28.957156: step 152620, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 11h:00m:30s remains)
INFO - root - 2017-12-17 00:10:31.181096: step 152630, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 10h:48m:07s remains)
INFO - root - 2017-12-17 00:10:33.467683: step 152640, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 11h:02m:02s remains)
INFO - root - 2017-12-17 00:10:35.686923: step 152650, loss = 0.50, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 11h:00m:27s remains)
INFO - root - 2017-12-17 00:10:37.927004: step 152660, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 11h:05m:48s remains)
INFO - root - 2017-12-17 00:10:40.126339: step 152670, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 10h:55m:24s remains)
INFO - root - 2017-12-17 00:10:42.339796: step 152680, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 11h:09m:10s remains)
INFO - root - 2017-12-17 00:10:44.575547: step 152690, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 10h:50m:16s remains)
INFO - root - 2017-12-17 00:10:46.801277: step 152700, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 11h:01m:55s remains)
INFO - root - 2017-12-17 00:10:49.140651: step 152710, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 11h:04m:52s remains)
INFO - root - 2017-12-17 00:10:51.359674: step 152720, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 10h:48m:30s remains)
INFO - root - 2017-12-17 00:10:53.589260: step 152730, loss = 0.48, batch loss = 0.30 (33.2 examples/sec; 0.241 sec/batch; 12h:01m:21s remains)
INFO - root - 2017-12-17 00:10:55.788797: step 152740, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 10h:50m:34s remains)
INFO - root - 2017-12-17 00:10:57.993032: step 152750, loss = 0.52, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 11h:20m:57s remains)
INFO - root - 2017-12-17 00:11:00.207702: step 152760, loss = 0.53, batch loss = 0.35 (34.0 examples/sec; 0.235 sec/batch; 11h:45m:04s remains)
INFO - root - 2017-12-17 00:11:02.413045: step 152770, loss = 0.58, batch loss = 0.40 (35.8 examples/sec; 0.223 sec/batch; 11h:09m:24s remains)
INFO - root - 2017-12-17 00:11:04.631314: step 152780, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 10h:55m:21s remains)
INFO - root - 2017-12-17 00:11:06.848422: step 152790, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.226 sec/batch; 11h:18m:14s remains)
INFO - root - 2017-12-17 00:11:09.085893: step 152800, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 11h:08m:31s remains)
INFO - root - 2017-12-17 00:11:11.422035: step 152810, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 10h:56m:26s remains)
INFO - root - 2017-12-17 00:11:13.634295: step 152820, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 11h:11m:25s remains)
INFO - root - 2017-12-17 00:11:15.882433: step 152830, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 11h:01m:44s remains)
INFO - root - 2017-12-17 00:11:18.054840: step 152840, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 10h:43m:37s remains)
INFO - root - 2017-12-17 00:11:20.269746: step 152850, loss = 0.45, batch loss = 0.27 (33.1 examples/sec; 0.241 sec/batch; 12h:02m:54s remains)
INFO - root - 2017-12-17 00:11:22.491720: step 152860, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 11h:08m:00s remains)
INFO - root - 2017-12-17 00:11:24.728703: step 152870, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 10h:44m:19s remains)
INFO - root - 2017-12-17 00:11:26.915429: step 152880, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 10h:49m:04s remains)
INFO - root - 2017-12-17 00:11:29.170916: step 152890, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 11h:06m:15s remains)
INFO - root - 2017-12-17 00:11:31.394484: step 152900, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 10h:51m:41s remains)
INFO - root - 2017-12-17 00:11:33.732040: step 152910, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 10h:53m:01s remains)
INFO - root - 2017-12-17 00:11:35.930515: step 152920, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 10h:49m:51s remains)
INFO - root - 2017-12-17 00:11:38.131516: step 152930, loss = 0.54, batch loss = 0.36 (37.3 examples/sec; 0.215 sec/batch; 10h:42m:08s remains)
INFO - root - 2017-12-17 00:11:40.343193: step 152940, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 10h:53m:45s remains)
INFO - root - 2017-12-17 00:11:42.534458: step 152950, loss = 0.59, batch loss = 0.41 (35.8 examples/sec; 0.224 sec/batch; 11h:09m:26s remains)
INFO - root - 2017-12-17 00:11:44.731793: step 152960, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 10h:47m:28s remains)
INFO - root - 2017-12-17 00:11:46.965843: step 152970, loss = 0.44, batch loss = 0.26 (37.5 examples/sec; 0.213 sec/batch; 10h:38m:26s remains)
INFO - root - 2017-12-17 00:11:49.197628: step 152980, loss = 0.42, batch loss = 0.24 (34.7 examples/sec; 0.231 sec/batch; 11h:30m:03s remains)
INFO - root - 2017-12-17 00:11:51.424265: step 152990, loss = 0.46, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 10h:53m:51s remains)
INFO - root - 2017-12-17 00:11:53.619326: step 153000, loss = 0.42, batch loss = 0.24 (35.6 examples/sec; 0.225 sec/batch; 11h:12m:08s remains)
INFO - root - 2017-12-17 00:11:56.006599: step 153010, loss = 0.44, batch loss = 0.26 (33.8 examples/sec; 0.237 sec/batch; 11h:48m:39s remains)
INFO - root - 2017-12-17 00:11:58.210373: step 153020, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 10h:50m:59s remains)
INFO - root - 2017-12-17 00:12:00.467741: step 153030, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 11h:00m:03s remains)
INFO - root - 2017-12-17 00:12:02.669049: step 153040, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 10h:46m:23s remains)
INFO - root - 2017-12-17 00:12:04.912793: step 153050, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 11h:18m:00s remains)
INFO - root - 2017-12-17 00:12:07.123828: step 153060, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 10h:59m:48s remains)
INFO - root - 2017-12-17 00:12:09.362297: step 153070, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 11h:16m:31s remains)
INFO - root - 2017-12-17 00:12:11.566316: step 153080, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 10h:33m:25s remains)
INFO - root - 2017-12-17 00:12:13.778972: step 153090, loss = 0.43, batch loss = 0.25 (37.5 examples/sec; 0.213 sec/batch; 10h:37m:54s remains)
INFO - root - 2017-12-17 00:12:16.016053: step 153100, loss = 0.47, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 11h:06m:44s remains)
INFO - root - 2017-12-17 00:12:18.337173: step 153110, loss = 0.42, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 11h:01m:18s remains)
INFO - root - 2017-12-17 00:12:20.563305: step 153120, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 11h:10m:08s remains)
INFO - root - 2017-12-17 00:12:22.766001: step 153130, loss = 0.51, batch loss = 0.33 (35.0 examples/sec; 0.229 sec/batch; 11h:23m:11s remains)
INFO - root - 2017-12-17 00:12:25.013145: step 153140, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 10h:50m:27s remains)
INFO - root - 2017-12-17 00:12:27.237762: step 153150, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 10h:56m:12s remains)
INFO - root - 2017-12-17 00:12:29.420926: step 153160, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 10h:43m:37s remains)
INFO - root - 2017-12-17 00:12:31.611486: step 153170, loss = 0.48, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 11h:08m:19s remains)
INFO - root - 2017-12-17 00:12:33.821247: step 153180, loss = 0.56, batch loss = 0.38 (36.4 examples/sec; 0.220 sec/batch; 10h:56m:16s remains)
INFO - root - 2017-12-17 00:12:36.053097: step 153190, loss = 0.52, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 11h:18m:50s remains)
INFO - root - 2017-12-17 00:12:38.289796: step 153200, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 11h:11m:24s remains)
INFO - root - 2017-12-17 00:12:40.656300: step 153210, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 10h:55m:19s remains)
INFO - root - 2017-12-17 00:12:42.869557: step 153220, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 10h:58m:32s remains)
INFO - root - 2017-12-17 00:12:45.083411: step 153230, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 10h:43m:21s remains)
INFO - root - 2017-12-17 00:12:47.284452: step 153240, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 11h:20m:28s remains)
INFO - root - 2017-12-17 00:12:49.521236: step 153250, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 10h:59m:56s remains)
INFO - root - 2017-12-17 00:12:51.723442: step 153260, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 11h:04m:52s remains)
INFO - root - 2017-12-17 00:12:53.930280: step 153270, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 10h:59m:40s remains)
INFO - root - 2017-12-17 00:12:56.140611: step 153280, loss = 0.52, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 11h:18m:44s remains)
INFO - root - 2017-12-17 00:12:58.359160: step 153290, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 10h:57m:49s remains)
INFO - root - 2017-12-17 00:13:00.579131: step 153300, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 10h:37m:26s remains)
INFO - root - 2017-12-17 00:13:02.935949: step 153310, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 11h:08m:55s remains)
INFO - root - 2017-12-17 00:13:05.173800: step 153320, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 11h:07m:08s remains)
INFO - root - 2017-12-17 00:13:07.403898: step 153330, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 10h:52m:05s remains)
INFO - root - 2017-12-17 00:13:09.612566: step 153340, loss = 0.41, batch loss = 0.23 (36.9 examples/sec; 0.217 sec/batch; 10h:46m:45s remains)
INFO - root - 2017-12-17 00:13:11.810503: step 153350, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 10h:41m:26s remains)
INFO - root - 2017-12-17 00:13:14.029713: step 153360, loss = 0.42, batch loss = 0.24 (35.9 examples/sec; 0.223 sec/batch; 11h:05m:46s remains)
INFO - root - 2017-12-17 00:13:16.247788: step 153370, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 11h:16m:54s remains)
INFO - root - 2017-12-17 00:13:18.477974: step 153380, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 10h:46m:15s remains)
INFO - root - 2017-12-17 00:13:20.668276: step 153390, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.218 sec/batch; 10h:49m:18s remains)
INFO - root - 2017-12-17 00:13:22.855044: step 153400, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 10h:34m:11s remains)
INFO - root - 2017-12-17 00:13:25.206423: step 153410, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 10h:47m:42s remains)
INFO - root - 2017-12-17 00:13:27.440996: step 153420, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 10h:59m:50s remains)
INFO - root - 2017-12-17 00:13:29.649559: step 153430, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 11h:04m:36s remains)
INFO - root - 2017-12-17 00:13:31.884616: step 153440, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 11h:08m:39s remains)
INFO - root - 2017-12-17 00:13:34.117011: step 153450, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 10h:49m:49s remains)
INFO - root - 2017-12-17 00:13:36.322292: step 153460, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 11h:00m:48s remains)
INFO - root - 2017-12-17 00:13:38.519584: step 153470, loss = 0.55, batch loss = 0.37 (38.1 examples/sec; 0.210 sec/batch; 10h:26m:19s remains)
INFO - root - 2017-12-17 00:13:40.741238: step 153480, loss = 0.42, batch loss = 0.24 (37.1 examples/sec; 0.216 sec/batch; 10h:43m:16s remains)
INFO - root - 2017-12-17 00:13:42.984107: step 153490, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 10h:51m:29s remains)
INFO - root - 2017-12-17 00:13:45.202393: step 153500, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 11h:07m:58s remains)
INFO - root - 2017-12-17 00:13:47.588071: step 153510, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 11h:01m:02s remains)
INFO - root - 2017-12-17 00:13:49.792918: step 153520, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 11h:10m:32s remains)
INFO - root - 2017-12-17 00:13:51.979195: step 153530, loss = 0.52, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 10h:48m:12s remains)
INFO - root - 2017-12-17 00:13:54.202256: step 153540, loss = 0.45, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 10h:42m:14s remains)
INFO - root - 2017-12-17 00:13:56.435762: step 153550, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 10h:53m:16s remains)
INFO - root - 2017-12-17 00:13:58.654198: step 153560, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.215 sec/batch; 10h:40m:27s remains)
INFO - root - 2017-12-17 00:14:00.871622: step 153570, loss = 0.51, batch loss = 0.33 (34.9 examples/sec; 0.229 sec/batch; 11h:22m:37s remains)
INFO - root - 2017-12-17 00:14:03.109897: step 153580, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 11h:05m:15s remains)
INFO - root - 2017-12-17 00:14:05.313641: step 153590, loss = 0.42, batch loss = 0.25 (36.6 examples/sec; 0.218 sec/batch; 10h:51m:09s remains)
INFO - root - 2017-12-17 00:14:07.519982: step 153600, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 10h:56m:21s remains)
INFO - root - 2017-12-17 00:14:09.909686: step 153610, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 10h:51m:29s remains)
INFO - root - 2017-12-17 00:14:12.109541: step 153620, loss = 0.44, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 10h:50m:30s remains)
INFO - root - 2017-12-17 00:14:14.320377: step 153630, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 11h:01m:11s remains)
INFO - root - 2017-12-17 00:14:16.518621: step 153640, loss = 0.55, batch loss = 0.38 (36.4 examples/sec; 0.220 sec/batch; 10h:55m:33s remains)
INFO - root - 2017-12-17 00:14:18.744064: step 153650, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 10h:57m:37s remains)
INFO - root - 2017-12-17 00:14:20.994215: step 153660, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 11h:12m:45s remains)
INFO - root - 2017-12-17 00:14:23.200254: step 153670, loss = 0.42, batch loss = 0.24 (34.6 examples/sec; 0.231 sec/batch; 11h:28m:44s remains)
INFO - root - 2017-12-17 00:14:25.413491: step 153680, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 11h:02m:41s remains)
INFO - root - 2017-12-17 00:14:27.614653: step 153690, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 11h:03m:20s remains)
INFO - root - 2017-12-17 00:14:29.795862: step 153700, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 10h:56m:22s remains)
INFO - root - 2017-12-17 00:14:32.138209: step 153710, loss = 0.56, batch loss = 0.38 (35.0 examples/sec; 0.228 sec/batch; 11h:20m:44s remains)
INFO - root - 2017-12-17 00:14:34.389684: step 153720, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 10h:55m:00s remains)
INFO - root - 2017-12-17 00:14:36.590758: step 153730, loss = 0.47, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 10h:38m:40s remains)
INFO - root - 2017-12-17 00:14:38.870783: step 153740, loss = 0.51, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 11h:04m:10s remains)
INFO - root - 2017-12-17 00:14:41.079986: step 153750, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 10h:46m:29s remains)
INFO - root - 2017-12-17 00:14:43.263701: step 153760, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 10h:49m:53s remains)
INFO - root - 2017-12-17 00:14:45.453504: step 153770, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 10h:42m:11s remains)
INFO - root - 2017-12-17 00:14:47.642324: step 153780, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 10h:45m:32s remains)
INFO - root - 2017-12-17 00:14:49.840448: step 153790, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 10h:35m:01s remains)
INFO - root - 2017-12-17 00:14:52.032948: step 153800, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 10h:44m:11s remains)
INFO - root - 2017-12-17 00:14:54.372003: step 153810, loss = 0.54, batch loss = 0.36 (34.3 examples/sec; 0.233 sec/batch; 11h:35m:13s remains)
INFO - root - 2017-12-17 00:14:56.607782: step 153820, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 10h:47m:35s remains)
INFO - root - 2017-12-17 00:14:58.835581: step 153830, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 11h:11m:56s remains)
INFO - root - 2017-12-17 00:15:01.083372: step 153840, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.218 sec/batch; 10h:50m:18s remains)
INFO - root - 2017-12-17 00:15:03.324892: step 153850, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.224 sec/batch; 11h:08m:09s remains)
INFO - root - 2017-12-17 00:15:05.541648: step 153860, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 10h:53m:19s remains)
INFO - root - 2017-12-17 00:15:07.831090: step 153870, loss = 0.47, batch loss = 0.29 (34.3 examples/sec; 0.233 sec/batch; 11h:33m:35s remains)
INFO - root - 2017-12-17 00:15:10.080727: step 153880, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 10h:48m:26s remains)
INFO - root - 2017-12-17 00:15:12.329048: step 153890, loss = 0.61, batch loss = 0.43 (35.0 examples/sec; 0.228 sec/batch; 11h:20m:00s remains)
INFO - root - 2017-12-17 00:15:14.516915: step 153900, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 10h:53m:35s remains)
INFO - root - 2017-12-17 00:15:16.873154: step 153910, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 11h:14m:33s remains)
INFO - root - 2017-12-17 00:15:19.080785: step 153920, loss = 0.50, batch loss = 0.32 (37.7 examples/sec; 0.212 sec/batch; 10h:31m:48s remains)
INFO - root - 2017-12-17 00:15:21.277785: step 153930, loss = 0.54, batch loss = 0.36 (36.0 examples/sec; 0.222 sec/batch; 11h:00m:36s remains)
INFO - root - 2017-12-17 00:15:23.490961: step 153940, loss = 0.51, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 11h:02m:16s remains)
INFO - root - 2017-12-17 00:15:25.710737: step 153950, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 10h:59m:19s remains)
INFO - root - 2017-12-17 00:15:27.916367: step 153960, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 11h:03m:00s remains)
INFO - root - 2017-12-17 00:15:30.108964: step 153970, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 10h:56m:05s remains)
INFO - root - 2017-12-17 00:15:32.352586: step 153980, loss = 0.46, batch loss = 0.28 (33.7 examples/sec; 0.237 sec/batch; 11h:45m:37s remains)
INFO - root - 2017-12-17 00:15:34.611971: step 153990, loss = 0.45, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 11h:26m:19s remains)
INFO - root - 2017-12-17 00:15:36.803327: step 154000, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 11h:18m:57s remains)
INFO - root - 2017-12-17 00:15:39.157422: step 154010, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 10h:56m:59s remains)
INFO - root - 2017-12-17 00:15:41.372043: step 154020, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 10h:50m:14s remains)
INFO - root - 2017-12-17 00:15:43.575140: step 154030, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 11h:03m:52s remains)
INFO - root - 2017-12-17 00:15:45.806325: step 154040, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 10h:33m:43s remains)
INFO - root - 2017-12-17 00:15:47.991252: step 154050, loss = 0.46, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 10h:45m:57s remains)
INFO - root - 2017-12-17 00:15:50.186758: step 154060, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 10h:49m:52s remains)
INFO - root - 2017-12-17 00:15:52.414239: step 154070, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 11h:07m:18s remains)
INFO - root - 2017-12-17 00:15:54.640140: step 154080, loss = 0.44, batch loss = 0.26 (34.7 examples/sec; 0.231 sec/batch; 11h:25m:38s remains)
INFO - root - 2017-12-17 00:15:56.890911: step 154090, loss = 0.47, batch loss = 0.29 (33.6 examples/sec; 0.238 sec/batch; 11h:47m:24s remains)
INFO - root - 2017-12-17 00:15:59.120866: step 154100, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 10h:55m:35s remains)
INFO - root - 2017-12-17 00:16:01.463954: step 154110, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 11h:29m:48s remains)
INFO - root - 2017-12-17 00:16:03.723213: step 154120, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 10h:55m:24s remains)
INFO - root - 2017-12-17 00:16:05.961169: step 154130, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 11h:03m:12s remains)
INFO - root - 2017-12-17 00:16:08.163109: step 154140, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 10h:52m:12s remains)
INFO - root - 2017-12-17 00:16:10.392045: step 154150, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 10h:59m:02s remains)
INFO - root - 2017-12-17 00:16:12.607383: step 154160, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 10h:56m:44s remains)
INFO - root - 2017-12-17 00:16:14.821003: step 154170, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 10h:33m:31s remains)
INFO - root - 2017-12-17 00:16:17.075811: step 154180, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 10h:44m:50s remains)
INFO - root - 2017-12-17 00:16:19.302161: step 154190, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 11h:00m:26s remains)
INFO - root - 2017-12-17 00:16:21.532132: step 154200, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 10h:46m:52s remains)
INFO - root - 2017-12-17 00:16:23.890342: step 154210, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 11h:08m:49s remains)
INFO - root - 2017-12-17 00:16:26.142395: step 154220, loss = 0.47, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 11h:35m:11s remains)
INFO - root - 2017-12-17 00:16:28.362028: step 154230, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 10h:44m:09s remains)
INFO - root - 2017-12-17 00:16:30.591421: step 154240, loss = 0.56, batch loss = 0.38 (36.5 examples/sec; 0.219 sec/batch; 10h:51m:19s remains)
INFO - root - 2017-12-17 00:16:32.821920: step 154250, loss = 0.44, batch loss = 0.26 (37.7 examples/sec; 0.212 sec/batch; 10h:31m:01s remains)
INFO - root - 2017-12-17 00:16:35.035441: step 154260, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 11h:10m:15s remains)
INFO - root - 2017-12-17 00:16:37.230217: step 154270, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.218 sec/batch; 10h:46m:11s remains)
INFO - root - 2017-12-17 00:16:39.420561: step 154280, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 10h:56m:36s remains)
INFO - root - 2017-12-17 00:16:41.628008: step 154290, loss = 0.43, batch loss = 0.25 (35.2 examples/sec; 0.227 sec/batch; 11h:15m:20s remains)
INFO - root - 2017-12-17 00:16:43.837851: step 154300, loss = 0.53, batch loss = 0.35 (35.1 examples/sec; 0.228 sec/batch; 11h:17m:19s remains)
INFO - root - 2017-12-17 00:16:46.198303: step 154310, loss = 0.51, batch loss = 0.33 (34.3 examples/sec; 0.234 sec/batch; 11h:33m:34s remains)
INFO - root - 2017-12-17 00:16:48.390626: step 154320, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 11h:05m:03s remains)
INFO - root - 2017-12-17 00:16:50.582244: step 154330, loss = 0.43, batch loss = 0.25 (34.8 examples/sec; 0.230 sec/batch; 11h:23m:14s remains)
INFO - root - 2017-12-17 00:16:52.815522: step 154340, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 10h:52m:07s remains)
INFO - root - 2017-12-17 00:16:54.998785: step 154350, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 10h:42m:53s remains)
INFO - root - 2017-12-17 00:16:57.237339: step 154360, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 10h:43m:50s remains)
INFO - root - 2017-12-17 00:16:59.468210: step 154370, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 10h:45m:34s remains)
INFO - root - 2017-12-17 00:17:01.670627: step 154380, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.224 sec/batch; 11h:06m:27s remains)
INFO - root - 2017-12-17 00:17:03.892485: step 154390, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 11h:14m:27s remains)
INFO - root - 2017-12-17 00:17:06.123051: step 154400, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 10h:52m:13s remains)
INFO - root - 2017-12-17 00:17:08.470032: step 154410, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 11h:04m:48s remains)
INFO - root - 2017-12-17 00:17:10.663403: step 154420, loss = 0.47, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 10h:51m:39s remains)
INFO - root - 2017-12-17 00:17:12.912495: step 154430, loss = 0.53, batch loss = 0.35 (34.1 examples/sec; 0.234 sec/batch; 11h:35m:38s remains)
INFO - root - 2017-12-17 00:17:15.126094: step 154440, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 11h:12m:44s remains)
INFO - root - 2017-12-17 00:17:17.338773: step 154450, loss = 0.50, batch loss = 0.32 (35.0 examples/sec; 0.228 sec/batch; 11h:17m:23s remains)
INFO - root - 2017-12-17 00:17:19.546902: step 154460, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 11h:05m:41s remains)
INFO - root - 2017-12-17 00:17:21.754289: step 154470, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 10h:48m:27s remains)
INFO - root - 2017-12-17 00:17:23.971294: step 154480, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 11h:04m:25s remains)
INFO - root - 2017-12-17 00:17:26.204754: step 154490, loss = 0.47, batch loss = 0.29 (34.0 examples/sec; 0.236 sec/batch; 11h:38m:58s remains)
INFO - root - 2017-12-17 00:17:28.402836: step 154500, loss = 0.55, batch loss = 0.37 (37.1 examples/sec; 0.215 sec/batch; 10h:38m:57s remains)
INFO - root - 2017-12-17 00:17:30.740780: step 154510, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 10h:42m:54s remains)
INFO - root - 2017-12-17 00:17:32.959938: step 154520, loss = 0.42, batch loss = 0.24 (35.9 examples/sec; 0.223 sec/batch; 11h:00m:31s remains)
INFO - root - 2017-12-17 00:17:35.170017: step 154530, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 11h:01m:24s remains)
INFO - root - 2017-12-17 00:17:37.404611: step 154540, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 10h:51m:08s remains)
INFO - root - 2017-12-17 00:17:39.597970: step 154550, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 10h:49m:00s remains)
INFO - root - 2017-12-17 00:17:41.840957: step 154560, loss = 0.52, batch loss = 0.34 (37.5 examples/sec; 0.214 sec/batch; 10h:33m:15s remains)
INFO - root - 2017-12-17 00:17:44.077821: step 154570, loss = 0.48, batch loss = 0.30 (34.7 examples/sec; 0.230 sec/batch; 11h:22m:46s remains)
INFO - root - 2017-12-17 00:17:46.290969: step 154580, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 10h:57m:57s remains)
INFO - root - 2017-12-17 00:17:48.493361: step 154590, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 10h:56m:58s remains)
INFO - root - 2017-12-17 00:17:50.671027: step 154600, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 10h:31m:06s remains)
INFO - root - 2017-12-17 00:17:53.057795: step 154610, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 10h:55m:49s remains)
INFO - root - 2017-12-17 00:17:55.253663: step 154620, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 10h:53m:24s remains)
INFO - root - 2017-12-17 00:17:57.495250: step 154630, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 11h:05m:53s remains)
INFO - root - 2017-12-17 00:17:59.715721: step 154640, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 11h:02m:24s remains)
INFO - root - 2017-12-17 00:18:01.965150: step 154650, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 11h:09m:37s remains)
INFO - root - 2017-12-17 00:18:04.241593: step 154660, loss = 0.57, batch loss = 0.39 (36.7 examples/sec; 0.218 sec/batch; 10h:46m:49s remains)
INFO - root - 2017-12-17 00:18:06.490835: step 154670, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 11h:03m:03s remains)
INFO - root - 2017-12-17 00:18:08.742704: step 154680, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 11h:25m:30s remains)
INFO - root - 2017-12-17 00:18:10.952912: step 154690, loss = 0.48, batch loss = 0.30 (37.9 examples/sec; 0.211 sec/batch; 10h:25m:41s remains)
INFO - root - 2017-12-17 00:18:13.162313: step 154700, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 10h:49m:49s remains)
INFO - root - 2017-12-17 00:18:15.572454: step 154710, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 10h:54m:00s remains)
INFO - root - 2017-12-17 00:18:17.812397: step 154720, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 11h:00m:59s remains)
INFO - root - 2017-12-17 00:18:20.055847: step 154730, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 10h:59m:43s remains)
INFO - root - 2017-12-17 00:18:22.295043: step 154740, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 10h:42m:04s remains)
INFO - root - 2017-12-17 00:18:24.499143: step 154750, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 10h:49m:28s remains)
INFO - root - 2017-12-17 00:18:26.722569: step 154760, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 10h:42m:05s remains)
INFO - root - 2017-12-17 00:18:28.962678: step 154770, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 10h:59m:37s remains)
INFO - root - 2017-12-17 00:18:31.208033: step 154780, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 11h:02m:27s remains)
INFO - root - 2017-12-17 00:18:33.439383: step 154790, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 10h:52m:28s remains)
INFO - root - 2017-12-17 00:18:35.627930: step 154800, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 10h:30m:47s remains)
INFO - root - 2017-12-17 00:18:37.975685: step 154810, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 10h:36m:11s remains)
INFO - root - 2017-12-17 00:18:40.176197: step 154820, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 10h:41m:30s remains)
INFO - root - 2017-12-17 00:18:42.387715: step 154830, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 10h:53m:32s remains)
INFO - root - 2017-12-17 00:18:44.591441: step 154840, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 10h:51m:39s remains)
INFO - root - 2017-12-17 00:18:46.808117: step 154850, loss = 0.49, batch loss = 0.31 (34.0 examples/sec; 0.235 sec/batch; 11h:36m:20s remains)
INFO - root - 2017-12-17 00:18:49.023292: step 154860, loss = 0.44, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 10h:29m:10s remains)
INFO - root - 2017-12-17 00:18:51.245510: step 154870, loss = 0.43, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 10h:47m:39s remains)
INFO - root - 2017-12-17 00:18:53.413442: step 154880, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 10h:52m:25s remains)
INFO - root - 2017-12-17 00:18:55.613627: step 154890, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 10h:59m:49s remains)
INFO - root - 2017-12-17 00:18:57.827994: step 154900, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.228 sec/batch; 11h:13m:32s remains)
INFO - root - 2017-12-17 00:19:00.189754: step 154910, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 10h:45m:09s remains)
INFO - root - 2017-12-17 00:19:02.379241: step 154920, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 10h:49m:45s remains)
INFO - root - 2017-12-17 00:19:04.606227: step 154930, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 10h:40m:04s remains)
INFO - root - 2017-12-17 00:19:06.798268: step 154940, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 10h:40m:32s remains)
INFO - root - 2017-12-17 00:19:09.040909: step 154950, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.215 sec/batch; 10h:37m:32s remains)
INFO - root - 2017-12-17 00:19:11.265958: step 154960, loss = 0.51, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 11h:14m:59s remains)
INFO - root - 2017-12-17 00:19:13.459018: step 154970, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 10h:50m:41s remains)
INFO - root - 2017-12-17 00:19:15.691981: step 154980, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 10h:59m:19s remains)
INFO - root - 2017-12-17 00:19:17.939805: step 154990, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 11h:04m:34s remains)
INFO - root - 2017-12-17 00:19:20.170507: step 155000, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 10h:53m:56s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-155000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-155000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 00:19:23.181353: step 155010, loss = 0.42, batch loss = 0.24 (37.0 examples/sec; 0.216 sec/batch; 10h:39m:28s remains)
INFO - root - 2017-12-17 00:19:25.422406: step 155020, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 11h:11m:10s remains)
INFO - root - 2017-12-17 00:19:27.667420: step 155030, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 10h:51m:01s remains)
INFO - root - 2017-12-17 00:19:29.875324: step 155040, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.216 sec/batch; 10h:37m:46s remains)
INFO - root - 2017-12-17 00:19:32.058605: step 155050, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.218 sec/batch; 10h:43m:37s remains)
INFO - root - 2017-12-17 00:19:34.232458: step 155060, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 10h:33m:12s remains)
INFO - root - 2017-12-17 00:19:36.439855: step 155070, loss = 0.48, batch loss = 0.30 (37.8 examples/sec; 0.211 sec/batch; 10h:25m:10s remains)
INFO - root - 2017-12-17 00:19:38.624367: step 155080, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 10h:37m:07s remains)
INFO - root - 2017-12-17 00:19:40.826848: step 155090, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 10h:40m:26s remains)
INFO - root - 2017-12-17 00:19:43.024727: step 155100, loss = 0.43, batch loss = 0.25 (34.0 examples/sec; 0.236 sec/batch; 11h:36m:38s remains)
INFO - root - 2017-12-17 00:19:45.372004: step 155110, loss = 0.53, batch loss = 0.35 (33.9 examples/sec; 0.236 sec/batch; 11h:36m:47s remains)
INFO - root - 2017-12-17 00:19:47.556583: step 155120, loss = 0.47, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 10h:40m:49s remains)
INFO - root - 2017-12-17 00:19:49.784540: step 155130, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 10h:46m:14s remains)
INFO - root - 2017-12-17 00:19:51.963571: step 155140, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 10h:54m:53s remains)
INFO - root - 2017-12-17 00:19:54.182853: step 155150, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 10h:53m:18s remains)
INFO - root - 2017-12-17 00:19:56.408591: step 155160, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 11h:00m:29s remains)
INFO - root - 2017-12-17 00:19:58.666214: step 155170, loss = 0.45, batch loss = 0.27 (37.8 examples/sec; 0.211 sec/batch; 10h:24m:51s remains)
INFO - root - 2017-12-17 00:20:00.877728: step 155180, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 10h:53m:47s remains)
INFO - root - 2017-12-17 00:20:03.075621: step 155190, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 11h:01m:24s remains)
INFO - root - 2017-12-17 00:20:05.258721: step 155200, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 10h:38m:46s remains)
INFO - root - 2017-12-17 00:20:07.600783: step 155210, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 10h:28m:41s remains)
INFO - root - 2017-12-17 00:20:09.839870: step 155220, loss = 0.51, batch loss = 0.33 (33.7 examples/sec; 0.237 sec/batch; 11h:40m:48s remains)
INFO - root - 2017-12-17 00:20:12.004868: step 155230, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 10h:39m:57s remains)
INFO - root - 2017-12-17 00:20:14.173439: step 155240, loss = 0.45, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 10h:39m:05s remains)
INFO - root - 2017-12-17 00:20:16.362999: step 155250, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 10h:55m:28s remains)
INFO - root - 2017-12-17 00:20:18.526410: step 155260, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 10h:39m:06s remains)
INFO - root - 2017-12-17 00:20:20.724133: step 155270, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 10h:52m:53s remains)
INFO - root - 2017-12-17 00:20:22.943390: step 155280, loss = 0.46, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 10h:44m:40s remains)
INFO - root - 2017-12-17 00:20:25.163660: step 155290, loss = 0.48, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 11h:08m:05s remains)
INFO - root - 2017-12-17 00:20:27.372351: step 155300, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 10h:51m:35s remains)
INFO - root - 2017-12-17 00:20:29.707068: step 155310, loss = 0.57, batch loss = 0.39 (37.3 examples/sec; 0.214 sec/batch; 10h:33m:25s remains)
INFO - root - 2017-12-17 00:20:31.946885: step 155320, loss = 0.49, batch loss = 0.31 (33.8 examples/sec; 0.237 sec/batch; 11h:38m:39s remains)
INFO - root - 2017-12-17 00:20:34.156489: step 155330, loss = 0.52, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 11h:13m:07s remains)
INFO - root - 2017-12-17 00:20:36.354890: step 155340, loss = 0.54, batch loss = 0.36 (38.1 examples/sec; 0.210 sec/batch; 10h:19m:30s remains)
INFO - root - 2017-12-17 00:20:38.544634: step 155350, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 10h:34m:41s remains)
INFO - root - 2017-12-17 00:20:40.718903: step 155360, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 10h:34m:39s remains)
INFO - root - 2017-12-17 00:20:42.934770: step 155370, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 10h:51m:28s remains)
INFO - root - 2017-12-17 00:20:45.168318: step 155380, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 10h:43m:25s remains)
INFO - root - 2017-12-17 00:20:47.332051: step 155390, loss = 0.42, batch loss = 0.24 (36.1 examples/sec; 0.222 sec/batch; 10h:54m:53s remains)
INFO - root - 2017-12-17 00:20:49.523567: step 155400, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 10h:32m:57s remains)
INFO - root - 2017-12-17 00:20:51.816512: step 155410, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 10h:43m:58s remains)
INFO - root - 2017-12-17 00:20:53.977804: step 155420, loss = 0.44, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 10h:27m:26s remains)
INFO - root - 2017-12-17 00:20:56.168495: step 155430, loss = 0.56, batch loss = 0.38 (35.7 examples/sec; 0.224 sec/batch; 11h:01m:01s remains)
INFO - root - 2017-12-17 00:20:58.355024: step 155440, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 10h:34m:59s remains)
INFO - root - 2017-12-17 00:21:00.569526: step 155450, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 10h:43m:48s remains)
INFO - root - 2017-12-17 00:21:02.781777: step 155460, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 11h:12m:24s remains)
INFO - root - 2017-12-17 00:21:05.006057: step 155470, loss = 0.48, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 10h:49m:19s remains)
INFO - root - 2017-12-17 00:21:07.210040: step 155480, loss = 0.48, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 10h:42m:00s remains)
INFO - root - 2017-12-17 00:21:09.389137: step 155490, loss = 0.50, batch loss = 0.32 (37.5 examples/sec; 0.213 sec/batch; 10h:29m:15s remains)
INFO - root - 2017-12-17 00:21:11.588354: step 155500, loss = 0.49, batch loss = 0.31 (34.4 examples/sec; 0.232 sec/batch; 11h:25m:23s remains)
INFO - root - 2017-12-17 00:21:13.899877: step 155510, loss = 0.47, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 10h:26m:37s remains)
INFO - root - 2017-12-17 00:21:16.110236: step 155520, loss = 0.57, batch loss = 0.39 (37.5 examples/sec; 0.213 sec/batch; 10h:28m:49s remains)
INFO - root - 2017-12-17 00:21:18.324459: step 155530, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 11h:02m:43s remains)
INFO - root - 2017-12-17 00:21:20.541349: step 155540, loss = 0.43, batch loss = 0.25 (37.3 examples/sec; 0.215 sec/batch; 10h:32m:48s remains)
INFO - root - 2017-12-17 00:21:22.782157: step 155550, loss = 0.55, batch loss = 0.38 (34.2 examples/sec; 0.234 sec/batch; 11h:29m:16s remains)
INFO - root - 2017-12-17 00:21:25.003632: step 155560, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 10h:58m:03s remains)
INFO - root - 2017-12-17 00:21:27.213486: step 155570, loss = 0.42, batch loss = 0.24 (37.2 examples/sec; 0.215 sec/batch; 10h:34m:27s remains)
INFO - root - 2017-12-17 00:21:29.387551: step 155580, loss = 0.45, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 10h:36m:16s remains)
INFO - root - 2017-12-17 00:21:31.611480: step 155590, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 11h:08m:51s remains)
INFO - root - 2017-12-17 00:21:33.825830: step 155600, loss = 0.52, batch loss = 0.34 (37.8 examples/sec; 0.212 sec/batch; 10h:23m:56s remains)
INFO - root - 2017-12-17 00:21:36.202528: step 155610, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 10h:44m:40s remains)
INFO - root - 2017-12-17 00:21:38.442174: step 155620, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 11h:05m:29s remains)
INFO - root - 2017-12-17 00:21:40.671067: step 155630, loss = 0.57, batch loss = 0.39 (35.5 examples/sec; 0.225 sec/batch; 11h:03m:38s remains)
INFO - root - 2017-12-17 00:21:42.870298: step 155640, loss = 0.44, batch loss = 0.26 (37.8 examples/sec; 0.211 sec/batch; 10h:23m:05s remains)
INFO - root - 2017-12-17 00:21:45.102215: step 155650, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 10h:28m:42s remains)
INFO - root - 2017-12-17 00:21:47.309618: step 155660, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 10h:49m:18s remains)
INFO - root - 2017-12-17 00:21:49.502227: step 155670, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 10h:41m:22s remains)
INFO - root - 2017-12-17 00:21:51.733583: step 155680, loss = 0.48, batch loss = 0.30 (37.8 examples/sec; 0.212 sec/batch; 10h:24m:27s remains)
INFO - root - 2017-12-17 00:21:53.974530: step 155690, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 10h:55m:24s remains)
INFO - root - 2017-12-17 00:21:56.146715: step 155700, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 10h:38m:17s remains)
INFO - root - 2017-12-17 00:21:58.473565: step 155710, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 11h:03m:47s remains)
INFO - root - 2017-12-17 00:22:00.678464: step 155720, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 10h:27m:09s remains)
INFO - root - 2017-12-17 00:22:02.870876: step 155730, loss = 0.48, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 10h:25m:37s remains)
INFO - root - 2017-12-17 00:22:05.066921: step 155740, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 10h:46m:22s remains)
INFO - root - 2017-12-17 00:22:07.266400: step 155750, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 10h:57m:36s remains)
INFO - root - 2017-12-17 00:22:09.468383: step 155760, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 10h:44m:38s remains)
INFO - root - 2017-12-17 00:22:11.676137: step 155770, loss = 0.42, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 10h:59m:23s remains)
INFO - root - 2017-12-17 00:22:13.911963: step 155780, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 10h:51m:18s remains)
INFO - root - 2017-12-17 00:22:16.162306: step 155790, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 11h:07m:57s remains)
INFO - root - 2017-12-17 00:22:18.340247: step 155800, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 10h:33m:07s remains)
INFO - root - 2017-12-17 00:22:20.647057: step 155810, loss = 0.43, batch loss = 0.25 (37.3 examples/sec; 0.214 sec/batch; 10h:31m:09s remains)
INFO - root - 2017-12-17 00:22:22.834619: step 155820, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 10h:39m:39s remains)
INFO - root - 2017-12-17 00:22:25.039845: step 155830, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 10h:58m:49s remains)
INFO - root - 2017-12-17 00:22:27.243720: step 155840, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 10h:45m:23s remains)
INFO - root - 2017-12-17 00:22:29.461239: step 155850, loss = 0.46, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 10h:57m:40s remains)
INFO - root - 2017-12-17 00:22:31.676272: step 155860, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 10h:40m:40s remains)
INFO - root - 2017-12-17 00:22:33.880999: step 155870, loss = 0.47, batch loss = 0.29 (34.1 examples/sec; 0.235 sec/batch; 11h:31m:09s remains)
INFO - root - 2017-12-17 00:22:36.073371: step 155880, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 10h:41m:37s remains)
INFO - root - 2017-12-17 00:22:38.301686: step 155890, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 10h:42m:27s remains)
INFO - root - 2017-12-17 00:22:40.515879: step 155900, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 10h:52m:32s remains)
INFO - root - 2017-12-17 00:22:42.818489: step 155910, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 10h:49m:36s remains)
INFO - root - 2017-12-17 00:22:45.042748: step 155920, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 11h:02m:44s remains)
INFO - root - 2017-12-17 00:22:47.251273: step 155930, loss = 0.47, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 10h:42m:26s remains)
INFO - root - 2017-12-17 00:22:49.443260: step 155940, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 10h:39m:29s remains)
INFO - root - 2017-12-17 00:22:51.632615: step 155950, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 10h:47m:12s remains)
INFO - root - 2017-12-17 00:22:53.865409: step 155960, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 10h:51m:37s remains)
INFO - root - 2017-12-17 00:22:56.069862: step 155970, loss = 0.60, batch loss = 0.43 (37.1 examples/sec; 0.216 sec/batch; 10h:34m:18s remains)
INFO - root - 2017-12-17 00:22:58.255442: step 155980, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 10h:38m:53s remains)
INFO - root - 2017-12-17 00:23:00.475455: step 155990, loss = 0.50, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 10h:38m:27s remains)
INFO - root - 2017-12-17 00:23:02.668275: step 156000, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 10h:39m:19s remains)
INFO - root - 2017-12-17 00:23:05.016906: step 156010, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 11h:07m:14s remains)
INFO - root - 2017-12-17 00:23:07.208275: step 156020, loss = 0.43, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 10h:44m:49s remains)
INFO - root - 2017-12-17 00:23:09.413344: step 156030, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 10h:55m:08s remains)
INFO - root - 2017-12-17 00:23:11.607303: step 156040, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.221 sec/batch; 10h:48m:31s remains)
INFO - root - 2017-12-17 00:23:13.795233: step 156050, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 10h:46m:51s remains)
INFO - root - 2017-12-17 00:23:15.987559: step 156060, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 10h:59m:08s remains)
INFO - root - 2017-12-17 00:23:18.154348: step 156070, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 10h:33m:46s remains)
INFO - root - 2017-12-17 00:23:20.315320: step 156080, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 10h:32m:21s remains)
INFO - root - 2017-12-17 00:23:22.531872: step 156090, loss = 0.44, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 11h:06m:54s remains)
INFO - root - 2017-12-17 00:23:24.715789: step 156100, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 10h:38m:24s remains)
INFO - root - 2017-12-17 00:23:27.059356: step 156110, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 11h:03m:25s remains)
INFO - root - 2017-12-17 00:23:29.309738: step 156120, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 10h:43m:20s remains)
INFO - root - 2017-12-17 00:23:31.505470: step 156130, loss = 0.41, batch loss = 0.23 (36.5 examples/sec; 0.219 sec/batch; 10h:44m:30s remains)
INFO - root - 2017-12-17 00:23:33.686939: step 156140, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 10h:35m:15s remains)
INFO - root - 2017-12-17 00:23:35.918226: step 156150, loss = 0.52, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 11h:10m:34s remains)
INFO - root - 2017-12-17 00:23:38.156755: step 156160, loss = 0.54, batch loss = 0.36 (33.4 examples/sec; 0.239 sec/batch; 11h:43m:39s remains)
INFO - root - 2017-12-17 00:23:40.421155: step 156170, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 10h:44m:51s remains)
INFO - root - 2017-12-17 00:23:42.653256: step 156180, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 10h:29m:34s remains)
INFO - root - 2017-12-17 00:23:44.837130: step 156190, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 10h:42m:09s remains)
INFO - root - 2017-12-17 00:23:47.045160: step 156200, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 10h:49m:38s remains)
INFO - root - 2017-12-17 00:23:49.345674: step 156210, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 10h:42m:09s remains)
INFO - root - 2017-12-17 00:23:51.520703: step 156220, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 10h:42m:08s remains)
INFO - root - 2017-12-17 00:23:53.732689: step 156230, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 11h:03m:51s remains)
INFO - root - 2017-12-17 00:23:55.960571: step 156240, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 10h:52m:29s remains)
INFO - root - 2017-12-17 00:23:58.182673: step 156250, loss = 0.44, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 11h:03m:41s remains)
INFO - root - 2017-12-17 00:24:00.377133: step 156260, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 10h:40m:11s remains)
INFO - root - 2017-12-17 00:24:02.565739: step 156270, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 10h:41m:06s remains)
INFO - root - 2017-12-17 00:24:04.801916: step 156280, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 11h:20m:54s remains)
INFO - root - 2017-12-17 00:24:07.025077: step 156290, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 10h:48m:50s remains)
INFO - root - 2017-12-17 00:24:09.180235: step 156300, loss = 0.49, batch loss = 0.31 (37.7 examples/sec; 0.212 sec/batch; 10h:23m:21s remains)
INFO - root - 2017-12-17 00:24:11.561312: step 156310, loss = 0.45, batch loss = 0.27 (33.5 examples/sec; 0.239 sec/batch; 11h:40m:41s remains)
INFO - root - 2017-12-17 00:24:13.754834: step 156320, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 10h:27m:26s remains)
INFO - root - 2017-12-17 00:24:15.969055: step 156330, loss = 0.48, batch loss = 0.30 (33.8 examples/sec; 0.236 sec/batch; 11h:34m:18s remains)
INFO - root - 2017-12-17 00:24:18.181804: step 156340, loss = 0.45, batch loss = 0.27 (34.8 examples/sec; 0.230 sec/batch; 11h:14m:46s remains)
INFO - root - 2017-12-17 00:24:20.420676: step 156350, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 10h:52m:37s remains)
INFO - root - 2017-12-17 00:24:22.662069: step 156360, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 10h:34m:49s remains)
INFO - root - 2017-12-17 00:24:24.896397: step 156370, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 10h:51m:38s remains)
INFO - root - 2017-12-17 00:24:27.131016: step 156380, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 10h:46m:39s remains)
INFO - root - 2017-12-17 00:24:29.342485: step 156390, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.226 sec/batch; 11h:02m:04s remains)
INFO - root - 2017-12-17 00:24:31.545636: step 156400, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 10h:57m:26s remains)
INFO - root - 2017-12-17 00:24:33.892343: step 156410, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 10h:54m:40s remains)
INFO - root - 2017-12-17 00:24:36.111134: step 156420, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 10h:28m:52s remains)
INFO - root - 2017-12-17 00:24:38.302251: step 156430, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 10h:59m:11s remains)
INFO - root - 2017-12-17 00:24:40.548675: step 156440, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 11h:00m:45s remains)
INFO - root - 2017-12-17 00:24:42.781992: step 156450, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 10h:39m:15s remains)
INFO - root - 2017-12-17 00:24:44.999527: step 156460, loss = 0.55, batch loss = 0.38 (35.6 examples/sec; 0.225 sec/batch; 10h:59m:46s remains)
INFO - root - 2017-12-17 00:24:47.187153: step 156470, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 10h:27m:19s remains)
INFO - root - 2017-12-17 00:24:49.420732: step 156480, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 10h:30m:21s remains)
INFO - root - 2017-12-17 00:24:51.606474: step 156490, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 10h:34m:02s remains)
INFO - root - 2017-12-17 00:24:53.833347: step 156500, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 11h:02m:04s remains)
INFO - root - 2017-12-17 00:24:56.224796: step 156510, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 10h:46m:52s remains)
INFO - root - 2017-12-17 00:24:58.442910: step 156520, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 10h:54m:57s remains)
INFO - root - 2017-12-17 00:25:00.637859: step 156530, loss = 0.51, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 11h:01m:16s remains)
INFO - root - 2017-12-17 00:25:02.853085: step 156540, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 10h:38m:38s remains)
INFO - root - 2017-12-17 00:25:05.105709: step 156550, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 10h:41m:40s remains)
INFO - root - 2017-12-17 00:25:07.352327: step 156560, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 10h:47m:42s remains)
INFO - root - 2017-12-17 00:25:09.548051: step 156570, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 10h:43m:15s remains)
INFO - root - 2017-12-17 00:25:11.720577: step 156580, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 10h:41m:15s remains)
INFO - root - 2017-12-17 00:25:13.947276: step 156590, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 10h:42m:29s remains)
INFO - root - 2017-12-17 00:25:16.118590: step 156600, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 10h:28m:14s remains)
INFO - root - 2017-12-17 00:25:18.457922: step 156610, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 10h:47m:49s remains)
INFO - root - 2017-12-17 00:25:20.661776: step 156620, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 11h:00m:32s remains)
INFO - root - 2017-12-17 00:25:22.886479: step 156630, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 10h:52m:51s remains)
INFO - root - 2017-12-17 00:25:25.103539: step 156640, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 10h:49m:56s remains)
INFO - root - 2017-12-17 00:25:27.320711: step 156650, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 10h:40m:19s remains)
INFO - root - 2017-12-17 00:25:29.515546: step 156660, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 10h:54m:16s remains)
INFO - root - 2017-12-17 00:25:31.704027: step 156670, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 10h:39m:14s remains)
INFO - root - 2017-12-17 00:25:33.884194: step 156680, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 11h:01m:22s remains)
INFO - root - 2017-12-17 00:25:36.128297: step 156690, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 10h:48m:35s remains)
INFO - root - 2017-12-17 00:25:38.350986: step 156700, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 10h:33m:47s remains)
INFO - root - 2017-12-17 00:25:40.679419: step 156710, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 10h:21m:15s remains)
INFO - root - 2017-12-17 00:25:42.884531: step 156720, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 10h:27m:56s remains)
INFO - root - 2017-12-17 00:25:45.106429: step 156730, loss = 0.52, batch loss = 0.34 (37.5 examples/sec; 0.213 sec/batch; 10h:24m:53s remains)
INFO - root - 2017-12-17 00:25:47.367247: step 156740, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 10h:50m:26s remains)
INFO - root - 2017-12-17 00:25:49.582923: step 156750, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 11h:04m:28s remains)
INFO - root - 2017-12-17 00:25:51.778961: step 156760, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 10h:43m:20s remains)
INFO - root - 2017-12-17 00:25:54.006135: step 156770, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 10h:35m:53s remains)
INFO - root - 2017-12-17 00:25:56.200412: step 156780, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 10h:33m:08s remains)
INFO - root - 2017-12-17 00:25:58.397490: step 156790, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 10h:41m:41s remains)
INFO - root - 2017-12-17 00:26:00.643204: step 156800, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 10h:36m:02s remains)
INFO - root - 2017-12-17 00:26:02.962047: step 156810, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 10h:41m:13s remains)
INFO - root - 2017-12-17 00:26:05.168417: step 156820, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 11h:13m:23s remains)
INFO - root - 2017-12-17 00:26:07.420037: step 156830, loss = 0.45, batch loss = 0.27 (37.8 examples/sec; 0.212 sec/batch; 10h:20m:23s remains)
INFO - root - 2017-12-17 00:26:09.613330: step 156840, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 11h:01m:57s remains)
INFO - root - 2017-12-17 00:26:11.811268: step 156850, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 10h:44m:25s remains)
INFO - root - 2017-12-17 00:26:14.020898: step 156860, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 10h:46m:28s remains)
INFO - root - 2017-12-17 00:26:16.249964: step 156870, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 10h:56m:14s remains)
INFO - root - 2017-12-17 00:26:18.462782: step 156880, loss = 0.45, batch loss = 0.27 (34.8 examples/sec; 0.230 sec/batch; 11h:13m:03s remains)
INFO - root - 2017-12-17 00:26:20.642644: step 156890, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 10h:53m:29s remains)
INFO - root - 2017-12-17 00:26:22.847825: step 156900, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 10h:32m:28s remains)
INFO - root - 2017-12-17 00:26:25.235101: step 156910, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 10h:48m:22s remains)
INFO - root - 2017-12-17 00:26:27.422531: step 156920, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 10h:40m:18s remains)
INFO - root - 2017-12-17 00:26:29.628390: step 156930, loss = 0.48, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 10h:47m:21s remains)
INFO - root - 2017-12-17 00:26:31.842121: step 156940, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 10h:26m:10s remains)
INFO - root - 2017-12-17 00:26:34.034283: step 156950, loss = 0.48, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 10h:20m:24s remains)
INFO - root - 2017-12-17 00:26:36.241880: step 156960, loss = 0.55, batch loss = 0.37 (35.9 examples/sec; 0.223 sec/batch; 10h:51m:34s remains)
INFO - root - 2017-12-17 00:26:38.450707: step 156970, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 10h:32m:31s remains)
INFO - root - 2017-12-17 00:26:40.655533: step 156980, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 10h:35m:53s remains)
INFO - root - 2017-12-17 00:26:42.842438: step 156990, loss = 0.45, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 11h:00m:02s remains)
INFO - root - 2017-12-17 00:26:45.052092: step 157000, loss = 0.55, batch loss = 0.37 (37.5 examples/sec; 0.213 sec/batch; 10h:23m:37s remains)
INFO - root - 2017-12-17 00:26:47.391671: step 157010, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 10h:36m:26s remains)
INFO - root - 2017-12-17 00:26:49.574662: step 157020, loss = 0.50, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 10h:42m:30s remains)
INFO - root - 2017-12-17 00:26:51.735717: step 157030, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 10h:44m:47s remains)
INFO - root - 2017-12-17 00:26:53.940227: step 157040, loss = 0.52, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 10h:37m:00s remains)
INFO - root - 2017-12-17 00:26:56.105456: step 157050, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 10h:44m:45s remains)
INFO - root - 2017-12-17 00:26:58.323723: step 157060, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 10h:34m:41s remains)
INFO - root - 2017-12-17 00:27:00.516663: step 157070, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 10h:31m:27s remains)
INFO - root - 2017-12-17 00:27:02.737899: step 157080, loss = 0.45, batch loss = 0.28 (34.2 examples/sec; 0.234 sec/batch; 11h:22m:58s remains)
INFO - root - 2017-12-17 00:27:04.943524: step 157090, loss = 0.55, batch loss = 0.37 (36.1 examples/sec; 0.222 sec/batch; 10h:48m:45s remains)
INFO - root - 2017-12-17 00:27:07.143011: step 157100, loss = 0.51, batch loss = 0.33 (33.2 examples/sec; 0.241 sec/batch; 11h:43m:26s remains)
INFO - root - 2017-12-17 00:27:09.502327: step 157110, loss = 0.52, batch loss = 0.34 (34.1 examples/sec; 0.235 sec/batch; 11h:26m:10s remains)
INFO - root - 2017-12-17 00:27:11.709104: step 157120, loss = 0.55, batch loss = 0.37 (36.0 examples/sec; 0.222 sec/batch; 10h:49m:35s remains)
INFO - root - 2017-12-17 00:27:13.915476: step 157130, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 10h:26m:28s remains)
INFO - root - 2017-12-17 00:27:16.147248: step 157140, loss = 0.47, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 11h:24m:16s remains)
INFO - root - 2017-12-17 00:27:18.331667: step 157150, loss = 0.49, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 10h:35m:12s remains)
INFO - root - 2017-12-17 00:27:20.540901: step 157160, loss = 0.47, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 10h:45m:33s remains)
INFO - root - 2017-12-17 00:27:22.747125: step 157170, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 11h:05m:49s remains)
INFO - root - 2017-12-17 00:27:24.968604: step 157180, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 10h:55m:39s remains)
INFO - root - 2017-12-17 00:27:27.172795: step 157190, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 10h:45m:19s remains)
INFO - root - 2017-12-17 00:27:29.373576: step 157200, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.218 sec/batch; 10h:35m:28s remains)
INFO - root - 2017-12-17 00:27:31.703582: step 157210, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 10h:31m:17s remains)
INFO - root - 2017-12-17 00:27:33.937942: step 157220, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 10h:41m:48s remains)
INFO - root - 2017-12-17 00:27:36.171386: step 157230, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 10h:33m:33s remains)
INFO - root - 2017-12-17 00:27:38.405666: step 157240, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 11h:03m:51s remains)
INFO - root - 2017-12-17 00:27:40.623955: step 157250, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 10h:23m:27s remains)
INFO - root - 2017-12-17 00:27:42.847044: step 157260, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 10h:54m:50s remains)
INFO - root - 2017-12-17 00:27:45.085306: step 157270, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 10h:47m:13s remains)
INFO - root - 2017-12-17 00:27:47.299217: step 157280, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.218 sec/batch; 10h:37m:39s remains)
INFO - root - 2017-12-17 00:27:49.503457: step 157290, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 10h:52m:32s remains)
INFO - root - 2017-12-17 00:27:51.689099: step 157300, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 10h:46m:56s remains)
INFO - root - 2017-12-17 00:27:54.081656: step 157310, loss = 0.48, batch loss = 0.30 (38.5 examples/sec; 0.208 sec/batch; 10h:07m:11s remains)
INFO - root - 2017-12-17 00:27:56.296465: step 157320, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 10h:39m:19s remains)
INFO - root - 2017-12-17 00:27:58.496198: step 157330, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 10h:33m:51s remains)
INFO - root - 2017-12-17 00:28:00.685340: step 157340, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 10h:25m:36s remains)
INFO - root - 2017-12-17 00:28:02.904873: step 157350, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 10h:41m:21s remains)
INFO - root - 2017-12-17 00:28:05.151649: step 157360, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 10h:48m:43s remains)
INFO - root - 2017-12-17 00:28:07.393090: step 157370, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 10h:52m:41s remains)
INFO - root - 2017-12-17 00:28:09.591542: step 157380, loss = 0.51, batch loss = 0.33 (37.8 examples/sec; 0.212 sec/batch; 10h:18m:04s remains)
INFO - root - 2017-12-17 00:28:11.779974: step 157390, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 10h:38m:40s remains)
INFO - root - 2017-12-17 00:28:13.952432: step 157400, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 10h:46m:49s remains)
INFO - root - 2017-12-17 00:28:16.274613: step 157410, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 10h:28m:41s remains)
INFO - root - 2017-12-17 00:28:18.479737: step 157420, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 10h:33m:00s remains)
INFO - root - 2017-12-17 00:28:20.711621: step 157430, loss = 0.51, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 11h:10m:32s remains)
INFO - root - 2017-12-17 00:28:22.962258: step 157440, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 10h:34m:51s remains)
INFO - root - 2017-12-17 00:28:25.197563: step 157450, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 11h:01m:07s remains)
INFO - root - 2017-12-17 00:28:27.423725: step 157460, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.233 sec/batch; 11h:18m:28s remains)
INFO - root - 2017-12-17 00:28:29.658239: step 157470, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 10h:51m:45s remains)
INFO - root - 2017-12-17 00:28:31.851396: step 157480, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 10h:47m:32s remains)
INFO - root - 2017-12-17 00:28:34.066113: step 157490, loss = 0.57, batch loss = 0.39 (36.2 examples/sec; 0.221 sec/batch; 10h:45m:24s remains)
INFO - root - 2017-12-17 00:28:36.329872: step 157500, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 10h:45m:03s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-157500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-157500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 00:28:39.072621: step 157510, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.231 sec/batch; 11h:14m:35s remains)
INFO - root - 2017-12-17 00:28:41.292778: step 157520, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 10h:35m:22s remains)
INFO - root - 2017-12-17 00:28:43.498490: step 157530, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 10h:25m:17s remains)
INFO - root - 2017-12-17 00:28:45.702199: step 157540, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 10h:32m:23s remains)
INFO - root - 2017-12-17 00:28:47.909485: step 157550, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 10h:56m:54s remains)
INFO - root - 2017-12-17 00:28:50.098378: step 157560, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.215 sec/batch; 10h:28m:01s remains)
INFO - root - 2017-12-17 00:28:52.302903: step 157570, loss = 0.44, batch loss = 0.26 (38.3 examples/sec; 0.209 sec/batch; 10h:08m:39s remains)
INFO - root - 2017-12-17 00:28:54.495287: step 157580, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 10h:27m:32s remains)
INFO - root - 2017-12-17 00:28:56.682053: step 157590, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 10h:36m:47s remains)
INFO - root - 2017-12-17 00:28:58.895118: step 157600, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 10h:41m:26s remains)
INFO - root - 2017-12-17 00:29:01.208277: step 157610, loss = 0.44, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 10h:32m:01s remains)
INFO - root - 2017-12-17 00:29:03.405607: step 157620, loss = 0.61, batch loss = 0.43 (36.9 examples/sec; 0.217 sec/batch; 10h:31m:55s remains)
INFO - root - 2017-12-17 00:29:05.596469: step 157630, loss = 0.51, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 10h:49m:35s remains)
INFO - root - 2017-12-17 00:29:07.862785: step 157640, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 10h:49m:52s remains)
INFO - root - 2017-12-17 00:29:10.123224: step 157650, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 11h:07m:52s remains)
INFO - root - 2017-12-17 00:29:12.336850: step 157660, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 10h:50m:44s remains)
INFO - root - 2017-12-17 00:29:14.560337: step 157670, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 10h:49m:13s remains)
INFO - root - 2017-12-17 00:29:16.800258: step 157680, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 10h:40m:05s remains)
INFO - root - 2017-12-17 00:29:18.987476: step 157690, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 10h:31m:43s remains)
INFO - root - 2017-12-17 00:29:21.209420: step 157700, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 10h:45m:43s remains)
INFO - root - 2017-12-17 00:29:23.567289: step 157710, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 10h:53m:27s remains)
INFO - root - 2017-12-17 00:29:25.742079: step 157720, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 10h:41m:10s remains)
INFO - root - 2017-12-17 00:29:27.941456: step 157730, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 10h:25m:35s remains)
INFO - root - 2017-12-17 00:29:30.137266: step 157740, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 10h:23m:43s remains)
INFO - root - 2017-12-17 00:29:32.386696: step 157750, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 10h:32m:05s remains)
INFO - root - 2017-12-17 00:29:34.613766: step 157760, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 10h:45m:11s remains)
INFO - root - 2017-12-17 00:29:36.834419: step 157770, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 10h:39m:00s remains)
INFO - root - 2017-12-17 00:29:39.060221: step 157780, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 10h:57m:31s remains)
INFO - root - 2017-12-17 00:29:41.244275: step 157790, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 10h:23m:32s remains)
INFO - root - 2017-12-17 00:29:43.450333: step 157800, loss = 0.55, batch loss = 0.37 (34.8 examples/sec; 0.230 sec/batch; 11h:10m:15s remains)
INFO - root - 2017-12-17 00:29:45.788305: step 157810, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 10h:46m:43s remains)
INFO - root - 2017-12-17 00:29:48.012455: step 157820, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 10h:29m:09s remains)
INFO - root - 2017-12-17 00:29:50.258736: step 157830, loss = 0.48, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 10h:39m:14s remains)
INFO - root - 2017-12-17 00:29:52.460471: step 157840, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 10h:58m:01s remains)
INFO - root - 2017-12-17 00:29:54.711177: step 157850, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 11h:04m:00s remains)
INFO - root - 2017-12-17 00:29:56.932387: step 157860, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 10h:23m:08s remains)
INFO - root - 2017-12-17 00:29:59.126203: step 157870, loss = 0.47, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 10h:47m:02s remains)
INFO - root - 2017-12-17 00:30:01.307799: step 157880, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 10h:38m:05s remains)
INFO - root - 2017-12-17 00:30:03.536667: step 157890, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 10h:38m:18s remains)
INFO - root - 2017-12-17 00:30:05.757004: step 157900, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 10h:45m:12s remains)
INFO - root - 2017-12-17 00:30:08.148891: step 157910, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 10h:51m:26s remains)
INFO - root - 2017-12-17 00:30:10.324496: step 157920, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 10h:23m:23s remains)
INFO - root - 2017-12-17 00:30:12.508272: step 157930, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 11h:02m:37s remains)
INFO - root - 2017-12-17 00:30:14.741072: step 157940, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.230 sec/batch; 11h:07m:44s remains)
INFO - root - 2017-12-17 00:30:16.967434: step 157950, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 10h:56m:57s remains)
INFO - root - 2017-12-17 00:30:19.184909: step 157960, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 10h:48m:19s remains)
INFO - root - 2017-12-17 00:30:21.385262: step 157970, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 10h:43m:01s remains)
INFO - root - 2017-12-17 00:30:23.599255: step 157980, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 10h:31m:57s remains)
INFO - root - 2017-12-17 00:30:25.803526: step 157990, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 10h:30m:59s remains)
INFO - root - 2017-12-17 00:30:28.004349: step 158000, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 10h:46m:09s remains)
INFO - root - 2017-12-17 00:30:30.372202: step 158010, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 10h:41m:01s remains)
INFO - root - 2017-12-17 00:30:32.619857: step 158020, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 10h:26m:07s remains)
INFO - root - 2017-12-17 00:30:34.830019: step 158030, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 10h:42m:17s remains)
INFO - root - 2017-12-17 00:30:36.988754: step 158040, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 10h:39m:57s remains)
INFO - root - 2017-12-17 00:30:39.187216: step 158050, loss = 0.46, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 10h:32m:42s remains)
INFO - root - 2017-12-17 00:30:41.408985: step 158060, loss = 0.51, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 10h:45m:01s remains)
INFO - root - 2017-12-17 00:30:43.635079: step 158070, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 10h:38m:48s remains)
INFO - root - 2017-12-17 00:30:45.851328: step 158080, loss = 0.49, batch loss = 0.31 (34.4 examples/sec; 0.232 sec/batch; 11h:15m:49s remains)
INFO - root - 2017-12-17 00:30:48.058190: step 158090, loss = 0.47, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 10h:40m:08s remains)
INFO - root - 2017-12-17 00:30:50.265016: step 158100, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 10h:48m:01s remains)
INFO - root - 2017-12-17 00:30:52.578788: step 158110, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 10h:27m:57s remains)
INFO - root - 2017-12-17 00:30:54.831935: step 158120, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 11h:06m:02s remains)
INFO - root - 2017-12-17 00:30:57.049883: step 158130, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 10h:47m:41s remains)
INFO - root - 2017-12-17 00:30:59.230149: step 158140, loss = 0.45, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 10h:33m:00s remains)
INFO - root - 2017-12-17 00:31:01.442044: step 158150, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 10h:42m:15s remains)
INFO - root - 2017-12-17 00:31:03.682528: step 158160, loss = 0.48, batch loss = 0.30 (33.8 examples/sec; 0.236 sec/batch; 11h:26m:43s remains)
INFO - root - 2017-12-17 00:31:05.945896: step 158170, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 10h:31m:36s remains)
INFO - root - 2017-12-17 00:31:08.204572: step 158180, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 10h:39m:49s remains)
INFO - root - 2017-12-17 00:31:10.408659: step 158190, loss = 0.46, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 10h:48m:18s remains)
INFO - root - 2017-12-17 00:31:12.640904: step 158200, loss = 0.49, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 10h:42m:01s remains)
INFO - root - 2017-12-17 00:31:15.017629: step 158210, loss = 0.55, batch loss = 0.37 (34.8 examples/sec; 0.230 sec/batch; 11h:08m:12s remains)
INFO - root - 2017-12-17 00:31:17.188075: step 158220, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 10h:30m:02s remains)
INFO - root - 2017-12-17 00:31:19.397159: step 158230, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 10h:47m:19s remains)
INFO - root - 2017-12-17 00:31:21.619697: step 158240, loss = 0.55, batch loss = 0.37 (37.3 examples/sec; 0.214 sec/batch; 10h:22m:46s remains)
INFO - root - 2017-12-17 00:31:23.878747: step 158250, loss = 0.42, batch loss = 0.24 (35.6 examples/sec; 0.224 sec/batch; 10h:51m:43s remains)
INFO - root - 2017-12-17 00:31:26.101630: step 158260, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 10h:21m:06s remains)
INFO - root - 2017-12-17 00:31:28.292983: step 158270, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 10h:47m:30s remains)
INFO - root - 2017-12-17 00:31:30.517815: step 158280, loss = 0.41, batch loss = 0.23 (35.4 examples/sec; 0.226 sec/batch; 10h:55m:50s remains)
INFO - root - 2017-12-17 00:31:32.742768: step 158290, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 10h:34m:16s remains)
INFO - root - 2017-12-17 00:31:34.952851: step 158300, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 10h:43m:23s remains)
INFO - root - 2017-12-17 00:31:37.349044: step 158310, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 10h:50m:36s remains)
INFO - root - 2017-12-17 00:31:39.543248: step 158320, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 10h:18m:46s remains)
INFO - root - 2017-12-17 00:31:41.753753: step 158330, loss = 0.52, batch loss = 0.34 (34.1 examples/sec; 0.235 sec/batch; 11h:21m:52s remains)
INFO - root - 2017-12-17 00:31:44.008202: step 158340, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 10h:58m:24s remains)
INFO - root - 2017-12-17 00:31:46.199760: step 158350, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 10h:27m:14s remains)
INFO - root - 2017-12-17 00:31:48.426440: step 158360, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 10h:55m:19s remains)
INFO - root - 2017-12-17 00:31:50.673349: step 158370, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 10h:24m:07s remains)
INFO - root - 2017-12-17 00:31:52.917164: step 158380, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.233 sec/batch; 11h:15m:44s remains)
INFO - root - 2017-12-17 00:31:55.141354: step 158390, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 10h:31m:19s remains)
INFO - root - 2017-12-17 00:31:57.370447: step 158400, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 10h:32m:06s remains)
INFO - root - 2017-12-17 00:31:59.701913: step 158410, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.218 sec/batch; 10h:33m:38s remains)
INFO - root - 2017-12-17 00:32:01.904546: step 158420, loss = 0.58, batch loss = 0.40 (35.2 examples/sec; 0.227 sec/batch; 10h:59m:44s remains)
INFO - root - 2017-12-17 00:32:04.138478: step 158430, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 10h:45m:01s remains)
INFO - root - 2017-12-17 00:32:06.387484: step 158440, loss = 0.45, batch loss = 0.27 (33.8 examples/sec; 0.237 sec/batch; 11h:26m:26s remains)
INFO - root - 2017-12-17 00:32:08.622450: step 158450, loss = 0.49, batch loss = 0.31 (34.4 examples/sec; 0.233 sec/batch; 11h:14m:59s remains)
INFO - root - 2017-12-17 00:32:10.876838: step 158460, loss = 0.46, batch loss = 0.28 (32.4 examples/sec; 0.247 sec/batch; 11h:56m:18s remains)
INFO - root - 2017-12-17 00:32:13.132722: step 158470, loss = 0.54, batch loss = 0.36 (34.6 examples/sec; 0.231 sec/batch; 11h:11m:22s remains)
INFO - root - 2017-12-17 00:32:15.348090: step 158480, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 11h:01m:51s remains)
INFO - root - 2017-12-17 00:32:17.580828: step 158490, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 10h:32m:26s remains)
INFO - root - 2017-12-17 00:32:19.803218: step 158500, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 10h:34m:11s remains)
INFO - root - 2017-12-17 00:32:22.114914: step 158510, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 10h:23m:30s remains)
INFO - root - 2017-12-17 00:32:24.320347: step 158520, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 10h:35m:46s remains)
INFO - root - 2017-12-17 00:32:26.566699: step 158530, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 10h:53m:23s remains)
INFO - root - 2017-12-17 00:32:28.814150: step 158540, loss = 0.55, batch loss = 0.37 (34.0 examples/sec; 0.235 sec/batch; 11h:22m:19s remains)
INFO - root - 2017-12-17 00:32:31.037013: step 158550, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 10h:29m:21s remains)
INFO - root - 2017-12-17 00:32:33.224799: step 158560, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 10h:19m:22s remains)
INFO - root - 2017-12-17 00:32:35.465856: step 158570, loss = 0.46, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 10h:52m:00s remains)
INFO - root - 2017-12-17 00:32:37.667074: step 158580, loss = 0.50, batch loss = 0.32 (34.1 examples/sec; 0.235 sec/batch; 11h:19m:54s remains)
INFO - root - 2017-12-17 00:32:39.872599: step 158590, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 10h:34m:07s remains)
INFO - root - 2017-12-17 00:32:42.097453: step 158600, loss = 0.43, batch loss = 0.26 (36.8 examples/sec; 0.218 sec/batch; 10h:30m:26s remains)
INFO - root - 2017-12-17 00:32:44.442318: step 158610, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 10h:36m:31s remains)
INFO - root - 2017-12-17 00:32:46.667500: step 158620, loss = 0.52, batch loss = 0.34 (33.7 examples/sec; 0.238 sec/batch; 11h:28m:18s remains)
INFO - root - 2017-12-17 00:32:48.898939: step 158630, loss = 0.53, batch loss = 0.35 (34.9 examples/sec; 0.229 sec/batch; 11h:04m:16s remains)
INFO - root - 2017-12-17 00:32:51.133234: step 158640, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 10h:38m:47s remains)
INFO - root - 2017-12-17 00:32:53.365461: step 158650, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 10h:36m:48s remains)
INFO - root - 2017-12-17 00:32:55.612128: step 158660, loss = 0.47, batch loss = 0.30 (32.6 examples/sec; 0.245 sec/batch; 11h:50m:25s remains)
INFO - root - 2017-12-17 00:32:57.825248: step 158670, loss = 0.44, batch loss = 0.26 (34.7 examples/sec; 0.230 sec/batch; 11h:07m:14s remains)
INFO - root - 2017-12-17 00:33:00.087548: step 158680, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 10h:23m:38s remains)
INFO - root - 2017-12-17 00:33:02.326490: step 158690, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 11h:03m:27s remains)
INFO - root - 2017-12-17 00:33:04.521151: step 158700, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 10h:33m:42s remains)
INFO - root - 2017-12-17 00:33:06.842587: step 158710, loss = 0.45, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 10h:22m:16s remains)
INFO - root - 2017-12-17 00:33:09.046889: step 158720, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 10h:27m:47s remains)
INFO - root - 2017-12-17 00:33:11.283439: step 158730, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 10h:20m:30s remains)
INFO - root - 2017-12-17 00:33:13.489910: step 158740, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 10h:48m:48s remains)
INFO - root - 2017-12-17 00:33:15.751508: step 158750, loss = 0.50, batch loss = 0.32 (33.7 examples/sec; 0.237 sec/batch; 11h:26m:58s remains)
INFO - root - 2017-12-17 00:33:17.957797: step 158760, loss = 0.50, batch loss = 0.32 (34.6 examples/sec; 0.231 sec/batch; 11h:09m:07s remains)
INFO - root - 2017-12-17 00:33:20.183270: step 158770, loss = 0.47, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 11h:03m:31s remains)
INFO - root - 2017-12-17 00:33:22.418835: step 158780, loss = 0.58, batch loss = 0.40 (35.0 examples/sec; 0.228 sec/batch; 11h:00m:53s remains)
INFO - root - 2017-12-17 00:33:24.651565: step 158790, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 10h:30m:38s remains)
INFO - root - 2017-12-17 00:33:26.853667: step 158800, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 10h:29m:26s remains)
INFO - root - 2017-12-17 00:33:29.246697: step 158810, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 10h:54m:04s remains)
INFO - root - 2017-12-17 00:33:31.445891: step 158820, loss = 0.56, batch loss = 0.38 (36.7 examples/sec; 0.218 sec/batch; 10h:30m:50s remains)
INFO - root - 2017-12-17 00:33:33.643123: step 158830, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 10h:50m:56s remains)
INFO - root - 2017-12-17 00:33:35.851275: step 158840, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 10h:21m:51s remains)
INFO - root - 2017-12-17 00:33:38.075732: step 158850, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 10h:25m:59s remains)
INFO - root - 2017-12-17 00:33:40.255363: step 158860, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 10h:30m:34s remains)
INFO - root - 2017-12-17 00:33:42.468650: step 158870, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 10h:35m:15s remains)
INFO - root - 2017-12-17 00:33:44.691044: step 158880, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 10h:46m:42s remains)
INFO - root - 2017-12-17 00:33:46.890101: step 158890, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 10h:42m:27s remains)
INFO - root - 2017-12-17 00:33:49.102646: step 158900, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 10h:33m:17s remains)
INFO - root - 2017-12-17 00:33:51.456725: step 158910, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 10h:36m:03s remains)
INFO - root - 2017-12-17 00:33:53.680422: step 158920, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 11h:02m:42s remains)
INFO - root - 2017-12-17 00:33:55.919363: step 158930, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 10h:46m:55s remains)
INFO - root - 2017-12-17 00:33:58.139664: step 158940, loss = 0.43, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 10h:17m:56s remains)
INFO - root - 2017-12-17 00:34:00.339625: step 158950, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 10h:35m:34s remains)
INFO - root - 2017-12-17 00:34:02.577393: step 158960, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.224 sec/batch; 10h:46m:51s remains)
INFO - root - 2017-12-17 00:34:04.780645: step 158970, loss = 0.54, batch loss = 0.36 (36.0 examples/sec; 0.222 sec/batch; 10h:43m:23s remains)
INFO - root - 2017-12-17 00:34:07.042020: step 158980, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 10h:40m:39s remains)
INFO - root - 2017-12-17 00:34:09.294214: step 158990, loss = 0.58, batch loss = 0.40 (37.9 examples/sec; 0.211 sec/batch; 10h:09m:48s remains)
INFO - root - 2017-12-17 00:34:11.510698: step 159000, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 10h:34m:10s remains)
INFO - root - 2017-12-17 00:34:13.839675: step 159010, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 10h:35m:59s remains)
INFO - root - 2017-12-17 00:34:16.068872: step 159020, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 10h:29m:32s remains)
INFO - root - 2017-12-17 00:34:18.305069: step 159030, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 10h:34m:41s remains)
INFO - root - 2017-12-17 00:34:20.518177: step 159040, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 10h:45m:47s remains)
INFO - root - 2017-12-17 00:34:22.730064: step 159050, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 10h:53m:24s remains)
INFO - root - 2017-12-17 00:34:24.934878: step 159060, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 10h:42m:49s remains)
INFO - root - 2017-12-17 00:34:27.133714: step 159070, loss = 0.48, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 10h:45m:51s remains)
INFO - root - 2017-12-17 00:34:29.339009: step 159080, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 10h:34m:18s remains)
INFO - root - 2017-12-17 00:34:31.566796: step 159090, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 10h:41m:23s remains)
INFO - root - 2017-12-17 00:34:33.803563: step 159100, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 10h:26m:45s remains)
INFO - root - 2017-12-17 00:34:36.138082: step 159110, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 10h:33m:32s remains)
INFO - root - 2017-12-17 00:34:38.345717: step 159120, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 10h:20m:31s remains)
INFO - root - 2017-12-17 00:34:40.567640: step 159130, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 10h:36m:43s remains)
INFO - root - 2017-12-17 00:34:42.799995: step 159140, loss = 0.45, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 10h:47m:59s remains)
INFO - root - 2017-12-17 00:34:45.032281: step 159150, loss = 0.54, batch loss = 0.36 (36.2 examples/sec; 0.221 sec/batch; 10h:37m:57s remains)
INFO - root - 2017-12-17 00:34:47.252587: step 159160, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 10h:21m:59s remains)
INFO - root - 2017-12-17 00:34:49.475375: step 159170, loss = 0.46, batch loss = 0.28 (34.4 examples/sec; 0.233 sec/batch; 11h:12m:14s remains)
INFO - root - 2017-12-17 00:34:51.677849: step 159180, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 10h:32m:32s remains)
INFO - root - 2017-12-17 00:34:53.866867: step 159190, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 10h:21m:57s remains)
INFO - root - 2017-12-17 00:34:56.078101: step 159200, loss = 0.54, batch loss = 0.36 (35.5 examples/sec; 0.225 sec/batch; 10h:51m:11s remains)
INFO - root - 2017-12-17 00:34:58.393327: step 159210, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.214 sec/batch; 10h:18m:51s remains)
INFO - root - 2017-12-17 00:35:00.590378: step 159220, loss = 0.43, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 10h:37m:19s remains)
INFO - root - 2017-12-17 00:35:02.820309: step 159230, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 10h:44m:19s remains)
INFO - root - 2017-12-17 00:35:05.030687: step 159240, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 10h:47m:10s remains)
INFO - root - 2017-12-17 00:35:07.273959: step 159250, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 10h:51m:17s remains)
INFO - root - 2017-12-17 00:35:09.504947: step 159260, loss = 0.54, batch loss = 0.37 (35.6 examples/sec; 0.225 sec/batch; 10h:49m:30s remains)
INFO - root - 2017-12-17 00:35:11.711462: step 159270, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 10h:37m:15s remains)
INFO - root - 2017-12-17 00:35:13.916171: step 159280, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 10h:27m:27s remains)
INFO - root - 2017-12-17 00:35:16.127054: step 159290, loss = 0.42, batch loss = 0.24 (33.4 examples/sec; 0.239 sec/batch; 11h:30m:26s remains)
INFO - root - 2017-12-17 00:35:18.339518: step 159300, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 10h:58m:15s remains)
INFO - root - 2017-12-17 00:35:20.660462: step 159310, loss = 0.52, batch loss = 0.34 (38.1 examples/sec; 0.210 sec/batch; 10h:06m:41s remains)
INFO - root - 2017-12-17 00:35:22.871690: step 159320, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 10h:54m:01s remains)
INFO - root - 2017-12-17 00:35:25.093743: step 159330, loss = 0.42, batch loss = 0.24 (35.4 examples/sec; 0.226 sec/batch; 10h:52m:57s remains)
INFO - root - 2017-12-17 00:35:27.309360: step 159340, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 10h:49m:36s remains)
INFO - root - 2017-12-17 00:35:29.554756: step 159350, loss = 0.55, batch loss = 0.37 (34.7 examples/sec; 0.230 sec/batch; 11h:05m:05s remains)
INFO - root - 2017-12-17 00:35:31.818064: step 159360, loss = 0.46, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 10h:50m:57s remains)
INFO - root - 2017-12-17 00:35:34.061118: step 159370, loss = 0.50, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 10h:20m:54s remains)
INFO - root - 2017-12-17 00:35:36.292607: step 159380, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 10h:35m:18s remains)
INFO - root - 2017-12-17 00:35:38.499027: step 159390, loss = 0.49, batch loss = 0.31 (34.7 examples/sec; 0.230 sec/batch; 11h:04m:33s remains)
INFO - root - 2017-12-17 00:35:40.699993: step 159400, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 10h:36m:29s remains)
INFO - root - 2017-12-17 00:35:43.039182: step 159410, loss = 0.45, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 10h:40m:15s remains)
INFO - root - 2017-12-17 00:35:45.246396: step 159420, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 10h:42m:17s remains)
INFO - root - 2017-12-17 00:35:47.494121: step 159430, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 10h:42m:15s remains)
INFO - root - 2017-12-17 00:35:49.709891: step 159440, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 10h:36m:31s remains)
INFO - root - 2017-12-17 00:35:51.965458: step 159450, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 10h:30m:27s remains)
INFO - root - 2017-12-17 00:35:54.165434: step 159460, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 10h:22m:15s remains)
INFO - root - 2017-12-17 00:35:56.385114: step 159470, loss = 0.45, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 10h:26m:47s remains)
INFO - root - 2017-12-17 00:35:58.585097: step 159480, loss = 0.57, batch loss = 0.39 (35.1 examples/sec; 0.228 sec/batch; 10h:56m:56s remains)
INFO - root - 2017-12-17 00:36:00.832598: step 159490, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 10h:51m:28s remains)
INFO - root - 2017-12-17 00:36:03.065702: step 159500, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.230 sec/batch; 11h:04m:28s remains)
INFO - root - 2017-12-17 00:36:05.430641: step 159510, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 10h:51m:16s remains)
INFO - root - 2017-12-17 00:36:07.662070: step 159520, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 10h:15m:05s remains)
INFO - root - 2017-12-17 00:36:09.851573: step 159530, loss = 0.52, batch loss = 0.34 (34.7 examples/sec; 0.230 sec/batch; 11h:03m:41s remains)
INFO - root - 2017-12-17 00:36:12.062019: step 159540, loss = 0.42, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 10h:38m:37s remains)
INFO - root - 2017-12-17 00:36:14.276429: step 159550, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 10h:43m:46s remains)
INFO - root - 2017-12-17 00:36:16.499056: step 159560, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 10h:36m:22s remains)
INFO - root - 2017-12-17 00:36:18.747967: step 159570, loss = 0.48, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 10h:59m:59s remains)
INFO - root - 2017-12-17 00:36:20.980066: step 159580, loss = 0.55, batch loss = 0.37 (35.4 examples/sec; 0.226 sec/batch; 10h:51m:39s remains)
INFO - root - 2017-12-17 00:36:23.215300: step 159590, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 11h:07m:55s remains)
INFO - root - 2017-12-17 00:36:25.462221: step 159600, loss = 0.42, batch loss = 0.24 (35.9 examples/sec; 0.223 sec/batch; 10h:42m:42s remains)
INFO - root - 2017-12-17 00:36:27.779354: step 159610, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 10h:43m:17s remains)
INFO - root - 2017-12-17 00:36:30.008819: step 159620, loss = 0.54, batch loss = 0.36 (36.8 examples/sec; 0.218 sec/batch; 10h:27m:01s remains)
INFO - root - 2017-12-17 00:36:32.236829: step 159630, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 10h:51m:11s remains)
INFO - root - 2017-12-17 00:36:34.446930: step 159640, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 10h:23m:35s remains)
INFO - root - 2017-12-17 00:36:36.691137: step 159650, loss = 0.49, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 10h:42m:13s remains)
INFO - root - 2017-12-17 00:36:38.916593: step 159660, loss = 0.42, batch loss = 0.24 (37.1 examples/sec; 0.216 sec/batch; 10h:21m:42s remains)
INFO - root - 2017-12-17 00:36:41.121825: step 159670, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 10h:34m:25s remains)
INFO - root - 2017-12-17 00:36:43.356829: step 159680, loss = 0.49, batch loss = 0.31 (33.9 examples/sec; 0.236 sec/batch; 11h:19m:58s remains)
INFO - root - 2017-12-17 00:36:45.568855: step 159690, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 10h:38m:39s remains)
INFO - root - 2017-12-17 00:36:47.792926: step 159700, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 10h:52m:28s remains)
INFO - root - 2017-12-17 00:36:50.143015: step 159710, loss = 0.55, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 10h:32m:27s remains)
INFO - root - 2017-12-17 00:36:52.356152: step 159720, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 10h:45m:40s remains)
INFO - root - 2017-12-17 00:36:54.566437: step 159730, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 10h:54m:44s remains)
INFO - root - 2017-12-17 00:36:56.801513: step 159740, loss = 0.50, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 10h:43m:04s remains)
INFO - root - 2017-12-17 00:36:59.009415: step 159750, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 10h:48m:32s remains)
INFO - root - 2017-12-17 00:37:01.241256: step 159760, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 10h:46m:44s remains)
INFO - root - 2017-12-17 00:37:03.483044: step 159770, loss = 0.42, batch loss = 0.24 (36.1 examples/sec; 0.221 sec/batch; 10h:37m:14s remains)
INFO - root - 2017-12-17 00:37:05.737541: step 159780, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 10h:43m:22s remains)
INFO - root - 2017-12-17 00:37:07.983894: step 159790, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 10h:17m:12s remains)
INFO - root - 2017-12-17 00:37:10.160757: step 159800, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 10h:41m:01s remains)
INFO - root - 2017-12-17 00:37:12.464323: step 159810, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 10h:41m:24s remains)
INFO - root - 2017-12-17 00:37:14.701608: step 159820, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 10h:55m:30s remains)
INFO - root - 2017-12-17 00:37:16.926048: step 159830, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 10h:39m:58s remains)
INFO - root - 2017-12-17 00:37:19.145805: step 159840, loss = 0.57, batch loss = 0.39 (36.9 examples/sec; 0.217 sec/batch; 10h:24m:19s remains)
INFO - root - 2017-12-17 00:37:21.373287: step 159850, loss = 0.53, batch loss = 0.36 (35.8 examples/sec; 0.223 sec/batch; 10h:42m:55s remains)
INFO - root - 2017-12-17 00:37:23.602252: step 159860, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 10h:37m:50s remains)
INFO - root - 2017-12-17 00:37:25.804545: step 159870, loss = 0.44, batch loss = 0.26 (34.1 examples/sec; 0.235 sec/batch; 11h:15m:33s remains)
INFO - root - 2017-12-17 00:37:28.032120: step 159880, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 10h:20m:58s remains)
INFO - root - 2017-12-17 00:37:30.214575: step 159890, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 10h:24m:09s remains)
INFO - root - 2017-12-17 00:37:32.449404: step 159900, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 10h:49m:51s remains)
INFO - root - 2017-12-17 00:37:34.844553: step 159910, loss = 0.43, batch loss = 0.25 (34.4 examples/sec; 0.233 sec/batch; 11h:09m:26s remains)
INFO - root - 2017-12-17 00:37:37.051980: step 159920, loss = 0.43, batch loss = 0.25 (37.3 examples/sec; 0.215 sec/batch; 10h:17m:25s remains)
INFO - root - 2017-12-17 00:37:39.291191: step 159930, loss = 0.54, batch loss = 0.36 (35.1 examples/sec; 0.228 sec/batch; 10h:55m:45s remains)
INFO - root - 2017-12-17 00:37:41.526933: step 159940, loss = 0.50, batch loss = 0.32 (37.5 examples/sec; 0.213 sec/batch; 10h:13m:30s remains)
INFO - root - 2017-12-17 00:37:43.728933: step 159950, loss = 0.53, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 10h:28m:31s remains)
INFO - root - 2017-12-17 00:37:45.922788: step 159960, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 10h:30m:58s remains)
INFO - root - 2017-12-17 00:37:48.130367: step 159970, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 10h:12m:49s remains)
INFO - root - 2017-12-17 00:37:50.380941: step 159980, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 10h:33m:07s remains)
INFO - root - 2017-12-17 00:37:52.601659: step 159990, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 10h:34m:13s remains)
INFO - root - 2017-12-17 00:37:54.842602: step 160000, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 10h:47m:10s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-160000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-160000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 00:37:57.621146: step 160010, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 10h:54m:22s remains)
INFO - root - 2017-12-17 00:37:59.822779: step 160020, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 10h:43m:16s remains)
INFO - root - 2017-12-17 00:38:02.079370: step 160030, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 10h:30m:35s remains)
INFO - root - 2017-12-17 00:38:04.278650: step 160040, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 10h:32m:48s remains)
INFO - root - 2017-12-17 00:38:06.497328: step 160050, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 10h:30m:38s remains)
INFO - root - 2017-12-17 00:38:08.742410: step 160060, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.228 sec/batch; 10h:53m:59s remains)
INFO - root - 2017-12-17 00:38:10.975469: step 160070, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 10h:25m:37s remains)
INFO - root - 2017-12-17 00:38:13.163518: step 160080, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 10h:46m:23s remains)
INFO - root - 2017-12-17 00:38:15.410682: step 160090, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 10h:34m:49s remains)
INFO - root - 2017-12-17 00:38:17.635914: step 160100, loss = 0.51, batch loss = 0.33 (35.0 examples/sec; 0.229 sec/batch; 10h:56m:52s remains)
INFO - root - 2017-12-17 00:38:19.991608: step 160110, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 10h:44m:42s remains)
INFO - root - 2017-12-17 00:38:22.193017: step 160120, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 10h:30m:51s remains)
INFO - root - 2017-12-17 00:38:24.423820: step 160130, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 10h:35m:13s remains)
INFO - root - 2017-12-17 00:38:26.650523: step 160140, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 10h:40m:08s remains)
INFO - root - 2017-12-17 00:38:28.932905: step 160150, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 10h:59m:03s remains)
INFO - root - 2017-12-17 00:38:31.172072: step 160160, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 10h:13m:04s remains)
INFO - root - 2017-12-17 00:38:33.382933: step 160170, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 10h:15m:00s remains)
INFO - root - 2017-12-17 00:38:35.603109: step 160180, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 10h:24m:01s remains)
INFO - root - 2017-12-17 00:38:37.844218: step 160190, loss = 0.51, batch loss = 0.33 (37.7 examples/sec; 0.212 sec/batch; 10h:10m:04s remains)
INFO - root - 2017-12-17 00:38:40.045812: step 160200, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 10h:14m:28s remains)
INFO - root - 2017-12-17 00:38:42.436417: step 160210, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 10h:33m:59s remains)
INFO - root - 2017-12-17 00:38:44.663648: step 160220, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 10h:52m:30s remains)
INFO - root - 2017-12-17 00:38:46.911557: step 160230, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 11h:04m:54s remains)
INFO - root - 2017-12-17 00:38:49.119976: step 160240, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 10h:27m:58s remains)
INFO - root - 2017-12-17 00:38:51.362619: step 160250, loss = 0.41, batch loss = 0.24 (33.5 examples/sec; 0.239 sec/batch; 11h:26m:33s remains)
INFO - root - 2017-12-17 00:38:53.584707: step 160260, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 10h:37m:14s remains)
INFO - root - 2017-12-17 00:38:55.766768: step 160270, loss = 0.43, batch loss = 0.25 (37.3 examples/sec; 0.214 sec/batch; 10h:15m:26s remains)
INFO - root - 2017-12-17 00:38:57.935364: step 160280, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 10h:22m:39s remains)
INFO - root - 2017-12-17 00:39:00.122969: step 160290, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 10h:19m:50s remains)
INFO - root - 2017-12-17 00:39:02.354423: step 160300, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 10h:26m:09s remains)
INFO - root - 2017-12-17 00:39:04.677167: step 160310, loss = 0.50, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 10h:57m:14s remains)
INFO - root - 2017-12-17 00:39:06.840880: step 160320, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 10h:14m:34s remains)
INFO - root - 2017-12-17 00:39:09.045590: step 160330, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 10h:39m:53s remains)
INFO - root - 2017-12-17 00:39:11.232013: step 160340, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 10h:21m:15s remains)
INFO - root - 2017-12-17 00:39:13.434185: step 160350, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 10h:36m:50s remains)
INFO - root - 2017-12-17 00:39:15.705657: step 160360, loss = 0.42, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 10h:35m:51s remains)
INFO - root - 2017-12-17 00:39:17.873039: step 160370, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 10h:19m:48s remains)
INFO - root - 2017-12-17 00:39:20.046875: step 160380, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 10h:25m:39s remains)
INFO - root - 2017-12-17 00:39:22.294786: step 160390, loss = 0.44, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 10h:53m:58s remains)
INFO - root - 2017-12-17 00:39:24.501805: step 160400, loss = 0.45, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 10h:11m:25s remains)
INFO - root - 2017-12-17 00:39:26.817034: step 160410, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 10h:12m:41s remains)
INFO - root - 2017-12-17 00:39:29.003811: step 160420, loss = 0.47, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 10h:43m:13s remains)
INFO - root - 2017-12-17 00:39:31.181785: step 160430, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 10h:17m:05s remains)
INFO - root - 2017-12-17 00:39:33.342456: step 160440, loss = 0.45, batch loss = 0.27 (37.8 examples/sec; 0.211 sec/batch; 10h:06m:13s remains)
INFO - root - 2017-12-17 00:39:35.544264: step 160450, loss = 0.54, batch loss = 0.36 (37.3 examples/sec; 0.214 sec/batch; 10h:14m:53s remains)
INFO - root - 2017-12-17 00:39:37.730313: step 160460, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 10h:40m:20s remains)
INFO - root - 2017-12-17 00:39:39.912522: step 160470, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 10h:38m:40s remains)
INFO - root - 2017-12-17 00:39:42.086035: step 160480, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 10h:13m:17s remains)
INFO - root - 2017-12-17 00:39:44.263733: step 160490, loss = 0.42, batch loss = 0.24 (36.1 examples/sec; 0.222 sec/batch; 10h:35m:41s remains)
INFO - root - 2017-12-17 00:39:46.453192: step 160500, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 10h:30m:13s remains)
INFO - root - 2017-12-17 00:39:48.801573: step 160510, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 10h:38m:06s remains)
INFO - root - 2017-12-17 00:39:50.968477: step 160520, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 10h:29m:19s remains)
INFO - root - 2017-12-17 00:39:53.195283: step 160530, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 10h:22m:47s remains)
INFO - root - 2017-12-17 00:39:55.383026: step 160540, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 10h:19m:39s remains)
INFO - root - 2017-12-17 00:39:57.608992: step 160550, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 10h:45m:04s remains)
INFO - root - 2017-12-17 00:39:59.778659: step 160560, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 10h:31m:04s remains)
INFO - root - 2017-12-17 00:40:01.988122: step 160570, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 10h:41m:55s remains)
INFO - root - 2017-12-17 00:40:04.209527: step 160580, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 10h:20m:09s remains)
INFO - root - 2017-12-17 00:40:06.400656: step 160590, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 10h:28m:40s remains)
INFO - root - 2017-12-17 00:40:08.696839: step 160600, loss = 0.53, batch loss = 0.35 (33.2 examples/sec; 0.241 sec/batch; 11h:30m:01s remains)
INFO - root - 2017-12-17 00:40:11.013582: step 160610, loss = 0.45, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 10h:42m:07s remains)
INFO - root - 2017-12-17 00:40:13.259961: step 160620, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 10h:30m:46s remains)
INFO - root - 2017-12-17 00:40:15.432495: step 160630, loss = 0.55, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 10h:30m:33s remains)
INFO - root - 2017-12-17 00:40:17.625668: step 160640, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 10h:26m:13s remains)
INFO - root - 2017-12-17 00:40:19.875210: step 160650, loss = 0.43, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 10h:22m:32s remains)
INFO - root - 2017-12-17 00:40:22.093156: step 160660, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 10h:31m:14s remains)
INFO - root - 2017-12-17 00:40:24.335925: step 160670, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 10h:24m:45s remains)
INFO - root - 2017-12-17 00:40:26.543138: step 160680, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.221 sec/batch; 10h:33m:58s remains)
INFO - root - 2017-12-17 00:40:28.741605: step 160690, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 10h:20m:49s remains)
INFO - root - 2017-12-17 00:40:30.911813: step 160700, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 10h:25m:19s remains)
INFO - root - 2017-12-17 00:40:33.276657: step 160710, loss = 0.45, batch loss = 0.28 (37.0 examples/sec; 0.217 sec/batch; 10h:19m:52s remains)
INFO - root - 2017-12-17 00:40:35.517057: step 160720, loss = 0.57, batch loss = 0.39 (38.0 examples/sec; 0.210 sec/batch; 10h:02m:02s remains)
INFO - root - 2017-12-17 00:40:37.699440: step 160730, loss = 0.44, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 10h:34m:52s remains)
INFO - root - 2017-12-17 00:40:39.900813: step 160740, loss = 0.50, batch loss = 0.33 (34.2 examples/sec; 0.234 sec/batch; 11h:08m:39s remains)
INFO - root - 2017-12-17 00:40:42.131444: step 160750, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 10h:35m:40s remains)
INFO - root - 2017-12-17 00:40:44.359140: step 160760, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 10h:24m:49s remains)
INFO - root - 2017-12-17 00:40:46.552974: step 160770, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 10h:38m:36s remains)
INFO - root - 2017-12-17 00:40:48.771568: step 160780, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 10h:18m:36s remains)
INFO - root - 2017-12-17 00:40:50.952847: step 160790, loss = 0.48, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 10h:47m:05s remains)
INFO - root - 2017-12-17 00:40:53.181182: step 160800, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 10h:19m:46s remains)
INFO - root - 2017-12-17 00:40:55.542791: step 160810, loss = 0.47, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 10h:45m:10s remains)
INFO - root - 2017-12-17 00:40:57.787071: step 160820, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 10h:33m:07s remains)
INFO - root - 2017-12-17 00:40:59.984632: step 160830, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 10h:32m:09s remains)
INFO - root - 2017-12-17 00:41:02.269697: step 160840, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 10h:40m:17s remains)
INFO - root - 2017-12-17 00:41:04.461822: step 160850, loss = 0.52, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 10h:17m:46s remains)
INFO - root - 2017-12-17 00:41:06.655445: step 160860, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 10h:32m:47s remains)
INFO - root - 2017-12-17 00:41:08.884054: step 160870, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 10h:25m:14s remains)
INFO - root - 2017-12-17 00:41:11.100310: step 160880, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 10h:38m:38s remains)
INFO - root - 2017-12-17 00:41:13.285680: step 160890, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 10h:38m:08s remains)
INFO - root - 2017-12-17 00:41:15.461682: step 160900, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 10h:19m:15s remains)
INFO - root - 2017-12-17 00:41:17.798738: step 160910, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 10h:19m:53s remains)
INFO - root - 2017-12-17 00:41:19.980384: step 160920, loss = 0.55, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 10h:30m:18s remains)
INFO - root - 2017-12-17 00:41:22.225116: step 160930, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 10h:31m:54s remains)
INFO - root - 2017-12-17 00:41:24.428173: step 160940, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 10h:25m:52s remains)
INFO - root - 2017-12-17 00:41:26.633272: step 160950, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 10h:35m:41s remains)
INFO - root - 2017-12-17 00:41:28.876025: step 160960, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 10h:17m:52s remains)
INFO - root - 2017-12-17 00:41:31.055359: step 160970, loss = 0.43, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 10h:19m:41s remains)
INFO - root - 2017-12-17 00:41:33.280740: step 160980, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 10h:42m:19s remains)
INFO - root - 2017-12-17 00:41:35.601383: step 160990, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 10h:29m:17s remains)
INFO - root - 2017-12-17 00:41:37.790720: step 161000, loss = 0.58, batch loss = 0.40 (35.5 examples/sec; 0.225 sec/batch; 10h:43m:56s remains)
INFO - root - 2017-12-17 00:41:40.145625: step 161010, loss = 0.50, batch loss = 0.32 (33.8 examples/sec; 0.236 sec/batch; 11h:15m:44s remains)
INFO - root - 2017-12-17 00:41:42.336031: step 161020, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 10h:27m:24s remains)
INFO - root - 2017-12-17 00:41:44.547242: step 161030, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 10h:59m:33s remains)
INFO - root - 2017-12-17 00:41:46.763348: step 161040, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 10h:31m:18s remains)
INFO - root - 2017-12-17 00:41:48.991107: step 161050, loss = 0.42, batch loss = 0.24 (36.0 examples/sec; 0.222 sec/batch; 10h:35m:19s remains)
INFO - root - 2017-12-17 00:41:51.197719: step 161060, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 10h:16m:16s remains)
INFO - root - 2017-12-17 00:41:53.399623: step 161070, loss = 0.44, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 10h:54m:16s remains)
INFO - root - 2017-12-17 00:41:55.620772: step 161080, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 10h:32m:56s remains)
INFO - root - 2017-12-17 00:41:57.833859: step 161090, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 10h:18m:35s remains)
INFO - root - 2017-12-17 00:42:00.104829: step 161100, loss = 0.48, batch loss = 0.31 (34.7 examples/sec; 0.230 sec/batch; 10h:57m:52s remains)
INFO - root - 2017-12-17 00:42:02.460014: step 161110, loss = 0.44, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 10h:18m:08s remains)
INFO - root - 2017-12-17 00:42:04.681426: step 161120, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 10h:14m:23s remains)
INFO - root - 2017-12-17 00:42:06.869109: step 161130, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 10h:33m:02s remains)
INFO - root - 2017-12-17 00:42:09.076695: step 161140, loss = 0.56, batch loss = 0.38 (37.0 examples/sec; 0.216 sec/batch; 10h:17m:30s remains)
INFO - root - 2017-12-17 00:42:11.262357: step 161150, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 10h:35m:57s remains)
INFO - root - 2017-12-17 00:42:13.476674: step 161160, loss = 0.47, batch loss = 0.29 (37.9 examples/sec; 0.211 sec/batch; 10h:03m:26s remains)
INFO - root - 2017-12-17 00:42:15.720771: step 161170, loss = 0.47, batch loss = 0.30 (34.1 examples/sec; 0.235 sec/batch; 11h:10m:15s remains)
INFO - root - 2017-12-17 00:42:17.912261: step 161180, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 10h:34m:13s remains)
INFO - root - 2017-12-17 00:42:20.174203: step 161190, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.233 sec/batch; 11h:03m:54s remains)
INFO - root - 2017-12-17 00:42:22.367566: step 161200, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 10h:22m:58s remains)
INFO - root - 2017-12-17 00:42:24.701100: step 161210, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 10h:33m:25s remains)
INFO - root - 2017-12-17 00:42:26.886577: step 161220, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 10h:31m:24s remains)
INFO - root - 2017-12-17 00:42:29.088394: step 161230, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 10h:33m:54s remains)
INFO - root - 2017-12-17 00:42:31.301618: step 161240, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 10h:42m:53s remains)
INFO - root - 2017-12-17 00:42:33.524615: step 161250, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 10h:27m:00s remains)
INFO - root - 2017-12-17 00:42:35.747051: step 161260, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 10h:42m:56s remains)
INFO - root - 2017-12-17 00:42:37.990676: step 161270, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.218 sec/batch; 10h:20m:57s remains)
INFO - root - 2017-12-17 00:42:40.214874: step 161280, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 10h:29m:21s remains)
INFO - root - 2017-12-17 00:42:42.460459: step 161290, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 10h:19m:15s remains)
INFO - root - 2017-12-17 00:42:44.674945: step 161300, loss = 0.55, batch loss = 0.37 (35.9 examples/sec; 0.223 sec/batch; 10h:36m:10s remains)
INFO - root - 2017-12-17 00:42:47.013363: step 161310, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 10h:17m:40s remains)
INFO - root - 2017-12-17 00:42:49.225355: step 161320, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 10h:22m:43s remains)
INFO - root - 2017-12-17 00:42:51.484576: step 161330, loss = 0.50, batch loss = 0.32 (34.4 examples/sec; 0.233 sec/batch; 11h:04m:18s remains)
INFO - root - 2017-12-17 00:42:53.736582: step 161340, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 10h:25m:06s remains)
INFO - root - 2017-12-17 00:42:55.934463: step 161350, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 10h:22m:02s remains)
INFO - root - 2017-12-17 00:42:58.134829: step 161360, loss = 0.55, batch loss = 0.37 (36.7 examples/sec; 0.218 sec/batch; 10h:21m:48s remains)
INFO - root - 2017-12-17 00:43:00.366325: step 161370, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 10h:03m:32s remains)
INFO - root - 2017-12-17 00:43:02.570471: step 161380, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.224 sec/batch; 10h:37m:40s remains)
INFO - root - 2017-12-17 00:43:04.769808: step 161390, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 10h:28m:00s remains)
INFO - root - 2017-12-17 00:43:06.989555: step 161400, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 10h:27m:00s remains)
INFO - root - 2017-12-17 00:43:09.372106: step 161410, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 10h:08m:04s remains)
INFO - root - 2017-12-17 00:43:11.556721: step 161420, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 10h:13m:31s remains)
INFO - root - 2017-12-17 00:43:13.776406: step 161430, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 10h:16m:24s remains)
INFO - root - 2017-12-17 00:43:15.977504: step 161440, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 10h:44m:19s remains)
INFO - root - 2017-12-17 00:43:18.187848: step 161450, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 10h:24m:12s remains)
INFO - root - 2017-12-17 00:43:20.414332: step 161460, loss = 0.57, batch loss = 0.40 (35.7 examples/sec; 0.224 sec/batch; 10h:38m:04s remains)
INFO - root - 2017-12-17 00:43:22.629694: step 161470, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 10h:12m:42s remains)
INFO - root - 2017-12-17 00:43:24.821824: step 161480, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 10h:17m:36s remains)
INFO - root - 2017-12-17 00:43:27.042136: step 161490, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 10h:41m:48s remains)
INFO - root - 2017-12-17 00:43:29.248349: step 161500, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 10h:30m:39s remains)
INFO - root - 2017-12-17 00:43:31.609842: step 161510, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 10h:20m:47s remains)
INFO - root - 2017-12-17 00:43:33.828948: step 161520, loss = 0.48, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 10h:41m:53s remains)
INFO - root - 2017-12-17 00:43:36.070630: step 161530, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 10h:12m:56s remains)
INFO - root - 2017-12-17 00:43:38.307800: step 161540, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 10h:24m:30s remains)
INFO - root - 2017-12-17 00:43:40.544314: step 161550, loss = 0.50, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 10h:23m:13s remains)
INFO - root - 2017-12-17 00:43:42.775459: step 161560, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 10h:47m:56s remains)
INFO - root - 2017-12-17 00:43:44.963824: step 161570, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 10h:10m:07s remains)
INFO - root - 2017-12-17 00:43:47.212731: step 161580, loss = 0.42, batch loss = 0.24 (36.6 examples/sec; 0.219 sec/batch; 10h:22m:43s remains)
INFO - root - 2017-12-17 00:43:49.424932: step 161590, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 10h:50m:15s remains)
INFO - root - 2017-12-17 00:43:51.625341: step 161600, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 10h:29m:35s remains)
INFO - root - 2017-12-17 00:43:53.958954: step 161610, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 10h:40m:43s remains)
INFO - root - 2017-12-17 00:43:56.156205: step 161620, loss = 0.48, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 10h:48m:45s remains)
INFO - root - 2017-12-17 00:43:58.390679: step 161630, loss = 0.46, batch loss = 0.28 (34.0 examples/sec; 0.236 sec/batch; 11h:10m:57s remains)
INFO - root - 2017-12-17 00:44:00.579029: step 161640, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 10h:29m:26s remains)
INFO - root - 2017-12-17 00:44:02.775434: step 161650, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 10h:29m:00s remains)
INFO - root - 2017-12-17 00:44:04.964888: step 161660, loss = 0.53, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 10h:40m:03s remains)
INFO - root - 2017-12-17 00:44:07.167019: step 161670, loss = 0.57, batch loss = 0.39 (36.5 examples/sec; 0.219 sec/batch; 10h:23m:48s remains)
INFO - root - 2017-12-17 00:44:09.389942: step 161680, loss = 0.49, batch loss = 0.32 (33.6 examples/sec; 0.238 sec/batch; 11h:18m:06s remains)
INFO - root - 2017-12-17 00:44:11.620614: step 161690, loss = 0.54, batch loss = 0.36 (33.5 examples/sec; 0.239 sec/batch; 11h:20m:38s remains)
INFO - root - 2017-12-17 00:44:13.822289: step 161700, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 10h:48m:55s remains)
INFO - root - 2017-12-17 00:44:16.161571: step 161710, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 10h:32m:05s remains)
INFO - root - 2017-12-17 00:44:18.362866: step 161720, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 10h:43m:16s remains)
INFO - root - 2017-12-17 00:44:20.552694: step 161730, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 10h:21m:26s remains)
INFO - root - 2017-12-17 00:44:22.737095: step 161740, loss = 0.45, batch loss = 0.28 (34.9 examples/sec; 0.230 sec/batch; 10h:53m:10s remains)
INFO - root - 2017-12-17 00:44:24.933904: step 161750, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 10h:15m:22s remains)
INFO - root - 2017-12-17 00:44:27.133690: step 161760, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 10h:42m:51s remains)
INFO - root - 2017-12-17 00:44:29.335445: step 161770, loss = 0.46, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 10h:24m:52s remains)
INFO - root - 2017-12-17 00:44:31.555429: step 161780, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 10h:25m:08s remains)
INFO - root - 2017-12-17 00:44:33.743012: step 161790, loss = 0.57, batch loss = 0.40 (36.5 examples/sec; 0.219 sec/batch; 10h:23m:53s remains)
INFO - root - 2017-12-17 00:44:35.986922: step 161800, loss = 0.61, batch loss = 0.43 (36.3 examples/sec; 0.220 sec/batch; 10h:27m:11s remains)
INFO - root - 2017-12-17 00:44:38.331207: step 161810, loss = 0.49, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 10h:19m:55s remains)
INFO - root - 2017-12-17 00:44:40.526804: step 161820, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 10h:23m:08s remains)
INFO - root - 2017-12-17 00:44:42.754956: step 161830, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 10h:17m:08s remains)
INFO - root - 2017-12-17 00:44:44.969103: step 161840, loss = 0.58, batch loss = 0.41 (36.3 examples/sec; 0.220 sec/batch; 10h:26m:18s remains)
INFO - root - 2017-12-17 00:44:47.204492: step 161850, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 10h:25m:46s remains)
INFO - root - 2017-12-17 00:44:49.428648: step 161860, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 10h:13m:34s remains)
INFO - root - 2017-12-17 00:44:51.635398: step 161870, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 10h:15m:04s remains)
INFO - root - 2017-12-17 00:44:53.857308: step 161880, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 10h:22m:15s remains)
INFO - root - 2017-12-17 00:44:56.083281: step 161890, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 10h:33m:29s remains)
INFO - root - 2017-12-17 00:44:58.266076: step 161900, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 10h:12m:28s remains)
INFO - root - 2017-12-17 00:45:00.630883: step 161910, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 10h:43m:00s remains)
INFO - root - 2017-12-17 00:45:02.824466: step 161920, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 10h:06m:42s remains)
INFO - root - 2017-12-17 00:45:05.033728: step 161930, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 10h:45m:58s remains)
INFO - root - 2017-12-17 00:45:07.270148: step 161940, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 10h:34m:34s remains)
INFO - root - 2017-12-17 00:45:09.475985: step 161950, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 10h:35m:40s remains)
INFO - root - 2017-12-17 00:45:11.671829: step 161960, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 10h:13m:46s remains)
INFO - root - 2017-12-17 00:45:13.851757: step 161970, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 10h:02m:29s remains)
INFO - root - 2017-12-17 00:45:16.088531: step 161980, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 10h:36m:57s remains)
INFO - root - 2017-12-17 00:45:18.300193: step 161990, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 10h:34m:29s remains)
INFO - root - 2017-12-17 00:45:20.511811: step 162000, loss = 0.55, batch loss = 0.37 (35.0 examples/sec; 0.229 sec/batch; 10h:49m:54s remains)
INFO - root - 2017-12-17 00:45:22.866537: step 162010, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 10h:28m:12s remains)
INFO - root - 2017-12-17 00:45:25.080463: step 162020, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.232 sec/batch; 10h:59m:53s remains)
INFO - root - 2017-12-17 00:45:27.293034: step 162030, loss = 0.52, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 10h:11m:47s remains)
INFO - root - 2017-12-17 00:45:29.506059: step 162040, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 10h:59m:36s remains)
INFO - root - 2017-12-17 00:45:31.769545: step 162050, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 10h:27m:27s remains)
INFO - root - 2017-12-17 00:45:33.969162: step 162060, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 10h:32m:00s remains)
INFO - root - 2017-12-17 00:45:36.181690: step 162070, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 10h:44m:13s remains)
INFO - root - 2017-12-17 00:45:38.458200: step 162080, loss = 0.46, batch loss = 0.29 (33.2 examples/sec; 0.241 sec/batch; 11h:24m:52s remains)
INFO - root - 2017-12-17 00:45:40.680314: step 162090, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 10h:17m:41s remains)
INFO - root - 2017-12-17 00:45:42.867277: step 162100, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 10h:38m:46s remains)
INFO - root - 2017-12-17 00:45:45.220753: step 162110, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 10h:13m:30s remains)
INFO - root - 2017-12-17 00:45:47.457583: step 162120, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 10h:19m:04s remains)
INFO - root - 2017-12-17 00:45:49.648697: step 162130, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 10h:22m:55s remains)
INFO - root - 2017-12-17 00:45:51.868531: step 162140, loss = 0.50, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 10h:15m:10s remains)
INFO - root - 2017-12-17 00:45:54.059073: step 162150, loss = 0.53, batch loss = 0.36 (35.0 examples/sec; 0.228 sec/batch; 10h:48m:06s remains)
INFO - root - 2017-12-17 00:45:56.253855: step 162160, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 10h:16m:37s remains)
INFO - root - 2017-12-17 00:45:58.443981: step 162170, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 10h:05m:42s remains)
INFO - root - 2017-12-17 00:46:00.647142: step 162180, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 10h:20m:27s remains)
INFO - root - 2017-12-17 00:46:02.889066: step 162190, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 10h:18m:58s remains)
INFO - root - 2017-12-17 00:46:05.108855: step 162200, loss = 0.60, batch loss = 0.42 (36.5 examples/sec; 0.219 sec/batch; 10h:22m:22s remains)
INFO - root - 2017-12-17 00:46:07.485890: step 162210, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 10h:43m:25s remains)
INFO - root - 2017-12-17 00:46:09.734547: step 162220, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 10h:07m:37s remains)
INFO - root - 2017-12-17 00:46:11.951720: step 162230, loss = 0.45, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 10h:15m:19s remains)
INFO - root - 2017-12-17 00:46:14.140473: step 162240, loss = 0.53, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 10h:21m:41s remains)
INFO - root - 2017-12-17 00:46:16.349029: step 162250, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 10h:32m:10s remains)
INFO - root - 2017-12-17 00:46:18.543683: step 162260, loss = 0.50, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 10h:06m:24s remains)
INFO - root - 2017-12-17 00:46:20.742619: step 162270, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 10h:57m:38s remains)
INFO - root - 2017-12-17 00:46:22.914206: step 162280, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 10h:16m:04s remains)
INFO - root - 2017-12-17 00:46:25.138058: step 162290, loss = 0.44, batch loss = 0.27 (35.0 examples/sec; 0.229 sec/batch; 10h:48m:25s remains)
INFO - root - 2017-12-17 00:46:27.379770: step 162300, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 10h:35m:54s remains)
INFO - root - 2017-12-17 00:46:29.725771: step 162310, loss = 0.41, batch loss = 0.23 (34.5 examples/sec; 0.232 sec/batch; 10h:57m:08s remains)
INFO - root - 2017-12-17 00:46:31.901294: step 162320, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.214 sec/batch; 10h:07m:38s remains)
INFO - root - 2017-12-17 00:46:34.102455: step 162330, loss = 0.57, batch loss = 0.39 (37.0 examples/sec; 0.216 sec/batch; 10h:12m:30s remains)
INFO - root - 2017-12-17 00:46:36.271642: step 162340, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 10h:18m:17s remains)
INFO - root - 2017-12-17 00:46:38.484997: step 162350, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 10h:28m:41s remains)
INFO - root - 2017-12-17 00:46:40.692428: step 162360, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 10h:18m:34s remains)
INFO - root - 2017-12-17 00:46:42.882321: step 162370, loss = 0.54, batch loss = 0.36 (37.0 examples/sec; 0.216 sec/batch; 10h:13m:41s remains)
INFO - root - 2017-12-17 00:46:45.131174: step 162380, loss = 0.47, batch loss = 0.29 (30.8 examples/sec; 0.259 sec/batch; 12h:15m:22s remains)
INFO - root - 2017-12-17 00:46:47.371061: step 162390, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 10h:09m:59s remains)
INFO - root - 2017-12-17 00:46:49.602494: step 162400, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 10h:20m:20s remains)
INFO - root - 2017-12-17 00:46:51.990076: step 162410, loss = 0.43, batch loss = 0.25 (37.5 examples/sec; 0.213 sec/batch; 10h:04m:27s remains)
INFO - root - 2017-12-17 00:46:54.209907: step 162420, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 10h:06m:10s remains)
INFO - root - 2017-12-17 00:46:56.443848: step 162430, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 10h:32m:49s remains)
INFO - root - 2017-12-17 00:46:58.653663: step 162440, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.224 sec/batch; 10h:36m:05s remains)
INFO - root - 2017-12-17 00:47:00.862044: step 162450, loss = 0.57, batch loss = 0.39 (36.0 examples/sec; 0.222 sec/batch; 10h:29m:48s remains)
INFO - root - 2017-12-17 00:47:03.084462: step 162460, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 10h:14m:25s remains)
INFO - root - 2017-12-17 00:47:05.329168: step 162470, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 10h:15m:16s remains)
INFO - root - 2017-12-17 00:47:07.522409: step 162480, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 10h:31m:48s remains)
INFO - root - 2017-12-17 00:47:09.772186: step 162490, loss = 0.50, batch loss = 0.32 (34.0 examples/sec; 0.235 sec/batch; 11h:06m:35s remains)
INFO - root - 2017-12-17 00:47:11.987421: step 162500, loss = 0.47, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 10h:27m:31s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-162500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-162500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 00:47:14.722391: step 162510, loss = 0.55, batch loss = 0.37 (37.2 examples/sec; 0.215 sec/batch; 10h:09m:05s remains)
INFO - root - 2017-12-17 00:47:16.942384: step 162520, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 10h:07m:46s remains)
INFO - root - 2017-12-17 00:47:19.131168: step 162530, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 10h:31m:10s remains)
INFO - root - 2017-12-17 00:47:21.322134: step 162540, loss = 0.50, batch loss = 0.32 (34.3 examples/sec; 0.233 sec/batch; 11h:00m:47s remains)
INFO - root - 2017-12-17 00:47:23.557100: step 162550, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 10h:18m:42s remains)
INFO - root - 2017-12-17 00:47:25.783855: step 162560, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 10h:25m:41s remains)
INFO - root - 2017-12-17 00:47:27.988396: step 162570, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 10h:14m:21s remains)
INFO - root - 2017-12-17 00:47:30.156718: step 162580, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 10h:29m:58s remains)
INFO - root - 2017-12-17 00:47:32.362433: step 162590, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 10h:25m:19s remains)
INFO - root - 2017-12-17 00:47:34.584325: step 162600, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 10h:33m:48s remains)
INFO - root - 2017-12-17 00:47:36.930018: step 162610, loss = 0.49, batch loss = 0.32 (37.4 examples/sec; 0.214 sec/batch; 10h:05m:44s remains)
INFO - root - 2017-12-17 00:47:39.119206: step 162620, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 10h:04m:10s remains)
INFO - root - 2017-12-17 00:47:41.315318: step 162630, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 10h:17m:33s remains)
INFO - root - 2017-12-17 00:47:43.528319: step 162640, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 10h:10m:55s remains)
INFO - root - 2017-12-17 00:47:45.766905: step 162650, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 10h:00m:50s remains)
INFO - root - 2017-12-17 00:47:47.975524: step 162660, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 10h:20m:41s remains)
INFO - root - 2017-12-17 00:47:50.164575: step 162670, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 10h:05m:00s remains)
INFO - root - 2017-12-17 00:47:52.420861: step 162680, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 10h:10m:33s remains)
INFO - root - 2017-12-17 00:47:54.689170: step 162690, loss = 0.48, batch loss = 0.30 (32.7 examples/sec; 0.245 sec/batch; 11h:32m:20s remains)
INFO - root - 2017-12-17 00:47:56.860255: step 162700, loss = 0.55, batch loss = 0.37 (35.9 examples/sec; 0.223 sec/batch; 10h:30m:16s remains)
INFO - root - 2017-12-17 00:47:59.232937: step 162710, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 10h:26m:24s remains)
INFO - root - 2017-12-17 00:48:01.465650: step 162720, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 10h:31m:37s remains)
INFO - root - 2017-12-17 00:48:03.661926: step 162730, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 10h:29m:57s remains)
INFO - root - 2017-12-17 00:48:05.886394: step 162740, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 10h:37m:16s remains)
INFO - root - 2017-12-17 00:48:08.078413: step 162750, loss = 0.55, batch loss = 0.37 (35.9 examples/sec; 0.223 sec/batch; 10h:30m:15s remains)
INFO - root - 2017-12-17 00:48:10.264707: step 162760, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 10h:15m:17s remains)
INFO - root - 2017-12-17 00:48:12.474741: step 162770, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 10h:22m:04s remains)
INFO - root - 2017-12-17 00:48:14.699325: step 162780, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 10h:21m:06s remains)
INFO - root - 2017-12-17 00:48:16.938066: step 162790, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 10h:24m:20s remains)
INFO - root - 2017-12-17 00:48:19.136746: step 162800, loss = 0.51, batch loss = 0.34 (37.1 examples/sec; 0.216 sec/batch; 10h:10m:41s remains)
INFO - root - 2017-12-17 00:48:21.465672: step 162810, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 10h:14m:48s remains)
INFO - root - 2017-12-17 00:48:23.709329: step 162820, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 10h:28m:26s remains)
INFO - root - 2017-12-17 00:48:25.907928: step 162830, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 10h:13m:00s remains)
INFO - root - 2017-12-17 00:48:28.118160: step 162840, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 10h:18m:51s remains)
INFO - root - 2017-12-17 00:48:30.308749: step 162850, loss = 0.49, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 10h:07m:50s remains)
INFO - root - 2017-12-17 00:48:32.524687: step 162860, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 10h:23m:23s remains)
INFO - root - 2017-12-17 00:48:34.732685: step 162870, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 10h:29m:41s remains)
INFO - root - 2017-12-17 00:48:36.998475: step 162880, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 10h:38m:41s remains)
INFO - root - 2017-12-17 00:48:39.187714: step 162890, loss = 0.53, batch loss = 0.35 (37.5 examples/sec; 0.213 sec/batch; 10h:03m:15s remains)
INFO - root - 2017-12-17 00:48:41.391060: step 162900, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 10h:11m:04s remains)
INFO - root - 2017-12-17 00:48:43.732909: step 162910, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 10h:17m:52s remains)
INFO - root - 2017-12-17 00:48:45.957197: step 162920, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 10h:12m:47s remains)
INFO - root - 2017-12-17 00:48:48.183033: step 162930, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.214 sec/batch; 10h:03m:24s remains)
INFO - root - 2017-12-17 00:48:50.387424: step 162940, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 10h:25m:57s remains)
INFO - root - 2017-12-17 00:48:52.596764: step 162950, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.232 sec/batch; 10h:56m:14s remains)
INFO - root - 2017-12-17 00:48:54.794200: step 162960, loss = 0.50, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 10h:19m:08s remains)
INFO - root - 2017-12-17 00:48:56.984835: step 162970, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 10h:07m:06s remains)
INFO - root - 2017-12-17 00:48:59.230656: step 162980, loss = 0.43, batch loss = 0.25 (35.2 examples/sec; 0.227 sec/batch; 10h:41m:47s remains)
INFO - root - 2017-12-17 00:49:01.425464: step 162990, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 10h:13m:42s remains)
INFO - root - 2017-12-17 00:49:03.648035: step 163000, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 10h:17m:16s remains)
INFO - root - 2017-12-17 00:49:06.043724: step 163010, loss = 0.47, batch loss = 0.30 (34.7 examples/sec; 0.231 sec/batch; 10h:52m:01s remains)
INFO - root - 2017-12-17 00:49:08.266457: step 163020, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 10h:25m:01s remains)
INFO - root - 2017-12-17 00:49:10.510453: step 163030, loss = 0.46, batch loss = 0.28 (34.5 examples/sec; 0.232 sec/batch; 10h:54m:05s remains)
INFO - root - 2017-12-17 00:49:12.735475: step 163040, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 10h:08m:05s remains)
INFO - root - 2017-12-17 00:49:14.955184: step 163050, loss = 0.55, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 10h:19m:12s remains)
INFO - root - 2017-12-17 00:49:17.137598: step 163060, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.221 sec/batch; 10h:25m:19s remains)
INFO - root - 2017-12-17 00:49:19.367116: step 163070, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 10h:18m:35s remains)
INFO - root - 2017-12-17 00:49:21.562974: step 163080, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 10h:09m:24s remains)
INFO - root - 2017-12-17 00:49:23.774208: step 163090, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 10h:36m:19s remains)
INFO - root - 2017-12-17 00:49:26.017806: step 163100, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 10h:36m:03s remains)
INFO - root - 2017-12-17 00:49:28.360247: step 163110, loss = 0.49, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 10h:54m:13s remains)
INFO - root - 2017-12-17 00:49:30.579459: step 163120, loss = 0.44, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 10h:25m:24s remains)
INFO - root - 2017-12-17 00:49:32.814682: step 163130, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 10h:20m:49s remains)
INFO - root - 2017-12-17 00:49:34.980094: step 163140, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.219 sec/batch; 10h:17m:05s remains)
INFO - root - 2017-12-17 00:49:37.189830: step 163150, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 10h:15m:57s remains)
INFO - root - 2017-12-17 00:49:39.436345: step 163160, loss = 0.53, batch loss = 0.35 (35.4 examples/sec; 0.226 sec/batch; 10h:37m:34s remains)
INFO - root - 2017-12-17 00:49:41.646381: step 163170, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 10h:07m:54s remains)
INFO - root - 2017-12-17 00:49:43.846246: step 163180, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 10h:22m:40s remains)
INFO - root - 2017-12-17 00:49:46.036729: step 163190, loss = 0.45, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 10h:09m:00s remains)
INFO - root - 2017-12-17 00:49:48.238960: step 163200, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 10h:33m:59s remains)
INFO - root - 2017-12-17 00:49:50.610259: step 163210, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 10h:13m:48s remains)
INFO - root - 2017-12-17 00:49:52.849161: step 163220, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 10h:40m:00s remains)
INFO - root - 2017-12-17 00:49:55.072778: step 163230, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 10h:06m:36s remains)
INFO - root - 2017-12-17 00:49:57.316446: step 163240, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 10h:30m:57s remains)
INFO - root - 2017-12-17 00:49:59.577508: step 163250, loss = 0.46, batch loss = 0.28 (33.5 examples/sec; 0.239 sec/batch; 11h:13m:19s remains)
INFO - root - 2017-12-17 00:50:01.827099: step 163260, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 10h:35m:57s remains)
INFO - root - 2017-12-17 00:50:04.025758: step 163270, loss = 0.49, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 10h:15m:24s remains)
INFO - root - 2017-12-17 00:50:06.198149: step 163280, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 10h:00m:23s remains)
INFO - root - 2017-12-17 00:50:08.397992: step 163290, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 10h:25m:46s remains)
INFO - root - 2017-12-17 00:50:10.610681: step 163300, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 10h:22m:19s remains)
INFO - root - 2017-12-17 00:50:12.926022: step 163310, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 10h:13m:10s remains)
INFO - root - 2017-12-17 00:50:15.171629: step 163320, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 10h:20m:43s remains)
INFO - root - 2017-12-17 00:50:17.378716: step 163330, loss = 0.44, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 10h:17m:56s remains)
INFO - root - 2017-12-17 00:50:19.601629: step 163340, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 10h:42m:46s remains)
INFO - root - 2017-12-17 00:50:21.827160: step 163350, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 10h:28m:29s remains)
INFO - root - 2017-12-17 00:50:24.042485: step 163360, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 10h:15m:14s remains)
INFO - root - 2017-12-17 00:50:26.268327: step 163370, loss = 0.43, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 10h:26m:01s remains)
INFO - root - 2017-12-17 00:50:28.452931: step 163380, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 10h:23m:42s remains)
INFO - root - 2017-12-17 00:50:30.704328: step 163390, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 9h:59m:03s remains)
INFO - root - 2017-12-17 00:50:32.913681: step 163400, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 10h:25m:23s remains)
INFO - root - 2017-12-17 00:50:35.334428: step 163410, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 10h:17m:22s remains)
INFO - root - 2017-12-17 00:50:37.563526: step 163420, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 10h:37m:41s remains)
INFO - root - 2017-12-17 00:50:39.775816: step 163430, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 10h:15m:18s remains)
INFO - root - 2017-12-17 00:50:41.966017: step 163440, loss = 0.41, batch loss = 0.23 (38.7 examples/sec; 0.207 sec/batch; 9h:42m:54s remains)
INFO - root - 2017-12-17 00:50:44.175439: step 163450, loss = 0.47, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 10h:15m:11s remains)
INFO - root - 2017-12-17 00:50:46.401907: step 163460, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 10h:26m:41s remains)
INFO - root - 2017-12-17 00:50:48.597366: step 163470, loss = 0.51, batch loss = 0.33 (37.7 examples/sec; 0.212 sec/batch; 9h:57m:45s remains)
INFO - root - 2017-12-17 00:50:50.790963: step 163480, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 10h:08m:31s remains)
INFO - root - 2017-12-17 00:50:53.033609: step 163490, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 10h:06m:51s remains)
INFO - root - 2017-12-17 00:50:55.269162: step 163500, loss = 0.56, batch loss = 0.38 (35.9 examples/sec; 0.223 sec/batch; 10h:28m:20s remains)
INFO - root - 2017-12-17 00:50:57.618188: step 163510, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 10h:06m:49s remains)
INFO - root - 2017-12-17 00:50:59.868224: step 163520, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 10h:37m:01s remains)
INFO - root - 2017-12-17 00:51:02.086252: step 163530, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 10h:45m:11s remains)
INFO - root - 2017-12-17 00:51:04.310606: step 163540, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 10h:27m:18s remains)
INFO - root - 2017-12-17 00:51:06.547096: step 163550, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 10h:19m:31s remains)
INFO - root - 2017-12-17 00:51:08.770664: step 163560, loss = 0.45, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 10h:24m:56s remains)
INFO - root - 2017-12-17 00:51:10.972870: step 163570, loss = 0.50, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 10h:07m:28s remains)
INFO - root - 2017-12-17 00:51:13.169264: step 163580, loss = 0.46, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 10h:08m:21s remains)
INFO - root - 2017-12-17 00:51:15.364551: step 163590, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 10h:32m:02s remains)
INFO - root - 2017-12-17 00:51:17.522020: step 163600, loss = 0.48, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 10h:20m:35s remains)
INFO - root - 2017-12-17 00:51:19.844849: step 163610, loss = 0.54, batch loss = 0.36 (35.6 examples/sec; 0.225 sec/batch; 10h:32m:48s remains)
INFO - root - 2017-12-17 00:51:22.039700: step 163620, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 10h:15m:09s remains)
INFO - root - 2017-12-17 00:51:24.262959: step 163630, loss = 0.45, batch loss = 0.27 (34.3 examples/sec; 0.233 sec/batch; 10h:56m:13s remains)
INFO - root - 2017-12-17 00:51:26.509773: step 163640, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 10h:25m:12s remains)
INFO - root - 2017-12-17 00:51:28.698229: step 163650, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 10h:19m:02s remains)
INFO - root - 2017-12-17 00:51:30.896006: step 163660, loss = 0.49, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 10h:20m:18s remains)
INFO - root - 2017-12-17 00:51:33.133839: step 163670, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 10h:01m:57s remains)
INFO - root - 2017-12-17 00:51:35.349598: step 163680, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.215 sec/batch; 10h:06m:00s remains)
INFO - root - 2017-12-17 00:51:37.576945: step 163690, loss = 0.45, batch loss = 0.27 (34.6 examples/sec; 0.231 sec/batch; 10h:50m:27s remains)
INFO - root - 2017-12-17 00:51:39.795653: step 163700, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 10h:26m:51s remains)
INFO - root - 2017-12-17 00:51:42.117365: step 163710, loss = 0.49, batch loss = 0.32 (35.6 examples/sec; 0.224 sec/batch; 10h:31m:25s remains)
INFO - root - 2017-12-17 00:51:44.289370: step 163720, loss = 0.51, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 10h:11m:55s remains)
INFO - root - 2017-12-17 00:51:46.516724: step 163730, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 10h:38m:07s remains)
INFO - root - 2017-12-17 00:51:48.706290: step 163740, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 10h:05m:50s remains)
INFO - root - 2017-12-17 00:51:50.911555: step 163750, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 10h:31m:35s remains)
INFO - root - 2017-12-17 00:51:53.137192: step 163760, loss = 0.49, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 10h:22m:05s remains)
INFO - root - 2017-12-17 00:51:55.328656: step 163770, loss = 0.51, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 10h:45m:40s remains)
INFO - root - 2017-12-17 00:51:57.565016: step 163780, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 10h:04m:04s remains)
INFO - root - 2017-12-17 00:51:59.769134: step 163790, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 10h:26m:37s remains)
INFO - root - 2017-12-17 00:52:01.988715: step 163800, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 10h:05m:58s remains)
INFO - root - 2017-12-17 00:52:04.291687: step 163810, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 10h:10m:13s remains)
INFO - root - 2017-12-17 00:52:06.488687: step 163820, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 10h:19m:02s remains)
INFO - root - 2017-12-17 00:52:08.712966: step 163830, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 10h:20m:19s remains)
INFO - root - 2017-12-17 00:52:10.910545: step 163840, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 10h:08m:22s remains)
INFO - root - 2017-12-17 00:52:13.145545: step 163850, loss = 0.40, batch loss = 0.22 (37.0 examples/sec; 0.216 sec/batch; 10h:07m:03s remains)
INFO - root - 2017-12-17 00:52:15.334760: step 163860, loss = 0.42, batch loss = 0.24 (37.3 examples/sec; 0.215 sec/batch; 10h:03m:08s remains)
INFO - root - 2017-12-17 00:52:17.544394: step 163870, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 10h:33m:58s remains)
INFO - root - 2017-12-17 00:52:19.817889: step 163880, loss = 0.43, batch loss = 0.25 (35.2 examples/sec; 0.227 sec/batch; 10h:38m:32s remains)
INFO - root - 2017-12-17 00:52:22.062360: step 163890, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 10h:13m:53s remains)
INFO - root - 2017-12-17 00:52:24.318360: step 163900, loss = 0.45, batch loss = 0.27 (32.5 examples/sec; 0.246 sec/batch; 11h:31m:12s remains)
INFO - root - 2017-12-17 00:52:26.657467: step 163910, loss = 0.48, batch loss = 0.30 (38.1 examples/sec; 0.210 sec/batch; 9h:49m:31s remains)
INFO - root - 2017-12-17 00:52:28.866104: step 163920, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 10h:18m:04s remains)
INFO - root - 2017-12-17 00:52:31.077052: step 163930, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 10h:23m:38s remains)
INFO - root - 2017-12-17 00:52:33.295261: step 163940, loss = 0.48, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 10h:07m:30s remains)
INFO - root - 2017-12-17 00:52:35.501134: step 163950, loss = 0.47, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 10h:57m:29s remains)
INFO - root - 2017-12-17 00:52:37.690545: step 163960, loss = 0.51, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 10h:25m:51s remains)
INFO - root - 2017-12-17 00:52:39.886105: step 163970, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 10h:21m:33s remains)
INFO - root - 2017-12-17 00:52:42.132111: step 163980, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 10h:21m:35s remains)
INFO - root - 2017-12-17 00:52:44.359842: step 163990, loss = 0.48, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 10h:26m:47s remains)
INFO - root - 2017-12-17 00:52:46.543751: step 164000, loss = 0.50, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 10h:20m:06s remains)
INFO - root - 2017-12-17 00:52:48.886612: step 164010, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 10h:06m:13s remains)
INFO - root - 2017-12-17 00:52:51.130113: step 164020, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 10h:32m:40s remains)
INFO - root - 2017-12-17 00:52:53.383981: step 164030, loss = 0.44, batch loss = 0.26 (34.2 examples/sec; 0.234 sec/batch; 10h:56m:49s remains)
INFO - root - 2017-12-17 00:52:55.599896: step 164040, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 10h:17m:44s remains)
INFO - root - 2017-12-17 00:52:57.814101: step 164050, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 10h:07m:45s remains)
INFO - root - 2017-12-17 00:53:00.064213: step 164060, loss = 0.44, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 10h:44m:01s remains)
INFO - root - 2017-12-17 00:53:02.241984: step 164070, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 10h:14m:56s remains)
INFO - root - 2017-12-17 00:53:04.413297: step 164080, loss = 0.58, batch loss = 0.40 (36.1 examples/sec; 0.222 sec/batch; 10h:21m:47s remains)
INFO - root - 2017-12-17 00:53:06.646093: step 164090, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.224 sec/batch; 10h:30m:06s remains)
INFO - root - 2017-12-17 00:53:08.884678: step 164100, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 10h:37m:54s remains)
INFO - root - 2017-12-17 00:53:11.261837: step 164110, loss = 0.48, batch loss = 0.30 (34.7 examples/sec; 0.231 sec/batch; 10h:47m:40s remains)
INFO - root - 2017-12-17 00:53:13.461795: step 164120, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 10h:13m:41s remains)
INFO - root - 2017-12-17 00:53:15.638735: step 164130, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 10h:28m:01s remains)
INFO - root - 2017-12-17 00:53:17.838000: step 164140, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.224 sec/batch; 10h:29m:52s remains)
INFO - root - 2017-12-17 00:53:20.044724: step 164150, loss = 0.41, batch loss = 0.23 (36.6 examples/sec; 0.218 sec/batch; 10h:13m:03s remains)
INFO - root - 2017-12-17 00:53:22.257313: step 164160, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 10h:14m:02s remains)
INFO - root - 2017-12-17 00:53:24.502854: step 164170, loss = 0.50, batch loss = 0.33 (35.1 examples/sec; 0.228 sec/batch; 10h:39m:45s remains)
INFO - root - 2017-12-17 00:53:26.753625: step 164180, loss = 0.48, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 10h:22m:26s remains)
INFO - root - 2017-12-17 00:53:28.970712: step 164190, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 10h:03m:36s remains)
INFO - root - 2017-12-17 00:53:31.199536: step 164200, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 10h:05m:57s remains)
INFO - root - 2017-12-17 00:53:33.514753: step 164210, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 10h:16m:22s remains)
INFO - root - 2017-12-17 00:53:35.737685: step 164220, loss = 0.51, batch loss = 0.33 (35.0 examples/sec; 0.228 sec/batch; 10h:40m:26s remains)
INFO - root - 2017-12-17 00:53:37.993783: step 164230, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 10h:07m:30s remains)
INFO - root - 2017-12-17 00:53:40.221615: step 164240, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.218 sec/batch; 10h:10m:25s remains)
INFO - root - 2017-12-17 00:53:42.423670: step 164250, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 10h:05m:44s remains)
INFO - root - 2017-12-17 00:53:44.632168: step 164260, loss = 0.63, batch loss = 0.46 (34.3 examples/sec; 0.233 sec/batch; 10h:54m:36s remains)
INFO - root - 2017-12-17 00:53:46.822179: step 164270, loss = 0.44, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 9h:55m:59s remains)
INFO - root - 2017-12-17 00:53:49.029921: step 164280, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 10h:48m:08s remains)
INFO - root - 2017-12-17 00:53:51.248602: step 164290, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 10h:08m:11s remains)
INFO - root - 2017-12-17 00:53:53.502874: step 164300, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 10h:20m:58s remains)
INFO - root - 2017-12-17 00:53:55.817219: step 164310, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 10h:12m:36s remains)
INFO - root - 2017-12-17 00:53:58.037717: step 164320, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 10h:18m:56s remains)
INFO - root - 2017-12-17 00:54:00.250029: step 164330, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 10h:37m:27s remains)
INFO - root - 2017-12-17 00:54:02.476616: step 164340, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 10h:17m:47s remains)
INFO - root - 2017-12-17 00:54:04.673501: step 164350, loss = 0.52, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 9h:59m:23s remains)
INFO - root - 2017-12-17 00:54:06.869062: step 164360, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 10h:13m:09s remains)
INFO - root - 2017-12-17 00:54:09.086898: step 164370, loss = 0.58, batch loss = 0.40 (36.3 examples/sec; 0.221 sec/batch; 10h:18m:10s remains)
INFO - root - 2017-12-17 00:54:11.315207: step 164380, loss = 0.51, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 10h:21m:26s remains)
INFO - root - 2017-12-17 00:54:13.507395: step 164390, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 10h:00m:21s remains)
INFO - root - 2017-12-17 00:54:15.740707: step 164400, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 10h:16m:42s remains)
INFO - root - 2017-12-17 00:54:18.086919: step 164410, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 10h:15m:10s remains)
INFO - root - 2017-12-17 00:54:20.309342: step 164420, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 10h:35m:43s remains)
INFO - root - 2017-12-17 00:54:22.554794: step 164430, loss = 0.57, batch loss = 0.40 (35.6 examples/sec; 0.225 sec/batch; 10h:29m:37s remains)
INFO - root - 2017-12-17 00:54:24.757819: step 164440, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 10h:14m:18s remains)
INFO - root - 2017-12-17 00:54:27.006523: step 164450, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 10h:30m:25s remains)
INFO - root - 2017-12-17 00:54:29.235794: step 164460, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 10h:20m:50s remains)
INFO - root - 2017-12-17 00:54:31.466326: step 164470, loss = 0.46, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 10h:24m:00s remains)
INFO - root - 2017-12-17 00:54:33.695959: step 164480, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 10h:04m:51s remains)
INFO - root - 2017-12-17 00:54:35.882943: step 164490, loss = 0.42, batch loss = 0.24 (36.5 examples/sec; 0.219 sec/batch; 10h:13m:42s remains)
INFO - root - 2017-12-17 00:54:38.121491: step 164500, loss = 0.49, batch loss = 0.31 (34.3 examples/sec; 0.233 sec/batch; 10h:52m:30s remains)
INFO - root - 2017-12-17 00:54:40.465154: step 164510, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 10h:15m:05s remains)
INFO - root - 2017-12-17 00:54:42.688948: step 164520, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.229 sec/batch; 10h:39m:43s remains)
INFO - root - 2017-12-17 00:54:44.888120: step 164530, loss = 0.48, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 10h:14m:13s remains)
INFO - root - 2017-12-17 00:54:47.081948: step 164540, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 10h:18m:14s remains)
INFO - root - 2017-12-17 00:54:49.268478: step 164550, loss = 0.45, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 10h:14m:06s remains)
INFO - root - 2017-12-17 00:54:51.472525: step 164560, loss = 0.44, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 10h:38m:03s remains)
INFO - root - 2017-12-17 00:54:53.725987: step 164570, loss = 0.45, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 10h:16m:55s remains)
INFO - root - 2017-12-17 00:54:55.984232: step 164580, loss = 0.45, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 10h:27m:12s remains)
INFO - root - 2017-12-17 00:54:58.206969: step 164590, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 10h:25m:28s remains)
INFO - root - 2017-12-17 00:55:00.425516: step 164600, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 10h:43m:49s remains)
INFO - root - 2017-12-17 00:55:02.793759: step 164610, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 10h:26m:10s remains)
INFO - root - 2017-12-17 00:55:05.024987: step 164620, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 10h:31m:54s remains)
INFO - root - 2017-12-17 00:55:07.226771: step 164630, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 10h:07m:37s remains)
INFO - root - 2017-12-17 00:55:09.456993: step 164640, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 9h:55m:52s remains)
INFO - root - 2017-12-17 00:55:11.639575: step 164650, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 10h:04m:49s remains)
INFO - root - 2017-12-17 00:55:13.870585: step 164660, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 10h:27m:26s remains)
INFO - root - 2017-12-17 00:55:16.099667: step 164670, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 10h:08m:27s remains)
INFO - root - 2017-12-17 00:55:18.333180: step 164680, loss = 0.50, batch loss = 0.32 (33.6 examples/sec; 0.238 sec/batch; 11h:06m:04s remains)
INFO - root - 2017-12-17 00:55:20.581027: step 164690, loss = 0.45, batch loss = 0.27 (33.5 examples/sec; 0.238 sec/batch; 11h:06m:56s remains)
INFO - root - 2017-12-17 00:55:22.841959: step 164700, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 10h:15m:11s remains)
INFO - root - 2017-12-17 00:55:25.213217: step 164710, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 10h:28m:26s remains)
INFO - root - 2017-12-17 00:55:27.421167: step 164720, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 10h:42m:01s remains)
INFO - root - 2017-12-17 00:55:29.622954: step 164730, loss = 0.49, batch loss = 0.31 (34.5 examples/sec; 0.232 sec/batch; 10h:47m:33s remains)
INFO - root - 2017-12-17 00:55:31.805464: step 164740, loss = 0.41, batch loss = 0.23 (35.8 examples/sec; 0.224 sec/batch; 10h:25m:08s remains)
INFO - root - 2017-12-17 00:55:34.042761: step 164750, loss = 0.55, batch loss = 0.37 (37.6 examples/sec; 0.213 sec/batch; 9h:54m:18s remains)
INFO - root - 2017-12-17 00:55:36.275538: step 164760, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 10h:28m:11s remains)
INFO - root - 2017-12-17 00:55:38.472508: step 164770, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 10h:16m:57s remains)
INFO - root - 2017-12-17 00:55:40.690449: step 164780, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 10h:31m:29s remains)
INFO - root - 2017-12-17 00:55:42.879855: step 164790, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 10h:00m:20s remains)
INFO - root - 2017-12-17 00:55:45.110355: step 164800, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 10h:29m:27s remains)
INFO - root - 2017-12-17 00:55:47.454486: step 164810, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 10h:01m:36s remains)
INFO - root - 2017-12-17 00:55:49.671861: step 164820, loss = 0.53, batch loss = 0.35 (38.1 examples/sec; 0.210 sec/batch; 9h:47m:33s remains)
INFO - root - 2017-12-17 00:55:51.930841: step 164830, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 10h:20m:25s remains)
INFO - root - 2017-12-17 00:55:54.183927: step 164840, loss = 0.54, batch loss = 0.36 (36.6 examples/sec; 0.218 sec/batch; 10h:10m:31s remains)
INFO - root - 2017-12-17 00:55:56.391703: step 164850, loss = 0.49, batch loss = 0.32 (34.4 examples/sec; 0.233 sec/batch; 10h:49m:58s remains)
INFO - root - 2017-12-17 00:55:58.613996: step 164860, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 10h:14m:41s remains)
INFO - root - 2017-12-17 00:56:00.810213: step 164870, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 10h:14m:46s remains)
INFO - root - 2017-12-17 00:56:02.990101: step 164880, loss = 0.44, batch loss = 0.26 (38.2 examples/sec; 0.209 sec/batch; 9h:44m:58s remains)
INFO - root - 2017-12-17 00:56:05.200244: step 164890, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 10h:11m:57s remains)
INFO - root - 2017-12-17 00:56:07.439418: step 164900, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 10h:20m:51s remains)
INFO - root - 2017-12-17 00:56:09.812370: step 164910, loss = 0.46, batch loss = 0.28 (33.5 examples/sec; 0.239 sec/batch; 11h:06m:15s remains)
INFO - root - 2017-12-17 00:56:12.045352: step 164920, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 10h:36m:35s remains)
INFO - root - 2017-12-17 00:56:14.269424: step 164930, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 10h:35m:51s remains)
INFO - root - 2017-12-17 00:56:16.474642: step 164940, loss = 0.56, batch loss = 0.38 (36.1 examples/sec; 0.221 sec/batch; 10h:18m:07s remains)
INFO - root - 2017-12-17 00:56:18.700357: step 164950, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 10h:05m:24s remains)
INFO - root - 2017-12-17 00:56:20.922326: step 164960, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 10h:33m:36s remains)
INFO - root - 2017-12-17 00:56:23.181638: step 164970, loss = 0.41, batch loss = 0.23 (35.2 examples/sec; 0.227 sec/batch; 10h:34m:16s remains)
INFO - root - 2017-12-17 00:56:25.424406: step 164980, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 10h:40m:00s remains)
INFO - root - 2017-12-17 00:56:27.629069: step 164990, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 10h:04m:02s remains)
INFO - root - 2017-12-17 00:56:29.815680: step 165000, loss = 0.48, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 9h:58m:55s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-165000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-165000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 00:56:32.532676: step 165010, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 10h:03m:36s remains)
INFO - root - 2017-12-17 00:56:34.733465: step 165020, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 10h:29m:15s remains)
INFO - root - 2017-12-17 00:56:36.937554: step 165030, loss = 0.54, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 10h:22m:09s remains)
INFO - root - 2017-12-17 00:56:39.167200: step 165040, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 10h:18m:59s remains)
INFO - root - 2017-12-17 00:56:41.415340: step 165050, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 10h:32m:45s remains)
INFO - root - 2017-12-17 00:56:43.644631: step 165060, loss = 0.62, batch loss = 0.44 (36.1 examples/sec; 0.222 sec/batch; 10h:18m:38s remains)
INFO - root - 2017-12-17 00:56:45.857172: step 165070, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.228 sec/batch; 10h:35m:06s remains)
INFO - root - 2017-12-17 00:56:48.069677: step 165080, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 10h:16m:32s remains)
INFO - root - 2017-12-17 00:56:50.310384: step 165090, loss = 0.48, batch loss = 0.31 (33.5 examples/sec; 0.239 sec/batch; 11h:06m:19s remains)
INFO - root - 2017-12-17 00:56:52.533259: step 165100, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 10h:03m:45s remains)
INFO - root - 2017-12-17 00:56:54.880505: step 165110, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 10h:28m:44s remains)
INFO - root - 2017-12-17 00:56:57.056504: step 165120, loss = 0.55, batch loss = 0.37 (35.7 examples/sec; 0.224 sec/batch; 10h:25m:47s remains)
INFO - root - 2017-12-17 00:56:59.246931: step 165130, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 10h:01m:19s remains)
INFO - root - 2017-12-17 00:57:01.415527: step 165140, loss = 0.46, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 10h:51m:40s remains)
INFO - root - 2017-12-17 00:57:03.606960: step 165150, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 10h:22m:18s remains)
INFO - root - 2017-12-17 00:57:05.827966: step 165160, loss = 0.52, batch loss = 0.35 (37.1 examples/sec; 0.216 sec/batch; 10h:01m:54s remains)
INFO - root - 2017-12-17 00:57:08.038088: step 165170, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 10h:00m:00s remains)
INFO - root - 2017-12-17 00:57:10.239375: step 165180, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 10h:06m:48s remains)
INFO - root - 2017-12-17 00:57:12.496234: step 165190, loss = 0.54, batch loss = 0.36 (34.5 examples/sec; 0.232 sec/batch; 10h:46m:47s remains)
INFO - root - 2017-12-17 00:57:14.734014: step 165200, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 10h:22m:29s remains)
INFO - root - 2017-12-17 00:57:17.104831: step 165210, loss = 0.54, batch loss = 0.36 (36.4 examples/sec; 0.220 sec/batch; 10h:12m:28s remains)
INFO - root - 2017-12-17 00:57:19.308621: step 165220, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 10h:07m:50s remains)
INFO - root - 2017-12-17 00:57:21.531935: step 165230, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 10h:25m:24s remains)
INFO - root - 2017-12-17 00:57:23.775886: step 165240, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 10h:13m:15s remains)
INFO - root - 2017-12-17 00:57:25.952840: step 165250, loss = 0.49, batch loss = 0.31 (37.8 examples/sec; 0.212 sec/batch; 9h:50m:36s remains)
INFO - root - 2017-12-17 00:57:28.186039: step 165260, loss = 0.49, batch loss = 0.31 (34.7 examples/sec; 0.230 sec/batch; 10h:41m:53s remains)
INFO - root - 2017-12-17 00:57:30.372314: step 165270, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 10h:18m:46s remains)
INFO - root - 2017-12-17 00:57:32.628176: step 165280, loss = 0.45, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 10h:13m:36s remains)
INFO - root - 2017-12-17 00:57:34.889196: step 165290, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 10h:17m:55s remains)
INFO - root - 2017-12-17 00:57:37.094675: step 165300, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 10h:12m:13s remains)
INFO - root - 2017-12-17 00:57:39.485299: step 165310, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 10h:22m:12s remains)
INFO - root - 2017-12-17 00:57:41.682262: step 165320, loss = 0.46, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 10h:06m:56s remains)
INFO - root - 2017-12-17 00:57:43.884753: step 165330, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 10h:20m:13s remains)
INFO - root - 2017-12-17 00:57:46.085893: step 165340, loss = 0.49, batch loss = 0.31 (34.2 examples/sec; 0.234 sec/batch; 10h:51m:57s remains)
INFO - root - 2017-12-17 00:57:48.301816: step 165350, loss = 0.44, batch loss = 0.27 (35.6 examples/sec; 0.224 sec/batch; 10h:25m:19s remains)
INFO - root - 2017-12-17 00:57:50.537112: step 165360, loss = 0.50, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 10h:29m:12s remains)
INFO - root - 2017-12-17 00:57:52.760948: step 165370, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 10h:18m:40s remains)
INFO - root - 2017-12-17 00:57:54.973258: step 165380, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 9h:56m:23s remains)
INFO - root - 2017-12-17 00:57:57.166855: step 165390, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 10h:03m:33s remains)
INFO - root - 2017-12-17 00:57:59.377531: step 165400, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 10h:12m:28s remains)
INFO - root - 2017-12-17 00:58:01.690449: step 165410, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 10h:02m:12s remains)
INFO - root - 2017-12-17 00:58:03.888967: step 165420, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.228 sec/batch; 10h:35m:49s remains)
INFO - root - 2017-12-17 00:58:06.079864: step 165430, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 10h:16m:31s remains)
INFO - root - 2017-12-17 00:58:08.303456: step 165440, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.224 sec/batch; 10h:22m:44s remains)
INFO - root - 2017-12-17 00:58:10.537856: step 165450, loss = 0.43, batch loss = 0.25 (37.6 examples/sec; 0.213 sec/batch; 9h:53m:05s remains)
INFO - root - 2017-12-17 00:58:12.753124: step 165460, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 10h:03m:42s remains)
INFO - root - 2017-12-17 00:58:14.913209: step 165470, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 9h:56m:35s remains)
INFO - root - 2017-12-17 00:58:17.167996: step 165480, loss = 0.50, batch loss = 0.32 (33.9 examples/sec; 0.236 sec/batch; 10h:56m:35s remains)
INFO - root - 2017-12-17 00:58:19.348199: step 165490, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 10h:03m:42s remains)
INFO - root - 2017-12-17 00:58:21.535057: step 165500, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 10h:03m:22s remains)
INFO - root - 2017-12-17 00:58:23.867771: step 165510, loss = 0.44, batch loss = 0.26 (34.0 examples/sec; 0.235 sec/batch; 10h:54m:31s remains)
INFO - root - 2017-12-17 00:58:26.067372: step 165520, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 10h:09m:16s remains)
INFO - root - 2017-12-17 00:58:28.264764: step 165530, loss = 0.50, batch loss = 0.33 (37.6 examples/sec; 0.213 sec/batch; 9h:52m:09s remains)
INFO - root - 2017-12-17 00:58:30.444718: step 165540, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 10h:41m:55s remains)
INFO - root - 2017-12-17 00:58:32.667301: step 165550, loss = 0.43, batch loss = 0.25 (34.5 examples/sec; 0.232 sec/batch; 10h:44m:57s remains)
INFO - root - 2017-12-17 00:58:34.859969: step 165560, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 10h:26m:08s remains)
INFO - root - 2017-12-17 00:58:37.061100: step 165570, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 10h:20m:23s remains)
INFO - root - 2017-12-17 00:58:39.280503: step 165580, loss = 0.59, batch loss = 0.41 (37.1 examples/sec; 0.216 sec/batch; 9h:59m:45s remains)
INFO - root - 2017-12-17 00:58:41.483325: step 165590, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 10h:18m:40s remains)
INFO - root - 2017-12-17 00:58:43.685052: step 165600, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 9h:58m:56s remains)
INFO - root - 2017-12-17 00:58:46.056495: step 165610, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 10h:24m:02s remains)
INFO - root - 2017-12-17 00:58:48.270909: step 165620, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 10h:05m:16s remains)
INFO - root - 2017-12-17 00:58:50.461165: step 165630, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 10h:15m:43s remains)
INFO - root - 2017-12-17 00:58:52.675918: step 165640, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 10h:12m:29s remains)
INFO - root - 2017-12-17 00:58:54.923089: step 165650, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 10h:17m:03s remains)
INFO - root - 2017-12-17 00:58:57.163413: step 165660, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 10h:14m:08s remains)
INFO - root - 2017-12-17 00:58:59.381431: step 165670, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 10h:20m:45s remains)
INFO - root - 2017-12-17 00:59:01.614425: step 165680, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 10h:01m:50s remains)
INFO - root - 2017-12-17 00:59:03.811785: step 165690, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 9h:59m:40s remains)
INFO - root - 2017-12-17 00:59:06.028021: step 165700, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 10h:13m:52s remains)
INFO - root - 2017-12-17 00:59:08.385939: step 165710, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 9h:56m:01s remains)
INFO - root - 2017-12-17 00:59:10.620945: step 165720, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 10h:18m:05s remains)
INFO - root - 2017-12-17 00:59:12.849762: step 165730, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 10h:30m:56s remains)
INFO - root - 2017-12-17 00:59:15.061004: step 165740, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 10h:06m:16s remains)
INFO - root - 2017-12-17 00:59:17.274313: step 165750, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 9h:56m:27s remains)
INFO - root - 2017-12-17 00:59:19.506151: step 165760, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 10h:16m:32s remains)
INFO - root - 2017-12-17 00:59:21.733915: step 165770, loss = 0.42, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 10h:22m:44s remains)
INFO - root - 2017-12-17 00:59:23.980395: step 165780, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 10h:29m:25s remains)
INFO - root - 2017-12-17 00:59:26.181498: step 165790, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 10h:22m:17s remains)
INFO - root - 2017-12-17 00:59:28.427828: step 165800, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 10h:15m:20s remains)
INFO - root - 2017-12-17 00:59:30.786935: step 165810, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 9h:54m:03s remains)
INFO - root - 2017-12-17 00:59:33.008813: step 165820, loss = 0.44, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 10h:36m:34s remains)
INFO - root - 2017-12-17 00:59:35.180338: step 165830, loss = 0.51, batch loss = 0.33 (37.8 examples/sec; 0.212 sec/batch; 9h:48m:22s remains)
INFO - root - 2017-12-17 00:59:37.385694: step 165840, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 10h:21m:29s remains)
INFO - root - 2017-12-17 00:59:39.644931: step 165850, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 10h:15m:36s remains)
INFO - root - 2017-12-17 00:59:41.867913: step 165860, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 10h:05m:00s remains)
INFO - root - 2017-12-17 00:59:44.077488: step 165870, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 10h:15m:20s remains)
INFO - root - 2017-12-17 00:59:46.339731: step 165880, loss = 0.43, batch loss = 0.25 (33.3 examples/sec; 0.240 sec/batch; 11h:06m:43s remains)
INFO - root - 2017-12-17 00:59:48.559521: step 165890, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 10h:06m:38s remains)
INFO - root - 2017-12-17 00:59:50.810013: step 165900, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 10h:17m:10s remains)
INFO - root - 2017-12-17 00:59:53.175170: step 165910, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 10h:08m:29s remains)
INFO - root - 2017-12-17 00:59:55.403388: step 165920, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 10h:27m:11s remains)
INFO - root - 2017-12-17 00:59:57.596891: step 165930, loss = 0.40, batch loss = 0.22 (37.5 examples/sec; 0.214 sec/batch; 9h:52m:47s remains)
INFO - root - 2017-12-17 00:59:59.835794: step 165940, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 10h:07m:52s remains)
INFO - root - 2017-12-17 01:00:02.085369: step 165950, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 10h:19m:25s remains)
INFO - root - 2017-12-17 01:00:04.298978: step 165960, loss = 0.53, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 10h:18m:29s remains)
INFO - root - 2017-12-17 01:00:06.512962: step 165970, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 10h:29m:45s remains)
INFO - root - 2017-12-17 01:00:08.719531: step 165980, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 9h:56m:47s remains)
INFO - root - 2017-12-17 01:00:10.909693: step 165990, loss = 0.47, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 10h:25m:52s remains)
INFO - root - 2017-12-17 01:00:13.086053: step 166000, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 10h:00m:59s remains)
INFO - root - 2017-12-17 01:00:15.430258: step 166010, loss = 0.44, batch loss = 0.26 (38.0 examples/sec; 0.211 sec/batch; 9h:44m:54s remains)
INFO - root - 2017-12-17 01:00:17.624631: step 166020, loss = 0.49, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 10h:11m:26s remains)
INFO - root - 2017-12-17 01:00:19.843863: step 166030, loss = 0.50, batch loss = 0.32 (33.6 examples/sec; 0.238 sec/batch; 11h:00m:01s remains)
INFO - root - 2017-12-17 01:00:22.011833: step 166040, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 10h:17m:56s remains)
INFO - root - 2017-12-17 01:00:24.213594: step 166050, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 9h:56m:02s remains)
INFO - root - 2017-12-17 01:00:26.425715: step 166060, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 10h:03m:03s remains)
INFO - root - 2017-12-17 01:00:28.632826: step 166070, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 10h:23m:24s remains)
INFO - root - 2017-12-17 01:00:30.860575: step 166080, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 10h:19m:29s remains)
INFO - root - 2017-12-17 01:00:33.078595: step 166090, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.218 sec/batch; 10h:05m:37s remains)
INFO - root - 2017-12-17 01:00:35.320338: step 166100, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 10h:37m:48s remains)
INFO - root - 2017-12-17 01:00:37.705427: step 166110, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.224 sec/batch; 10h:20m:15s remains)
INFO - root - 2017-12-17 01:00:39.983461: step 166120, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 10h:27m:51s remains)
INFO - root - 2017-12-17 01:00:42.250238: step 166130, loss = 0.52, batch loss = 0.35 (35.2 examples/sec; 0.227 sec/batch; 10h:29m:53s remains)
INFO - root - 2017-12-17 01:00:44.447967: step 166140, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 10h:08m:52s remains)
INFO - root - 2017-12-17 01:00:46.669225: step 166150, loss = 0.42, batch loss = 0.24 (37.0 examples/sec; 0.216 sec/batch; 9h:58m:47s remains)
INFO - root - 2017-12-17 01:00:48.880173: step 166160, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 10h:26m:31s remains)
INFO - root - 2017-12-17 01:00:51.064490: step 166170, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 10h:17m:30s remains)
INFO - root - 2017-12-17 01:00:53.275483: step 166180, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 9h:57m:41s remains)
INFO - root - 2017-12-17 01:00:55.474701: step 166190, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 10h:17m:29s remains)
INFO - root - 2017-12-17 01:00:57.682368: step 166200, loss = 0.47, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 10h:03m:59s remains)
INFO - root - 2017-12-17 01:01:00.052939: step 166210, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 10h:13m:46s remains)
INFO - root - 2017-12-17 01:01:02.301818: step 166220, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 10h:03m:48s remains)
INFO - root - 2017-12-17 01:01:04.563607: step 166230, loss = 0.49, batch loss = 0.31 (34.3 examples/sec; 0.233 sec/batch; 10h:46m:05s remains)
INFO - root - 2017-12-17 01:01:06.810860: step 166240, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 10h:19m:04s remains)
INFO - root - 2017-12-17 01:01:09.045874: step 166250, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 10h:15m:37s remains)
INFO - root - 2017-12-17 01:01:11.270141: step 166260, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 10h:00m:51s remains)
INFO - root - 2017-12-17 01:01:13.457200: step 166270, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 9h:57m:20s remains)
INFO - root - 2017-12-17 01:01:15.694416: step 166280, loss = 0.53, batch loss = 0.35 (37.5 examples/sec; 0.213 sec/batch; 9h:51m:26s remains)
INFO - root - 2017-12-17 01:01:17.913688: step 166290, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 10h:24m:22s remains)
INFO - root - 2017-12-17 01:01:20.111301: step 166300, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 10h:04m:53s remains)
INFO - root - 2017-12-17 01:01:22.512167: step 166310, loss = 0.49, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 10h:22m:39s remains)
INFO - root - 2017-12-17 01:01:24.751156: step 166320, loss = 0.46, batch loss = 0.29 (34.7 examples/sec; 0.231 sec/batch; 10h:39m:21s remains)
INFO - root - 2017-12-17 01:01:26.961149: step 166330, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 10h:11m:08s remains)
INFO - root - 2017-12-17 01:01:29.191374: step 166340, loss = 0.59, batch loss = 0.41 (35.7 examples/sec; 0.224 sec/batch; 10h:19m:51s remains)
INFO - root - 2017-12-17 01:01:31.424653: step 166350, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 10h:04m:17s remains)
INFO - root - 2017-12-17 01:01:33.667225: step 166360, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 10h:07m:51s remains)
INFO - root - 2017-12-17 01:01:35.920731: step 166370, loss = 0.48, batch loss = 0.30 (33.6 examples/sec; 0.238 sec/batch; 10h:58m:37s remains)
INFO - root - 2017-12-17 01:01:38.149349: step 166380, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 10h:12m:17s remains)
INFO - root - 2017-12-17 01:01:40.389481: step 166390, loss = 0.45, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 10h:33m:52s remains)
INFO - root - 2017-12-17 01:01:42.609193: step 166400, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 10h:13m:51s remains)
INFO - root - 2017-12-17 01:01:45.001076: step 166410, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.214 sec/batch; 9h:51m:02s remains)
INFO - root - 2017-12-17 01:01:47.232287: step 166420, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 10h:41m:35s remains)
INFO - root - 2017-12-17 01:01:49.463793: step 166430, loss = 0.44, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 9h:57m:57s remains)
INFO - root - 2017-12-17 01:01:51.656864: step 166440, loss = 0.53, batch loss = 0.35 (35.8 examples/sec; 0.223 sec/batch; 10h:17m:41s remains)
INFO - root - 2017-12-17 01:01:53.884237: step 166450, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 10h:13m:53s remains)
INFO - root - 2017-12-17 01:01:56.104951: step 166460, loss = 0.47, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 10h:10m:12s remains)
INFO - root - 2017-12-17 01:01:58.338843: step 166470, loss = 0.57, batch loss = 0.39 (36.2 examples/sec; 0.221 sec/batch; 10h:12m:17s remains)
INFO - root - 2017-12-17 01:02:00.571790: step 166480, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 10h:06m:25s remains)
INFO - root - 2017-12-17 01:02:02.770762: step 166490, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 10h:05m:49s remains)
INFO - root - 2017-12-17 01:02:04.977174: step 166500, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 10h:19m:13s remains)
INFO - root - 2017-12-17 01:02:07.364602: step 166510, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 10h:34m:50s remains)
INFO - root - 2017-12-17 01:02:09.614868: step 166520, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 10h:19m:19s remains)
INFO - root - 2017-12-17 01:02:11.850864: step 166530, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 9h:59m:37s remains)
INFO - root - 2017-12-17 01:02:14.066663: step 166540, loss = 0.53, batch loss = 0.35 (37.1 examples/sec; 0.216 sec/batch; 9h:56m:52s remains)
INFO - root - 2017-12-17 01:02:16.285391: step 166550, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 10h:13m:52s remains)
INFO - root - 2017-12-17 01:02:18.522226: step 166560, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 9h:52m:57s remains)
INFO - root - 2017-12-17 01:02:20.738087: step 166570, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 9h:59m:16s remains)
INFO - root - 2017-12-17 01:02:22.971025: step 166580, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 10h:23m:45s remains)
INFO - root - 2017-12-17 01:02:25.189789: step 166590, loss = 0.54, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 10h:07m:48s remains)
INFO - root - 2017-12-17 01:02:27.414378: step 166600, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 10h:41m:20s remains)
INFO - root - 2017-12-17 01:02:29.801079: step 166610, loss = 0.42, batch loss = 0.24 (34.9 examples/sec; 0.229 sec/batch; 10h:33m:37s remains)
INFO - root - 2017-12-17 01:02:32.013610: step 166620, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 10h:06m:31s remains)
INFO - root - 2017-12-17 01:02:34.215299: step 166630, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 10h:26m:31s remains)
INFO - root - 2017-12-17 01:02:36.404510: step 166640, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 10h:05m:09s remains)
INFO - root - 2017-12-17 01:02:38.616681: step 166650, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 10h:36m:15s remains)
INFO - root - 2017-12-17 01:02:40.802746: step 166660, loss = 0.55, batch loss = 0.37 (37.7 examples/sec; 0.212 sec/batch; 9h:47m:15s remains)
INFO - root - 2017-12-17 01:02:43.011874: step 166670, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 9h:45m:12s remains)
INFO - root - 2017-12-17 01:02:45.191519: step 166680, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 9h:59m:01s remains)
INFO - root - 2017-12-17 01:02:47.419708: step 166690, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 10h:20m:40s remains)
INFO - root - 2017-12-17 01:02:49.623348: step 166700, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 10h:11m:25s remains)
INFO - root - 2017-12-17 01:02:52.001362: step 166710, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 9h:47m:13s remains)
INFO - root - 2017-12-17 01:02:54.174705: step 166720, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 10h:09m:06s remains)
INFO - root - 2017-12-17 01:02:56.408825: step 166730, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 10h:19m:19s remains)
INFO - root - 2017-12-17 01:02:58.653683: step 166740, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.215 sec/batch; 9h:55m:01s remains)
INFO - root - 2017-12-17 01:03:00.847200: step 166750, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 9h:54m:39s remains)
INFO - root - 2017-12-17 01:03:03.046899: step 166760, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 10h:01m:23s remains)
INFO - root - 2017-12-17 01:03:05.269143: step 166770, loss = 0.52, batch loss = 0.34 (35.0 examples/sec; 0.229 sec/batch; 10h:32m:06s remains)
INFO - root - 2017-12-17 01:03:07.468927: step 166780, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 10h:19m:07s remains)
INFO - root - 2017-12-17 01:03:09.743294: step 166790, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 10h:27m:09s remains)
INFO - root - 2017-12-17 01:03:11.999619: step 166800, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 10h:20m:09s remains)
INFO - root - 2017-12-17 01:03:14.334802: step 166810, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 10h:08m:05s remains)
INFO - root - 2017-12-17 01:03:16.544481: step 166820, loss = 0.56, batch loss = 0.38 (36.2 examples/sec; 0.221 sec/batch; 10h:09m:26s remains)
INFO - root - 2017-12-17 01:03:18.751534: step 166830, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 10h:04m:02s remains)
INFO - root - 2017-12-17 01:03:20.992935: step 166840, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 10h:02m:17s remains)
INFO - root - 2017-12-17 01:03:23.250637: step 166850, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 10h:22m:36s remains)
INFO - root - 2017-12-17 01:03:25.474192: step 166860, loss = 0.51, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 10h:07m:46s remains)
INFO - root - 2017-12-17 01:03:27.686111: step 166870, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 10h:02m:00s remains)
INFO - root - 2017-12-17 01:03:29.904321: step 166880, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 10h:06m:28s remains)
INFO - root - 2017-12-17 01:03:32.145000: step 166890, loss = 0.43, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 10h:25m:55s remains)
INFO - root - 2017-12-17 01:03:34.326939: step 166900, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 9h:59m:00s remains)
INFO - root - 2017-12-17 01:03:36.650565: step 166910, loss = 0.46, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 9h:54m:59s remains)
INFO - root - 2017-12-17 01:03:38.848703: step 166920, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 9h:58m:32s remains)
INFO - root - 2017-12-17 01:03:41.049258: step 166930, loss = 0.46, batch loss = 0.28 (37.9 examples/sec; 0.211 sec/batch; 9h:42m:20s remains)
INFO - root - 2017-12-17 01:03:43.220176: step 166940, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 10h:16m:04s remains)
INFO - root - 2017-12-17 01:03:45.415812: step 166950, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 10h:30m:38s remains)
INFO - root - 2017-12-17 01:03:47.603977: step 166960, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 9h:51m:18s remains)
INFO - root - 2017-12-17 01:03:49.824863: step 166970, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 10h:23m:18s remains)
INFO - root - 2017-12-17 01:03:52.034644: step 166980, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 9h:53m:37s remains)
INFO - root - 2017-12-17 01:03:54.257049: step 166990, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 9h:57m:11s remains)
INFO - root - 2017-12-17 01:03:56.488062: step 167000, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 10h:03m:25s remains)
INFO - root - 2017-12-17 01:03:58.827964: step 167010, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 10h:18m:28s remains)
INFO - root - 2017-12-17 01:04:01.017993: step 167020, loss = 0.42, batch loss = 0.24 (35.6 examples/sec; 0.225 sec/batch; 10h:19m:48s remains)
INFO - root - 2017-12-17 01:04:03.208286: step 167030, loss = 0.52, batch loss = 0.34 (34.8 examples/sec; 0.230 sec/batch; 10h:33m:13s remains)
INFO - root - 2017-12-17 01:04:05.390003: step 167040, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 10h:04m:40s remains)
INFO - root - 2017-12-17 01:04:07.623464: step 167050, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 10h:27m:42s remains)
INFO - root - 2017-12-17 01:04:09.806234: step 167060, loss = 0.54, batch loss = 0.36 (37.0 examples/sec; 0.216 sec/batch; 9h:56m:49s remains)
INFO - root - 2017-12-17 01:04:12.013688: step 167070, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 10h:08m:59s remains)
INFO - root - 2017-12-17 01:04:14.209499: step 167080, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 10h:04m:31s remains)
INFO - root - 2017-12-17 01:04:16.417004: step 167090, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 10h:05m:08s remains)
INFO - root - 2017-12-17 01:04:18.597837: step 167100, loss = 0.46, batch loss = 0.28 (37.9 examples/sec; 0.211 sec/batch; 9h:42m:10s remains)
INFO - root - 2017-12-17 01:04:20.918918: step 167110, loss = 0.46, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 10h:02m:02s remains)
INFO - root - 2017-12-17 01:04:23.145161: step 167120, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 10h:18m:53s remains)
INFO - root - 2017-12-17 01:04:25.324584: step 167130, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 10h:18m:20s remains)
INFO - root - 2017-12-17 01:04:27.516442: step 167140, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 9h:59m:01s remains)
INFO - root - 2017-12-17 01:04:29.724401: step 167150, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 10h:05m:55s remains)
INFO - root - 2017-12-17 01:04:31.963084: step 167160, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 9h:53m:08s remains)
INFO - root - 2017-12-17 01:04:34.169906: step 167170, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 10h:06m:42s remains)
INFO - root - 2017-12-17 01:04:36.367524: step 167180, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 10h:17m:56s remains)
INFO - root - 2017-12-17 01:04:38.585587: step 167190, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 10h:04m:05s remains)
INFO - root - 2017-12-17 01:04:40.783048: step 167200, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 10h:05m:20s remains)
INFO - root - 2017-12-17 01:04:43.111898: step 167210, loss = 0.50, batch loss = 0.32 (33.9 examples/sec; 0.236 sec/batch; 10h:49m:49s remains)
INFO - root - 2017-12-17 01:04:45.318814: step 167220, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 10h:09m:52s remains)
INFO - root - 2017-12-17 01:04:47.513668: step 167230, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 9h:58m:49s remains)
INFO - root - 2017-12-17 01:04:49.693784: step 167240, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 10h:20m:05s remains)
INFO - root - 2017-12-17 01:04:51.916687: step 167250, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 9h:54m:03s remains)
INFO - root - 2017-12-17 01:04:54.171469: step 167260, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 10h:07m:54s remains)
INFO - root - 2017-12-17 01:04:56.396454: step 167270, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 10h:06m:26s remains)
INFO - root - 2017-12-17 01:04:58.601267: step 167280, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 10h:24m:05s remains)
INFO - root - 2017-12-17 01:05:00.791513: step 167290, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 10h:00m:45s remains)
INFO - root - 2017-12-17 01:05:03.008603: step 167300, loss = 0.43, batch loss = 0.25 (37.0 examples/sec; 0.216 sec/batch; 9h:55m:52s remains)
INFO - root - 2017-12-17 01:05:05.343864: step 167310, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 10h:00m:04s remains)
INFO - root - 2017-12-17 01:05:07.558454: step 167320, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 9h:58m:03s remains)
INFO - root - 2017-12-17 01:05:09.764805: step 167330, loss = 0.48, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 10h:00m:37s remains)
INFO - root - 2017-12-17 01:05:11.950696: step 167340, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 9h:59m:41s remains)
INFO - root - 2017-12-17 01:05:14.151271: step 167350, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 9h:59m:10s remains)
INFO - root - 2017-12-17 01:05:16.330901: step 167360, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 10h:01m:00s remains)
INFO - root - 2017-12-17 01:05:18.538371: step 167370, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 9h:58m:29s remains)
INFO - root - 2017-12-17 01:05:20.748575: step 167380, loss = 0.52, batch loss = 0.34 (37.5 examples/sec; 0.214 sec/batch; 9h:47m:51s remains)
INFO - root - 2017-12-17 01:05:22.962552: step 167390, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 9h:57m:03s remains)
INFO - root - 2017-12-17 01:05:25.174624: step 167400, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 10h:02m:09s remains)
INFO - root - 2017-12-17 01:05:27.500647: step 167410, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 10h:19m:26s remains)
INFO - root - 2017-12-17 01:05:29.683101: step 167420, loss = 0.42, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 10h:02m:35s remains)
INFO - root - 2017-12-17 01:05:31.908091: step 167430, loss = 0.49, batch loss = 0.31 (34.1 examples/sec; 0.234 sec/batch; 10h:44m:38s remains)
INFO - root - 2017-12-17 01:05:34.092166: step 167440, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 9h:56m:00s remains)
INFO - root - 2017-12-17 01:05:36.329880: step 167450, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 9h:49m:08s remains)
INFO - root - 2017-12-17 01:05:38.533262: step 167460, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 10h:35m:06s remains)
INFO - root - 2017-12-17 01:05:40.733597: step 167470, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 10h:20m:16s remains)
INFO - root - 2017-12-17 01:05:42.919262: step 167480, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 9h:50m:27s remains)
INFO - root - 2017-12-17 01:05:45.087882: step 167490, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 9h:46m:05s remains)
INFO - root - 2017-12-17 01:05:47.303390: step 167500, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 10h:22m:54s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-167500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-167500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 01:05:50.264995: step 167510, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 9h:56m:56s remains)
INFO - root - 2017-12-17 01:05:52.454164: step 167520, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 10h:16m:57s remains)
INFO - root - 2017-12-17 01:05:54.669739: step 167530, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 10h:31m:26s remains)
INFO - root - 2017-12-17 01:05:56.910989: step 167540, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.233 sec/batch; 10h:39m:16s remains)
INFO - root - 2017-12-17 01:05:59.130297: step 167550, loss = 0.49, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 9h:54m:49s remains)
INFO - root - 2017-12-17 01:06:01.306099: step 167560, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 10h:03m:11s remains)
INFO - root - 2017-12-17 01:06:03.526380: step 167570, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 9h:59m:08s remains)
INFO - root - 2017-12-17 01:06:05.732078: step 167580, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 9h:48m:25s remains)
INFO - root - 2017-12-17 01:06:07.913202: step 167590, loss = 0.43, batch loss = 0.25 (35.2 examples/sec; 0.227 sec/batch; 10h:25m:07s remains)
INFO - root - 2017-12-17 01:06:10.116326: step 167600, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 9h:55m:00s remains)
INFO - root - 2017-12-17 01:06:12.506307: step 167610, loss = 0.50, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 9h:51m:43s remains)
INFO - root - 2017-12-17 01:06:14.734352: step 167620, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 9h:59m:52s remains)
INFO - root - 2017-12-17 01:06:16.942775: step 167630, loss = 0.47, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 10h:11m:36s remains)
INFO - root - 2017-12-17 01:06:19.120619: step 167640, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 9h:58m:10s remains)
INFO - root - 2017-12-17 01:06:21.353276: step 167650, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 10h:08m:14s remains)
INFO - root - 2017-12-17 01:06:23.577759: step 167660, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 9h:57m:29s remains)
INFO - root - 2017-12-17 01:06:25.760197: step 167670, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 10h:07m:35s remains)
INFO - root - 2017-12-17 01:06:27.952897: step 167680, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 9h:53m:07s remains)
INFO - root - 2017-12-17 01:06:30.160550: step 167690, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 9h:55m:50s remains)
INFO - root - 2017-12-17 01:06:32.366317: step 167700, loss = 0.47, batch loss = 0.30 (37.7 examples/sec; 0.212 sec/batch; 9h:42m:31s remains)
INFO - root - 2017-12-17 01:06:34.684036: step 167710, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 9h:52m:35s remains)
INFO - root - 2017-12-17 01:06:36.882966: step 167720, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 10h:06m:36s remains)
INFO - root - 2017-12-17 01:06:39.093487: step 167730, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 9h:57m:09s remains)
INFO - root - 2017-12-17 01:06:41.300827: step 167740, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 10h:02m:41s remains)
INFO - root - 2017-12-17 01:06:43.542037: step 167750, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 10h:02m:04s remains)
INFO - root - 2017-12-17 01:06:45.774426: step 167760, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 10h:03m:54s remains)
INFO - root - 2017-12-17 01:06:47.977065: step 167770, loss = 0.54, batch loss = 0.36 (37.5 examples/sec; 0.213 sec/batch; 9h:46m:05s remains)
INFO - root - 2017-12-17 01:06:50.162375: step 167780, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 9h:53m:03s remains)
INFO - root - 2017-12-17 01:06:52.348282: step 167790, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.221 sec/batch; 10h:05m:37s remains)
INFO - root - 2017-12-17 01:06:54.601730: step 167800, loss = 0.47, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 10h:19m:14s remains)
INFO - root - 2017-12-17 01:06:56.927623: step 167810, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 9h:47m:57s remains)
INFO - root - 2017-12-17 01:06:59.147397: step 167820, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 9h:54m:05s remains)
INFO - root - 2017-12-17 01:07:01.346858: step 167830, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 10h:09m:06s remains)
INFO - root - 2017-12-17 01:07:03.576094: step 167840, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 9h:59m:26s remains)
INFO - root - 2017-12-17 01:07:05.785523: step 167850, loss = 0.63, batch loss = 0.45 (35.6 examples/sec; 0.225 sec/batch; 10h:17m:09s remains)
INFO - root - 2017-12-17 01:07:07.993880: step 167860, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 9h:53m:21s remains)
INFO - root - 2017-12-17 01:07:10.197388: step 167870, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.226 sec/batch; 10h:18m:58s remains)
INFO - root - 2017-12-17 01:07:12.431573: step 167880, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.224 sec/batch; 10h:15m:51s remains)
INFO - root - 2017-12-17 01:07:14.624424: step 167890, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 10h:17m:17s remains)
INFO - root - 2017-12-17 01:07:16.862328: step 167900, loss = 0.57, batch loss = 0.39 (34.9 examples/sec; 0.229 sec/batch; 10h:28m:41s remains)
INFO - root - 2017-12-17 01:07:19.225958: step 167910, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 10h:16m:09s remains)
INFO - root - 2017-12-17 01:07:21.457994: step 167920, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 10h:15m:52s remains)
INFO - root - 2017-12-17 01:07:23.637470: step 167930, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 10h:12m:34s remains)
INFO - root - 2017-12-17 01:07:25.843004: step 167940, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 10h:16m:15s remains)
INFO - root - 2017-12-17 01:07:28.045841: step 167950, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 10h:08m:44s remains)
INFO - root - 2017-12-17 01:07:30.266950: step 167960, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 9h:50m:26s remains)
INFO - root - 2017-12-17 01:07:32.455188: step 167970, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 9h:55m:12s remains)
INFO - root - 2017-12-17 01:07:34.685408: step 167980, loss = 0.41, batch loss = 0.24 (36.4 examples/sec; 0.220 sec/batch; 10h:03m:26s remains)
INFO - root - 2017-12-17 01:07:36.906258: step 167990, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 10h:04m:31s remains)
INFO - root - 2017-12-17 01:07:39.155731: step 168000, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 10h:03m:04s remains)
INFO - root - 2017-12-17 01:07:41.514250: step 168010, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 10h:06m:17s remains)
INFO - root - 2017-12-17 01:07:43.719400: step 168020, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 10h:05m:38s remains)
INFO - root - 2017-12-17 01:07:45.965288: step 168030, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 10h:06m:17s remains)
INFO - root - 2017-12-17 01:07:48.189336: step 168040, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 10h:27m:45s remains)
INFO - root - 2017-12-17 01:07:50.391352: step 168050, loss = 0.50, batch loss = 0.32 (34.7 examples/sec; 0.231 sec/batch; 10h:32m:26s remains)
INFO - root - 2017-12-17 01:07:52.622565: step 168060, loss = 0.43, batch loss = 0.25 (34.4 examples/sec; 0.233 sec/batch; 10h:37m:45s remains)
INFO - root - 2017-12-17 01:07:54.838085: step 168070, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 10h:01m:32s remains)
INFO - root - 2017-12-17 01:07:57.044261: step 168080, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 10h:08m:11s remains)
INFO - root - 2017-12-17 01:07:59.266317: step 168090, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 9h:50m:14s remains)
INFO - root - 2017-12-17 01:08:01.445192: step 168100, loss = 0.48, batch loss = 0.30 (38.0 examples/sec; 0.211 sec/batch; 9h:37m:07s remains)
INFO - root - 2017-12-17 01:08:03.755733: step 168110, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 10h:07m:26s remains)
INFO - root - 2017-12-17 01:08:05.985229: step 168120, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 9h:57m:37s remains)
INFO - root - 2017-12-17 01:08:08.201347: step 168130, loss = 0.44, batch loss = 0.26 (33.3 examples/sec; 0.241 sec/batch; 10h:58m:54s remains)
INFO - root - 2017-12-17 01:08:10.382626: step 168140, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 9h:43m:11s remains)
INFO - root - 2017-12-17 01:08:12.567665: step 168150, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 9h:50m:31s remains)
INFO - root - 2017-12-17 01:08:14.782762: step 168160, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 10h:08m:58s remains)
INFO - root - 2017-12-17 01:08:16.952585: step 168170, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 10h:07m:12s remains)
INFO - root - 2017-12-17 01:08:19.136949: step 168180, loss = 0.44, batch loss = 0.26 (37.8 examples/sec; 0.212 sec/batch; 9h:40m:08s remains)
INFO - root - 2017-12-17 01:08:21.323159: step 168190, loss = 0.41, batch loss = 0.23 (38.0 examples/sec; 0.210 sec/batch; 9h:35m:56s remains)
INFO - root - 2017-12-17 01:08:23.512581: step 168200, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 9h:47m:43s remains)
INFO - root - 2017-12-17 01:08:25.856164: step 168210, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 10h:00m:15s remains)
INFO - root - 2017-12-17 01:08:28.059638: step 168220, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 10h:04m:26s remains)
INFO - root - 2017-12-17 01:08:30.260126: step 168230, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 10h:03m:23s remains)
INFO - root - 2017-12-17 01:08:32.446030: step 168240, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 9h:47m:28s remains)
INFO - root - 2017-12-17 01:08:34.674155: step 168250, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 9h:50m:10s remains)
INFO - root - 2017-12-17 01:08:36.872938: step 168260, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 9h:50m:38s remains)
INFO - root - 2017-12-17 01:08:39.093149: step 168270, loss = 0.52, batch loss = 0.34 (34.6 examples/sec; 0.231 sec/batch; 10h:33m:01s remains)
INFO - root - 2017-12-17 01:08:41.305206: step 168280, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 10h:17m:06s remains)
INFO - root - 2017-12-17 01:08:43.508156: step 168290, loss = 0.57, batch loss = 0.39 (36.7 examples/sec; 0.218 sec/batch; 9h:56m:53s remains)
INFO - root - 2017-12-17 01:08:45.715521: step 168300, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 9h:55m:10s remains)
INFO - root - 2017-12-17 01:08:48.020171: step 168310, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 9h:49m:37s remains)
INFO - root - 2017-12-17 01:08:50.236235: step 168320, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 9h:54m:02s remains)
INFO - root - 2017-12-17 01:08:52.434566: step 168330, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 10h:02m:48s remains)
INFO - root - 2017-12-17 01:08:54.629649: step 168340, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 10h:14m:32s remains)
INFO - root - 2017-12-17 01:08:56.803803: step 168350, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 9h:52m:21s remains)
INFO - root - 2017-12-17 01:08:59.049738: step 168360, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 10h:07m:59s remains)
INFO - root - 2017-12-17 01:09:01.239937: step 168370, loss = 0.53, batch loss = 0.35 (35.8 examples/sec; 0.223 sec/batch; 10h:11m:19s remains)
INFO - root - 2017-12-17 01:09:03.418567: step 168380, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 9h:54m:18s remains)
INFO - root - 2017-12-17 01:09:05.632725: step 168390, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 10h:15m:28s remains)
INFO - root - 2017-12-17 01:09:07.878490: step 168400, loss = 0.52, batch loss = 0.34 (34.0 examples/sec; 0.235 sec/batch; 10h:43m:21s remains)
INFO - root - 2017-12-17 01:09:10.233645: step 168410, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 9h:51m:40s remains)
INFO - root - 2017-12-17 01:09:12.437417: step 168420, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 9h:57m:32s remains)
INFO - root - 2017-12-17 01:09:14.641760: step 168430, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 10h:33m:18s remains)
INFO - root - 2017-12-17 01:09:16.852502: step 168440, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 9h:48m:10s remains)
INFO - root - 2017-12-17 01:09:19.051695: step 168450, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 10h:21m:25s remains)
INFO - root - 2017-12-17 01:09:21.291153: step 168460, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 10h:15m:06s remains)
INFO - root - 2017-12-17 01:09:23.525577: step 168470, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 10h:09m:10s remains)
INFO - root - 2017-12-17 01:09:25.732859: step 168480, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 9h:56m:27s remains)
INFO - root - 2017-12-17 01:09:27.934038: step 168490, loss = 0.46, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 10h:13m:19s remains)
INFO - root - 2017-12-17 01:09:30.145411: step 168500, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 9h:48m:46s remains)
INFO - root - 2017-12-17 01:09:32.483768: step 168510, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 10h:12m:46s remains)
INFO - root - 2017-12-17 01:09:34.692251: step 168520, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 9h:41m:43s remains)
INFO - root - 2017-12-17 01:09:36.880300: step 168530, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 9h:56m:24s remains)
INFO - root - 2017-12-17 01:09:39.115999: step 168540, loss = 0.49, batch loss = 0.31 (38.0 examples/sec; 0.210 sec/batch; 9h:34m:35s remains)
INFO - root - 2017-12-17 01:09:41.308038: step 168550, loss = 0.50, batch loss = 0.32 (37.8 examples/sec; 0.212 sec/batch; 9h:38m:13s remains)
INFO - root - 2017-12-17 01:09:43.533802: step 168560, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 9h:56m:47s remains)
INFO - root - 2017-12-17 01:09:45.778468: step 168570, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 10h:21m:53s remains)
INFO - root - 2017-12-17 01:09:48.005688: step 168580, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 10h:00m:54s remains)
INFO - root - 2017-12-17 01:09:50.224485: step 168590, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 10h:03m:18s remains)
INFO - root - 2017-12-17 01:09:52.402841: step 168600, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 10h:05m:06s remains)
INFO - root - 2017-12-17 01:09:54.778770: step 168610, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 10h:04m:25s remains)
INFO - root - 2017-12-17 01:09:57.036389: step 168620, loss = 0.47, batch loss = 0.29 (33.7 examples/sec; 0.238 sec/batch; 10h:48m:44s remains)
INFO - root - 2017-12-17 01:09:59.263402: step 168630, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 10h:02m:50s remains)
INFO - root - 2017-12-17 01:10:01.515590: step 168640, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 10h:00m:41s remains)
INFO - root - 2017-12-17 01:10:03.774118: step 168650, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 10h:12m:28s remains)
INFO - root - 2017-12-17 01:10:05.992867: step 168660, loss = 0.47, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 9h:48m:54s remains)
INFO - root - 2017-12-17 01:10:08.187283: step 168670, loss = 0.60, batch loss = 0.43 (36.3 examples/sec; 0.220 sec/batch; 10h:01m:14s remains)
INFO - root - 2017-12-17 01:10:10.420150: step 168680, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 10h:29m:36s remains)
INFO - root - 2017-12-17 01:10:12.650175: step 168690, loss = 0.54, batch loss = 0.36 (35.0 examples/sec; 0.228 sec/batch; 10h:23m:19s remains)
INFO - root - 2017-12-17 01:10:14.863501: step 168700, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 9h:59m:42s remains)
INFO - root - 2017-12-17 01:10:17.187796: step 168710, loss = 0.42, batch loss = 0.24 (37.3 examples/sec; 0.214 sec/batch; 9h:44m:56s remains)
INFO - root - 2017-12-17 01:10:19.402966: step 168720, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 10h:05m:23s remains)
INFO - root - 2017-12-17 01:10:21.611408: step 168730, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 9h:57m:57s remains)
INFO - root - 2017-12-17 01:10:23.817269: step 168740, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 10h:07m:51s remains)
INFO - root - 2017-12-17 01:10:26.023122: step 168750, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.232 sec/batch; 10h:34m:28s remains)
INFO - root - 2017-12-17 01:10:28.241152: step 168760, loss = 0.57, batch loss = 0.39 (36.9 examples/sec; 0.217 sec/batch; 9h:51m:55s remains)
INFO - root - 2017-12-17 01:10:30.472247: step 168770, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 9h:58m:02s remains)
INFO - root - 2017-12-17 01:10:32.708761: step 168780, loss = 0.43, batch loss = 0.25 (33.9 examples/sec; 0.236 sec/batch; 10h:43m:29s remains)
INFO - root - 2017-12-17 01:10:34.923831: step 168790, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 10h:06m:55s remains)
INFO - root - 2017-12-17 01:10:37.157061: step 168800, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 10h:14m:55s remains)
INFO - root - 2017-12-17 01:10:39.489638: step 168810, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 10h:02m:05s remains)
INFO - root - 2017-12-17 01:10:41.697713: step 168820, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 10h:32m:18s remains)
INFO - root - 2017-12-17 01:10:43.905762: step 168830, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 9h:49m:50s remains)
INFO - root - 2017-12-17 01:10:46.096973: step 168840, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 9h:53m:29s remains)
INFO - root - 2017-12-17 01:10:48.320246: step 168850, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 9h:57m:08s remains)
INFO - root - 2017-12-17 01:10:50.516140: step 168860, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 9h:43m:23s remains)
INFO - root - 2017-12-17 01:10:52.769061: step 168870, loss = 0.45, batch loss = 0.27 (32.3 examples/sec; 0.248 sec/batch; 11h:15m:27s remains)
INFO - root - 2017-12-17 01:10:54.965254: step 168880, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 9h:44m:25s remains)
INFO - root - 2017-12-17 01:10:57.169994: step 168890, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 9h:57m:57s remains)
INFO - root - 2017-12-17 01:10:59.387974: step 168900, loss = 0.47, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 9h:55m:39s remains)
INFO - root - 2017-12-17 01:11:01.748992: step 168910, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 9h:50m:38s remains)
INFO - root - 2017-12-17 01:11:03.996799: step 168920, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 9h:56m:58s remains)
INFO - root - 2017-12-17 01:11:06.216323: step 168930, loss = 0.48, batch loss = 0.30 (34.0 examples/sec; 0.235 sec/batch; 10h:40m:37s remains)
INFO - root - 2017-12-17 01:11:08.490520: step 168940, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 10h:24m:55s remains)
INFO - root - 2017-12-17 01:11:10.683668: step 168950, loss = 0.50, batch loss = 0.32 (35.0 examples/sec; 0.229 sec/batch; 10h:23m:49s remains)
INFO - root - 2017-12-17 01:11:12.919644: step 168960, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 10h:09m:58s remains)
INFO - root - 2017-12-17 01:11:15.137685: step 168970, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.219 sec/batch; 9h:56m:02s remains)
INFO - root - 2017-12-17 01:11:17.319294: step 168980, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.226 sec/batch; 10h:14m:35s remains)
INFO - root - 2017-12-17 01:11:19.501017: step 168990, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 9h:45m:22s remains)
INFO - root - 2017-12-17 01:11:21.680810: step 169000, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.219 sec/batch; 9h:55m:52s remains)
INFO - root - 2017-12-17 01:11:24.029359: step 169010, loss = 0.47, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 10h:12m:36s remains)
INFO - root - 2017-12-17 01:11:26.219066: step 169020, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 9h:50m:35s remains)
INFO - root - 2017-12-17 01:11:28.408516: step 169030, loss = 0.41, batch loss = 0.23 (35.6 examples/sec; 0.225 sec/batch; 10h:12m:57s remains)
INFO - root - 2017-12-17 01:11:30.633678: step 169040, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 10h:03m:29s remains)
INFO - root - 2017-12-17 01:11:32.855743: step 169050, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 9h:56m:42s remains)
INFO - root - 2017-12-17 01:11:35.063132: step 169060, loss = 0.43, batch loss = 0.26 (35.0 examples/sec; 0.229 sec/batch; 10h:23m:16s remains)
INFO - root - 2017-12-17 01:11:37.283225: step 169070, loss = 0.45, batch loss = 0.27 (38.0 examples/sec; 0.210 sec/batch; 9h:33m:21s remains)
INFO - root - 2017-12-17 01:11:39.510968: step 169080, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 9h:56m:59s remains)
INFO - root - 2017-12-17 01:11:41.723496: step 169090, loss = 0.44, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 9h:53m:49s remains)
INFO - root - 2017-12-17 01:11:43.950434: step 169100, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 10h:15m:03s remains)
INFO - root - 2017-12-17 01:11:46.266909: step 169110, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 10h:18m:05s remains)
INFO - root - 2017-12-17 01:11:48.475040: step 169120, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 10h:03m:56s remains)
INFO - root - 2017-12-17 01:11:50.683877: step 169130, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 9h:59m:27s remains)
INFO - root - 2017-12-17 01:11:52.901488: step 169140, loss = 0.49, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 9h:55m:27s remains)
INFO - root - 2017-12-17 01:11:55.107976: step 169150, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.226 sec/batch; 10h:16m:24s remains)
INFO - root - 2017-12-17 01:11:57.275232: step 169160, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 9h:50m:32s remains)
INFO - root - 2017-12-17 01:11:59.468921: step 169170, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 9h:59m:01s remains)
INFO - root - 2017-12-17 01:12:01.720673: step 169180, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 10h:00m:02s remains)
INFO - root - 2017-12-17 01:12:03.969999: step 169190, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 10h:07m:34s remains)
INFO - root - 2017-12-17 01:12:06.197733: step 169200, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 9h:47m:36s remains)
INFO - root - 2017-12-17 01:12:08.526024: step 169210, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 9h:50m:09s remains)
INFO - root - 2017-12-17 01:12:10.730640: step 169220, loss = 0.43, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 10h:12m:18s remains)
INFO - root - 2017-12-17 01:12:12.924214: step 169230, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 9h:50m:47s remains)
INFO - root - 2017-12-17 01:12:15.112768: step 169240, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 9h:38m:44s remains)
INFO - root - 2017-12-17 01:12:17.334939: step 169250, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 9h:39m:49s remains)
INFO - root - 2017-12-17 01:12:19.582666: step 169260, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 10h:02m:37s remains)
INFO - root - 2017-12-17 01:12:21.781021: step 169270, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.226 sec/batch; 10h:13m:50s remains)
INFO - root - 2017-12-17 01:12:23.982893: step 169280, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 9h:40m:43s remains)
INFO - root - 2017-12-17 01:12:26.165848: step 169290, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 9h:49m:38s remains)
INFO - root - 2017-12-17 01:12:28.353237: step 169300, loss = 0.52, batch loss = 0.34 (37.5 examples/sec; 0.213 sec/batch; 9h:40m:17s remains)
INFO - root - 2017-12-17 01:12:30.680663: step 169310, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 10h:03m:00s remains)
INFO - root - 2017-12-17 01:12:32.899948: step 169320, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 10h:05m:25s remains)
INFO - root - 2017-12-17 01:12:35.134097: step 169330, loss = 0.50, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 10h:16m:33s remains)
INFO - root - 2017-12-17 01:12:37.366589: step 169340, loss = 0.58, batch loss = 0.40 (36.6 examples/sec; 0.219 sec/batch; 9h:55m:02s remains)
INFO - root - 2017-12-17 01:12:39.597515: step 169350, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 9h:44m:09s remains)
INFO - root - 2017-12-17 01:12:41.851555: step 169360, loss = 0.41, batch loss = 0.23 (35.9 examples/sec; 0.223 sec/batch; 10h:05m:15s remains)
INFO - root - 2017-12-17 01:12:44.067463: step 169370, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 9h:57m:26s remains)
INFO - root - 2017-12-17 01:12:46.250543: step 169380, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 9h:44m:18s remains)
INFO - root - 2017-12-17 01:12:48.438135: step 169390, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 9h:58m:55s remains)
INFO - root - 2017-12-17 01:12:50.665418: step 169400, loss = 0.42, batch loss = 0.24 (34.6 examples/sec; 0.231 sec/batch; 10h:28m:42s remains)
INFO - root - 2017-12-17 01:12:53.055313: step 169410, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.224 sec/batch; 10h:07m:54s remains)
INFO - root - 2017-12-17 01:12:55.299957: step 169420, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.214 sec/batch; 9h:42m:56s remains)
INFO - root - 2017-12-17 01:12:57.529449: step 169430, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.215 sec/batch; 9h:45m:21s remains)
INFO - root - 2017-12-17 01:12:59.736208: step 169440, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 10h:00m:44s remains)
INFO - root - 2017-12-17 01:13:01.944160: step 169450, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 10h:02m:14s remains)
INFO - root - 2017-12-17 01:13:04.160025: step 169460, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 10h:12m:53s remains)
INFO - root - 2017-12-17 01:13:06.362432: step 169470, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 10h:04m:46s remains)
INFO - root - 2017-12-17 01:13:08.632209: step 169480, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 10h:17m:15s remains)
INFO - root - 2017-12-17 01:13:10.809564: step 169490, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 10h:10m:37s remains)
INFO - root - 2017-12-17 01:13:13.007310: step 169500, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 9h:57m:59s remains)
INFO - root - 2017-12-17 01:13:15.370076: step 169510, loss = 0.49, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 9h:52m:58s remains)
INFO - root - 2017-12-17 01:13:17.547337: step 169520, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 9h:53m:13s remains)
INFO - root - 2017-12-17 01:13:19.746479: step 169530, loss = 0.43, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 9h:56m:14s remains)
INFO - root - 2017-12-17 01:13:21.980515: step 169540, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 10h:13m:57s remains)
INFO - root - 2017-12-17 01:13:24.207284: step 169550, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 9h:39m:12s remains)
INFO - root - 2017-12-17 01:13:26.407752: step 169560, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 9h:59m:35s remains)
INFO - root - 2017-12-17 01:13:28.617122: step 169570, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 9h:57m:52s remains)
INFO - root - 2017-12-17 01:13:30.814762: step 169580, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 9h:59m:15s remains)
INFO - root - 2017-12-17 01:13:33.023168: step 169590, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 10h:00m:48s remains)
INFO - root - 2017-12-17 01:13:35.245325: step 169600, loss = 0.45, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 9h:59m:55s remains)
INFO - root - 2017-12-17 01:13:37.572142: step 169610, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 10h:00m:04s remains)
INFO - root - 2017-12-17 01:13:39.791277: step 169620, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 9h:43m:32s remains)
INFO - root - 2017-12-17 01:13:42.006589: step 169630, loss = 0.57, batch loss = 0.39 (36.2 examples/sec; 0.221 sec/batch; 9h:59m:25s remains)
INFO - root - 2017-12-17 01:13:44.238053: step 169640, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 9h:47m:20s remains)
INFO - root - 2017-12-17 01:13:46.445200: step 169650, loss = 0.54, batch loss = 0.36 (35.3 examples/sec; 0.227 sec/batch; 10h:15m:48s remains)
INFO - root - 2017-12-17 01:13:48.625798: step 169660, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 9h:49m:03s remains)
INFO - root - 2017-12-17 01:13:50.816576: step 169670, loss = 0.47, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 10h:10m:35s remains)
INFO - root - 2017-12-17 01:13:52.997634: step 169680, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 9h:54m:07s remains)
INFO - root - 2017-12-17 01:13:55.203604: step 169690, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 9h:44m:34s remains)
INFO - root - 2017-12-17 01:13:57.431869: step 169700, loss = 0.49, batch loss = 0.31 (34.4 examples/sec; 0.232 sec/batch; 10h:30m:18s remains)
INFO - root - 2017-12-17 01:13:59.781910: step 169710, loss = 0.47, batch loss = 0.29 (34.1 examples/sec; 0.235 sec/batch; 10h:37m:18s remains)
INFO - root - 2017-12-17 01:14:01.981060: step 169720, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.215 sec/batch; 9h:44m:31s remains)
INFO - root - 2017-12-17 01:14:04.214564: step 169730, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 9h:58m:50s remains)
INFO - root - 2017-12-17 01:14:06.440807: step 169740, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 10h:12m:02s remains)
INFO - root - 2017-12-17 01:14:08.730601: step 169750, loss = 0.46, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 10h:22m:59s remains)
INFO - root - 2017-12-17 01:14:10.958035: step 169760, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 9h:43m:12s remains)
INFO - root - 2017-12-17 01:14:13.175880: step 169770, loss = 0.45, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 9h:49m:06s remains)
INFO - root - 2017-12-17 01:14:15.380439: step 169780, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.224 sec/batch; 10h:06m:19s remains)
INFO - root - 2017-12-17 01:14:17.572144: step 169790, loss = 0.52, batch loss = 0.34 (37.3 examples/sec; 0.214 sec/batch; 9h:41m:35s remains)
INFO - root - 2017-12-17 01:14:19.780117: step 169800, loss = 0.45, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 10h:02m:00s remains)
INFO - root - 2017-12-17 01:14:22.133972: step 169810, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 9h:52m:13s remains)
INFO - root - 2017-12-17 01:14:24.419654: step 169820, loss = 0.50, batch loss = 0.32 (34.6 examples/sec; 0.231 sec/batch; 10h:26m:39s remains)
INFO - root - 2017-12-17 01:14:26.644658: step 169830, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 10h:10m:11s remains)
INFO - root - 2017-12-17 01:14:28.893060: step 169840, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 10h:01m:57s remains)
INFO - root - 2017-12-17 01:14:31.068352: step 169850, loss = 0.44, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 9h:51m:08s remains)
INFO - root - 2017-12-17 01:14:33.254714: step 169860, loss = 0.46, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 10h:16m:28s remains)
INFO - root - 2017-12-17 01:14:35.440643: step 169870, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 9h:51m:22s remains)
INFO - root - 2017-12-17 01:14:37.656308: step 169880, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 10h:25m:20s remains)
INFO - root - 2017-12-17 01:14:39.899357: step 169890, loss = 0.55, batch loss = 0.37 (36.8 examples/sec; 0.217 sec/batch; 9h:48m:56s remains)
INFO - root - 2017-12-17 01:14:42.084741: step 169900, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 9h:56m:10s remains)
INFO - root - 2017-12-17 01:14:44.423245: step 169910, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 9h:38m:53s remains)
INFO - root - 2017-12-17 01:14:46.647659: step 169920, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 10h:13m:49s remains)
INFO - root - 2017-12-17 01:14:48.833510: step 169930, loss = 0.46, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 9h:35m:49s remains)
INFO - root - 2017-12-17 01:14:51.048446: step 169940, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 10h:01m:41s remains)
INFO - root - 2017-12-17 01:14:53.288704: step 169950, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 9h:54m:33s remains)
INFO - root - 2017-12-17 01:14:55.501572: step 169960, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 9h:45m:08s remains)
INFO - root - 2017-12-17 01:14:57.745380: step 169970, loss = 0.57, batch loss = 0.40 (33.8 examples/sec; 0.236 sec/batch; 10h:40m:26s remains)
INFO - root - 2017-12-17 01:14:59.936870: step 169980, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 9h:50m:30s remains)
INFO - root - 2017-12-17 01:15:02.155677: step 169990, loss = 0.49, batch loss = 0.31 (34.2 examples/sec; 0.234 sec/batch; 10h:32m:40s remains)
INFO - root - 2017-12-17 01:15:04.332179: step 170000, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 10h:01m:05s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-170000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-170000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 01:15:07.100831: step 170010, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 9h:50m:16s remains)
INFO - root - 2017-12-17 01:15:09.337225: step 170020, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 9h:47m:59s remains)
INFO - root - 2017-12-17 01:15:11.541151: step 170030, loss = 0.56, batch loss = 0.38 (36.3 examples/sec; 0.221 sec/batch; 9h:57m:18s remains)
INFO - root - 2017-12-17 01:15:13.799063: step 170040, loss = 0.44, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 10h:01m:36s remains)
INFO - root - 2017-12-17 01:15:16.046144: step 170050, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 9h:44m:01s remains)
INFO - root - 2017-12-17 01:15:18.269736: step 170060, loss = 0.56, batch loss = 0.38 (34.8 examples/sec; 0.230 sec/batch; 10h:21m:45s remains)
INFO - root - 2017-12-17 01:15:20.442507: step 170070, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 9h:41m:14s remains)
INFO - root - 2017-12-17 01:15:22.659625: step 170080, loss = 0.41, batch loss = 0.23 (36.1 examples/sec; 0.221 sec/batch; 9h:59m:28s remains)
INFO - root - 2017-12-17 01:15:24.896346: step 170090, loss = 0.46, batch loss = 0.28 (33.0 examples/sec; 0.242 sec/batch; 10h:55m:30s remains)
INFO - root - 2017-12-17 01:15:27.125827: step 170100, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 9h:53m:34s remains)
INFO - root - 2017-12-17 01:15:29.517079: step 170110, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 10h:03m:04s remains)
INFO - root - 2017-12-17 01:15:31.705690: step 170120, loss = 0.53, batch loss = 0.36 (35.8 examples/sec; 0.224 sec/batch; 10h:05m:05s remains)
INFO - root - 2017-12-17 01:15:33.914287: step 170130, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 10h:08m:44s remains)
INFO - root - 2017-12-17 01:15:36.125291: step 170140, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 10h:00m:10s remains)
INFO - root - 2017-12-17 01:15:38.369131: step 170150, loss = 0.47, batch loss = 0.29 (33.8 examples/sec; 0.237 sec/batch; 10h:41m:05s remains)
INFO - root - 2017-12-17 01:15:40.581860: step 170160, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 9h:47m:35s remains)
INFO - root - 2017-12-17 01:15:42.786737: step 170170, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 9h:58m:30s remains)
INFO - root - 2017-12-17 01:15:44.993433: step 170180, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 10h:14m:47s remains)
INFO - root - 2017-12-17 01:15:47.249419: step 170190, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 9h:55m:24s remains)
INFO - root - 2017-12-17 01:15:49.433308: step 170200, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 10h:01m:16s remains)
INFO - root - 2017-12-17 01:15:51.729888: step 170210, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 9h:43m:29s remains)
INFO - root - 2017-12-17 01:15:53.932379: step 170220, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 10h:04m:28s remains)
INFO - root - 2017-12-17 01:15:56.184864: step 170230, loss = 0.47, batch loss = 0.29 (34.0 examples/sec; 0.235 sec/batch; 10h:36m:24s remains)
INFO - root - 2017-12-17 01:15:58.368735: step 170240, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 9h:49m:41s remains)
INFO - root - 2017-12-17 01:16:00.585462: step 170250, loss = 0.44, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 10h:11m:03s remains)
INFO - root - 2017-12-17 01:16:02.775481: step 170260, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 9h:46m:54s remains)
INFO - root - 2017-12-17 01:16:04.968879: step 170270, loss = 0.50, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 10h:19m:46s remains)
INFO - root - 2017-12-17 01:16:07.163364: step 170280, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 10h:00m:59s remains)
INFO - root - 2017-12-17 01:16:09.367682: step 170290, loss = 0.43, batch loss = 0.25 (37.5 examples/sec; 0.214 sec/batch; 9h:37m:20s remains)
INFO - root - 2017-12-17 01:16:11.556083: step 170300, loss = 0.57, batch loss = 0.39 (37.0 examples/sec; 0.216 sec/batch; 9h:45m:16s remains)
INFO - root - 2017-12-17 01:16:13.923981: step 170310, loss = 0.59, batch loss = 0.41 (36.8 examples/sec; 0.217 sec/batch; 9h:47m:20s remains)
INFO - root - 2017-12-17 01:16:16.159368: step 170320, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 9h:50m:30s remains)
INFO - root - 2017-12-17 01:16:18.394760: step 170330, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 9h:57m:09s remains)
INFO - root - 2017-12-17 01:16:20.604469: step 170340, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 10h:16m:12s remains)
INFO - root - 2017-12-17 01:16:22.874243: step 170350, loss = 0.47, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 9h:48m:38s remains)
INFO - root - 2017-12-17 01:16:25.097334: step 170360, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 10h:11m:34s remains)
INFO - root - 2017-12-17 01:16:27.299476: step 170370, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 9h:49m:35s remains)
INFO - root - 2017-12-17 01:16:29.499108: step 170380, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 9h:40m:19s remains)
INFO - root - 2017-12-17 01:16:31.727646: step 170390, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 9h:54m:53s remains)
INFO - root - 2017-12-17 01:16:33.933126: step 170400, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 10h:13m:34s remains)
INFO - root - 2017-12-17 01:16:36.288665: step 170410, loss = 0.52, batch loss = 0.34 (34.3 examples/sec; 0.233 sec/batch; 10h:29m:16s remains)
INFO - root - 2017-12-17 01:16:38.514195: step 170420, loss = 0.55, batch loss = 0.37 (35.8 examples/sec; 0.224 sec/batch; 10h:03m:46s remains)
INFO - root - 2017-12-17 01:16:40.725427: step 170430, loss = 0.48, batch loss = 0.31 (33.9 examples/sec; 0.236 sec/batch; 10h:38m:03s remains)
INFO - root - 2017-12-17 01:16:42.924477: step 170440, loss = 0.50, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 9h:44m:58s remains)
INFO - root - 2017-12-17 01:16:45.135771: step 170450, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 10h:02m:16s remains)
INFO - root - 2017-12-17 01:16:47.356464: step 170460, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 10h:07m:45s remains)
INFO - root - 2017-12-17 01:16:49.538287: step 170470, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.214 sec/batch; 9h:38m:48s remains)
INFO - root - 2017-12-17 01:16:51.775085: step 170480, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 10h:08m:52s remains)
INFO - root - 2017-12-17 01:16:53.963953: step 170490, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 9h:40m:47s remains)
INFO - root - 2017-12-17 01:16:56.173645: step 170500, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 10h:03m:45s remains)
INFO - root - 2017-12-17 01:16:58.531458: step 170510, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.231 sec/batch; 10h:22m:58s remains)
INFO - root - 2017-12-17 01:17:00.707933: step 170520, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 9h:42m:07s remains)
INFO - root - 2017-12-17 01:17:02.908811: step 170530, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 10h:08m:03s remains)
INFO - root - 2017-12-17 01:17:05.138888: step 170540, loss = 0.43, batch loss = 0.25 (34.6 examples/sec; 0.231 sec/batch; 10h:23m:14s remains)
INFO - root - 2017-12-17 01:17:07.338922: step 170550, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 10h:15m:22s remains)
INFO - root - 2017-12-17 01:17:09.580814: step 170560, loss = 0.43, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 10h:07m:57s remains)
INFO - root - 2017-12-17 01:17:11.816901: step 170570, loss = 0.48, batch loss = 0.30 (34.3 examples/sec; 0.234 sec/batch; 10h:30m:14s remains)
INFO - root - 2017-12-17 01:17:14.039042: step 170580, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 9h:44m:14s remains)
INFO - root - 2017-12-17 01:17:16.250782: step 170590, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 10h:09m:22s remains)
INFO - root - 2017-12-17 01:17:18.489007: step 170600, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 10h:06m:29s remains)
INFO - root - 2017-12-17 01:17:20.845023: step 170610, loss = 0.45, batch loss = 0.27 (34.0 examples/sec; 0.236 sec/batch; 10h:35m:45s remains)
INFO - root - 2017-12-17 01:17:23.075703: step 170620, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 10h:01m:48s remains)
INFO - root - 2017-12-17 01:17:25.287649: step 170630, loss = 0.55, batch loss = 0.38 (37.2 examples/sec; 0.215 sec/batch; 9h:40m:53s remains)
INFO - root - 2017-12-17 01:17:27.524292: step 170640, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 9h:49m:24s remains)
INFO - root - 2017-12-17 01:17:29.722220: step 170650, loss = 0.53, batch loss = 0.35 (37.0 examples/sec; 0.216 sec/batch; 9h:43m:04s remains)
INFO - root - 2017-12-17 01:17:31.964818: step 170660, loss = 0.50, batch loss = 0.32 (34.1 examples/sec; 0.235 sec/batch; 10h:33m:39s remains)
INFO - root - 2017-12-17 01:17:34.152615: step 170670, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 10h:03m:49s remains)
INFO - root - 2017-12-17 01:17:36.353682: step 170680, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 10h:08m:11s remains)
INFO - root - 2017-12-17 01:17:38.592026: step 170690, loss = 0.43, batch loss = 0.25 (33.6 examples/sec; 0.238 sec/batch; 10h:42m:09s remains)
INFO - root - 2017-12-17 01:17:40.789694: step 170700, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 10h:05m:26s remains)
INFO - root - 2017-12-17 01:17:43.155446: step 170710, loss = 0.49, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 9h:38m:55s remains)
INFO - root - 2017-12-17 01:17:45.365144: step 170720, loss = 0.59, batch loss = 0.41 (36.4 examples/sec; 0.220 sec/batch; 9h:52m:58s remains)
INFO - root - 2017-12-17 01:17:47.607864: step 170730, loss = 0.54, batch loss = 0.36 (36.8 examples/sec; 0.217 sec/batch; 9h:45m:40s remains)
INFO - root - 2017-12-17 01:17:49.830547: step 170740, loss = 0.44, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 9h:57m:59s remains)
INFO - root - 2017-12-17 01:17:52.041940: step 170750, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 9h:41m:48s remains)
INFO - root - 2017-12-17 01:17:54.232680: step 170760, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 9h:49m:09s remains)
INFO - root - 2017-12-17 01:17:56.418956: step 170770, loss = 0.46, batch loss = 0.29 (37.9 examples/sec; 0.211 sec/batch; 9h:29m:11s remains)
INFO - root - 2017-12-17 01:17:58.646854: step 170780, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 9h:57m:06s remains)
INFO - root - 2017-12-17 01:18:00.848614: step 170790, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 9h:32m:14s remains)
INFO - root - 2017-12-17 01:18:03.086766: step 170800, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 9h:40m:49s remains)
INFO - root - 2017-12-17 01:18:05.411279: step 170810, loss = 0.53, batch loss = 0.36 (34.7 examples/sec; 0.231 sec/batch; 10h:21m:24s remains)
INFO - root - 2017-12-17 01:18:07.674383: step 170820, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 9h:56m:52s remains)
INFO - root - 2017-12-17 01:18:09.883902: step 170830, loss = 0.47, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 9h:56m:09s remains)
INFO - root - 2017-12-17 01:18:12.115343: step 170840, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 9h:54m:16s remains)
INFO - root - 2017-12-17 01:18:14.316636: step 170850, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 9h:42m:34s remains)
INFO - root - 2017-12-17 01:18:16.542965: step 170860, loss = 0.46, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 10h:00m:06s remains)
INFO - root - 2017-12-17 01:18:18.768522: step 170870, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 10h:22m:31s remains)
INFO - root - 2017-12-17 01:18:20.973606: step 170880, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 9h:56m:46s remains)
INFO - root - 2017-12-17 01:18:23.171688: step 170890, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 9h:47m:33s remains)
INFO - root - 2017-12-17 01:18:25.394579: step 170900, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 9h:50m:11s remains)
INFO - root - 2017-12-17 01:18:27.759556: step 170910, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.224 sec/batch; 10h:04m:24s remains)
INFO - root - 2017-12-17 01:18:29.975809: step 170920, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.218 sec/batch; 9h:45m:47s remains)
INFO - root - 2017-12-17 01:18:32.169654: step 170930, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 9h:42m:55s remains)
INFO - root - 2017-12-17 01:18:34.387607: step 170940, loss = 0.43, batch loss = 0.25 (37.0 examples/sec; 0.216 sec/batch; 9h:41m:28s remains)
INFO - root - 2017-12-17 01:18:36.641314: step 170950, loss = 0.46, batch loss = 0.28 (38.1 examples/sec; 0.210 sec/batch; 9h:24m:42s remains)
INFO - root - 2017-12-17 01:18:38.875381: step 170960, loss = 0.51, batch loss = 0.33 (37.5 examples/sec; 0.213 sec/batch; 9h:34m:37s remains)
INFO - root - 2017-12-17 01:18:41.127279: step 170970, loss = 0.53, batch loss = 0.36 (35.6 examples/sec; 0.225 sec/batch; 10h:05m:08s remains)
INFO - root - 2017-12-17 01:18:43.384506: step 170980, loss = 0.44, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 10h:03m:43s remains)
INFO - root - 2017-12-17 01:18:45.599110: step 170990, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 9h:29m:56s remains)
INFO - root - 2017-12-17 01:18:47.801931: step 171000, loss = 0.49, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 10h:11m:40s remains)
INFO - root - 2017-12-17 01:18:50.170994: step 171010, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 10h:04m:59s remains)
INFO - root - 2017-12-17 01:18:52.359119: step 171020, loss = 0.50, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 9h:49m:47s remains)
INFO - root - 2017-12-17 01:18:54.581067: step 171030, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 9h:55m:03s remains)
INFO - root - 2017-12-17 01:18:56.811386: step 171040, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 10h:04m:32s remains)
INFO - root - 2017-12-17 01:18:58.995473: step 171050, loss = 0.50, batch loss = 0.32 (38.0 examples/sec; 0.211 sec/batch; 9h:27m:13s remains)
INFO - root - 2017-12-17 01:19:01.250208: step 171060, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 9h:53m:32s remains)
INFO - root - 2017-12-17 01:19:03.447858: step 171070, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.224 sec/batch; 10h:01m:20s remains)
INFO - root - 2017-12-17 01:19:05.688163: step 171080, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 9h:45m:30s remains)
INFO - root - 2017-12-17 01:19:07.885791: step 171090, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 9h:48m:20s remains)
INFO - root - 2017-12-17 01:19:10.098057: step 171100, loss = 0.48, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 9h:46m:25s remains)
INFO - root - 2017-12-17 01:19:12.465292: step 171110, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 10h:00m:54s remains)
INFO - root - 2017-12-17 01:19:14.661807: step 171120, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 9h:54m:46s remains)
INFO - root - 2017-12-17 01:19:16.860890: step 171130, loss = 0.47, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 10h:09m:11s remains)
INFO - root - 2017-12-17 01:19:19.111287: step 171140, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 9h:56m:26s remains)
INFO - root - 2017-12-17 01:19:21.360678: step 171150, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 10h:07m:31s remains)
INFO - root - 2017-12-17 01:19:23.603311: step 171160, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 9h:50m:28s remains)
INFO - root - 2017-12-17 01:19:25.808520: step 171170, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 10h:23m:25s remains)
INFO - root - 2017-12-17 01:19:28.090524: step 171180, loss = 0.49, batch loss = 0.32 (35.3 examples/sec; 0.226 sec/batch; 10h:08m:46s remains)
INFO - root - 2017-12-17 01:19:30.315355: step 171190, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 9h:50m:43s remains)
INFO - root - 2017-12-17 01:19:32.576849: step 171200, loss = 0.53, batch loss = 0.36 (36.1 examples/sec; 0.221 sec/batch; 9h:55m:22s remains)
INFO - root - 2017-12-17 01:19:34.938480: step 171210, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 9h:48m:03s remains)
INFO - root - 2017-12-17 01:19:37.191669: step 171220, loss = 0.47, batch loss = 0.30 (33.7 examples/sec; 0.237 sec/batch; 10h:38m:06s remains)
INFO - root - 2017-12-17 01:19:39.436218: step 171230, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 9h:53m:54s remains)
INFO - root - 2017-12-17 01:19:41.652821: step 171240, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 9h:52m:41s remains)
INFO - root - 2017-12-17 01:19:43.863691: step 171250, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 9h:38m:50s remains)
INFO - root - 2017-12-17 01:19:46.080089: step 171260, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 10h:03m:47s remains)
INFO - root - 2017-12-17 01:19:48.282047: step 171270, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 9h:50m:56s remains)
INFO - root - 2017-12-17 01:19:50.555037: step 171280, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 10h:14m:13s remains)
INFO - root - 2017-12-17 01:19:52.822837: step 171290, loss = 0.43, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 9h:52m:34s remains)
INFO - root - 2017-12-17 01:19:55.058712: step 171300, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 10h:05m:41s remains)
INFO - root - 2017-12-17 01:19:57.379544: step 171310, loss = 0.54, batch loss = 0.36 (37.5 examples/sec; 0.213 sec/batch; 9h:33m:20s remains)
INFO - root - 2017-12-17 01:19:59.597314: step 171320, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 9h:52m:36s remains)
INFO - root - 2017-12-17 01:20:01.810814: step 171330, loss = 0.51, batch loss = 0.33 (34.1 examples/sec; 0.234 sec/batch; 10h:29m:40s remains)
INFO - root - 2017-12-17 01:20:04.051314: step 171340, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 9h:47m:58s remains)
INFO - root - 2017-12-17 01:20:06.271043: step 171350, loss = 0.47, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 9h:43m:49s remains)
INFO - root - 2017-12-17 01:20:08.558197: step 171360, loss = 0.50, batch loss = 0.32 (33.4 examples/sec; 0.239 sec/batch; 10h:42m:44s remains)
INFO - root - 2017-12-17 01:20:10.795146: step 171370, loss = 0.53, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 10h:01m:25s remains)
INFO - root - 2017-12-17 01:20:13.052243: step 171380, loss = 0.45, batch loss = 0.28 (34.1 examples/sec; 0.234 sec/batch; 10h:29m:20s remains)
INFO - root - 2017-12-17 01:20:15.231209: step 171390, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 9h:47m:04s remains)
INFO - root - 2017-12-17 01:20:17.463316: step 171400, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 9h:51m:23s remains)
INFO - root - 2017-12-17 01:20:19.820316: step 171410, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 9h:47m:50s remains)
INFO - root - 2017-12-17 01:20:22.025782: step 171420, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 9h:47m:39s remains)
INFO - root - 2017-12-17 01:20:24.268163: step 171430, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 10h:03m:46s remains)
INFO - root - 2017-12-17 01:20:26.455102: step 171440, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 9h:42m:25s remains)
INFO - root - 2017-12-17 01:20:28.640577: step 171450, loss = 0.42, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 9h:56m:24s remains)
INFO - root - 2017-12-17 01:20:30.893663: step 171460, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 9h:50m:02s remains)
INFO - root - 2017-12-17 01:20:33.118682: step 171470, loss = 0.44, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 10h:05m:11s remains)
INFO - root - 2017-12-17 01:20:35.337293: step 171480, loss = 0.51, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 10h:16m:14s remains)
INFO - root - 2017-12-17 01:20:37.558621: step 171490, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 9h:51m:16s remains)
INFO - root - 2017-12-17 01:20:39.785736: step 171500, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 9h:53m:22s remains)
INFO - root - 2017-12-17 01:20:42.165538: step 171510, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 9h:41m:56s remains)
INFO - root - 2017-12-17 01:20:44.378128: step 171520, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 10h:03m:06s remains)
INFO - root - 2017-12-17 01:20:46.573491: step 171530, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 9h:52m:29s remains)
INFO - root - 2017-12-17 01:20:48.759078: step 171540, loss = 0.58, batch loss = 0.40 (36.8 examples/sec; 0.218 sec/batch; 9h:43m:41s remains)
INFO - root - 2017-12-17 01:20:50.969873: step 171550, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 10h:03m:39s remains)
INFO - root - 2017-12-17 01:20:53.201878: step 171560, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 10h:03m:12s remains)
INFO - root - 2017-12-17 01:20:55.391075: step 171570, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 9h:27m:29s remains)
INFO - root - 2017-12-17 01:20:57.598234: step 171580, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 10h:10m:26s remains)
INFO - root - 2017-12-17 01:20:59.863175: step 171590, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 10h:00m:21s remains)
INFO - root - 2017-12-17 01:21:02.090905: step 171600, loss = 0.45, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 10h:04m:17s remains)
INFO - root - 2017-12-17 01:21:04.411578: step 171610, loss = 0.51, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 9h:48m:39s remains)
INFO - root - 2017-12-17 01:21:06.637034: step 171620, loss = 0.50, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 10h:17m:06s remains)
INFO - root - 2017-12-17 01:21:08.851828: step 171630, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 9h:55m:08s remains)
INFO - root - 2017-12-17 01:21:11.069972: step 171640, loss = 0.49, batch loss = 0.32 (34.7 examples/sec; 0.230 sec/batch; 10h:17m:52s remains)
INFO - root - 2017-12-17 01:21:13.312854: step 171650, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 9h:57m:51s remains)
INFO - root - 2017-12-17 01:21:15.509531: step 171660, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 10h:00m:18s remains)
INFO - root - 2017-12-17 01:21:17.720220: step 171670, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 9h:43m:06s remains)
INFO - root - 2017-12-17 01:21:19.934825: step 171680, loss = 0.47, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 9h:46m:38s remains)
INFO - root - 2017-12-17 01:21:22.162009: step 171690, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 9h:44m:50s remains)
INFO - root - 2017-12-17 01:21:24.361774: step 171700, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 9h:58m:03s remains)
INFO - root - 2017-12-17 01:21:26.725782: step 171710, loss = 0.47, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 10h:04m:15s remains)
INFO - root - 2017-12-17 01:21:28.945433: step 171720, loss = 0.42, batch loss = 0.25 (33.9 examples/sec; 0.236 sec/batch; 10h:31m:41s remains)
INFO - root - 2017-12-17 01:21:31.146817: step 171730, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 9h:41m:11s remains)
INFO - root - 2017-12-17 01:21:33.407196: step 171740, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 9h:50m:14s remains)
INFO - root - 2017-12-17 01:21:35.653937: step 171750, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 9h:54m:25s remains)
INFO - root - 2017-12-17 01:21:37.893384: step 171760, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 9h:48m:47s remains)
INFO - root - 2017-12-17 01:21:40.116157: step 171770, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 9h:34m:29s remains)
INFO - root - 2017-12-17 01:21:42.334180: step 171780, loss = 0.41, batch loss = 0.23 (35.6 examples/sec; 0.225 sec/batch; 10h:02m:43s remains)
INFO - root - 2017-12-17 01:21:44.560939: step 171790, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 9h:46m:49s remains)
INFO - root - 2017-12-17 01:21:46.765392: step 171800, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 9h:54m:53s remains)
INFO - root - 2017-12-17 01:21:49.125454: step 171810, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 9h:45m:06s remains)
INFO - root - 2017-12-17 01:21:51.349843: step 171820, loss = 0.48, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 9h:30m:34s remains)
INFO - root - 2017-12-17 01:21:53.620294: step 171830, loss = 0.43, batch loss = 0.25 (34.6 examples/sec; 0.231 sec/batch; 10h:18m:32s remains)
INFO - root - 2017-12-17 01:21:55.855510: step 171840, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 9h:51m:53s remains)
INFO - root - 2017-12-17 01:21:58.100317: step 171850, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 10h:13m:13s remains)
INFO - root - 2017-12-17 01:22:00.275965: step 171860, loss = 0.43, batch loss = 0.25 (37.8 examples/sec; 0.212 sec/batch; 9h:27m:06s remains)
INFO - root - 2017-12-17 01:22:02.517763: step 171870, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 9h:50m:47s remains)
INFO - root - 2017-12-17 01:22:04.744678: step 171880, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 9h:40m:30s remains)
INFO - root - 2017-12-17 01:22:06.967718: step 171890, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 9h:52m:13s remains)
INFO - root - 2017-12-17 01:22:09.194477: step 171900, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 9h:49m:06s remains)
INFO - root - 2017-12-17 01:22:11.532651: step 171910, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 9h:33m:40s remains)
INFO - root - 2017-12-17 01:22:13.757883: step 171920, loss = 0.57, batch loss = 0.39 (35.9 examples/sec; 0.223 sec/batch; 9h:55m:48s remains)
INFO - root - 2017-12-17 01:22:15.998928: step 171930, loss = 0.42, batch loss = 0.24 (32.9 examples/sec; 0.243 sec/batch; 10h:49m:50s remains)
INFO - root - 2017-12-17 01:22:18.182421: step 171940, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 9h:53m:03s remains)
INFO - root - 2017-12-17 01:22:20.423697: step 171950, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 9h:59m:55s remains)
INFO - root - 2017-12-17 01:22:22.672823: step 171960, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 9h:48m:57s remains)
INFO - root - 2017-12-17 01:22:24.881067: step 171970, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 9h:58m:57s remains)
INFO - root - 2017-12-17 01:22:27.081209: step 171980, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 9h:42m:00s remains)
INFO - root - 2017-12-17 01:22:29.318875: step 171990, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.229 sec/batch; 10h:12m:19s remains)
INFO - root - 2017-12-17 01:22:31.567981: step 172000, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 9h:58m:36s remains)
INFO - root - 2017-12-17 01:22:33.940526: step 172010, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 10h:03m:25s remains)
INFO - root - 2017-12-17 01:22:36.198520: step 172020, loss = 0.45, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 9h:44m:59s remains)
INFO - root - 2017-12-17 01:22:38.410251: step 172030, loss = 0.56, batch loss = 0.38 (36.4 examples/sec; 0.220 sec/batch; 9h:48m:11s remains)
INFO - root - 2017-12-17 01:22:40.597118: step 172040, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 9h:48m:47s remains)
INFO - root - 2017-12-17 01:22:42.770961: step 172050, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 9h:45m:49s remains)
INFO - root - 2017-12-17 01:22:45.005297: step 172060, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 10h:01m:54s remains)
INFO - root - 2017-12-17 01:22:47.235217: step 172070, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.233 sec/batch; 10h:21m:55s remains)
INFO - root - 2017-12-17 01:22:49.458775: step 172080, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 9h:50m:18s remains)
INFO - root - 2017-12-17 01:22:51.638051: step 172090, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 10h:02m:18s remains)
INFO - root - 2017-12-17 01:22:53.842858: step 172100, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 10h:02m:51s remains)
INFO - root - 2017-12-17 01:22:56.236413: step 172110, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 10h:04m:26s remains)
INFO - root - 2017-12-17 01:22:58.434983: step 172120, loss = 0.50, batch loss = 0.32 (38.0 examples/sec; 0.211 sec/batch; 9h:22m:59s remains)
INFO - root - 2017-12-17 01:23:00.628398: step 172130, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 9h:51m:51s remains)
INFO - root - 2017-12-17 01:23:02.822358: step 172140, loss = 0.54, batch loss = 0.36 (37.7 examples/sec; 0.212 sec/batch; 9h:27m:04s remains)
INFO - root - 2017-12-17 01:23:05.041544: step 172150, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 9h:45m:10s remains)
INFO - root - 2017-12-17 01:23:07.288058: step 172160, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 9h:41m:25s remains)
INFO - root - 2017-12-17 01:23:09.512977: step 172170, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 10h:12m:37s remains)
INFO - root - 2017-12-17 01:23:11.732287: step 172180, loss = 0.45, batch loss = 0.27 (34.6 examples/sec; 0.232 sec/batch; 10h:18m:38s remains)
INFO - root - 2017-12-17 01:23:13.905848: step 172190, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 9h:36m:20s remains)
INFO - root - 2017-12-17 01:23:16.140830: step 172200, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 9h:58m:04s remains)
INFO - root - 2017-12-17 01:23:18.481855: step 172210, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.218 sec/batch; 9h:41m:13s remains)
INFO - root - 2017-12-17 01:23:20.702341: step 172220, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 9h:36m:58s remains)
INFO - root - 2017-12-17 01:23:22.915341: step 172230, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 10h:08m:38s remains)
INFO - root - 2017-12-17 01:23:25.126221: step 172240, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 9h:46m:12s remains)
INFO - root - 2017-12-17 01:23:27.346649: step 172250, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 9h:52m:19s remains)
INFO - root - 2017-12-17 01:23:29.600423: step 172260, loss = 0.44, batch loss = 0.26 (33.3 examples/sec; 0.240 sec/batch; 10h:41m:02s remains)
INFO - root - 2017-12-17 01:23:31.829203: step 172270, loss = 0.57, batch loss = 0.39 (34.2 examples/sec; 0.234 sec/batch; 10h:24m:40s remains)
INFO - root - 2017-12-17 01:23:33.996240: step 172280, loss = 0.59, batch loss = 0.41 (36.8 examples/sec; 0.217 sec/batch; 9h:40m:39s remains)
INFO - root - 2017-12-17 01:23:36.214232: step 172290, loss = 0.43, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 10h:06m:48s remains)
INFO - root - 2017-12-17 01:23:38.448093: step 172300, loss = 0.56, batch loss = 0.38 (35.3 examples/sec; 0.227 sec/batch; 10h:05m:08s remains)
INFO - root - 2017-12-17 01:23:40.784718: step 172310, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 9h:37m:18s remains)
INFO - root - 2017-12-17 01:23:43.020265: step 172320, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 9h:43m:20s remains)
INFO - root - 2017-12-17 01:23:45.221248: step 172330, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 9h:45m:03s remains)
INFO - root - 2017-12-17 01:23:47.445639: step 172340, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 9h:47m:20s remains)
INFO - root - 2017-12-17 01:23:49.681461: step 172350, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 10h:11m:19s remains)
INFO - root - 2017-12-17 01:23:51.920049: step 172360, loss = 0.42, batch loss = 0.24 (34.2 examples/sec; 0.234 sec/batch; 10h:23m:27s remains)
INFO - root - 2017-12-17 01:23:54.145430: step 172370, loss = 0.46, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 9h:48m:15s remains)
INFO - root - 2017-12-17 01:23:56.406372: step 172380, loss = 0.43, batch loss = 0.25 (35.2 examples/sec; 0.227 sec/batch; 10h:05m:49s remains)
INFO - root - 2017-12-17 01:23:58.631715: step 172390, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 9h:58m:19s remains)
INFO - root - 2017-12-17 01:24:00.821355: step 172400, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 9h:32m:04s remains)
INFO - root - 2017-12-17 01:24:03.176106: step 172410, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 9h:41m:41s remains)
INFO - root - 2017-12-17 01:24:05.394283: step 172420, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 9h:51m:39s remains)
INFO - root - 2017-12-17 01:24:07.589924: step 172430, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 9h:59m:17s remains)
INFO - root - 2017-12-17 01:24:09.825211: step 172440, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 9h:46m:15s remains)
INFO - root - 2017-12-17 01:24:12.033640: step 172450, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 9h:57m:09s remains)
INFO - root - 2017-12-17 01:24:14.268482: step 172460, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 9h:58m:26s remains)
INFO - root - 2017-12-17 01:24:16.479025: step 172470, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.221 sec/batch; 9h:50m:42s remains)
INFO - root - 2017-12-17 01:24:18.697033: step 172480, loss = 0.47, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 9h:32m:46s remains)
INFO - root - 2017-12-17 01:24:20.891766: step 172490, loss = 0.52, batch loss = 0.34 (37.3 examples/sec; 0.214 sec/batch; 9h:31m:24s remains)
INFO - root - 2017-12-17 01:24:23.121943: step 172500, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 9h:57m:15s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-172500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-172500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 01:24:26.167683: step 172510, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 9h:54m:32s remains)
INFO - root - 2017-12-17 01:24:28.395276: step 172520, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 9h:47m:48s remains)
INFO - root - 2017-12-17 01:24:30.605199: step 172530, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 9h:55m:16s remains)
INFO - root - 2017-12-17 01:24:32.809519: step 172540, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 9h:44m:41s remains)
INFO - root - 2017-12-17 01:24:34.984461: step 172550, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.216 sec/batch; 9h:35m:20s remains)
INFO - root - 2017-12-17 01:24:37.219812: step 172560, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 9h:45m:51s remains)
INFO - root - 2017-12-17 01:24:39.441336: step 172570, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 9h:36m:59s remains)
INFO - root - 2017-12-17 01:24:41.656365: step 172580, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 9h:54m:03s remains)
INFO - root - 2017-12-17 01:24:43.873076: step 172590, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 9h:25m:45s remains)
INFO - root - 2017-12-17 01:24:46.064003: step 172600, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 9h:50m:29s remains)
INFO - root - 2017-12-17 01:24:48.401762: step 172610, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 10h:15m:36s remains)
INFO - root - 2017-12-17 01:24:50.610557: step 172620, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 9h:57m:39s remains)
INFO - root - 2017-12-17 01:24:52.849510: step 172630, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 9h:43m:58s remains)
INFO - root - 2017-12-17 01:24:55.075863: step 172640, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 9h:54m:19s remains)
INFO - root - 2017-12-17 01:24:57.311151: step 172650, loss = 0.53, batch loss = 0.35 (34.9 examples/sec; 0.229 sec/batch; 10h:10m:56s remains)
INFO - root - 2017-12-17 01:24:59.533603: step 172660, loss = 0.54, batch loss = 0.36 (37.1 examples/sec; 0.215 sec/batch; 9h:34m:03s remains)
INFO - root - 2017-12-17 01:25:01.757418: step 172670, loss = 0.50, batch loss = 0.33 (32.9 examples/sec; 0.243 sec/batch; 10h:48m:03s remains)
INFO - root - 2017-12-17 01:25:03.981938: step 172680, loss = 0.52, batch loss = 0.34 (33.9 examples/sec; 0.236 sec/batch; 10h:27m:44s remains)
INFO - root - 2017-12-17 01:25:06.236373: step 172690, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 9h:53m:40s remains)
INFO - root - 2017-12-17 01:25:08.428404: step 172700, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 9h:32m:27s remains)
INFO - root - 2017-12-17 01:25:10.761018: step 172710, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 9h:38m:36s remains)
INFO - root - 2017-12-17 01:25:13.012570: step 172720, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 10h:04m:51s remains)
INFO - root - 2017-12-17 01:25:15.240175: step 172730, loss = 0.42, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 9h:48m:09s remains)
INFO - root - 2017-12-17 01:25:17.454601: step 172740, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 9h:37m:17s remains)
INFO - root - 2017-12-17 01:25:19.678917: step 172750, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.228 sec/batch; 10h:05m:54s remains)
INFO - root - 2017-12-17 01:25:21.881619: step 172760, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 9h:48m:10s remains)
INFO - root - 2017-12-17 01:25:24.077817: step 172770, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 9h:52m:32s remains)
INFO - root - 2017-12-17 01:25:26.268069: step 172780, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 9h:48m:29s remains)
INFO - root - 2017-12-17 01:25:28.493721: step 172790, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 9h:38m:48s remains)
INFO - root - 2017-12-17 01:25:30.753964: step 172800, loss = 0.48, batch loss = 0.30 (33.0 examples/sec; 0.243 sec/batch; 10h:45m:33s remains)
INFO - root - 2017-12-17 01:25:33.099755: step 172810, loss = 0.50, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 9h:59m:14s remains)
INFO - root - 2017-12-17 01:25:35.308132: step 172820, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 9h:43m:43s remains)
INFO - root - 2017-12-17 01:25:37.539984: step 172830, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.219 sec/batch; 9h:44m:05s remains)
INFO - root - 2017-12-17 01:25:39.753945: step 172840, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 9h:39m:04s remains)
INFO - root - 2017-12-17 01:25:41.986953: step 172850, loss = 0.46, batch loss = 0.28 (34.5 examples/sec; 0.232 sec/batch; 10h:17m:07s remains)
INFO - root - 2017-12-17 01:25:44.168968: step 172860, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 9h:36m:00s remains)
INFO - root - 2017-12-17 01:25:46.358811: step 172870, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 9h:44m:32s remains)
INFO - root - 2017-12-17 01:25:48.610793: step 172880, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 9h:48m:24s remains)
INFO - root - 2017-12-17 01:25:50.859250: step 172890, loss = 0.48, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 10h:11m:58s remains)
INFO - root - 2017-12-17 01:25:53.065425: step 172900, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 9h:34m:42s remains)
INFO - root - 2017-12-17 01:25:55.416008: step 172910, loss = 0.54, batch loss = 0.36 (36.4 examples/sec; 0.219 sec/batch; 9h:43m:47s remains)
INFO - root - 2017-12-17 01:25:57.620450: step 172920, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 9h:55m:55s remains)
INFO - root - 2017-12-17 01:25:59.838532: step 172930, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 9h:50m:11s remains)
INFO - root - 2017-12-17 01:26:02.060420: step 172940, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 9h:48m:32s remains)
INFO - root - 2017-12-17 01:26:04.312580: step 172950, loss = 0.51, batch loss = 0.34 (34.8 examples/sec; 0.230 sec/batch; 10h:10m:44s remains)
INFO - root - 2017-12-17 01:26:06.487994: step 172960, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 9h:35m:45s remains)
INFO - root - 2017-12-17 01:26:08.673584: step 172970, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 9h:55m:29s remains)
INFO - root - 2017-12-17 01:26:10.858103: step 172980, loss = 0.53, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 9h:55m:29s remains)
INFO - root - 2017-12-17 01:26:13.089923: step 172990, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 10h:03m:48s remains)
INFO - root - 2017-12-17 01:26:15.313616: step 173000, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 9h:43m:11s remains)
INFO - root - 2017-12-17 01:26:17.663721: step 173010, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 10h:00m:35s remains)
INFO - root - 2017-12-17 01:26:19.871680: step 173020, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 9h:43m:37s remains)
INFO - root - 2017-12-17 01:26:22.079030: step 173030, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 9h:57m:00s remains)
INFO - root - 2017-12-17 01:26:24.288648: step 173040, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 9h:49m:08s remains)
INFO - root - 2017-12-17 01:26:26.535161: step 173050, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 10h:00m:29s remains)
INFO - root - 2017-12-17 01:26:28.734650: step 173060, loss = 0.54, batch loss = 0.36 (36.4 examples/sec; 0.220 sec/batch; 9h:44m:09s remains)
INFO - root - 2017-12-17 01:26:30.953307: step 173070, loss = 0.51, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 9h:35m:45s remains)
INFO - root - 2017-12-17 01:26:33.174611: step 173080, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 9h:52m:58s remains)
INFO - root - 2017-12-17 01:26:35.390675: step 173090, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 9h:35m:31s remains)
INFO - root - 2017-12-17 01:26:37.612382: step 173100, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 9h:57m:26s remains)
INFO - root - 2017-12-17 01:26:39.977227: step 173110, loss = 0.44, batch loss = 0.26 (37.4 examples/sec; 0.214 sec/batch; 9h:28m:31s remains)
INFO - root - 2017-12-17 01:26:42.210894: step 173120, loss = 0.48, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 9h:43m:27s remains)
INFO - root - 2017-12-17 01:26:44.398603: step 173130, loss = 0.49, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 9h:45m:50s remains)
INFO - root - 2017-12-17 01:26:46.615683: step 173140, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 9h:37m:22s remains)
INFO - root - 2017-12-17 01:26:48.843048: step 173150, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 9h:38m:02s remains)
INFO - root - 2017-12-17 01:26:51.075100: step 173160, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 9h:41m:33s remains)
INFO - root - 2017-12-17 01:26:53.298267: step 173170, loss = 0.54, batch loss = 0.36 (35.5 examples/sec; 0.225 sec/batch; 9h:58m:06s remains)
INFO - root - 2017-12-17 01:26:55.538446: step 173180, loss = 0.46, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 9h:34m:06s remains)
INFO - root - 2017-12-17 01:26:57.742013: step 173190, loss = 0.56, batch loss = 0.38 (34.2 examples/sec; 0.234 sec/batch; 10h:21m:00s remains)
INFO - root - 2017-12-17 01:26:59.941533: step 173200, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 9h:40m:01s remains)
INFO - root - 2017-12-17 01:27:02.314800: step 173210, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 9h:45m:25s remains)
INFO - root - 2017-12-17 01:27:04.518253: step 173220, loss = 0.50, batch loss = 0.32 (37.8 examples/sec; 0.212 sec/batch; 9h:22m:13s remains)
INFO - root - 2017-12-17 01:27:06.738262: step 173230, loss = 0.50, batch loss = 0.32 (34.0 examples/sec; 0.236 sec/batch; 10h:25m:21s remains)
INFO - root - 2017-12-17 01:27:08.958952: step 173240, loss = 0.46, batch loss = 0.29 (35.3 examples/sec; 0.226 sec/batch; 10h:01m:12s remains)
INFO - root - 2017-12-17 01:27:11.140482: step 173250, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 9h:33m:44s remains)
INFO - root - 2017-12-17 01:27:13.359067: step 173260, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 9h:30m:36s remains)
INFO - root - 2017-12-17 01:27:15.560091: step 173270, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 10h:03m:27s remains)
INFO - root - 2017-12-17 01:27:17.780013: step 173280, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 9h:49m:12s remains)
INFO - root - 2017-12-17 01:27:20.002330: step 173290, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 10h:06m:30s remains)
INFO - root - 2017-12-17 01:27:22.237973: step 173300, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 9h:43m:14s remains)
INFO - root - 2017-12-17 01:27:24.605525: step 173310, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 9h:58m:04s remains)
INFO - root - 2017-12-17 01:27:26.835446: step 173320, loss = 0.50, batch loss = 0.32 (33.1 examples/sec; 0.242 sec/batch; 10h:41m:41s remains)
INFO - root - 2017-12-17 01:27:29.090965: step 173330, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 10h:01m:12s remains)
INFO - root - 2017-12-17 01:27:31.342962: step 173340, loss = 0.43, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 9h:49m:35s remains)
INFO - root - 2017-12-17 01:27:33.579743: step 173350, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.230 sec/batch; 10h:10m:48s remains)
INFO - root - 2017-12-17 01:27:35.777463: step 173360, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 9h:51m:22s remains)
INFO - root - 2017-12-17 01:27:38.020490: step 173370, loss = 0.44, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 9h:53m:52s remains)
INFO - root - 2017-12-17 01:27:40.252638: step 173380, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.221 sec/batch; 9h:44m:49s remains)
INFO - root - 2017-12-17 01:27:42.498030: step 173390, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 9h:59m:29s remains)
INFO - root - 2017-12-17 01:27:44.696482: step 173400, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 9h:55m:01s remains)
INFO - root - 2017-12-17 01:27:47.016101: step 173410, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 9h:34m:05s remains)
INFO - root - 2017-12-17 01:27:49.257558: step 173420, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 9h:46m:54s remains)
INFO - root - 2017-12-17 01:27:51.437551: step 173430, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 9h:49m:25s remains)
INFO - root - 2017-12-17 01:27:53.668976: step 173440, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 9h:42m:56s remains)
INFO - root - 2017-12-17 01:27:55.856194: step 173450, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 9h:26m:44s remains)
INFO - root - 2017-12-17 01:27:58.055013: step 173460, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.214 sec/batch; 9h:28m:21s remains)
INFO - root - 2017-12-17 01:28:00.281417: step 173470, loss = 0.42, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 9h:54m:12s remains)
INFO - root - 2017-12-17 01:28:02.493068: step 173480, loss = 0.50, batch loss = 0.32 (34.4 examples/sec; 0.232 sec/batch; 10h:15m:44s remains)
INFO - root - 2017-12-17 01:28:04.760307: step 173490, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 10h:01m:29s remains)
INFO - root - 2017-12-17 01:28:06.979991: step 173500, loss = 0.52, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 10h:04m:30s remains)
INFO - root - 2017-12-17 01:28:09.359638: step 173510, loss = 0.51, batch loss = 0.33 (34.9 examples/sec; 0.229 sec/batch; 10h:08m:04s remains)
INFO - root - 2017-12-17 01:28:11.579622: step 173520, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 10h:03m:14s remains)
INFO - root - 2017-12-17 01:28:13.850009: step 173530, loss = 0.53, batch loss = 0.36 (35.8 examples/sec; 0.224 sec/batch; 9h:52m:36s remains)
INFO - root - 2017-12-17 01:28:16.065194: step 173540, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 10h:13m:34s remains)
INFO - root - 2017-12-17 01:28:18.323003: step 173550, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.226 sec/batch; 9h:59m:55s remains)
INFO - root - 2017-12-17 01:28:20.549246: step 173560, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 9h:34m:16s remains)
INFO - root - 2017-12-17 01:28:22.732858: step 173570, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 9h:30m:13s remains)
INFO - root - 2017-12-17 01:28:24.937449: step 173580, loss = 0.55, batch loss = 0.38 (35.2 examples/sec; 0.227 sec/batch; 10h:01m:35s remains)
INFO - root - 2017-12-17 01:28:27.156436: step 173590, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 9h:58m:04s remains)
INFO - root - 2017-12-17 01:28:29.369686: step 173600, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.223 sec/batch; 9h:51m:36s remains)
INFO - root - 2017-12-17 01:28:31.714727: step 173610, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 9h:38m:40s remains)
INFO - root - 2017-12-17 01:28:33.900954: step 173620, loss = 0.52, batch loss = 0.34 (37.6 examples/sec; 0.213 sec/batch; 9h:22m:48s remains)
INFO - root - 2017-12-17 01:28:36.135883: step 173630, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 9h:58m:30s remains)
INFO - root - 2017-12-17 01:28:38.378378: step 173640, loss = 0.48, batch loss = 0.30 (34.3 examples/sec; 0.233 sec/batch; 10h:17m:31s remains)
INFO - root - 2017-12-17 01:28:40.585184: step 173650, loss = 0.57, batch loss = 0.39 (37.5 examples/sec; 0.213 sec/batch; 9h:24m:27s remains)
INFO - root - 2017-12-17 01:28:42.792057: step 173660, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 9h:31m:55s remains)
INFO - root - 2017-12-17 01:28:45.003279: step 173670, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 9h:41m:04s remains)
INFO - root - 2017-12-17 01:28:47.231353: step 173680, loss = 0.50, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 9h:34m:52s remains)
INFO - root - 2017-12-17 01:28:49.479803: step 173690, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 9h:50m:37s remains)
INFO - root - 2017-12-17 01:28:51.740418: step 173700, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 9h:24m:10s remains)
INFO - root - 2017-12-17 01:28:54.060359: step 173710, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 9h:58m:46s remains)
INFO - root - 2017-12-17 01:28:56.246939: step 173720, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 9h:48m:43s remains)
INFO - root - 2017-12-17 01:28:58.477245: step 173730, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 9h:45m:51s remains)
INFO - root - 2017-12-17 01:29:00.665761: step 173740, loss = 0.46, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 9h:54m:57s remains)
INFO - root - 2017-12-17 01:29:02.904003: step 173750, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 9h:33m:50s remains)
INFO - root - 2017-12-17 01:29:05.137469: step 173760, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 9h:43m:32s remains)
INFO - root - 2017-12-17 01:29:07.383503: step 173770, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 9h:32m:19s remains)
INFO - root - 2017-12-17 01:29:09.611689: step 173780, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 9h:51m:25s remains)
INFO - root - 2017-12-17 01:29:11.830384: step 173790, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 10h:02m:28s remains)
INFO - root - 2017-12-17 01:29:14.051490: step 173800, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 9h:35m:34s remains)
INFO - root - 2017-12-17 01:29:16.369736: step 173810, loss = 0.51, batch loss = 0.33 (37.5 examples/sec; 0.213 sec/batch; 9h:24m:32s remains)
INFO - root - 2017-12-17 01:29:18.568041: step 173820, loss = 0.51, batch loss = 0.33 (34.6 examples/sec; 0.231 sec/batch; 10h:10m:49s remains)
INFO - root - 2017-12-17 01:29:20.846555: step 173830, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 9h:37m:53s remains)
INFO - root - 2017-12-17 01:29:23.108374: step 173840, loss = 0.43, batch loss = 0.25 (31.7 examples/sec; 0.252 sec/batch; 11h:06m:44s remains)
INFO - root - 2017-12-17 01:29:25.318965: step 173850, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 10h:02m:56s remains)
INFO - root - 2017-12-17 01:29:27.550131: step 173860, loss = 0.56, batch loss = 0.38 (35.1 examples/sec; 0.228 sec/batch; 10h:02m:05s remains)
INFO - root - 2017-12-17 01:29:29.762573: step 173870, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 9h:42m:17s remains)
INFO - root - 2017-12-17 01:29:31.979876: step 173880, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 10h:01m:06s remains)
INFO - root - 2017-12-17 01:29:34.202039: step 173890, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 10h:06m:19s remains)
INFO - root - 2017-12-17 01:29:36.419004: step 173900, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 9h:48m:28s remains)
INFO - root - 2017-12-17 01:29:38.716399: step 173910, loss = 0.42, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 9h:44m:12s remains)
INFO - root - 2017-12-17 01:29:40.958508: step 173920, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 9h:55m:05s remains)
INFO - root - 2017-12-17 01:29:43.162972: step 173930, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 9h:34m:19s remains)
INFO - root - 2017-12-17 01:29:45.376795: step 173940, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 9h:39m:29s remains)
INFO - root - 2017-12-17 01:29:47.587646: step 173950, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 9h:46m:23s remains)
INFO - root - 2017-12-17 01:29:49.838785: step 173960, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.226 sec/batch; 9h:58m:20s remains)
INFO - root - 2017-12-17 01:29:52.042795: step 173970, loss = 0.46, batch loss = 0.28 (33.8 examples/sec; 0.236 sec/batch; 10h:24m:39s remains)
INFO - root - 2017-12-17 01:29:54.277708: step 173980, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 9h:33m:55s remains)
INFO - root - 2017-12-17 01:29:56.473998: step 173990, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 9h:33m:27s remains)
INFO - root - 2017-12-17 01:29:58.663573: step 174000, loss = 0.46, batch loss = 0.28 (38.1 examples/sec; 0.210 sec/batch; 9h:15m:14s remains)
INFO - root - 2017-12-17 01:30:01.031661: step 174010, loss = 0.45, batch loss = 0.27 (33.9 examples/sec; 0.236 sec/batch; 10h:23m:31s remains)
INFO - root - 2017-12-17 01:30:03.273757: step 174020, loss = 0.54, batch loss = 0.36 (34.1 examples/sec; 0.235 sec/batch; 10h:20m:24s remains)
INFO - root - 2017-12-17 01:30:05.508365: step 174030, loss = 0.55, batch loss = 0.37 (36.7 examples/sec; 0.218 sec/batch; 9h:35m:44s remains)
INFO - root - 2017-12-17 01:30:07.801972: step 174040, loss = 0.46, batch loss = 0.28 (34.0 examples/sec; 0.236 sec/batch; 10h:22m:18s remains)
INFO - root - 2017-12-17 01:30:10.010794: step 174050, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.231 sec/batch; 10h:08m:48s remains)
INFO - root - 2017-12-17 01:30:12.218717: step 174060, loss = 0.45, batch loss = 0.28 (34.2 examples/sec; 0.234 sec/batch; 10h:18m:35s remains)
INFO - root - 2017-12-17 01:30:14.425638: step 174070, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 9h:47m:30s remains)
INFO - root - 2017-12-17 01:30:16.651700: step 174080, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 9h:45m:33s remains)
INFO - root - 2017-12-17 01:30:18.879061: step 174090, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 9h:39m:21s remains)
INFO - root - 2017-12-17 01:30:21.087256: step 174100, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 9h:53m:24s remains)
INFO - root - 2017-12-17 01:30:23.447420: step 174110, loss = 0.48, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 9h:48m:32s remains)
INFO - root - 2017-12-17 01:30:25.622768: step 174120, loss = 0.52, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 9h:33m:43s remains)
INFO - root - 2017-12-17 01:30:27.835465: step 174130, loss = 0.50, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 10h:04m:35s remains)
INFO - root - 2017-12-17 01:30:30.037010: step 174140, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 9h:34m:05s remains)
INFO - root - 2017-12-17 01:30:32.251971: step 174150, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 9h:41m:09s remains)
INFO - root - 2017-12-17 01:30:34.448574: step 174160, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 9h:31m:19s remains)
INFO - root - 2017-12-17 01:30:36.650937: step 174170, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 9h:49m:36s remains)
INFO - root - 2017-12-17 01:30:38.929641: step 174180, loss = 0.57, batch loss = 0.39 (35.6 examples/sec; 0.225 sec/batch; 9h:53m:18s remains)
INFO - root - 2017-12-17 01:30:41.137302: step 174190, loss = 0.50, batch loss = 0.32 (35.0 examples/sec; 0.228 sec/batch; 10h:02m:31s remains)
INFO - root - 2017-12-17 01:30:43.354005: step 174200, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 10h:03m:16s remains)
INFO - root - 2017-12-17 01:30:45.709704: step 174210, loss = 0.44, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 9h:31m:51s remains)
INFO - root - 2017-12-17 01:30:47.946647: step 174220, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 9h:56m:40s remains)
INFO - root - 2017-12-17 01:30:50.178315: step 174230, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 9h:45m:14s remains)
INFO - root - 2017-12-17 01:30:52.391959: step 174240, loss = 0.50, batch loss = 0.33 (34.6 examples/sec; 0.231 sec/batch; 10h:09m:18s remains)
INFO - root - 2017-12-17 01:30:54.591031: step 174250, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 9h:42m:00s remains)
INFO - root - 2017-12-17 01:30:56.825540: step 174260, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 10h:04m:32s remains)
INFO - root - 2017-12-17 01:30:59.015013: step 174270, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 9h:44m:41s remains)
INFO - root - 2017-12-17 01:31:01.194130: step 174280, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 9h:31m:28s remains)
INFO - root - 2017-12-17 01:31:03.390964: step 174290, loss = 0.48, batch loss = 0.30 (37.8 examples/sec; 0.212 sec/batch; 9h:18m:21s remains)
INFO - root - 2017-12-17 01:31:05.607204: step 174300, loss = 0.54, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 9h:40m:41s remains)
INFO - root - 2017-12-17 01:31:07.971481: step 174310, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 9h:43m:24s remains)
INFO - root - 2017-12-17 01:31:10.228331: step 174320, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 9h:29m:39s remains)
INFO - root - 2017-12-17 01:31:12.432423: step 174330, loss = 0.49, batch loss = 0.32 (36.1 examples/sec; 0.221 sec/batch; 9h:43m:35s remains)
INFO - root - 2017-12-17 01:31:14.657715: step 174340, loss = 0.54, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 9h:41m:08s remains)
INFO - root - 2017-12-17 01:31:16.883653: step 174350, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 9h:43m:06s remains)
INFO - root - 2017-12-17 01:31:19.128271: step 174360, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 9h:31m:59s remains)
INFO - root - 2017-12-17 01:31:21.331478: step 174370, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 9h:30m:48s remains)
INFO - root - 2017-12-17 01:31:23.556847: step 174380, loss = 0.47, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 9h:37m:26s remains)
INFO - root - 2017-12-17 01:31:25.789325: step 174390, loss = 0.47, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 9h:50m:37s remains)
INFO - root - 2017-12-17 01:31:28.040204: step 174400, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 9h:49m:41s remains)
INFO - root - 2017-12-17 01:31:30.375768: step 174410, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 9h:37m:37s remains)
INFO - root - 2017-12-17 01:31:32.619626: step 174420, loss = 0.50, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 10h:05m:18s remains)
INFO - root - 2017-12-17 01:31:34.834713: step 174430, loss = 0.51, batch loss = 0.34 (37.4 examples/sec; 0.214 sec/batch; 9h:23m:22s remains)
INFO - root - 2017-12-17 01:31:37.003833: step 174440, loss = 0.49, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 9h:21m:42s remains)
INFO - root - 2017-12-17 01:31:39.198003: step 174450, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 9h:56m:10s remains)
INFO - root - 2017-12-17 01:31:41.434085: step 174460, loss = 0.46, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 9h:41m:53s remains)
INFO - root - 2017-12-17 01:31:43.650754: step 174470, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 9h:59m:31s remains)
INFO - root - 2017-12-17 01:31:45.840549: step 174480, loss = 0.43, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 9h:48m:56s remains)
INFO - root - 2017-12-17 01:31:48.014835: step 174490, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 9h:38m:19s remains)
INFO - root - 2017-12-17 01:31:50.236766: step 174500, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 9h:43m:59s remains)
INFO - root - 2017-12-17 01:31:52.570917: step 174510, loss = 0.54, batch loss = 0.36 (36.4 examples/sec; 0.220 sec/batch; 9h:38m:55s remains)
INFO - root - 2017-12-17 01:31:54.789162: step 174520, loss = 0.49, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 9h:38m:30s remains)
INFO - root - 2017-12-17 01:31:56.987850: step 174530, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 9h:51m:47s remains)
INFO - root - 2017-12-17 01:31:59.188598: step 174540, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 9h:46m:31s remains)
INFO - root - 2017-12-17 01:32:01.359033: step 174550, loss = 0.54, batch loss = 0.36 (37.4 examples/sec; 0.214 sec/batch; 9h:23m:12s remains)
INFO - root - 2017-12-17 01:32:03.596401: step 174560, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 9h:54m:14s remains)
INFO - root - 2017-12-17 01:32:05.789137: step 174570, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 9h:38m:06s remains)
INFO - root - 2017-12-17 01:32:07.991363: step 174580, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 9h:38m:03s remains)
INFO - root - 2017-12-17 01:32:10.196536: step 174590, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 9h:51m:42s remains)
INFO - root - 2017-12-17 01:32:12.356357: step 174600, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 9h:33m:32s remains)
INFO - root - 2017-12-17 01:32:14.688207: step 174610, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 9h:47m:44s remains)
INFO - root - 2017-12-17 01:32:16.897088: step 174620, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 9h:40m:58s remains)
INFO - root - 2017-12-17 01:32:19.104951: step 174630, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 9h:30m:08s remains)
INFO - root - 2017-12-17 01:32:21.317601: step 174640, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 10h:02m:37s remains)
INFO - root - 2017-12-17 01:32:23.533727: step 174650, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 9h:46m:03s remains)
INFO - root - 2017-12-17 01:32:25.810456: step 174660, loss = 0.50, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 10h:04m:31s remains)
INFO - root - 2017-12-17 01:32:28.023955: step 174670, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 9h:46m:34s remains)
INFO - root - 2017-12-17 01:32:30.249539: step 174680, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 9h:59m:45s remains)
INFO - root - 2017-12-17 01:32:32.455293: step 174690, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 9h:47m:09s remains)
INFO - root - 2017-12-17 01:32:34.675688: step 174700, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 9h:44m:43s remains)
INFO - root - 2017-12-17 01:32:37.003839: step 174710, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 9h:43m:54s remains)
INFO - root - 2017-12-17 01:32:39.227005: step 174720, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 9h:50m:55s remains)
INFO - root - 2017-12-17 01:32:41.433655: step 174730, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 9h:47m:57s remains)
INFO - root - 2017-12-17 01:32:43.659919: step 174740, loss = 0.62, batch loss = 0.44 (35.4 examples/sec; 0.226 sec/batch; 9h:53m:23s remains)
INFO - root - 2017-12-17 01:32:45.883675: step 174750, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 9h:24m:02s remains)
INFO - root - 2017-12-17 01:32:48.102958: step 174760, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 9h:31m:27s remains)
INFO - root - 2017-12-17 01:32:50.302642: step 174770, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 9h:37m:12s remains)
INFO - root - 2017-12-17 01:32:52.541040: step 174780, loss = 0.48, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 9h:28m:06s remains)
INFO - root - 2017-12-17 01:32:54.761089: step 174790, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 9h:59m:34s remains)
INFO - root - 2017-12-17 01:32:56.992864: step 174800, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 9h:35m:03s remains)
INFO - root - 2017-12-17 01:32:59.345648: step 174810, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.214 sec/batch; 9h:23m:39s remains)
INFO - root - 2017-12-17 01:33:01.537373: step 174820, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 9h:35m:40s remains)
INFO - root - 2017-12-17 01:33:03.754960: step 174830, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 9h:42m:16s remains)
INFO - root - 2017-12-17 01:33:05.983216: step 174840, loss = 0.58, batch loss = 0.40 (35.6 examples/sec; 0.225 sec/batch; 9h:50m:15s remains)
INFO - root - 2017-12-17 01:33:08.201933: step 174850, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 9h:33m:28s remains)
INFO - root - 2017-12-17 01:33:10.434176: step 174860, loss = 0.47, batch loss = 0.29 (34.6 examples/sec; 0.231 sec/batch; 10h:07m:42s remains)
INFO - root - 2017-12-17 01:33:12.657112: step 174870, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 9h:58m:44s remains)
INFO - root - 2017-12-17 01:33:14.882893: step 174880, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 10h:00m:52s remains)
INFO - root - 2017-12-17 01:33:17.067413: step 174890, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 9h:33m:15s remains)
INFO - root - 2017-12-17 01:33:19.267704: step 174900, loss = 0.59, batch loss = 0.41 (35.6 examples/sec; 0.225 sec/batch; 9h:50m:44s remains)
INFO - root - 2017-12-17 01:33:21.602051: step 174910, loss = 0.49, batch loss = 0.31 (34.5 examples/sec; 0.232 sec/batch; 10h:08m:49s remains)
INFO - root - 2017-12-17 01:33:23.853940: step 174920, loss = 0.57, batch loss = 0.39 (36.2 examples/sec; 0.221 sec/batch; 9h:41m:10s remains)
INFO - root - 2017-12-17 01:33:26.067572: step 174930, loss = 0.54, batch loss = 0.36 (34.6 examples/sec; 0.231 sec/batch; 10h:06m:43s remains)
INFO - root - 2017-12-17 01:33:28.359109: step 174940, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 9h:40m:50s remains)
INFO - root - 2017-12-17 01:33:30.598069: step 174950, loss = 0.43, batch loss = 0.25 (33.8 examples/sec; 0.236 sec/batch; 10h:20m:52s remains)
INFO - root - 2017-12-17 01:33:32.815576: step 174960, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 9h:54m:31s remains)
INFO - root - 2017-12-17 01:33:35.039549: step 174970, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 9h:50m:07s remains)
INFO - root - 2017-12-17 01:33:37.252667: step 174980, loss = 0.55, batch loss = 0.37 (37.4 examples/sec; 0.214 sec/batch; 9h:21m:17s remains)
INFO - root - 2017-12-17 01:33:39.445277: step 174990, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 9h:38m:56s remains)
INFO - root - 2017-12-17 01:33:41.665220: step 175000, loss = 0.55, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 9h:40m:27s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-175000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-175000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 01:33:44.385150: step 175010, loss = 0.42, batch loss = 0.25 (37.6 examples/sec; 0.213 sec/batch; 9h:18m:42s remains)
INFO - root - 2017-12-17 01:33:46.610415: step 175020, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 9h:35m:54s remains)
INFO - root - 2017-12-17 01:33:48.848577: step 175030, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 9h:35m:28s remains)
INFO - root - 2017-12-17 01:33:51.082315: step 175040, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 9h:54m:49s remains)
INFO - root - 2017-12-17 01:33:53.313232: step 175050, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 9h:35m:48s remains)
INFO - root - 2017-12-17 01:33:55.546055: step 175060, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 9h:53m:46s remains)
INFO - root - 2017-12-17 01:33:57.767839: step 175070, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.223 sec/batch; 9h:45m:33s remains)
INFO - root - 2017-12-17 01:33:59.996005: step 175080, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 9h:48m:45s remains)
INFO - root - 2017-12-17 01:34:02.210316: step 175090, loss = 0.46, batch loss = 0.28 (33.6 examples/sec; 0.238 sec/batch; 10h:25m:33s remains)
INFO - root - 2017-12-17 01:34:04.443525: step 175100, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 9h:36m:20s remains)
INFO - root - 2017-12-17 01:34:06.828203: step 175110, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 9h:51m:21s remains)
INFO - root - 2017-12-17 01:34:09.039426: step 175120, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.226 sec/batch; 9h:51m:45s remains)
INFO - root - 2017-12-17 01:34:11.253469: step 175130, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 9h:43m:17s remains)
INFO - root - 2017-12-17 01:34:13.469139: step 175140, loss = 0.47, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 10h:02m:47s remains)
INFO - root - 2017-12-17 01:34:15.684516: step 175150, loss = 0.47, batch loss = 0.29 (33.8 examples/sec; 0.237 sec/batch; 10h:21m:26s remains)
INFO - root - 2017-12-17 01:34:17.948438: step 175160, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 9h:45m:37s remains)
INFO - root - 2017-12-17 01:34:20.104184: step 175170, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 9h:29m:45s remains)
INFO - root - 2017-12-17 01:34:22.345716: step 175180, loss = 0.51, batch loss = 0.33 (33.9 examples/sec; 0.236 sec/batch; 10h:18m:13s remains)
INFO - root - 2017-12-17 01:34:24.585204: step 175190, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 9h:40m:16s remains)
INFO - root - 2017-12-17 01:34:26.832002: step 175200, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 9h:49m:30s remains)
INFO - root - 2017-12-17 01:34:29.171459: step 175210, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 9h:55m:18s remains)
INFO - root - 2017-12-17 01:34:31.407939: step 175220, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 9h:35m:23s remains)
INFO - root - 2017-12-17 01:34:33.626477: step 175230, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 10h:02m:04s remains)
INFO - root - 2017-12-17 01:34:35.817097: step 175240, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 9h:26m:52s remains)
INFO - root - 2017-12-17 01:34:38.037367: step 175250, loss = 0.50, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 9h:27m:59s remains)
INFO - root - 2017-12-17 01:34:40.284777: step 175260, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 9h:34m:01s remains)
INFO - root - 2017-12-17 01:34:42.497926: step 175270, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 9h:36m:57s remains)
INFO - root - 2017-12-17 01:34:44.701984: step 175280, loss = 0.50, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 9h:49m:10s remains)
INFO - root - 2017-12-17 01:34:46.929018: step 175290, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 9h:32m:05s remains)
INFO - root - 2017-12-17 01:34:49.141965: step 175300, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 9h:58m:12s remains)
INFO - root - 2017-12-17 01:34:51.463163: step 175310, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 9h:23m:57s remains)
INFO - root - 2017-12-17 01:34:53.702202: step 175320, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 9h:47m:13s remains)
INFO - root - 2017-12-17 01:34:55.889270: step 175330, loss = 0.55, batch loss = 0.37 (36.8 examples/sec; 0.218 sec/batch; 9h:29m:47s remains)
INFO - root - 2017-12-17 01:34:58.112701: step 175340, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.214 sec/batch; 9h:21m:32s remains)
INFO - root - 2017-12-17 01:35:00.301775: step 175350, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 9h:35m:06s remains)
INFO - root - 2017-12-17 01:35:02.522038: step 175360, loss = 0.50, batch loss = 0.32 (31.9 examples/sec; 0.250 sec/batch; 10h:56m:02s remains)
INFO - root - 2017-12-17 01:35:04.786168: step 175370, loss = 0.54, batch loss = 0.36 (36.8 examples/sec; 0.217 sec/batch; 9h:29m:25s remains)
INFO - root - 2017-12-17 01:35:07.050385: step 175380, loss = 0.47, batch loss = 0.30 (32.6 examples/sec; 0.245 sec/batch; 10h:41m:56s remains)
INFO - root - 2017-12-17 01:35:09.341658: step 175390, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.226 sec/batch; 9h:53m:05s remains)
INFO - root - 2017-12-17 01:35:11.591222: step 175400, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 9h:34m:06s remains)
INFO - root - 2017-12-17 01:35:13.943416: step 175410, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 9h:43m:50s remains)
INFO - root - 2017-12-17 01:35:16.146334: step 175420, loss = 0.47, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 9h:32m:02s remains)
INFO - root - 2017-12-17 01:35:18.374993: step 175430, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 9h:28m:43s remains)
INFO - root - 2017-12-17 01:35:20.596311: step 175440, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 9h:42m:32s remains)
INFO - root - 2017-12-17 01:35:22.825443: step 175450, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 9h:49m:10s remains)
INFO - root - 2017-12-17 01:35:25.056090: step 175460, loss = 0.43, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 9h:52m:53s remains)
INFO - root - 2017-12-17 01:35:27.307375: step 175470, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 9h:35m:18s remains)
INFO - root - 2017-12-17 01:35:29.531135: step 175480, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 9h:47m:53s remains)
INFO - root - 2017-12-17 01:35:31.750691: step 175490, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 9h:59m:55s remains)
INFO - root - 2017-12-17 01:35:33.976107: step 175500, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 9h:23m:10s remains)
INFO - root - 2017-12-17 01:35:36.302267: step 175510, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 9h:33m:57s remains)
INFO - root - 2017-12-17 01:35:38.532381: step 175520, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 9h:46m:31s remains)
INFO - root - 2017-12-17 01:35:40.741503: step 175530, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.221 sec/batch; 9h:36m:57s remains)
INFO - root - 2017-12-17 01:35:42.944315: step 175540, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 9h:54m:14s remains)
INFO - root - 2017-12-17 01:35:45.156153: step 175550, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 9h:30m:20s remains)
INFO - root - 2017-12-17 01:35:47.376415: step 175560, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 9h:30m:06s remains)
INFO - root - 2017-12-17 01:35:49.596988: step 175570, loss = 0.48, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 9h:46m:44s remains)
INFO - root - 2017-12-17 01:35:51.791449: step 175580, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 9h:27m:46s remains)
INFO - root - 2017-12-17 01:35:54.017187: step 175590, loss = 0.54, batch loss = 0.36 (35.0 examples/sec; 0.229 sec/batch; 9h:57m:35s remains)
INFO - root - 2017-12-17 01:35:56.262126: step 175600, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 9h:34m:05s remains)
INFO - root - 2017-12-17 01:35:58.564048: step 175610, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 9h:48m:08s remains)
INFO - root - 2017-12-17 01:36:00.747326: step 175620, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 9h:55m:59s remains)
INFO - root - 2017-12-17 01:36:02.969620: step 175630, loss = 0.51, batch loss = 0.33 (35.2 examples/sec; 0.227 sec/batch; 9h:53m:42s remains)
INFO - root - 2017-12-17 01:36:05.193846: step 175640, loss = 0.50, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 9h:58m:31s remains)
INFO - root - 2017-12-17 01:36:07.383147: step 175650, loss = 0.49, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 9h:36m:23s remains)
INFO - root - 2017-12-17 01:36:09.614017: step 175660, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 9h:48m:20s remains)
INFO - root - 2017-12-17 01:36:11.820304: step 175670, loss = 0.45, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 9h:19m:05s remains)
INFO - root - 2017-12-17 01:36:14.019555: step 175680, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 9h:32m:23s remains)
INFO - root - 2017-12-17 01:36:16.239991: step 175690, loss = 0.50, batch loss = 0.32 (34.2 examples/sec; 0.234 sec/batch; 10h:10m:37s remains)
INFO - root - 2017-12-17 01:36:18.443169: step 175700, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 9h:29m:05s remains)
INFO - root - 2017-12-17 01:36:20.769707: step 175710, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 10h:00m:38s remains)
INFO - root - 2017-12-17 01:36:23.032472: step 175720, loss = 0.50, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 9h:49m:07s remains)
INFO - root - 2017-12-17 01:36:25.215758: step 175730, loss = 0.44, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 9h:39m:43s remains)
INFO - root - 2017-12-17 01:36:27.474470: step 175740, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 9h:38m:52s remains)
INFO - root - 2017-12-17 01:36:29.697049: step 175750, loss = 0.43, batch loss = 0.25 (37.3 examples/sec; 0.215 sec/batch; 9h:20m:53s remains)
INFO - root - 2017-12-17 01:36:31.894622: step 175760, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 9h:36m:55s remains)
INFO - root - 2017-12-17 01:36:34.104567: step 175770, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 9h:48m:49s remains)
INFO - root - 2017-12-17 01:36:36.307074: step 175780, loss = 0.48, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 9h:31m:43s remains)
INFO - root - 2017-12-17 01:36:38.542976: step 175790, loss = 0.45, batch loss = 0.27 (33.9 examples/sec; 0.236 sec/batch; 10h:15m:42s remains)
INFO - root - 2017-12-17 01:36:40.754994: step 175800, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 9h:25m:33s remains)
INFO - root - 2017-12-17 01:36:43.077677: step 175810, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 9h:45m:23s remains)
INFO - root - 2017-12-17 01:36:45.319938: step 175820, loss = 0.45, batch loss = 0.27 (33.5 examples/sec; 0.239 sec/batch; 10h:23m:58s remains)
INFO - root - 2017-12-17 01:36:47.581666: step 175830, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 9h:32m:54s remains)
INFO - root - 2017-12-17 01:36:49.787562: step 175840, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 9h:39m:18s remains)
INFO - root - 2017-12-17 01:36:51.992516: step 175850, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 9h:46m:49s remains)
INFO - root - 2017-12-17 01:36:54.199783: step 175860, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 9h:27m:00s remains)
INFO - root - 2017-12-17 01:36:56.417611: step 175870, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 9h:35m:45s remains)
INFO - root - 2017-12-17 01:36:58.642962: step 175880, loss = 0.45, batch loss = 0.27 (34.3 examples/sec; 0.233 sec/batch; 10h:08m:21s remains)
INFO - root - 2017-12-17 01:37:00.872611: step 175890, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 9h:37m:06s remains)
INFO - root - 2017-12-17 01:37:03.048462: step 175900, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 9h:20m:37s remains)
INFO - root - 2017-12-17 01:37:05.394615: step 175910, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 9h:45m:26s remains)
INFO - root - 2017-12-17 01:37:07.641711: step 175920, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 9h:41m:17s remains)
INFO - root - 2017-12-17 01:37:09.854551: step 175930, loss = 0.49, batch loss = 0.31 (38.0 examples/sec; 0.210 sec/batch; 9h:09m:05s remains)
INFO - root - 2017-12-17 01:37:12.108036: step 175940, loss = 0.43, batch loss = 0.25 (34.8 examples/sec; 0.230 sec/batch; 10h:00m:10s remains)
INFO - root - 2017-12-17 01:37:14.337881: step 175950, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 9h:27m:55s remains)
INFO - root - 2017-12-17 01:37:16.545098: step 175960, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 9h:38m:45s remains)
INFO - root - 2017-12-17 01:37:18.777898: step 175970, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 9h:44m:03s remains)
INFO - root - 2017-12-17 01:37:21.017493: step 175980, loss = 0.53, batch loss = 0.35 (37.4 examples/sec; 0.214 sec/batch; 9h:17m:19s remains)
INFO - root - 2017-12-17 01:37:23.225154: step 175990, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 9h:41m:52s remains)
INFO - root - 2017-12-17 01:37:25.454331: step 176000, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 9h:46m:25s remains)
INFO - root - 2017-12-17 01:37:27.835200: step 176010, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 9h:46m:29s remains)
INFO - root - 2017-12-17 01:37:30.034064: step 176020, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 9h:24m:57s remains)
INFO - root - 2017-12-17 01:37:32.260424: step 176030, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 9h:44m:07s remains)
INFO - root - 2017-12-17 01:37:34.467761: step 176040, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 9h:30m:09s remains)
INFO - root - 2017-12-17 01:37:36.675186: step 176050, loss = 0.47, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 9h:39m:08s remains)
INFO - root - 2017-12-17 01:37:38.902183: step 176060, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 9h:40m:24s remains)
INFO - root - 2017-12-17 01:37:41.125534: step 176070, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.226 sec/batch; 9h:50m:30s remains)
INFO - root - 2017-12-17 01:37:43.350165: step 176080, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 9h:33m:54s remains)
INFO - root - 2017-12-17 01:37:45.576889: step 176090, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 9h:31m:22s remains)
INFO - root - 2017-12-17 01:37:47.776105: step 176100, loss = 0.46, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 9h:40m:19s remains)
INFO - root - 2017-12-17 01:37:50.111376: step 176110, loss = 0.45, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 9h:22m:12s remains)
INFO - root - 2017-12-17 01:37:52.313005: step 176120, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 9h:33m:23s remains)
INFO - root - 2017-12-17 01:37:54.533143: step 176130, loss = 0.50, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 9h:58m:00s remains)
INFO - root - 2017-12-17 01:37:56.701122: step 176140, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 9h:34m:48s remains)
INFO - root - 2017-12-17 01:37:58.892495: step 176150, loss = 0.52, batch loss = 0.34 (38.2 examples/sec; 0.209 sec/batch; 9h:05m:37s remains)
INFO - root - 2017-12-17 01:38:01.122034: step 176160, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 9h:28m:28s remains)
INFO - root - 2017-12-17 01:38:03.345437: step 176170, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 9h:29m:24s remains)
INFO - root - 2017-12-17 01:38:05.568743: step 176180, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 9h:23m:00s remains)
INFO - root - 2017-12-17 01:38:07.794300: step 176190, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.215 sec/batch; 9h:19m:00s remains)
INFO - root - 2017-12-17 01:38:10.017435: step 176200, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 9h:24m:20s remains)
INFO - root - 2017-12-17 01:38:12.370536: step 176210, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 9h:47m:50s remains)
INFO - root - 2017-12-17 01:38:14.598783: step 176220, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 9h:38m:48s remains)
INFO - root - 2017-12-17 01:38:16.836184: step 176230, loss = 0.46, batch loss = 0.28 (33.9 examples/sec; 0.236 sec/batch; 10h:15m:28s remains)
INFO - root - 2017-12-17 01:38:19.052799: step 176240, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 9h:26m:25s remains)
INFO - root - 2017-12-17 01:38:21.262140: step 176250, loss = 0.55, batch loss = 0.37 (36.6 examples/sec; 0.219 sec/batch; 9h:29m:27s remains)
INFO - root - 2017-12-17 01:38:23.474040: step 176260, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.218 sec/batch; 9h:26m:28s remains)
INFO - root - 2017-12-17 01:38:25.728534: step 176270, loss = 0.45, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 9h:42m:50s remains)
INFO - root - 2017-12-17 01:38:27.945165: step 176280, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 9h:16m:59s remains)
INFO - root - 2017-12-17 01:38:30.154764: step 176290, loss = 0.44, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 9h:22m:42s remains)
INFO - root - 2017-12-17 01:38:32.392850: step 176300, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 9h:37m:09s remains)
INFO - root - 2017-12-17 01:38:34.745651: step 176310, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 9h:30m:58s remains)
INFO - root - 2017-12-17 01:38:36.920770: step 176320, loss = 0.46, batch loss = 0.29 (37.6 examples/sec; 0.212 sec/batch; 9h:13m:06s remains)
INFO - root - 2017-12-17 01:38:39.162369: step 176330, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 9h:40m:05s remains)
INFO - root - 2017-12-17 01:38:41.354095: step 176340, loss = 0.48, batch loss = 0.30 (34.7 examples/sec; 0.231 sec/batch; 10h:00m:06s remains)
INFO - root - 2017-12-17 01:38:43.557068: step 176350, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 9h:51m:43s remains)
INFO - root - 2017-12-17 01:38:45.765511: step 176360, loss = 0.50, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 9h:49m:38s remains)
INFO - root - 2017-12-17 01:38:48.002983: step 176370, loss = 0.51, batch loss = 0.33 (33.9 examples/sec; 0.236 sec/batch; 10h:13m:14s remains)
INFO - root - 2017-12-17 01:38:50.273555: step 176380, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 9h:42m:14s remains)
INFO - root - 2017-12-17 01:38:52.450778: step 176390, loss = 0.50, batch loss = 0.32 (37.7 examples/sec; 0.212 sec/batch; 9h:12m:31s remains)
INFO - root - 2017-12-17 01:38:54.694962: step 176400, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 9h:25m:06s remains)
INFO - root - 2017-12-17 01:38:57.054301: step 176410, loss = 0.52, batch loss = 0.35 (35.9 examples/sec; 0.223 sec/batch; 9h:39m:26s remains)
INFO - root - 2017-12-17 01:38:59.292099: step 176420, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 9h:34m:43s remains)
INFO - root - 2017-12-17 01:39:01.500762: step 176430, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 9h:41m:13s remains)
INFO - root - 2017-12-17 01:39:03.712356: step 176440, loss = 0.53, batch loss = 0.35 (36.3 examples/sec; 0.221 sec/batch; 9h:33m:49s remains)
INFO - root - 2017-12-17 01:39:05.960530: step 176450, loss = 0.46, batch loss = 0.28 (34.5 examples/sec; 0.232 sec/batch; 10h:03m:14s remains)
INFO - root - 2017-12-17 01:39:08.252194: step 176460, loss = 0.54, batch loss = 0.36 (34.0 examples/sec; 0.235 sec/batch; 10h:11m:21s remains)
INFO - root - 2017-12-17 01:39:10.460005: step 176470, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 9h:27m:49s remains)
INFO - root - 2017-12-17 01:39:12.666721: step 176480, loss = 0.49, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 9h:27m:00s remains)
INFO - root - 2017-12-17 01:39:14.919376: step 176490, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.226 sec/batch; 9h:46m:28s remains)
INFO - root - 2017-12-17 01:39:17.146749: step 176500, loss = 0.56, batch loss = 0.38 (37.3 examples/sec; 0.214 sec/batch; 9h:17m:30s remains)
INFO - root - 2017-12-17 01:39:19.459390: step 176510, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 9h:30m:09s remains)
INFO - root - 2017-12-17 01:39:21.679656: step 176520, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 9h:27m:23s remains)
INFO - root - 2017-12-17 01:39:23.935165: step 176530, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 9h:26m:19s remains)
INFO - root - 2017-12-17 01:39:26.186624: step 176540, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.231 sec/batch; 10h:00m:28s remains)
INFO - root - 2017-12-17 01:39:28.370774: step 176550, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 9h:38m:18s remains)
INFO - root - 2017-12-17 01:39:30.581172: step 176560, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 9h:29m:30s remains)
INFO - root - 2017-12-17 01:39:32.805629: step 176570, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 9h:39m:17s remains)
INFO - root - 2017-12-17 01:39:35.016509: step 176580, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 9h:36m:26s remains)
INFO - root - 2017-12-17 01:39:37.233146: step 176590, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 9h:56m:12s remains)
INFO - root - 2017-12-17 01:39:39.420957: step 176600, loss = 0.55, batch loss = 0.38 (36.9 examples/sec; 0.217 sec/batch; 9h:23m:31s remains)
INFO - root - 2017-12-17 01:39:41.775999: step 176610, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 9h:28m:50s remains)
INFO - root - 2017-12-17 01:39:43.999070: step 176620, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 9h:27m:46s remains)
INFO - root - 2017-12-17 01:39:46.220570: step 176630, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 9h:34m:10s remains)
INFO - root - 2017-12-17 01:39:48.441116: step 176640, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 9h:42m:01s remains)
INFO - root - 2017-12-17 01:39:50.676803: step 176650, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 9h:43m:37s remains)
INFO - root - 2017-12-17 01:39:52.905043: step 176660, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 9h:36m:10s remains)
INFO - root - 2017-12-17 01:39:55.128737: step 176670, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 9h:55m:37s remains)
INFO - root - 2017-12-17 01:39:57.338535: step 176680, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 9h:26m:12s remains)
INFO - root - 2017-12-17 01:39:59.552526: step 176690, loss = 0.43, batch loss = 0.25 (37.5 examples/sec; 0.214 sec/batch; 9h:14m:37s remains)
INFO - root - 2017-12-17 01:40:01.775451: step 176700, loss = 0.50, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 9h:56m:33s remains)
INFO - root - 2017-12-17 01:40:04.126188: step 176710, loss = 0.44, batch loss = 0.26 (37.6 examples/sec; 0.213 sec/batch; 9h:12m:15s remains)
INFO - root - 2017-12-17 01:40:06.327933: step 176720, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 9h:26m:25s remains)
INFO - root - 2017-12-17 01:40:08.542826: step 176730, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.224 sec/batch; 9h:42m:46s remains)
INFO - root - 2017-12-17 01:40:10.755028: step 176740, loss = 0.45, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 9h:34m:18s remains)
INFO - root - 2017-12-17 01:40:12.982920: step 176750, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 9h:53m:59s remains)
INFO - root - 2017-12-17 01:40:15.193822: step 176760, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 9h:28m:43s remains)
INFO - root - 2017-12-17 01:40:17.391736: step 176770, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 9h:29m:22s remains)
INFO - root - 2017-12-17 01:40:19.588709: step 176780, loss = 0.43, batch loss = 0.26 (35.2 examples/sec; 0.228 sec/batch; 9h:50m:31s remains)
INFO - root - 2017-12-17 01:40:21.826470: step 176790, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.221 sec/batch; 9h:32m:39s remains)
INFO - root - 2017-12-17 01:40:24.071957: step 176800, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 9h:25m:45s remains)
INFO - root - 2017-12-17 01:40:26.467141: step 176810, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 9h:22m:43s remains)
INFO - root - 2017-12-17 01:40:28.684120: step 176820, loss = 0.58, batch loss = 0.40 (36.5 examples/sec; 0.219 sec/batch; 9h:28m:17s remains)
INFO - root - 2017-12-17 01:40:30.910373: step 176830, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 9h:25m:14s remains)
INFO - root - 2017-12-17 01:40:33.152518: step 176840, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 9h:36m:23s remains)
INFO - root - 2017-12-17 01:40:35.357945: step 176850, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 9h:33m:48s remains)
INFO - root - 2017-12-17 01:40:37.557218: step 176860, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 9h:31m:56s remains)
INFO - root - 2017-12-17 01:40:39.793036: step 176870, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 9h:35m:18s remains)
INFO - root - 2017-12-17 01:40:42.016510: step 176880, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 9h:16m:04s remains)
INFO - root - 2017-12-17 01:40:44.243399: step 176890, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 9h:24m:33s remains)
INFO - root - 2017-12-17 01:40:46.478225: step 176900, loss = 0.52, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 9h:36m:45s remains)
INFO - root - 2017-12-17 01:40:48.848929: step 176910, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 9h:43m:48s remains)
INFO - root - 2017-12-17 01:40:51.060080: step 176920, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.215 sec/batch; 9h:18m:35s remains)
INFO - root - 2017-12-17 01:40:53.270429: step 176930, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 9h:28m:10s remains)
INFO - root - 2017-12-17 01:40:55.497241: step 176940, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 9h:39m:07s remains)
INFO - root - 2017-12-17 01:40:57.757049: step 176950, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 9h:45m:00s remains)
INFO - root - 2017-12-17 01:41:00.014528: step 176960, loss = 0.50, batch loss = 0.32 (34.7 examples/sec; 0.230 sec/batch; 9h:57m:03s remains)
INFO - root - 2017-12-17 01:41:02.209860: step 176970, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.223 sec/batch; 9h:36m:47s remains)
INFO - root - 2017-12-17 01:41:04.438992: step 176980, loss = 0.63, batch loss = 0.45 (35.5 examples/sec; 0.225 sec/batch; 9h:44m:20s remains)
INFO - root - 2017-12-17 01:41:06.636799: step 176990, loss = 0.41, batch loss = 0.24 (35.3 examples/sec; 0.227 sec/batch; 9h:48m:05s remains)
INFO - root - 2017-12-17 01:41:08.904412: step 177000, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 9h:43m:22s remains)
INFO - root - 2017-12-17 01:41:11.250532: step 177010, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 9h:35m:42s remains)
INFO - root - 2017-12-17 01:41:13.463625: step 177020, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 9h:25m:05s remains)
INFO - root - 2017-12-17 01:41:15.680297: step 177030, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 9h:50m:32s remains)
INFO - root - 2017-12-17 01:41:17.885097: step 177040, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 9h:30m:50s remains)
INFO - root - 2017-12-17 01:41:20.098491: step 177050, loss = 0.52, batch loss = 0.35 (35.2 examples/sec; 0.227 sec/batch; 9h:48m:38s remains)
INFO - root - 2017-12-17 01:41:22.305009: step 177060, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 9h:30m:50s remains)
INFO - root - 2017-12-17 01:41:24.533106: step 177070, loss = 0.45, batch loss = 0.27 (34.8 examples/sec; 0.230 sec/batch; 9h:55m:30s remains)
INFO - root - 2017-12-17 01:41:26.738732: step 177080, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 9h:44m:03s remains)
INFO - root - 2017-12-17 01:41:28.952159: step 177090, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 9h:30m:27s remains)
INFO - root - 2017-12-17 01:41:31.167126: step 177100, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 9h:38m:50s remains)
INFO - root - 2017-12-17 01:41:33.477299: step 177110, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 9h:13m:34s remains)
INFO - root - 2017-12-17 01:41:35.716885: step 177120, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 9h:43m:02s remains)
INFO - root - 2017-12-17 01:41:37.903243: step 177130, loss = 0.44, batch loss = 0.26 (38.3 examples/sec; 0.209 sec/batch; 9h:00m:34s remains)
INFO - root - 2017-12-17 01:41:40.104078: step 177140, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 9h:34m:50s remains)
INFO - root - 2017-12-17 01:41:42.294537: step 177150, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 9h:31m:16s remains)
INFO - root - 2017-12-17 01:41:44.513720: step 177160, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 9h:33m:22s remains)
INFO - root - 2017-12-17 01:41:46.742776: step 177170, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 9h:34m:49s remains)
INFO - root - 2017-12-17 01:41:48.935965: step 177180, loss = 0.55, batch loss = 0.37 (37.6 examples/sec; 0.213 sec/batch; 9h:10m:24s remains)
INFO - root - 2017-12-17 01:41:51.142519: step 177190, loss = 0.49, batch loss = 0.31 (33.0 examples/sec; 0.243 sec/batch; 10h:28m:13s remains)
INFO - root - 2017-12-17 01:41:53.386403: step 177200, loss = 0.49, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 9h:33m:44s remains)
INFO - root - 2017-12-17 01:41:55.744959: step 177210, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 9h:39m:15s remains)
INFO - root - 2017-12-17 01:41:58.007459: step 177220, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 9h:47m:49s remains)
INFO - root - 2017-12-17 01:42:00.251289: step 177230, loss = 0.50, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 9h:12m:58s remains)
INFO - root - 2017-12-17 01:42:02.501849: step 177240, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 9h:32m:36s remains)
INFO - root - 2017-12-17 01:42:04.722177: step 177250, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 9h:41m:40s remains)
INFO - root - 2017-12-17 01:42:06.941957: step 177260, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 9h:18m:24s remains)
INFO - root - 2017-12-17 01:42:09.150821: step 177270, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 9h:41m:53s remains)
INFO - root - 2017-12-17 01:42:11.361904: step 177280, loss = 0.57, batch loss = 0.39 (36.8 examples/sec; 0.217 sec/batch; 9h:21m:38s remains)
INFO - root - 2017-12-17 01:42:13.590950: step 177290, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 9h:46m:24s remains)
INFO - root - 2017-12-17 01:42:15.794682: step 177300, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.214 sec/batch; 9h:12m:17s remains)
INFO - root - 2017-12-17 01:42:18.120463: step 177310, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 9h:16m:34s remains)
INFO - root - 2017-12-17 01:42:20.375108: step 177320, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 9h:26m:24s remains)
INFO - root - 2017-12-17 01:42:22.590742: step 177330, loss = 0.50, batch loss = 0.32 (35.1 examples/sec; 0.228 sec/batch; 9h:49m:56s remains)
INFO - root - 2017-12-17 01:42:24.829307: step 177340, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 9h:28m:57s remains)
INFO - root - 2017-12-17 01:42:27.035635: step 177350, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 9h:25m:16s remains)
INFO - root - 2017-12-17 01:42:29.279536: step 177360, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 9h:52m:51s remains)
INFO - root - 2017-12-17 01:42:31.511744: step 177370, loss = 0.49, batch loss = 0.31 (37.9 examples/sec; 0.211 sec/batch; 9h:06m:24s remains)
INFO - root - 2017-12-17 01:42:33.714927: step 177380, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 9h:43m:51s remains)
INFO - root - 2017-12-17 01:42:35.936652: step 177390, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 9h:27m:02s remains)
INFO - root - 2017-12-17 01:42:38.132094: step 177400, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 9h:35m:27s remains)
INFO - root - 2017-12-17 01:42:40.475698: step 177410, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 9h:16m:26s remains)
INFO - root - 2017-12-17 01:42:42.683253: step 177420, loss = 0.52, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 9h:26m:18s remains)
INFO - root - 2017-12-17 01:42:44.914621: step 177430, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 9h:33m:17s remains)
INFO - root - 2017-12-17 01:42:47.124094: step 177440, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 9h:27m:58s remains)
INFO - root - 2017-12-17 01:42:49.326204: step 177450, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 9h:21m:01s remains)
INFO - root - 2017-12-17 01:42:51.535389: step 177460, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 9h:15m:38s remains)
INFO - root - 2017-12-17 01:42:53.754233: step 177470, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 9h:19m:04s remains)
INFO - root - 2017-12-17 01:42:55.958893: step 177480, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 9h:42m:37s remains)
INFO - root - 2017-12-17 01:42:58.181906: step 177490, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 9h:15m:15s remains)
INFO - root - 2017-12-17 01:43:00.407727: step 177500, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 9h:14m:06s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-177500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-177500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 01:43:03.422978: step 177510, loss = 0.46, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 9h:28m:49s remains)
INFO - root - 2017-12-17 01:43:05.654585: step 177520, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.218 sec/batch; 9h:22m:07s remains)
INFO - root - 2017-12-17 01:43:07.868727: step 177530, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 9h:17m:33s remains)
INFO - root - 2017-12-17 01:43:10.065783: step 177540, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 9h:18m:45s remains)
INFO - root - 2017-12-17 01:43:12.320385: step 177550, loss = 0.53, batch loss = 0.35 (34.2 examples/sec; 0.234 sec/batch; 10h:03m:39s remains)
INFO - root - 2017-12-17 01:43:14.548470: step 177560, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 9h:56m:00s remains)
INFO - root - 2017-12-17 01:43:16.745057: step 177570, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 9h:32m:08s remains)
INFO - root - 2017-12-17 01:43:18.945722: step 177580, loss = 0.49, batch loss = 0.31 (38.2 examples/sec; 0.209 sec/batch; 9h:00m:23s remains)
INFO - root - 2017-12-17 01:43:21.138213: step 177590, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 9h:16m:48s remains)
INFO - root - 2017-12-17 01:43:23.395402: step 177600, loss = 0.43, batch loss = 0.25 (39.4 examples/sec; 0.203 sec/batch; 8h:44m:16s remains)
INFO - root - 2017-12-17 01:43:25.735091: step 177610, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 9h:22m:38s remains)
INFO - root - 2017-12-17 01:43:27.950265: step 177620, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.219 sec/batch; 9h:26m:32s remains)
INFO - root - 2017-12-17 01:43:30.183220: step 177630, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 9h:38m:52s remains)
INFO - root - 2017-12-17 01:43:32.346628: step 177640, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 9h:24m:44s remains)
INFO - root - 2017-12-17 01:43:34.551912: step 177650, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 9h:21m:09s remains)
INFO - root - 2017-12-17 01:43:36.771187: step 177660, loss = 0.46, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 9h:15m:46s remains)
INFO - root - 2017-12-17 01:43:39.005198: step 177670, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 9h:43m:45s remains)
INFO - root - 2017-12-17 01:43:41.235941: step 177680, loss = 0.49, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 9h:32m:37s remains)
INFO - root - 2017-12-17 01:43:43.455790: step 177690, loss = 0.41, batch loss = 0.23 (36.4 examples/sec; 0.220 sec/batch; 9h:27m:33s remains)
INFO - root - 2017-12-17 01:43:45.669444: step 177700, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 9h:31m:23s remains)
INFO - root - 2017-12-17 01:43:48.003187: step 177710, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 9h:26m:53s remains)
INFO - root - 2017-12-17 01:43:50.199078: step 177720, loss = 0.49, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 9h:34m:16s remains)
INFO - root - 2017-12-17 01:43:52.387515: step 177730, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 9h:19m:18s remains)
INFO - root - 2017-12-17 01:43:54.611802: step 177740, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 9h:21m:49s remains)
INFO - root - 2017-12-17 01:43:56.801302: step 177750, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 9h:14m:27s remains)
INFO - root - 2017-12-17 01:43:59.027750: step 177760, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 9h:21m:33s remains)
INFO - root - 2017-12-17 01:44:01.190864: step 177770, loss = 0.45, batch loss = 0.27 (37.6 examples/sec; 0.213 sec/batch; 9h:08m:44s remains)
INFO - root - 2017-12-17 01:44:03.369164: step 177780, loss = 0.52, batch loss = 0.34 (37.2 examples/sec; 0.215 sec/batch; 9h:14m:13s remains)
INFO - root - 2017-12-17 01:44:05.537643: step 177790, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 9h:16m:45s remains)
INFO - root - 2017-12-17 01:44:07.742919: step 177800, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 9h:26m:07s remains)
INFO - root - 2017-12-17 01:44:10.102895: step 177810, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 9h:53m:08s remains)
INFO - root - 2017-12-17 01:44:12.298402: step 177820, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 9h:31m:03s remains)
INFO - root - 2017-12-17 01:44:14.541986: step 177830, loss = 0.54, batch loss = 0.36 (37.0 examples/sec; 0.216 sec/batch; 9h:18m:06s remains)
INFO - root - 2017-12-17 01:44:16.761102: step 177840, loss = 0.47, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 9h:46m:24s remains)
INFO - root - 2017-12-17 01:44:18.961974: step 177850, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 9h:17m:59s remains)
INFO - root - 2017-12-17 01:44:21.156920: step 177860, loss = 0.45, batch loss = 0.27 (37.6 examples/sec; 0.213 sec/batch; 9h:08m:05s remains)
INFO - root - 2017-12-17 01:44:23.348183: step 177870, loss = 0.47, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 9h:41m:18s remains)
INFO - root - 2017-12-17 01:44:25.561872: step 177880, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 9h:13m:40s remains)
INFO - root - 2017-12-17 01:44:27.786686: step 177890, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 9h:18m:20s remains)
INFO - root - 2017-12-17 01:44:29.986185: step 177900, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 9h:24m:54s remains)
INFO - root - 2017-12-17 01:44:32.298819: step 177910, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 9h:31m:13s remains)
INFO - root - 2017-12-17 01:44:34.477419: step 177920, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 9h:24m:41s remains)
INFO - root - 2017-12-17 01:44:36.667093: step 177930, loss = 0.54, batch loss = 0.36 (37.7 examples/sec; 0.212 sec/batch; 9h:07m:16s remains)
INFO - root - 2017-12-17 01:44:38.868259: step 177940, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 9h:24m:48s remains)
INFO - root - 2017-12-17 01:44:41.047510: step 177950, loss = 0.53, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 9h:37m:00s remains)
INFO - root - 2017-12-17 01:44:43.272912: step 177960, loss = 0.47, batch loss = 0.29 (32.0 examples/sec; 0.250 sec/batch; 10h:43m:11s remains)
INFO - root - 2017-12-17 01:44:45.442814: step 177970, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.216 sec/batch; 9h:15m:01s remains)
INFO - root - 2017-12-17 01:44:47.651242: step 177980, loss = 0.54, batch loss = 0.36 (35.1 examples/sec; 0.228 sec/batch; 9h:47m:04s remains)
INFO - root - 2017-12-17 01:44:49.816694: step 177990, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 9h:12m:37s remains)
INFO - root - 2017-12-17 01:44:52.024317: step 178000, loss = 0.50, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 9h:26m:54s remains)
INFO - root - 2017-12-17 01:44:54.394696: step 178010, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 9h:39m:00s remains)
INFO - root - 2017-12-17 01:44:56.595809: step 178020, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.216 sec/batch; 9h:15m:06s remains)
INFO - root - 2017-12-17 01:44:58.824768: step 178030, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 9h:22m:20s remains)
INFO - root - 2017-12-17 01:45:01.014454: step 178040, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 9h:31m:05s remains)
INFO - root - 2017-12-17 01:45:03.216481: step 178050, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.218 sec/batch; 9h:20m:16s remains)
INFO - root - 2017-12-17 01:45:05.425525: step 178060, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 9h:41m:08s remains)
INFO - root - 2017-12-17 01:45:07.639859: step 178070, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 9h:27m:28s remains)
INFO - root - 2017-12-17 01:45:09.842586: step 178080, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 9h:39m:18s remains)
INFO - root - 2017-12-17 01:45:12.064420: step 178090, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 9h:18m:20s remains)
INFO - root - 2017-12-17 01:45:14.276346: step 178100, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 9h:20m:31s remains)
INFO - root - 2017-12-17 01:45:16.572579: step 178110, loss = 0.42, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 9h:17m:26s remains)
INFO - root - 2017-12-17 01:45:18.797018: step 178120, loss = 0.47, batch loss = 0.29 (38.2 examples/sec; 0.210 sec/batch; 8h:59m:18s remains)
INFO - root - 2017-12-17 01:45:21.037381: step 178130, loss = 0.55, batch loss = 0.37 (36.7 examples/sec; 0.218 sec/batch; 9h:21m:25s remains)
INFO - root - 2017-12-17 01:45:23.256508: step 178140, loss = 0.46, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 9h:26m:00s remains)
INFO - root - 2017-12-17 01:45:25.454800: step 178150, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 9h:35m:55s remains)
INFO - root - 2017-12-17 01:45:27.623404: step 178160, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 9h:31m:22s remains)
INFO - root - 2017-12-17 01:45:29.853740: step 178170, loss = 0.57, batch loss = 0.39 (36.8 examples/sec; 0.217 sec/batch; 9h:18m:33s remains)
INFO - root - 2017-12-17 01:45:32.075209: step 178180, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 9h:33m:55s remains)
INFO - root - 2017-12-17 01:45:34.291178: step 178190, loss = 0.51, batch loss = 0.33 (37.6 examples/sec; 0.213 sec/batch; 9h:06m:54s remains)
INFO - root - 2017-12-17 01:45:36.486739: step 178200, loss = 0.50, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 9h:15m:49s remains)
INFO - root - 2017-12-17 01:45:38.824771: step 178210, loss = 0.57, batch loss = 0.39 (36.5 examples/sec; 0.219 sec/batch; 9h:23m:40s remains)
INFO - root - 2017-12-17 01:45:41.041680: step 178220, loss = 0.43, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 9h:29m:44s remains)
INFO - root - 2017-12-17 01:45:43.259380: step 178230, loss = 0.44, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 9h:18m:37s remains)
INFO - root - 2017-12-17 01:45:45.477087: step 178240, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 9h:21m:25s remains)
INFO - root - 2017-12-17 01:45:47.658037: step 178250, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 9h:21m:26s remains)
INFO - root - 2017-12-17 01:45:49.839537: step 178260, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 9h:03m:58s remains)
INFO - root - 2017-12-17 01:45:52.082368: step 178270, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 9h:32m:54s remains)
INFO - root - 2017-12-17 01:45:54.314813: step 178280, loss = 0.51, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 9h:35m:32s remains)
INFO - root - 2017-12-17 01:45:56.516664: step 178290, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 9h:20m:39s remains)
INFO - root - 2017-12-17 01:45:58.702771: step 178300, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 9h:17m:47s remains)
INFO - root - 2017-12-17 01:46:00.983954: step 178310, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 9h:22m:33s remains)
INFO - root - 2017-12-17 01:46:03.159177: step 178320, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 9h:11m:21s remains)
INFO - root - 2017-12-17 01:46:05.345935: step 178330, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 9h:27m:32s remains)
INFO - root - 2017-12-17 01:46:07.583855: step 178340, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 9h:45m:19s remains)
INFO - root - 2017-12-17 01:46:09.777172: step 178350, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 9h:20m:40s remains)
INFO - root - 2017-12-17 01:46:11.953675: step 178360, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 9h:34m:20s remains)
INFO - root - 2017-12-17 01:46:14.182178: step 178370, loss = 0.43, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 9h:42m:50s remains)
INFO - root - 2017-12-17 01:46:16.379489: step 178380, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 9h:22m:08s remains)
INFO - root - 2017-12-17 01:46:18.579757: step 178390, loss = 0.52, batch loss = 0.34 (32.9 examples/sec; 0.243 sec/batch; 10h:24m:08s remains)
INFO - root - 2017-12-17 01:46:20.799156: step 178400, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 9h:10m:29s remains)
INFO - root - 2017-12-17 01:46:23.114187: step 178410, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 9h:25m:29s remains)
INFO - root - 2017-12-17 01:46:25.300032: step 178420, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 9h:03m:25s remains)
INFO - root - 2017-12-17 01:46:27.513334: step 178430, loss = 0.55, batch loss = 0.37 (36.7 examples/sec; 0.218 sec/batch; 9h:19m:19s remains)
INFO - root - 2017-12-17 01:46:29.689615: step 178440, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 9h:36m:54s remains)
INFO - root - 2017-12-17 01:46:31.952271: step 178450, loss = 0.52, batch loss = 0.34 (37.5 examples/sec; 0.213 sec/batch; 9h:07m:55s remains)
INFO - root - 2017-12-17 01:46:34.139739: step 178460, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 9h:22m:40s remains)
INFO - root - 2017-12-17 01:46:36.349682: step 178470, loss = 0.49, batch loss = 0.31 (34.7 examples/sec; 0.231 sec/batch; 9h:52m:02s remains)
INFO - root - 2017-12-17 01:46:38.592905: step 178480, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 9h:30m:59s remains)
INFO - root - 2017-12-17 01:46:40.822707: step 178490, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 9h:47m:53s remains)
INFO - root - 2017-12-17 01:46:43.040680: step 178500, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 9h:15m:18s remains)
INFO - root - 2017-12-17 01:46:45.345463: step 178510, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 9h:14m:26s remains)
INFO - root - 2017-12-17 01:46:47.506474: step 178520, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 9h:17m:14s remains)
INFO - root - 2017-12-17 01:46:49.696974: step 178530, loss = 0.50, batch loss = 0.32 (37.1 examples/sec; 0.215 sec/batch; 9h:12m:46s remains)
INFO - root - 2017-12-17 01:46:51.933230: step 178540, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 9h:13m:31s remains)
INFO - root - 2017-12-17 01:46:54.127773: step 178550, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 9h:25m:58s remains)
INFO - root - 2017-12-17 01:46:56.352076: step 178560, loss = 0.50, batch loss = 0.32 (34.6 examples/sec; 0.231 sec/batch; 9h:52m:35s remains)
INFO - root - 2017-12-17 01:46:58.551960: step 178570, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 9h:38m:42s remains)
INFO - root - 2017-12-17 01:47:00.781235: step 178580, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 9h:25m:00s remains)
INFO - root - 2017-12-17 01:47:02.988028: step 178590, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 9h:16m:24s remains)
INFO - root - 2017-12-17 01:47:05.206524: step 178600, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 9h:39m:44s remains)
INFO - root - 2017-12-17 01:47:07.545586: step 178610, loss = 0.43, batch loss = 0.25 (37.9 examples/sec; 0.211 sec/batch; 9h:01m:58s remains)
INFO - root - 2017-12-17 01:47:09.776832: step 178620, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 9h:26m:31s remains)
INFO - root - 2017-12-17 01:47:11.947082: step 178630, loss = 0.54, batch loss = 0.36 (37.4 examples/sec; 0.214 sec/batch; 9h:08m:06s remains)
INFO - root - 2017-12-17 01:47:14.173057: step 178640, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 9h:32m:47s remains)
INFO - root - 2017-12-17 01:47:16.361697: step 178650, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 9h:05m:23s remains)
INFO - root - 2017-12-17 01:47:18.552693: step 178660, loss = 0.45, batch loss = 0.27 (37.7 examples/sec; 0.212 sec/batch; 9h:04m:31s remains)
INFO - root - 2017-12-17 01:47:20.795950: step 178670, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 9h:19m:02s remains)
INFO - root - 2017-12-17 01:47:22.996329: step 178680, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.226 sec/batch; 9h:40m:24s remains)
INFO - root - 2017-12-17 01:47:25.294642: step 178690, loss = 0.48, batch loss = 0.30 (33.1 examples/sec; 0.242 sec/batch; 10h:19m:18s remains)
INFO - root - 2017-12-17 01:47:27.506697: step 178700, loss = 0.45, batch loss = 0.27 (37.6 examples/sec; 0.213 sec/batch; 9h:05m:06s remains)
INFO - root - 2017-12-17 01:47:29.838628: step 178710, loss = 0.47, batch loss = 0.30 (34.0 examples/sec; 0.236 sec/batch; 10h:03m:45s remains)
INFO - root - 2017-12-17 01:47:32.031317: step 178720, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 9h:18m:20s remains)
INFO - root - 2017-12-17 01:47:34.248205: step 178730, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 9h:15m:36s remains)
INFO - root - 2017-12-17 01:47:36.426225: step 178740, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 9h:19m:39s remains)
INFO - root - 2017-12-17 01:47:38.658906: step 178750, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 9h:30m:05s remains)
INFO - root - 2017-12-17 01:47:40.836846: step 178760, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 9h:20m:18s remains)
INFO - root - 2017-12-17 01:47:43.052885: step 178770, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 9h:29m:30s remains)
INFO - root - 2017-12-17 01:47:45.222165: step 178780, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 9h:17m:45s remains)
INFO - root - 2017-12-17 01:47:47.422890: step 178790, loss = 0.49, batch loss = 0.32 (37.5 examples/sec; 0.213 sec/batch; 9h:05m:55s remains)
INFO - root - 2017-12-17 01:47:49.606913: step 178800, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.214 sec/batch; 9h:09m:02s remains)
INFO - root - 2017-12-17 01:47:51.920161: step 178810, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 9h:27m:20s remains)
INFO - root - 2017-12-17 01:47:54.131943: step 178820, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 9h:24m:57s remains)
INFO - root - 2017-12-17 01:47:56.332056: step 178830, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 9h:04m:35s remains)
INFO - root - 2017-12-17 01:47:58.516699: step 178840, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 9h:37m:29s remains)
INFO - root - 2017-12-17 01:48:00.720066: step 178850, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 9h:14m:43s remains)
INFO - root - 2017-12-17 01:48:02.898391: step 178860, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 9h:21m:49s remains)
INFO - root - 2017-12-17 01:48:05.114432: step 178870, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.218 sec/batch; 9h:18m:57s remains)
INFO - root - 2017-12-17 01:48:07.325246: step 178880, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 9h:22m:58s remains)
INFO - root - 2017-12-17 01:48:09.534785: step 178890, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 9h:48m:19s remains)
INFO - root - 2017-12-17 01:48:11.750813: step 178900, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 9h:26m:21s remains)
INFO - root - 2017-12-17 01:48:14.088284: step 178910, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 9h:09m:22s remains)
INFO - root - 2017-12-17 01:48:16.294733: step 178920, loss = 0.49, batch loss = 0.31 (34.4 examples/sec; 0.233 sec/batch; 9h:55m:09s remains)
INFO - root - 2017-12-17 01:48:18.510140: step 178930, loss = 0.54, batch loss = 0.37 (35.4 examples/sec; 0.226 sec/batch; 9h:38m:32s remains)
INFO - root - 2017-12-17 01:48:20.733459: step 178940, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 9h:12m:27s remains)
INFO - root - 2017-12-17 01:48:22.928984: step 178950, loss = 0.53, batch loss = 0.35 (34.2 examples/sec; 0.234 sec/batch; 9h:58m:44s remains)
INFO - root - 2017-12-17 01:48:25.132455: step 178960, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 9h:09m:23s remains)
INFO - root - 2017-12-17 01:48:27.317804: step 178970, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 9h:15m:47s remains)
INFO - root - 2017-12-17 01:48:29.488201: step 178980, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 9h:18m:50s remains)
INFO - root - 2017-12-17 01:48:31.701669: step 178990, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 9h:16m:17s remains)
INFO - root - 2017-12-17 01:48:33.884134: step 179000, loss = 0.45, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 9h:36m:33s remains)
INFO - root - 2017-12-17 01:48:36.198413: step 179010, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 9h:29m:04s remains)
INFO - root - 2017-12-17 01:48:38.398461: step 179020, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 9h:19m:09s remains)
INFO - root - 2017-12-17 01:48:40.616440: step 179030, loss = 0.56, batch loss = 0.38 (36.3 examples/sec; 0.221 sec/batch; 9h:24m:12s remains)
INFO - root - 2017-12-17 01:48:42.849938: step 179040, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 9h:28m:21s remains)
INFO - root - 2017-12-17 01:48:45.081497: step 179050, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 9h:32m:24s remains)
INFO - root - 2017-12-17 01:48:47.282531: step 179060, loss = 0.56, batch loss = 0.39 (35.3 examples/sec; 0.227 sec/batch; 9h:40m:00s remains)
INFO - root - 2017-12-17 01:48:49.463066: step 179070, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 9h:24m:57s remains)
INFO - root - 2017-12-17 01:48:51.667222: step 179080, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 9h:20m:34s remains)
INFO - root - 2017-12-17 01:48:53.910241: step 179090, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 9h:25m:10s remains)
INFO - root - 2017-12-17 01:48:56.093131: step 179100, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 9h:27m:03s remains)
INFO - root - 2017-12-17 01:48:58.459171: step 179110, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 9h:23m:18s remains)
INFO - root - 2017-12-17 01:49:00.677828: step 179120, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 9h:20m:25s remains)
INFO - root - 2017-12-17 01:49:02.883764: step 179130, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 9h:28m:05s remains)
INFO - root - 2017-12-17 01:49:05.083258: step 179140, loss = 0.44, batch loss = 0.26 (34.7 examples/sec; 0.231 sec/batch; 9h:49m:55s remains)
INFO - root - 2017-12-17 01:49:07.271824: step 179150, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 9h:20m:54s remains)
INFO - root - 2017-12-17 01:49:09.477420: step 179160, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 9h:13m:52s remains)
INFO - root - 2017-12-17 01:49:11.674340: step 179170, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 9h:37m:31s remains)
INFO - root - 2017-12-17 01:49:13.864153: step 179180, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 9h:16m:34s remains)
INFO - root - 2017-12-17 01:49:16.051506: step 179190, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 9h:19m:14s remains)
INFO - root - 2017-12-17 01:49:18.293766: step 179200, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 9h:20m:49s remains)
INFO - root - 2017-12-17 01:49:20.657429: step 179210, loss = 0.42, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 9h:24m:56s remains)
INFO - root - 2017-12-17 01:49:22.926303: step 179220, loss = 0.48, batch loss = 0.30 (33.0 examples/sec; 0.242 sec/batch; 10h:18m:28s remains)
INFO - root - 2017-12-17 01:49:25.167229: step 179230, loss = 0.54, batch loss = 0.36 (36.8 examples/sec; 0.217 sec/batch; 9h:14m:39s remains)
INFO - root - 2017-12-17 01:49:27.361650: step 179240, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 9h:18m:07s remains)
INFO - root - 2017-12-17 01:49:29.659776: step 179250, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 9h:36m:10s remains)
INFO - root - 2017-12-17 01:49:31.943296: step 179260, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 9h:33m:01s remains)
INFO - root - 2017-12-17 01:49:34.170284: step 179270, loss = 0.54, batch loss = 0.36 (36.5 examples/sec; 0.219 sec/batch; 9h:19m:26s remains)
INFO - root - 2017-12-17 01:49:36.368973: step 179280, loss = 0.54, batch loss = 0.36 (37.5 examples/sec; 0.214 sec/batch; 9h:05m:29s remains)
INFO - root - 2017-12-17 01:49:38.595439: step 179290, loss = 0.44, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 9h:13m:36s remains)
INFO - root - 2017-12-17 01:49:40.825399: step 179300, loss = 0.54, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 9h:28m:16s remains)
INFO - root - 2017-12-17 01:49:43.225050: step 179310, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.218 sec/batch; 9h:17m:24s remains)
INFO - root - 2017-12-17 01:49:45.407281: step 179320, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 9h:06m:16s remains)
INFO - root - 2017-12-17 01:49:47.583870: step 179330, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 9h:26m:41s remains)
INFO - root - 2017-12-17 01:49:49.820628: step 179340, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.214 sec/batch; 9h:06m:51s remains)
INFO - root - 2017-12-17 01:49:52.035742: step 179350, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 9h:23m:40s remains)
INFO - root - 2017-12-17 01:49:54.276563: step 179360, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.215 sec/batch; 9h:07m:59s remains)
INFO - root - 2017-12-17 01:49:56.494476: step 179370, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 9h:15m:53s remains)
INFO - root - 2017-12-17 01:49:58.743957: step 179380, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 9h:23m:46s remains)
INFO - root - 2017-12-17 01:50:00.975767: step 179390, loss = 0.45, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 9h:14m:52s remains)
INFO - root - 2017-12-17 01:50:03.200677: step 179400, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 9h:41m:12s remains)
INFO - root - 2017-12-17 01:50:05.555873: step 179410, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 9h:03m:43s remains)
INFO - root - 2017-12-17 01:50:07.782647: step 179420, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 9h:25m:57s remains)
INFO - root - 2017-12-17 01:50:10.006499: step 179430, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 9h:28m:40s remains)
INFO - root - 2017-12-17 01:50:12.210812: step 179440, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 9h:45m:37s remains)
INFO - root - 2017-12-17 01:50:14.429710: step 179450, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 9h:31m:34s remains)
INFO - root - 2017-12-17 01:50:16.626243: step 179460, loss = 0.54, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 9h:24m:09s remains)
INFO - root - 2017-12-17 01:50:18.818492: step 179470, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 9h:22m:14s remains)
INFO - root - 2017-12-17 01:50:21.042227: step 179480, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 9h:22m:13s remains)
INFO - root - 2017-12-17 01:50:23.253724: step 179490, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.224 sec/batch; 9h:32m:17s remains)
INFO - root - 2017-12-17 01:50:25.478587: step 179500, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 9h:45m:55s remains)
INFO - root - 2017-12-17 01:50:27.802105: step 179510, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 9h:08m:54s remains)
INFO - root - 2017-12-17 01:50:30.003695: step 179520, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 9h:10m:44s remains)
INFO - root - 2017-12-17 01:50:32.188696: step 179530, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 9h:10m:30s remains)
INFO - root - 2017-12-17 01:50:34.373711: step 179540, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 9h:10m:34s remains)
INFO - root - 2017-12-17 01:50:36.557737: step 179550, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 9h:35m:34s remains)
INFO - root - 2017-12-17 01:50:38.759948: step 179560, loss = 0.45, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 9h:38m:21s remains)
INFO - root - 2017-12-17 01:50:40.960295: step 179570, loss = 0.48, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 9h:30m:44s remains)
INFO - root - 2017-12-17 01:50:43.184456: step 179580, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.231 sec/batch; 9h:47m:54s remains)
INFO - root - 2017-12-17 01:50:45.402610: step 179590, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 9h:20m:09s remains)
INFO - root - 2017-12-17 01:50:47.612888: step 179600, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 9h:25m:37s remains)
INFO - root - 2017-12-17 01:50:49.952243: step 179610, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 9h:21m:14s remains)
INFO - root - 2017-12-17 01:50:52.170882: step 179620, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 9h:26m:10s remains)
INFO - root - 2017-12-17 01:50:54.399120: step 179630, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 9h:14m:51s remains)
INFO - root - 2017-12-17 01:50:56.587902: step 179640, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 9h:14m:44s remains)
INFO - root - 2017-12-17 01:50:58.804727: step 179650, loss = 0.44, batch loss = 0.26 (37.7 examples/sec; 0.212 sec/batch; 9h:01m:01s remains)
INFO - root - 2017-12-17 01:51:00.998884: step 179660, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 9h:09m:05s remains)
INFO - root - 2017-12-17 01:51:03.215117: step 179670, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 9h:16m:13s remains)
INFO - root - 2017-12-17 01:51:05.451813: step 179680, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 9h:25m:18s remains)
INFO - root - 2017-12-17 01:51:07.672464: step 179690, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 9h:11m:31s remains)
INFO - root - 2017-12-17 01:51:09.916677: step 179700, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 9h:04m:48s remains)
INFO - root - 2017-12-17 01:51:12.250360: step 179710, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 9h:17m:52s remains)
INFO - root - 2017-12-17 01:51:14.488879: step 179720, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 9h:20m:23s remains)
INFO - root - 2017-12-17 01:51:16.707363: step 179730, loss = 0.46, batch loss = 0.29 (35.0 examples/sec; 0.228 sec/batch; 9h:41m:27s remains)
INFO - root - 2017-12-17 01:51:18.957392: step 179740, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 9h:21m:10s remains)
INFO - root - 2017-12-17 01:51:21.193780: step 179750, loss = 0.44, batch loss = 0.26 (35.0 examples/sec; 0.229 sec/batch; 9h:42m:23s remains)
INFO - root - 2017-12-17 01:51:23.414291: step 179760, loss = 0.47, batch loss = 0.29 (34.7 examples/sec; 0.231 sec/batch; 9h:47m:07s remains)
INFO - root - 2017-12-17 01:51:25.616535: step 179770, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 9h:09m:35s remains)
INFO - root - 2017-12-17 01:51:27.828583: step 179780, loss = 0.56, batch loss = 0.38 (35.0 examples/sec; 0.229 sec/batch; 9h:41m:44s remains)
INFO - root - 2017-12-17 01:51:30.085951: step 179790, loss = 0.48, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 9h:19m:33s remains)
INFO - root - 2017-12-17 01:51:32.318936: step 179800, loss = 0.51, batch loss = 0.33 (34.9 examples/sec; 0.229 sec/batch; 9h:42m:47s remains)
INFO - root - 2017-12-17 01:51:34.648311: step 179810, loss = 0.55, batch loss = 0.37 (36.1 examples/sec; 0.222 sec/batch; 9h:24m:21s remains)
INFO - root - 2017-12-17 01:51:36.852140: step 179820, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 9h:32m:27s remains)
INFO - root - 2017-12-17 01:51:39.081397: step 179830, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 9h:12m:32s remains)
INFO - root - 2017-12-17 01:51:41.316487: step 179840, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 9h:30m:26s remains)
INFO - root - 2017-12-17 01:51:43.534521: step 179850, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 9h:43m:31s remains)
INFO - root - 2017-12-17 01:51:45.779394: step 179860, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 9h:19m:37s remains)
INFO - root - 2017-12-17 01:51:47.996736: step 179870, loss = 0.49, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 9h:23m:29s remains)
INFO - root - 2017-12-17 01:51:50.206797: step 179880, loss = 0.44, batch loss = 0.27 (37.4 examples/sec; 0.214 sec/batch; 9h:03m:56s remains)
INFO - root - 2017-12-17 01:51:52.418849: step 179890, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.226 sec/batch; 9h:33m:39s remains)
INFO - root - 2017-12-17 01:51:54.640318: step 179900, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 9h:17m:50s remains)
INFO - root - 2017-12-17 01:51:56.939360: step 179910, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 9h:13m:41s remains)
INFO - root - 2017-12-17 01:51:59.181698: step 179920, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 9h:15m:51s remains)
INFO - root - 2017-12-17 01:52:01.371929: step 179930, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 9h:25m:29s remains)
INFO - root - 2017-12-17 01:52:03.568325: step 179940, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 9h:11m:46s remains)
INFO - root - 2017-12-17 01:52:05.823883: step 179950, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 9h:33m:21s remains)
INFO - root - 2017-12-17 01:52:08.053356: step 179960, loss = 0.42, batch loss = 0.24 (35.0 examples/sec; 0.228 sec/batch; 9h:40m:34s remains)
INFO - root - 2017-12-17 01:52:10.321542: step 179970, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 9h:20m:09s remains)
INFO - root - 2017-12-17 01:52:12.544574: step 179980, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 9h:28m:09s remains)
INFO - root - 2017-12-17 01:52:14.794926: step 179990, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 9h:37m:58s remains)
INFO - root - 2017-12-17 01:52:16.992742: step 180000, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 9h:32m:53s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-180000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-180000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 01:52:19.781389: step 180010, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.216 sec/batch; 9h:08m:07s remains)
INFO - root - 2017-12-17 01:52:21.969985: step 180020, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 9h:03m:35s remains)
INFO - root - 2017-12-17 01:52:24.183354: step 180030, loss = 0.55, batch loss = 0.37 (37.0 examples/sec; 0.216 sec/batch; 9h:10m:09s remains)
INFO - root - 2017-12-17 01:52:26.383073: step 180040, loss = 0.53, batch loss = 0.35 (35.8 examples/sec; 0.223 sec/batch; 9h:27m:39s remains)
INFO - root - 2017-12-17 01:52:28.610447: step 180050, loss = 0.55, batch loss = 0.37 (36.7 examples/sec; 0.218 sec/batch; 9h:13m:10s remains)
INFO - root - 2017-12-17 01:52:30.850936: step 180060, loss = 0.49, batch loss = 0.31 (34.6 examples/sec; 0.231 sec/batch; 9h:46m:59s remains)
INFO - root - 2017-12-17 01:52:33.075948: step 180070, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 9h:21m:04s remains)
INFO - root - 2017-12-17 01:52:35.270926: step 180080, loss = 0.48, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 9h:06m:34s remains)
INFO - root - 2017-12-17 01:52:37.529990: step 180090, loss = 0.41, batch loss = 0.23 (34.3 examples/sec; 0.233 sec/batch; 9h:52m:28s remains)
INFO - root - 2017-12-17 01:52:39.784767: step 180100, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 9h:15m:24s remains)
INFO - root - 2017-12-17 01:52:42.121410: step 180110, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 9h:11m:07s remains)
INFO - root - 2017-12-17 01:52:44.367288: step 180120, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 9h:18m:13s remains)
INFO - root - 2017-12-17 01:52:46.577510: step 180130, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.214 sec/batch; 9h:03m:59s remains)
INFO - root - 2017-12-17 01:52:48.773628: step 180140, loss = 0.42, batch loss = 0.24 (34.8 examples/sec; 0.230 sec/batch; 9h:43m:06s remains)
INFO - root - 2017-12-17 01:52:50.993690: step 180150, loss = 0.48, batch loss = 0.30 (33.8 examples/sec; 0.237 sec/batch; 10h:01m:33s remains)
INFO - root - 2017-12-17 01:52:53.252220: step 180160, loss = 0.42, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 9h:12m:58s remains)
INFO - root - 2017-12-17 01:52:55.455278: step 180170, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 9h:15m:29s remains)
INFO - root - 2017-12-17 01:52:57.674798: step 180180, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 9h:09m:24s remains)
INFO - root - 2017-12-17 01:52:59.923706: step 180190, loss = 0.44, batch loss = 0.27 (35.0 examples/sec; 0.228 sec/batch; 9h:39m:55s remains)
INFO - root - 2017-12-17 01:53:02.137091: step 180200, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.223 sec/batch; 9h:26m:33s remains)
INFO - root - 2017-12-17 01:53:04.482468: step 180210, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 9h:31m:56s remains)
INFO - root - 2017-12-17 01:53:06.673291: step 180220, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 9h:17m:35s remains)
INFO - root - 2017-12-17 01:53:08.861606: step 180230, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 9h:14m:09s remains)
INFO - root - 2017-12-17 01:53:11.093084: step 180240, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 9h:29m:12s remains)
INFO - root - 2017-12-17 01:53:13.298239: step 180250, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 9h:11m:39s remains)
INFO - root - 2017-12-17 01:53:15.572065: step 180260, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 9h:23m:39s remains)
INFO - root - 2017-12-17 01:53:17.784252: step 180270, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 9h:33m:19s remains)
INFO - root - 2017-12-17 01:53:20.029081: step 180280, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 9h:23m:18s remains)
INFO - root - 2017-12-17 01:53:22.241754: step 180290, loss = 0.54, batch loss = 0.36 (36.0 examples/sec; 0.222 sec/batch; 9h:24m:14s remains)
INFO - root - 2017-12-17 01:53:24.468588: step 180300, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 9h:25m:34s remains)
INFO - root - 2017-12-17 01:53:26.790988: step 180310, loss = 0.44, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 9h:09m:14s remains)
INFO - root - 2017-12-17 01:53:29.053827: step 180320, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 9h:48m:13s remains)
INFO - root - 2017-12-17 01:53:31.288483: step 180330, loss = 0.50, batch loss = 0.32 (34.3 examples/sec; 0.233 sec/batch; 9h:51m:30s remains)
INFO - root - 2017-12-17 01:53:33.523402: step 180340, loss = 0.45, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 9h:16m:50s remains)
INFO - root - 2017-12-17 01:53:35.737422: step 180350, loss = 0.51, batch loss = 0.34 (34.2 examples/sec; 0.234 sec/batch; 9h:52m:28s remains)
INFO - root - 2017-12-17 01:53:37.998464: step 180360, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.224 sec/batch; 9h:26m:57s remains)
INFO - root - 2017-12-17 01:53:40.205801: step 180370, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 9h:19m:31s remains)
INFO - root - 2017-12-17 01:53:42.392897: step 180380, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 9h:33m:41s remains)
INFO - root - 2017-12-17 01:53:44.604017: step 180390, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 9h:09m:32s remains)
INFO - root - 2017-12-17 01:53:46.817526: step 180400, loss = 0.55, batch loss = 0.37 (35.1 examples/sec; 0.228 sec/batch; 9h:36m:59s remains)
INFO - root - 2017-12-17 01:53:49.160136: step 180410, loss = 0.43, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 9h:29m:23s remains)
INFO - root - 2017-12-17 01:53:51.386415: step 180420, loss = 0.41, batch loss = 0.24 (35.6 examples/sec; 0.225 sec/batch; 9h:29m:42s remains)
INFO - root - 2017-12-17 01:53:53.591664: step 180430, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 9h:03m:53s remains)
INFO - root - 2017-12-17 01:53:55.762838: step 180440, loss = 0.47, batch loss = 0.29 (37.9 examples/sec; 0.211 sec/batch; 8h:54m:19s remains)
INFO - root - 2017-12-17 01:53:58.005888: step 180450, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 9h:31m:10s remains)
INFO - root - 2017-12-17 01:54:00.200331: step 180460, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 9h:09m:36s remains)
INFO - root - 2017-12-17 01:54:02.414362: step 180470, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 9h:07m:29s remains)
INFO - root - 2017-12-17 01:54:04.604508: step 180480, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 9h:06m:07s remains)
INFO - root - 2017-12-17 01:54:06.815318: step 180490, loss = 0.44, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 9h:03m:23s remains)
INFO - root - 2017-12-17 01:54:09.022885: step 180500, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 9h:06m:11s remains)
INFO - root - 2017-12-17 01:54:11.343117: step 180510, loss = 0.43, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 9h:14m:49s remains)
INFO - root - 2017-12-17 01:54:13.587471: step 180520, loss = 0.57, batch loss = 0.39 (34.4 examples/sec; 0.233 sec/batch; 9h:49m:35s remains)
INFO - root - 2017-12-17 01:54:15.804233: step 180530, loss = 0.44, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 9h:29m:25s remains)
INFO - root - 2017-12-17 01:54:18.033982: step 180540, loss = 0.48, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 9h:05m:13s remains)
INFO - root - 2017-12-17 01:54:20.253656: step 180550, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 9h:22m:52s remains)
INFO - root - 2017-12-17 01:54:22.454268: step 180560, loss = 0.50, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 9h:24m:29s remains)
INFO - root - 2017-12-17 01:54:24.660673: step 180570, loss = 0.51, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 9h:32m:28s remains)
INFO - root - 2017-12-17 01:54:26.885495: step 180580, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 9h:47m:01s remains)
INFO - root - 2017-12-17 01:54:29.088663: step 180590, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 9h:05m:44s remains)
INFO - root - 2017-12-17 01:54:31.328007: step 180600, loss = 0.53, batch loss = 0.35 (32.7 examples/sec; 0.245 sec/batch; 10h:19m:11s remains)
INFO - root - 2017-12-17 01:54:33.699690: step 180610, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 9h:17m:47s remains)
INFO - root - 2017-12-17 01:54:35.924764: step 180620, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 9h:24m:51s remains)
INFO - root - 2017-12-17 01:54:38.103492: step 180630, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 9h:12m:57s remains)
INFO - root - 2017-12-17 01:54:40.310074: step 180640, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 9h:16m:25s remains)
INFO - root - 2017-12-17 01:54:42.510500: step 180650, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 9h:16m:56s remains)
INFO - root - 2017-12-17 01:54:44.727914: step 180660, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 9h:25m:36s remains)
INFO - root - 2017-12-17 01:54:46.942072: step 180670, loss = 0.43, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 9h:31m:05s remains)
INFO - root - 2017-12-17 01:54:49.164996: step 180680, loss = 0.46, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 9h:34m:10s remains)
INFO - root - 2017-12-17 01:54:51.381084: step 180690, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 9h:06m:15s remains)
INFO - root - 2017-12-17 01:54:53.642171: step 180700, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 9h:18m:45s remains)
INFO - root - 2017-12-17 01:54:56.041578: step 180710, loss = 0.44, batch loss = 0.27 (35.0 examples/sec; 0.229 sec/batch; 9h:38m:52s remains)
INFO - root - 2017-12-17 01:54:58.305950: step 180720, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 9h:41m:08s remains)
INFO - root - 2017-12-17 01:55:00.521774: step 180730, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 9h:26m:17s remains)
INFO - root - 2017-12-17 01:55:02.739955: step 180740, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 9h:10m:34s remains)
INFO - root - 2017-12-17 01:55:04.934652: step 180750, loss = 0.43, batch loss = 0.25 (35.0 examples/sec; 0.228 sec/batch; 9h:37m:17s remains)
INFO - root - 2017-12-17 01:55:07.203310: step 180760, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 9h:13m:10s remains)
INFO - root - 2017-12-17 01:55:09.373714: step 180770, loss = 0.56, batch loss = 0.38 (36.6 examples/sec; 0.219 sec/batch; 9h:12m:54s remains)
INFO - root - 2017-12-17 01:55:11.572490: step 180780, loss = 0.52, batch loss = 0.35 (34.2 examples/sec; 0.234 sec/batch; 9h:51m:09s remains)
INFO - root - 2017-12-17 01:55:13.768592: step 180790, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 9h:25m:23s remains)
INFO - root - 2017-12-17 01:55:15.991770: step 180800, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 9h:30m:00s remains)
INFO - root - 2017-12-17 01:55:18.352304: step 180810, loss = 0.44, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 9h:26m:30s remains)
INFO - root - 2017-12-17 01:55:20.583747: step 180820, loss = 0.48, batch loss = 0.30 (34.3 examples/sec; 0.233 sec/batch; 9h:50m:10s remains)
INFO - root - 2017-12-17 01:55:22.794226: step 180830, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 9h:09m:53s remains)
INFO - root - 2017-12-17 01:55:25.008276: step 180840, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 9h:28m:12s remains)
INFO - root - 2017-12-17 01:55:27.248425: step 180850, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 9h:08m:58s remains)
INFO - root - 2017-12-17 01:55:29.504873: step 180860, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 9h:07m:01s remains)
INFO - root - 2017-12-17 01:55:31.720861: step 180870, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.224 sec/batch; 9h:27m:18s remains)
INFO - root - 2017-12-17 01:55:33.906188: step 180880, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 9h:02m:28s remains)
INFO - root - 2017-12-17 01:55:36.115499: step 180890, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 9h:01m:47s remains)
INFO - root - 2017-12-17 01:55:38.362549: step 180900, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.228 sec/batch; 9h:36m:46s remains)
INFO - root - 2017-12-17 01:55:40.715384: step 180910, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 9h:21m:19s remains)
INFO - root - 2017-12-17 01:55:42.952931: step 180920, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 9h:26m:13s remains)
INFO - root - 2017-12-17 01:55:45.196468: step 180930, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 9h:23m:10s remains)
INFO - root - 2017-12-17 01:55:47.401007: step 180940, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 9h:29m:12s remains)
INFO - root - 2017-12-17 01:55:49.607514: step 180950, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 9h:16m:08s remains)
INFO - root - 2017-12-17 01:55:51.826354: step 180960, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 9h:01m:56s remains)
INFO - root - 2017-12-17 01:55:54.085301: step 180970, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 9h:21m:08s remains)
INFO - root - 2017-12-17 01:55:56.283649: step 180980, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 9h:23m:53s remains)
INFO - root - 2017-12-17 01:55:58.519411: step 180990, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 9h:27m:17s remains)
INFO - root - 2017-12-17 01:56:00.762038: step 181000, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 9h:34m:41s remains)
INFO - root - 2017-12-17 01:56:03.106185: step 181010, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 9h:19m:32s remains)
INFO - root - 2017-12-17 01:56:05.322169: step 181020, loss = 0.42, batch loss = 0.24 (37.4 examples/sec; 0.214 sec/batch; 9h:00m:30s remains)
INFO - root - 2017-12-17 01:56:07.569237: step 181030, loss = 0.48, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 9h:20m:38s remains)
INFO - root - 2017-12-17 01:56:09.793813: step 181040, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 8h:56m:44s remains)
INFO - root - 2017-12-17 01:56:12.014398: step 181050, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 9h:16m:30s remains)
INFO - root - 2017-12-17 01:56:14.245601: step 181060, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 9h:34m:55s remains)
INFO - root - 2017-12-17 01:56:16.478837: step 181070, loss = 0.48, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 9h:30m:37s remains)
INFO - root - 2017-12-17 01:56:18.700843: step 181080, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 9h:07m:40s remains)
INFO - root - 2017-12-17 01:56:20.960533: step 181090, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 9h:21m:45s remains)
INFO - root - 2017-12-17 01:56:23.158279: step 181100, loss = 0.52, batch loss = 0.34 (34.8 examples/sec; 0.230 sec/batch; 9h:39m:52s remains)
INFO - root - 2017-12-17 01:56:25.507631: step 181110, loss = 0.54, batch loss = 0.36 (37.0 examples/sec; 0.216 sec/batch; 9h:05m:21s remains)
INFO - root - 2017-12-17 01:56:27.730411: step 181120, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 9h:27m:26s remains)
INFO - root - 2017-12-17 01:56:29.986064: step 181130, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 9h:30m:25s remains)
INFO - root - 2017-12-17 01:56:32.233441: step 181140, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 9h:29m:25s remains)
INFO - root - 2017-12-17 01:56:34.472459: step 181150, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 9h:20m:06s remains)
INFO - root - 2017-12-17 01:56:36.664746: step 181160, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 9h:22m:05s remains)
INFO - root - 2017-12-17 01:56:38.874063: step 181170, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 9h:33m:06s remains)
INFO - root - 2017-12-17 01:56:41.091242: step 181180, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 9h:15m:54s remains)
INFO - root - 2017-12-17 01:56:43.318413: step 181190, loss = 0.50, batch loss = 0.32 (34.3 examples/sec; 0.233 sec/batch; 9h:48m:20s remains)
INFO - root - 2017-12-17 01:56:45.528931: step 181200, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 9h:07m:24s remains)
INFO - root - 2017-12-17 01:56:47.872980: step 181210, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 9h:16m:23s remains)
INFO - root - 2017-12-17 01:56:50.103421: step 181220, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 9h:31m:09s remains)
INFO - root - 2017-12-17 01:56:52.326056: step 181230, loss = 0.55, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 9h:16m:43s remains)
INFO - root - 2017-12-17 01:56:54.514778: step 181240, loss = 0.44, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 9h:22m:50s remains)
INFO - root - 2017-12-17 01:56:56.728168: step 181250, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 9h:38m:16s remains)
INFO - root - 2017-12-17 01:56:58.950301: step 181260, loss = 0.49, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 9h:22m:50s remains)
INFO - root - 2017-12-17 01:57:01.161554: step 181270, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 9h:20m:03s remains)
INFO - root - 2017-12-17 01:57:03.361749: step 181280, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 9h:19m:43s remains)
INFO - root - 2017-12-17 01:57:05.583045: step 181290, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 9h:16m:43s remains)
INFO - root - 2017-12-17 01:57:07.800525: step 181300, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 8h:55m:33s remains)
INFO - root - 2017-12-17 01:57:10.162544: step 181310, loss = 0.43, batch loss = 0.25 (35.1 examples/sec; 0.228 sec/batch; 9h:34m:20s remains)
INFO - root - 2017-12-17 01:57:12.443544: step 181320, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 9h:23m:14s remains)
INFO - root - 2017-12-17 01:57:14.632697: step 181330, loss = 0.46, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 9h:27m:09s remains)
INFO - root - 2017-12-17 01:57:16.831178: step 181340, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.224 sec/batch; 9h:25m:33s remains)
INFO - root - 2017-12-17 01:57:19.039705: step 181350, loss = 0.45, batch loss = 0.27 (38.2 examples/sec; 0.210 sec/batch; 8h:48m:06s remains)
INFO - root - 2017-12-17 01:57:21.249348: step 181360, loss = 0.43, batch loss = 0.25 (35.0 examples/sec; 0.229 sec/batch; 9h:36m:18s remains)
INFO - root - 2017-12-17 01:57:23.481345: step 181370, loss = 0.49, batch loss = 0.31 (37.9 examples/sec; 0.211 sec/batch; 8h:51m:06s remains)
INFO - root - 2017-12-17 01:57:25.666499: step 181380, loss = 0.60, batch loss = 0.42 (36.1 examples/sec; 0.221 sec/batch; 9h:17m:26s remains)
INFO - root - 2017-12-17 01:57:27.906776: step 181390, loss = 0.43, batch loss = 0.25 (36.8 examples/sec; 0.217 sec/batch; 9h:07m:41s remains)
INFO - root - 2017-12-17 01:57:30.154041: step 181400, loss = 0.43, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 9h:18m:47s remains)
INFO - root - 2017-12-17 01:57:32.513211: step 181410, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 9h:14m:49s remains)
INFO - root - 2017-12-17 01:57:34.730102: step 181420, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 9h:04m:42s remains)
INFO - root - 2017-12-17 01:57:36.902155: step 181430, loss = 0.49, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 9h:11m:58s remains)
INFO - root - 2017-12-17 01:57:39.126650: step 181440, loss = 0.46, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 9h:17m:40s remains)
INFO - root - 2017-12-17 01:57:41.380894: step 181450, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 9h:19m:06s remains)
INFO - root - 2017-12-17 01:57:43.603336: step 181460, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 9h:27m:23s remains)
INFO - root - 2017-12-17 01:57:45.776175: step 181470, loss = 0.46, batch loss = 0.28 (38.0 examples/sec; 0.211 sec/batch; 8h:50m:32s remains)
INFO - root - 2017-12-17 01:57:47.952340: step 181480, loss = 0.51, batch loss = 0.33 (37.2 examples/sec; 0.215 sec/batch; 9h:01m:58s remains)
INFO - root - 2017-12-17 01:57:50.172469: step 181490, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 9h:17m:59s remains)
INFO - root - 2017-12-17 01:57:52.385163: step 181500, loss = 0.42, batch loss = 0.24 (36.1 examples/sec; 0.221 sec/batch; 9h:17m:16s remains)
INFO - root - 2017-12-17 01:57:54.716816: step 181510, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 9h:22m:40s remains)
INFO - root - 2017-12-17 01:57:56.894264: step 181520, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 9h:08m:35s remains)
INFO - root - 2017-12-17 01:57:59.100104: step 181530, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 9h:13m:58s remains)
INFO - root - 2017-12-17 01:58:01.319013: step 181540, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.223 sec/batch; 9h:21m:36s remains)
INFO - root - 2017-12-17 01:58:03.549774: step 181550, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.228 sec/batch; 9h:32m:27s remains)
INFO - root - 2017-12-17 01:58:05.804342: step 181560, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 9h:22m:30s remains)
INFO - root - 2017-12-17 01:58:08.035969: step 181570, loss = 0.46, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 9h:14m:51s remains)
INFO - root - 2017-12-17 01:58:10.270875: step 181580, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 9h:04m:33s remains)
INFO - root - 2017-12-17 01:58:12.484507: step 181590, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 9h:11m:58s remains)
INFO - root - 2017-12-17 01:58:14.676360: step 181600, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 9h:05m:52s remains)
INFO - root - 2017-12-17 01:58:17.021568: step 181610, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 9h:24m:19s remains)
INFO - root - 2017-12-17 01:58:19.260409: step 181620, loss = 0.50, batch loss = 0.32 (34.4 examples/sec; 0.232 sec/batch; 9h:44m:27s remains)
INFO - root - 2017-12-17 01:58:21.473595: step 181630, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.228 sec/batch; 9h:32m:15s remains)
INFO - root - 2017-12-17 01:58:23.640282: step 181640, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 8h:58m:38s remains)
INFO - root - 2017-12-17 01:58:25.866796: step 181650, loss = 0.43, batch loss = 0.25 (37.2 examples/sec; 0.215 sec/batch; 9h:00m:59s remains)
INFO - root - 2017-12-17 01:58:28.088908: step 181660, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 9h:27m:50s remains)
INFO - root - 2017-12-17 01:58:30.272180: step 181670, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 9h:19m:49s remains)
INFO - root - 2017-12-17 01:58:32.498763: step 181680, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 9h:15m:06s remains)
INFO - root - 2017-12-17 01:58:34.730442: step 181690, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 9h:15m:37s remains)
INFO - root - 2017-12-17 01:58:36.950119: step 181700, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 9h:07m:42s remains)
INFO - root - 2017-12-17 01:58:39.282759: step 181710, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 9h:19m:02s remains)
INFO - root - 2017-12-17 01:58:41.508802: step 181720, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 9h:03m:02s remains)
INFO - root - 2017-12-17 01:58:43.699047: step 181730, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 9h:05m:12s remains)
INFO - root - 2017-12-17 01:58:45.950132: step 181740, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.226 sec/batch; 9h:28m:53s remains)
INFO - root - 2017-12-17 01:58:48.133710: step 181750, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 9h:06m:05s remains)
INFO - root - 2017-12-17 01:58:50.346209: step 181760, loss = 0.49, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 9h:14m:01s remains)
INFO - root - 2017-12-17 01:58:52.577879: step 181770, loss = 0.52, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 9h:26m:58s remains)
INFO - root - 2017-12-17 01:58:54.815787: step 181780, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 9h:27m:22s remains)
INFO - root - 2017-12-17 01:58:57.057309: step 181790, loss = 0.55, batch loss = 0.37 (34.8 examples/sec; 0.230 sec/batch; 9h:38m:04s remains)
INFO - root - 2017-12-17 01:58:59.232598: step 181800, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 9h:17m:29s remains)
INFO - root - 2017-12-17 01:59:01.576053: step 181810, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 9h:12m:40s remains)
INFO - root - 2017-12-17 01:59:03.802531: step 181820, loss = 0.48, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 9h:04m:59s remains)
INFO - root - 2017-12-17 01:59:05.991764: step 181830, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 9h:10m:15s remains)
INFO - root - 2017-12-17 01:59:08.160638: step 181840, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 9h:14m:23s remains)
INFO - root - 2017-12-17 01:59:10.360635: step 181850, loss = 0.54, batch loss = 0.36 (37.7 examples/sec; 0.212 sec/batch; 8h:53m:26s remains)
INFO - root - 2017-12-17 01:59:12.583502: step 181860, loss = 0.42, batch loss = 0.24 (36.3 examples/sec; 0.221 sec/batch; 9h:13m:48s remains)
INFO - root - 2017-12-17 01:59:14.791068: step 181870, loss = 0.53, batch loss = 0.36 (36.1 examples/sec; 0.222 sec/batch; 9h:16m:17s remains)
INFO - root - 2017-12-17 01:59:16.988564: step 181880, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 9h:07m:06s remains)
INFO - root - 2017-12-17 01:59:19.190228: step 181890, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 9h:06m:41s remains)
INFO - root - 2017-12-17 01:59:21.438337: step 181900, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.219 sec/batch; 9h:08m:42s remains)
INFO - root - 2017-12-17 01:59:23.800062: step 181910, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 9h:20m:53s remains)
INFO - root - 2017-12-17 01:59:26.002384: step 181920, loss = 0.46, batch loss = 0.28 (37.1 examples/sec; 0.216 sec/batch; 9h:01m:51s remains)
INFO - root - 2017-12-17 01:59:28.217518: step 181930, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 9h:22m:01s remains)
INFO - root - 2017-12-17 01:59:30.466471: step 181940, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 9h:03m:05s remains)
INFO - root - 2017-12-17 01:59:32.672164: step 181950, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 9h:03m:16s remains)
INFO - root - 2017-12-17 01:59:34.904556: step 181960, loss = 0.45, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 9h:23m:54s remains)
INFO - root - 2017-12-17 01:59:37.134396: step 181970, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 9h:29m:28s remains)
INFO - root - 2017-12-17 01:59:39.394497: step 181980, loss = 0.54, batch loss = 0.36 (37.8 examples/sec; 0.212 sec/batch; 8h:51m:31s remains)
INFO - root - 2017-12-17 01:59:41.576397: step 181990, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 9h:10m:23s remains)
INFO - root - 2017-12-17 01:59:43.809436: step 182000, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 9h:05m:32s remains)
INFO - root - 2017-12-17 01:59:46.178789: step 182010, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 9h:20m:02s remains)
INFO - root - 2017-12-17 01:59:48.427925: step 182020, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 9h:09m:39s remains)
INFO - root - 2017-12-17 01:59:50.614973: step 182030, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 9h:09m:08s remains)
INFO - root - 2017-12-17 01:59:52.817258: step 182040, loss = 0.50, batch loss = 0.32 (33.6 examples/sec; 0.238 sec/batch; 9h:56m:26s remains)
INFO - root - 2017-12-17 01:59:55.052637: step 182050, loss = 0.47, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 9h:32m:55s remains)
INFO - root - 2017-12-17 01:59:57.254253: step 182060, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 9h:12m:01s remains)
INFO - root - 2017-12-17 01:59:59.472988: step 182070, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 9h:02m:07s remains)
INFO - root - 2017-12-17 02:00:01.654594: step 182080, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 9h:07m:51s remains)
INFO - root - 2017-12-17 02:00:03.856868: step 182090, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.215 sec/batch; 9h:00m:12s remains)
INFO - root - 2017-12-17 02:00:06.081012: step 182100, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.215 sec/batch; 8h:57m:45s remains)
INFO - root - 2017-12-17 02:00:08.453508: step 182110, loss = 0.49, batch loss = 0.31 (33.4 examples/sec; 0.240 sec/batch; 10h:00m:39s remains)
INFO - root - 2017-12-17 02:00:10.659817: step 182120, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 9h:15m:18s remains)
INFO - root - 2017-12-17 02:00:12.910578: step 182130, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 9h:09m:22s remains)
INFO - root - 2017-12-17 02:00:15.110216: step 182140, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 9h:10m:42s remains)
INFO - root - 2017-12-17 02:00:17.378226: step 182150, loss = 0.56, batch loss = 0.38 (34.1 examples/sec; 0.235 sec/batch; 9h:48m:37s remains)
INFO - root - 2017-12-17 02:00:19.577064: step 182160, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 9h:20m:38s remains)
INFO - root - 2017-12-17 02:00:21.774499: step 182170, loss = 0.51, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 9h:07m:45s remains)
INFO - root - 2017-12-17 02:00:23.959957: step 182180, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 9h:08m:08s remains)
INFO - root - 2017-12-17 02:00:26.201605: step 182190, loss = 0.55, batch loss = 0.38 (35.5 examples/sec; 0.226 sec/batch; 9h:25m:10s remains)
INFO - root - 2017-12-17 02:00:28.434920: step 182200, loss = 0.43, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 9h:08m:13s remains)
INFO - root - 2017-12-17 02:00:30.790895: step 182210, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 9h:03m:49s remains)
INFO - root - 2017-12-17 02:00:32.987317: step 182220, loss = 0.45, batch loss = 0.27 (37.8 examples/sec; 0.212 sec/batch; 8h:49m:45s remains)
INFO - root - 2017-12-17 02:00:35.200266: step 182230, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 9h:14m:06s remains)
INFO - root - 2017-12-17 02:00:37.414714: step 182240, loss = 0.53, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 9h:02m:38s remains)
INFO - root - 2017-12-17 02:00:39.628625: step 182250, loss = 0.46, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 9h:00m:21s remains)
INFO - root - 2017-12-17 02:00:41.853643: step 182260, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 9h:08m:43s remains)
INFO - root - 2017-12-17 02:00:44.047997: step 182270, loss = 0.54, batch loss = 0.36 (37.6 examples/sec; 0.213 sec/batch; 8h:52m:38s remains)
INFO - root - 2017-12-17 02:00:46.271670: step 182280, loss = 0.44, batch loss = 0.26 (34.2 examples/sec; 0.234 sec/batch; 9h:46m:08s remains)
INFO - root - 2017-12-17 02:00:48.473536: step 182290, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 9h:09m:01s remains)
INFO - root - 2017-12-17 02:00:50.711328: step 182300, loss = 0.49, batch loss = 0.31 (32.6 examples/sec; 0.245 sec/batch; 10h:13m:55s remains)
INFO - root - 2017-12-17 02:00:53.072394: step 182310, loss = 0.42, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 9h:20m:25s remains)
INFO - root - 2017-12-17 02:00:55.278940: step 182320, loss = 0.42, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 9h:23m:38s remains)
INFO - root - 2017-12-17 02:00:57.496482: step 182330, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 9h:19m:49s remains)
INFO - root - 2017-12-17 02:00:59.678798: step 182340, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 9h:08m:13s remains)
INFO - root - 2017-12-17 02:01:01.889112: step 182350, loss = 0.47, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 9h:05m:01s remains)
INFO - root - 2017-12-17 02:01:04.142323: step 182360, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 9h:06m:43s remains)
INFO - root - 2017-12-17 02:01:06.335051: step 182370, loss = 0.54, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 9h:17m:23s remains)
INFO - root - 2017-12-17 02:01:08.572568: step 182380, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 9h:10m:49s remains)
INFO - root - 2017-12-17 02:01:10.740574: step 182390, loss = 0.47, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 8h:58m:25s remains)
INFO - root - 2017-12-17 02:01:12.968604: step 182400, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 8h:58m:34s remains)
INFO - root - 2017-12-17 02:01:15.298212: step 182410, loss = 0.50, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 9h:18m:55s remains)
INFO - root - 2017-12-17 02:01:17.470154: step 182420, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 9h:03m:37s remains)
INFO - root - 2017-12-17 02:01:19.682670: step 182430, loss = 0.50, batch loss = 0.32 (34.0 examples/sec; 0.235 sec/batch; 9h:48m:34s remains)
INFO - root - 2017-12-17 02:01:21.872333: step 182440, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 9h:18m:36s remains)
INFO - root - 2017-12-17 02:01:24.074114: step 182450, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 9h:15m:14s remains)
INFO - root - 2017-12-17 02:01:26.280221: step 182460, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.216 sec/batch; 8h:59m:48s remains)
INFO - root - 2017-12-17 02:01:28.503317: step 182470, loss = 0.47, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 9h:17m:51s remains)
INFO - root - 2017-12-17 02:01:30.724463: step 182480, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 9h:14m:18s remains)
INFO - root - 2017-12-17 02:01:32.952588: step 182490, loss = 0.47, batch loss = 0.29 (34.4 examples/sec; 0.232 sec/batch; 9h:40m:47s remains)
INFO - root - 2017-12-17 02:01:35.142693: step 182500, loss = 0.44, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 9h:08m:19s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-182500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-182500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 02:01:38.077908: step 182510, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 9h:10m:33s remains)
INFO - root - 2017-12-17 02:01:40.289233: step 182520, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 9h:06m:05s remains)
INFO - root - 2017-12-17 02:01:42.514118: step 182530, loss = 0.51, batch loss = 0.33 (32.9 examples/sec; 0.243 sec/batch; 10h:08m:36s remains)
INFO - root - 2017-12-17 02:01:44.718762: step 182540, loss = 0.53, batch loss = 0.35 (37.4 examples/sec; 0.214 sec/batch; 8h:54m:03s remains)
INFO - root - 2017-12-17 02:01:46.972748: step 182550, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 9h:21m:25s remains)
INFO - root - 2017-12-17 02:01:49.228501: step 182560, loss = 0.54, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 9h:04m:21s remains)
INFO - root - 2017-12-17 02:01:51.470364: step 182570, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 9h:15m:01s remains)
INFO - root - 2017-12-17 02:01:53.659572: step 182580, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 9h:10m:16s remains)
INFO - root - 2017-12-17 02:01:55.847037: step 182590, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 9h:05m:43s remains)
INFO - root - 2017-12-17 02:01:58.094997: step 182600, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 9h:27m:01s remains)
INFO - root - 2017-12-17 02:02:00.436740: step 182610, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 8h:51m:56s remains)
INFO - root - 2017-12-17 02:02:02.670342: step 182620, loss = 0.50, batch loss = 0.32 (37.5 examples/sec; 0.213 sec/batch; 8h:52m:12s remains)
INFO - root - 2017-12-17 02:02:04.905099: step 182630, loss = 0.43, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 9h:23m:04s remains)
INFO - root - 2017-12-17 02:02:07.103805: step 182640, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 9h:03m:59s remains)
INFO - root - 2017-12-17 02:02:09.319028: step 182650, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 9h:01m:40s remains)
INFO - root - 2017-12-17 02:02:11.517947: step 182660, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.223 sec/batch; 9h:15m:42s remains)
INFO - root - 2017-12-17 02:02:13.733914: step 182670, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 9h:10m:16s remains)
INFO - root - 2017-12-17 02:02:15.945747: step 182680, loss = 0.42, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 9h:12m:29s remains)
INFO - root - 2017-12-17 02:02:18.162810: step 182690, loss = 0.43, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 9h:00m:51s remains)
INFO - root - 2017-12-17 02:02:20.371273: step 182700, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 9h:16m:02s remains)
INFO - root - 2017-12-17 02:02:22.757224: step 182710, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 9h:13m:19s remains)
INFO - root - 2017-12-17 02:02:25.005627: step 182720, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 9h:17m:21s remains)
INFO - root - 2017-12-17 02:02:27.216986: step 182730, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 9h:02m:31s remains)
INFO - root - 2017-12-17 02:02:29.457698: step 182740, loss = 0.47, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 9h:36m:17s remains)
INFO - root - 2017-12-17 02:02:31.681325: step 182750, loss = 0.56, batch loss = 0.38 (35.6 examples/sec; 0.225 sec/batch; 9h:21m:08s remains)
INFO - root - 2017-12-17 02:02:33.869619: step 182760, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 9h:00m:34s remains)
INFO - root - 2017-12-17 02:02:36.065847: step 182770, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 8h:59m:50s remains)
INFO - root - 2017-12-17 02:02:38.324397: step 182780, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 9h:06m:44s remains)
INFO - root - 2017-12-17 02:02:40.537518: step 182790, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.228 sec/batch; 9h:27m:40s remains)
INFO - root - 2017-12-17 02:02:42.743335: step 182800, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.224 sec/batch; 9h:20m:06s remains)
INFO - root - 2017-12-17 02:02:45.099252: step 182810, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.224 sec/batch; 9h:20m:00s remains)
INFO - root - 2017-12-17 02:02:47.329835: step 182820, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 9h:15m:46s remains)
INFO - root - 2017-12-17 02:02:49.541115: step 182830, loss = 0.52, batch loss = 0.34 (34.3 examples/sec; 0.233 sec/batch; 9h:41m:49s remains)
INFO - root - 2017-12-17 02:02:51.756844: step 182840, loss = 0.52, batch loss = 0.34 (34.5 examples/sec; 0.232 sec/batch; 9h:38m:09s remains)
INFO - root - 2017-12-17 02:02:53.986090: step 182850, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 8h:58m:34s remains)
INFO - root - 2017-12-17 02:02:56.207945: step 182860, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 9h:23m:51s remains)
INFO - root - 2017-12-17 02:02:58.420949: step 182870, loss = 0.47, batch loss = 0.29 (33.3 examples/sec; 0.240 sec/batch; 9h:58m:50s remains)
INFO - root - 2017-12-17 02:03:00.672704: step 182880, loss = 0.50, batch loss = 0.32 (33.8 examples/sec; 0.237 sec/batch; 9h:50m:22s remains)
INFO - root - 2017-12-17 02:03:02.917940: step 182890, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.221 sec/batch; 9h:12m:15s remains)
INFO - root - 2017-12-17 02:03:05.123360: step 182900, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 9h:06m:30s remains)
INFO - root - 2017-12-17 02:03:07.480874: step 182910, loss = 0.45, batch loss = 0.27 (34.0 examples/sec; 0.235 sec/batch; 9h:46m:07s remains)
INFO - root - 2017-12-17 02:03:09.687276: step 182920, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 9h:02m:34s remains)
INFO - root - 2017-12-17 02:03:11.883523: step 182930, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 9h:00m:58s remains)
INFO - root - 2017-12-17 02:03:14.101568: step 182940, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 9h:06m:39s remains)
INFO - root - 2017-12-17 02:03:16.317940: step 182950, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 9h:05m:29s remains)
INFO - root - 2017-12-17 02:03:18.557632: step 182960, loss = 0.42, batch loss = 0.24 (35.5 examples/sec; 0.225 sec/batch; 9h:20m:53s remains)
INFO - root - 2017-12-17 02:03:20.774807: step 182970, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 9h:05m:27s remains)
INFO - root - 2017-12-17 02:03:22.979332: step 182980, loss = 0.52, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 9h:14m:46s remains)
INFO - root - 2017-12-17 02:03:25.229493: step 182990, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 9h:18m:34s remains)
INFO - root - 2017-12-17 02:03:27.441956: step 183000, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 9h:13m:04s remains)
INFO - root - 2017-12-17 02:03:29.768411: step 183010, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 9h:02m:43s remains)
INFO - root - 2017-12-17 02:03:31.973644: step 183020, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 9h:14m:45s remains)
INFO - root - 2017-12-17 02:03:34.159281: step 183030, loss = 0.50, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 9h:19m:18s remains)
INFO - root - 2017-12-17 02:03:36.399920: step 183040, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 8h:59m:36s remains)
INFO - root - 2017-12-17 02:03:38.645312: step 183050, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 8h:57m:46s remains)
INFO - root - 2017-12-17 02:03:40.841396: step 183060, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 9h:12m:39s remains)
INFO - root - 2017-12-17 02:03:43.064140: step 183070, loss = 0.43, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 8h:55m:44s remains)
INFO - root - 2017-12-17 02:03:45.282979: step 183080, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 9h:16m:35s remains)
INFO - root - 2017-12-17 02:03:47.510355: step 183090, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 9h:13m:51s remains)
INFO - root - 2017-12-17 02:03:49.721224: step 183100, loss = 0.45, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 9h:08m:51s remains)
INFO - root - 2017-12-17 02:03:52.075670: step 183110, loss = 0.50, batch loss = 0.32 (33.7 examples/sec; 0.237 sec/batch; 9h:51m:18s remains)
INFO - root - 2017-12-17 02:03:54.329079: step 183120, loss = 0.46, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 9h:15m:10s remains)
INFO - root - 2017-12-17 02:03:56.498730: step 183130, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.218 sec/batch; 9h:01m:36s remains)
INFO - root - 2017-12-17 02:03:58.714331: step 183140, loss = 0.49, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 9h:08m:45s remains)
INFO - root - 2017-12-17 02:04:00.901223: step 183150, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 8h:55m:17s remains)
INFO - root - 2017-12-17 02:04:03.150578: step 183160, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 9h:05m:10s remains)
INFO - root - 2017-12-17 02:04:05.335005: step 183170, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 9h:09m:17s remains)
INFO - root - 2017-12-17 02:04:07.506723: step 183180, loss = 0.56, batch loss = 0.38 (36.8 examples/sec; 0.217 sec/batch; 9h:01m:12s remains)
INFO - root - 2017-12-17 02:04:09.737048: step 183190, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 9h:16m:15s remains)
INFO - root - 2017-12-17 02:04:11.972463: step 183200, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 9h:07m:37s remains)
INFO - root - 2017-12-17 02:04:14.316589: step 183210, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.226 sec/batch; 9h:23m:17s remains)
INFO - root - 2017-12-17 02:04:16.549262: step 183220, loss = 0.54, batch loss = 0.36 (36.4 examples/sec; 0.220 sec/batch; 9h:06m:15s remains)
INFO - root - 2017-12-17 02:04:18.757195: step 183230, loss = 0.51, batch loss = 0.33 (36.2 examples/sec; 0.221 sec/batch; 9h:10m:07s remains)
INFO - root - 2017-12-17 02:04:20.967967: step 183240, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 9h:13m:06s remains)
INFO - root - 2017-12-17 02:04:23.183852: step 183250, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 9h:07m:31s remains)
INFO - root - 2017-12-17 02:04:25.390726: step 183260, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 9h:24m:09s remains)
INFO - root - 2017-12-17 02:04:27.626127: step 183270, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 8h:54m:27s remains)
INFO - root - 2017-12-17 02:04:29.836394: step 183280, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 9h:05m:13s remains)
INFO - root - 2017-12-17 02:04:32.045472: step 183290, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.223 sec/batch; 9h:15m:06s remains)
INFO - root - 2017-12-17 02:04:34.292541: step 183300, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 9h:13m:13s remains)
INFO - root - 2017-12-17 02:04:36.666491: step 183310, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 9h:14m:54s remains)
INFO - root - 2017-12-17 02:04:38.864944: step 183320, loss = 0.54, batch loss = 0.36 (37.0 examples/sec; 0.216 sec/batch; 8h:56m:59s remains)
INFO - root - 2017-12-17 02:04:41.074784: step 183330, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 9h:01m:12s remains)
INFO - root - 2017-12-17 02:04:43.254746: step 183340, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 9h:13m:04s remains)
INFO - root - 2017-12-17 02:04:45.508916: step 183350, loss = 0.48, batch loss = 0.30 (34.4 examples/sec; 0.232 sec/batch; 9h:37m:22s remains)
INFO - root - 2017-12-17 02:04:47.779827: step 183360, loss = 0.53, batch loss = 0.35 (35.3 examples/sec; 0.227 sec/batch; 9h:24m:01s remains)
INFO - root - 2017-12-17 02:04:49.962436: step 183370, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 8h:46m:23s remains)
INFO - root - 2017-12-17 02:04:52.169708: step 183380, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 9h:11m:23s remains)
INFO - root - 2017-12-17 02:04:54.355460: step 183390, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 9h:05m:34s remains)
INFO - root - 2017-12-17 02:04:56.583571: step 183400, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 9h:11m:37s remains)
INFO - root - 2017-12-17 02:04:58.919759: step 183410, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 9h:12m:24s remains)
INFO - root - 2017-12-17 02:05:01.109060: step 183420, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 8h:49m:27s remains)
INFO - root - 2017-12-17 02:05:03.360121: step 183430, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 9h:21m:19s remains)
INFO - root - 2017-12-17 02:05:05.591414: step 183440, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 8h:59m:48s remains)
INFO - root - 2017-12-17 02:05:07.832488: step 183450, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 8h:51m:52s remains)
INFO - root - 2017-12-17 02:05:10.059786: step 183460, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 9h:28m:53s remains)
INFO - root - 2017-12-17 02:05:12.268850: step 183470, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 9h:23m:25s remains)
INFO - root - 2017-12-17 02:05:14.486980: step 183480, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 9h:06m:11s remains)
INFO - root - 2017-12-17 02:05:16.724658: step 183490, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 9h:06m:25s remains)
INFO - root - 2017-12-17 02:05:18.960967: step 183500, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 9h:31m:11s remains)
INFO - root - 2017-12-17 02:05:21.314478: step 183510, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 9h:01m:52s remains)
INFO - root - 2017-12-17 02:05:23.586393: step 183520, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 9h:06m:51s remains)
INFO - root - 2017-12-17 02:05:25.756040: step 183530, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 9h:18m:30s remains)
INFO - root - 2017-12-17 02:05:27.966723: step 183540, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 8h:59m:00s remains)
INFO - root - 2017-12-17 02:05:30.200782: step 183550, loss = 0.44, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 9h:22m:51s remains)
INFO - root - 2017-12-17 02:05:32.420283: step 183560, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 9h:10m:51s remains)
INFO - root - 2017-12-17 02:05:34.650111: step 183570, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 8h:58m:19s remains)
INFO - root - 2017-12-17 02:05:36.874894: step 183580, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 9h:00m:37s remains)
INFO - root - 2017-12-17 02:05:39.148528: step 183590, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 9h:18m:31s remains)
INFO - root - 2017-12-17 02:05:41.371222: step 183600, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 8h:58m:03s remains)
INFO - root - 2017-12-17 02:05:43.715713: step 183610, loss = 0.43, batch loss = 0.25 (37.0 examples/sec; 0.216 sec/batch; 8h:57m:06s remains)
INFO - root - 2017-12-17 02:05:45.957489: step 183620, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 9h:02m:18s remains)
INFO - root - 2017-12-17 02:05:48.161035: step 183630, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 8h:50m:51s remains)
INFO - root - 2017-12-17 02:05:50.372066: step 183640, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 8h:55m:04s remains)
INFO - root - 2017-12-17 02:05:52.587443: step 183650, loss = 0.51, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 9h:15m:32s remains)
INFO - root - 2017-12-17 02:05:54.777146: step 183660, loss = 0.50, batch loss = 0.32 (37.5 examples/sec; 0.213 sec/batch; 8h:48m:47s remains)
INFO - root - 2017-12-17 02:05:57.038663: step 183670, loss = 0.48, batch loss = 0.30 (36.6 examples/sec; 0.218 sec/batch; 9h:01m:47s remains)
INFO - root - 2017-12-17 02:05:59.250003: step 183680, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 9h:34m:38s remains)
INFO - root - 2017-12-17 02:06:01.468958: step 183690, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.224 sec/batch; 9h:16m:43s remains)
INFO - root - 2017-12-17 02:06:03.669156: step 183700, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 9h:09m:41s remains)
INFO - root - 2017-12-17 02:06:06.030008: step 183710, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 8h:53m:23s remains)
INFO - root - 2017-12-17 02:06:08.214717: step 183720, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 9h:03m:41s remains)
INFO - root - 2017-12-17 02:06:10.446175: step 183730, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 9h:17m:49s remains)
INFO - root - 2017-12-17 02:06:12.673071: step 183740, loss = 0.58, batch loss = 0.41 (35.7 examples/sec; 0.224 sec/batch; 9h:15m:20s remains)
INFO - root - 2017-12-17 02:06:14.908460: step 183750, loss = 0.44, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 9h:06m:57s remains)
INFO - root - 2017-12-17 02:06:17.098569: step 183760, loss = 0.51, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 8h:55m:50s remains)
INFO - root - 2017-12-17 02:06:19.296520: step 183770, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 9h:18m:48s remains)
INFO - root - 2017-12-17 02:06:21.569575: step 183780, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 9h:10m:31s remains)
INFO - root - 2017-12-17 02:06:23.811432: step 183790, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 9h:16m:34s remains)
INFO - root - 2017-12-17 02:06:26.032136: step 183800, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 9h:17m:08s remains)
INFO - root - 2017-12-17 02:06:28.351296: step 183810, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 9h:02m:48s remains)
INFO - root - 2017-12-17 02:06:30.607505: step 183820, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 8h:56m:38s remains)
INFO - root - 2017-12-17 02:06:32.813919: step 183830, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 9h:12m:50s remains)
INFO - root - 2017-12-17 02:06:35.037283: step 183840, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 9h:08m:34s remains)
INFO - root - 2017-12-17 02:06:37.246173: step 183850, loss = 0.50, batch loss = 0.32 (34.4 examples/sec; 0.232 sec/batch; 9h:35m:57s remains)
INFO - root - 2017-12-17 02:06:39.452415: step 183860, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 8h:52m:42s remains)
INFO - root - 2017-12-17 02:06:41.659557: step 183870, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.226 sec/batch; 9h:18m:36s remains)
INFO - root - 2017-12-17 02:06:43.854591: step 183880, loss = 0.44, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 9h:01m:03s remains)
INFO - root - 2017-12-17 02:06:46.077256: step 183890, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.221 sec/batch; 9h:06m:31s remains)
INFO - root - 2017-12-17 02:06:48.287014: step 183900, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 9h:04m:46s remains)
INFO - root - 2017-12-17 02:06:50.634766: step 183910, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 8h:49m:25s remains)
INFO - root - 2017-12-17 02:06:52.839059: step 183920, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 9h:12m:19s remains)
INFO - root - 2017-12-17 02:06:55.061075: step 183930, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 9h:14m:19s remains)
INFO - root - 2017-12-17 02:06:57.293775: step 183940, loss = 0.57, batch loss = 0.39 (35.6 examples/sec; 0.225 sec/batch; 9h:16m:21s remains)
INFO - root - 2017-12-17 02:06:59.504306: step 183950, loss = 0.55, batch loss = 0.37 (36.5 examples/sec; 0.219 sec/batch; 9h:02m:52s remains)
INFO - root - 2017-12-17 02:07:01.710913: step 183960, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.224 sec/batch; 9h:13m:41s remains)
INFO - root - 2017-12-17 02:07:03.940421: step 183970, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 9h:18m:07s remains)
INFO - root - 2017-12-17 02:07:06.181699: step 183980, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 9h:02m:55s remains)
INFO - root - 2017-12-17 02:07:08.420832: step 183990, loss = 0.48, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 9h:24m:52s remains)
INFO - root - 2017-12-17 02:07:10.670170: step 184000, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 9h:09m:58s remains)
INFO - root - 2017-12-17 02:07:13.019491: step 184010, loss = 0.53, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 8h:57m:49s remains)
INFO - root - 2017-12-17 02:07:15.185138: step 184020, loss = 0.48, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 9h:15m:15s remains)
INFO - root - 2017-12-17 02:07:17.390953: step 184030, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 9h:08m:58s remains)
INFO - root - 2017-12-17 02:07:19.608866: step 184040, loss = 0.53, batch loss = 0.35 (35.1 examples/sec; 0.228 sec/batch; 9h:23m:11s remains)
INFO - root - 2017-12-17 02:07:21.812972: step 184050, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 9h:02m:41s remains)
INFO - root - 2017-12-17 02:07:24.026678: step 184060, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 9h:15m:47s remains)
INFO - root - 2017-12-17 02:07:26.233848: step 184070, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 8h:54m:42s remains)
INFO - root - 2017-12-17 02:07:28.448401: step 184080, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 9h:18m:04s remains)
INFO - root - 2017-12-17 02:07:30.689634: step 184090, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 9h:21m:58s remains)
INFO - root - 2017-12-17 02:07:32.917490: step 184100, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 9h:08m:10s remains)
INFO - root - 2017-12-17 02:07:35.278422: step 184110, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 9h:28m:33s remains)
INFO - root - 2017-12-17 02:07:37.484521: step 184120, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 9h:03m:33s remains)
INFO - root - 2017-12-17 02:07:39.688788: step 184130, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 9h:17m:02s remains)
INFO - root - 2017-12-17 02:07:41.908302: step 184140, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 9h:05m:02s remains)
INFO - root - 2017-12-17 02:07:44.133137: step 184150, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 8h:58m:23s remains)
INFO - root - 2017-12-17 02:07:46.318618: step 184160, loss = 0.51, batch loss = 0.33 (37.9 examples/sec; 0.211 sec/batch; 8h:42m:14s remains)
INFO - root - 2017-12-17 02:07:48.527061: step 184170, loss = 0.43, batch loss = 0.25 (35.8 examples/sec; 0.223 sec/batch; 9h:11m:49s remains)
INFO - root - 2017-12-17 02:07:50.724300: step 184180, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 9h:11m:25s remains)
INFO - root - 2017-12-17 02:07:52.968953: step 184190, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 8h:58m:22s remains)
INFO - root - 2017-12-17 02:07:55.177312: step 184200, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 9h:17m:26s remains)
INFO - root - 2017-12-17 02:07:57.543382: step 184210, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 9h:29m:42s remains)
INFO - root - 2017-12-17 02:07:59.790160: step 184220, loss = 0.47, batch loss = 0.29 (34.3 examples/sec; 0.233 sec/batch; 9h:35m:49s remains)
INFO - root - 2017-12-17 02:08:02.020857: step 184230, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 9h:26m:47s remains)
INFO - root - 2017-12-17 02:08:04.261562: step 184240, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 9h:05m:53s remains)
INFO - root - 2017-12-17 02:08:06.496271: step 184250, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 9h:14m:57s remains)
INFO - root - 2017-12-17 02:08:08.718692: step 184260, loss = 0.55, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 9h:03m:27s remains)
INFO - root - 2017-12-17 02:08:10.925838: step 184270, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 9h:04m:30s remains)
INFO - root - 2017-12-17 02:08:13.141293: step 184280, loss = 0.45, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 9h:14m:07s remains)
INFO - root - 2017-12-17 02:08:15.335165: step 184290, loss = 0.42, batch loss = 0.24 (37.2 examples/sec; 0.215 sec/batch; 8h:50m:48s remains)
INFO - root - 2017-12-17 02:08:17.536796: step 184300, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 9h:13m:37s remains)
INFO - root - 2017-12-17 02:08:19.912664: step 184310, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 9h:12m:29s remains)
INFO - root - 2017-12-17 02:08:22.133065: step 184320, loss = 0.44, batch loss = 0.26 (37.8 examples/sec; 0.212 sec/batch; 8h:42m:47s remains)
INFO - root - 2017-12-17 02:08:24.325699: step 184330, loss = 0.51, batch loss = 0.33 (36.1 examples/sec; 0.222 sec/batch; 9h:07m:16s remains)
INFO - root - 2017-12-17 02:08:26.571094: step 184340, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 8h:55m:40s remains)
INFO - root - 2017-12-17 02:08:28.774683: step 184350, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 8h:59m:32s remains)
INFO - root - 2017-12-17 02:08:31.003992: step 184360, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 9h:07m:54s remains)
INFO - root - 2017-12-17 02:08:33.223235: step 184370, loss = 0.51, batch loss = 0.33 (35.2 examples/sec; 0.227 sec/batch; 9h:20m:31s remains)
INFO - root - 2017-12-17 02:08:35.398922: step 184380, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 9h:07m:51s remains)
INFO - root - 2017-12-17 02:08:37.641467: step 184390, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.230 sec/batch; 9h:28m:54s remains)
INFO - root - 2017-12-17 02:08:39.850036: step 184400, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 9h:07m:14s remains)
INFO - root - 2017-12-17 02:08:42.175663: step 184410, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 8h:52m:00s remains)
INFO - root - 2017-12-17 02:08:44.396584: step 184420, loss = 0.46, batch loss = 0.29 (33.9 examples/sec; 0.236 sec/batch; 9h:41m:53s remains)
INFO - root - 2017-12-17 02:08:46.628166: step 184430, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 9h:21m:22s remains)
INFO - root - 2017-12-17 02:08:48.838402: step 184440, loss = 0.47, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 8h:45m:34s remains)
INFO - root - 2017-12-17 02:08:51.032339: step 184450, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 9h:04m:38s remains)
INFO - root - 2017-12-17 02:08:53.240719: step 184460, loss = 0.48, batch loss = 0.30 (34.6 examples/sec; 0.231 sec/batch; 9h:30m:45s remains)
INFO - root - 2017-12-17 02:08:55.457463: step 184470, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 8h:58m:03s remains)
INFO - root - 2017-12-17 02:08:57.648940: step 184480, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 9h:12m:38s remains)
INFO - root - 2017-12-17 02:08:59.874361: step 184490, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 9h:26m:48s remains)
INFO - root - 2017-12-17 02:09:02.065315: step 184500, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 9h:01m:34s remains)
INFO - root - 2017-12-17 02:09:04.397779: step 184510, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 8h:51m:09s remains)
INFO - root - 2017-12-17 02:09:06.617486: step 184520, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 8h:52m:33s remains)
INFO - root - 2017-12-17 02:09:08.876105: step 184530, loss = 0.50, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 9h:19m:17s remains)
INFO - root - 2017-12-17 02:09:11.073898: step 184540, loss = 0.47, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 9h:09m:30s remains)
INFO - root - 2017-12-17 02:09:13.276322: step 184550, loss = 0.48, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 9h:11m:55s remains)
INFO - root - 2017-12-17 02:09:15.502255: step 184560, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 9h:04m:19s remains)
INFO - root - 2017-12-17 02:09:17.677771: step 184570, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 8h:57m:21s remains)
INFO - root - 2017-12-17 02:09:19.885735: step 184580, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 9h:08m:50s remains)
INFO - root - 2017-12-17 02:09:22.074329: step 184590, loss = 0.54, batch loss = 0.36 (37.5 examples/sec; 0.214 sec/batch; 8h:46m:22s remains)
INFO - root - 2017-12-17 02:09:24.285868: step 184600, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 8h:50m:32s remains)
INFO - root - 2017-12-17 02:09:26.598425: step 184610, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 8h:54m:29s remains)
INFO - root - 2017-12-17 02:09:28.795500: step 184620, loss = 0.43, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 9h:17m:33s remains)
INFO - root - 2017-12-17 02:09:30.992074: step 184630, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 9h:07m:42s remains)
INFO - root - 2017-12-17 02:09:33.257960: step 184640, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 9h:16m:06s remains)
INFO - root - 2017-12-17 02:09:35.508538: step 184650, loss = 0.46, batch loss = 0.28 (37.3 examples/sec; 0.215 sec/batch; 8h:49m:02s remains)
INFO - root - 2017-12-17 02:09:37.729966: step 184660, loss = 0.43, batch loss = 0.26 (34.4 examples/sec; 0.232 sec/batch; 9h:32m:15s remains)
INFO - root - 2017-12-17 02:09:39.966269: step 184670, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 9h:11m:23s remains)
INFO - root - 2017-12-17 02:09:42.160467: step 184680, loss = 0.48, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 9h:06m:00s remains)
INFO - root - 2017-12-17 02:09:44.348696: step 184690, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 9h:01m:09s remains)
INFO - root - 2017-12-17 02:09:46.557990: step 184700, loss = 0.55, batch loss = 0.37 (36.6 examples/sec; 0.218 sec/batch; 8h:58m:01s remains)
INFO - root - 2017-12-17 02:09:48.892781: step 184710, loss = 0.51, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 9h:09m:21s remains)
INFO - root - 2017-12-17 02:09:51.115012: step 184720, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 8h:56m:32s remains)
INFO - root - 2017-12-17 02:09:53.370812: step 184730, loss = 0.42, batch loss = 0.24 (33.4 examples/sec; 0.239 sec/batch; 9h:49m:21s remains)
INFO - root - 2017-12-17 02:09:55.607942: step 184740, loss = 0.47, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 8h:43m:12s remains)
INFO - root - 2017-12-17 02:09:57.830266: step 184750, loss = 0.55, batch loss = 0.37 (37.0 examples/sec; 0.216 sec/batch; 8h:53m:05s remains)
INFO - root - 2017-12-17 02:10:00.050311: step 184760, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 8h:59m:59s remains)
INFO - root - 2017-12-17 02:10:02.251262: step 184770, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 8h:56m:38s remains)
INFO - root - 2017-12-17 02:10:04.459025: step 184780, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 9h:08m:39s remains)
INFO - root - 2017-12-17 02:10:06.691518: step 184790, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 9h:02m:38s remains)
INFO - root - 2017-12-17 02:10:08.913412: step 184800, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 8h:59m:16s remains)
INFO - root - 2017-12-17 02:10:11.280406: step 184810, loss = 0.51, batch loss = 0.34 (33.8 examples/sec; 0.236 sec/batch; 9h:41m:50s remains)
INFO - root - 2017-12-17 02:10:13.504242: step 184820, loss = 0.45, batch loss = 0.27 (34.2 examples/sec; 0.234 sec/batch; 9h:35m:57s remains)
INFO - root - 2017-12-17 02:10:15.706788: step 184830, loss = 0.58, batch loss = 0.40 (37.1 examples/sec; 0.216 sec/batch; 8h:51m:15s remains)
INFO - root - 2017-12-17 02:10:17.954015: step 184840, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 9h:14m:51s remains)
INFO - root - 2017-12-17 02:10:20.183560: step 184850, loss = 0.51, batch loss = 0.33 (37.4 examples/sec; 0.214 sec/batch; 8h:46m:00s remains)
INFO - root - 2017-12-17 02:10:22.374475: step 184860, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 9h:01m:08s remains)
INFO - root - 2017-12-17 02:10:24.582712: step 184870, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 9h:16m:58s remains)
INFO - root - 2017-12-17 02:10:26.823125: step 184880, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 9h:03m:55s remains)
INFO - root - 2017-12-17 02:10:29.061130: step 184890, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 9h:01m:52s remains)
INFO - root - 2017-12-17 02:10:31.259259: step 184900, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 9h:04m:58s remains)
INFO - root - 2017-12-17 02:10:33.625113: step 184910, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 9h:16m:06s remains)
INFO - root - 2017-12-17 02:10:35.853597: step 184920, loss = 0.50, batch loss = 0.33 (34.1 examples/sec; 0.234 sec/batch; 9h:36m:19s remains)
INFO - root - 2017-12-17 02:10:38.130199: step 184930, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 9h:11m:24s remains)
INFO - root - 2017-12-17 02:10:40.324955: step 184940, loss = 0.46, batch loss = 0.29 (37.7 examples/sec; 0.212 sec/batch; 8h:42m:13s remains)
INFO - root - 2017-12-17 02:10:42.493733: step 184950, loss = 0.44, batch loss = 0.26 (35.5 examples/sec; 0.226 sec/batch; 9h:14m:37s remains)
INFO - root - 2017-12-17 02:10:44.746439: step 184960, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 9h:10m:51s remains)
INFO - root - 2017-12-17 02:10:46.975078: step 184970, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 9h:05m:35s remains)
INFO - root - 2017-12-17 02:10:49.194853: step 184980, loss = 0.44, batch loss = 0.26 (34.2 examples/sec; 0.234 sec/batch; 9h:35m:26s remains)
INFO - root - 2017-12-17 02:10:51.402517: step 184990, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 9h:00m:43s remains)
INFO - root - 2017-12-17 02:10:53.592098: step 185000, loss = 0.47, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 9h:34m:18s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-185000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-185000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 02:10:56.325437: step 185010, loss = 0.48, batch loss = 0.31 (37.5 examples/sec; 0.214 sec/batch; 8h:44m:53s remains)
INFO - root - 2017-12-17 02:10:58.515605: step 185020, loss = 0.51, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 9h:12m:24s remains)
INFO - root - 2017-12-17 02:11:00.753062: step 185030, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 8h:43m:00s remains)
INFO - root - 2017-12-17 02:11:02.979658: step 185040, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 8h:50m:25s remains)
INFO - root - 2017-12-17 02:11:05.185908: step 185050, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 9h:00m:36s remains)
INFO - root - 2017-12-17 02:11:07.386190: step 185060, loss = 0.47, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 8h:49m:03s remains)
INFO - root - 2017-12-17 02:11:09.629252: step 185070, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 9h:12m:20s remains)
INFO - root - 2017-12-17 02:11:11.847675: step 185080, loss = 0.45, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 8h:59m:51s remains)
INFO - root - 2017-12-17 02:11:14.028874: step 185090, loss = 0.44, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 8h:58m:05s remains)
INFO - root - 2017-12-17 02:11:16.251015: step 185100, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 8h:50m:51s remains)
INFO - root - 2017-12-17 02:11:18.568286: step 185110, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 8h:46m:50s remains)
INFO - root - 2017-12-17 02:11:20.766663: step 185120, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 9h:00m:43s remains)
INFO - root - 2017-12-17 02:11:22.987930: step 185130, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 9h:21m:47s remains)
INFO - root - 2017-12-17 02:11:25.186447: step 185140, loss = 0.43, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 9h:05m:31s remains)
INFO - root - 2017-12-17 02:11:27.409277: step 185150, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 9h:08m:26s remains)
INFO - root - 2017-12-17 02:11:29.605665: step 185160, loss = 0.44, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 8h:52m:42s remains)
INFO - root - 2017-12-17 02:11:31.831105: step 185170, loss = 0.51, batch loss = 0.33 (35.3 examples/sec; 0.227 sec/batch; 9h:16m:21s remains)
INFO - root - 2017-12-17 02:11:34.009387: step 185180, loss = 0.51, batch loss = 0.33 (37.3 examples/sec; 0.214 sec/batch; 8h:45m:58s remains)
INFO - root - 2017-12-17 02:11:36.201269: step 185190, loss = 0.48, batch loss = 0.31 (37.5 examples/sec; 0.213 sec/batch; 8h:43m:39s remains)
INFO - root - 2017-12-17 02:11:38.461228: step 185200, loss = 0.58, batch loss = 0.40 (36.8 examples/sec; 0.218 sec/batch; 8h:54m:10s remains)
INFO - root - 2017-12-17 02:11:40.811814: step 185210, loss = 0.53, batch loss = 0.35 (36.2 examples/sec; 0.221 sec/batch; 9h:02m:34s remains)
INFO - root - 2017-12-17 02:11:43.037827: step 185220, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 9h:14m:53s remains)
INFO - root - 2017-12-17 02:11:45.232115: step 185230, loss = 0.47, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 9h:14m:11s remains)
INFO - root - 2017-12-17 02:11:47.498868: step 185240, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 9h:05m:00s remains)
INFO - root - 2017-12-17 02:11:49.685820: step 185250, loss = 0.50, batch loss = 0.32 (35.0 examples/sec; 0.229 sec/batch; 9h:21m:39s remains)
INFO - root - 2017-12-17 02:11:51.919138: step 185260, loss = 0.45, batch loss = 0.28 (37.7 examples/sec; 0.212 sec/batch; 8h:41m:14s remains)
INFO - root - 2017-12-17 02:11:54.148234: step 185270, loss = 0.46, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 9h:18m:38s remains)
INFO - root - 2017-12-17 02:11:56.319644: step 185280, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 8h:51m:22s remains)
INFO - root - 2017-12-17 02:11:58.545190: step 185290, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 8h:58m:52s remains)
INFO - root - 2017-12-17 02:12:00.779166: step 185300, loss = 0.49, batch loss = 0.31 (34.9 examples/sec; 0.230 sec/batch; 9h:23m:04s remains)
INFO - root - 2017-12-17 02:12:03.136791: step 185310, loss = 0.51, batch loss = 0.33 (34.5 examples/sec; 0.232 sec/batch; 9h:29m:16s remains)
INFO - root - 2017-12-17 02:12:05.378189: step 185320, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 8h:58m:08s remains)
INFO - root - 2017-12-17 02:12:07.567319: step 185330, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.226 sec/batch; 9h:15m:11s remains)
INFO - root - 2017-12-17 02:12:09.825790: step 185340, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 8h:50m:41s remains)
INFO - root - 2017-12-17 02:12:12.056561: step 185350, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 9h:02m:13s remains)
INFO - root - 2017-12-17 02:12:14.298034: step 185360, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 8h:56m:22s remains)
INFO - root - 2017-12-17 02:12:16.501362: step 185370, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 8h:57m:59s remains)
INFO - root - 2017-12-17 02:12:18.712763: step 185380, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 8h:55m:08s remains)
INFO - root - 2017-12-17 02:12:20.925100: step 185390, loss = 0.47, batch loss = 0.30 (35.0 examples/sec; 0.229 sec/batch; 9h:20m:35s remains)
INFO - root - 2017-12-17 02:12:23.162355: step 185400, loss = 0.50, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 8h:50m:00s remains)
INFO - root - 2017-12-17 02:12:25.503066: step 185410, loss = 0.41, batch loss = 0.23 (35.5 examples/sec; 0.226 sec/batch; 9h:12m:57s remains)
INFO - root - 2017-12-17 02:12:27.740231: step 185420, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 9h:12m:39s remains)
INFO - root - 2017-12-17 02:12:29.960727: step 185430, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 9h:03m:49s remains)
INFO - root - 2017-12-17 02:12:32.212715: step 185440, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 9h:11m:38s remains)
INFO - root - 2017-12-17 02:12:34.416189: step 185450, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 8h:40m:48s remains)
INFO - root - 2017-12-17 02:12:36.615446: step 185460, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 8h:49m:55s remains)
INFO - root - 2017-12-17 02:12:38.813935: step 185470, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 8h:54m:06s remains)
INFO - root - 2017-12-17 02:12:41.066215: step 185480, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 9h:01m:01s remains)
INFO - root - 2017-12-17 02:12:43.298217: step 185490, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 9h:07m:50s remains)
INFO - root - 2017-12-17 02:12:45.489482: step 185500, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 8h:53m:39s remains)
INFO - root - 2017-12-17 02:12:47.807926: step 185510, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 9h:03m:15s remains)
INFO - root - 2017-12-17 02:12:50.028479: step 185520, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 8h:59m:09s remains)
INFO - root - 2017-12-17 02:12:52.241918: step 185530, loss = 0.45, batch loss = 0.27 (31.6 examples/sec; 0.253 sec/batch; 10h:19m:12s remains)
INFO - root - 2017-12-17 02:12:54.506216: step 185540, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 8h:58m:27s remains)
INFO - root - 2017-12-17 02:12:56.701624: step 185550, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 8h:44m:51s remains)
INFO - root - 2017-12-17 02:12:58.910576: step 185560, loss = 0.45, batch loss = 0.27 (34.3 examples/sec; 0.234 sec/batch; 9h:31m:53s remains)
INFO - root - 2017-12-17 02:13:01.107087: step 185570, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 8h:57m:13s remains)
INFO - root - 2017-12-17 02:13:03.319096: step 185580, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 8h:59m:54s remains)
INFO - root - 2017-12-17 02:13:05.558313: step 185590, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 8h:59m:39s remains)
INFO - root - 2017-12-17 02:13:07.824486: step 185600, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.228 sec/batch; 9h:17m:01s remains)
INFO - root - 2017-12-17 02:13:10.175892: step 185610, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 8h:43m:49s remains)
INFO - root - 2017-12-17 02:13:12.411688: step 185620, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 9h:07m:08s remains)
INFO - root - 2017-12-17 02:13:14.629440: step 185630, loss = 0.49, batch loss = 0.31 (34.2 examples/sec; 0.234 sec/batch; 9h:32m:39s remains)
INFO - root - 2017-12-17 02:13:16.823227: step 185640, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.226 sec/batch; 9h:12m:05s remains)
INFO - root - 2017-12-17 02:13:19.063334: step 185650, loss = 0.56, batch loss = 0.38 (37.0 examples/sec; 0.216 sec/batch; 8h:49m:13s remains)
INFO - root - 2017-12-17 02:13:21.289807: step 185660, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 9h:09m:02s remains)
INFO - root - 2017-12-17 02:13:23.488867: step 185670, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 8h:51m:17s remains)
INFO - root - 2017-12-17 02:13:25.736126: step 185680, loss = 0.48, batch loss = 0.31 (37.5 examples/sec; 0.214 sec/batch; 8h:42m:33s remains)
INFO - root - 2017-12-17 02:13:27.981612: step 185690, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 9h:07m:25s remains)
INFO - root - 2017-12-17 02:13:30.190759: step 185700, loss = 0.50, batch loss = 0.32 (34.3 examples/sec; 0.233 sec/batch; 9h:30m:44s remains)
INFO - root - 2017-12-17 02:13:32.553826: step 185710, loss = 0.54, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 8h:50m:01s remains)
INFO - root - 2017-12-17 02:13:34.774610: step 185720, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 8h:46m:25s remains)
INFO - root - 2017-12-17 02:13:37.035966: step 185730, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 9h:01m:04s remains)
INFO - root - 2017-12-17 02:13:39.264936: step 185740, loss = 0.42, batch loss = 0.24 (36.4 examples/sec; 0.220 sec/batch; 8h:57m:38s remains)
INFO - root - 2017-12-17 02:13:41.526280: step 185750, loss = 0.51, batch loss = 0.33 (34.4 examples/sec; 0.233 sec/batch; 9h:28m:49s remains)
INFO - root - 2017-12-17 02:13:43.769728: step 185760, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 8h:56m:06s remains)
INFO - root - 2017-12-17 02:13:45.964215: step 185770, loss = 0.49, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 9h:17m:31s remains)
INFO - root - 2017-12-17 02:13:48.154524: step 185780, loss = 0.49, batch loss = 0.31 (37.0 examples/sec; 0.216 sec/batch; 8h:48m:21s remains)
INFO - root - 2017-12-17 02:13:50.334819: step 185790, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 8h:43m:38s remains)
INFO - root - 2017-12-17 02:13:52.574379: step 185800, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.226 sec/batch; 9h:13m:34s remains)
INFO - root - 2017-12-17 02:13:54.944724: step 185810, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 9h:13m:51s remains)
INFO - root - 2017-12-17 02:13:57.170181: step 185820, loss = 0.50, batch loss = 0.32 (34.1 examples/sec; 0.235 sec/batch; 9h:33m:51s remains)
INFO - root - 2017-12-17 02:13:59.365035: step 185830, loss = 0.46, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 8h:52m:11s remains)
INFO - root - 2017-12-17 02:14:01.608290: step 185840, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 8h:56m:04s remains)
INFO - root - 2017-12-17 02:14:03.823830: step 185850, loss = 0.42, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 9h:02m:05s remains)
INFO - root - 2017-12-17 02:14:06.057055: step 185860, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 8h:48m:45s remains)
INFO - root - 2017-12-17 02:14:08.261019: step 185870, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 9h:02m:39s remains)
INFO - root - 2017-12-17 02:14:10.436631: step 185880, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 8h:56m:55s remains)
INFO - root - 2017-12-17 02:14:12.658832: step 185890, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 9h:22m:08s remains)
INFO - root - 2017-12-17 02:14:14.880599: step 185900, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 8h:54m:05s remains)
INFO - root - 2017-12-17 02:14:17.211808: step 185910, loss = 0.56, batch loss = 0.38 (36.4 examples/sec; 0.220 sec/batch; 8h:57m:33s remains)
INFO - root - 2017-12-17 02:14:19.420106: step 185920, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 8h:54m:54s remains)
INFO - root - 2017-12-17 02:14:21.618644: step 185930, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 8h:51m:52s remains)
INFO - root - 2017-12-17 02:14:23.825578: step 185940, loss = 0.47, batch loss = 0.29 (34.4 examples/sec; 0.233 sec/batch; 9h:28m:20s remains)
INFO - root - 2017-12-17 02:14:26.025967: step 185950, loss = 0.55, batch loss = 0.37 (36.7 examples/sec; 0.218 sec/batch; 8h:51m:44s remains)
INFO - root - 2017-12-17 02:14:28.233082: step 185960, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 9h:11m:51s remains)
INFO - root - 2017-12-17 02:14:30.450667: step 185970, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 9h:11m:11s remains)
INFO - root - 2017-12-17 02:14:32.663670: step 185980, loss = 0.43, batch loss = 0.25 (34.9 examples/sec; 0.229 sec/batch; 9h:19m:16s remains)
INFO - root - 2017-12-17 02:14:34.873283: step 185990, loss = 0.45, batch loss = 0.28 (36.8 examples/sec; 0.218 sec/batch; 8h:51m:15s remains)
INFO - root - 2017-12-17 02:14:37.100242: step 186000, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 8h:57m:41s remains)
INFO - root - 2017-12-17 02:14:39.471754: step 186010, loss = 0.52, batch loss = 0.34 (37.1 examples/sec; 0.216 sec/batch; 8h:47m:10s remains)
INFO - root - 2017-12-17 02:14:41.695189: step 186020, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 9h:10m:41s remains)
INFO - root - 2017-12-17 02:14:43.933187: step 186030, loss = 0.54, batch loss = 0.36 (35.2 examples/sec; 0.227 sec/batch; 9h:14m:30s remains)
INFO - root - 2017-12-17 02:14:46.184034: step 186040, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 9h:14m:40s remains)
INFO - root - 2017-12-17 02:14:48.413803: step 186050, loss = 0.47, batch loss = 0.29 (37.6 examples/sec; 0.213 sec/batch; 8h:39m:10s remains)
INFO - root - 2017-12-17 02:14:50.634950: step 186060, loss = 0.44, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 9h:00m:59s remains)
INFO - root - 2017-12-17 02:14:52.858914: step 186070, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 9h:10m:50s remains)
INFO - root - 2017-12-17 02:14:55.063897: step 186080, loss = 0.43, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 9h:08m:08s remains)
INFO - root - 2017-12-17 02:14:57.243917: step 186090, loss = 0.50, batch loss = 0.33 (37.7 examples/sec; 0.212 sec/batch; 8h:37m:57s remains)
INFO - root - 2017-12-17 02:14:59.434834: step 186100, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 9h:03m:53s remains)
INFO - root - 2017-12-17 02:15:01.799137: step 186110, loss = 0.52, batch loss = 0.34 (35.8 examples/sec; 0.224 sec/batch; 9h:05m:20s remains)
INFO - root - 2017-12-17 02:15:04.012274: step 186120, loss = 0.49, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 8h:55m:21s remains)
INFO - root - 2017-12-17 02:15:06.236911: step 186130, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 8h:39m:33s remains)
INFO - root - 2017-12-17 02:15:08.474841: step 186140, loss = 0.45, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 8h:53m:22s remains)
INFO - root - 2017-12-17 02:15:10.651814: step 186150, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 8h:48m:07s remains)
INFO - root - 2017-12-17 02:15:12.873581: step 186160, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 8h:54m:14s remains)
INFO - root - 2017-12-17 02:15:15.109485: step 186170, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 8h:54m:26s remains)
INFO - root - 2017-12-17 02:15:17.351930: step 186180, loss = 0.53, batch loss = 0.35 (35.0 examples/sec; 0.229 sec/batch; 9h:17m:40s remains)
INFO - root - 2017-12-17 02:15:19.621703: step 186190, loss = 0.44, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 9h:13m:28s remains)
INFO - root - 2017-12-17 02:15:21.850680: step 186200, loss = 0.45, batch loss = 0.27 (37.3 examples/sec; 0.214 sec/batch; 8h:42m:42s remains)
INFO - root - 2017-12-17 02:15:24.278540: step 186210, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 8h:48m:57s remains)
INFO - root - 2017-12-17 02:15:26.473692: step 186220, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 8h:49m:53s remains)
INFO - root - 2017-12-17 02:15:28.678093: step 186230, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 8h:41m:42s remains)
INFO - root - 2017-12-17 02:15:30.920588: step 186240, loss = 0.51, batch loss = 0.33 (34.9 examples/sec; 0.229 sec/batch; 9h:18m:34s remains)
INFO - root - 2017-12-17 02:15:33.138023: step 186250, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 8h:52m:37s remains)
INFO - root - 2017-12-17 02:15:35.353648: step 186260, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 8h:46m:05s remains)
INFO - root - 2017-12-17 02:15:37.618900: step 186270, loss = 0.46, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 9h:02m:31s remains)
INFO - root - 2017-12-17 02:15:39.847775: step 186280, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 9h:15m:01s remains)
INFO - root - 2017-12-17 02:15:42.079225: step 186290, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 9h:13m:40s remains)
INFO - root - 2017-12-17 02:15:44.283177: step 186300, loss = 0.52, batch loss = 0.34 (34.2 examples/sec; 0.234 sec/batch; 9h:30m:30s remains)
INFO - root - 2017-12-17 02:15:46.601606: step 186310, loss = 0.52, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 8h:49m:34s remains)
INFO - root - 2017-12-17 02:15:48.814972: step 186320, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 9h:24m:18s remains)
INFO - root - 2017-12-17 02:15:51.032120: step 186330, loss = 0.48, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 9h:14m:09s remains)
INFO - root - 2017-12-17 02:15:53.243024: step 186340, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 8h:56m:33s remains)
INFO - root - 2017-12-17 02:15:55.447048: step 186350, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 9h:19m:31s remains)
INFO - root - 2017-12-17 02:15:57.689363: step 186360, loss = 0.47, batch loss = 0.29 (34.5 examples/sec; 0.232 sec/batch; 9h:25m:14s remains)
INFO - root - 2017-12-17 02:15:59.895838: step 186370, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 8h:48m:03s remains)
INFO - root - 2017-12-17 02:16:02.102309: step 186380, loss = 0.46, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 9h:17m:52s remains)
INFO - root - 2017-12-17 02:16:04.348158: step 186390, loss = 0.52, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 8h:59m:49s remains)
INFO - root - 2017-12-17 02:16:06.530881: step 186400, loss = 0.52, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 9h:06m:41s remains)
INFO - root - 2017-12-17 02:16:08.920587: step 186410, loss = 0.51, batch loss = 0.34 (37.5 examples/sec; 0.213 sec/batch; 8h:38m:52s remains)
INFO - root - 2017-12-17 02:16:11.126972: step 186420, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 8h:48m:50s remains)
INFO - root - 2017-12-17 02:16:13.382208: step 186430, loss = 0.53, batch loss = 0.35 (33.9 examples/sec; 0.236 sec/batch; 9h:34m:51s remains)
INFO - root - 2017-12-17 02:16:15.634113: step 186440, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 9h:15m:14s remains)
INFO - root - 2017-12-17 02:16:17.872434: step 186450, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 8h:50m:47s remains)
INFO - root - 2017-12-17 02:16:20.118040: step 186460, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 8h:59m:36s remains)
INFO - root - 2017-12-17 02:16:22.334038: step 186470, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 8h:48m:55s remains)
INFO - root - 2017-12-17 02:16:24.569326: step 186480, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 8h:52m:19s remains)
INFO - root - 2017-12-17 02:16:26.821043: step 186490, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.226 sec/batch; 9h:09m:09s remains)
INFO - root - 2017-12-17 02:16:29.017721: step 186500, loss = 0.45, batch loss = 0.27 (37.5 examples/sec; 0.213 sec/batch; 8h:38m:46s remains)
INFO - root - 2017-12-17 02:16:31.364149: step 186510, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 9h:08m:03s remains)
INFO - root - 2017-12-17 02:16:33.561707: step 186520, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 8h:51m:39s remains)
INFO - root - 2017-12-17 02:16:35.774953: step 186530, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 9h:07m:08s remains)
INFO - root - 2017-12-17 02:16:37.999447: step 186540, loss = 0.42, batch loss = 0.25 (35.2 examples/sec; 0.227 sec/batch; 9h:12m:44s remains)
INFO - root - 2017-12-17 02:16:40.223029: step 186550, loss = 0.54, batch loss = 0.37 (36.9 examples/sec; 0.217 sec/batch; 8h:47m:56s remains)
INFO - root - 2017-12-17 02:16:42.420165: step 186560, loss = 0.51, batch loss = 0.33 (34.9 examples/sec; 0.229 sec/batch; 9h:17m:50s remains)
INFO - root - 2017-12-17 02:16:44.642496: step 186570, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 8h:54m:39s remains)
INFO - root - 2017-12-17 02:16:46.857047: step 186580, loss = 0.44, batch loss = 0.27 (34.1 examples/sec; 0.235 sec/batch; 9h:30m:50s remains)
INFO - root - 2017-12-17 02:16:49.069124: step 186590, loss = 0.52, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 9h:12m:45s remains)
INFO - root - 2017-12-17 02:16:51.325659: step 186600, loss = 0.47, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 9h:17m:56s remains)
INFO - root - 2017-12-17 02:16:53.693547: step 186610, loss = 0.50, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 8h:45m:16s remains)
INFO - root - 2017-12-17 02:16:55.902707: step 186620, loss = 0.43, batch loss = 0.25 (37.1 examples/sec; 0.216 sec/batch; 8h:44m:27s remains)
INFO - root - 2017-12-17 02:16:58.125192: step 186630, loss = 0.45, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 8h:48m:31s remains)
INFO - root - 2017-12-17 02:17:00.296149: step 186640, loss = 0.47, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 8h:49m:57s remains)
INFO - root - 2017-12-17 02:17:02.525154: step 186650, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 9h:01m:41s remains)
INFO - root - 2017-12-17 02:17:04.755029: step 186660, loss = 0.56, batch loss = 0.38 (37.3 examples/sec; 0.215 sec/batch; 8h:41m:59s remains)
INFO - root - 2017-12-17 02:17:07.021924: step 186670, loss = 0.55, batch loss = 0.38 (35.7 examples/sec; 0.224 sec/batch; 9h:04m:30s remains)
INFO - root - 2017-12-17 02:17:09.226891: step 186680, loss = 0.41, batch loss = 0.23 (35.8 examples/sec; 0.223 sec/batch; 9h:02m:32s remains)
INFO - root - 2017-12-17 02:17:11.442763: step 186690, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 8h:55m:39s remains)
INFO - root - 2017-12-17 02:17:13.640362: step 186700, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 8h:57m:33s remains)
INFO - root - 2017-12-17 02:17:15.978587: step 186710, loss = 0.46, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 9h:06m:42s remains)
INFO - root - 2017-12-17 02:17:18.202705: step 186720, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 9h:02m:45s remains)
INFO - root - 2017-12-17 02:17:20.436716: step 186730, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 9h:08m:57s remains)
INFO - root - 2017-12-17 02:17:22.647832: step 186740, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 9h:11m:56s remains)
INFO - root - 2017-12-17 02:17:24.868333: step 186750, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 8h:47m:07s remains)
INFO - root - 2017-12-17 02:17:27.066764: step 186760, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 8h:46m:19s remains)
INFO - root - 2017-12-17 02:17:29.263673: step 186770, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 8h:56m:56s remains)
INFO - root - 2017-12-17 02:17:31.496240: step 186780, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 8h:44m:55s remains)
INFO - root - 2017-12-17 02:17:33.689947: step 186790, loss = 0.54, batch loss = 0.36 (36.2 examples/sec; 0.221 sec/batch; 8h:56m:38s remains)
INFO - root - 2017-12-17 02:17:35.875553: step 186800, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 8h:51m:34s remains)
INFO - root - 2017-12-17 02:17:38.248051: step 186810, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 8h:44m:12s remains)
INFO - root - 2017-12-17 02:17:40.434530: step 186820, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 8h:50m:43s remains)
INFO - root - 2017-12-17 02:17:42.631919: step 186830, loss = 0.50, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 9h:02m:59s remains)
INFO - root - 2017-12-17 02:17:44.797595: step 186840, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 8h:45m:11s remains)
INFO - root - 2017-12-17 02:17:47.033081: step 186850, loss = 0.56, batch loss = 0.38 (35.6 examples/sec; 0.225 sec/batch; 9h:05m:03s remains)
INFO - root - 2017-12-17 02:17:49.227833: step 186860, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 8h:41m:58s remains)
INFO - root - 2017-12-17 02:17:51.452680: step 186870, loss = 0.47, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 8h:52m:28s remains)
INFO - root - 2017-12-17 02:17:53.671840: step 186880, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 8h:55m:40s remains)
INFO - root - 2017-12-17 02:17:55.849908: step 186890, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 8h:47m:32s remains)
INFO - root - 2017-12-17 02:17:58.068589: step 186900, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 8h:53m:48s remains)
INFO - root - 2017-12-17 02:18:00.426941: step 186910, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 8h:48m:51s remains)
INFO - root - 2017-12-17 02:18:02.626486: step 186920, loss = 0.45, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 8h:49m:21s remains)
INFO - root - 2017-12-17 02:18:04.833010: step 186930, loss = 0.54, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 8h:54m:40s remains)
INFO - root - 2017-12-17 02:18:07.091098: step 186940, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 8h:52m:46s remains)
INFO - root - 2017-12-17 02:18:09.318171: step 186950, loss = 0.52, batch loss = 0.34 (36.2 examples/sec; 0.221 sec/batch; 8h:56m:27s remains)
INFO - root - 2017-12-17 02:18:11.488697: step 186960, loss = 0.52, batch loss = 0.34 (37.6 examples/sec; 0.213 sec/batch; 8h:36m:21s remains)
INFO - root - 2017-12-17 02:18:13.724235: step 186970, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 8h:56m:15s remains)
INFO - root - 2017-12-17 02:18:15.936153: step 186980, loss = 0.51, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 9h:01m:24s remains)
INFO - root - 2017-12-17 02:18:18.145021: step 186990, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 8h:44m:49s remains)
INFO - root - 2017-12-17 02:18:20.391380: step 187000, loss = 0.52, batch loss = 0.34 (37.0 examples/sec; 0.216 sec/batch; 8h:44m:35s remains)
INFO - root - 2017-12-17 02:18:22.749434: step 187010, loss = 0.50, batch loss = 0.32 (36.8 examples/sec; 0.218 sec/batch; 8h:47m:48s remains)
INFO - root - 2017-12-17 02:18:24.959186: step 187020, loss = 0.52, batch loss = 0.34 (36.0 examples/sec; 0.222 sec/batch; 8h:58m:56s remains)
INFO - root - 2017-12-17 02:18:27.165966: step 187030, loss = 0.55, batch loss = 0.38 (37.0 examples/sec; 0.216 sec/batch; 8h:44m:29s remains)
INFO - root - 2017-12-17 02:18:29.346064: step 187040, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 8h:55m:31s remains)
INFO - root - 2017-12-17 02:18:31.583567: step 187050, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.220 sec/batch; 8h:53m:52s remains)
INFO - root - 2017-12-17 02:18:33.820775: step 187060, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 9h:06m:36s remains)
INFO - root - 2017-12-17 02:18:36.029576: step 187070, loss = 0.53, batch loss = 0.35 (36.7 examples/sec; 0.218 sec/batch; 8h:47m:56s remains)
INFO - root - 2017-12-17 02:18:38.267262: step 187080, loss = 0.47, batch loss = 0.30 (33.8 examples/sec; 0.237 sec/batch; 9h:33m:44s remains)
INFO - root - 2017-12-17 02:18:40.478294: step 187090, loss = 0.53, batch loss = 0.35 (37.5 examples/sec; 0.213 sec/batch; 8h:37m:00s remains)
INFO - root - 2017-12-17 02:18:42.645702: step 187100, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 8h:53m:35s remains)
INFO - root - 2017-12-17 02:18:44.953756: step 187110, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 8h:45m:41s remains)
INFO - root - 2017-12-17 02:18:47.158866: step 187120, loss = 0.62, batch loss = 0.44 (34.7 examples/sec; 0.231 sec/batch; 9h:18m:37s remains)
INFO - root - 2017-12-17 02:18:49.357329: step 187130, loss = 0.45, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 8h:50m:38s remains)
INFO - root - 2017-12-17 02:18:51.556206: step 187140, loss = 0.54, batch loss = 0.36 (38.1 examples/sec; 0.210 sec/batch; 8h:28m:12s remains)
INFO - root - 2017-12-17 02:18:53.787475: step 187150, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.224 sec/batch; 9h:03m:40s remains)
INFO - root - 2017-12-17 02:18:56.008448: step 187160, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 9h:04m:04s remains)
INFO - root - 2017-12-17 02:18:58.266550: step 187170, loss = 0.46, batch loss = 0.28 (33.9 examples/sec; 0.236 sec/batch; 9h:31m:15s remains)
INFO - root - 2017-12-17 02:19:00.475887: step 187180, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 8h:38m:10s remains)
INFO - root - 2017-12-17 02:19:02.680256: step 187190, loss = 0.50, batch loss = 0.33 (36.0 examples/sec; 0.223 sec/batch; 8h:58m:51s remains)
INFO - root - 2017-12-17 02:19:04.893092: step 187200, loss = 0.49, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 9h:06m:44s remains)
INFO - root - 2017-12-17 02:19:07.181121: step 187210, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 8h:40m:07s remains)
INFO - root - 2017-12-17 02:19:09.432214: step 187220, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 9h:11m:42s remains)
INFO - root - 2017-12-17 02:19:11.641750: step 187230, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 8h:50m:32s remains)
INFO - root - 2017-12-17 02:19:13.841208: step 187240, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.215 sec/batch; 8h:39m:23s remains)
INFO - root - 2017-12-17 02:19:16.039513: step 187250, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 8h:34m:34s remains)
INFO - root - 2017-12-17 02:19:18.272508: step 187260, loss = 0.44, batch loss = 0.26 (34.7 examples/sec; 0.230 sec/batch; 9h:17m:37s remains)
INFO - root - 2017-12-17 02:19:20.461515: step 187270, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 8h:55m:22s remains)
INFO - root - 2017-12-17 02:19:22.661473: step 187280, loss = 0.48, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 8h:45m:38s remains)
INFO - root - 2017-12-17 02:19:24.920663: step 187290, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.226 sec/batch; 9h:08m:07s remains)
INFO - root - 2017-12-17 02:19:27.137010: step 187300, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.226 sec/batch; 9h:05m:46s remains)
INFO - root - 2017-12-17 02:19:29.534176: step 187310, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 9h:02m:42s remains)
INFO - root - 2017-12-17 02:19:31.750523: step 187320, loss = 0.48, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 9h:21m:12s remains)
INFO - root - 2017-12-17 02:19:33.925619: step 187330, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 8h:47m:27s remains)
INFO - root - 2017-12-17 02:19:36.135915: step 187340, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 8h:52m:19s remains)
INFO - root - 2017-12-17 02:19:38.384122: step 187350, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 8h:56m:31s remains)
INFO - root - 2017-12-17 02:19:40.578806: step 187360, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.214 sec/batch; 8h:36m:32s remains)
INFO - root - 2017-12-17 02:19:42.789799: step 187370, loss = 0.57, batch loss = 0.39 (35.4 examples/sec; 0.226 sec/batch; 9h:06m:43s remains)
INFO - root - 2017-12-17 02:19:45.017423: step 187380, loss = 0.49, batch loss = 0.31 (36.5 examples/sec; 0.219 sec/batch; 8h:50m:39s remains)
INFO - root - 2017-12-17 02:19:47.239554: step 187390, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 8h:57m:26s remains)
INFO - root - 2017-12-17 02:19:49.450948: step 187400, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 8h:44m:15s remains)
INFO - root - 2017-12-17 02:19:51.795931: step 187410, loss = 0.45, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 9h:00m:01s remains)
INFO - root - 2017-12-17 02:19:54.051734: step 187420, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 9h:15m:49s remains)
INFO - root - 2017-12-17 02:19:56.252343: step 187430, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 8h:45m:21s remains)
INFO - root - 2017-12-17 02:19:58.490011: step 187440, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.224 sec/batch; 9h:02m:41s remains)
INFO - root - 2017-12-17 02:20:00.724562: step 187450, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 8h:56m:58s remains)
INFO - root - 2017-12-17 02:20:02.937715: step 187460, loss = 0.48, batch loss = 0.30 (32.6 examples/sec; 0.246 sec/batch; 9h:54m:00s remains)
INFO - root - 2017-12-17 02:20:05.142738: step 187470, loss = 0.49, batch loss = 0.31 (35.0 examples/sec; 0.229 sec/batch; 9h:12m:32s remains)
INFO - root - 2017-12-17 02:20:07.379895: step 187480, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 8h:55m:27s remains)
INFO - root - 2017-12-17 02:20:09.584361: step 187490, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 8h:56m:29s remains)
INFO - root - 2017-12-17 02:20:11.777007: step 187500, loss = 0.50, batch loss = 0.32 (37.5 examples/sec; 0.213 sec/batch; 8h:35m:25s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-187500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-187500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 02:20:14.456487: step 187510, loss = 0.58, batch loss = 0.40 (37.0 examples/sec; 0.216 sec/batch; 8h:42m:37s remains)
INFO - root - 2017-12-17 02:20:16.668081: step 187520, loss = 0.45, batch loss = 0.27 (33.8 examples/sec; 0.237 sec/batch; 9h:31m:31s remains)
INFO - root - 2017-12-17 02:20:18.903993: step 187530, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 8h:46m:48s remains)
INFO - root - 2017-12-17 02:20:21.103799: step 187540, loss = 0.42, batch loss = 0.24 (35.0 examples/sec; 0.229 sec/batch; 9h:12m:25s remains)
INFO - root - 2017-12-17 02:20:23.344528: step 187550, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 8h:55m:09s remains)
INFO - root - 2017-12-17 02:20:25.603893: step 187560, loss = 0.45, batch loss = 0.27 (34.9 examples/sec; 0.229 sec/batch; 9h:12m:59s remains)
INFO - root - 2017-12-17 02:20:27.819027: step 187570, loss = 0.62, batch loss = 0.44 (36.3 examples/sec; 0.220 sec/batch; 8h:52m:04s remains)
INFO - root - 2017-12-17 02:20:30.042732: step 187580, loss = 0.53, batch loss = 0.35 (36.6 examples/sec; 0.218 sec/batch; 8h:47m:42s remains)
INFO - root - 2017-12-17 02:20:32.240085: step 187590, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 8h:44m:57s remains)
INFO - root - 2017-12-17 02:20:34.427166: step 187600, loss = 0.49, batch loss = 0.31 (36.3 examples/sec; 0.221 sec/batch; 8h:52m:44s remains)
INFO - root - 2017-12-17 02:20:36.740875: step 187610, loss = 0.46, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 8h:54m:24s remains)
INFO - root - 2017-12-17 02:20:38.971688: step 187620, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 8h:41m:24s remains)
INFO - root - 2017-12-17 02:20:41.195351: step 187630, loss = 0.44, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 8h:59m:25s remains)
INFO - root - 2017-12-17 02:20:43.379929: step 187640, loss = 0.46, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 8h:52m:56s remains)
INFO - root - 2017-12-17 02:20:45.569971: step 187650, loss = 0.49, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 9h:09m:04s remains)
INFO - root - 2017-12-17 02:20:47.739126: step 187660, loss = 0.51, batch loss = 0.34 (36.5 examples/sec; 0.219 sec/batch; 8h:49m:47s remains)
INFO - root - 2017-12-17 02:20:49.942982: step 187670, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 8h:49m:29s remains)
INFO - root - 2017-12-17 02:20:52.193404: step 187680, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 8h:45m:34s remains)
INFO - root - 2017-12-17 02:20:54.401783: step 187690, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 8h:45m:49s remains)
INFO - root - 2017-12-17 02:20:56.622272: step 187700, loss = 0.47, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 8h:36m:02s remains)
INFO - root - 2017-12-17 02:20:58.955588: step 187710, loss = 0.46, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 8h:33m:12s remains)
INFO - root - 2017-12-17 02:21:01.161391: step 187720, loss = 0.54, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 8h:57m:26s remains)
INFO - root - 2017-12-17 02:21:03.366078: step 187730, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 8h:46m:14s remains)
INFO - root - 2017-12-17 02:21:05.623554: step 187740, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 9h:00m:13s remains)
INFO - root - 2017-12-17 02:21:07.824440: step 187750, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 9h:03m:07s remains)
INFO - root - 2017-12-17 02:21:10.045494: step 187760, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 8h:57m:09s remains)
INFO - root - 2017-12-17 02:21:12.286747: step 187770, loss = 0.49, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 9h:02m:35s remains)
INFO - root - 2017-12-17 02:21:14.485040: step 187780, loss = 0.47, batch loss = 0.29 (37.8 examples/sec; 0.212 sec/batch; 8h:30m:37s remains)
INFO - root - 2017-12-17 02:21:16.716894: step 187790, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 9h:07m:43s remains)
INFO - root - 2017-12-17 02:21:18.919588: step 187800, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 8h:50m:45s remains)
INFO - root - 2017-12-17 02:21:21.288527: step 187810, loss = 0.47, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 8h:41m:27s remains)
INFO - root - 2017-12-17 02:21:23.505762: step 187820, loss = 0.42, batch loss = 0.24 (36.7 examples/sec; 0.218 sec/batch; 8h:45m:21s remains)
INFO - root - 2017-12-17 02:21:25.751786: step 187830, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.224 sec/batch; 9h:01m:16s remains)
INFO - root - 2017-12-17 02:21:27.946012: step 187840, loss = 0.50, batch loss = 0.32 (34.6 examples/sec; 0.232 sec/batch; 9h:18m:08s remains)
INFO - root - 2017-12-17 02:21:30.166242: step 187850, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 9h:03m:39s remains)
INFO - root - 2017-12-17 02:21:32.424538: step 187860, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 8h:42m:17s remains)
INFO - root - 2017-12-17 02:21:34.647005: step 187870, loss = 0.50, batch loss = 0.32 (34.1 examples/sec; 0.235 sec/batch; 9h:25m:18s remains)
INFO - root - 2017-12-17 02:21:36.873413: step 187880, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 8h:59m:24s remains)
INFO - root - 2017-12-17 02:21:39.126171: step 187890, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 9h:04m:28s remains)
INFO - root - 2017-12-17 02:21:41.351365: step 187900, loss = 0.55, batch loss = 0.37 (35.3 examples/sec; 0.227 sec/batch; 9h:06m:23s remains)
INFO - root - 2017-12-17 02:21:43.701759: step 187910, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 8h:55m:36s remains)
INFO - root - 2017-12-17 02:21:45.933699: step 187920, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 8h:47m:22s remains)
INFO - root - 2017-12-17 02:21:48.128501: step 187930, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 8h:35m:12s remains)
INFO - root - 2017-12-17 02:21:50.332999: step 187940, loss = 0.47, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 8h:48m:01s remains)
INFO - root - 2017-12-17 02:21:52.600629: step 187950, loss = 0.48, batch loss = 0.31 (34.3 examples/sec; 0.233 sec/batch; 9h:21m:32s remains)
INFO - root - 2017-12-17 02:21:54.806545: step 187960, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 9h:09m:13s remains)
INFO - root - 2017-12-17 02:21:57.016280: step 187970, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 8h:44m:39s remains)
INFO - root - 2017-12-17 02:21:59.247120: step 187980, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 8h:56m:05s remains)
INFO - root - 2017-12-17 02:22:01.472226: step 187990, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 8h:58m:11s remains)
INFO - root - 2017-12-17 02:22:03.692601: step 188000, loss = 0.50, batch loss = 0.33 (35.2 examples/sec; 0.227 sec/batch; 9h:07m:08s remains)
INFO - root - 2017-12-17 02:22:06.036977: step 188010, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 8h:49m:46s remains)
INFO - root - 2017-12-17 02:22:08.214355: step 188020, loss = 0.47, batch loss = 0.29 (37.5 examples/sec; 0.214 sec/batch; 8h:34m:13s remains)
INFO - root - 2017-12-17 02:22:10.429058: step 188030, loss = 0.51, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 8h:42m:39s remains)
INFO - root - 2017-12-17 02:22:12.686054: step 188040, loss = 0.57, batch loss = 0.39 (35.3 examples/sec; 0.227 sec/batch; 9h:05m:48s remains)
INFO - root - 2017-12-17 02:22:14.933303: step 188050, loss = 0.52, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 8h:41m:25s remains)
INFO - root - 2017-12-17 02:22:17.100386: step 188060, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 8h:47m:36s remains)
INFO - root - 2017-12-17 02:22:19.320922: step 188070, loss = 0.51, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 8h:46m:34s remains)
INFO - root - 2017-12-17 02:22:21.516900: step 188080, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 8h:47m:47s remains)
INFO - root - 2017-12-17 02:22:23.767882: step 188090, loss = 0.51, batch loss = 0.33 (36.4 examples/sec; 0.220 sec/batch; 8h:49m:32s remains)
INFO - root - 2017-12-17 02:22:25.958440: step 188100, loss = 0.49, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 8h:42m:26s remains)
INFO - root - 2017-12-17 02:22:28.330205: step 188110, loss = 0.54, batch loss = 0.36 (35.8 examples/sec; 0.223 sec/batch; 8h:57m:37s remains)
INFO - root - 2017-12-17 02:22:30.534811: step 188120, loss = 0.46, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 8h:32m:51s remains)
INFO - root - 2017-12-17 02:22:32.725849: step 188130, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 8h:49m:52s remains)
INFO - root - 2017-12-17 02:22:34.932574: step 188140, loss = 0.46, batch loss = 0.28 (37.4 examples/sec; 0.214 sec/batch; 8h:34m:20s remains)
INFO - root - 2017-12-17 02:22:37.124836: step 188150, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 8h:46m:24s remains)
INFO - root - 2017-12-17 02:22:39.381940: step 188160, loss = 0.44, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 8h:47m:31s remains)
INFO - root - 2017-12-17 02:22:41.584191: step 188170, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 9h:01m:34s remains)
INFO - root - 2017-12-17 02:22:43.798145: step 188180, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 8h:43m:02s remains)
INFO - root - 2017-12-17 02:22:46.046280: step 188190, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 8h:39m:56s remains)
INFO - root - 2017-12-17 02:22:48.239280: step 188200, loss = 0.49, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 8h:39m:50s remains)
INFO - root - 2017-12-17 02:22:50.629965: step 188210, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 9h:07m:41s remains)
INFO - root - 2017-12-17 02:22:52.896532: step 188220, loss = 0.44, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 9h:05m:41s remains)
INFO - root - 2017-12-17 02:22:55.116330: step 188230, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 8h:49m:31s remains)
INFO - root - 2017-12-17 02:22:57.333170: step 188240, loss = 0.58, batch loss = 0.40 (35.9 examples/sec; 0.223 sec/batch; 8h:55m:54s remains)
INFO - root - 2017-12-17 02:22:59.557926: step 188250, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 8h:59m:15s remains)
INFO - root - 2017-12-17 02:23:01.799943: step 188260, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 8h:46m:14s remains)
INFO - root - 2017-12-17 02:23:04.008039: step 188270, loss = 0.45, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 9h:06m:26s remains)
INFO - root - 2017-12-17 02:23:06.258601: step 188280, loss = 0.62, batch loss = 0.44 (35.8 examples/sec; 0.224 sec/batch; 8h:57m:13s remains)
INFO - root - 2017-12-17 02:23:08.476219: step 188290, loss = 0.47, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 8h:49m:29s remains)
INFO - root - 2017-12-17 02:23:10.700797: step 188300, loss = 0.44, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 8h:49m:23s remains)
INFO - root - 2017-12-17 02:23:13.034309: step 188310, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 9h:01m:08s remains)
INFO - root - 2017-12-17 02:23:15.243924: step 188320, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.233 sec/batch; 9h:19m:06s remains)
INFO - root - 2017-12-17 02:23:17.458438: step 188330, loss = 0.52, batch loss = 0.34 (37.3 examples/sec; 0.215 sec/batch; 8h:35m:40s remains)
INFO - root - 2017-12-17 02:23:19.683211: step 188340, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 8h:52m:20s remains)
INFO - root - 2017-12-17 02:23:21.915720: step 188350, loss = 0.51, batch loss = 0.33 (34.7 examples/sec; 0.231 sec/batch; 9h:14m:33s remains)
INFO - root - 2017-12-17 02:23:24.142149: step 188360, loss = 0.53, batch loss = 0.35 (35.3 examples/sec; 0.227 sec/batch; 9h:04m:55s remains)
INFO - root - 2017-12-17 02:23:26.353482: step 188370, loss = 0.44, batch loss = 0.26 (37.5 examples/sec; 0.213 sec/batch; 8h:32m:22s remains)
INFO - root - 2017-12-17 02:23:28.577893: step 188380, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 8h:56m:32s remains)
INFO - root - 2017-12-17 02:23:30.755228: step 188390, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 8h:39m:46s remains)
INFO - root - 2017-12-17 02:23:32.952278: step 188400, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 8h:42m:01s remains)
INFO - root - 2017-12-17 02:23:35.298130: step 188410, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.222 sec/batch; 8h:52m:05s remains)
INFO - root - 2017-12-17 02:23:37.471314: step 188420, loss = 0.49, batch loss = 0.31 (38.8 examples/sec; 0.206 sec/batch; 8h:15m:27s remains)
INFO - root - 2017-12-17 02:23:39.725079: step 188430, loss = 0.48, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 9h:12m:15s remains)
INFO - root - 2017-12-17 02:23:41.929390: step 188440, loss = 0.56, batch loss = 0.38 (36.8 examples/sec; 0.218 sec/batch; 8h:42m:15s remains)
INFO - root - 2017-12-17 02:23:44.125359: step 188450, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 8h:34m:01s remains)
INFO - root - 2017-12-17 02:23:46.374236: step 188460, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 8h:41m:08s remains)
INFO - root - 2017-12-17 02:23:48.587499: step 188470, loss = 0.43, batch loss = 0.25 (34.0 examples/sec; 0.235 sec/batch; 9h:24m:34s remains)
INFO - root - 2017-12-17 02:23:50.795724: step 188480, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 8h:56m:32s remains)
INFO - root - 2017-12-17 02:23:53.051550: step 188490, loss = 0.50, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 8h:39m:02s remains)
INFO - root - 2017-12-17 02:23:55.227001: step 188500, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 8h:33m:51s remains)
INFO - root - 2017-12-17 02:23:57.552737: step 188510, loss = 0.45, batch loss = 0.27 (34.3 examples/sec; 0.233 sec/batch; 9h:19m:45s remains)
INFO - root - 2017-12-17 02:23:59.777437: step 188520, loss = 0.48, batch loss = 0.30 (34.1 examples/sec; 0.234 sec/batch; 9h:22m:36s remains)
INFO - root - 2017-12-17 02:24:01.998060: step 188530, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 8h:42m:16s remains)
INFO - root - 2017-12-17 02:24:04.222508: step 188540, loss = 0.46, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 8h:49m:32s remains)
INFO - root - 2017-12-17 02:24:06.432632: step 188550, loss = 0.56, batch loss = 0.39 (34.5 examples/sec; 0.232 sec/batch; 9h:16m:43s remains)
INFO - root - 2017-12-17 02:24:08.649688: step 188560, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 8h:54m:45s remains)
INFO - root - 2017-12-17 02:24:10.876105: step 188570, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.218 sec/batch; 8h:41m:57s remains)
INFO - root - 2017-12-17 02:24:13.097967: step 188580, loss = 0.47, batch loss = 0.30 (33.5 examples/sec; 0.239 sec/batch; 9h:33m:37s remains)
INFO - root - 2017-12-17 02:24:15.337735: step 188590, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 8h:51m:42s remains)
INFO - root - 2017-12-17 02:24:17.540859: step 188600, loss = 0.43, batch loss = 0.25 (35.9 examples/sec; 0.223 sec/batch; 8h:53m:54s remains)
INFO - root - 2017-12-17 02:24:19.884054: step 188610, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 8h:55m:18s remains)
INFO - root - 2017-12-17 02:24:22.109755: step 188620, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 8h:59m:09s remains)
INFO - root - 2017-12-17 02:24:24.353783: step 188630, loss = 0.43, batch loss = 0.25 (37.3 examples/sec; 0.214 sec/batch; 8h:34m:14s remains)
INFO - root - 2017-12-17 02:24:26.585149: step 188640, loss = 0.46, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 8h:48m:16s remains)
INFO - root - 2017-12-17 02:24:28.808282: step 188650, loss = 0.47, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 8h:56m:33s remains)
INFO - root - 2017-12-17 02:24:30.996439: step 188660, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 8h:45m:52s remains)
INFO - root - 2017-12-17 02:24:33.211125: step 188670, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 8h:44m:19s remains)
INFO - root - 2017-12-17 02:24:35.424374: step 188680, loss = 0.49, batch loss = 0.31 (34.8 examples/sec; 0.230 sec/batch; 9h:11m:30s remains)
INFO - root - 2017-12-17 02:24:37.630916: step 188690, loss = 0.49, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 9h:01m:26s remains)
INFO - root - 2017-12-17 02:24:39.857081: step 188700, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 8h:48m:02s remains)
INFO - root - 2017-12-17 02:24:42.245768: step 188710, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 8h:54m:26s remains)
INFO - root - 2017-12-17 02:24:44.448747: step 188720, loss = 0.52, batch loss = 0.34 (36.3 examples/sec; 0.220 sec/batch; 8h:48m:04s remains)
INFO - root - 2017-12-17 02:24:46.654786: step 188730, loss = 0.44, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 9h:02m:03s remains)
INFO - root - 2017-12-17 02:24:48.861248: step 188740, loss = 0.44, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 8h:34m:39s remains)
INFO - root - 2017-12-17 02:24:51.075778: step 188750, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 9h:03m:34s remains)
INFO - root - 2017-12-17 02:24:53.268478: step 188760, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.221 sec/batch; 8h:48m:33s remains)
INFO - root - 2017-12-17 02:24:55.467066: step 188770, loss = 0.46, batch loss = 0.29 (37.0 examples/sec; 0.216 sec/batch; 8h:38m:27s remains)
INFO - root - 2017-12-17 02:24:57.692841: step 188780, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 8h:51m:04s remains)
INFO - root - 2017-12-17 02:24:59.908477: step 188790, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 8h:57m:52s remains)
INFO - root - 2017-12-17 02:25:02.129388: step 188800, loss = 0.42, batch loss = 0.24 (35.3 examples/sec; 0.226 sec/batch; 9h:02m:27s remains)
INFO - root - 2017-12-17 02:25:04.488295: step 188810, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 8h:53m:51s remains)
INFO - root - 2017-12-17 02:25:06.720363: step 188820, loss = 0.50, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 8h:43m:27s remains)
INFO - root - 2017-12-17 02:25:08.926230: step 188830, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 8h:34m:02s remains)
INFO - root - 2017-12-17 02:25:11.124785: step 188840, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 8h:52m:00s remains)
INFO - root - 2017-12-17 02:25:13.309622: step 188850, loss = 0.48, batch loss = 0.30 (38.0 examples/sec; 0.210 sec/batch; 8h:23m:24s remains)
INFO - root - 2017-12-17 02:25:15.522617: step 188860, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 9h:01m:32s remains)
INFO - root - 2017-12-17 02:25:17.760797: step 188870, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.217 sec/batch; 8h:38m:16s remains)
INFO - root - 2017-12-17 02:25:20.010169: step 188880, loss = 0.50, batch loss = 0.32 (35.8 examples/sec; 0.224 sec/batch; 8h:55m:20s remains)
INFO - root - 2017-12-17 02:25:22.222616: step 188890, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 8h:51m:18s remains)
INFO - root - 2017-12-17 02:25:24.446485: step 188900, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.215 sec/batch; 8h:33m:34s remains)
INFO - root - 2017-12-17 02:25:26.785170: step 188910, loss = 0.48, batch loss = 0.31 (37.3 examples/sec; 0.215 sec/batch; 8h:33m:32s remains)
INFO - root - 2017-12-17 02:25:28.968816: step 188920, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 8h:46m:49s remains)
INFO - root - 2017-12-17 02:25:31.188042: step 188930, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 8h:36m:33s remains)
INFO - root - 2017-12-17 02:25:33.451416: step 188940, loss = 0.49, batch loss = 0.31 (33.8 examples/sec; 0.236 sec/batch; 9h:25m:35s remains)
INFO - root - 2017-12-17 02:25:35.686600: step 188950, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 8h:57m:21s remains)
INFO - root - 2017-12-17 02:25:37.922007: step 188960, loss = 0.44, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 8h:37m:35s remains)
INFO - root - 2017-12-17 02:25:40.138027: step 188970, loss = 0.46, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 9h:17m:47s remains)
INFO - root - 2017-12-17 02:25:42.372820: step 188980, loss = 0.45, batch loss = 0.27 (33.9 examples/sec; 0.236 sec/batch; 9h:24m:25s remains)
INFO - root - 2017-12-17 02:25:44.631624: step 188990, loss = 0.48, batch loss = 0.30 (33.4 examples/sec; 0.240 sec/batch; 9h:33m:35s remains)
INFO - root - 2017-12-17 02:25:46.882052: step 189000, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 8h:47m:24s remains)
INFO - root - 2017-12-17 02:25:49.220429: step 189010, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.228 sec/batch; 9h:06m:01s remains)
INFO - root - 2017-12-17 02:25:51.457597: step 189020, loss = 0.53, batch loss = 0.35 (37.1 examples/sec; 0.216 sec/batch; 8h:36m:14s remains)
INFO - root - 2017-12-17 02:25:53.697240: step 189030, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 8h:44m:16s remains)
INFO - root - 2017-12-17 02:25:55.882929: step 189040, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 8h:37m:25s remains)
INFO - root - 2017-12-17 02:25:58.100100: step 189050, loss = 0.51, batch loss = 0.33 (36.3 examples/sec; 0.220 sec/batch; 8h:46m:16s remains)
INFO - root - 2017-12-17 02:26:00.323992: step 189060, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.228 sec/batch; 9h:05m:41s remains)
INFO - root - 2017-12-17 02:26:02.524268: step 189070, loss = 0.46, batch loss = 0.28 (34.1 examples/sec; 0.234 sec/batch; 9h:20m:13s remains)
INFO - root - 2017-12-17 02:26:04.746453: step 189080, loss = 0.53, batch loss = 0.35 (34.5 examples/sec; 0.232 sec/batch; 9h:14m:20s remains)
INFO - root - 2017-12-17 02:26:06.979876: step 189090, loss = 0.48, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 9h:05m:45s remains)
INFO - root - 2017-12-17 02:26:09.199734: step 189100, loss = 0.46, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 8h:54m:24s remains)
INFO - root - 2017-12-17 02:26:11.583934: step 189110, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 8h:39m:07s remains)
INFO - root - 2017-12-17 02:26:13.817388: step 189120, loss = 0.40, batch loss = 0.22 (36.0 examples/sec; 0.222 sec/batch; 8h:50m:35s remains)
INFO - root - 2017-12-17 02:26:16.043543: step 189130, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 8h:52m:18s remains)
INFO - root - 2017-12-17 02:26:18.271777: step 189140, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 8h:48m:37s remains)
INFO - root - 2017-12-17 02:26:20.522051: step 189150, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.219 sec/batch; 8h:42m:55s remains)
INFO - root - 2017-12-17 02:26:22.747080: step 189160, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 8h:43m:08s remains)
INFO - root - 2017-12-17 02:26:24.972523: step 189170, loss = 0.52, batch loss = 0.34 (33.9 examples/sec; 0.236 sec/batch; 9h:24m:24s remains)
INFO - root - 2017-12-17 02:26:27.169895: step 189180, loss = 0.43, batch loss = 0.25 (37.4 examples/sec; 0.214 sec/batch; 8h:30m:55s remains)
INFO - root - 2017-12-17 02:26:29.407861: step 189190, loss = 0.45, batch loss = 0.27 (33.2 examples/sec; 0.241 sec/batch; 9h:35m:52s remains)
INFO - root - 2017-12-17 02:26:31.602565: step 189200, loss = 0.43, batch loss = 0.26 (37.2 examples/sec; 0.215 sec/batch; 8h:33m:06s remains)
INFO - root - 2017-12-17 02:26:33.967612: step 189210, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 8h:34m:14s remains)
INFO - root - 2017-12-17 02:26:36.197389: step 189220, loss = 0.46, batch loss = 0.28 (34.5 examples/sec; 0.232 sec/batch; 9h:13m:02s remains)
INFO - root - 2017-12-17 02:26:38.422388: step 189230, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 9h:00m:19s remains)
INFO - root - 2017-12-17 02:26:40.632405: step 189240, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 8h:44m:44s remains)
INFO - root - 2017-12-17 02:26:42.895787: step 189250, loss = 0.49, batch loss = 0.31 (33.7 examples/sec; 0.237 sec/batch; 9h:26m:06s remains)
INFO - root - 2017-12-17 02:26:45.114120: step 189260, loss = 0.48, batch loss = 0.30 (38.0 examples/sec; 0.210 sec/batch; 8h:22m:05s remains)
INFO - root - 2017-12-17 02:26:47.331770: step 189270, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 8h:45m:21s remains)
INFO - root - 2017-12-17 02:26:49.541387: step 189280, loss = 0.43, batch loss = 0.25 (35.0 examples/sec; 0.229 sec/batch; 9h:06m:10s remains)
INFO - root - 2017-12-17 02:26:51.733437: step 189290, loss = 0.48, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 8h:28m:52s remains)
INFO - root - 2017-12-17 02:26:53.962760: step 189300, loss = 0.52, batch loss = 0.34 (35.0 examples/sec; 0.229 sec/batch; 9h:05m:51s remains)
INFO - root - 2017-12-17 02:26:56.315920: step 189310, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 8h:45m:59s remains)
INFO - root - 2017-12-17 02:26:58.520978: step 189320, loss = 0.49, batch loss = 0.31 (37.9 examples/sec; 0.211 sec/batch; 8h:24m:00s remains)
INFO - root - 2017-12-17 02:27:00.739958: step 189330, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.218 sec/batch; 8h:41m:13s remains)
INFO - root - 2017-12-17 02:27:02.943428: step 189340, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 8h:35m:06s remains)
INFO - root - 2017-12-17 02:27:05.169895: step 189350, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 8h:49m:45s remains)
INFO - root - 2017-12-17 02:27:07.376634: step 189360, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 8h:35m:16s remains)
INFO - root - 2017-12-17 02:27:09.578660: step 189370, loss = 0.48, batch loss = 0.30 (34.7 examples/sec; 0.231 sec/batch; 9h:09m:55s remains)
INFO - root - 2017-12-17 02:27:11.809863: step 189380, loss = 0.48, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 8h:54m:47s remains)
INFO - root - 2017-12-17 02:27:14.015268: step 189390, loss = 0.54, batch loss = 0.36 (36.8 examples/sec; 0.217 sec/batch; 8h:38m:27s remains)
INFO - root - 2017-12-17 02:27:16.229964: step 189400, loss = 0.44, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 8h:52m:12s remains)
INFO - root - 2017-12-17 02:27:18.533765: step 189410, loss = 0.56, batch loss = 0.39 (36.8 examples/sec; 0.217 sec/batch; 8h:38m:25s remains)
INFO - root - 2017-12-17 02:27:20.748986: step 189420, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 8h:40m:14s remains)
INFO - root - 2017-12-17 02:27:22.979940: step 189430, loss = 0.43, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 8h:53m:23s remains)
INFO - root - 2017-12-17 02:27:25.212939: step 189440, loss = 0.50, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 8h:57m:54s remains)
INFO - root - 2017-12-17 02:27:27.415123: step 189450, loss = 0.45, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 9h:12m:41s remains)
INFO - root - 2017-12-17 02:27:29.617136: step 189460, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 8h:38m:27s remains)
INFO - root - 2017-12-17 02:27:31.835539: step 189470, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 8h:36m:37s remains)
INFO - root - 2017-12-17 02:27:34.061103: step 189480, loss = 0.46, batch loss = 0.28 (33.4 examples/sec; 0.239 sec/batch; 9h:30m:21s remains)
INFO - root - 2017-12-17 02:27:36.263031: step 189490, loss = 0.47, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 8h:39m:28s remains)
INFO - root - 2017-12-17 02:27:38.481304: step 189500, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 8h:44m:21s remains)
INFO - root - 2017-12-17 02:27:40.810409: step 189510, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 8h:43m:11s remains)
INFO - root - 2017-12-17 02:27:43.009478: step 189520, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.214 sec/batch; 8h:30m:36s remains)
INFO - root - 2017-12-17 02:27:45.206233: step 189530, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 8h:54m:19s remains)
INFO - root - 2017-12-17 02:27:47.431181: step 189540, loss = 0.44, batch loss = 0.26 (36.6 examples/sec; 0.218 sec/batch; 8h:40m:21s remains)
INFO - root - 2017-12-17 02:27:49.700679: step 189550, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 8h:51m:07s remains)
INFO - root - 2017-12-17 02:27:51.929898: step 189560, loss = 0.47, batch loss = 0.29 (34.6 examples/sec; 0.232 sec/batch; 9h:11m:31s remains)
INFO - root - 2017-12-17 02:27:54.179539: step 189570, loss = 0.56, batch loss = 0.38 (36.0 examples/sec; 0.222 sec/batch; 8h:49m:25s remains)
INFO - root - 2017-12-17 02:27:56.403955: step 189580, loss = 0.46, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 8h:36m:35s remains)
INFO - root - 2017-12-17 02:27:58.643921: step 189590, loss = 0.53, batch loss = 0.35 (33.1 examples/sec; 0.241 sec/batch; 9h:34m:49s remains)
INFO - root - 2017-12-17 02:28:00.876432: step 189600, loss = 0.55, batch loss = 0.37 (35.2 examples/sec; 0.227 sec/batch; 9h:01m:46s remains)
INFO - root - 2017-12-17 02:28:03.233996: step 189610, loss = 0.46, batch loss = 0.28 (34.1 examples/sec; 0.235 sec/batch; 9h:19m:19s remains)
INFO - root - 2017-12-17 02:28:05.458178: step 189620, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 8h:41m:21s remains)
INFO - root - 2017-12-17 02:28:07.686439: step 189630, loss = 0.47, batch loss = 0.29 (34.8 examples/sec; 0.230 sec/batch; 9h:07m:59s remains)
INFO - root - 2017-12-17 02:28:09.902044: step 189640, loss = 0.52, batch loss = 0.34 (35.3 examples/sec; 0.227 sec/batch; 9h:00m:00s remains)
INFO - root - 2017-12-17 02:28:12.139907: step 189650, loss = 0.46, batch loss = 0.28 (37.2 examples/sec; 0.215 sec/batch; 8h:31m:35s remains)
INFO - root - 2017-12-17 02:28:14.362882: step 189660, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 8h:55m:34s remains)
INFO - root - 2017-12-17 02:28:16.611447: step 189670, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 9h:07m:55s remains)
INFO - root - 2017-12-17 02:28:18.832848: step 189680, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 8h:36m:43s remains)
INFO - root - 2017-12-17 02:28:21.074729: step 189690, loss = 0.51, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 9h:07m:10s remains)
INFO - root - 2017-12-17 02:28:23.296466: step 189700, loss = 0.48, batch loss = 0.31 (37.1 examples/sec; 0.215 sec/batch; 8h:32m:36s remains)
INFO - root - 2017-12-17 02:28:25.652210: step 189710, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 8h:37m:29s remains)
INFO - root - 2017-12-17 02:28:27.904709: step 189720, loss = 0.47, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 8h:49m:10s remains)
INFO - root - 2017-12-17 02:28:30.134591: step 189730, loss = 0.43, batch loss = 0.25 (34.0 examples/sec; 0.235 sec/batch; 9h:20m:03s remains)
INFO - root - 2017-12-17 02:28:32.347779: step 189740, loss = 0.52, batch loss = 0.34 (36.4 examples/sec; 0.220 sec/batch; 8h:43m:38s remains)
INFO - root - 2017-12-17 02:28:34.557887: step 189750, loss = 0.53, batch loss = 0.35 (37.2 examples/sec; 0.215 sec/batch; 8h:31m:09s remains)
INFO - root - 2017-12-17 02:28:36.759356: step 189760, loss = 0.45, batch loss = 0.27 (37.8 examples/sec; 0.212 sec/batch; 8h:23m:39s remains)
INFO - root - 2017-12-17 02:28:39.005893: step 189770, loss = 0.58, batch loss = 0.40 (35.3 examples/sec; 0.227 sec/batch; 8h:59m:45s remains)
INFO - root - 2017-12-17 02:28:41.272060: step 189780, loss = 0.51, batch loss = 0.33 (33.9 examples/sec; 0.236 sec/batch; 9h:22m:04s remains)
INFO - root - 2017-12-17 02:28:43.510566: step 189790, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 8h:32m:39s remains)
INFO - root - 2017-12-17 02:28:45.719951: step 189800, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 8h:46m:59s remains)
INFO - root - 2017-12-17 02:28:48.096029: step 189810, loss = 0.43, batch loss = 0.25 (35.0 examples/sec; 0.229 sec/batch; 9h:03m:48s remains)
INFO - root - 2017-12-17 02:28:50.299955: step 189820, loss = 0.45, batch loss = 0.27 (36.8 examples/sec; 0.217 sec/batch; 8h:36m:29s remains)
INFO - root - 2017-12-17 02:28:52.517711: step 189830, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 8h:48m:46s remains)
INFO - root - 2017-12-17 02:28:54.698985: step 189840, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 8h:31m:10s remains)
INFO - root - 2017-12-17 02:28:56.901516: step 189850, loss = 0.47, batch loss = 0.30 (36.3 examples/sec; 0.221 sec/batch; 8h:44m:26s remains)
INFO - root - 2017-12-17 02:28:59.069078: step 189860, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 8h:29m:24s remains)
INFO - root - 2017-12-17 02:29:01.311623: step 189870, loss = 0.43, batch loss = 0.25 (36.3 examples/sec; 0.221 sec/batch; 8h:44m:21s remains)
INFO - root - 2017-12-17 02:29:03.524286: step 189880, loss = 0.44, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 8h:50m:28s remains)
INFO - root - 2017-12-17 02:29:05.687438: step 189890, loss = 0.49, batch loss = 0.31 (37.2 examples/sec; 0.215 sec/batch; 8h:30m:36s remains)
INFO - root - 2017-12-17 02:29:07.939485: step 189900, loss = 0.51, batch loss = 0.33 (35.0 examples/sec; 0.228 sec/batch; 9h:02m:38s remains)
INFO - root - 2017-12-17 02:29:10.281899: step 189910, loss = 0.49, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 8h:45m:12s remains)
INFO - root - 2017-12-17 02:29:12.459793: step 189920, loss = 0.46, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 8h:23m:22s remains)
INFO - root - 2017-12-17 02:29:14.689555: step 189930, loss = 0.49, batch loss = 0.32 (37.1 examples/sec; 0.215 sec/batch; 8h:31m:58s remains)
INFO - root - 2017-12-17 02:29:16.893465: step 189940, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.215 sec/batch; 8h:30m:02s remains)
INFO - root - 2017-12-17 02:29:19.118667: step 189950, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 8h:49m:23s remains)
INFO - root - 2017-12-17 02:29:21.313893: step 189960, loss = 0.49, batch loss = 0.31 (38.0 examples/sec; 0.211 sec/batch; 8h:20m:36s remains)
INFO - root - 2017-12-17 02:29:23.538557: step 189970, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 8h:38m:55s remains)
INFO - root - 2017-12-17 02:29:25.791636: step 189980, loss = 0.43, batch loss = 0.26 (33.1 examples/sec; 0.242 sec/batch; 9h:34m:42s remains)
INFO - root - 2017-12-17 02:29:28.043940: step 189990, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 8h:43m:14s remains)
INFO - root - 2017-12-17 02:29:30.275560: step 190000, loss = 0.45, batch loss = 0.27 (37.8 examples/sec; 0.212 sec/batch; 8h:22m:41s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-190000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-190000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 02:29:33.408048: step 190010, loss = 0.46, batch loss = 0.28 (33.2 examples/sec; 0.241 sec/batch; 9h:32m:25s remains)
INFO - root - 2017-12-17 02:29:35.635258: step 190020, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.217 sec/batch; 8h:34m:06s remains)
INFO - root - 2017-12-17 02:29:37.870001: step 190030, loss = 0.45, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 8h:41m:16s remains)
INFO - root - 2017-12-17 02:29:40.102024: step 190040, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 8h:41m:28s remains)
INFO - root - 2017-12-17 02:29:42.344198: step 190050, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 8h:41m:35s remains)
INFO - root - 2017-12-17 02:29:44.556268: step 190060, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 8h:44m:07s remains)
INFO - root - 2017-12-17 02:29:46.762756: step 190070, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 8h:40m:32s remains)
INFO - root - 2017-12-17 02:29:48.978197: step 190080, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 8h:59m:08s remains)
INFO - root - 2017-12-17 02:29:51.204706: step 190090, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 8h:44m:44s remains)
INFO - root - 2017-12-17 02:29:53.440311: step 190100, loss = 0.47, batch loss = 0.29 (37.3 examples/sec; 0.214 sec/batch; 8h:28m:48s remains)
INFO - root - 2017-12-17 02:29:55.773902: step 190110, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 8h:39m:13s remains)
INFO - root - 2017-12-17 02:29:57.993961: step 190120, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 8h:43m:57s remains)
INFO - root - 2017-12-17 02:30:00.250155: step 190130, loss = 0.45, batch loss = 0.27 (34.7 examples/sec; 0.231 sec/batch; 9h:07m:17s remains)
INFO - root - 2017-12-17 02:30:02.464413: step 190140, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 8h:34m:52s remains)
INFO - root - 2017-12-17 02:30:04.687220: step 190150, loss = 0.46, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 8h:47m:18s remains)
INFO - root - 2017-12-17 02:30:06.939319: step 190160, loss = 0.48, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 8h:35m:15s remains)
INFO - root - 2017-12-17 02:30:09.195794: step 190170, loss = 0.58, batch loss = 0.41 (36.7 examples/sec; 0.218 sec/batch; 8h:36m:39s remains)
INFO - root - 2017-12-17 02:30:11.441861: step 190180, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 8h:46m:37s remains)
INFO - root - 2017-12-17 02:30:13.666429: step 190190, loss = 0.46, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 8h:45m:04s remains)
INFO - root - 2017-12-17 02:30:15.923917: step 190200, loss = 0.46, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 8h:43m:33s remains)
INFO - root - 2017-12-17 02:30:18.278589: step 190210, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 8h:45m:23s remains)
INFO - root - 2017-12-17 02:30:20.485281: step 190220, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 8h:40m:42s remains)
INFO - root - 2017-12-17 02:30:22.681495: step 190230, loss = 0.53, batch loss = 0.36 (37.2 examples/sec; 0.215 sec/batch; 8h:29m:29s remains)
INFO - root - 2017-12-17 02:30:24.890773: step 190240, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 8h:32m:48s remains)
INFO - root - 2017-12-17 02:30:27.108134: step 190250, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 9h:00m:00s remains)
INFO - root - 2017-12-17 02:30:29.346180: step 190260, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.226 sec/batch; 8h:54m:38s remains)
INFO - root - 2017-12-17 02:30:31.541228: step 190270, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 8h:43m:40s remains)
INFO - root - 2017-12-17 02:30:33.805169: step 190280, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 9h:00m:25s remains)
INFO - root - 2017-12-17 02:30:36.019443: step 190290, loss = 0.55, batch loss = 0.37 (35.3 examples/sec; 0.227 sec/batch; 8h:57m:06s remains)
INFO - root - 2017-12-17 02:30:38.270229: step 190300, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 8h:50m:22s remains)
INFO - root - 2017-12-17 02:30:40.583975: step 190310, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 8h:37m:11s remains)
INFO - root - 2017-12-17 02:30:42.795785: step 190320, loss = 0.50, batch loss = 0.32 (36.9 examples/sec; 0.217 sec/batch; 8h:33m:38s remains)
INFO - root - 2017-12-17 02:30:45.004080: step 190330, loss = 0.54, batch loss = 0.36 (36.4 examples/sec; 0.220 sec/batch; 8h:40m:15s remains)
INFO - root - 2017-12-17 02:30:47.231527: step 190340, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 8h:39m:48s remains)
INFO - root - 2017-12-17 02:30:49.423872: step 190350, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 9h:02m:54s remains)
INFO - root - 2017-12-17 02:30:51.662173: step 190360, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 8h:50m:44s remains)
INFO - root - 2017-12-17 02:30:53.883699: step 190370, loss = 0.51, batch loss = 0.33 (36.8 examples/sec; 0.217 sec/batch; 8h:34m:40s remains)
INFO - root - 2017-12-17 02:30:56.139684: step 190380, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 8h:59m:28s remains)
INFO - root - 2017-12-17 02:30:58.358994: step 190390, loss = 0.45, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 8h:44m:09s remains)
INFO - root - 2017-12-17 02:31:00.612690: step 190400, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 8h:36m:45s remains)
INFO - root - 2017-12-17 02:31:02.954494: step 190410, loss = 0.43, batch loss = 0.25 (35.1 examples/sec; 0.228 sec/batch; 9h:00m:02s remains)
INFO - root - 2017-12-17 02:31:05.218261: step 190420, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 8h:52m:17s remains)
INFO - root - 2017-12-17 02:31:07.397264: step 190430, loss = 0.44, batch loss = 0.26 (37.0 examples/sec; 0.216 sec/batch; 8h:31m:46s remains)
INFO - root - 2017-12-17 02:31:09.592178: step 190440, loss = 0.45, batch loss = 0.27 (37.1 examples/sec; 0.216 sec/batch; 8h:31m:01s remains)
INFO - root - 2017-12-17 02:31:11.842003: step 190450, loss = 0.56, batch loss = 0.38 (36.4 examples/sec; 0.220 sec/batch; 8h:40m:36s remains)
INFO - root - 2017-12-17 02:31:14.047154: step 190460, loss = 0.55, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 8h:40m:50s remains)
INFO - root - 2017-12-17 02:31:16.247200: step 190470, loss = 0.46, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 9h:12m:32s remains)
INFO - root - 2017-12-17 02:31:18.454180: step 190480, loss = 0.48, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 8h:47m:38s remains)
INFO - root - 2017-12-17 02:31:20.666704: step 190490, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 8h:45m:41s remains)
INFO - root - 2017-12-17 02:31:22.859982: step 190500, loss = 0.53, batch loss = 0.35 (37.3 examples/sec; 0.214 sec/batch; 8h:27m:04s remains)
INFO - root - 2017-12-17 02:31:25.219010: step 190510, loss = 0.49, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 8h:46m:53s remains)
INFO - root - 2017-12-17 02:31:27.446952: step 190520, loss = 0.46, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 8h:58m:57s remains)
INFO - root - 2017-12-17 02:31:29.656952: step 190530, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 8h:51m:30s remains)
INFO - root - 2017-12-17 02:31:31.872312: step 190540, loss = 0.51, batch loss = 0.33 (36.0 examples/sec; 0.222 sec/batch; 8h:45m:39s remains)
INFO - root - 2017-12-17 02:31:34.101434: step 190550, loss = 0.50, batch loss = 0.32 (36.4 examples/sec; 0.220 sec/batch; 8h:39m:58s remains)
INFO - root - 2017-12-17 02:31:36.316065: step 190560, loss = 0.45, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 8h:51m:07s remains)
INFO - root - 2017-12-17 02:31:38.553949: step 190570, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 8h:42m:13s remains)
INFO - root - 2017-12-17 02:31:40.758690: step 190580, loss = 0.45, batch loss = 0.27 (35.3 examples/sec; 0.226 sec/batch; 8h:55m:26s remains)
INFO - root - 2017-12-17 02:31:43.000653: step 190590, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 8h:35m:56s remains)
INFO - root - 2017-12-17 02:31:45.231382: step 190600, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.217 sec/batch; 8h:33m:26s remains)
INFO - root - 2017-12-17 02:31:47.572432: step 190610, loss = 0.46, batch loss = 0.29 (36.0 examples/sec; 0.222 sec/batch; 8h:45m:06s remains)
INFO - root - 2017-12-17 02:31:49.789347: step 190620, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 8h:46m:20s remains)
INFO - root - 2017-12-17 02:31:51.993034: step 190630, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 8h:52m:39s remains)
INFO - root - 2017-12-17 02:31:54.236800: step 190640, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 8h:51m:36s remains)
INFO - root - 2017-12-17 02:31:56.484079: step 190650, loss = 0.56, batch loss = 0.38 (36.4 examples/sec; 0.220 sec/batch; 8h:40m:18s remains)
INFO - root - 2017-12-17 02:31:58.676480: step 190660, loss = 0.57, batch loss = 0.39 (35.8 examples/sec; 0.223 sec/batch; 8h:47m:35s remains)
INFO - root - 2017-12-17 02:32:00.903524: step 190670, loss = 0.46, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 9h:03m:25s remains)
INFO - root - 2017-12-17 02:32:03.125911: step 190680, loss = 0.51, batch loss = 0.33 (37.5 examples/sec; 0.213 sec/batch; 8h:23m:49s remains)
INFO - root - 2017-12-17 02:32:05.340861: step 190690, loss = 0.47, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 8h:39m:06s remains)
INFO - root - 2017-12-17 02:32:07.584938: step 190700, loss = 0.52, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 8h:40m:17s remains)
INFO - root - 2017-12-17 02:32:09.928487: step 190710, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 8h:34m:51s remains)
INFO - root - 2017-12-17 02:32:12.154767: step 190720, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 8h:51m:38s remains)
INFO - root - 2017-12-17 02:32:14.389225: step 190730, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 8h:50m:37s remains)
INFO - root - 2017-12-17 02:32:16.576785: step 190740, loss = 0.46, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 8h:32m:00s remains)
INFO - root - 2017-12-17 02:32:18.787222: step 190750, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 8h:50m:39s remains)
INFO - root - 2017-12-17 02:32:21.002964: step 190760, loss = 0.50, batch loss = 0.33 (35.1 examples/sec; 0.228 sec/batch; 8h:58m:09s remains)
INFO - root - 2017-12-17 02:32:23.225181: step 190770, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 8h:28m:30s remains)
INFO - root - 2017-12-17 02:32:25.426038: step 190780, loss = 0.50, batch loss = 0.32 (35.4 examples/sec; 0.226 sec/batch; 8h:53m:10s remains)
INFO - root - 2017-12-17 02:32:27.650138: step 190790, loss = 0.55, batch loss = 0.37 (36.6 examples/sec; 0.219 sec/batch; 8h:36m:03s remains)
INFO - root - 2017-12-17 02:32:29.859675: step 190800, loss = 0.50, batch loss = 0.33 (36.9 examples/sec; 0.217 sec/batch; 8h:31m:48s remains)
INFO - root - 2017-12-17 02:32:32.205379: step 190810, loss = 0.54, batch loss = 0.36 (35.6 examples/sec; 0.225 sec/batch; 8h:50m:46s remains)
INFO - root - 2017-12-17 02:32:34.431549: step 190820, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.230 sec/batch; 9h:03m:52s remains)
INFO - root - 2017-12-17 02:32:36.700751: step 190830, loss = 0.44, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 9h:02m:06s remains)
INFO - root - 2017-12-17 02:32:38.912208: step 190840, loss = 0.46, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 8h:49m:41s remains)
INFO - root - 2017-12-17 02:32:41.116849: step 190850, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 8h:58m:31s remains)
INFO - root - 2017-12-17 02:32:43.327766: step 190860, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 8h:27m:41s remains)
INFO - root - 2017-12-17 02:32:45.514577: step 190870, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 8h:44m:19s remains)
INFO - root - 2017-12-17 02:32:47.765518: step 190880, loss = 0.53, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 8h:49m:34s remains)
INFO - root - 2017-12-17 02:32:49.998129: step 190890, loss = 0.52, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 8h:52m:10s remains)
INFO - root - 2017-12-17 02:32:52.192362: step 190900, loss = 0.48, batch loss = 0.30 (35.5 examples/sec; 0.225 sec/batch; 8h:51m:08s remains)
INFO - root - 2017-12-17 02:32:54.556177: step 190910, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 8h:35m:14s remains)
INFO - root - 2017-12-17 02:32:56.774607: step 190920, loss = 0.46, batch loss = 0.28 (34.4 examples/sec; 0.233 sec/batch; 9h:09m:24s remains)
INFO - root - 2017-12-17 02:32:58.998938: step 190930, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 8h:30m:22s remains)
INFO - root - 2017-12-17 02:33:01.199037: step 190940, loss = 0.50, batch loss = 0.32 (37.6 examples/sec; 0.213 sec/batch; 8h:22m:14s remains)
INFO - root - 2017-12-17 02:33:03.420485: step 190950, loss = 0.40, batch loss = 0.22 (35.7 examples/sec; 0.224 sec/batch; 8h:48m:04s remains)
INFO - root - 2017-12-17 02:33:05.643746: step 190960, loss = 0.52, batch loss = 0.34 (33.7 examples/sec; 0.237 sec/batch; 9h:19m:29s remains)
INFO - root - 2017-12-17 02:33:07.863659: step 190970, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 8h:39m:31s remains)
INFO - root - 2017-12-17 02:33:10.111970: step 190980, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 8h:41m:46s remains)
INFO - root - 2017-12-17 02:33:12.343016: step 190990, loss = 0.58, batch loss = 0.40 (36.5 examples/sec; 0.219 sec/batch; 8h:36m:45s remains)
INFO - root - 2017-12-17 02:33:14.550140: step 191000, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 8h:33m:47s remains)
INFO - root - 2017-12-17 02:33:16.895567: step 191010, loss = 0.48, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 8h:34m:43s remains)
INFO - root - 2017-12-17 02:33:19.113623: step 191020, loss = 0.58, batch loss = 0.40 (34.8 examples/sec; 0.230 sec/batch; 9h:02m:37s remains)
INFO - root - 2017-12-17 02:33:21.296936: step 191030, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 8h:54m:32s remains)
INFO - root - 2017-12-17 02:33:23.534344: step 191040, loss = 0.51, batch loss = 0.34 (37.1 examples/sec; 0.216 sec/batch; 8h:28m:38s remains)
INFO - root - 2017-12-17 02:33:25.764548: step 191050, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 8h:29m:36s remains)
INFO - root - 2017-12-17 02:33:28.009490: step 191060, loss = 0.45, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 8h:50m:43s remains)
INFO - root - 2017-12-17 02:33:30.234604: step 191070, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 8h:30m:17s remains)
INFO - root - 2017-12-17 02:33:32.461962: step 191080, loss = 0.44, batch loss = 0.26 (35.0 examples/sec; 0.229 sec/batch; 8h:59m:13s remains)
INFO - root - 2017-12-17 02:33:34.694189: step 191090, loss = 0.48, batch loss = 0.30 (37.1 examples/sec; 0.216 sec/batch; 8h:28m:39s remains)
INFO - root - 2017-12-17 02:33:36.912043: step 191100, loss = 0.54, batch loss = 0.36 (35.4 examples/sec; 0.226 sec/batch; 8h:52m:48s remains)
INFO - root - 2017-12-17 02:33:39.246470: step 191110, loss = 0.45, batch loss = 0.28 (37.6 examples/sec; 0.213 sec/batch; 8h:21m:23s remains)
INFO - root - 2017-12-17 02:33:41.491058: step 191120, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.229 sec/batch; 8h:58m:32s remains)
INFO - root - 2017-12-17 02:33:43.754636: step 191130, loss = 0.47, batch loss = 0.29 (38.2 examples/sec; 0.209 sec/batch; 8h:12m:54s remains)
INFO - root - 2017-12-17 02:33:45.964176: step 191140, loss = 0.50, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 8h:35m:02s remains)
INFO - root - 2017-12-17 02:33:48.144363: step 191150, loss = 0.43, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 8h:42m:03s remains)
INFO - root - 2017-12-17 02:33:50.356160: step 191160, loss = 0.51, batch loss = 0.33 (37.9 examples/sec; 0.211 sec/batch; 8h:17m:50s remains)
INFO - root - 2017-12-17 02:33:52.560472: step 191170, loss = 0.56, batch loss = 0.38 (33.5 examples/sec; 0.239 sec/batch; 9h:22m:06s remains)
INFO - root - 2017-12-17 02:33:54.775818: step 191180, loss = 0.44, batch loss = 0.26 (37.3 examples/sec; 0.215 sec/batch; 8h:25m:37s remains)
INFO - root - 2017-12-17 02:33:56.979609: step 191190, loss = 0.46, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 8h:49m:18s remains)
INFO - root - 2017-12-17 02:33:59.205641: step 191200, loss = 0.56, batch loss = 0.38 (36.7 examples/sec; 0.218 sec/batch; 8h:33m:25s remains)
INFO - root - 2017-12-17 02:34:01.557743: step 191210, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 8h:43m:34s remains)
INFO - root - 2017-12-17 02:34:03.764246: step 191220, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 8h:25m:55s remains)
INFO - root - 2017-12-17 02:34:05.999935: step 191230, loss = 0.48, batch loss = 0.30 (35.8 examples/sec; 0.224 sec/batch; 8h:46m:50s remains)
INFO - root - 2017-12-17 02:34:08.235873: step 191240, loss = 0.48, batch loss = 0.30 (37.4 examples/sec; 0.214 sec/batch; 8h:23m:53s remains)
INFO - root - 2017-12-17 02:34:10.436318: step 191250, loss = 0.59, batch loss = 0.41 (37.0 examples/sec; 0.216 sec/batch; 8h:28m:38s remains)
INFO - root - 2017-12-17 02:34:12.660186: step 191260, loss = 0.47, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 8h:52m:58s remains)
INFO - root - 2017-12-17 02:34:14.878621: step 191270, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 8h:45m:52s remains)
INFO - root - 2017-12-17 02:34:17.070603: step 191280, loss = 0.57, batch loss = 0.39 (37.6 examples/sec; 0.213 sec/batch; 8h:20m:39s remains)
INFO - root - 2017-12-17 02:34:19.331011: step 191290, loss = 0.50, batch loss = 0.33 (35.1 examples/sec; 0.228 sec/batch; 8h:56m:36s remains)
INFO - root - 2017-12-17 02:34:21.560715: step 191300, loss = 0.51, batch loss = 0.34 (36.3 examples/sec; 0.221 sec/batch; 8h:39m:03s remains)
INFO - root - 2017-12-17 02:34:23.889147: step 191310, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 8h:35m:39s remains)
INFO - root - 2017-12-17 02:34:26.117582: step 191320, loss = 0.50, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 8h:36m:10s remains)
INFO - root - 2017-12-17 02:34:28.335220: step 191330, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 8h:27m:52s remains)
INFO - root - 2017-12-17 02:34:30.544529: step 191340, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 8h:47m:14s remains)
INFO - root - 2017-12-17 02:34:32.780162: step 191350, loss = 0.42, batch loss = 0.24 (34.5 examples/sec; 0.232 sec/batch; 9h:04m:57s remains)
INFO - root - 2017-12-17 02:34:35.003448: step 191360, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 8h:41m:32s remains)
INFO - root - 2017-12-17 02:34:37.234114: step 191370, loss = 0.44, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 8h:37m:13s remains)
INFO - root - 2017-12-17 02:34:39.428232: step 191380, loss = 0.49, batch loss = 0.32 (35.3 examples/sec; 0.226 sec/batch; 8h:52m:26s remains)
INFO - root - 2017-12-17 02:34:41.646227: step 191390, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.224 sec/batch; 8h:45m:56s remains)
INFO - root - 2017-12-17 02:34:43.854484: step 191400, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 8h:47m:33s remains)
INFO - root - 2017-12-17 02:34:46.216943: step 191410, loss = 0.47, batch loss = 0.29 (36.3 examples/sec; 0.220 sec/batch; 8h:38m:18s remains)
INFO - root - 2017-12-17 02:34:48.424199: step 191420, loss = 0.46, batch loss = 0.28 (37.7 examples/sec; 0.212 sec/batch; 8h:18m:39s remains)
INFO - root - 2017-12-17 02:34:50.667937: step 191430, loss = 0.47, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 8h:55m:47s remains)
INFO - root - 2017-12-17 02:34:52.880804: step 191440, loss = 0.54, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 8h:46m:45s remains)
INFO - root - 2017-12-17 02:34:55.110461: step 191450, loss = 0.46, batch loss = 0.28 (36.5 examples/sec; 0.219 sec/batch; 8h:34m:43s remains)
INFO - root - 2017-12-17 02:34:57.313785: step 191460, loss = 0.44, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 8h:32m:02s remains)
INFO - root - 2017-12-17 02:34:59.520987: step 191470, loss = 0.44, batch loss = 0.26 (37.8 examples/sec; 0.211 sec/batch; 8h:16m:54s remains)
INFO - root - 2017-12-17 02:35:01.758439: step 191480, loss = 0.54, batch loss = 0.36 (35.5 examples/sec; 0.226 sec/batch; 8h:50m:08s remains)
INFO - root - 2017-12-17 02:35:03.976468: step 191490, loss = 0.50, batch loss = 0.32 (34.5 examples/sec; 0.232 sec/batch; 9h:05m:20s remains)
INFO - root - 2017-12-17 02:35:06.235867: step 191500, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 8h:58m:18s remains)
INFO - root - 2017-12-17 02:35:08.640816: step 191510, loss = 0.46, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 8h:47m:37s remains)
INFO - root - 2017-12-17 02:35:10.858269: step 191520, loss = 0.55, batch loss = 0.37 (36.3 examples/sec; 0.220 sec/batch; 8h:38m:00s remains)
INFO - root - 2017-12-17 02:35:13.069473: step 191530, loss = 0.52, batch loss = 0.34 (34.8 examples/sec; 0.230 sec/batch; 9h:00m:37s remains)
INFO - root - 2017-12-17 02:35:15.279264: step 191540, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 8h:37m:11s remains)
INFO - root - 2017-12-17 02:35:17.508651: step 191550, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 8h:55m:16s remains)
INFO - root - 2017-12-17 02:35:19.725536: step 191560, loss = 0.42, batch loss = 0.24 (35.8 examples/sec; 0.224 sec/batch; 8h:45m:28s remains)
INFO - root - 2017-12-17 02:35:21.933732: step 191570, loss = 0.46, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 8h:45m:34s remains)
INFO - root - 2017-12-17 02:35:24.177041: step 191580, loss = 0.44, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 8h:41m:31s remains)
INFO - root - 2017-12-17 02:35:26.373806: step 191590, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 8h:48m:39s remains)
INFO - root - 2017-12-17 02:35:28.609861: step 191600, loss = 0.49, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 8h:33m:28s remains)
INFO - root - 2017-12-17 02:35:30.941694: step 191610, loss = 0.49, batch loss = 0.31 (35.8 examples/sec; 0.223 sec/batch; 8h:44m:34s remains)
INFO - root - 2017-12-17 02:35:33.164111: step 191620, loss = 0.53, batch loss = 0.36 (35.0 examples/sec; 0.229 sec/batch; 8h:56m:49s remains)
INFO - root - 2017-12-17 02:35:35.386631: step 191630, loss = 0.46, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 8h:50m:43s remains)
INFO - root - 2017-12-17 02:35:37.654383: step 191640, loss = 0.45, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 8h:38m:29s remains)
INFO - root - 2017-12-17 02:35:39.872683: step 191650, loss = 0.48, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 8h:35m:12s remains)
INFO - root - 2017-12-17 02:35:42.078468: step 191660, loss = 0.52, batch loss = 0.34 (34.8 examples/sec; 0.230 sec/batch; 8h:59m:20s remains)
INFO - root - 2017-12-17 02:35:44.269130: step 191670, loss = 0.48, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 8h:31m:26s remains)
INFO - root - 2017-12-17 02:35:46.454753: step 191680, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 8h:39m:24s remains)
INFO - root - 2017-12-17 02:35:48.674954: step 191690, loss = 0.52, batch loss = 0.35 (37.3 examples/sec; 0.214 sec/batch; 8h:23m:21s remains)
INFO - root - 2017-12-17 02:35:50.914231: step 191700, loss = 0.46, batch loss = 0.28 (34.6 examples/sec; 0.231 sec/batch; 9h:03m:06s remains)
INFO - root - 2017-12-17 02:35:53.305088: step 191710, loss = 0.47, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 8h:39m:09s remains)
INFO - root - 2017-12-17 02:35:55.535033: step 191720, loss = 0.57, batch loss = 0.39 (36.5 examples/sec; 0.219 sec/batch; 8h:34m:30s remains)
INFO - root - 2017-12-17 02:35:57.764264: step 191730, loss = 0.46, batch loss = 0.29 (33.9 examples/sec; 0.236 sec/batch; 9h:13m:18s remains)
INFO - root - 2017-12-17 02:35:59.957577: step 191740, loss = 0.50, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 8h:41m:10s remains)
INFO - root - 2017-12-17 02:36:02.159874: step 191750, loss = 0.53, batch loss = 0.35 (34.7 examples/sec; 0.231 sec/batch; 9h:00m:58s remains)
INFO - root - 2017-12-17 02:36:04.370423: step 191760, loss = 0.47, batch loss = 0.29 (36.9 examples/sec; 0.217 sec/batch; 8h:28m:28s remains)
INFO - root - 2017-12-17 02:36:06.607609: step 191770, loss = 0.49, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 8h:52m:01s remains)
INFO - root - 2017-12-17 02:36:08.871395: step 191780, loss = 0.51, batch loss = 0.33 (38.0 examples/sec; 0.211 sec/batch; 8h:14m:17s remains)
INFO - root - 2017-12-17 02:36:11.094769: step 191790, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 8h:26m:58s remains)
INFO - root - 2017-12-17 02:36:13.290930: step 191800, loss = 0.51, batch loss = 0.33 (38.1 examples/sec; 0.210 sec/batch; 8h:12m:13s remains)
INFO - root - 2017-12-17 02:36:15.646587: step 191810, loss = 0.44, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 8h:54m:00s remains)
INFO - root - 2017-12-17 02:36:17.902178: step 191820, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 8h:48m:03s remains)
INFO - root - 2017-12-17 02:36:20.093740: step 191830, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 8h:42m:10s remains)
INFO - root - 2017-12-17 02:36:22.333227: step 191840, loss = 0.45, batch loss = 0.27 (35.7 examples/sec; 0.224 sec/batch; 8h:45m:30s remains)
INFO - root - 2017-12-17 02:36:24.537137: step 191850, loss = 0.43, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 8h:35m:19s remains)
INFO - root - 2017-12-17 02:36:26.728030: step 191860, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.218 sec/batch; 8h:31m:39s remains)
INFO - root - 2017-12-17 02:36:28.932001: step 191870, loss = 0.51, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 8h:27m:23s remains)
INFO - root - 2017-12-17 02:36:31.122824: step 191880, loss = 0.47, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 8h:24m:25s remains)
INFO - root - 2017-12-17 02:36:33.350262: step 191890, loss = 0.46, batch loss = 0.28 (37.0 examples/sec; 0.216 sec/batch; 8h:26m:55s remains)
INFO - root - 2017-12-17 02:36:35.559095: step 191900, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 8h:32m:28s remains)
INFO - root - 2017-12-17 02:36:37.935155: step 191910, loss = 0.46, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 8h:42m:37s remains)
INFO - root - 2017-12-17 02:36:40.147669: step 191920, loss = 0.44, batch loss = 0.26 (37.1 examples/sec; 0.216 sec/batch; 8h:25m:40s remains)
INFO - root - 2017-12-17 02:36:42.397063: step 191930, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 8h:46m:36s remains)
INFO - root - 2017-12-17 02:36:44.608772: step 191940, loss = 0.50, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 8h:46m:02s remains)
INFO - root - 2017-12-17 02:36:46.837111: step 191950, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 8h:35m:59s remains)
INFO - root - 2017-12-17 02:36:49.055056: step 191960, loss = 0.54, batch loss = 0.36 (36.0 examples/sec; 0.222 sec/batch; 8h:39m:51s remains)
INFO - root - 2017-12-17 02:36:51.316463: step 191970, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 8h:45m:58s remains)
INFO - root - 2017-12-17 02:36:53.547488: step 191980, loss = 0.52, batch loss = 0.34 (32.9 examples/sec; 0.243 sec/batch; 9h:29m:59s remains)
INFO - root - 2017-12-17 02:36:55.746655: step 191990, loss = 0.53, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 8h:39m:06s remains)
INFO - root - 2017-12-17 02:36:57.974074: step 192000, loss = 0.45, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 8h:58m:45s remains)
INFO - root - 2017-12-17 02:37:00.292964: step 192010, loss = 0.48, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 8h:46m:43s remains)
INFO - root - 2017-12-17 02:37:02.483813: step 192020, loss = 0.52, batch loss = 0.34 (36.7 examples/sec; 0.218 sec/batch; 8h:30m:25s remains)
INFO - root - 2017-12-17 02:37:04.670668: step 192030, loss = 0.45, batch loss = 0.27 (37.2 examples/sec; 0.215 sec/batch; 8h:23m:07s remains)
INFO - root - 2017-12-17 02:37:06.874933: step 192040, loss = 0.47, batch loss = 0.29 (36.6 examples/sec; 0.219 sec/batch; 8h:31m:42s remains)
INFO - root - 2017-12-17 02:37:09.080520: step 192050, loss = 0.57, batch loss = 0.39 (35.6 examples/sec; 0.225 sec/batch; 8h:46m:45s remains)
INFO - root - 2017-12-17 02:37:11.314203: step 192060, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 8h:51m:52s remains)
INFO - root - 2017-12-17 02:37:13.500972: step 192070, loss = 0.47, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 8h:42m:20s remains)
INFO - root - 2017-12-17 02:37:15.702837: step 192080, loss = 0.46, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 8h:44m:09s remains)
INFO - root - 2017-12-17 02:37:17.945338: step 192090, loss = 0.51, batch loss = 0.33 (36.7 examples/sec; 0.218 sec/batch; 8h:29m:44s remains)
INFO - root - 2017-12-17 02:37:20.185450: step 192100, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 8h:43m:43s remains)
INFO - root - 2017-12-17 02:37:22.561283: step 192110, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 8h:51m:53s remains)
INFO - root - 2017-12-17 02:37:24.762606: step 192120, loss = 0.47, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 8h:40m:57s remains)
INFO - root - 2017-12-17 02:37:26.993886: step 192130, loss = 0.48, batch loss = 0.30 (36.4 examples/sec; 0.220 sec/batch; 8h:34m:23s remains)
INFO - root - 2017-12-17 02:37:29.176086: step 192140, loss = 0.46, batch loss = 0.29 (37.3 examples/sec; 0.215 sec/batch; 8h:22m:03s remains)
INFO - root - 2017-12-17 02:37:31.401618: step 192150, loss = 0.48, batch loss = 0.30 (34.9 examples/sec; 0.229 sec/batch; 8h:55m:56s remains)
INFO - root - 2017-12-17 02:37:33.642086: step 192160, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 8h:46m:02s remains)
INFO - root - 2017-12-17 02:37:35.839995: step 192170, loss = 0.47, batch loss = 0.29 (36.8 examples/sec; 0.217 sec/batch; 8h:28m:20s remains)
INFO - root - 2017-12-17 02:37:38.070359: step 192180, loss = 0.51, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 8h:57m:22s remains)
INFO - root - 2017-12-17 02:37:40.237342: step 192190, loss = 0.50, batch loss = 0.32 (37.0 examples/sec; 0.216 sec/batch; 8h:25m:05s remains)
INFO - root - 2017-12-17 02:37:42.452435: step 192200, loss = 0.47, batch loss = 0.29 (35.4 examples/sec; 0.226 sec/batch; 8h:48m:54s remains)
INFO - root - 2017-12-17 02:37:44.787071: step 192210, loss = 0.53, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 8h:32m:09s remains)
INFO - root - 2017-12-17 02:37:46.960584: step 192220, loss = 0.45, batch loss = 0.27 (37.8 examples/sec; 0.212 sec/batch; 8h:14m:33s remains)
INFO - root - 2017-12-17 02:37:49.165660: step 192230, loss = 0.45, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 8h:32m:36s remains)
INFO - root - 2017-12-17 02:37:51.377233: step 192240, loss = 0.44, batch loss = 0.26 (34.4 examples/sec; 0.232 sec/batch; 9h:02m:52s remains)
INFO - root - 2017-12-17 02:37:53.603294: step 192250, loss = 0.53, batch loss = 0.35 (34.3 examples/sec; 0.233 sec/batch; 9h:04m:38s remains)
INFO - root - 2017-12-17 02:37:55.823157: step 192260, loss = 0.49, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 8h:28m:45s remains)
INFO - root - 2017-12-17 02:37:58.015551: step 192270, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 8h:25m:52s remains)
INFO - root - 2017-12-17 02:38:00.184123: step 192280, loss = 0.49, batch loss = 0.31 (37.3 examples/sec; 0.214 sec/batch; 8h:20m:56s remains)
INFO - root - 2017-12-17 02:38:02.405677: step 192290, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 8h:51m:16s remains)
INFO - root - 2017-12-17 02:38:04.578655: step 192300, loss = 0.50, batch loss = 0.32 (37.3 examples/sec; 0.214 sec/batch; 8h:21m:08s remains)
INFO - root - 2017-12-17 02:38:06.923924: step 192310, loss = 0.44, batch loss = 0.26 (36.8 examples/sec; 0.217 sec/batch; 8h:27m:49s remains)
INFO - root - 2017-12-17 02:38:09.169386: step 192320, loss = 0.51, batch loss = 0.33 (37.1 examples/sec; 0.216 sec/batch; 8h:24m:11s remains)
INFO - root - 2017-12-17 02:38:11.388830: step 192330, loss = 0.42, batch loss = 0.24 (35.2 examples/sec; 0.227 sec/batch; 8h:50m:53s remains)
INFO - root - 2017-12-17 02:38:13.604296: step 192340, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 8h:22m:25s remains)
INFO - root - 2017-12-17 02:38:15.836871: step 192350, loss = 0.44, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 8h:54m:48s remains)
INFO - root - 2017-12-17 02:38:18.039382: step 192360, loss = 0.49, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 8h:43m:36s remains)
INFO - root - 2017-12-17 02:38:20.235744: step 192370, loss = 0.54, batch loss = 0.36 (37.3 examples/sec; 0.214 sec/batch; 8h:20m:55s remains)
INFO - root - 2017-12-17 02:38:22.434884: step 192380, loss = 0.43, batch loss = 0.25 (36.7 examples/sec; 0.218 sec/batch; 8h:28m:43s remains)
INFO - root - 2017-12-17 02:38:24.673878: step 192390, loss = 0.47, batch loss = 0.30 (34.7 examples/sec; 0.230 sec/batch; 8h:57m:36s remains)
INFO - root - 2017-12-17 02:38:26.863577: step 192400, loss = 0.50, batch loss = 0.32 (37.2 examples/sec; 0.215 sec/batch; 8h:22m:23s remains)
INFO - root - 2017-12-17 02:38:29.165397: step 192410, loss = 0.53, batch loss = 0.35 (37.6 examples/sec; 0.213 sec/batch; 8h:17m:16s remains)
INFO - root - 2017-12-17 02:38:31.384975: step 192420, loss = 0.55, batch loss = 0.37 (35.3 examples/sec; 0.227 sec/batch; 8h:48m:54s remains)
INFO - root - 2017-12-17 02:38:33.591367: step 192430, loss = 0.49, batch loss = 0.31 (37.9 examples/sec; 0.211 sec/batch; 8h:12m:22s remains)
INFO - root - 2017-12-17 02:38:35.821868: step 192440, loss = 0.52, batch loss = 0.34 (36.6 examples/sec; 0.218 sec/batch; 8h:30m:01s remains)
INFO - root - 2017-12-17 02:38:38.035077: step 192450, loss = 0.48, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 8h:40m:16s remains)
INFO - root - 2017-12-17 02:38:40.229002: step 192460, loss = 0.45, batch loss = 0.27 (37.0 examples/sec; 0.216 sec/batch; 8h:24m:24s remains)
INFO - root - 2017-12-17 02:38:42.434135: step 192470, loss = 0.47, batch loss = 0.29 (34.6 examples/sec; 0.231 sec/batch; 8h:59m:57s remains)
INFO - root - 2017-12-17 02:38:44.647811: step 192480, loss = 0.49, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 8h:48m:56s remains)
INFO - root - 2017-12-17 02:38:46.833755: step 192490, loss = 0.51, batch loss = 0.33 (35.4 examples/sec; 0.226 sec/batch; 8h:47m:34s remains)
INFO - root - 2017-12-17 02:38:49.031831: step 192500, loss = 0.46, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 8h:26m:49s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-192500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-fixqian-clip20/model.ckpt-192500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 02:38:51.860950: step 192510, loss = 0.53, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 8h:32m:18s remains)
INFO - root - 2017-12-17 02:38:54.124635: step 192520, loss = 0.47, batch loss = 0.29 (33.0 examples/sec; 0.242 sec/batch; 9h:25m:23s remains)
INFO - root - 2017-12-17 02:38:56.347803: step 192530, loss = 0.45, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 9h:03m:58s remains)
INFO - root - 2017-12-17 02:38:58.575924: step 192540, loss = 0.46, batch loss = 0.28 (36.6 examples/sec; 0.219 sec/batch; 8h:29m:51s remains)
INFO - root - 2017-12-17 02:39:00.758890: step 192550, loss = 0.50, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 8h:35m:09s remains)
INFO - root - 2017-12-17 02:39:02.956438: step 192560, loss = 0.48, batch loss = 0.30 (37.2 examples/sec; 0.215 sec/batch; 8h:21m:16s remains)
INFO - root - 2017-12-17 02:39:05.195721: step 192570, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 8h:45m:04s remains)
INFO - root - 2017-12-17 02:39:07.420209: step 192580, loss = 0.45, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 8h:40m:07s remains)
INFO - root - 2017-12-17 02:39:09.659749: step 192590, loss = 0.45, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 8h:38m:38s remains)
INFO - root - 2017-12-17 02:39:11.850571: step 192600, loss = 0.47, batch loss = 0.29 (35.5 examples/sec; 0.225 sec/batch; 8h:45m:38s remains)
INFO - root - 2017-12-17 02:39:14.231679: step 192610, loss = 0.49, batch loss = 0.31 (36.7 examples/sec; 0.218 sec/batch; 8h:27m:52s remains)
INFO - root - 2017-12-17 02:39:16.459225: step 192620, loss = 0.47, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 8h:36m:11s remains)
INFO - root - 2017-12-17 02:39:18.664114: step 192630, loss = 0.47, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 8h:42m:42s remains)
INFO - root - 2017-12-17 02:39:20.896259: step 192640, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 8h:47m:04s remains)
INFO - root - 2017-12-17 02:39:23.119733: step 192650, loss = 0.48, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 8h:51m:29s remains)
INFO - root - 2017-12-17 02:39:25.323508: step 192660, loss = 0.45, batch loss = 0.27 (36.7 examples/sec; 0.218 sec/batch; 8h:28m:06s remains)
INFO - root - 2017-12-17 02:39:27.581236: step 192670, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 8h:23m:55s remains)
INFO - root - 2017-12-17 02:39:29.766669: step 192680, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.221 sec/batch; 8h:35m:48s remains)
INFO - root - 2017-12-17 02:39:31.953036: step 192690, loss = 0.50, batch loss = 0.32 (36.3 examples/sec; 0.221 sec/batch; 8h:33m:54s remains)
INFO - root - 2017-12-17 02:39:34.193233: step 192700, loss = 0.45, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 8h:25m:19s remains)
INFO - root - 2017-12-17 02:39:36.507997: step 192710, loss = 0.49, batch loss = 0.31 (35.5 examples/sec; 0.225 sec/batch; 8h:44m:44s remains)
INFO - root - 2017-12-17 02:39:38.776482: step 192720, loss = 0.48, batch loss = 0.31 (34.9 examples/sec; 0.229 sec/batch; 8h:53m:34s remains)
INFO - root - 2017-12-17 02:39:40.957660: step 192730, loss = 0.50, batch loss = 0.32 (35.7 examples/sec; 0.224 sec/batch; 8h:41m:41s remains)
INFO - root - 2017-12-17 02:39:43.160201: step 192740, loss = 0.51, batch loss = 0.33 (36.5 examples/sec; 0.219 sec/batch; 8h:29m:54s remains)
INFO - root - 2017-12-17 02:39:45.349405: step 192750, loss = 0.48, batch loss = 0.31 (36.9 examples/sec; 0.217 sec/batch; 8h:25m:03s remains)
INFO - root - 2017-12-17 02:39:47.557106: step 192760, loss = 0.45, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 8h:50m:13s remains)
INFO - root - 2017-12-17 02:39:49.776125: step 192770, loss = 0.48, batch loss = 0.30 (37.3 examples/sec; 0.215 sec/batch; 8h:20m:05s remains)
INFO - root - 2017-12-17 02:39:52.037435: step 192780, loss = 0.51, batch loss = 0.33 (35.5 examples/sec; 0.225 sec/batch; 8h:44m:21s remains)
INFO - root - 2017-12-17 02:39:54.225848: step 192790, loss = 0.45, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 8h:46m:19s remains)
INFO - root - 2017-12-17 02:39:56.462178: step 192800, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.228 sec/batch; 8h:51m:25s remains)
INFO - root - 2017-12-17 02:39:58.815020: step 192810, loss = 0.45, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 8h:34m:34s remains)
INFO - root - 2017-12-17 02:40:01.000579: step 192820, loss = 0.48, batch loss = 0.30 (36.9 examples/sec; 0.217 sec/batch; 8h:24m:12s remains)
INFO - root - 2017-12-17 02:40:03.212768: step 192830, loss = 0.49, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 8h:37m:30s remains)
INFO - root - 2017-12-17 02:40:05.429635: step 192840, loss = 0.44, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 8h:29m:53s remains)
INFO - root - 2017-12-17 02:40:07.640183: step 192850, loss = 0.49, batch loss = 0.31 (37.4 examples/sec; 0.214 sec/batch; 8h:17m:27s remains)
INFO - root - 2017-12-17 02:40:09.847436: step 192860, loss = 0.49, batch loss = 0.31 (37.6 examples/sec; 0.213 sec/batch; 8h:15m:20s remains)
INFO - root - 2017-12-17 02:40:12.063749: step 192870, loss = 0.46, batch loss = 0.28 (34.2 examples/sec; 0.234 sec/batch; 9h:03m:34s remains)
INFO - root - 2017-12-17 02:40:14.242242: step 192880, loss = 0.46, batch loss = 0.29 (37.5 examples/sec; 0.213 sec/batch; 8h:16m:30s remains)
INFO - root - 2017-12-17 02:40:16.488624: step 192890, loss = 0.51, batch loss = 0.33 (37.7 examples/sec; 0.212 sec/batch; 8h:14m:03s remains)
INFO - root - 2017-12-17 02:40:18.728997: step 192900, loss = 0.46, batch loss = 0.28 (33.5 examples/sec; 0.239 sec/batch; 9h:15m:02s remains)
INFO - root - 2017-12-17 02:40:21.068036: step 192910, loss = 0.52, batch loss = 0.35 (37.1 examples/sec; 0.215 sec/batch; 8h:21m:17s remains)
INFO - root - 2017-12-17 02:40:23.263844: step 192920, loss = 0.49, batch loss = 0.31 (36.6 examples/sec; 0.219 sec/batch; 8h:28m:52s remains)
INFO - root - 2017-12-17 02:40:25.479860: step 192930, loss = 0.46, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 8h:49m:03s remains)
INFO - root - 2017-12-17 02:40:27.706040: step 192940, loss = 0.43, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 8h:33m:48s remains)
INFO - root - 2017-12-17 02:40:29.936120: step 192950, loss = 0.43, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 8h:29m:07s remains)
INFO - root - 2017-12-17 02:40:32.173173: step 192960, loss = 0.49, batch loss = 0.31 (36.1 examples/sec; 0.222 sec/batch; 8h:35m:19s remains)
INFO - root - 2017-12-17 02:40:34.363881: step 192970, loss = 0.47, batch loss = 0.29 (37.4 examples/sec; 0.214 sec/batch; 8h:17m:20s remains)
INFO - root - 2017-12-17 02:40:36.580804: step 192980, loss = 0.50, batch loss = 0.32 (35.3 examples/sec; 0.226 sec/batch; 8h:46m:26s remains)
INFO - root - 2017-12-17 02:40:38.797202: step 192990, loss = 0.45, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 8h:31m:57s remains)
INFO - root - 2017-12-17 02:40:40.986885: step 193000, loss = 0.49, batch loss = 0.31 (37.1 examples/sec; 0.216 sec/batch; 8h:21m:22s remains)
INFO - root - 2017-12-17 02:40:43.337615: step 193010, loss = 0.50, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 8h:27m:02s remains)
INFO - root - 2017-12-17 02:40:45.533456: step 193020, loss = 0.46, batch loss = 0.28 (36.7 examples/sec; 0.218 sec/batch; 8h:26m:45s remains)
INFO - root - 2017-12-17 02:40:47.737608: step 193030, loss = 0.48, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 8h:33m:11s remains)
INFO - root - 2017-12-17 02:40:49.975343: step 193040, loss = 0.43, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 8h:40m:30s remains)
INFO - root - 2017-12-17 02:40:52.150283: step 193050, loss = 0.44, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 8h:33m:42s remains)
INFO - root - 2017-12-17 02:40:54.384228: step 193060, loss = 0.47, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 8h:47m:53s remains)
INFO - root - 2017-12-17 02:40:56.604911: step 193070, loss = 0.47, batch loss = 0.29 (35.6 examples/sec; 0.225 sec/batch; 8h:42m:12s remains)
INFO - root - 2017-12-17 02:40:58.798469: step 193080, loss = 0.47, batch loss = 0.29 (37.1 examples/sec; 0.215 sec/batch; 8h:20m:38s remains)
INFO - root - 2017-12-17 02:41:01.037514: step 193090, loss = 0.52, batch loss = 0.34 (34.7 examples/sec; 0.230 sec/batch; 8h:55m:04s remains)
INFO - root - 2017-12-17 02:41:03.289032: step 193100, loss = 0.48, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 8h:34m:47s remains)
INFO - root - 2017-12-17 02:41:05.638341: step 193110, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 8h:30m:09s remains)
INFO - root - 2017-12-17 02:41:07.868908: step 193120, loss = 0.46, batch loss = 0.28 (34.7 examples/sec; 0.230 sec/batch; 8h:55m:03s remains)
INFO - root - 2017-12-17 02:41:10.074070: step 193130, loss = 0.48, batch loss = 0.30 (37.0 examples/sec; 0.216 sec/batch; 8h:22m:00s remains)
INFO - root - 2017-12-17 02:41:12.284339: step 193140, loss = 0.45, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 8h:28m:02s remains)
INFO - root - 2017-12-17 02:41:14.494462: step 193150, loss = 0.49, batch loss = 0.31 (36.4 examples/sec; 0.220 sec/batch; 8h:30m:17s remains)
INFO - root - 2017-12-17 02:41:16.690508: step 193160, loss = 0.45, batch loss = 0.28 (37.8 examples/sec; 0.212 sec/batch; 8h:11m:54s remains)
INFO - root - 2017-12-17 02:41:18.905783: step 193170, loss = 0.46, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 8h:29m:48s remains)
INFO - root - 2017-12-17 02:41:21.106070: step 193180, loss = 0.54, batch loss = 0.36 (37.0 examples/sec; 0.216 sec/batch; 8h:22m:41s remains)
INFO - root - 2017-12-17 02:41:23.351982: step 193190, loss = 0.46, batch loss = 0.28 (35.0 examples/sec; 0.228 sec/batch; 8h:50m:23s remains)
INFO - root - 2017-12-17 02:41:25.618755: step 193200, loss = 0.47, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 8h:46m:11s remains)
INFO - root - 2017-12-17 02:41:27.966313: step 193210, loss = 0.48, batch loss = 0.30 (37.6 examples/sec; 0.213 sec/batch; 8h:14m:11s remains)
INFO - root - 2017-12-17 02:41:30.210941: step 193220, loss = 0.44, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 8h:34m:50s remains)
INFO - root - 2017-12-17 02:41:32.440251: step 193230, loss = 0.49, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 8h:47m:47s remains)
INFO - root - 2017-12-17 02:41:34.658658: step 193240, loss = 0.48, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 8h:31m:20s remains)
