INFO - Siam-FC - Running command 'main'
INFO - Siam-FC - Started run with ID "339"
INFO - root - Creating training directory: /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1
INFO - root - preproces -- siamese_fc_color
WARNING - root - root is not explicitly specified, using default value: None
INFO - root - For training, we use instance size 255 - 2 * 8 ...
WARNING - root - init_method is not explicitly specified, using default value: None
INFO - root - preproces -- None
WARNING - root - root is not explicitly specified, using default value: None
/home/v-chaoqw/MYSFC-ORI/workspace/train_imdb.pickle
inputs Tensor("train/batch:0", shape=(8, 127, 127, 3), dtype=float32, device=/device:CPU:0)
conv1 Tensor("train/siamese_fc/pool1/MaxPool:0", shape=(8, 29, 29, 96), dtype=float32)
net Tensor("train/siamese_fc/conv4/concat:0", shape=(8, 8, 8, 384), dtype=float32)
Tensor("train/siamese_fc/conv5/def/transpose:0", shape=(8, 384, 8, 8), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(256, 384, 3, 3) dtype=float32_ref> Tensor("train/siamese_fc/conv5/def/transpose_1:0", shape=(8, 18, 8, 8), dtype=float32)
inputs Tensor("train/batch:1", shape=(8, 239, 239, 3), dtype=float32, device=/device:CPU:0)
conv1 Tensor("train/siamese_fc_1/pool1/MaxPool:0", shape=(8, 57, 57, 96), dtype=float32)
net Tensor("train/siamese_fc_1/conv4/concat:0", shape=(8, 22, 22, 384), dtype=float32)
Tensor("train/siamese_fc_1/conv5/def/transpose:0", shape=(8, 384, 22, 22), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(256, 384, 3, 3) dtype=float32_ref> Tensor("train/siamese_fc_1/conv5/def/transpose_1:0", shape=(8, 18, 22, 22), dtype=float32)
/home/v-chaoqw/MYSFC-ORI/workspace/val_imdb.pickle
INFO - root - For training, we use instance size 255 - 2 * 8 ...
WARNING - root - init_method is not explicitly specified, using default value: None
2017-12-17 02:54:51.610794: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 02:54:51.610869: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 02:54:51.610889: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 02:54:51.610911: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 02:54:51.610932: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 02:54:52.720508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 5791:00:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2017-12-17 02:54:52.720581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-12-17 02:54:52.720608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-12-17 02:54:52.720633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 5791:00:00.0)
INFO - root - Restore from last checkpoint: /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO:tensorflow:Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO - tensorflow - Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO - root - Starting threads 0 ...

INFO - root - Starting threads 0 ...

INFO - root - training for 332500 steps
INFO - root - 2017-12-17 02:54:57.281672: step 0, loss = 2.28, batch loss = 2.23 (2.5 examples/sec; 3.163 sec/batch; 292h:08m:38s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
inputs Tensor("val/batch:0", shape=(8, 127, 127, 3), dtype=float32, device=/device:CPU:0)
conv1 Tensor("val/siamese_fc/pool1/MaxPool:0", shape=(8, 29, 29, 96), dtype=float32)
net Tensor("val/siamese_fc/conv4/concat:0", shape=(8, 8, 8, 384), dtype=float32)
Tensor("val/siamese_fc/conv5/def/transpose:0", shape=(8, 384, 8, 8), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(256, 384, 3, 3) dtype=float32_ref> Tensor("val/siamese_fc/conv5/def/transpose_1:0", shape=(8, 18, 8, 8), dtype=float32)
inputs Tensor("val/batch:1", shape=(8, 239, 239, 3), dtype=float32, device=/device:CPU:0)
conv1 Tensor("val/siamese_fc_1/pool1/MaxPool:0", shape=(8, 57, 57, 96), dtype=float32)
net Tensor("val/siamese_fc_1/conv4/concat:0", shape=(8, 22, 22, 384), dtype=float32)
Tensor("val/siamese_fc_1/conv5/def/transpose:0", shape=(8, 384, 22, 22), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(256, 384, 3, 3) dtype=float32_ref> Tensor("val/siamese_fc_1/conv5/def/transpose_1:0", shape=(8, 18, 22, 22), dtype=float32)
INFO - root - 2017-12-17 02:55:00.493625: step 10, loss = 1.27, batch loss = 1.21 (36.9 examples/sec; 0.217 sec/batch; 20h:02m:47s remains)
INFO - root - 2017-12-17 02:55:02.631838: step 20, loss = 0.69, batch loss = 0.63 (36.7 examples/sec; 0.218 sec/batch; 20h:09m:31s remains)
INFO - root - 2017-12-17 02:55:04.813797: step 30, loss = 0.65, batch loss = 0.59 (37.0 examples/sec; 0.216 sec/batch; 19h:58m:49s remains)
INFO - root - 2017-12-17 02:55:06.959377: step 40, loss = 0.78, batch loss = 0.71 (37.3 examples/sec; 0.215 sec/batch; 19h:49m:05s remains)
INFO - root - 2017-12-17 02:55:09.116421: step 50, loss = 0.61, batch loss = 0.54 (36.9 examples/sec; 0.217 sec/batch; 20h:02m:43s remains)
INFO - root - 2017-12-17 02:55:11.255284: step 60, loss = 0.56, batch loss = 0.49 (36.9 examples/sec; 0.217 sec/batch; 19h:59m:56s remains)
INFO - root - 2017-12-17 02:55:13.389857: step 70, loss = 0.50, batch loss = 0.43 (37.3 examples/sec; 0.215 sec/batch; 19h:49m:53s remains)
INFO - root - 2017-12-17 02:55:15.555145: step 80, loss = 0.60, batch loss = 0.52 (35.2 examples/sec; 0.228 sec/batch; 21h:00m:54s remains)
INFO - root - 2017-12-17 02:55:17.729316: step 90, loss = 0.47, batch loss = 0.40 (37.5 examples/sec; 0.214 sec/batch; 19h:43m:10s remains)
INFO - root - 2017-12-17 02:55:19.878280: step 100, loss = 0.47, batch loss = 0.40 (37.3 examples/sec; 0.215 sec/batch; 19h:49m:08s remains)
INFO - root - 2017-12-17 02:55:22.200845: step 110, loss = 0.50, batch loss = 0.43 (36.9 examples/sec; 0.217 sec/batch; 20h:02m:36s remains)
INFO - root - 2017-12-17 02:55:24.381082: step 120, loss = 0.57, batch loss = 0.50 (35.7 examples/sec; 0.224 sec/batch; 20h:41m:35s remains)
INFO - root - 2017-12-17 02:55:26.598823: step 130, loss = 0.51, batch loss = 0.44 (37.2 examples/sec; 0.215 sec/batch; 19h:49m:54s remains)
INFO - root - 2017-12-17 02:55:28.774365: step 140, loss = 0.47, batch loss = 0.40 (37.3 examples/sec; 0.214 sec/batch; 19h:47m:41s remains)
INFO - root - 2017-12-17 02:55:30.974774: step 150, loss = 0.42, batch loss = 0.35 (36.8 examples/sec; 0.217 sec/batch; 20h:02m:41s remains)
INFO - root - 2017-12-17 02:55:33.214252: step 160, loss = 0.42, batch loss = 0.35 (36.3 examples/sec; 0.220 sec/batch; 20h:20m:01s remains)
INFO - root - 2017-12-17 02:55:35.378480: step 170, loss = 0.44, batch loss = 0.37 (37.4 examples/sec; 0.214 sec/batch; 19h:45m:34s remains)
INFO - root - 2017-12-17 02:55:37.595066: step 180, loss = 0.43, batch loss = 0.35 (34.8 examples/sec; 0.230 sec/batch; 21h:14m:23s remains)
INFO - root - 2017-12-17 02:55:39.787552: step 190, loss = 0.40, batch loss = 0.33 (36.6 examples/sec; 0.218 sec/batch; 20h:09m:32s remains)
INFO - root - 2017-12-17 02:55:41.960631: step 200, loss = 0.52, batch loss = 0.45 (36.5 examples/sec; 0.219 sec/batch; 20h:12m:53s remains)
INFO - root - 2017-12-17 02:55:44.266696: step 210, loss = 0.45, batch loss = 0.38 (36.8 examples/sec; 0.217 sec/batch; 20h:03m:08s remains)
INFO - root - 2017-12-17 02:55:46.430786: step 220, loss = 0.48, batch loss = 0.41 (36.6 examples/sec; 0.218 sec/batch; 20h:08m:54s remains)
INFO - root - 2017-12-17 02:55:48.611291: step 230, loss = 0.42, batch loss = 0.35 (36.3 examples/sec; 0.221 sec/batch; 20h:21m:31s remains)
INFO - root - 2017-12-17 02:55:50.817117: step 240, loss = 0.43, batch loss = 0.36 (36.8 examples/sec; 0.217 sec/batch; 20h:03m:04s remains)
INFO - root - 2017-12-17 02:55:53.047607: step 250, loss = 0.48, batch loss = 0.41 (36.5 examples/sec; 0.219 sec/batch; 20h:14m:57s remains)
INFO - root - 2017-12-17 02:55:55.260760: step 260, loss = 0.39, batch loss = 0.32 (33.6 examples/sec; 0.238 sec/batch; 21h:57m:37s remains)
INFO - root - 2017-12-17 02:55:57.442347: step 270, loss = 0.50, batch loss = 0.43 (37.2 examples/sec; 0.215 sec/batch; 19h:50m:40s remains)
INFO - root - 2017-12-17 02:55:59.644489: step 280, loss = 0.45, batch loss = 0.38 (34.5 examples/sec; 0.232 sec/batch; 21h:25m:15s remains)
INFO - root - 2017-12-17 02:56:01.888301: step 290, loss = 0.39, batch loss = 0.32 (36.2 examples/sec; 0.221 sec/batch; 20h:24m:13s remains)
INFO - root - 2017-12-17 02:56:04.095384: step 300, loss = 0.45, batch loss = 0.38 (36.8 examples/sec; 0.217 sec/batch; 20h:03m:15s remains)
INFO - root - 2017-12-17 02:56:06.483811: step 310, loss = 0.50, batch loss = 0.43 (36.4 examples/sec; 0.220 sec/batch; 20h:15m:43s remains)
INFO - root - 2017-12-17 02:56:08.706260: step 320, loss = 0.56, batch loss = 0.49 (35.8 examples/sec; 0.223 sec/batch; 20h:36m:51s remains)
INFO - root - 2017-12-17 02:56:10.923164: step 330, loss = 0.43, batch loss = 0.36 (34.9 examples/sec; 0.230 sec/batch; 21h:10m:41s remains)
INFO - root - 2017-12-17 02:56:13.107007: step 340, loss = 0.44, batch loss = 0.37 (35.3 examples/sec; 0.226 sec/batch; 20h:53m:30s remains)
INFO - root - 2017-12-17 02:56:15.296666: step 350, loss = 0.45, batch loss = 0.38 (35.9 examples/sec; 0.223 sec/batch; 20h:33m:03s remains)
INFO - root - 2017-12-17 02:56:17.486884: step 360, loss = 0.41, batch loss = 0.34 (36.9 examples/sec; 0.217 sec/batch; 20h:01m:35s remains)
INFO - root - 2017-12-17 02:56:19.670297: step 370, loss = 0.44, batch loss = 0.37 (35.9 examples/sec; 0.223 sec/batch; 20h:31m:51s remains)
INFO - root - 2017-12-17 02:56:21.952651: step 380, loss = 0.48, batch loss = 0.41 (36.4 examples/sec; 0.220 sec/batch; 20h:15m:39s remains)
INFO - root - 2017-12-17 02:56:24.216776: step 390, loss = 0.47, batch loss = 0.40 (36.1 examples/sec; 0.221 sec/batch; 20h:25m:44s remains)
INFO - root - 2017-12-17 02:56:26.431041: step 400, loss = 0.46, batch loss = 0.39 (36.7 examples/sec; 0.218 sec/batch; 20h:05m:00s remains)
INFO - root - 2017-12-17 02:56:28.740216: step 410, loss = 0.47, batch loss = 0.40 (35.9 examples/sec; 0.223 sec/batch; 20h:33m:33s remains)
INFO - root - 2017-12-17 02:56:30.988280: step 420, loss = 0.40, batch loss = 0.33 (37.0 examples/sec; 0.216 sec/batch; 19h:57m:35s remains)
INFO - root - 2017-12-17 02:56:33.169332: step 430, loss = 0.47, batch loss = 0.40 (36.6 examples/sec; 0.219 sec/batch; 20h:10m:43s remains)
INFO - root - 2017-12-17 02:56:35.353273: step 440, loss = 0.45, batch loss = 0.38 (35.6 examples/sec; 0.224 sec/batch; 20h:41m:58s remains)
INFO - root - 2017-12-17 02:56:37.593203: step 450, loss = 0.71, batch loss = 0.64 (34.4 examples/sec; 0.232 sec/batch; 21h:25m:34s remains)
INFO - root - 2017-12-17 02:56:39.817664: step 460, loss = 0.37, batch loss = 0.30 (37.5 examples/sec; 0.213 sec/batch; 19h:40m:48s remains)
INFO - root - 2017-12-17 02:56:42.046103: step 470, loss = 0.45, batch loss = 0.38 (36.6 examples/sec; 0.218 sec/batch; 20h:08m:54s remains)
INFO - root - 2017-12-17 02:56:44.295025: step 480, loss = 0.37, batch loss = 0.30 (34.7 examples/sec; 0.231 sec/batch; 21h:16m:21s remains)
INFO - root - 2017-12-17 02:56:46.548824: step 490, loss = 0.31, batch loss = 0.24 (35.8 examples/sec; 0.224 sec/batch; 20h:37m:14s remains)
INFO - root - 2017-12-17 02:56:48.737728: step 500, loss = 0.55, batch loss = 0.48 (35.9 examples/sec; 0.223 sec/batch; 20h:33m:00s remains)
INFO - root - 2017-12-17 02:56:51.064465: step 510, loss = 0.34, batch loss = 0.28 (35.8 examples/sec; 0.224 sec/batch; 20h:37m:22s remains)
INFO - root - 2017-12-17 02:56:53.291700: step 520, loss = 0.55, batch loss = 0.49 (36.2 examples/sec; 0.221 sec/batch; 20h:21m:39s remains)
INFO - root - 2017-12-17 02:56:55.483105: step 530, loss = 0.30, batch loss = 0.23 (36.7 examples/sec; 0.218 sec/batch; 20h:06m:54s remains)
INFO - root - 2017-12-17 02:56:57.666081: step 540, loss = 0.45, batch loss = 0.39 (35.1 examples/sec; 0.228 sec/batch; 21h:01m:34s remains)
INFO - root - 2017-12-17 02:56:59.877921: step 550, loss = 0.45, batch loss = 0.39 (37.5 examples/sec; 0.213 sec/batch; 19h:38m:42s remains)
INFO - root - 2017-12-17 02:57:02.079720: step 560, loss = 0.37, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 20h:02m:35s remains)
INFO - root - 2017-12-17 02:57:04.262238: step 570, loss = 0.48, batch loss = 0.41 (36.9 examples/sec; 0.217 sec/batch; 19h:57m:50s remains)
INFO - root - 2017-12-17 02:57:06.456921: step 580, loss = 0.45, batch loss = 0.38 (35.9 examples/sec; 0.223 sec/batch; 20h:32m:25s remains)
INFO - root - 2017-12-17 02:57:08.651290: step 590, loss = 0.36, batch loss = 0.29 (37.2 examples/sec; 0.215 sec/batch; 19h:48m:46s remains)
INFO - root - 2017-12-17 02:57:10.829005: step 600, loss = 0.52, batch loss = 0.45 (37.2 examples/sec; 0.215 sec/batch; 19h:48m:38s remains)
INFO - root - 2017-12-17 02:57:13.137370: step 610, loss = 0.50, batch loss = 0.43 (37.3 examples/sec; 0.214 sec/batch; 19h:44m:55s remains)
INFO - root - 2017-12-17 02:57:15.299790: step 620, loss = 0.36, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 20h:13m:25s remains)
INFO - root - 2017-12-17 02:57:17.472456: step 630, loss = 0.33, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 20h:57m:28s remains)
INFO - root - 2017-12-17 02:57:19.670757: step 640, loss = 0.42, batch loss = 0.35 (37.8 examples/sec; 0.212 sec/batch; 19h:31m:40s remains)
INFO - root - 2017-12-17 02:57:21.886038: step 650, loss = 0.34, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 20h:12m:47s remains)
INFO - root - 2017-12-17 02:57:24.071293: step 660, loss = 0.35, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 20h:17m:01s remains)
INFO - root - 2017-12-17 02:57:26.234699: step 670, loss = 0.32, batch loss = 0.25 (37.5 examples/sec; 0.213 sec/batch; 19h:40m:45s remains)
INFO - root - 2017-12-17 02:57:28.438744: step 680, loss = 0.34, batch loss = 0.27 (36.9 examples/sec; 0.217 sec/batch; 19h:57m:35s remains)
INFO - root - 2017-12-17 02:57:30.659086: step 690, loss = 0.33, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 20h:43m:49s remains)
INFO - root - 2017-12-17 02:57:32.838269: step 700, loss = 0.34, batch loss = 0.28 (37.5 examples/sec; 0.213 sec/batch; 19h:38m:27s remains)
INFO - root - 2017-12-17 02:57:35.162527: step 710, loss = 0.41, batch loss = 0.35 (34.2 examples/sec; 0.234 sec/batch; 21h:33m:35s remains)
INFO - root - 2017-12-17 02:57:37.353993: step 720, loss = 0.35, batch loss = 0.28 (36.8 examples/sec; 0.217 sec/batch; 20h:01m:50s remains)
INFO - root - 2017-12-17 02:57:39.544642: step 730, loss = 0.35, batch loss = 0.29 (36.1 examples/sec; 0.222 sec/batch; 20h:25m:53s remains)
INFO - root - 2017-12-17 02:57:41.764066: step 740, loss = 0.31, batch loss = 0.24 (36.5 examples/sec; 0.219 sec/batch; 20h:12m:29s remains)
INFO - root - 2017-12-17 02:57:44.003155: step 750, loss = 0.37, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 20h:06m:14s remains)
INFO - root - 2017-12-17 02:57:46.200079: step 760, loss = 0.39, batch loss = 0.32 (37.1 examples/sec; 0.215 sec/batch; 19h:51m:15s remains)
INFO - root - 2017-12-17 02:57:48.373310: step 770, loss = 0.43, batch loss = 0.36 (36.7 examples/sec; 0.218 sec/batch; 20h:04m:21s remains)
INFO - root - 2017-12-17 02:57:50.567827: step 780, loss = 0.28, batch loss = 0.21 (36.0 examples/sec; 0.222 sec/batch; 20h:26m:57s remains)
INFO - root - 2017-12-17 02:57:52.781300: step 790, loss = 0.37, batch loss = 0.30 (34.9 examples/sec; 0.230 sec/batch; 21h:08m:52s remains)
INFO - root - 2017-12-17 02:57:55.015400: step 800, loss = 0.36, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 20h:53m:41s remains)
INFO - root - 2017-12-17 02:57:57.389486: step 810, loss = 0.31, batch loss = 0.24 (36.4 examples/sec; 0.220 sec/batch; 20h:16m:00s remains)
INFO - root - 2017-12-17 02:57:59.556622: step 820, loss = 0.42, batch loss = 0.35 (36.6 examples/sec; 0.218 sec/batch; 20h:07m:30s remains)
INFO - root - 2017-12-17 02:58:01.728520: step 830, loss = 0.45, batch loss = 0.38 (36.2 examples/sec; 0.221 sec/batch; 20h:20m:53s remains)
INFO - root - 2017-12-17 02:58:03.945782: step 840, loss = 0.35, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 21h:15m:56s remains)
INFO - root - 2017-12-17 02:58:06.147875: step 850, loss = 0.33, batch loss = 0.26 (35.3 examples/sec; 0.227 sec/batch; 20h:54m:01s remains)
INFO - root - 2017-12-17 02:58:08.374529: step 860, loss = 0.36, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 20h:58m:16s remains)
INFO - root - 2017-12-17 02:58:10.556397: step 870, loss = 0.34, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 20h:10m:00s remains)
INFO - root - 2017-12-17 02:58:12.732888: step 880, loss = 0.37, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 20h:02m:08s remains)
INFO - root - 2017-12-17 02:58:14.915313: step 890, loss = 0.41, batch loss = 0.34 (36.8 examples/sec; 0.217 sec/batch; 20h:01m:19s remains)
INFO - root - 2017-12-17 02:58:17.127522: step 900, loss = 0.33, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 20h:17m:18s remains)
INFO - root - 2017-12-17 02:58:19.425735: step 910, loss = 0.33, batch loss = 0.26 (37.3 examples/sec; 0.215 sec/batch; 19h:46m:00s remains)
INFO - root - 2017-12-17 02:58:21.608438: step 920, loss = 0.42, batch loss = 0.35 (37.1 examples/sec; 0.215 sec/batch; 19h:50m:25s remains)
INFO - root - 2017-12-17 02:58:23.845140: step 930, loss = 0.37, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 21h:02m:02s remains)
INFO - root - 2017-12-17 02:58:26.080546: step 940, loss = 0.39, batch loss = 0.33 (36.6 examples/sec; 0.219 sec/batch; 20h:08m:47s remains)
INFO - root - 2017-12-17 02:58:28.316624: step 950, loss = 0.53, batch loss = 0.46 (36.8 examples/sec; 0.217 sec/batch; 20h:00m:01s remains)
INFO - root - 2017-12-17 02:58:30.514701: step 960, loss = 0.36, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 20h:05m:10s remains)
INFO - root - 2017-12-17 02:58:32.733829: step 970, loss = 0.29, batch loss = 0.23 (36.0 examples/sec; 0.222 sec/batch; 20h:28m:34s remains)
INFO - root - 2017-12-17 02:58:34.927374: step 980, loss = 0.30, batch loss = 0.23 (36.8 examples/sec; 0.217 sec/batch; 20h:00m:00s remains)
INFO - root - 2017-12-17 02:58:37.126197: step 990, loss = 0.38, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 20h:29m:41s remains)
INFO - root - 2017-12-17 02:58:39.342292: step 1000, loss = 0.37, batch loss = 0.30 (36.8 examples/sec; 0.217 sec/batch; 19h:59m:55s remains)
INFO - root - 2017-12-17 02:58:41.712455: step 1010, loss = 0.38, batch loss = 0.31 (34.0 examples/sec; 0.235 sec/batch; 21h:38m:42s remains)
INFO - root - 2017-12-17 02:58:43.919815: step 1020, loss = 0.33, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 20h:57m:40s remains)
INFO - root - 2017-12-17 02:58:46.089541: step 1030, loss = 0.26, batch loss = 0.20 (37.1 examples/sec; 0.216 sec/batch; 19h:52m:27s remains)
INFO - root - 2017-12-17 02:58:48.269218: step 1040, loss = 0.39, batch loss = 0.32 (35.6 examples/sec; 0.225 sec/batch; 20h:41m:38s remains)
INFO - root - 2017-12-17 02:58:50.491535: step 1050, loss = 0.29, batch loss = 0.22 (37.3 examples/sec; 0.214 sec/batch; 19h:44m:12s remains)
INFO - root - 2017-12-17 02:58:52.696640: step 1060, loss = 0.36, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 20h:41m:27s remains)
INFO - root - 2017-12-17 02:58:54.940193: step 1070, loss = 0.27, batch loss = 0.20 (35.6 examples/sec; 0.225 sec/batch; 20h:41m:58s remains)
INFO - root - 2017-12-17 02:58:57.166278: step 1080, loss = 0.33, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 20h:23m:49s remains)
INFO - root - 2017-12-17 02:58:59.356147: step 1090, loss = 0.29, batch loss = 0.22 (36.4 examples/sec; 0.220 sec/batch; 20h:14m:35s remains)
INFO - root - 2017-12-17 02:59:01.580279: step 1100, loss = 0.35, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 20h:19m:02s remains)
INFO - root - 2017-12-17 02:59:03.955136: step 1110, loss = 0.36, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 20h:22m:29s remains)
INFO - root - 2017-12-17 02:59:06.174419: step 1120, loss = 0.27, batch loss = 0.21 (36.2 examples/sec; 0.221 sec/batch; 20h:20m:31s remains)
INFO - root - 2017-12-17 02:59:08.414026: step 1130, loss = 0.42, batch loss = 0.36 (35.7 examples/sec; 0.224 sec/batch; 20h:37m:25s remains)
INFO - root - 2017-12-17 02:59:10.590764: step 1140, loss = 0.37, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 20h:38m:57s remains)
INFO - root - 2017-12-17 02:59:12.778057: step 1150, loss = 0.31, batch loss = 0.25 (36.6 examples/sec; 0.218 sec/batch; 20h:06m:25s remains)
INFO - root - 2017-12-17 02:59:15.014905: step 1160, loss = 0.31, batch loss = 0.24 (35.3 examples/sec; 0.227 sec/batch; 20h:51m:20s remains)
INFO - root - 2017-12-17 02:59:17.240088: step 1170, loss = 0.26, batch loss = 0.20 (35.0 examples/sec; 0.229 sec/batch; 21h:03m:04s remains)
INFO - root - 2017-12-17 02:59:19.444016: step 1180, loss = 0.28, batch loss = 0.22 (36.6 examples/sec; 0.219 sec/batch; 20h:06m:52s remains)
INFO - root - 2017-12-17 02:59:21.670566: step 1190, loss = 0.29, batch loss = 0.22 (35.9 examples/sec; 0.223 sec/batch; 20h:30m:42s remains)
INFO - root - 2017-12-17 02:59:23.892686: step 1200, loss = 0.32, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 20h:40m:17s remains)
INFO - root - 2017-12-17 02:59:26.292369: step 1210, loss = 0.27, batch loss = 0.21 (34.4 examples/sec; 0.233 sec/batch; 21h:24m:47s remains)
INFO - root - 2017-12-17 02:59:28.543011: step 1220, loss = 0.41, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 20h:26m:51s remains)
INFO - root - 2017-12-17 02:59:30.787950: step 1230, loss = 0.29, batch loss = 0.22 (36.3 examples/sec; 0.220 sec/batch; 20h:16m:26s remains)
INFO - root - 2017-12-17 02:59:32.956691: step 1240, loss = 0.30, batch loss = 0.23 (37.2 examples/sec; 0.215 sec/batch; 19h:48m:27s remains)
INFO - root - 2017-12-17 02:59:35.160046: step 1250, loss = 0.32, batch loss = 0.25 (36.6 examples/sec; 0.218 sec/batch; 20h:05m:37s remains)
INFO - root - 2017-12-17 02:59:37.348816: step 1260, loss = 0.27, batch loss = 0.20 (37.5 examples/sec; 0.214 sec/batch; 19h:38m:41s remains)
INFO - root - 2017-12-17 02:59:39.534218: step 1270, loss = 0.26, batch loss = 0.20 (36.7 examples/sec; 0.218 sec/batch; 20h:02m:44s remains)
INFO - root - 2017-12-17 02:59:41.743712: step 1280, loss = 0.31, batch loss = 0.24 (35.6 examples/sec; 0.225 sec/batch; 20h:41m:31s remains)
INFO - root - 2017-12-17 02:59:43.937065: step 1290, loss = 0.24, batch loss = 0.17 (36.6 examples/sec; 0.218 sec/batch; 20h:05m:05s remains)
INFO - root - 2017-12-17 02:59:46.144174: step 1300, loss = 0.27, batch loss = 0.20 (35.7 examples/sec; 0.224 sec/batch; 20h:37m:15s remains)
INFO - root - 2017-12-17 02:59:48.473597: step 1310, loss = 0.32, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 20h:10m:54s remains)
INFO - root - 2017-12-17 02:59:50.698603: step 1320, loss = 0.31, batch loss = 0.24 (36.8 examples/sec; 0.217 sec/batch; 20h:00m:30s remains)
INFO - root - 2017-12-17 02:59:52.909059: step 1330, loss = 0.34, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 21h:03m:15s remains)
INFO - root - 2017-12-17 02:59:55.131865: step 1340, loss = 0.29, batch loss = 0.22 (36.1 examples/sec; 0.221 sec/batch; 20h:21m:57s remains)
INFO - root - 2017-12-17 02:59:57.326793: step 1350, loss = 0.23, batch loss = 0.16 (35.9 examples/sec; 0.223 sec/batch; 20h:31m:26s remains)
INFO - root - 2017-12-17 02:59:59.537188: step 1360, loss = 0.33, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 20h:06m:20s remains)
INFO - root - 2017-12-17 03:00:01.745019: step 1370, loss = 0.34, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 20h:09m:36s remains)
INFO - root - 2017-12-17 03:00:03.920340: step 1380, loss = 0.31, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 20h:14m:42s remains)
INFO - root - 2017-12-17 03:00:06.115949: step 1390, loss = 0.29, batch loss = 0.22 (35.9 examples/sec; 0.223 sec/batch; 20h:28m:57s remains)
INFO - root - 2017-12-17 03:00:08.348584: step 1400, loss = 0.32, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 21h:10m:13s remains)
INFO - root - 2017-12-17 03:00:10.726329: step 1410, loss = 0.37, batch loss = 0.31 (36.1 examples/sec; 0.221 sec/batch; 20h:21m:27s remains)
INFO - root - 2017-12-17 03:00:12.927476: step 1420, loss = 0.29, batch loss = 0.22 (35.1 examples/sec; 0.228 sec/batch; 20h:58m:31s remains)
INFO - root - 2017-12-17 03:00:15.151050: step 1430, loss = 0.31, batch loss = 0.25 (34.5 examples/sec; 0.232 sec/batch; 21h:18m:01s remains)
INFO - root - 2017-12-17 03:00:17.394322: step 1440, loss = 0.26, batch loss = 0.20 (36.2 examples/sec; 0.221 sec/batch; 20h:19m:01s remains)
INFO - root - 2017-12-17 03:00:19.594092: step 1450, loss = 0.27, batch loss = 0.20 (36.8 examples/sec; 0.217 sec/batch; 19h:59m:55s remains)
INFO - root - 2017-12-17 03:00:21.788654: step 1460, loss = 0.28, batch loss = 0.21 (36.4 examples/sec; 0.220 sec/batch; 20h:11m:47s remains)
INFO - root - 2017-12-17 03:00:23.993194: step 1470, loss = 0.28, batch loss = 0.21 (36.6 examples/sec; 0.219 sec/batch; 20h:06m:52s remains)
INFO - root - 2017-12-17 03:00:26.179225: step 1480, loss = 0.32, batch loss = 0.26 (36.1 examples/sec; 0.221 sec/batch; 20h:21m:50s remains)
INFO - root - 2017-12-17 03:00:28.408360: step 1490, loss = 0.29, batch loss = 0.22 (36.1 examples/sec; 0.222 sec/batch; 20h:22m:29s remains)
INFO - root - 2017-12-17 03:00:30.605529: step 1500, loss = 0.28, batch loss = 0.22 (38.2 examples/sec; 0.209 sec/batch; 19h:15m:12s remains)
INFO - root - 2017-12-17 03:00:32.938111: step 1510, loss = 0.23, batch loss = 0.17 (36.9 examples/sec; 0.217 sec/batch; 19h:57m:04s remains)
INFO - root - 2017-12-17 03:00:35.159717: step 1520, loss = 0.27, batch loss = 0.20 (35.5 examples/sec; 0.225 sec/batch; 20h:43m:39s remains)
INFO - root - 2017-12-17 03:00:37.350762: step 1530, loss = 0.29, batch loss = 0.23 (36.9 examples/sec; 0.217 sec/batch; 19h:57m:05s remains)
INFO - root - 2017-12-17 03:00:39.555571: step 1540, loss = 0.34, batch loss = 0.27 (34.7 examples/sec; 0.230 sec/batch; 21h:11m:12s remains)
INFO - root - 2017-12-17 03:00:41.773382: step 1550, loss = 0.28, batch loss = 0.22 (36.9 examples/sec; 0.217 sec/batch; 19h:56m:27s remains)
INFO - root - 2017-12-17 03:00:43.969267: step 1560, loss = 0.21, batch loss = 0.15 (36.3 examples/sec; 0.220 sec/batch; 20h:15m:18s remains)
INFO - root - 2017-12-17 03:00:46.159394: step 1570, loss = 0.37, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 20h:01m:25s remains)
INFO - root - 2017-12-17 03:00:48.338788: step 1580, loss = 0.27, batch loss = 0.21 (35.9 examples/sec; 0.223 sec/batch; 20h:28m:14s remains)
INFO - root - 2017-12-17 03:00:50.575249: step 1590, loss = 0.24, batch loss = 0.18 (36.4 examples/sec; 0.220 sec/batch; 20h:12m:22s remains)
INFO - root - 2017-12-17 03:00:52.809939: step 1600, loss = 0.27, batch loss = 0.21 (33.6 examples/sec; 0.238 sec/batch; 21h:54m:40s remains)
INFO - root - 2017-12-17 03:00:55.167915: step 1610, loss = 0.25, batch loss = 0.19 (33.8 examples/sec; 0.237 sec/batch; 21h:46m:49s remains)
INFO - root - 2017-12-17 03:00:57.413094: step 1620, loss = 0.38, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 20h:07m:15s remains)
INFO - root - 2017-12-17 03:00:59.597126: step 1630, loss = 0.38, batch loss = 0.31 (36.3 examples/sec; 0.220 sec/batch; 20h:15m:41s remains)
INFO - root - 2017-12-17 03:01:01.804707: step 1640, loss = 0.25, batch loss = 0.18 (36.0 examples/sec; 0.222 sec/batch; 20h:26m:36s remains)
INFO - root - 2017-12-17 03:01:04.001060: step 1650, loss = 0.29, batch loss = 0.23 (36.4 examples/sec; 0.219 sec/batch; 20h:10m:18s remains)
INFO - root - 2017-12-17 03:01:06.191814: step 1660, loss = 0.22, batch loss = 0.16 (37.0 examples/sec; 0.216 sec/batch; 19h:51m:17s remains)
INFO - root - 2017-12-17 03:01:08.408800: step 1670, loss = 0.29, batch loss = 0.22 (35.6 examples/sec; 0.224 sec/batch; 20h:37m:40s remains)
INFO - root - 2017-12-17 03:01:10.595403: step 1680, loss = 0.31, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 20h:22m:17s remains)
INFO - root - 2017-12-17 03:01:12.779671: step 1690, loss = 0.27, batch loss = 0.21 (36.7 examples/sec; 0.218 sec/batch; 20h:02m:52s remains)
INFO - root - 2017-12-17 03:01:14.981840: step 1700, loss = 0.27, batch loss = 0.21 (36.6 examples/sec; 0.219 sec/batch; 20h:06m:18s remains)
INFO - root - 2017-12-17 03:01:17.323031: step 1710, loss = 0.28, batch loss = 0.22 (36.6 examples/sec; 0.219 sec/batch; 20h:05m:12s remains)
INFO - root - 2017-12-17 03:01:19.523257: step 1720, loss = 0.28, batch loss = 0.22 (35.7 examples/sec; 0.224 sec/batch; 20h:33m:41s remains)
INFO - root - 2017-12-17 03:01:21.768108: step 1730, loss = 0.21, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 20h:26m:29s remains)
INFO - root - 2017-12-17 03:01:24.031574: step 1740, loss = 0.22, batch loss = 0.16 (36.0 examples/sec; 0.223 sec/batch; 20h:26m:37s remains)
INFO - root - 2017-12-17 03:01:26.251404: step 1750, loss = 0.38, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 20h:49m:27s remains)
INFO - root - 2017-12-17 03:01:28.481237: step 1760, loss = 0.26, batch loss = 0.19 (36.2 examples/sec; 0.221 sec/batch; 20h:19m:08s remains)
INFO - root - 2017-12-17 03:01:30.751118: step 1770, loss = 0.33, batch loss = 0.27 (36.1 examples/sec; 0.222 sec/batch; 20h:21m:50s remains)
INFO - root - 2017-12-17 03:01:32.975058: step 1780, loss = 0.23, batch loss = 0.17 (36.8 examples/sec; 0.217 sec/batch; 19h:57m:43s remains)
INFO - root - 2017-12-17 03:01:35.216139: step 1790, loss = 0.30, batch loss = 0.23 (36.4 examples/sec; 0.220 sec/batch; 20h:11m:53s remains)
INFO - root - 2017-12-17 03:01:37.459255: step 1800, loss = 0.25, batch loss = 0.19 (35.4 examples/sec; 0.226 sec/batch; 20h:45m:56s remains)
INFO - root - 2017-12-17 03:01:39.861086: step 1810, loss = 0.26, batch loss = 0.19 (35.0 examples/sec; 0.228 sec/batch; 20h:59m:02s remains)
INFO - root - 2017-12-17 03:01:42.105056: step 1820, loss = 0.28, batch loss = 0.22 (35.7 examples/sec; 0.224 sec/batch; 20h:33m:33s remains)
INFO - root - 2017-12-17 03:01:44.343339: step 1830, loss = 0.31, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 20h:13m:37s remains)
INFO - root - 2017-12-17 03:01:46.545511: step 1840, loss = 0.27, batch loss = 0.21 (35.9 examples/sec; 0.223 sec/batch; 20h:27m:00s remains)
INFO - root - 2017-12-17 03:01:48.796268: step 1850, loss = 0.42, batch loss = 0.36 (36.3 examples/sec; 0.220 sec/batch; 20h:15m:08s remains)
INFO - root - 2017-12-17 03:01:51.009675: step 1860, loss = 0.28, batch loss = 0.22 (35.6 examples/sec; 0.225 sec/batch; 20h:40m:03s remains)
INFO - root - 2017-12-17 03:01:53.250649: step 1870, loss = 0.27, batch loss = 0.21 (36.1 examples/sec; 0.222 sec/batch; 20h:20m:36s remains)
INFO - root - 2017-12-17 03:01:55.486819: step 1880, loss = 0.27, batch loss = 0.20 (34.6 examples/sec; 0.231 sec/batch; 21h:14m:15s remains)
INFO - root - 2017-12-17 03:01:57.741562: step 1890, loss = 0.28, batch loss = 0.22 (36.3 examples/sec; 0.221 sec/batch; 20h:15m:05s remains)
INFO - root - 2017-12-17 03:01:59.948433: step 1900, loss = 0.27, batch loss = 0.20 (36.0 examples/sec; 0.222 sec/batch; 20h:24m:33s remains)
INFO - root - 2017-12-17 03:02:02.302086: step 1910, loss = 0.28, batch loss = 0.22 (36.1 examples/sec; 0.221 sec/batch; 20h:19m:30s remains)
INFO - root - 2017-12-17 03:02:04.537244: step 1920, loss = 0.24, batch loss = 0.18 (35.8 examples/sec; 0.224 sec/batch; 20h:31m:58s remains)
INFO - root - 2017-12-17 03:02:06.783471: step 1930, loss = 0.42, batch loss = 0.36 (36.9 examples/sec; 0.217 sec/batch; 19h:55m:38s remains)
INFO - root - 2017-12-17 03:02:09.017373: step 1940, loss = 0.27, batch loss = 0.21 (36.6 examples/sec; 0.219 sec/batch; 20h:04m:29s remains)
INFO - root - 2017-12-17 03:02:11.267633: step 1950, loss = 0.35, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 20h:35m:43s remains)
INFO - root - 2017-12-17 03:02:13.511566: step 1960, loss = 0.25, batch loss = 0.19 (36.0 examples/sec; 0.222 sec/batch; 20h:24m:51s remains)
INFO - root - 2017-12-17 03:02:15.743506: step 1970, loss = 0.36, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 20h:39m:37s remains)
INFO - root - 2017-12-17 03:02:17.974685: step 1980, loss = 0.25, batch loss = 0.19 (34.9 examples/sec; 0.230 sec/batch; 21h:04m:28s remains)
INFO - root - 2017-12-17 03:02:20.210563: step 1990, loss = 0.27, batch loss = 0.21 (36.2 examples/sec; 0.221 sec/batch; 20h:17m:31s remains)
INFO - root - 2017-12-17 03:02:22.439331: step 2000, loss = 0.26, batch loss = 0.20 (35.7 examples/sec; 0.224 sec/batch; 20h:33m:32s remains)
INFO - root - 2017-12-17 03:02:24.811566: step 2010, loss = 0.26, batch loss = 0.20 (36.8 examples/sec; 0.217 sec/batch; 19h:55m:54s remains)
INFO - root - 2017-12-17 03:02:27.036935: step 2020, loss = 0.25, batch loss = 0.18 (35.2 examples/sec; 0.227 sec/batch; 20h:50m:15s remains)
INFO - root - 2017-12-17 03:02:29.294132: step 2030, loss = 0.26, batch loss = 0.20 (35.3 examples/sec; 0.226 sec/batch; 20h:46m:42s remains)
INFO - root - 2017-12-17 03:02:31.513666: step 2040, loss = 0.27, batch loss = 0.21 (35.3 examples/sec; 0.227 sec/batch; 20h:49m:41s remains)
INFO - root - 2017-12-17 03:02:33.738995: step 2050, loss = 0.21, batch loss = 0.15 (36.6 examples/sec; 0.219 sec/batch; 20h:04m:49s remains)
INFO - root - 2017-12-17 03:02:35.952724: step 2060, loss = 0.26, batch loss = 0.20 (36.3 examples/sec; 0.220 sec/batch; 20h:12m:18s remains)
INFO - root - 2017-12-17 03:02:38.281164: step 2070, loss = 0.27, batch loss = 0.20 (34.1 examples/sec; 0.235 sec/batch; 21h:33m:30s remains)
INFO - root - 2017-12-17 03:02:40.527973: step 2080, loss = 0.24, batch loss = 0.18 (36.3 examples/sec; 0.221 sec/batch; 20h:14m:49s remains)
INFO - root - 2017-12-17 03:02:42.742964: step 2090, loss = 0.29, batch loss = 0.22 (36.7 examples/sec; 0.218 sec/batch; 20h:01m:45s remains)
INFO - root - 2017-12-17 03:02:45.003006: step 2100, loss = 0.25, batch loss = 0.19 (36.5 examples/sec; 0.219 sec/batch; 20h:06m:53s remains)
INFO - root - 2017-12-17 03:02:47.396128: step 2110, loss = 0.29, batch loss = 0.23 (36.5 examples/sec; 0.219 sec/batch; 20h:08m:30s remains)
INFO - root - 2017-12-17 03:02:49.641408: step 2120, loss = 0.26, batch loss = 0.20 (36.5 examples/sec; 0.219 sec/batch; 20h:06m:31s remains)
INFO - root - 2017-12-17 03:02:51.894530: step 2130, loss = 0.31, batch loss = 0.24 (36.1 examples/sec; 0.221 sec/batch; 20h:18m:57s remains)
INFO - root - 2017-12-17 03:02:54.156759: step 2140, loss = 0.43, batch loss = 0.36 (36.6 examples/sec; 0.219 sec/batch; 20h:03m:20s remains)
INFO - root - 2017-12-17 03:02:56.399843: step 2150, loss = 0.26, batch loss = 0.19 (35.3 examples/sec; 0.227 sec/batch; 20h:48m:20s remains)
INFO - root - 2017-12-17 03:02:58.623546: step 2160, loss = 0.26, batch loss = 0.20 (35.3 examples/sec; 0.227 sec/batch; 20h:49m:12s remains)
INFO - root - 2017-12-17 03:03:00.881067: step 2170, loss = 0.32, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 20h:16m:01s remains)
INFO - root - 2017-12-17 03:03:03.130940: step 2180, loss = 0.27, batch loss = 0.21 (36.2 examples/sec; 0.221 sec/batch; 20h:15m:15s remains)
INFO - root - 2017-12-17 03:03:05.386176: step 2190, loss = 0.26, batch loss = 0.19 (36.1 examples/sec; 0.222 sec/batch; 20h:21m:30s remains)
INFO - root - 2017-12-17 03:03:07.625796: step 2200, loss = 0.24, batch loss = 0.18 (36.5 examples/sec; 0.219 sec/batch; 20h:06m:27s remains)
INFO - root - 2017-12-17 03:03:09.996438: step 2210, loss = 0.32, batch loss = 0.25 (36.1 examples/sec; 0.222 sec/batch; 20h:20m:38s remains)
INFO - root - 2017-12-17 03:03:12.258487: step 2220, loss = 0.23, batch loss = 0.17 (36.8 examples/sec; 0.217 sec/batch; 19h:55m:12s remains)
INFO - root - 2017-12-17 03:03:14.489461: step 2230, loss = 0.25, batch loss = 0.19 (36.4 examples/sec; 0.220 sec/batch; 20h:08m:58s remains)
INFO - root - 2017-12-17 03:03:16.712742: step 2240, loss = 0.27, batch loss = 0.21 (35.3 examples/sec; 0.227 sec/batch; 20h:47m:23s remains)
INFO - root - 2017-12-17 03:03:18.948328: step 2250, loss = 0.31, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 19h:52m:02s remains)
INFO - root - 2017-12-17 03:03:21.191822: step 2260, loss = 0.23, batch loss = 0.17 (36.7 examples/sec; 0.218 sec/batch; 20h:00m:12s remains)
INFO - root - 2017-12-17 03:03:23.426798: step 2270, loss = 0.20, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 20h:22m:37s remains)
INFO - root - 2017-12-17 03:03:25.676159: step 2280, loss = 0.22, batch loss = 0.16 (35.8 examples/sec; 0.223 sec/batch; 20h:29m:30s remains)
INFO - root - 2017-12-17 03:03:27.935472: step 2290, loss = 0.41, batch loss = 0.35 (36.5 examples/sec; 0.219 sec/batch; 20h:07m:39s remains)
INFO - root - 2017-12-17 03:03:30.168367: step 2300, loss = 0.23, batch loss = 0.17 (36.2 examples/sec; 0.221 sec/batch; 20h:17m:04s remains)
INFO - root - 2017-12-17 03:03:32.539193: step 2310, loss = 0.26, batch loss = 0.20 (36.6 examples/sec; 0.218 sec/batch; 20h:01m:28s remains)
INFO - root - 2017-12-17 03:03:34.764525: step 2320, loss = 0.28, batch loss = 0.22 (36.5 examples/sec; 0.219 sec/batch; 20h:05m:44s remains)
INFO - root - 2017-12-17 03:03:37.006176: step 2330, loss = 0.23, batch loss = 0.17 (35.2 examples/sec; 0.227 sec/batch; 20h:50m:33s remains)
INFO - root - 2017-12-17 03:03:39.271983: step 2340, loss = 0.31, batch loss = 0.25 (36.4 examples/sec; 0.220 sec/batch; 20h:09m:16s remains)
INFO - root - 2017-12-17 03:03:41.509978: step 2350, loss = 0.23, batch loss = 0.17 (35.9 examples/sec; 0.223 sec/batch; 20h:27m:30s remains)
INFO - root - 2017-12-17 03:03:43.714813: step 2360, loss = 0.22, batch loss = 0.16 (36.0 examples/sec; 0.222 sec/batch; 20h:21m:26s remains)
INFO - root - 2017-12-17 03:03:45.914294: step 2370, loss = 0.21, batch loss = 0.15 (36.3 examples/sec; 0.220 sec/batch; 20h:11m:43s remains)
INFO - root - 2017-12-17 03:03:48.139538: step 2380, loss = 0.35, batch loss = 0.29 (36.2 examples/sec; 0.221 sec/batch; 20h:16m:29s remains)
INFO - root - 2017-12-17 03:03:50.335954: step 2390, loss = 0.26, batch loss = 0.20 (36.9 examples/sec; 0.217 sec/batch; 19h:52m:11s remains)
INFO - root - 2017-12-17 03:03:52.575534: step 2400, loss = 0.26, batch loss = 0.20 (34.9 examples/sec; 0.229 sec/batch; 21h:00m:08s remains)
INFO - root - 2017-12-17 03:03:54.934221: step 2410, loss = 0.30, batch loss = 0.24 (36.5 examples/sec; 0.219 sec/batch; 20h:04m:49s remains)
INFO - root - 2017-12-17 03:03:57.137880: step 2420, loss = 0.25, batch loss = 0.19 (37.0 examples/sec; 0.216 sec/batch; 19h:50m:22s remains)
INFO - root - 2017-12-17 03:03:59.360143: step 2430, loss = 0.28, batch loss = 0.22 (35.7 examples/sec; 0.224 sec/batch; 20h:33m:43s remains)
INFO - root - 2017-12-17 03:04:01.575641: step 2440, loss = 0.21, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 20h:26m:30s remains)
INFO - root - 2017-12-17 03:04:03.780864: step 2450, loss = 0.23, batch loss = 0.16 (36.4 examples/sec; 0.220 sec/batch; 20h:08m:14s remains)
INFO - root - 2017-12-17 03:04:06.043615: step 2460, loss = 0.23, batch loss = 0.17 (37.4 examples/sec; 0.214 sec/batch; 19h:35m:12s remains)
INFO - root - 2017-12-17 03:04:08.276350: step 2470, loss = 0.26, batch loss = 0.20 (36.2 examples/sec; 0.221 sec/batch; 20h:14m:20s remains)
INFO - root - 2017-12-17 03:04:10.485638: step 2480, loss = 0.27, batch loss = 0.21 (36.5 examples/sec; 0.219 sec/batch; 20h:04m:47s remains)
INFO - root - 2017-12-17 03:04:12.698132: step 2490, loss = 0.24, batch loss = 0.18 (35.6 examples/sec; 0.224 sec/batch; 20h:34m:32s remains)
INFO - root - 2017-12-17 03:04:14.963324: step 2500, loss = 0.31, batch loss = 0.25 (36.9 examples/sec; 0.217 sec/batch; 19h:51m:43s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-2500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-2500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 03:04:17.816239: step 2510, loss = 0.38, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 20h:50m:33s remains)
INFO - root - 2017-12-17 03:04:20.017265: step 2520, loss = 0.25, batch loss = 0.18 (37.0 examples/sec; 0.216 sec/batch; 19h:49m:37s remains)
INFO - root - 2017-12-17 03:04:22.250608: step 2530, loss = 0.25, batch loss = 0.19 (35.7 examples/sec; 0.224 sec/batch; 20h:31m:18s remains)
INFO - root - 2017-12-17 03:04:24.498000: step 2540, loss = 0.23, batch loss = 0.17 (35.9 examples/sec; 0.223 sec/batch; 20h:25m:18s remains)
INFO - root - 2017-12-17 03:04:26.696295: step 2550, loss = 0.29, batch loss = 0.23 (35.3 examples/sec; 0.227 sec/batch; 20h:47m:24s remains)
INFO - root - 2017-12-17 03:04:28.929367: step 2560, loss = 0.40, batch loss = 0.34 (35.0 examples/sec; 0.228 sec/batch; 20h:56m:17s remains)
INFO - root - 2017-12-17 03:04:31.164863: step 2570, loss = 0.24, batch loss = 0.18 (36.3 examples/sec; 0.221 sec/batch; 20h:12m:31s remains)
INFO - root - 2017-12-17 03:04:33.436509: step 2580, loss = 0.24, batch loss = 0.18 (35.2 examples/sec; 0.227 sec/batch; 20h:48m:04s remains)
INFO - root - 2017-12-17 03:04:35.648454: step 2590, loss = 0.28, batch loss = 0.22 (36.2 examples/sec; 0.221 sec/batch; 20h:14m:03s remains)
INFO - root - 2017-12-17 03:04:37.870750: step 2600, loss = 0.29, batch loss = 0.23 (37.8 examples/sec; 0.212 sec/batch; 19h:23m:34s remains)
INFO - root - 2017-12-17 03:04:40.284015: step 2610, loss = 0.25, batch loss = 0.19 (35.1 examples/sec; 0.228 sec/batch; 20h:53m:22s remains)
INFO - root - 2017-12-17 03:04:42.516718: step 2620, loss = 0.25, batch loss = 0.19 (36.4 examples/sec; 0.220 sec/batch; 20h:07m:13s remains)
INFO - root - 2017-12-17 03:04:44.746476: step 2630, loss = 0.27, batch loss = 0.21 (36.0 examples/sec; 0.222 sec/batch; 20h:20m:12s remains)
INFO - root - 2017-12-17 03:04:46.960765: step 2640, loss = 0.22, batch loss = 0.16 (35.4 examples/sec; 0.226 sec/batch; 20h:43m:09s remains)
INFO - root - 2017-12-17 03:04:49.190968: step 2650, loss = 0.26, batch loss = 0.20 (35.9 examples/sec; 0.223 sec/batch; 20h:25m:24s remains)
INFO - root - 2017-12-17 03:04:51.390615: step 2660, loss = 0.20, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 20h:06m:03s remains)
INFO - root - 2017-12-17 03:04:53.587722: step 2670, loss = 0.21, batch loss = 0.15 (34.8 examples/sec; 0.230 sec/batch; 21h:04m:17s remains)
INFO - root - 2017-12-17 03:04:55.805309: step 2680, loss = 0.26, batch loss = 0.20 (36.6 examples/sec; 0.218 sec/batch; 19h:59m:57s remains)
INFO - root - 2017-12-17 03:04:58.024286: step 2690, loss = 0.24, batch loss = 0.18 (35.1 examples/sec; 0.228 sec/batch; 20h:53m:48s remains)
INFO - root - 2017-12-17 03:05:00.249844: step 2700, loss = 0.21, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 20h:24m:00s remains)
INFO - root - 2017-12-17 03:05:02.619111: step 2710, loss = 0.28, batch loss = 0.22 (35.9 examples/sec; 0.223 sec/batch; 20h:24m:14s remains)
INFO - root - 2017-12-17 03:05:04.857359: step 2720, loss = 0.46, batch loss = 0.40 (36.6 examples/sec; 0.219 sec/batch; 20h:01m:46s remains)
INFO - root - 2017-12-17 03:05:07.081781: step 2730, loss = 0.22, batch loss = 0.16 (36.1 examples/sec; 0.222 sec/batch; 20h:19m:27s remains)
INFO - root - 2017-12-17 03:05:09.298061: step 2740, loss = 0.26, batch loss = 0.20 (36.7 examples/sec; 0.218 sec/batch; 19h:59m:16s remains)
INFO - root - 2017-12-17 03:05:11.516692: step 2750, loss = 0.28, batch loss = 0.22 (36.3 examples/sec; 0.220 sec/batch; 20h:09m:47s remains)
INFO - root - 2017-12-17 03:05:13.714342: step 2760, loss = 0.34, batch loss = 0.28 (36.3 examples/sec; 0.220 sec/batch; 20h:10m:26s remains)
INFO - root - 2017-12-17 03:05:15.951027: step 2770, loss = 0.23, batch loss = 0.17 (36.5 examples/sec; 0.219 sec/batch; 20h:04m:03s remains)
INFO - root - 2017-12-17 03:05:18.198679: step 2780, loss = 0.25, batch loss = 0.19 (37.5 examples/sec; 0.213 sec/batch; 19h:32m:28s remains)
INFO - root - 2017-12-17 03:05:20.435634: step 2790, loss = 0.24, batch loss = 0.18 (36.4 examples/sec; 0.220 sec/batch; 20h:08m:16s remains)
INFO - root - 2017-12-17 03:05:22.663223: step 2800, loss = 0.26, batch loss = 0.20 (34.6 examples/sec; 0.231 sec/batch; 21h:08m:44s remains)
INFO - root - 2017-12-17 03:05:25.041366: step 2810, loss = 0.31, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 20h:22m:00s remains)
INFO - root - 2017-12-17 03:05:27.290499: step 2820, loss = 0.24, batch loss = 0.18 (34.4 examples/sec; 0.233 sec/batch; 21h:18m:17s remains)
INFO - root - 2017-12-17 03:05:29.510554: step 2830, loss = 0.29, batch loss = 0.23 (36.2 examples/sec; 0.221 sec/batch; 20h:15m:24s remains)
INFO - root - 2017-12-17 03:05:31.762321: step 2840, loss = 0.21, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 20h:53m:45s remains)
INFO - root - 2017-12-17 03:05:33.976914: step 2850, loss = 0.27, batch loss = 0.21 (35.2 examples/sec; 0.227 sec/batch; 20h:48m:08s remains)
INFO - root - 2017-12-17 03:05:36.209372: step 2860, loss = 0.29, batch loss = 0.23 (35.9 examples/sec; 0.223 sec/batch; 20h:24m:23s remains)
INFO - root - 2017-12-17 03:05:38.430964: step 2870, loss = 0.23, batch loss = 0.17 (36.3 examples/sec; 0.220 sec/batch; 20h:09m:58s remains)
INFO - root - 2017-12-17 03:05:40.665676: step 2880, loss = 0.23, batch loss = 0.17 (35.8 examples/sec; 0.224 sec/batch; 20h:28m:10s remains)
INFO - root - 2017-12-17 03:05:42.902477: step 2890, loss = 0.24, batch loss = 0.18 (33.9 examples/sec; 0.236 sec/batch; 21h:35m:03s remains)
INFO - root - 2017-12-17 03:05:45.148384: step 2900, loss = 0.28, batch loss = 0.22 (35.2 examples/sec; 0.227 sec/batch; 20h:48m:01s remains)
INFO - root - 2017-12-17 03:05:47.473685: step 2910, loss = 0.20, batch loss = 0.14 (35.8 examples/sec; 0.224 sec/batch; 20h:29m:07s remains)
INFO - root - 2017-12-17 03:05:49.706144: step 2920, loss = 0.25, batch loss = 0.19 (35.3 examples/sec; 0.227 sec/batch; 20h:46m:18s remains)
INFO - root - 2017-12-17 03:05:51.926609: step 2930, loss = 0.25, batch loss = 0.19 (35.7 examples/sec; 0.224 sec/batch; 20h:29m:17s remains)
INFO - root - 2017-12-17 03:05:54.164573: step 2940, loss = 0.24, batch loss = 0.18 (34.6 examples/sec; 0.231 sec/batch; 21h:11m:17s remains)
INFO - root - 2017-12-17 03:05:56.408288: step 2950, loss = 0.21, batch loss = 0.15 (36.8 examples/sec; 0.217 sec/batch; 19h:54m:12s remains)
INFO - root - 2017-12-17 03:05:58.654113: step 2960, loss = 0.23, batch loss = 0.17 (35.6 examples/sec; 0.225 sec/batch; 20h:33m:12s remains)
INFO - root - 2017-12-17 03:06:00.890657: step 2970, loss = 0.30, batch loss = 0.24 (34.7 examples/sec; 0.230 sec/batch; 21h:05m:24s remains)
INFO - root - 2017-12-17 03:06:03.125616: step 2980, loss = 0.22, batch loss = 0.16 (36.1 examples/sec; 0.222 sec/batch; 20h:17m:35s remains)
INFO - root - 2017-12-17 03:06:05.381614: step 2990, loss = 0.21, batch loss = 0.15 (36.5 examples/sec; 0.219 sec/batch; 20h:03m:28s remains)
INFO - root - 2017-12-17 03:06:07.613810: step 3000, loss = 0.20, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 20h:59m:53s remains)
INFO - root - 2017-12-17 03:06:09.980410: step 3010, loss = 0.33, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 20h:41m:25s remains)
INFO - root - 2017-12-17 03:06:12.214656: step 3020, loss = 0.37, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 20h:51m:37s remains)
INFO - root - 2017-12-17 03:06:14.433823: step 3030, loss = 0.28, batch loss = 0.23 (36.5 examples/sec; 0.219 sec/batch; 20h:03m:01s remains)
INFO - root - 2017-12-17 03:06:16.692997: step 3040, loss = 0.25, batch loss = 0.19 (34.1 examples/sec; 0.235 sec/batch; 21h:27m:52s remains)
INFO - root - 2017-12-17 03:06:18.936554: step 3050, loss = 0.21, batch loss = 0.15 (35.6 examples/sec; 0.225 sec/batch; 20h:34m:26s remains)
INFO - root - 2017-12-17 03:06:21.148628: step 3060, loss = 0.23, batch loss = 0.17 (36.8 examples/sec; 0.217 sec/batch; 19h:53m:55s remains)
INFO - root - 2017-12-17 03:06:23.390169: step 3070, loss = 0.25, batch loss = 0.19 (36.5 examples/sec; 0.219 sec/batch; 20h:03m:59s remains)
INFO - root - 2017-12-17 03:06:25.606864: step 3080, loss = 0.19, batch loss = 0.13 (35.3 examples/sec; 0.226 sec/batch; 20h:43m:31s remains)
INFO - root - 2017-12-17 03:06:27.869976: step 3090, loss = 0.20, batch loss = 0.14 (35.5 examples/sec; 0.225 sec/batch; 20h:37m:16s remains)
INFO - root - 2017-12-17 03:06:30.119976: step 3100, loss = 0.23, batch loss = 0.17 (36.4 examples/sec; 0.220 sec/batch; 20h:06m:24s remains)
INFO - root - 2017-12-17 03:06:32.537779: step 3110, loss = 0.27, batch loss = 0.21 (36.2 examples/sec; 0.221 sec/batch; 20h:12m:19s remains)
INFO - root - 2017-12-17 03:06:34.744004: step 3120, loss = 0.24, batch loss = 0.19 (36.3 examples/sec; 0.220 sec/batch; 20h:08m:30s remains)
INFO - root - 2017-12-17 03:06:36.973592: step 3130, loss = 0.24, batch loss = 0.18 (35.9 examples/sec; 0.223 sec/batch; 20h:23m:12s remains)
INFO - root - 2017-12-17 03:06:39.215352: step 3140, loss = 0.23, batch loss = 0.17 (34.9 examples/sec; 0.229 sec/batch; 20h:59m:15s remains)
INFO - root - 2017-12-17 03:06:41.475345: step 3150, loss = 0.22, batch loss = 0.16 (34.7 examples/sec; 0.230 sec/batch; 21h:04m:13s remains)
INFO - root - 2017-12-17 03:06:43.731884: step 3160, loss = 0.36, batch loss = 0.30 (36.2 examples/sec; 0.221 sec/batch; 20h:11m:56s remains)
INFO - root - 2017-12-17 03:06:45.988480: step 3170, loss = 0.29, batch loss = 0.24 (36.0 examples/sec; 0.222 sec/batch; 20h:20m:34s remains)
INFO - root - 2017-12-17 03:06:48.239675: step 3180, loss = 0.21, batch loss = 0.15 (35.3 examples/sec; 0.227 sec/batch; 20h:44m:48s remains)
INFO - root - 2017-12-17 03:06:50.476339: step 3190, loss = 0.22, batch loss = 0.16 (36.7 examples/sec; 0.218 sec/batch; 19h:56m:16s remains)
INFO - root - 2017-12-17 03:06:52.669198: step 3200, loss = 0.32, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 20h:18m:17s remains)
INFO - root - 2017-12-17 03:06:55.041511: step 3210, loss = 0.28, batch loss = 0.22 (36.7 examples/sec; 0.218 sec/batch; 19h:57m:49s remains)
INFO - root - 2017-12-17 03:06:57.258226: step 3220, loss = 0.20, batch loss = 0.14 (35.3 examples/sec; 0.227 sec/batch; 20h:43m:21s remains)
INFO - root - 2017-12-17 03:06:59.512978: step 3230, loss = 0.27, batch loss = 0.21 (35.4 examples/sec; 0.226 sec/batch; 20h:41m:43s remains)
INFO - root - 2017-12-17 03:07:01.739939: step 3240, loss = 0.36, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 20h:19m:47s remains)
INFO - root - 2017-12-17 03:07:03.968839: step 3250, loss = 0.36, batch loss = 0.30 (35.3 examples/sec; 0.226 sec/batch; 20h:42m:34s remains)
INFO - root - 2017-12-17 03:07:06.214362: step 3260, loss = 0.29, batch loss = 0.23 (35.1 examples/sec; 0.228 sec/batch; 20h:50m:46s remains)
INFO - root - 2017-12-17 03:07:08.519436: step 3270, loss = 0.18, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 20h:34m:36s remains)
INFO - root - 2017-12-17 03:07:10.747070: step 3280, loss = 0.23, batch loss = 0.17 (37.3 examples/sec; 0.215 sec/batch; 19h:38m:05s remains)
INFO - root - 2017-12-17 03:07:12.976632: step 3290, loss = 0.21, batch loss = 0.15 (35.7 examples/sec; 0.224 sec/batch; 20h:28m:45s remains)
INFO - root - 2017-12-17 03:07:15.177166: step 3300, loss = 0.27, batch loss = 0.21 (36.0 examples/sec; 0.222 sec/batch; 20h:19m:41s remains)
INFO - root - 2017-12-17 03:07:17.552679: step 3310, loss = 0.23, batch loss = 0.17 (36.2 examples/sec; 0.221 sec/batch; 20h:12m:17s remains)
INFO - root - 2017-12-17 03:07:19.786298: step 3320, loss = 0.30, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 20h:13m:00s remains)
INFO - root - 2017-12-17 03:07:21.981227: step 3330, loss = 0.37, batch loss = 0.31 (36.8 examples/sec; 0.218 sec/batch; 19h:53m:38s remains)
INFO - root - 2017-12-17 03:07:24.203288: step 3340, loss = 0.19, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 20h:04m:34s remains)
INFO - root - 2017-12-17 03:07:26.444203: step 3350, loss = 0.21, batch loss = 0.15 (37.0 examples/sec; 0.217 sec/batch; 19h:47m:41s remains)
INFO - root - 2017-12-17 03:07:28.683453: step 3360, loss = 0.24, batch loss = 0.18 (35.3 examples/sec; 0.227 sec/batch; 20h:44m:52s remains)
INFO - root - 2017-12-17 03:07:30.915894: step 3370, loss = 0.24, batch loss = 0.18 (37.1 examples/sec; 0.216 sec/batch; 19h:43m:48s remains)
INFO - root - 2017-12-17 03:07:33.164384: step 3380, loss = 0.23, batch loss = 0.17 (35.4 examples/sec; 0.226 sec/batch; 20h:39m:18s remains)
INFO - root - 2017-12-17 03:07:35.431325: step 3390, loss = 0.20, batch loss = 0.14 (34.1 examples/sec; 0.235 sec/batch; 21h:26m:19s remains)
INFO - root - 2017-12-17 03:07:37.665389: step 3400, loss = 0.28, batch loss = 0.22 (35.4 examples/sec; 0.226 sec/batch; 20h:38m:26s remains)
INFO - root - 2017-12-17 03:07:40.015463: step 3410, loss = 0.22, batch loss = 0.16 (36.1 examples/sec; 0.222 sec/batch; 20h:15m:09s remains)
INFO - root - 2017-12-17 03:07:42.225510: step 3420, loss = 0.25, batch loss = 0.19 (36.1 examples/sec; 0.222 sec/batch; 20h:16m:06s remains)
INFO - root - 2017-12-17 03:07:44.463665: step 3430, loss = 0.20, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 20h:08m:10s remains)
INFO - root - 2017-12-17 03:07:46.694562: step 3440, loss = 0.20, batch loss = 0.14 (34.7 examples/sec; 0.230 sec/batch; 21h:03m:55s remains)
INFO - root - 2017-12-17 03:07:48.966138: step 3450, loss = 0.20, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 20h:17m:41s remains)
INFO - root - 2017-12-17 03:07:51.221937: step 3460, loss = 0.17, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 20h:20m:38s remains)
INFO - root - 2017-12-17 03:07:53.412437: step 3470, loss = 0.18, batch loss = 0.12 (37.0 examples/sec; 0.216 sec/batch; 19h:45m:47s remains)
INFO - root - 2017-12-17 03:07:55.691280: step 3480, loss = 0.22, batch loss = 0.16 (35.6 examples/sec; 0.224 sec/batch; 20h:30m:44s remains)
INFO - root - 2017-12-17 03:07:57.929652: step 3490, loss = 0.30, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 20h:32m:21s remains)
INFO - root - 2017-12-17 03:08:00.146089: step 3500, loss = 0.16, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 20h:32m:27s remains)
INFO - root - 2017-12-17 03:08:02.493760: step 3510, loss = 0.24, batch loss = 0.19 (36.7 examples/sec; 0.218 sec/batch; 19h:55m:07s remains)
INFO - root - 2017-12-17 03:08:04.724662: step 3520, loss = 0.26, batch loss = 0.21 (35.6 examples/sec; 0.225 sec/batch; 20h:31m:47s remains)
INFO - root - 2017-12-17 03:08:06.948098: step 3530, loss = 0.20, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 20h:22m:35s remains)
INFO - root - 2017-12-17 03:08:09.184710: step 3540, loss = 0.19, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 20h:51m:06s remains)
INFO - root - 2017-12-17 03:08:11.410693: step 3550, loss = 0.18, batch loss = 0.12 (36.6 examples/sec; 0.218 sec/batch; 19h:56m:46s remains)
INFO - root - 2017-12-17 03:08:13.628217: step 3560, loss = 0.19, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 20h:19m:19s remains)
INFO - root - 2017-12-17 03:08:15.831191: step 3570, loss = 0.22, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 20h:10m:49s remains)
INFO - root - 2017-12-17 03:08:18.031415: step 3580, loss = 0.19, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 20h:44m:15s remains)
INFO - root - 2017-12-17 03:08:20.211718: step 3590, loss = 0.21, batch loss = 0.16 (35.9 examples/sec; 0.223 sec/batch; 20h:21m:37s remains)
INFO - root - 2017-12-17 03:08:22.451368: step 3600, loss = 0.23, batch loss = 0.18 (36.2 examples/sec; 0.221 sec/batch; 20h:11m:31s remains)
INFO - root - 2017-12-17 03:08:24.793473: step 3610, loss = 0.19, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 20h:12m:21s remains)
INFO - root - 2017-12-17 03:08:27.016708: step 3620, loss = 0.20, batch loss = 0.14 (33.2 examples/sec; 0.241 sec/batch; 21h:59m:42s remains)
INFO - root - 2017-12-17 03:08:29.283261: step 3630, loss = 0.21, batch loss = 0.15 (34.1 examples/sec; 0.235 sec/batch; 21h:27m:12s remains)
INFO - root - 2017-12-17 03:08:31.511432: step 3640, loss = 0.28, batch loss = 0.22 (36.0 examples/sec; 0.222 sec/batch; 20h:18m:11s remains)
INFO - root - 2017-12-17 03:08:33.747721: step 3650, loss = 0.23, batch loss = 0.17 (35.6 examples/sec; 0.225 sec/batch; 20h:32m:51s remains)
INFO - root - 2017-12-17 03:08:35.968494: step 3660, loss = 0.21, batch loss = 0.16 (36.5 examples/sec; 0.219 sec/batch; 20h:00m:24s remains)
INFO - root - 2017-12-17 03:08:38.180521: step 3670, loss = 0.21, batch loss = 0.15 (37.1 examples/sec; 0.215 sec/batch; 19h:40m:58s remains)
INFO - root - 2017-12-17 03:08:40.361863: step 3680, loss = 0.21, batch loss = 0.15 (36.4 examples/sec; 0.220 sec/batch; 20h:03m:35s remains)
INFO - root - 2017-12-17 03:08:42.591627: step 3690, loss = 0.27, batch loss = 0.21 (35.2 examples/sec; 0.228 sec/batch; 20h:47m:02s remains)
INFO - root - 2017-12-17 03:08:44.818650: step 3700, loss = 0.24, batch loss = 0.18 (36.8 examples/sec; 0.218 sec/batch; 19h:52m:22s remains)
INFO - root - 2017-12-17 03:08:47.153607: step 3710, loss = 0.18, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 20h:20m:21s remains)
INFO - root - 2017-12-17 03:08:49.401912: step 3720, loss = 0.21, batch loss = 0.16 (35.8 examples/sec; 0.224 sec/batch; 20h:24m:42s remains)
INFO - root - 2017-12-17 03:08:51.651766: step 3730, loss = 0.25, batch loss = 0.20 (34.0 examples/sec; 0.235 sec/batch; 21h:27m:27s remains)
INFO - root - 2017-12-17 03:08:53.910248: step 3740, loss = 0.26, batch loss = 0.21 (37.1 examples/sec; 0.216 sec/batch; 19h:41m:41s remains)
INFO - root - 2017-12-17 03:08:56.095000: step 3750, loss = 0.20, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 20h:11m:26s remains)
INFO - root - 2017-12-17 03:08:58.331652: step 3760, loss = 0.25, batch loss = 0.19 (36.0 examples/sec; 0.222 sec/batch; 20h:16m:18s remains)
INFO - root - 2017-12-17 03:09:00.557294: step 3770, loss = 0.28, batch loss = 0.23 (35.4 examples/sec; 0.226 sec/batch; 20h:38m:45s remains)
INFO - root - 2017-12-17 03:09:02.819849: step 3780, loss = 0.23, batch loss = 0.18 (36.8 examples/sec; 0.218 sec/batch; 19h:51m:38s remains)
INFO - root - 2017-12-17 03:09:05.088191: step 3790, loss = 0.20, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 21h:00m:56s remains)
INFO - root - 2017-12-17 03:09:07.330935: step 3800, loss = 0.16, batch loss = 0.11 (31.9 examples/sec; 0.250 sec/batch; 22h:51m:53s remains)
INFO - root - 2017-12-17 03:09:09.711496: step 3810, loss = 0.26, batch loss = 0.21 (35.6 examples/sec; 0.225 sec/batch; 20h:31m:15s remains)
INFO - root - 2017-12-17 03:09:11.908545: step 3820, loss = 0.22, batch loss = 0.16 (36.1 examples/sec; 0.221 sec/batch; 20h:12m:33s remains)
INFO - root - 2017-12-17 03:09:14.125298: step 3830, loss = 0.33, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 20h:36m:34s remains)
INFO - root - 2017-12-17 03:09:16.344975: step 3840, loss = 0.27, batch loss = 0.22 (36.6 examples/sec; 0.218 sec/batch; 19h:55m:58s remains)
INFO - root - 2017-12-17 03:09:18.589983: step 3850, loss = 0.17, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 21h:05m:16s remains)
INFO - root - 2017-12-17 03:09:20.785078: step 3860, loss = 0.19, batch loss = 0.13 (35.8 examples/sec; 0.224 sec/batch; 20h:24m:56s remains)
INFO - root - 2017-12-17 03:09:23.031925: step 3870, loss = 0.18, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 20h:48m:38s remains)
INFO - root - 2017-12-17 03:09:25.256934: step 3880, loss = 0.22, batch loss = 0.16 (36.3 examples/sec; 0.220 sec/batch; 20h:07m:36s remains)
INFO - root - 2017-12-17 03:09:27.488925: step 3890, loss = 0.26, batch loss = 0.20 (36.7 examples/sec; 0.218 sec/batch; 19h:54m:39s remains)
INFO - root - 2017-12-17 03:09:29.696747: step 3900, loss = 0.21, batch loss = 0.15 (36.5 examples/sec; 0.219 sec/batch; 19h:59m:20s remains)
INFO - root - 2017-12-17 03:09:32.050383: step 3910, loss = 0.19, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 20h:28m:37s remains)
INFO - root - 2017-12-17 03:09:34.240576: step 3920, loss = 0.20, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 20h:19m:19s remains)
INFO - root - 2017-12-17 03:09:36.436467: step 3930, loss = 0.34, batch loss = 0.28 (35.5 examples/sec; 0.226 sec/batch; 20h:34m:54s remains)
INFO - root - 2017-12-17 03:09:38.689555: step 3940, loss = 0.19, batch loss = 0.14 (34.4 examples/sec; 0.233 sec/batch; 21h:14m:54s remains)
INFO - root - 2017-12-17 03:09:40.874257: step 3950, loss = 0.31, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 20h:17m:35s remains)
INFO - root - 2017-12-17 03:09:43.088068: step 3960, loss = 0.18, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 20h:06m:20s remains)
INFO - root - 2017-12-17 03:09:45.325872: step 3970, loss = 0.24, batch loss = 0.18 (35.3 examples/sec; 0.226 sec/batch; 20h:39m:20s remains)
INFO - root - 2017-12-17 03:09:47.547737: step 3980, loss = 0.24, batch loss = 0.18 (36.0 examples/sec; 0.223 sec/batch; 20h:18m:20s remains)
INFO - root - 2017-12-17 03:09:49.783149: step 3990, loss = 0.23, batch loss = 0.17 (35.6 examples/sec; 0.225 sec/batch; 20h:29m:35s remains)
INFO - root - 2017-12-17 03:09:51.988752: step 4000, loss = 0.24, batch loss = 0.19 (36.3 examples/sec; 0.221 sec/batch; 20h:07m:49s remains)
INFO - root - 2017-12-17 03:09:54.360165: step 4010, loss = 0.25, batch loss = 0.19 (35.8 examples/sec; 0.223 sec/batch; 20h:22m:47s remains)
INFO - root - 2017-12-17 03:09:56.558593: step 4020, loss = 0.27, batch loss = 0.21 (34.7 examples/sec; 0.230 sec/batch; 21h:00m:49s remains)
INFO - root - 2017-12-17 03:09:58.777652: step 4030, loss = 0.23, batch loss = 0.17 (36.7 examples/sec; 0.218 sec/batch; 19h:53m:51s remains)
INFO - root - 2017-12-17 03:10:01.017451: step 4040, loss = 0.31, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 20h:06m:18s remains)
INFO - root - 2017-12-17 03:10:03.240272: step 4050, loss = 0.21, batch loss = 0.16 (36.4 examples/sec; 0.220 sec/batch; 20h:04m:10s remains)
INFO - root - 2017-12-17 03:10:05.541653: step 4060, loss = 0.27, batch loss = 0.21 (35.3 examples/sec; 0.227 sec/batch; 20h:42m:18s remains)
INFO - root - 2017-12-17 03:10:07.806759: step 4070, loss = 0.20, batch loss = 0.15 (30.2 examples/sec; 0.265 sec/batch; 24h:08m:09s remains)
INFO - root - 2017-12-17 03:10:10.013172: step 4080, loss = 0.18, batch loss = 0.12 (36.1 examples/sec; 0.221 sec/batch; 20h:11m:36s remains)
INFO - root - 2017-12-17 03:10:12.267804: step 4090, loss = 0.27, batch loss = 0.22 (35.6 examples/sec; 0.225 sec/batch; 20h:29m:13s remains)
INFO - root - 2017-12-17 03:10:14.529762: step 4100, loss = 0.26, batch loss = 0.20 (35.6 examples/sec; 0.225 sec/batch; 20h:29m:06s remains)
INFO - root - 2017-12-17 03:10:16.894662: step 4110, loss = 0.22, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 20h:09m:13s remains)
INFO - root - 2017-12-17 03:10:19.110357: step 4120, loss = 0.31, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 19h:59m:37s remains)
INFO - root - 2017-12-17 03:10:21.301464: step 4130, loss = 0.16, batch loss = 0.11 (37.3 examples/sec; 0.215 sec/batch; 19h:35m:01s remains)
INFO - root - 2017-12-17 03:10:23.520514: step 4140, loss = 0.38, batch loss = 0.33 (35.2 examples/sec; 0.227 sec/batch; 20h:44m:01s remains)
INFO - root - 2017-12-17 03:10:25.736223: step 4150, loss = 0.32, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 20h:24m:19s remains)
INFO - root - 2017-12-17 03:10:27.980787: step 4160, loss = 0.22, batch loss = 0.17 (36.2 examples/sec; 0.221 sec/batch; 20h:08m:46s remains)
INFO - root - 2017-12-17 03:10:30.188038: step 4170, loss = 0.20, batch loss = 0.14 (36.7 examples/sec; 0.218 sec/batch; 19h:52m:08s remains)
INFO - root - 2017-12-17 03:10:32.416197: step 4180, loss = 0.26, batch loss = 0.20 (35.4 examples/sec; 0.226 sec/batch; 20h:37m:33s remains)
INFO - root - 2017-12-17 03:10:34.633846: step 4190, loss = 0.20, batch loss = 0.15 (37.5 examples/sec; 0.213 sec/batch; 19h:26m:25s remains)
INFO - root - 2017-12-17 03:10:36.823770: step 4200, loss = 0.26, batch loss = 0.21 (36.2 examples/sec; 0.221 sec/batch; 20h:09m:12s remains)
INFO - root - 2017-12-17 03:10:39.163685: step 4210, loss = 0.21, batch loss = 0.16 (35.1 examples/sec; 0.228 sec/batch; 20h:47m:14s remains)
INFO - root - 2017-12-17 03:10:41.403429: step 4220, loss = 0.24, batch loss = 0.19 (36.5 examples/sec; 0.219 sec/batch; 19h:58m:48s remains)
INFO - root - 2017-12-17 03:10:43.623164: step 4230, loss = 0.24, batch loss = 0.18 (34.0 examples/sec; 0.235 sec/batch; 21h:26m:58s remains)
INFO - root - 2017-12-17 03:10:45.866510: step 4240, loss = 0.19, batch loss = 0.14 (36.4 examples/sec; 0.220 sec/batch; 20h:00m:58s remains)
INFO - root - 2017-12-17 03:10:48.061331: step 4250, loss = 0.22, batch loss = 0.16 (37.9 examples/sec; 0.211 sec/batch; 19h:14m:15s remains)
INFO - root - 2017-12-17 03:10:50.283382: step 4260, loss = 0.24, batch loss = 0.19 (36.5 examples/sec; 0.219 sec/batch; 19h:58m:11s remains)
INFO - root - 2017-12-17 03:10:52.541656: step 4270, loss = 0.31, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 20h:10m:06s remains)
INFO - root - 2017-12-17 03:10:54.757203: step 4280, loss = 0.32, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 20h:04m:55s remains)
INFO - root - 2017-12-17 03:10:56.943741: step 4290, loss = 0.17, batch loss = 0.12 (35.6 examples/sec; 0.224 sec/batch; 20h:27m:40s remains)
INFO - root - 2017-12-17 03:10:59.164728: step 4300, loss = 0.19, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 19h:59m:27s remains)
INFO - root - 2017-12-17 03:11:01.474303: step 4310, loss = 0.22, batch loss = 0.16 (36.6 examples/sec; 0.219 sec/batch; 19h:55m:54s remains)
INFO - root - 2017-12-17 03:11:03.692944: step 4320, loss = 0.29, batch loss = 0.24 (35.6 examples/sec; 0.225 sec/batch; 20h:28m:15s remains)
INFO - root - 2017-12-17 03:11:05.888559: step 4330, loss = 0.20, batch loss = 0.15 (37.4 examples/sec; 0.214 sec/batch; 19h:31m:27s remains)
INFO - root - 2017-12-17 03:11:08.094195: step 4340, loss = 0.23, batch loss = 0.18 (36.2 examples/sec; 0.221 sec/batch; 20h:08m:09s remains)
INFO - root - 2017-12-17 03:11:10.325147: step 4350, loss = 0.21, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 20h:35m:13s remains)
INFO - root - 2017-12-17 03:11:12.539040: step 4360, loss = 0.20, batch loss = 0.15 (37.0 examples/sec; 0.216 sec/batch; 19h:43m:04s remains)
INFO - root - 2017-12-17 03:11:14.763872: step 4370, loss = 0.28, batch loss = 0.23 (36.3 examples/sec; 0.221 sec/batch; 20h:06m:11s remains)
INFO - root - 2017-12-17 03:11:16.961059: step 4380, loss = 0.21, batch loss = 0.15 (36.8 examples/sec; 0.217 sec/batch; 19h:48m:59s remains)
INFO - root - 2017-12-17 03:11:19.166746: step 4390, loss = 0.21, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 20h:08m:04s remains)
INFO - root - 2017-12-17 03:11:21.413898: step 4400, loss = 0.31, batch loss = 0.25 (34.8 examples/sec; 0.230 sec/batch; 20h:56m:49s remains)
INFO - root - 2017-12-17 03:11:23.766596: step 4410, loss = 0.19, batch loss = 0.13 (36.9 examples/sec; 0.217 sec/batch; 19h:45m:45s remains)
INFO - root - 2017-12-17 03:11:26.028167: step 4420, loss = 0.22, batch loss = 0.17 (37.5 examples/sec; 0.213 sec/batch; 19h:27m:12s remains)
INFO - root - 2017-12-17 03:11:28.239907: step 4430, loss = 0.27, batch loss = 0.22 (35.9 examples/sec; 0.223 sec/batch; 20h:18m:33s remains)
INFO - root - 2017-12-17 03:11:30.432486: step 4440, loss = 0.19, batch loss = 0.13 (36.6 examples/sec; 0.219 sec/batch; 19h:55m:02s remains)
INFO - root - 2017-12-17 03:11:32.616272: step 4450, loss = 0.33, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 20h:29m:09s remains)
INFO - root - 2017-12-17 03:11:34.864268: step 4460, loss = 0.21, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 20h:44m:46s remains)
INFO - root - 2017-12-17 03:11:37.076186: step 4470, loss = 0.19, batch loss = 0.13 (36.6 examples/sec; 0.218 sec/batch; 19h:53m:51s remains)
INFO - root - 2017-12-17 03:11:39.324159: step 4480, loss = 0.26, batch loss = 0.21 (35.0 examples/sec; 0.229 sec/batch; 20h:50m:21s remains)
INFO - root - 2017-12-17 03:11:41.557744: step 4490, loss = 0.22, batch loss = 0.17 (35.6 examples/sec; 0.225 sec/batch; 20h:29m:07s remains)
INFO - root - 2017-12-17 03:11:43.769945: step 4500, loss = 0.22, batch loss = 0.17 (34.1 examples/sec; 0.234 sec/batch; 21h:20m:48s remains)
INFO - root - 2017-12-17 03:11:46.089899: step 4510, loss = 0.20, batch loss = 0.14 (36.8 examples/sec; 0.217 sec/batch; 19h:48m:17s remains)
INFO - root - 2017-12-17 03:11:48.271307: step 4520, loss = 0.25, batch loss = 0.19 (37.7 examples/sec; 0.212 sec/batch; 19h:19m:22s remains)
INFO - root - 2017-12-17 03:11:50.486332: step 4530, loss = 0.32, batch loss = 0.27 (36.1 examples/sec; 0.221 sec/batch; 20h:09m:49s remains)
INFO - root - 2017-12-17 03:11:52.730644: step 4540, loss = 0.18, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 20h:11m:06s remains)
INFO - root - 2017-12-17 03:11:54.938879: step 4550, loss = 0.26, batch loss = 0.21 (36.6 examples/sec; 0.219 sec/batch; 19h:55m:50s remains)
INFO - root - 2017-12-17 03:11:57.150747: step 4560, loss = 0.17, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 19h:51m:11s remains)
INFO - root - 2017-12-17 03:11:59.352335: step 4570, loss = 0.17, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 19h:58m:43s remains)
INFO - root - 2017-12-17 03:12:01.578339: step 4580, loss = 0.23, batch loss = 0.18 (35.8 examples/sec; 0.224 sec/batch; 20h:22m:00s remains)
INFO - root - 2017-12-17 03:12:03.786377: step 4590, loss = 0.21, batch loss = 0.16 (35.0 examples/sec; 0.229 sec/batch; 20h:50m:46s remains)
INFO - root - 2017-12-17 03:12:06.007343: step 4600, loss = 0.22, batch loss = 0.16 (33.4 examples/sec; 0.239 sec/batch; 21h:47m:07s remains)
INFO - root - 2017-12-17 03:12:08.355373: step 4610, loss = 0.16, batch loss = 0.11 (33.6 examples/sec; 0.238 sec/batch; 21h:42m:18s remains)
INFO - root - 2017-12-17 03:12:10.564732: step 4620, loss = 0.31, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 20h:44m:26s remains)
INFO - root - 2017-12-17 03:12:12.788353: step 4630, loss = 0.16, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 20h:39m:48s remains)
INFO - root - 2017-12-17 03:12:15.026617: step 4640, loss = 0.19, batch loss = 0.13 (36.8 examples/sec; 0.217 sec/batch; 19h:48m:22s remains)
INFO - root - 2017-12-17 03:12:17.231996: step 4650, loss = 0.21, batch loss = 0.16 (36.1 examples/sec; 0.222 sec/batch; 20h:10m:36s remains)
INFO - root - 2017-12-17 03:12:19.441835: step 4660, loss = 0.20, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 20h:15m:23s remains)
INFO - root - 2017-12-17 03:12:21.637406: step 4670, loss = 0.22, batch loss = 0.17 (36.4 examples/sec; 0.220 sec/batch; 20h:00m:52s remains)
INFO - root - 2017-12-17 03:12:23.852122: step 4680, loss = 0.34, batch loss = 0.29 (35.8 examples/sec; 0.223 sec/batch; 20h:20m:09s remains)
INFO - root - 2017-12-17 03:12:26.045163: step 4690, loss = 0.25, batch loss = 0.20 (37.6 examples/sec; 0.213 sec/batch; 19h:22m:41s remains)
INFO - root - 2017-12-17 03:12:28.255025: step 4700, loss = 0.19, batch loss = 0.14 (35.0 examples/sec; 0.228 sec/batch; 20h:47m:19s remains)
INFO - root - 2017-12-17 03:12:30.648371: step 4710, loss = 0.23, batch loss = 0.18 (35.3 examples/sec; 0.227 sec/batch; 20h:38m:06s remains)
INFO - root - 2017-12-17 03:12:32.827769: step 4720, loss = 0.24, batch loss = 0.19 (36.1 examples/sec; 0.222 sec/batch; 20h:10m:06s remains)
INFO - root - 2017-12-17 03:12:35.022504: step 4730, loss = 0.20, batch loss = 0.15 (36.8 examples/sec; 0.218 sec/batch; 19h:48m:15s remains)
INFO - root - 2017-12-17 03:12:37.214106: step 4740, loss = 0.25, batch loss = 0.20 (36.8 examples/sec; 0.217 sec/batch; 19h:46m:47s remains)
INFO - root - 2017-12-17 03:12:39.420041: step 4750, loss = 0.25, batch loss = 0.20 (36.9 examples/sec; 0.217 sec/batch; 19h:43m:23s remains)
INFO - root - 2017-12-17 03:12:41.618109: step 4760, loss = 0.18, batch loss = 0.13 (36.8 examples/sec; 0.217 sec/batch; 19h:47m:28s remains)
INFO - root - 2017-12-17 03:12:43.810077: step 4770, loss = 0.28, batch loss = 0.23 (36.9 examples/sec; 0.217 sec/batch; 19h:45m:38s remains)
INFO - root - 2017-12-17 03:12:46.032615: step 4780, loss = 0.27, batch loss = 0.22 (34.8 examples/sec; 0.230 sec/batch; 20h:54m:05s remains)
INFO - root - 2017-12-17 03:12:48.259153: step 4790, loss = 0.19, batch loss = 0.14 (37.7 examples/sec; 0.212 sec/batch; 19h:20m:25s remains)
INFO - root - 2017-12-17 03:12:50.444241: step 4800, loss = 0.23, batch loss = 0.17 (37.7 examples/sec; 0.212 sec/batch; 19h:18m:16s remains)
INFO - root - 2017-12-17 03:12:52.821961: step 4810, loss = 0.15, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 20h:08m:35s remains)
INFO - root - 2017-12-17 03:12:55.020190: step 4820, loss = 0.16, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 20h:38m:10s remains)
INFO - root - 2017-12-17 03:12:57.190748: step 4830, loss = 0.20, batch loss = 0.14 (37.2 examples/sec; 0.215 sec/batch; 19h:34m:06s remains)
INFO - root - 2017-12-17 03:12:59.431690: step 4840, loss = 0.19, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 20h:24m:15s remains)
INFO - root - 2017-12-17 03:13:01.636279: step 4850, loss = 0.16, batch loss = 0.11 (36.6 examples/sec; 0.219 sec/batch; 19h:53m:15s remains)
INFO - root - 2017-12-17 03:13:03.861711: step 4860, loss = 0.18, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 20h:48m:01s remains)
INFO - root - 2017-12-17 03:13:06.055109: step 4870, loss = 0.20, batch loss = 0.15 (36.6 examples/sec; 0.219 sec/batch; 19h:54m:35s remains)
INFO - root - 2017-12-17 03:13:08.335300: step 4880, loss = 0.16, batch loss = 0.11 (35.8 examples/sec; 0.223 sec/batch; 20h:18m:47s remains)
INFO - root - 2017-12-17 03:13:10.572717: step 4890, loss = 0.18, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 20h:11m:53s remains)
INFO - root - 2017-12-17 03:13:12.757535: step 4900, loss = 0.19, batch loss = 0.14 (36.4 examples/sec; 0.220 sec/batch; 19h:58m:30s remains)
INFO - root - 2017-12-17 03:13:15.066189: step 4910, loss = 0.23, batch loss = 0.18 (35.8 examples/sec; 0.223 sec/batch; 20h:18m:26s remains)
INFO - root - 2017-12-17 03:13:17.271108: step 4920, loss = 0.17, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 19h:49m:55s remains)
INFO - root - 2017-12-17 03:13:19.482288: step 4930, loss = 0.20, batch loss = 0.14 (36.4 examples/sec; 0.220 sec/batch; 20h:01m:09s remains)
INFO - root - 2017-12-17 03:13:21.683236: step 4940, loss = 0.19, batch loss = 0.14 (36.4 examples/sec; 0.220 sec/batch; 19h:58m:56s remains)
INFO - root - 2017-12-17 03:13:23.901629: step 4950, loss = 0.27, batch loss = 0.22 (36.4 examples/sec; 0.220 sec/batch; 20h:01m:25s remains)
INFO - root - 2017-12-17 03:13:26.088077: step 4960, loss = 0.20, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 20h:12m:14s remains)
INFO - root - 2017-12-17 03:13:28.278302: step 4970, loss = 0.18, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 20h:04m:55s remains)
INFO - root - 2017-12-17 03:13:30.459078: step 4980, loss = 0.13, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 20h:16m:30s remains)
INFO - root - 2017-12-17 03:13:32.693038: step 4990, loss = 0.31, batch loss = 0.26 (36.1 examples/sec; 0.222 sec/batch; 20h:10m:54s remains)
INFO - root - 2017-12-17 03:13:34.884266: step 5000, loss = 0.25, batch loss = 0.20 (37.9 examples/sec; 0.211 sec/batch; 19h:12m:16s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-5000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-5000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 03:13:37.991195: step 5010, loss = 0.19, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 20h:24m:07s remains)
INFO - root - 2017-12-17 03:13:40.206668: step 5020, loss = 0.16, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 20h:22m:33s remains)
INFO - root - 2017-12-17 03:13:42.407669: step 5030, loss = 0.16, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 20h:11m:34s remains)
INFO - root - 2017-12-17 03:13:44.628921: step 5040, loss = 0.35, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 20h:40m:07s remains)
INFO - root - 2017-12-17 03:13:46.883981: step 5050, loss = 0.18, batch loss = 0.13 (36.7 examples/sec; 0.218 sec/batch; 19h:50m:40s remains)
INFO - root - 2017-12-17 03:13:49.098302: step 5060, loss = 0.19, batch loss = 0.14 (37.2 examples/sec; 0.215 sec/batch; 19h:34m:55s remains)
INFO - root - 2017-12-17 03:13:51.343793: step 5070, loss = 0.21, batch loss = 0.16 (35.8 examples/sec; 0.224 sec/batch; 20h:20m:58s remains)
INFO - root - 2017-12-17 03:13:53.547561: step 5080, loss = 0.16, batch loss = 0.11 (37.1 examples/sec; 0.215 sec/batch; 19h:35m:18s remains)
INFO - root - 2017-12-17 03:13:55.793872: step 5090, loss = 0.19, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 20h:53m:08s remains)
INFO - root - 2017-12-17 03:13:57.984021: step 5100, loss = 0.20, batch loss = 0.15 (36.6 examples/sec; 0.219 sec/batch; 19h:52m:48s remains)
INFO - root - 2017-12-17 03:14:00.320717: step 5110, loss = 0.21, batch loss = 0.16 (36.8 examples/sec; 0.217 sec/batch; 19h:44m:42s remains)
INFO - root - 2017-12-17 03:14:02.542119: step 5120, loss = 0.22, batch loss = 0.17 (36.6 examples/sec; 0.218 sec/batch; 19h:52m:10s remains)
INFO - root - 2017-12-17 03:14:04.803638: step 5130, loss = 0.20, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 20h:04m:43s remains)
INFO - root - 2017-12-17 03:14:07.009888: step 5140, loss = 0.20, batch loss = 0.14 (37.0 examples/sec; 0.216 sec/batch; 19h:41m:12s remains)
INFO - root - 2017-12-17 03:14:09.220688: step 5150, loss = 0.20, batch loss = 0.14 (37.1 examples/sec; 0.216 sec/batch; 19h:37m:15s remains)
INFO - root - 2017-12-17 03:14:11.464477: step 5160, loss = 0.17, batch loss = 0.12 (34.7 examples/sec; 0.230 sec/batch; 20h:57m:20s remains)
INFO - root - 2017-12-17 03:14:13.693362: step 5170, loss = 0.19, batch loss = 0.14 (36.1 examples/sec; 0.222 sec/batch; 20h:10m:11s remains)
INFO - root - 2017-12-17 03:14:15.888661: step 5180, loss = 0.17, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 20h:04m:29s remains)
INFO - root - 2017-12-17 03:14:18.148102: step 5190, loss = 0.21, batch loss = 0.16 (35.7 examples/sec; 0.224 sec/batch; 20h:23m:53s remains)
INFO - root - 2017-12-17 03:14:20.366876: step 5200, loss = 0.19, batch loss = 0.14 (36.6 examples/sec; 0.219 sec/batch; 19h:53m:35s remains)
INFO - root - 2017-12-17 03:14:22.715887: step 5210, loss = 0.15, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 20h:27m:48s remains)
INFO - root - 2017-12-17 03:14:24.945513: step 5220, loss = 0.23, batch loss = 0.18 (36.2 examples/sec; 0.221 sec/batch; 20h:05m:05s remains)
INFO - root - 2017-12-17 03:14:27.146589: step 5230, loss = 0.19, batch loss = 0.14 (36.8 examples/sec; 0.217 sec/batch; 19h:45m:41s remains)
INFO - root - 2017-12-17 03:14:29.333973: step 5240, loss = 0.15, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 19h:59m:15s remains)
INFO - root - 2017-12-17 03:14:31.569470: step 5250, loss = 0.23, batch loss = 0.18 (36.3 examples/sec; 0.220 sec/batch; 20h:02m:20s remains)
INFO - root - 2017-12-17 03:14:33.776918: step 5260, loss = 0.25, batch loss = 0.20 (37.2 examples/sec; 0.215 sec/batch; 19h:33m:16s remains)
INFO - root - 2017-12-17 03:14:35.945638: step 5270, loss = 0.17, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 20h:01m:43s remains)
INFO - root - 2017-12-17 03:14:38.150041: step 5280, loss = 0.20, batch loss = 0.15 (36.9 examples/sec; 0.217 sec/batch; 19h:40m:54s remains)
INFO - root - 2017-12-17 03:14:40.364508: step 5290, loss = 0.22, batch loss = 0.17 (36.5 examples/sec; 0.219 sec/batch; 19h:55m:20s remains)
INFO - root - 2017-12-17 03:14:42.603748: step 5300, loss = 0.17, batch loss = 0.12 (34.9 examples/sec; 0.230 sec/batch; 20h:51m:47s remains)
INFO - root - 2017-12-17 03:14:44.963838: step 5310, loss = 0.16, batch loss = 0.11 (37.2 examples/sec; 0.215 sec/batch; 19h:32m:14s remains)
INFO - root - 2017-12-17 03:14:47.129053: step 5320, loss = 0.26, batch loss = 0.21 (36.7 examples/sec; 0.218 sec/batch; 19h:49m:49s remains)
INFO - root - 2017-12-17 03:14:49.316732: step 5330, loss = 0.15, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 20h:25m:22s remains)
INFO - root - 2017-12-17 03:14:51.544855: step 5340, loss = 0.15, batch loss = 0.10 (34.9 examples/sec; 0.229 sec/batch; 20h:49m:41s remains)
INFO - root - 2017-12-17 03:14:53.769838: step 5350, loss = 0.18, batch loss = 0.13 (35.8 examples/sec; 0.224 sec/batch; 20h:18m:53s remains)
INFO - root - 2017-12-17 03:14:56.002844: step 5360, loss = 0.18, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 20h:05m:45s remains)
INFO - root - 2017-12-17 03:14:58.195000: step 5370, loss = 0.20, batch loss = 0.15 (36.9 examples/sec; 0.217 sec/batch; 19h:43m:12s remains)
INFO - root - 2017-12-17 03:15:00.399683: step 5380, loss = 0.17, batch loss = 0.12 (37.0 examples/sec; 0.216 sec/batch; 19h:38m:46s remains)
INFO - root - 2017-12-17 03:15:02.595613: step 5390, loss = 0.17, batch loss = 0.12 (36.9 examples/sec; 0.217 sec/batch; 19h:41m:19s remains)
INFO - root - 2017-12-17 03:15:04.849977: step 5400, loss = 0.22, batch loss = 0.17 (36.1 examples/sec; 0.222 sec/batch; 20h:09m:26s remains)
INFO - root - 2017-12-17 03:15:07.233341: step 5410, loss = 0.23, batch loss = 0.18 (36.8 examples/sec; 0.217 sec/batch; 19h:44m:16s remains)
INFO - root - 2017-12-17 03:15:09.445266: step 5420, loss = 0.19, batch loss = 0.14 (37.3 examples/sec; 0.215 sec/batch; 19h:30m:27s remains)
INFO - root - 2017-12-17 03:15:11.695500: step 5430, loss = 0.18, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 20h:39m:22s remains)
INFO - root - 2017-12-17 03:15:13.930851: step 5440, loss = 0.17, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 20h:11m:01s remains)
INFO - root - 2017-12-17 03:15:16.156701: step 5450, loss = 0.26, batch loss = 0.21 (36.1 examples/sec; 0.222 sec/batch; 20h:09m:06s remains)
INFO - root - 2017-12-17 03:15:18.342599: step 5460, loss = 0.17, batch loss = 0.12 (35.3 examples/sec; 0.226 sec/batch; 20h:33m:32s remains)
INFO - root - 2017-12-17 03:15:20.593851: step 5470, loss = 0.18, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 20h:01m:44s remains)
INFO - root - 2017-12-17 03:15:22.813287: step 5480, loss = 0.18, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 20h:28m:14s remains)
INFO - root - 2017-12-17 03:15:25.066144: step 5490, loss = 0.16, batch loss = 0.11 (36.7 examples/sec; 0.218 sec/batch; 19h:49m:30s remains)
INFO - root - 2017-12-17 03:15:27.308664: step 5500, loss = 0.21, batch loss = 0.16 (35.4 examples/sec; 0.226 sec/batch; 20h:30m:46s remains)
INFO - root - 2017-12-17 03:15:29.667113: step 5510, loss = 0.15, batch loss = 0.10 (36.8 examples/sec; 0.217 sec/batch; 19h:43m:34s remains)
INFO - root - 2017-12-17 03:15:31.843868: step 5520, loss = 0.19, batch loss = 0.14 (36.6 examples/sec; 0.218 sec/batch; 19h:50m:11s remains)
INFO - root - 2017-12-17 03:15:34.064737: step 5530, loss = 0.23, batch loss = 0.18 (34.2 examples/sec; 0.234 sec/batch; 21h:14m:46s remains)
INFO - root - 2017-12-17 03:15:36.292537: step 5540, loss = 0.19, batch loss = 0.14 (36.7 examples/sec; 0.218 sec/batch; 19h:47m:25s remains)
INFO - root - 2017-12-17 03:15:38.491651: step 5550, loss = 0.22, batch loss = 0.17 (34.6 examples/sec; 0.231 sec/batch; 20h:58m:59s remains)
INFO - root - 2017-12-17 03:15:40.718529: step 5560, loss = 0.21, batch loss = 0.16 (37.1 examples/sec; 0.216 sec/batch; 19h:35m:17s remains)
INFO - root - 2017-12-17 03:15:42.917473: step 5570, loss = 0.29, batch loss = 0.24 (36.3 examples/sec; 0.220 sec/batch; 19h:59m:57s remains)
INFO - root - 2017-12-17 03:15:45.130198: step 5580, loss = 0.16, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 20h:15m:28s remains)
INFO - root - 2017-12-17 03:15:47.333268: step 5590, loss = 0.27, batch loss = 0.22 (36.1 examples/sec; 0.221 sec/batch; 20h:06m:21s remains)
INFO - root - 2017-12-17 03:15:49.525921: step 5600, loss = 0.22, batch loss = 0.17 (36.4 examples/sec; 0.220 sec/batch; 19h:56m:03s remains)
INFO - root - 2017-12-17 03:15:51.842067: step 5610, loss = 0.25, batch loss = 0.20 (36.3 examples/sec; 0.220 sec/batch; 20h:00m:45s remains)
INFO - root - 2017-12-17 03:15:54.036558: step 5620, loss = 0.25, batch loss = 0.20 (36.5 examples/sec; 0.219 sec/batch; 19h:55m:19s remains)
INFO - root - 2017-12-17 03:15:56.244333: step 5630, loss = 0.17, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 20h:35m:33s remains)
INFO - root - 2017-12-17 03:15:58.432119: step 5640, loss = 0.21, batch loss = 0.16 (36.4 examples/sec; 0.220 sec/batch; 19h:56m:32s remains)
INFO - root - 2017-12-17 03:16:00.656595: step 5650, loss = 0.17, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 20h:17m:57s remains)
INFO - root - 2017-12-17 03:16:02.870340: step 5660, loss = 0.17, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 19h:46m:56s remains)
INFO - root - 2017-12-17 03:16:05.088111: step 5670, loss = 0.18, batch loss = 0.13 (37.2 examples/sec; 0.215 sec/batch; 19h:31m:51s remains)
INFO - root - 2017-12-17 03:16:07.295178: step 5680, loss = 0.20, batch loss = 0.15 (36.7 examples/sec; 0.218 sec/batch; 19h:48m:48s remains)
INFO - root - 2017-12-17 03:16:09.526664: step 5690, loss = 0.22, batch loss = 0.17 (34.7 examples/sec; 0.231 sec/batch; 20h:55m:30s remains)
INFO - root - 2017-12-17 03:16:11.726460: step 5700, loss = 0.17, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 19h:57m:43s remains)
INFO - root - 2017-12-17 03:16:14.043849: step 5710, loss = 0.24, batch loss = 0.19 (36.9 examples/sec; 0.217 sec/batch; 19h:41m:04s remains)
INFO - root - 2017-12-17 03:16:16.286617: step 5720, loss = 0.23, batch loss = 0.18 (37.1 examples/sec; 0.216 sec/batch; 19h:35m:51s remains)
INFO - root - 2017-12-17 03:16:18.463230: step 5730, loss = 0.16, batch loss = 0.11 (37.2 examples/sec; 0.215 sec/batch; 19h:31m:40s remains)
INFO - root - 2017-12-17 03:16:20.653648: step 5740, loss = 0.19, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 19h:53m:15s remains)
INFO - root - 2017-12-17 03:16:22.840746: step 5750, loss = 0.15, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 20h:02m:46s remains)
INFO - root - 2017-12-17 03:16:25.063853: step 5760, loss = 0.18, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 20h:40m:17s remains)
INFO - root - 2017-12-17 03:16:27.315895: step 5770, loss = 0.17, batch loss = 0.12 (34.5 examples/sec; 0.232 sec/batch; 21h:02m:20s remains)
INFO - root - 2017-12-17 03:16:29.525361: step 5780, loss = 0.21, batch loss = 0.16 (36.3 examples/sec; 0.220 sec/batch; 19h:59m:17s remains)
INFO - root - 2017-12-17 03:16:31.732143: step 5790, loss = 0.21, batch loss = 0.16 (37.4 examples/sec; 0.214 sec/batch; 19h:24m:43s remains)
INFO - root - 2017-12-17 03:16:33.905041: step 5800, loss = 0.22, batch loss = 0.18 (37.2 examples/sec; 0.215 sec/batch; 19h:32m:21s remains)
INFO - root - 2017-12-17 03:16:36.235018: step 5810, loss = 0.18, batch loss = 0.13 (37.5 examples/sec; 0.213 sec/batch; 19h:20m:31s remains)
INFO - root - 2017-12-17 03:16:38.424566: step 5820, loss = 0.20, batch loss = 0.15 (36.5 examples/sec; 0.219 sec/batch; 19h:54m:06s remains)
INFO - root - 2017-12-17 03:16:40.653026: step 5830, loss = 0.20, batch loss = 0.15 (35.7 examples/sec; 0.224 sec/batch; 20h:21m:13s remains)
INFO - root - 2017-12-17 03:16:42.877945: step 5840, loss = 0.19, batch loss = 0.14 (36.3 examples/sec; 0.221 sec/batch; 20h:00m:59s remains)
INFO - root - 2017-12-17 03:16:45.100483: step 5850, loss = 0.22, batch loss = 0.17 (36.6 examples/sec; 0.218 sec/batch; 19h:48m:58s remains)
INFO - root - 2017-12-17 03:16:47.291269: step 5860, loss = 0.20, batch loss = 0.15 (37.2 examples/sec; 0.215 sec/batch; 19h:30m:41s remains)
INFO - root - 2017-12-17 03:16:49.502179: step 5870, loss = 0.31, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 20h:03m:03s remains)
INFO - root - 2017-12-17 03:16:51.748143: step 5880, loss = 0.19, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 20h:29m:50s remains)
INFO - root - 2017-12-17 03:16:54.064792: step 5890, loss = 0.15, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 20h:04m:36s remains)
INFO - root - 2017-12-17 03:16:56.245360: step 5900, loss = 0.17, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 20h:02m:04s remains)
INFO - root - 2017-12-17 03:16:58.561845: step 5910, loss = 0.16, batch loss = 0.11 (36.1 examples/sec; 0.221 sec/batch; 20h:04m:49s remains)
INFO - root - 2017-12-17 03:17:00.779699: step 5920, loss = 0.15, batch loss = 0.10 (35.1 examples/sec; 0.228 sec/batch; 20h:41m:20s remains)
INFO - root - 2017-12-17 03:17:02.994793: step 5930, loss = 0.19, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 20h:31m:07s remains)
INFO - root - 2017-12-17 03:17:05.230552: step 5940, loss = 0.16, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 19h:57m:58s remains)
INFO - root - 2017-12-17 03:17:07.486833: step 5950, loss = 0.14, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 20h:28m:27s remains)
INFO - root - 2017-12-17 03:17:09.704152: step 5960, loss = 0.18, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 19h:57m:48s remains)
INFO - root - 2017-12-17 03:17:11.934645: step 5970, loss = 0.17, batch loss = 0.13 (36.9 examples/sec; 0.217 sec/batch; 19h:39m:24s remains)
INFO - root - 2017-12-17 03:17:14.127410: step 5980, loss = 0.25, batch loss = 0.20 (36.2 examples/sec; 0.221 sec/batch; 20h:03m:53s remains)
INFO - root - 2017-12-17 03:17:16.303746: step 5990, loss = 0.17, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 20h:13m:51s remains)
INFO - root - 2017-12-17 03:17:18.524126: step 6000, loss = 0.20, batch loss = 0.16 (36.1 examples/sec; 0.222 sec/batch; 20h:07m:16s remains)
INFO - root - 2017-12-17 03:17:20.852039: step 6010, loss = 0.17, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 20h:11m:01s remains)
INFO - root - 2017-12-17 03:17:23.100055: step 6020, loss = 0.20, batch loss = 0.15 (35.0 examples/sec; 0.228 sec/batch; 20h:42m:43s remains)
INFO - root - 2017-12-17 03:17:25.335300: step 6030, loss = 0.13, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 20h:24m:03s remains)
INFO - root - 2017-12-17 03:17:27.567993: step 6040, loss = 0.25, batch loss = 0.20 (36.0 examples/sec; 0.222 sec/batch; 20h:08m:12s remains)
INFO - root - 2017-12-17 03:17:29.788967: step 6050, loss = 0.16, batch loss = 0.12 (36.1 examples/sec; 0.222 sec/batch; 20h:07m:14s remains)
INFO - root - 2017-12-17 03:17:32.012837: step 6060, loss = 0.15, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 20h:30m:00s remains)
INFO - root - 2017-12-17 03:17:34.235118: step 6070, loss = 0.16, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 20h:00m:54s remains)
INFO - root - 2017-12-17 03:17:36.422598: step 6080, loss = 0.17, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 19h:59m:24s remains)
INFO - root - 2017-12-17 03:17:38.626970: step 6090, loss = 0.20, batch loss = 0.15 (36.3 examples/sec; 0.221 sec/batch; 19h:59m:36s remains)
INFO - root - 2017-12-17 03:17:40.810391: step 6100, loss = 0.21, batch loss = 0.16 (37.1 examples/sec; 0.216 sec/batch; 19h:33m:27s remains)
INFO - root - 2017-12-17 03:17:43.120523: step 6110, loss = 0.17, batch loss = 0.12 (37.1 examples/sec; 0.216 sec/batch; 19h:33m:32s remains)
INFO - root - 2017-12-17 03:17:45.363655: step 6120, loss = 0.16, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 20h:02m:50s remains)
INFO - root - 2017-12-17 03:17:47.584998: step 6130, loss = 0.22, batch loss = 0.17 (36.5 examples/sec; 0.219 sec/batch; 19h:50m:46s remains)
INFO - root - 2017-12-17 03:17:49.826245: step 6140, loss = 0.19, batch loss = 0.14 (33.5 examples/sec; 0.238 sec/batch; 21h:37m:08s remains)
INFO - root - 2017-12-17 03:17:52.067058: step 6150, loss = 0.21, batch loss = 0.17 (34.2 examples/sec; 0.234 sec/batch; 21h:10m:47s remains)
INFO - root - 2017-12-17 03:17:54.309618: step 6160, loss = 0.32, batch loss = 0.27 (36.6 examples/sec; 0.219 sec/batch; 19h:50m:07s remains)
INFO - root - 2017-12-17 03:17:56.476980: step 6170, loss = 0.23, batch loss = 0.18 (38.1 examples/sec; 0.210 sec/batch; 19h:00m:35s remains)
INFO - root - 2017-12-17 03:17:58.705943: step 6180, loss = 0.15, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 19h:49m:48s remains)
INFO - root - 2017-12-17 03:18:00.943095: step 6190, loss = 0.23, batch loss = 0.18 (37.3 examples/sec; 0.215 sec/batch; 19h:27m:58s remains)
INFO - root - 2017-12-17 03:18:03.144498: step 6200, loss = 0.22, batch loss = 0.17 (36.6 examples/sec; 0.218 sec/batch; 19h:47m:47s remains)
INFO - root - 2017-12-17 03:18:05.461376: step 6210, loss = 0.17, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 20h:16m:14s remains)
INFO - root - 2017-12-17 03:18:07.704383: step 6220, loss = 0.21, batch loss = 0.16 (34.2 examples/sec; 0.234 sec/batch; 21h:10m:16s remains)
INFO - root - 2017-12-17 03:18:09.929217: step 6230, loss = 0.16, batch loss = 0.11 (37.3 examples/sec; 0.215 sec/batch; 19h:27m:42s remains)
INFO - root - 2017-12-17 03:18:12.159103: step 6240, loss = 0.19, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 20h:01m:56s remains)
INFO - root - 2017-12-17 03:18:14.374449: step 6250, loss = 0.19, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 19h:51m:31s remains)
INFO - root - 2017-12-17 03:18:16.588021: step 6260, loss = 0.22, batch loss = 0.17 (35.4 examples/sec; 0.226 sec/batch; 20h:27m:39s remains)
INFO - root - 2017-12-17 03:18:18.807813: step 6270, loss = 0.15, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 20h:17m:21s remains)
INFO - root - 2017-12-17 03:18:21.044035: step 6280, loss = 0.19, batch loss = 0.15 (36.3 examples/sec; 0.220 sec/batch; 19h:57m:08s remains)
INFO - root - 2017-12-17 03:18:23.273485: step 6290, loss = 0.18, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 20h:21m:55s remains)
INFO - root - 2017-12-17 03:18:25.544592: step 6300, loss = 0.25, batch loss = 0.20 (34.9 examples/sec; 0.229 sec/batch; 20h:46m:39s remains)
INFO - root - 2017-12-17 03:18:27.941017: step 6310, loss = 0.16, batch loss = 0.11 (36.1 examples/sec; 0.221 sec/batch; 20h:03m:37s remains)
INFO - root - 2017-12-17 03:18:30.157737: step 6320, loss = 0.20, batch loss = 0.15 (34.7 examples/sec; 0.231 sec/batch; 20h:55m:03s remains)
INFO - root - 2017-12-17 03:18:32.384757: step 6330, loss = 0.21, batch loss = 0.16 (34.1 examples/sec; 0.235 sec/batch; 21h:15m:49s remains)
INFO - root - 2017-12-17 03:18:34.581461: step 6340, loss = 0.19, batch loss = 0.14 (36.6 examples/sec; 0.219 sec/batch; 19h:49m:10s remains)
INFO - root - 2017-12-17 03:18:36.805512: step 6350, loss = 0.14, batch loss = 0.09 (36.8 examples/sec; 0.217 sec/batch; 19h:41m:57s remains)
INFO - root - 2017-12-17 03:18:39.025446: step 6360, loss = 0.15, batch loss = 0.10 (36.7 examples/sec; 0.218 sec/batch; 19h:46m:19s remains)
INFO - root - 2017-12-17 03:18:41.190501: step 6370, loss = 0.17, batch loss = 0.12 (36.8 examples/sec; 0.217 sec/batch; 19h:40m:02s remains)
INFO - root - 2017-12-17 03:18:43.378545: step 6380, loss = 0.18, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 20h:04m:29s remains)
INFO - root - 2017-12-17 03:18:45.627417: step 6390, loss = 0.18, batch loss = 0.13 (35.0 examples/sec; 0.228 sec/batch; 20h:40m:41s remains)
INFO - root - 2017-12-17 03:18:47.856915: step 6400, loss = 0.16, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 20h:01m:49s remains)
INFO - root - 2017-12-17 03:18:50.161866: step 6410, loss = 0.20, batch loss = 0.15 (35.8 examples/sec; 0.223 sec/batch; 20h:14m:33s remains)
INFO - root - 2017-12-17 03:18:52.363858: step 6420, loss = 0.16, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 19h:56m:32s remains)
INFO - root - 2017-12-17 03:18:54.567220: step 6430, loss = 0.23, batch loss = 0.18 (36.4 examples/sec; 0.220 sec/batch; 19h:55m:35s remains)
INFO - root - 2017-12-17 03:18:56.745013: step 6440, loss = 0.24, batch loss = 0.20 (37.0 examples/sec; 0.216 sec/batch; 19h:35m:06s remains)
INFO - root - 2017-12-17 03:18:58.926686: step 6450, loss = 0.21, batch loss = 0.17 (36.2 examples/sec; 0.221 sec/batch; 19h:59m:34s remains)
INFO - root - 2017-12-17 03:19:01.218456: step 6460, loss = 0.17, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 20h:20m:36s remains)
INFO - root - 2017-12-17 03:19:03.408758: step 6470, loss = 0.18, batch loss = 0.13 (36.6 examples/sec; 0.219 sec/batch; 19h:48m:47s remains)
INFO - root - 2017-12-17 03:19:05.644583: step 6480, loss = 0.18, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 19h:56m:32s remains)
INFO - root - 2017-12-17 03:19:07.840544: step 6490, loss = 0.15, batch loss = 0.11 (36.9 examples/sec; 0.217 sec/batch; 19h:36m:43s remains)
INFO - root - 2017-12-17 03:19:10.068072: step 6500, loss = 0.20, batch loss = 0.15 (36.1 examples/sec; 0.221 sec/batch; 20h:02m:36s remains)
INFO - root - 2017-12-17 03:19:12.388029: step 6510, loss = 0.25, batch loss = 0.20 (36.5 examples/sec; 0.219 sec/batch; 19h:52m:13s remains)
INFO - root - 2017-12-17 03:19:14.610962: step 6520, loss = 0.15, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 20h:33m:37s remains)
INFO - root - 2017-12-17 03:19:16.790899: step 6530, loss = 0.17, batch loss = 0.13 (37.0 examples/sec; 0.216 sec/batch; 19h:34m:48s remains)
INFO - root - 2017-12-17 03:19:19.033290: step 6540, loss = 0.16, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 19h:54m:36s remains)
INFO - root - 2017-12-17 03:19:21.287956: step 6550, loss = 0.16, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 20h:39m:46s remains)
INFO - root - 2017-12-17 03:19:23.540166: step 6560, loss = 0.18, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 20h:35m:28s remains)
INFO - root - 2017-12-17 03:19:25.759004: step 6570, loss = 0.18, batch loss = 0.13 (37.1 examples/sec; 0.216 sec/batch; 19h:31m:38s remains)
INFO - root - 2017-12-17 03:19:27.983341: step 6580, loss = 0.17, batch loss = 0.13 (36.0 examples/sec; 0.223 sec/batch; 20h:08m:42s remains)
INFO - root - 2017-12-17 03:19:30.218867: step 6590, loss = 0.21, batch loss = 0.16 (34.5 examples/sec; 0.232 sec/batch; 20h:59m:26s remains)
INFO - root - 2017-12-17 03:19:32.428811: step 6600, loss = 0.17, batch loss = 0.12 (37.0 examples/sec; 0.216 sec/batch; 19h:34m:57s remains)
INFO - root - 2017-12-17 03:19:34.751324: step 6610, loss = 0.20, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 20h:05m:40s remains)
INFO - root - 2017-12-17 03:19:36.974918: step 6620, loss = 0.16, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 20h:22m:49s remains)
INFO - root - 2017-12-17 03:19:39.223929: step 6630, loss = 0.16, batch loss = 0.11 (35.6 examples/sec; 0.224 sec/batch; 20h:18m:54s remains)
INFO - root - 2017-12-17 03:19:41.439199: step 6640, loss = 0.13, batch loss = 0.09 (36.8 examples/sec; 0.217 sec/batch; 19h:39m:44s remains)
INFO - root - 2017-12-17 03:19:43.662833: step 6650, loss = 0.22, batch loss = 0.17 (35.5 examples/sec; 0.226 sec/batch; 20h:25m:30s remains)
INFO - root - 2017-12-17 03:19:45.888178: step 6660, loss = 0.18, batch loss = 0.13 (37.0 examples/sec; 0.216 sec/batch; 19h:35m:28s remains)
INFO - root - 2017-12-17 03:19:48.139240: step 6670, loss = 0.14, batch loss = 0.09 (34.7 examples/sec; 0.230 sec/batch; 20h:51m:02s remains)
INFO - root - 2017-12-17 03:19:50.353756: step 6680, loss = 0.21, batch loss = 0.16 (36.4 examples/sec; 0.220 sec/batch; 19h:53m:10s remains)
INFO - root - 2017-12-17 03:19:52.590003: step 6690, loss = 0.18, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 20h:45m:28s remains)
INFO - root - 2017-12-17 03:19:54.839613: step 6700, loss = 0.19, batch loss = 0.14 (37.0 examples/sec; 0.216 sec/batch; 19h:34m:35s remains)
INFO - root - 2017-12-17 03:19:57.326046: step 6710, loss = 0.16, batch loss = 0.12 (33.7 examples/sec; 0.238 sec/batch; 21h:29m:47s remains)
INFO - root - 2017-12-17 03:19:59.594282: step 6720, loss = 0.16, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 20h:06m:43s remains)
INFO - root - 2017-12-17 03:20:01.813873: step 6730, loss = 0.17, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 19h:54m:34s remains)
INFO - root - 2017-12-17 03:20:04.031252: step 6740, loss = 0.28, batch loss = 0.24 (35.8 examples/sec; 0.224 sec/batch; 20h:14m:29s remains)
INFO - root - 2017-12-17 03:20:06.242479: step 6750, loss = 0.24, batch loss = 0.20 (37.1 examples/sec; 0.216 sec/batch; 19h:32m:07s remains)
INFO - root - 2017-12-17 03:20:08.485760: step 6760, loss = 0.23, batch loss = 0.18 (36.9 examples/sec; 0.217 sec/batch; 19h:35m:57s remains)
INFO - root - 2017-12-17 03:20:10.732719: step 6770, loss = 0.18, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 20h:30m:02s remains)
INFO - root - 2017-12-17 03:20:12.973377: step 6780, loss = 0.21, batch loss = 0.17 (35.2 examples/sec; 0.227 sec/batch; 20h:32m:16s remains)
INFO - root - 2017-12-17 03:20:15.183179: step 6790, loss = 0.21, batch loss = 0.16 (35.6 examples/sec; 0.225 sec/batch; 20h:21m:24s remains)
INFO - root - 2017-12-17 03:20:17.363811: step 6800, loss = 0.26, batch loss = 0.22 (37.6 examples/sec; 0.213 sec/batch; 19h:15m:33s remains)
INFO - root - 2017-12-17 03:20:19.689346: step 6810, loss = 0.15, batch loss = 0.10 (36.1 examples/sec; 0.221 sec/batch; 20h:01m:16s remains)
INFO - root - 2017-12-17 03:20:21.933504: step 6820, loss = 0.21, batch loss = 0.17 (36.4 examples/sec; 0.220 sec/batch; 19h:51m:56s remains)
INFO - root - 2017-12-17 03:20:24.141421: step 6830, loss = 0.20, batch loss = 0.15 (37.0 examples/sec; 0.216 sec/batch; 19h:32m:39s remains)
INFO - root - 2017-12-17 03:20:26.330688: step 6840, loss = 0.17, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 19h:42m:38s remains)
INFO - root - 2017-12-17 03:20:28.557510: step 6850, loss = 0.20, batch loss = 0.16 (35.6 examples/sec; 0.225 sec/batch; 20h:19m:46s remains)
INFO - root - 2017-12-17 03:20:30.813986: step 6860, loss = 0.24, batch loss = 0.19 (34.3 examples/sec; 0.234 sec/batch; 21h:07m:25s remains)
INFO - root - 2017-12-17 03:20:33.034278: step 6870, loss = 0.15, batch loss = 0.11 (35.2 examples/sec; 0.227 sec/batch; 20h:32m:23s remains)
INFO - root - 2017-12-17 03:20:35.277469: step 6880, loss = 0.12, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 19h:49m:52s remains)
INFO - root - 2017-12-17 03:20:37.468406: step 6890, loss = 0.16, batch loss = 0.11 (35.0 examples/sec; 0.228 sec/batch; 20h:39m:19s remains)
INFO - root - 2017-12-17 03:20:39.662193: step 6900, loss = 0.17, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 19h:54m:05s remains)
INFO - root - 2017-12-17 03:20:42.048596: step 6910, loss = 0.17, batch loss = 0.13 (36.5 examples/sec; 0.219 sec/batch; 19h:49m:22s remains)
INFO - root - 2017-12-17 03:20:44.292692: step 6920, loss = 0.14, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 19h:50m:08s remains)
INFO - root - 2017-12-17 03:20:46.491654: step 6930, loss = 0.16, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 19h:52m:48s remains)
INFO - root - 2017-12-17 03:20:48.726519: step 6940, loss = 0.15, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 20h:14m:12s remains)
INFO - root - 2017-12-17 03:20:50.940488: step 6950, loss = 0.21, batch loss = 0.16 (35.4 examples/sec; 0.226 sec/batch; 20h:26m:08s remains)
INFO - root - 2017-12-17 03:20:53.160551: step 6960, loss = 0.15, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 20h:53m:53s remains)
INFO - root - 2017-12-17 03:20:55.375402: step 6970, loss = 0.22, batch loss = 0.17 (35.9 examples/sec; 0.223 sec/batch; 20h:08m:31s remains)
INFO - root - 2017-12-17 03:20:57.650777: step 6980, loss = 0.24, batch loss = 0.20 (35.4 examples/sec; 0.226 sec/batch; 20h:24m:54s remains)
INFO - root - 2017-12-17 03:20:59.894811: step 6990, loss = 0.16, batch loss = 0.12 (34.5 examples/sec; 0.232 sec/batch; 20h:58m:41s remains)
INFO - root - 2017-12-17 03:21:02.148044: step 7000, loss = 0.19, batch loss = 0.15 (35.7 examples/sec; 0.224 sec/batch; 20h:16m:26s remains)
INFO - root - 2017-12-17 03:21:04.520371: step 7010, loss = 0.18, batch loss = 0.13 (36.3 examples/sec; 0.221 sec/batch; 19h:57m:07s remains)
INFO - root - 2017-12-17 03:21:06.711788: step 7020, loss = 0.16, batch loss = 0.12 (37.3 examples/sec; 0.214 sec/batch; 19h:22m:28s remains)
INFO - root - 2017-12-17 03:21:08.943960: step 7030, loss = 0.21, batch loss = 0.17 (34.9 examples/sec; 0.229 sec/batch; 20h:42m:24s remains)
INFO - root - 2017-12-17 03:21:11.182851: step 7040, loss = 0.16, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 20h:21m:02s remains)
INFO - root - 2017-12-17 03:21:13.417138: step 7050, loss = 0.18, batch loss = 0.14 (35.0 examples/sec; 0.229 sec/batch; 20h:40m:29s remains)
INFO - root - 2017-12-17 03:21:15.653783: step 7060, loss = 0.18, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 20h:40m:00s remains)
INFO - root - 2017-12-17 03:21:17.856036: step 7070, loss = 0.13, batch loss = 0.08 (35.1 examples/sec; 0.228 sec/batch; 20h:34m:47s remains)
INFO - root - 2017-12-17 03:21:20.054518: step 7080, loss = 0.11, batch loss = 0.07 (36.8 examples/sec; 0.217 sec/batch; 19h:38m:18s remains)
INFO - root - 2017-12-17 03:21:22.286278: step 7090, loss = 0.46, batch loss = 0.41 (36.0 examples/sec; 0.222 sec/batch; 20h:04m:29s remains)
INFO - root - 2017-12-17 03:21:24.485326: step 7100, loss = 0.18, batch loss = 0.13 (36.1 examples/sec; 0.221 sec/batch; 20h:00m:24s remains)
INFO - root - 2017-12-17 03:21:26.800027: step 7110, loss = 0.17, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 20h:46m:31s remains)
INFO - root - 2017-12-17 03:21:29.013478: step 7120, loss = 0.18, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 20h:02m:46s remains)
INFO - root - 2017-12-17 03:21:31.225706: step 7130, loss = 0.15, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 20h:26m:47s remains)
INFO - root - 2017-12-17 03:21:33.423355: step 7140, loss = 0.28, batch loss = 0.23 (36.0 examples/sec; 0.222 sec/batch; 20h:06m:27s remains)
INFO - root - 2017-12-17 03:21:35.605266: step 7150, loss = 0.20, batch loss = 0.15 (36.9 examples/sec; 0.217 sec/batch; 19h:35m:16s remains)
INFO - root - 2017-12-17 03:21:37.848092: step 7160, loss = 0.16, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 20h:24m:21s remains)
INFO - root - 2017-12-17 03:21:40.067984: step 7170, loss = 0.18, batch loss = 0.14 (37.0 examples/sec; 0.216 sec/batch; 19h:31m:51s remains)
INFO - root - 2017-12-17 03:21:42.273493: step 7180, loss = 0.15, batch loss = 0.10 (37.5 examples/sec; 0.213 sec/batch; 19h:16m:47s remains)
INFO - root - 2017-12-17 03:21:44.495234: step 7190, loss = 0.20, batch loss = 0.16 (35.8 examples/sec; 0.224 sec/batch; 20h:12m:43s remains)
INFO - root - 2017-12-17 03:21:46.717628: step 7200, loss = 0.17, batch loss = 0.13 (37.0 examples/sec; 0.216 sec/batch; 19h:33m:13s remains)
INFO - root - 2017-12-17 03:21:49.043935: step 7210, loss = 0.17, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 19h:51m:34s remains)
INFO - root - 2017-12-17 03:21:51.286279: step 7220, loss = 0.13, batch loss = 0.08 (36.1 examples/sec; 0.222 sec/batch; 20h:03m:02s remains)
INFO - root - 2017-12-17 03:21:53.517104: step 7230, loss = 0.15, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 20h:19m:44s remains)
INFO - root - 2017-12-17 03:21:55.727187: step 7240, loss = 0.17, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 20h:07m:59s remains)
INFO - root - 2017-12-17 03:21:57.980333: step 7250, loss = 0.14, batch loss = 0.09 (34.9 examples/sec; 0.229 sec/batch; 20h:41m:06s remains)
INFO - root - 2017-12-17 03:22:00.221078: step 7260, loss = 0.20, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 20h:24m:59s remains)
INFO - root - 2017-12-17 03:22:02.425960: step 7270, loss = 0.16, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 20h:14m:54s remains)
INFO - root - 2017-12-17 03:22:04.595777: step 7280, loss = 0.16, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 19h:40m:59s remains)
INFO - root - 2017-12-17 03:22:06.790585: step 7290, loss = 0.19, batch loss = 0.15 (37.1 examples/sec; 0.216 sec/batch; 19h:30m:11s remains)
INFO - root - 2017-12-17 03:22:09.006431: step 7300, loss = 0.19, batch loss = 0.15 (36.1 examples/sec; 0.222 sec/batch; 20h:01m:17s remains)
INFO - root - 2017-12-17 03:22:11.337718: step 7310, loss = 0.18, batch loss = 0.14 (37.0 examples/sec; 0.216 sec/batch; 19h:31m:03s remains)
INFO - root - 2017-12-17 03:22:13.570816: step 7320, loss = 0.16, batch loss = 0.12 (37.1 examples/sec; 0.216 sec/batch; 19h:28m:48s remains)
INFO - root - 2017-12-17 03:22:15.725926: step 7330, loss = 0.14, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 19h:45m:12s remains)
INFO - root - 2017-12-17 03:22:17.921448: step 7340, loss = 0.13, batch loss = 0.08 (36.3 examples/sec; 0.220 sec/batch; 19h:54m:16s remains)
INFO - root - 2017-12-17 03:22:20.109725: step 7350, loss = 0.19, batch loss = 0.14 (36.9 examples/sec; 0.217 sec/batch; 19h:34m:47s remains)
INFO - root - 2017-12-17 03:22:22.315067: step 7360, loss = 0.16, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 20h:08m:31s remains)
INFO - root - 2017-12-17 03:22:24.510389: step 7370, loss = 0.19, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 20h:31m:35s remains)
INFO - root - 2017-12-17 03:22:26.757007: step 7380, loss = 0.13, batch loss = 0.08 (34.2 examples/sec; 0.234 sec/batch; 21h:08m:41s remains)
INFO - root - 2017-12-17 03:22:28.979988: step 7390, loss = 0.20, batch loss = 0.15 (35.0 examples/sec; 0.229 sec/batch; 20h:40m:07s remains)
INFO - root - 2017-12-17 03:22:31.203297: step 7400, loss = 0.27, batch loss = 0.22 (35.2 examples/sec; 0.227 sec/batch; 20h:31m:42s remains)
INFO - root - 2017-12-17 03:22:33.536028: step 7410, loss = 0.20, batch loss = 0.16 (36.4 examples/sec; 0.220 sec/batch; 19h:50m:42s remains)
INFO - root - 2017-12-17 03:22:35.739805: step 7420, loss = 0.17, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 20h:52m:41s remains)
INFO - root - 2017-12-17 03:22:37.943168: step 7430, loss = 0.15, batch loss = 0.11 (36.8 examples/sec; 0.218 sec/batch; 19h:39m:03s remains)
INFO - root - 2017-12-17 03:22:40.173796: step 7440, loss = 0.16, batch loss = 0.11 (36.6 examples/sec; 0.219 sec/batch; 19h:45m:09s remains)
INFO - root - 2017-12-17 03:22:42.370259: step 7450, loss = 0.18, batch loss = 0.14 (37.0 examples/sec; 0.216 sec/batch; 19h:32m:19s remains)
INFO - root - 2017-12-17 03:22:44.572979: step 7460, loss = 0.15, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 20h:16m:18s remains)
INFO - root - 2017-12-17 03:22:46.777657: step 7470, loss = 0.11, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 20h:13m:18s remains)
INFO - root - 2017-12-17 03:22:48.998713: step 7480, loss = 0.13, batch loss = 0.09 (35.8 examples/sec; 0.224 sec/batch; 20h:11m:23s remains)
INFO - root - 2017-12-17 03:22:51.218259: step 7490, loss = 0.18, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 19h:46m:44s remains)
INFO - root - 2017-12-17 03:22:53.441898: step 7500, loss = 0.13, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 20h:03m:04s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-7500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-7500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 03:22:56.312841: step 7510, loss = 0.16, batch loss = 0.12 (34.3 examples/sec; 0.233 sec/batch; 21h:03m:34s remains)
INFO - root - 2017-12-17 03:22:58.528301: step 7520, loss = 0.16, batch loss = 0.11 (36.9 examples/sec; 0.217 sec/batch; 19h:35m:05s remains)
INFO - root - 2017-12-17 03:23:00.731559: step 7530, loss = 0.18, batch loss = 0.13 (36.9 examples/sec; 0.217 sec/batch; 19h:32m:49s remains)
INFO - root - 2017-12-17 03:23:02.916242: step 7540, loss = 0.20, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 19h:57m:58s remains)
INFO - root - 2017-12-17 03:23:05.151571: step 7550, loss = 0.18, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 19h:46m:18s remains)
INFO - root - 2017-12-17 03:23:07.411742: step 7560, loss = 0.16, batch loss = 0.11 (35.8 examples/sec; 0.223 sec/batch; 20h:08m:35s remains)
INFO - root - 2017-12-17 03:23:09.692630: step 7570, loss = 0.17, batch loss = 0.12 (31.0 examples/sec; 0.258 sec/batch; 23h:18m:20s remains)
INFO - root - 2017-12-17 03:23:11.906594: step 7580, loss = 0.21, batch loss = 0.16 (36.0 examples/sec; 0.222 sec/batch; 20h:04m:52s remains)
INFO - root - 2017-12-17 03:23:14.978728: step 7590, loss = 0.18, batch loss = 0.13 (22.4 examples/sec; 0.357 sec/batch; 32h:14m:05s remains)
INFO - root - 2017-12-17 03:23:18.647628: step 7600, loss = 0.15, batch loss = 0.10 (21.8 examples/sec; 0.366 sec/batch; 33h:03m:38s remains)
INFO - root - 2017-12-17 03:23:22.491827: step 7610, loss = 0.18, batch loss = 0.13 (21.7 examples/sec; 0.368 sec/batch; 33h:14m:34s remains)
INFO - root - 2017-12-17 03:23:26.186739: step 7620, loss = 0.13, batch loss = 0.09 (21.1 examples/sec; 0.379 sec/batch; 34h:10m:46s remains)
INFO - root - 2017-12-17 03:23:29.911180: step 7630, loss = 0.16, batch loss = 0.11 (21.9 examples/sec; 0.365 sec/batch; 32h:57m:16s remains)
INFO - root - 2017-12-17 03:23:33.615700: step 7640, loss = 0.14, batch loss = 0.10 (21.0 examples/sec; 0.381 sec/batch; 34h:22m:08s remains)
INFO - root - 2017-12-17 03:23:37.284309: step 7650, loss = 0.14, batch loss = 0.09 (22.0 examples/sec; 0.364 sec/batch; 32h:49m:09s remains)
INFO - root - 2017-12-17 03:23:40.976288: step 7660, loss = 0.17, batch loss = 0.13 (21.9 examples/sec; 0.366 sec/batch; 33h:00m:18s remains)
INFO - root - 2017-12-17 03:23:44.665559: step 7670, loss = 0.14, batch loss = 0.10 (22.6 examples/sec; 0.354 sec/batch; 31h:56m:34s remains)
INFO - root - 2017-12-17 03:23:48.328898: step 7680, loss = 0.18, batch loss = 0.14 (21.8 examples/sec; 0.366 sec/batch; 33h:03m:55s remains)
INFO - root - 2017-12-17 03:23:51.880457: step 7690, loss = 0.17, batch loss = 0.12 (22.2 examples/sec; 0.360 sec/batch; 32h:27m:37s remains)
INFO - root - 2017-12-17 03:23:55.439538: step 7700, loss = 0.19, batch loss = 0.15 (22.3 examples/sec; 0.359 sec/batch; 32h:23m:50s remains)
INFO - root - 2017-12-17 03:23:59.207044: step 7710, loss = 0.16, batch loss = 0.12 (23.1 examples/sec; 0.347 sec/batch; 31h:16m:02s remains)
INFO - root - 2017-12-17 03:24:02.781857: step 7720, loss = 0.23, batch loss = 0.19 (23.5 examples/sec; 0.341 sec/batch; 30h:43m:46s remains)
INFO - root - 2017-12-17 03:24:06.373444: step 7730, loss = 0.17, batch loss = 0.13 (22.5 examples/sec; 0.356 sec/batch; 32h:07m:09s remains)
INFO - root - 2017-12-17 03:24:09.895786: step 7740, loss = 0.17, batch loss = 0.13 (21.2 examples/sec; 0.377 sec/batch; 34h:02m:07s remains)
INFO - root - 2017-12-17 03:24:13.547583: step 7750, loss = 0.22, batch loss = 0.18 (21.8 examples/sec; 0.366 sec/batch; 33h:02m:41s remains)
INFO - root - 2017-12-17 03:24:17.131103: step 7760, loss = 0.13, batch loss = 0.09 (22.4 examples/sec; 0.358 sec/batch; 32h:16m:30s remains)
INFO - root - 2017-12-17 03:24:20.779916: step 7770, loss = 0.13, batch loss = 0.09 (21.4 examples/sec; 0.373 sec/batch; 33h:39m:49s remains)
INFO - root - 2017-12-17 03:24:24.347580: step 7780, loss = 0.15, batch loss = 0.11 (21.3 examples/sec; 0.376 sec/batch; 33h:54m:54s remains)
INFO - root - 2017-12-17 03:24:27.941208: step 7790, loss = 0.12, batch loss = 0.07 (22.8 examples/sec; 0.351 sec/batch; 31h:41m:26s remains)
INFO - root - 2017-12-17 03:24:31.531090: step 7800, loss = 0.15, batch loss = 0.10 (23.4 examples/sec; 0.342 sec/batch; 30h:50m:56s remains)
INFO - root - 2017-12-17 03:24:35.347950: step 7810, loss = 0.13, batch loss = 0.09 (22.5 examples/sec; 0.355 sec/batch; 32h:01m:46s remains)
INFO - root - 2017-12-17 03:24:38.697854: step 7820, loss = 0.14, batch loss = 0.10 (28.0 examples/sec; 0.286 sec/batch; 25h:45m:57s remains)
INFO - root - 2017-12-17 03:24:41.809379: step 7830, loss = 0.16, batch loss = 0.11 (24.1 examples/sec; 0.331 sec/batch; 29h:52m:52s remains)
INFO - root - 2017-12-17 03:24:45.392763: step 7840, loss = 0.17, batch loss = 0.13 (21.9 examples/sec; 0.365 sec/batch; 32h:57m:18s remains)
INFO - root - 2017-12-17 03:24:49.057212: step 7850, loss = 0.13, batch loss = 0.09 (21.8 examples/sec; 0.367 sec/batch; 33h:03m:49s remains)
INFO - root - 2017-12-17 03:24:52.744698: step 7860, loss = 0.13, batch loss = 0.08 (21.8 examples/sec; 0.367 sec/batch; 33h:05m:38s remains)
INFO - root - 2017-12-17 03:24:56.526779: step 7870, loss = 0.17, batch loss = 0.13 (20.7 examples/sec; 0.386 sec/batch; 34h:51m:03s remains)
INFO - root - 2017-12-17 03:25:00.273654: step 7880, loss = 0.20, batch loss = 0.15 (21.7 examples/sec; 0.369 sec/batch; 33h:17m:36s remains)
INFO - root - 2017-12-17 03:25:03.985721: step 7890, loss = 0.13, batch loss = 0.09 (21.5 examples/sec; 0.373 sec/batch; 33h:37m:41s remains)
INFO - root - 2017-12-17 03:25:07.729373: step 7900, loss = 0.16, batch loss = 0.12 (21.5 examples/sec; 0.373 sec/batch; 33h:36m:16s remains)
INFO - root - 2017-12-17 03:25:11.560753: step 7910, loss = 0.16, batch loss = 0.12 (27.4 examples/sec; 0.292 sec/batch; 26h:22m:01s remains)
INFO - root - 2017-12-17 03:25:15.267422: step 7920, loss = 0.24, batch loss = 0.20 (21.5 examples/sec; 0.371 sec/batch; 33h:28m:26s remains)
INFO - root - 2017-12-17 03:25:19.070316: step 7930, loss = 0.18, batch loss = 0.13 (21.1 examples/sec; 0.380 sec/batch; 34h:13m:49s remains)
INFO - root - 2017-12-17 03:25:22.920096: step 7940, loss = 0.15, batch loss = 0.11 (22.1 examples/sec; 0.363 sec/batch; 32h:41m:51s remains)
INFO - root - 2017-12-17 03:25:26.659193: step 7950, loss = 0.15, batch loss = 0.11 (21.8 examples/sec; 0.368 sec/batch; 33h:08m:00s remains)
INFO - root - 2017-12-17 03:25:30.394446: step 7960, loss = 0.14, batch loss = 0.10 (20.5 examples/sec; 0.391 sec/batch; 35h:13m:09s remains)
INFO - root - 2017-12-17 03:25:33.447293: step 7970, loss = 0.35, batch loss = 0.30 (31.1 examples/sec; 0.258 sec/batch; 23h:13m:24s remains)
INFO - root - 2017-12-17 03:25:36.656836: step 7980, loss = 0.18, batch loss = 0.14 (21.7 examples/sec; 0.368 sec/batch; 33h:10m:11s remains)
INFO - root - 2017-12-17 03:25:40.446881: step 7990, loss = 0.15, batch loss = 0.11 (20.5 examples/sec; 0.389 sec/batch; 35h:06m:23s remains)
INFO - root - 2017-12-17 03:25:44.229867: step 8000, loss = 0.20, batch loss = 0.16 (21.8 examples/sec; 0.367 sec/batch; 33h:04m:47s remains)
INFO - root - 2017-12-17 03:25:48.065860: step 8010, loss = 0.18, batch loss = 0.14 (21.1 examples/sec; 0.379 sec/batch; 34h:09m:40s remains)
INFO - root - 2017-12-17 03:25:51.835381: step 8020, loss = 0.14, batch loss = 0.10 (20.7 examples/sec; 0.386 sec/batch; 34h:47m:02s remains)
INFO - root - 2017-12-17 03:25:55.553352: step 8030, loss = 0.16, batch loss = 0.12 (21.9 examples/sec; 0.366 sec/batch; 32h:59m:24s remains)
INFO - root - 2017-12-17 03:25:59.320344: step 8040, loss = 0.15, batch loss = 0.11 (21.1 examples/sec; 0.380 sec/batch; 34h:13m:23s remains)
INFO - root - 2017-12-17 03:26:02.950022: step 8050, loss = 0.28, batch loss = 0.24 (21.1 examples/sec; 0.379 sec/batch; 34h:11m:46s remains)
INFO - root - 2017-12-17 03:26:06.588179: step 8060, loss = 0.18, batch loss = 0.14 (21.5 examples/sec; 0.372 sec/batch; 33h:29m:08s remains)
INFO - root - 2017-12-17 03:26:10.356900: step 8070, loss = 0.11, batch loss = 0.07 (21.5 examples/sec; 0.373 sec/batch; 33h:36m:28s remains)
INFO - root - 2017-12-17 03:26:13.709236: step 8080, loss = 0.15, batch loss = 0.11 (26.3 examples/sec; 0.305 sec/batch; 27h:26m:49s remains)
INFO - root - 2017-12-17 03:26:16.890856: step 8090, loss = 0.25, batch loss = 0.20 (22.4 examples/sec; 0.357 sec/batch; 32h:10m:03s remains)
INFO - root - 2017-12-17 03:26:20.424830: step 8100, loss = 0.15, batch loss = 0.10 (21.0 examples/sec; 0.380 sec/batch; 34h:15m:25s remains)
INFO - root - 2017-12-17 03:26:24.384168: step 8110, loss = 0.15, batch loss = 0.11 (20.6 examples/sec; 0.388 sec/batch; 35h:00m:01s remains)
INFO - root - 2017-12-17 03:26:28.178180: step 8120, loss = 0.14, batch loss = 0.10 (21.2 examples/sec; 0.378 sec/batch; 34h:03m:11s remains)
INFO - root - 2017-12-17 03:26:31.931735: step 8130, loss = 0.17, batch loss = 0.12 (21.9 examples/sec; 0.366 sec/batch; 32h:57m:31s remains)
INFO - root - 2017-12-17 03:26:35.664730: step 8140, loss = 0.14, batch loss = 0.10 (21.8 examples/sec; 0.367 sec/batch; 33h:02m:33s remains)
INFO - root - 2017-12-17 03:26:39.065870: step 8150, loss = 0.18, batch loss = 0.14 (22.8 examples/sec; 0.351 sec/batch; 31h:39m:58s remains)
INFO - root - 2017-12-17 03:26:42.731051: step 8160, loss = 0.13, batch loss = 0.09 (21.4 examples/sec; 0.373 sec/batch; 33h:36m:48s remains)
INFO - root - 2017-12-17 03:26:46.484072: step 8170, loss = 0.15, batch loss = 0.11 (20.5 examples/sec; 0.390 sec/batch; 35h:09m:49s remains)
INFO - root - 2017-12-17 03:26:50.304211: step 8180, loss = 0.16, batch loss = 0.12 (20.8 examples/sec; 0.385 sec/batch; 34h:40m:11s remains)
INFO - root - 2017-12-17 03:26:54.118912: step 8190, loss = 0.15, batch loss = 0.11 (20.8 examples/sec; 0.385 sec/batch; 34h:43m:09s remains)
INFO - root - 2017-12-17 03:26:57.875833: step 8200, loss = 0.15, batch loss = 0.11 (22.3 examples/sec; 0.359 sec/batch; 32h:20m:56s remains)
INFO - root - 2017-12-17 03:27:01.716974: step 8210, loss = 0.15, batch loss = 0.11 (22.6 examples/sec; 0.353 sec/batch; 31h:50m:04s remains)
INFO - root - 2017-12-17 03:27:05.398851: step 8220, loss = 0.15, batch loss = 0.11 (21.4 examples/sec; 0.373 sec/batch; 33h:37m:25s remains)
INFO - root - 2017-12-17 03:27:09.068312: step 8230, loss = 0.18, batch loss = 0.14 (21.4 examples/sec; 0.374 sec/batch; 33h:42m:43s remains)
INFO - root - 2017-12-17 03:27:12.703489: step 8240, loss = 0.15, batch loss = 0.11 (21.5 examples/sec; 0.372 sec/batch; 33h:29m:57s remains)
INFO - root - 2017-12-17 03:27:16.358561: step 8250, loss = 0.23, batch loss = 0.18 (22.8 examples/sec; 0.351 sec/batch; 31h:36m:31s remains)
INFO - root - 2017-12-17 03:27:20.007031: step 8260, loss = 0.14, batch loss = 0.09 (26.5 examples/sec; 0.302 sec/batch; 27h:09m:52s remains)
INFO - root - 2017-12-17 03:27:23.144282: step 8270, loss = 0.16, batch loss = 0.12 (24.8 examples/sec; 0.322 sec/batch; 29h:00m:51s remains)
INFO - root - 2017-12-17 03:27:26.743484: step 8280, loss = 0.14, batch loss = 0.09 (21.9 examples/sec; 0.366 sec/batch; 32h:55m:43s remains)
INFO - root - 2017-12-17 03:27:30.409120: step 8290, loss = 0.21, batch loss = 0.17 (20.7 examples/sec; 0.386 sec/batch; 34h:43m:38s remains)
INFO - root - 2017-12-17 03:27:34.212749: step 8300, loss = 0.17, batch loss = 0.13 (20.5 examples/sec; 0.391 sec/batch; 35h:12m:21s remains)
INFO - root - 2017-12-17 03:27:38.162371: step 8310, loss = 0.13, batch loss = 0.09 (21.6 examples/sec; 0.370 sec/batch; 33h:21m:08s remains)
INFO - root - 2017-12-17 03:27:41.659820: step 8320, loss = 0.19, batch loss = 0.15 (22.2 examples/sec; 0.360 sec/batch; 32h:25m:51s remains)
INFO - root - 2017-12-17 03:27:45.354216: step 8330, loss = 0.13, batch loss = 0.09 (20.8 examples/sec; 0.385 sec/batch; 34h:42m:07s remains)
INFO - root - 2017-12-17 03:27:49.094588: step 8340, loss = 0.16, batch loss = 0.12 (21.0 examples/sec; 0.381 sec/batch; 34h:19m:04s remains)
INFO - root - 2017-12-17 03:27:52.889080: step 8350, loss = 0.13, batch loss = 0.09 (20.7 examples/sec; 0.387 sec/batch; 34h:49m:33s remains)
INFO - root - 2017-12-17 03:27:56.711136: step 8360, loss = 0.15, batch loss = 0.11 (21.3 examples/sec; 0.376 sec/batch; 33h:53m:42s remains)
INFO - root - 2017-12-17 03:28:00.334386: step 8370, loss = 0.14, batch loss = 0.09 (21.0 examples/sec; 0.380 sec/batch; 34h:14m:18s remains)
INFO - root - 2017-12-17 03:28:04.134481: step 8380, loss = 0.16, batch loss = 0.11 (21.4 examples/sec; 0.375 sec/batch; 33h:43m:07s remains)
INFO - root - 2017-12-17 03:28:07.894799: step 8390, loss = 0.17, batch loss = 0.13 (20.5 examples/sec; 0.389 sec/batch; 35h:03m:06s remains)
INFO - root - 2017-12-17 03:28:11.686762: step 8400, loss = 0.13, batch loss = 0.09 (20.6 examples/sec; 0.388 sec/batch; 34h:53m:57s remains)
INFO - root - 2017-12-17 03:28:15.646885: step 8410, loss = 0.16, batch loss = 0.11 (20.3 examples/sec; 0.394 sec/batch; 35h:28m:48s remains)
INFO - root - 2017-12-17 03:28:19.328554: step 8420, loss = 0.14, batch loss = 0.10 (22.5 examples/sec; 0.355 sec/batch; 31h:57m:05s remains)
INFO - root - 2017-12-17 03:28:23.111741: step 8430, loss = 0.16, batch loss = 0.11 (21.0 examples/sec; 0.381 sec/batch; 34h:16m:05s remains)
INFO - root - 2017-12-17 03:28:26.845311: step 8440, loss = 0.14, batch loss = 0.10 (21.4 examples/sec; 0.373 sec/batch; 33h:35m:33s remains)
INFO - root - 2017-12-17 03:28:29.798440: step 8450, loss = 0.17, batch loss = 0.13 (25.9 examples/sec; 0.308 sec/batch; 27h:45m:54s remains)
INFO - root - 2017-12-17 03:28:32.771738: step 8460, loss = 0.11, batch loss = 0.07 (25.7 examples/sec; 0.312 sec/batch; 28h:02m:48s remains)
INFO - root - 2017-12-17 03:28:35.798356: step 8470, loss = 0.34, batch loss = 0.30 (29.2 examples/sec; 0.274 sec/batch; 24h:39m:11s remains)
INFO - root - 2017-12-17 03:28:38.723770: step 8480, loss = 0.14, batch loss = 0.10 (30.2 examples/sec; 0.265 sec/batch; 23h:48m:26s remains)
INFO - root - 2017-12-17 03:28:41.910683: step 8490, loss = 0.20, batch loss = 0.16 (27.8 examples/sec; 0.287 sec/batch; 25h:51m:34s remains)
INFO - root - 2017-12-17 03:28:44.988883: step 8500, loss = 0.22, batch loss = 0.18 (30.4 examples/sec; 0.263 sec/batch; 23h:41m:19s remains)
INFO - root - 2017-12-17 03:28:48.220654: step 8510, loss = 0.17, batch loss = 0.13 (24.8 examples/sec; 0.323 sec/batch; 29h:01m:40s remains)
INFO - root - 2017-12-17 03:28:51.431941: step 8520, loss = 0.16, batch loss = 0.12 (25.2 examples/sec; 0.317 sec/batch; 28h:34m:17s remains)
INFO - root - 2017-12-17 03:28:54.702960: step 8530, loss = 0.16, batch loss = 0.12 (23.4 examples/sec; 0.342 sec/batch; 30h:49m:04s remains)
INFO - root - 2017-12-17 03:28:58.319861: step 8540, loss = 0.16, batch loss = 0.12 (22.3 examples/sec; 0.358 sec/batch; 32h:13m:17s remains)
INFO - root - 2017-12-17 03:29:01.867694: step 8550, loss = 0.15, batch loss = 0.11 (23.5 examples/sec; 0.340 sec/batch; 30h:35m:35s remains)
INFO - root - 2017-12-17 03:29:05.513681: step 8560, loss = 0.15, batch loss = 0.11 (26.4 examples/sec; 0.303 sec/batch; 27h:15m:19s remains)
INFO - root - 2017-12-17 03:29:09.298192: step 8570, loss = 0.17, batch loss = 0.13 (21.3 examples/sec; 0.375 sec/batch; 33h:45m:47s remains)
INFO - root - 2017-12-17 03:29:13.025778: step 8580, loss = 0.15, batch loss = 0.11 (20.9 examples/sec; 0.383 sec/batch; 34h:27m:28s remains)
INFO - root - 2017-12-17 03:29:16.773868: step 8590, loss = 0.16, batch loss = 0.12 (20.4 examples/sec; 0.393 sec/batch; 35h:20m:02s remains)
INFO - root - 2017-12-17 03:29:20.540540: step 8600, loss = 0.14, batch loss = 0.10 (21.6 examples/sec; 0.371 sec/batch; 33h:23m:51s remains)
INFO - root - 2017-12-17 03:29:24.459277: step 8610, loss = 0.14, batch loss = 0.10 (21.3 examples/sec; 0.376 sec/batch; 33h:47m:03s remains)
INFO - root - 2017-12-17 03:29:28.212872: step 8620, loss = 0.12, batch loss = 0.08 (23.7 examples/sec; 0.338 sec/batch; 30h:22m:34s remains)
INFO - root - 2017-12-17 03:29:32.006448: step 8630, loss = 0.14, batch loss = 0.10 (20.9 examples/sec; 0.383 sec/batch; 34h:29m:30s remains)
INFO - root - 2017-12-17 03:29:35.760433: step 8640, loss = 0.16, batch loss = 0.12 (20.8 examples/sec; 0.384 sec/batch; 34h:32m:21s remains)
INFO - root - 2017-12-17 03:29:39.573583: step 8650, loss = 0.12, batch loss = 0.08 (20.4 examples/sec; 0.392 sec/batch; 35h:18m:00s remains)
INFO - root - 2017-12-17 03:29:43.298969: step 8660, loss = 0.27, batch loss = 0.23 (20.8 examples/sec; 0.384 sec/batch; 34h:35m:12s remains)
INFO - root - 2017-12-17 03:29:47.013970: step 8670, loss = 0.13, batch loss = 0.09 (21.4 examples/sec; 0.374 sec/batch; 33h:40m:17s remains)
INFO - root - 2017-12-17 03:29:50.802245: step 8680, loss = 0.24, batch loss = 0.20 (20.4 examples/sec; 0.393 sec/batch; 35h:21m:19s remains)
INFO - root - 2017-12-17 03:29:54.509362: step 8690, loss = 0.14, batch loss = 0.10 (21.2 examples/sec; 0.378 sec/batch; 34h:00m:36s remains)
INFO - root - 2017-12-17 03:29:58.278919: step 8700, loss = 0.15, batch loss = 0.11 (21.4 examples/sec; 0.374 sec/batch; 33h:40m:15s remains)
INFO - root - 2017-12-17 03:30:02.295886: step 8710, loss = 0.21, batch loss = 0.17 (22.3 examples/sec; 0.359 sec/batch; 32h:17m:37s remains)
INFO - root - 2017-12-17 03:30:06.091955: step 8720, loss = 0.20, batch loss = 0.16 (21.1 examples/sec; 0.379 sec/batch; 34h:05m:44s remains)
INFO - root - 2017-12-17 03:30:09.806007: step 8730, loss = 0.12, batch loss = 0.08 (21.7 examples/sec; 0.369 sec/batch; 33h:11m:25s remains)
INFO - root - 2017-12-17 03:30:13.584111: step 8740, loss = 0.14, batch loss = 0.10 (21.3 examples/sec; 0.375 sec/batch; 33h:44m:41s remains)
INFO - root - 2017-12-17 03:30:17.373999: step 8750, loss = 0.19, batch loss = 0.15 (21.3 examples/sec; 0.375 sec/batch; 33h:45m:22s remains)
INFO - root - 2017-12-17 03:30:21.104940: step 8760, loss = 0.16, batch loss = 0.12 (21.2 examples/sec; 0.377 sec/batch; 33h:55m:26s remains)
INFO - root - 2017-12-17 03:30:24.805494: step 8770, loss = 0.14, batch loss = 0.10 (21.2 examples/sec; 0.378 sec/batch; 34h:00m:39s remains)
INFO - root - 2017-12-17 03:30:28.595845: step 8780, loss = 0.15, batch loss = 0.11 (21.4 examples/sec; 0.374 sec/batch; 33h:35m:23s remains)
INFO - root - 2017-12-17 03:30:32.401954: step 8790, loss = 0.18, batch loss = 0.14 (20.9 examples/sec; 0.382 sec/batch; 34h:21m:24s remains)
INFO - root - 2017-12-17 03:30:36.217653: step 8800, loss = 0.14, batch loss = 0.10 (21.4 examples/sec; 0.374 sec/batch; 33h:35m:24s remains)
INFO - root - 2017-12-17 03:30:40.137640: step 8810, loss = 0.18, batch loss = 0.13 (22.0 examples/sec; 0.364 sec/batch; 32h:45m:08s remains)
INFO - root - 2017-12-17 03:30:43.854629: step 8820, loss = 0.15, batch loss = 0.11 (21.1 examples/sec; 0.380 sec/batch; 34h:07m:51s remains)
INFO - root - 2017-12-17 03:30:47.566739: step 8830, loss = 0.15, batch loss = 0.11 (21.4 examples/sec; 0.375 sec/batch; 33h:40m:48s remains)
INFO - root - 2017-12-17 03:30:51.309380: step 8840, loss = 0.16, batch loss = 0.12 (22.2 examples/sec; 0.360 sec/batch; 32h:21m:50s remains)
INFO - root - 2017-12-17 03:30:55.088329: step 8850, loss = 0.11, batch loss = 0.07 (20.3 examples/sec; 0.394 sec/batch; 35h:25m:20s remains)
INFO - root - 2017-12-17 03:30:58.900003: step 8860, loss = 0.14, batch loss = 0.10 (20.7 examples/sec; 0.386 sec/batch; 34h:41m:26s remains)
INFO - root - 2017-12-17 03:31:02.724461: step 8870, loss = 0.14, batch loss = 0.10 (20.9 examples/sec; 0.382 sec/batch; 34h:22m:07s remains)
INFO - root - 2017-12-17 03:31:06.503552: step 8880, loss = 0.12, batch loss = 0.08 (20.6 examples/sec; 0.388 sec/batch; 34h:53m:12s remains)
INFO - root - 2017-12-17 03:31:10.220058: step 8890, loss = 0.13, batch loss = 0.09 (21.3 examples/sec; 0.376 sec/batch; 33h:48m:32s remains)
INFO - root - 2017-12-17 03:31:13.919173: step 8900, loss = 0.17, batch loss = 0.13 (20.9 examples/sec; 0.383 sec/batch; 34h:25m:56s remains)
INFO - root - 2017-12-17 03:31:17.914179: step 8910, loss = 0.12, batch loss = 0.08 (21.0 examples/sec; 0.381 sec/batch; 34h:12m:15s remains)
INFO - root - 2017-12-17 03:31:21.653580: step 8920, loss = 0.19, batch loss = 0.15 (21.8 examples/sec; 0.367 sec/batch; 33h:00m:48s remains)
INFO - root - 2017-12-17 03:31:25.444233: step 8930, loss = 0.18, batch loss = 0.14 (20.9 examples/sec; 0.382 sec/batch; 34h:22m:41s remains)
INFO - root - 2017-12-17 03:31:29.125909: step 8940, loss = 0.16, batch loss = 0.12 (21.9 examples/sec; 0.365 sec/batch; 32h:48m:36s remains)
INFO - root - 2017-12-17 03:31:32.868825: step 8950, loss = 0.19, batch loss = 0.15 (20.8 examples/sec; 0.384 sec/batch; 34h:30m:10s remains)
INFO - root - 2017-12-17 03:31:36.662862: step 8960, loss = 0.18, batch loss = 0.14 (21.7 examples/sec; 0.368 sec/batch; 33h:03m:28s remains)
INFO - root - 2017-12-17 03:31:40.426851: step 8970, loss = 0.14, batch loss = 0.10 (22.7 examples/sec; 0.353 sec/batch; 31h:40m:55s remains)
INFO - root - 2017-12-17 03:31:44.178402: step 8980, loss = 0.19, batch loss = 0.15 (21.7 examples/sec; 0.369 sec/batch; 33h:09m:35s remains)
INFO - root - 2017-12-17 03:31:47.706998: step 8990, loss = 0.11, batch loss = 0.07 (22.3 examples/sec; 0.359 sec/batch; 32h:13m:28s remains)
INFO - root - 2017-12-17 03:31:51.441210: step 9000, loss = 0.14, batch loss = 0.10 (22.8 examples/sec; 0.351 sec/batch; 31h:34m:24s remains)
INFO - root - 2017-12-17 03:31:55.383228: step 9010, loss = 0.13, batch loss = 0.09 (21.4 examples/sec; 0.374 sec/batch; 33h:37m:40s remains)
INFO - root - 2017-12-17 03:31:59.018953: step 9020, loss = 0.14, batch loss = 0.10 (21.9 examples/sec; 0.366 sec/batch; 32h:52m:04s remains)
INFO - root - 2017-12-17 03:32:02.616367: step 9030, loss = 0.11, batch loss = 0.07 (22.8 examples/sec; 0.350 sec/batch; 31h:28m:19s remains)
INFO - root - 2017-12-17 03:32:06.097067: step 9040, loss = 0.14, batch loss = 0.10 (24.6 examples/sec; 0.325 sec/batch; 29h:13m:48s remains)
INFO - root - 2017-12-17 03:32:09.775180: step 9050, loss = 0.12, batch loss = 0.08 (21.3 examples/sec; 0.375 sec/batch; 33h:40m:10s remains)
INFO - root - 2017-12-17 03:32:13.386835: step 9060, loss = 0.15, batch loss = 0.11 (20.4 examples/sec; 0.392 sec/batch; 35h:15m:24s remains)
INFO - root - 2017-12-17 03:32:17.116308: step 9070, loss = 0.14, batch loss = 0.10 (21.6 examples/sec; 0.371 sec/batch; 33h:20m:58s remains)
INFO - root - 2017-12-17 03:32:20.797322: step 9080, loss = 0.15, batch loss = 0.11 (22.3 examples/sec; 0.358 sec/batch; 32h:12m:07s remains)
INFO - root - 2017-12-17 03:32:24.497528: step 9090, loss = 0.15, batch loss = 0.11 (21.0 examples/sec; 0.381 sec/batch; 34h:11m:52s remains)
INFO - root - 2017-12-17 03:32:28.175352: step 9100, loss = 0.12, batch loss = 0.08 (21.8 examples/sec; 0.366 sec/batch; 32h:54m:21s remains)
INFO - root - 2017-12-17 03:32:32.040846: step 9110, loss = 0.15, batch loss = 0.11 (21.8 examples/sec; 0.368 sec/batch; 33h:00m:58s remains)
INFO - root - 2017-12-17 03:32:35.747026: step 9120, loss = 0.13, batch loss = 0.09 (22.0 examples/sec; 0.364 sec/batch; 32h:39m:15s remains)
INFO - root - 2017-12-17 03:32:39.491147: step 9130, loss = 0.16, batch loss = 0.12 (20.9 examples/sec; 0.383 sec/batch; 34h:25m:54s remains)
INFO - root - 2017-12-17 03:32:43.084313: step 9140, loss = 0.18, batch loss = 0.14 (26.2 examples/sec; 0.306 sec/batch; 27h:27m:41s remains)
INFO - root - 2017-12-17 03:32:46.777307: step 9150, loss = 0.13, batch loss = 0.09 (22.5 examples/sec; 0.355 sec/batch; 31h:52m:08s remains)
INFO - root - 2017-12-17 03:32:50.553868: step 9160, loss = 0.12, batch loss = 0.08 (22.0 examples/sec; 0.363 sec/batch; 32h:35m:57s remains)
INFO - root - 2017-12-17 03:32:54.256597: step 9170, loss = 0.16, batch loss = 0.12 (20.8 examples/sec; 0.385 sec/batch; 34h:35m:51s remains)
INFO - root - 2017-12-17 03:32:58.010147: step 9180, loss = 0.26, batch loss = 0.22 (19.8 examples/sec; 0.404 sec/batch; 36h:17m:40s remains)
INFO - root - 2017-12-17 03:33:01.701630: step 9190, loss = 0.17, batch loss = 0.13 (23.4 examples/sec; 0.341 sec/batch; 30h:38m:28s remains)
INFO - root - 2017-12-17 03:33:05.492268: step 9200, loss = 0.17, batch loss = 0.13 (21.2 examples/sec; 0.377 sec/batch; 33h:49m:12s remains)
INFO - root - 2017-12-17 03:33:09.382370: step 9210, loss = 0.16, batch loss = 0.12 (21.7 examples/sec; 0.368 sec/batch; 33h:04m:23s remains)
INFO - root - 2017-12-17 03:33:13.131550: step 9220, loss = 0.25, batch loss = 0.21 (20.9 examples/sec; 0.382 sec/batch; 34h:19m:57s remains)
INFO - root - 2017-12-17 03:33:16.758217: step 9230, loss = 0.18, batch loss = 0.14 (22.2 examples/sec; 0.360 sec/batch; 32h:20m:59s remains)
INFO - root - 2017-12-17 03:33:20.457644: step 9240, loss = 0.17, batch loss = 0.13 (21.6 examples/sec; 0.370 sec/batch; 33h:15m:11s remains)
INFO - root - 2017-12-17 03:33:24.185823: step 9250, loss = 0.16, batch loss = 0.12 (21.8 examples/sec; 0.366 sec/batch; 32h:52m:48s remains)
INFO - root - 2017-12-17 03:33:27.783343: step 9260, loss = 0.14, batch loss = 0.10 (21.8 examples/sec; 0.367 sec/batch; 32h:55m:18s remains)
INFO - root - 2017-12-17 03:33:31.465882: step 9270, loss = 0.13, batch loss = 0.09 (21.6 examples/sec; 0.370 sec/batch; 33h:14m:03s remains)
INFO - root - 2017-12-17 03:33:35.225254: step 9280, loss = 0.20, batch loss = 0.16 (20.8 examples/sec; 0.385 sec/batch; 34h:33m:22s remains)
INFO - root - 2017-12-17 03:33:39.067114: step 9290, loss = 0.15, batch loss = 0.11 (21.3 examples/sec; 0.375 sec/batch; 33h:38m:43s remains)
INFO - root - 2017-12-17 03:33:42.844409: step 9300, loss = 0.16, batch loss = 0.12 (20.9 examples/sec; 0.382 sec/batch; 34h:20m:02s remains)
INFO - root - 2017-12-17 03:33:46.762865: step 9310, loss = 0.18, batch loss = 0.14 (22.1 examples/sec; 0.361 sec/batch; 32h:26m:42s remains)
INFO - root - 2017-12-17 03:33:50.588139: step 9320, loss = 0.14, batch loss = 0.10 (21.3 examples/sec; 0.376 sec/batch; 33h:43m:49s remains)
INFO - root - 2017-12-17 03:33:54.248225: step 9330, loss = 0.16, batch loss = 0.12 (21.4 examples/sec; 0.374 sec/batch; 33h:36m:28s remains)
INFO - root - 2017-12-17 03:33:57.999768: step 9340, loss = 0.14, batch loss = 0.10 (20.6 examples/sec; 0.388 sec/batch; 34h:51m:42s remains)
INFO - root - 2017-12-17 03:34:01.653599: step 9350, loss = 0.19, batch loss = 0.16 (21.5 examples/sec; 0.372 sec/batch; 33h:24m:22s remains)
INFO - root - 2017-12-17 03:34:05.310694: step 9360, loss = 0.17, batch loss = 0.13 (23.1 examples/sec; 0.347 sec/batch; 31h:08m:38s remains)
INFO - root - 2017-12-17 03:34:08.984070: step 9370, loss = 0.13, batch loss = 0.09 (21.8 examples/sec; 0.366 sec/batch; 32h:53m:28s remains)
INFO - root - 2017-12-17 03:34:12.689386: step 9380, loss = 0.11, batch loss = 0.08 (20.7 examples/sec; 0.386 sec/batch; 34h:39m:21s remains)
INFO - root - 2017-12-17 03:34:16.508174: step 9390, loss = 0.12, batch loss = 0.09 (20.1 examples/sec; 0.398 sec/batch; 35h:42m:20s remains)
INFO - root - 2017-12-17 03:34:20.246417: step 9400, loss = 0.25, batch loss = 0.22 (22.1 examples/sec; 0.363 sec/batch; 32h:32m:27s remains)
INFO - root - 2017-12-17 03:34:24.180090: step 9410, loss = 0.22, batch loss = 0.18 (21.5 examples/sec; 0.372 sec/batch; 33h:21m:05s remains)
INFO - root - 2017-12-17 03:34:27.864486: step 9420, loss = 0.12, batch loss = 0.08 (22.0 examples/sec; 0.364 sec/batch; 32h:40m:45s remains)
INFO - root - 2017-12-17 03:34:31.454009: step 9430, loss = 0.14, batch loss = 0.10 (21.4 examples/sec; 0.374 sec/batch; 33h:33m:15s remains)
INFO - root - 2017-12-17 03:34:35.064415: step 9440, loss = 0.12, batch loss = 0.08 (21.2 examples/sec; 0.377 sec/batch; 33h:47m:57s remains)
INFO - root - 2017-12-17 03:34:38.717224: step 9450, loss = 0.15, batch loss = 0.11 (21.5 examples/sec; 0.371 sec/batch; 33h:19m:32s remains)
INFO - root - 2017-12-17 03:34:42.454283: step 9460, loss = 0.17, batch loss = 0.13 (21.0 examples/sec; 0.381 sec/batch; 34h:13m:56s remains)
INFO - root - 2017-12-17 03:34:46.178770: step 9470, loss = 0.16, batch loss = 0.12 (21.0 examples/sec; 0.381 sec/batch; 34h:13m:07s remains)
INFO - root - 2017-12-17 03:34:49.882788: step 9480, loss = 0.17, batch loss = 0.13 (20.9 examples/sec; 0.383 sec/batch; 34h:23m:19s remains)
INFO - root - 2017-12-17 03:34:53.509717: step 9490, loss = 0.12, batch loss = 0.08 (22.8 examples/sec; 0.350 sec/batch; 31h:26m:16s remains)
INFO - root - 2017-12-17 03:34:57.232314: step 9500, loss = 0.19, batch loss = 0.16 (22.0 examples/sec; 0.363 sec/batch; 32h:34m:43s remains)
INFO - root - 2017-12-17 03:35:01.095549: step 9510, loss = 0.17, batch loss = 0.13 (22.2 examples/sec; 0.361 sec/batch; 32h:22m:15s remains)
INFO - root - 2017-12-17 03:35:04.683808: step 9520, loss = 0.12, batch loss = 0.08 (28.9 examples/sec; 0.277 sec/batch; 24h:50m:35s remains)
INFO - root - 2017-12-17 03:35:07.828697: step 9530, loss = 0.17, batch loss = 0.13 (23.9 examples/sec; 0.335 sec/batch; 30h:03m:03s remains)
INFO - root - 2017-12-17 03:35:11.314285: step 9540, loss = 0.20, batch loss = 0.16 (26.6 examples/sec; 0.300 sec/batch; 26h:57m:11s remains)
INFO - root - 2017-12-17 03:35:14.984551: step 9550, loss = 0.15, batch loss = 0.11 (24.4 examples/sec; 0.328 sec/batch; 29h:23m:01s remains)
INFO - root - 2017-12-17 03:35:18.632266: step 9560, loss = 0.19, batch loss = 0.16 (22.5 examples/sec; 0.356 sec/batch; 31h:57m:07s remains)
INFO - root - 2017-12-17 03:35:22.236627: step 9570, loss = 0.18, batch loss = 0.15 (22.1 examples/sec; 0.362 sec/batch; 32h:29m:30s remains)
INFO - root - 2017-12-17 03:35:25.738393: step 9580, loss = 0.29, batch loss = 0.26 (22.2 examples/sec; 0.361 sec/batch; 32h:20m:16s remains)
INFO - root - 2017-12-17 03:35:29.437369: step 9590, loss = 0.20, batch loss = 0.17 (21.6 examples/sec; 0.370 sec/batch; 33h:10m:58s remains)
INFO - root - 2017-12-17 03:35:33.203550: step 9600, loss = 0.18, batch loss = 0.14 (21.6 examples/sec; 0.371 sec/batch; 33h:14m:21s remains)
INFO - root - 2017-12-17 03:35:37.174529: step 9610, loss = 0.17, batch loss = 0.13 (20.3 examples/sec; 0.395 sec/batch; 35h:23m:37s remains)
INFO - root - 2017-12-17 03:35:40.910128: step 9620, loss = 0.13, batch loss = 0.09 (21.5 examples/sec; 0.373 sec/batch; 33h:26m:34s remains)
INFO - root - 2017-12-17 03:35:44.471585: step 9630, loss = 0.17, batch loss = 0.13 (24.7 examples/sec; 0.324 sec/batch; 29h:04m:07s remains)
INFO - root - 2017-12-17 03:35:48.055499: step 9640, loss = 0.15, batch loss = 0.12 (20.7 examples/sec; 0.387 sec/batch; 34h:43m:05s remains)
INFO - root - 2017-12-17 03:35:51.881751: step 9650, loss = 0.16, batch loss = 0.12 (21.3 examples/sec; 0.376 sec/batch; 33h:45m:22s remains)
INFO - root - 2017-12-17 03:35:55.656573: step 9660, loss = 0.14, batch loss = 0.10 (21.1 examples/sec; 0.379 sec/batch; 34h:01m:07s remains)
INFO - root - 2017-12-17 03:35:59.456616: step 9670, loss = 0.12, batch loss = 0.08 (20.8 examples/sec; 0.384 sec/batch; 34h:24m:59s remains)
INFO - root - 2017-12-17 03:36:03.225630: step 9680, loss = 0.16, batch loss = 0.12 (20.0 examples/sec; 0.400 sec/batch; 35h:49m:56s remains)
INFO - root - 2017-12-17 03:36:06.931575: step 9690, loss = 0.24, batch loss = 0.20 (21.8 examples/sec; 0.367 sec/batch; 32h:54m:38s remains)
INFO - root - 2017-12-17 03:36:10.689691: step 9700, loss = 0.13, batch loss = 0.09 (21.6 examples/sec; 0.371 sec/batch; 33h:15m:43s remains)
INFO - root - 2017-12-17 03:36:14.582211: step 9710, loss = 0.12, batch loss = 0.08 (21.7 examples/sec; 0.368 sec/batch; 33h:01m:02s remains)
INFO - root - 2017-12-17 03:36:18.223498: step 9720, loss = 0.13, batch loss = 0.10 (22.3 examples/sec; 0.358 sec/batch; 32h:06m:19s remains)
INFO - root - 2017-12-17 03:36:21.665988: step 9730, loss = 0.14, batch loss = 0.10 (23.9 examples/sec; 0.335 sec/batch; 30h:01m:03s remains)
INFO - root - 2017-12-17 03:36:25.257098: step 9740, loss = 0.14, batch loss = 0.10 (20.7 examples/sec; 0.386 sec/batch; 34h:36m:58s remains)
INFO - root - 2017-12-17 03:36:28.916891: step 9750, loss = 0.18, batch loss = 0.14 (22.4 examples/sec; 0.357 sec/batch; 32h:00m:00s remains)
INFO - root - 2017-12-17 03:36:32.399812: step 9760, loss = 0.16, batch loss = 0.12 (21.5 examples/sec; 0.371 sec/batch; 33h:17m:38s remains)
INFO - root - 2017-12-17 03:36:36.057972: step 9770, loss = 0.16, batch loss = 0.12 (22.6 examples/sec; 0.354 sec/batch; 31h:46m:15s remains)
INFO - root - 2017-12-17 03:36:39.771990: step 9780, loss = 0.15, batch loss = 0.11 (21.9 examples/sec; 0.366 sec/batch; 32h:48m:14s remains)
INFO - root - 2017-12-17 03:36:43.300922: step 9790, loss = 0.13, batch loss = 0.09 (23.8 examples/sec; 0.336 sec/batch; 30h:09m:44s remains)
INFO - root - 2017-12-17 03:36:46.917087: step 9800, loss = 0.15, batch loss = 0.11 (21.9 examples/sec; 0.366 sec/batch; 32h:46m:07s remains)
INFO - root - 2017-12-17 03:36:50.756458: step 9810, loss = 0.16, batch loss = 0.12 (22.2 examples/sec; 0.360 sec/batch; 32h:15m:45s remains)
INFO - root - 2017-12-17 03:36:54.300222: step 9820, loss = 0.17, batch loss = 0.13 (22.8 examples/sec; 0.350 sec/batch; 31h:22m:55s remains)
INFO - root - 2017-12-17 03:36:57.941357: step 9830, loss = 0.12, batch loss = 0.08 (21.4 examples/sec; 0.373 sec/batch; 33h:26m:10s remains)
INFO - root - 2017-12-17 03:37:01.672461: step 9840, loss = 0.16, batch loss = 0.12 (21.4 examples/sec; 0.374 sec/batch; 33h:32m:09s remains)
INFO - root - 2017-12-17 03:37:05.327936: step 9850, loss = 0.18, batch loss = 0.15 (22.4 examples/sec; 0.357 sec/batch; 31h:58m:38s remains)
INFO - root - 2017-12-17 03:37:08.985367: step 9860, loss = 0.13, batch loss = 0.09 (22.7 examples/sec; 0.353 sec/batch; 31h:35m:49s remains)
INFO - root - 2017-12-17 03:37:12.731819: step 9870, loss = 0.14, batch loss = 0.10 (21.2 examples/sec; 0.377 sec/batch; 33h:47m:35s remains)
INFO - root - 2017-12-17 03:37:16.442706: step 9880, loss = 0.19, batch loss = 0.15 (21.8 examples/sec; 0.367 sec/batch; 32h:54m:53s remains)
INFO - root - 2017-12-17 03:37:20.090520: step 9890, loss = 0.13, batch loss = 0.09 (21.7 examples/sec; 0.369 sec/batch; 33h:04m:18s remains)
INFO - root - 2017-12-17 03:37:23.747271: step 9900, loss = 0.15, batch loss = 0.11 (23.3 examples/sec; 0.344 sec/batch; 30h:49m:27s remains)
INFO - root - 2017-12-17 03:37:27.563942: step 9910, loss = 0.14, batch loss = 0.10 (23.0 examples/sec; 0.348 sec/batch; 31h:11m:41s remains)
INFO - root - 2017-12-17 03:37:31.325345: step 9920, loss = 0.14, batch loss = 0.10 (21.7 examples/sec; 0.369 sec/batch; 33h:06m:17s remains)
INFO - root - 2017-12-17 03:37:35.027959: step 9930, loss = 0.15, batch loss = 0.11 (22.2 examples/sec; 0.361 sec/batch; 32h:20m:56s remains)
INFO - root - 2017-12-17 03:37:38.715413: step 9940, loss = 0.15, batch loss = 0.11 (22.1 examples/sec; 0.362 sec/batch; 32h:28m:47s remains)
INFO - root - 2017-12-17 03:37:42.204606: step 9950, loss = 0.12, batch loss = 0.08 (21.8 examples/sec; 0.366 sec/batch; 32h:48m:26s remains)
INFO - root - 2017-12-17 03:37:45.876971: step 9960, loss = 0.13, batch loss = 0.09 (22.7 examples/sec; 0.353 sec/batch; 31h:36m:14s remains)
INFO - root - 2017-12-17 03:37:49.490210: step 9970, loss = 0.17, batch loss = 0.13 (22.6 examples/sec; 0.354 sec/batch; 31h:43m:30s remains)
INFO - root - 2017-12-17 03:37:53.084657: step 9980, loss = 0.17, batch loss = 0.13 (22.7 examples/sec; 0.352 sec/batch; 31h:33m:25s remains)
INFO - root - 2017-12-17 03:37:56.700637: step 9990, loss = 0.14, batch loss = 0.10 (21.4 examples/sec; 0.374 sec/batch; 33h:28m:39s remains)
INFO - root - 2017-12-17 03:38:00.303608: step 10000, loss = 0.13, batch loss = 0.09 (24.1 examples/sec; 0.332 sec/batch; 29h:46m:31s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-10000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-10000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 03:38:04.550551: step 10010, loss = 0.14, batch loss = 0.10 (23.5 examples/sec; 0.340 sec/batch; 30h:26m:57s remains)
INFO - root - 2017-12-17 03:38:08.154855: step 10020, loss = 0.12, batch loss = 0.08 (22.7 examples/sec; 0.353 sec/batch; 31h:37m:31s remains)
INFO - root - 2017-12-17 03:38:11.800391: step 10030, loss = 0.17, batch loss = 0.14 (22.7 examples/sec; 0.353 sec/batch; 31h:35m:58s remains)
INFO - root - 2017-12-17 03:38:15.442959: step 10040, loss = 0.12, batch loss = 0.08 (21.0 examples/sec; 0.382 sec/batch; 34h:11m:14s remains)
INFO - root - 2017-12-17 03:38:19.108146: step 10050, loss = 0.14, batch loss = 0.11 (21.8 examples/sec; 0.367 sec/batch; 32h:50m:33s remains)
INFO - root - 2017-12-17 03:38:22.737796: step 10060, loss = 0.17, batch loss = 0.13 (21.8 examples/sec; 0.366 sec/batch; 32h:48m:23s remains)
INFO - root - 2017-12-17 03:38:26.349547: step 10070, loss = 0.21, batch loss = 0.17 (21.9 examples/sec; 0.366 sec/batch; 32h:45m:08s remains)
INFO - root - 2017-12-17 03:38:29.941525: step 10080, loss = 0.14, batch loss = 0.10 (22.9 examples/sec; 0.349 sec/batch; 31h:15m:40s remains)
INFO - root - 2017-12-17 03:38:33.648757: step 10090, loss = 0.13, batch loss = 0.09 (21.6 examples/sec; 0.371 sec/batch; 33h:13m:07s remains)
INFO - root - 2017-12-17 03:38:37.292007: step 10100, loss = 0.11, batch loss = 0.08 (21.6 examples/sec; 0.370 sec/batch; 33h:07m:34s remains)
INFO - root - 2017-12-17 03:38:41.090421: step 10110, loss = 0.16, batch loss = 0.12 (22.2 examples/sec; 0.361 sec/batch; 32h:17m:20s remains)
INFO - root - 2017-12-17 03:38:44.744144: step 10120, loss = 0.12, batch loss = 0.09 (21.9 examples/sec; 0.366 sec/batch; 32h:46m:26s remains)
INFO - root - 2017-12-17 03:38:48.233381: step 10130, loss = 0.18, batch loss = 0.14 (21.1 examples/sec; 0.379 sec/batch; 33h:54m:23s remains)
INFO - root - 2017-12-17 03:38:51.895011: step 10140, loss = 0.16, batch loss = 0.13 (22.1 examples/sec; 0.362 sec/batch; 32h:22m:24s remains)
INFO - root - 2017-12-17 03:38:55.546226: step 10150, loss = 0.15, batch loss = 0.11 (20.9 examples/sec; 0.382 sec/batch; 34h:12m:30s remains)
INFO - root - 2017-12-17 03:38:59.315973: step 10160, loss = 0.13, batch loss = 0.09 (21.3 examples/sec; 0.376 sec/batch; 33h:37m:19s remains)
INFO - root - 2017-12-17 03:39:03.034198: step 10170, loss = 0.11, batch loss = 0.07 (20.8 examples/sec; 0.384 sec/batch; 34h:24m:18s remains)
INFO - root - 2017-12-17 03:39:06.724376: step 10180, loss = 0.10, batch loss = 0.06 (22.6 examples/sec; 0.353 sec/batch; 31h:37m:32s remains)
INFO - root - 2017-12-17 03:39:10.347922: step 10190, loss = 0.13, batch loss = 0.09 (23.0 examples/sec; 0.347 sec/batch; 31h:04m:57s remains)
INFO - root - 2017-12-17 03:39:14.046528: step 10200, loss = 0.14, batch loss = 0.11 (21.9 examples/sec; 0.366 sec/batch; 32h:45m:45s remains)
INFO - root - 2017-12-17 03:39:17.868281: step 10210, loss = 0.14, batch loss = 0.11 (21.7 examples/sec; 0.368 sec/batch; 32h:56m:49s remains)
INFO - root - 2017-12-17 03:39:21.516696: step 10220, loss = 0.12, batch loss = 0.08 (21.0 examples/sec; 0.381 sec/batch; 34h:04m:48s remains)
INFO - root - 2017-12-17 03:39:25.171064: step 10230, loss = 0.14, batch loss = 0.10 (21.8 examples/sec; 0.367 sec/batch; 32h:50m:05s remains)
INFO - root - 2017-12-17 03:39:28.842691: step 10240, loss = 0.10, batch loss = 0.06 (22.2 examples/sec; 0.361 sec/batch; 32h:16m:53s remains)
INFO - root - 2017-12-17 03:39:32.460444: step 10250, loss = 0.11, batch loss = 0.07 (22.2 examples/sec; 0.360 sec/batch; 32h:13m:28s remains)
INFO - root - 2017-12-17 03:39:36.135777: step 10260, loss = 0.15, batch loss = 0.11 (21.2 examples/sec; 0.378 sec/batch; 33h:50m:49s remains)
INFO - root - 2017-12-17 03:39:39.905916: step 10270, loss = 0.13, batch loss = 0.10 (22.0 examples/sec; 0.363 sec/batch; 32h:31m:47s remains)
INFO - root - 2017-12-17 03:39:43.570615: step 10280, loss = 0.15, batch loss = 0.11 (22.2 examples/sec; 0.361 sec/batch; 32h:19m:17s remains)
INFO - root - 2017-12-17 03:39:47.271743: step 10290, loss = 0.11, batch loss = 0.07 (21.3 examples/sec; 0.376 sec/batch; 33h:37m:49s remains)
INFO - root - 2017-12-17 03:39:50.938066: step 10300, loss = 0.11, batch loss = 0.07 (20.7 examples/sec; 0.386 sec/batch; 34h:31m:23s remains)
INFO - root - 2017-12-17 03:39:54.737892: step 10310, loss = 0.13, batch loss = 0.09 (20.8 examples/sec; 0.385 sec/batch; 34h:25m:51s remains)
INFO - root - 2017-12-17 03:39:58.476563: step 10320, loss = 0.15, batch loss = 0.11 (20.6 examples/sec; 0.389 sec/batch; 34h:46m:28s remains)
INFO - root - 2017-12-17 03:40:02.185877: step 10330, loss = 0.17, batch loss = 0.14 (21.9 examples/sec; 0.366 sec/batch; 32h:45m:17s remains)
INFO - root - 2017-12-17 03:40:05.849835: step 10340, loss = 0.12, batch loss = 0.08 (21.6 examples/sec; 0.370 sec/batch; 33h:09m:19s remains)
INFO - root - 2017-12-17 03:40:09.519998: step 10350, loss = 0.15, batch loss = 0.12 (22.9 examples/sec; 0.350 sec/batch; 31h:18m:55s remains)
INFO - root - 2017-12-17 03:40:13.123221: step 10360, loss = 0.11, batch loss = 0.07 (30.3 examples/sec; 0.264 sec/batch; 23h:35m:28s remains)
INFO - root - 2017-12-17 03:40:16.567194: step 10370, loss = 0.14, batch loss = 0.10 (22.7 examples/sec; 0.352 sec/batch; 31h:31m:52s remains)
INFO - root - 2017-12-17 03:40:20.200782: step 10380, loss = 0.11, batch loss = 0.08 (20.3 examples/sec; 0.395 sec/batch; 35h:20m:53s remains)
INFO - root - 2017-12-17 03:40:23.920947: step 10390, loss = 0.11, batch loss = 0.07 (20.8 examples/sec; 0.385 sec/batch; 34h:24m:51s remains)
INFO - root - 2017-12-17 03:40:27.622286: step 10400, loss = 0.14, batch loss = 0.10 (22.1 examples/sec; 0.362 sec/batch; 32h:23m:21s remains)
INFO - root - 2017-12-17 03:40:31.561832: step 10410, loss = 0.11, batch loss = 0.07 (21.4 examples/sec; 0.374 sec/batch; 33h:27m:35s remains)
INFO - root - 2017-12-17 03:40:35.326000: step 10420, loss = 0.11, batch loss = 0.07 (21.5 examples/sec; 0.372 sec/batch; 33h:17m:52s remains)
INFO - root - 2017-12-17 03:40:38.986225: step 10430, loss = 0.13, batch loss = 0.09 (21.9 examples/sec; 0.366 sec/batch; 32h:43m:48s remains)
INFO - root - 2017-12-17 03:40:42.716673: step 10440, loss = 0.14, batch loss = 0.10 (21.5 examples/sec; 0.372 sec/batch; 33h:17m:37s remains)
INFO - root - 2017-12-17 03:40:46.454288: step 10450, loss = 0.14, batch loss = 0.11 (21.1 examples/sec; 0.380 sec/batch; 33h:58m:06s remains)
INFO - root - 2017-12-17 03:40:50.150662: step 10460, loss = 0.12, batch loss = 0.08 (21.5 examples/sec; 0.372 sec/batch; 33h:17m:48s remains)
INFO - root - 2017-12-17 03:40:53.811445: step 10470, loss = 0.20, batch loss = 0.16 (21.9 examples/sec; 0.365 sec/batch; 32h:38m:54s remains)
INFO - root - 2017-12-17 03:40:57.514941: step 10480, loss = 0.11, batch loss = 0.07 (23.1 examples/sec; 0.346 sec/batch; 30h:59m:14s remains)
INFO - root - 2017-12-17 03:41:01.237735: step 10490, loss = 0.11, batch loss = 0.07 (21.3 examples/sec; 0.376 sec/batch; 33h:35m:45s remains)
INFO - root - 2017-12-17 03:41:04.956834: step 10500, loss = 0.12, batch loss = 0.08 (21.0 examples/sec; 0.382 sec/batch; 34h:07m:32s remains)
INFO - root - 2017-12-17 03:41:08.797895: step 10510, loss = 0.11, batch loss = 0.08 (23.4 examples/sec; 0.342 sec/batch; 30h:35m:13s remains)
INFO - root - 2017-12-17 03:41:12.504533: step 10520, loss = 0.12, batch loss = 0.09 (21.4 examples/sec; 0.375 sec/batch; 33h:29m:56s remains)
INFO - root - 2017-12-17 03:41:16.148625: step 10530, loss = 0.13, batch loss = 0.09 (22.6 examples/sec; 0.355 sec/batch; 31h:43m:09s remains)
INFO - root - 2017-12-17 03:41:19.768079: step 10540, loss = 0.13, batch loss = 0.09 (23.5 examples/sec; 0.341 sec/batch; 30h:27m:30s remains)
INFO - root - 2017-12-17 03:41:23.369788: step 10550, loss = 0.11, batch loss = 0.07 (21.6 examples/sec; 0.370 sec/batch; 33h:06m:57s remains)
INFO - root - 2017-12-17 03:41:27.006401: step 10560, loss = 0.16, batch loss = 0.12 (21.4 examples/sec; 0.374 sec/batch; 33h:28m:40s remains)
INFO - root - 2017-12-17 03:41:30.430592: step 10570, loss = 0.12, batch loss = 0.08 (34.4 examples/sec; 0.233 sec/batch; 20h:47m:53s remains)
INFO - root - 2017-12-17 03:41:33.816588: step 10580, loss = 0.14, batch loss = 0.10 (22.1 examples/sec; 0.363 sec/batch; 32h:26m:18s remains)
INFO - root - 2017-12-17 03:41:37.488091: step 10590, loss = 0.11, batch loss = 0.08 (21.0 examples/sec; 0.381 sec/batch; 34h:06m:26s remains)
INFO - root - 2017-12-17 03:41:40.735466: step 10600, loss = 0.10, batch loss = 0.06 (28.6 examples/sec; 0.280 sec/batch; 25h:01m:04s remains)
INFO - root - 2017-12-17 03:41:44.379145: step 10610, loss = 0.11, batch loss = 0.07 (21.7 examples/sec; 0.369 sec/batch; 32h:57m:58s remains)
INFO - root - 2017-12-17 03:41:47.975212: step 10620, loss = 0.10, batch loss = 0.06 (21.8 examples/sec; 0.366 sec/batch; 32h:44m:31s remains)
INFO - root - 2017-12-17 03:41:51.654599: step 10630, loss = 0.19, batch loss = 0.15 (22.4 examples/sec; 0.357 sec/batch; 31h:55m:17s remains)
INFO - root - 2017-12-17 03:41:55.337857: step 10640, loss = 0.10, batch loss = 0.07 (20.8 examples/sec; 0.384 sec/batch; 34h:18m:17s remains)
INFO - root - 2017-12-17 03:41:58.955786: step 10650, loss = 0.14, batch loss = 0.10 (21.3 examples/sec; 0.376 sec/batch; 33h:36m:05s remains)
INFO - root - 2017-12-17 03:42:02.522400: step 10660, loss = 0.12, batch loss = 0.08 (25.0 examples/sec; 0.321 sec/batch; 28h:39m:52s remains)
INFO - root - 2017-12-17 03:42:06.146219: step 10670, loss = 0.16, batch loss = 0.12 (20.1 examples/sec; 0.398 sec/batch; 35h:36m:02s remains)
INFO - root - 2017-12-17 03:42:09.715020: step 10680, loss = 0.10, batch loss = 0.06 (31.2 examples/sec; 0.256 sec/batch; 22h:55m:06s remains)
INFO - root - 2017-12-17 03:42:13.356513: step 10690, loss = 0.12, batch loss = 0.09 (22.0 examples/sec; 0.363 sec/batch; 32h:26m:30s remains)
INFO - root - 2017-12-17 03:42:17.093318: step 10700, loss = 0.12, batch loss = 0.08 (21.6 examples/sec; 0.370 sec/batch; 33h:06m:12s remains)
INFO - root - 2017-12-17 03:42:20.942969: step 10710, loss = 0.12, batch loss = 0.08 (22.8 examples/sec; 0.350 sec/batch; 31h:18m:24s remains)
INFO - root - 2017-12-17 03:42:24.571924: step 10720, loss = 0.13, batch loss = 0.10 (22.1 examples/sec; 0.361 sec/batch; 32h:17m:27s remains)
INFO - root - 2017-12-17 03:42:27.946394: step 10730, loss = 0.15, batch loss = 0.11 (26.7 examples/sec; 0.300 sec/batch; 26h:47m:52s remains)
INFO - root - 2017-12-17 03:42:30.892528: step 10740, loss = 0.14, batch loss = 0.10 (27.0 examples/sec; 0.297 sec/batch; 26h:31m:06s remains)
INFO - root - 2017-12-17 03:42:34.267900: step 10750, loss = 0.11, batch loss = 0.07 (23.3 examples/sec; 0.343 sec/batch; 30h:38m:19s remains)
INFO - root - 2017-12-17 03:42:37.724121: step 10760, loss = 0.11, batch loss = 0.07 (22.8 examples/sec; 0.350 sec/batch; 31h:18m:56s remains)
INFO - root - 2017-12-17 03:42:41.434486: step 10770, loss = 0.13, batch loss = 0.09 (22.1 examples/sec; 0.361 sec/batch; 32h:17m:38s remains)
INFO - root - 2017-12-17 03:42:45.058726: step 10780, loss = 0.11, batch loss = 0.07 (22.0 examples/sec; 0.364 sec/batch; 32h:29m:43s remains)
INFO - root - 2017-12-17 03:42:48.375618: step 10790, loss = 0.11, batch loss = 0.08 (27.3 examples/sec; 0.293 sec/batch; 26h:10m:10s remains)
INFO - root - 2017-12-17 03:42:51.226896: step 10800, loss = 0.16, batch loss = 0.12 (27.4 examples/sec; 0.292 sec/batch; 26h:06m:27s remains)
INFO - root - 2017-12-17 03:42:54.673754: step 10810, loss = 0.15, batch loss = 0.12 (25.8 examples/sec; 0.309 sec/batch; 27h:39m:21s remains)
INFO - root - 2017-12-17 03:42:58.377274: step 10820, loss = 0.12, batch loss = 0.08 (20.7 examples/sec; 0.387 sec/batch; 34h:35m:12s remains)
INFO - root - 2017-12-17 03:43:02.069232: step 10830, loss = 0.14, batch loss = 0.11 (22.2 examples/sec; 0.360 sec/batch; 32h:09m:04s remains)
INFO - root - 2017-12-17 03:43:05.813808: step 10840, loss = 0.12, batch loss = 0.09 (20.6 examples/sec; 0.388 sec/batch; 34h:38m:38s remains)
INFO - root - 2017-12-17 03:43:09.575095: step 10850, loss = 0.15, batch loss = 0.11 (20.5 examples/sec; 0.390 sec/batch; 34h:51m:20s remains)
INFO - root - 2017-12-17 03:43:13.174508: step 10860, loss = 0.11, batch loss = 0.07 (23.3 examples/sec; 0.343 sec/batch; 30h:40m:33s remains)
INFO - root - 2017-12-17 03:43:16.830436: step 10870, loss = 0.13, batch loss = 0.09 (21.6 examples/sec; 0.371 sec/batch; 33h:06m:38s remains)
INFO - root - 2017-12-17 03:43:20.458879: step 10880, loss = 0.11, batch loss = 0.07 (21.6 examples/sec; 0.370 sec/batch; 33h:02m:56s remains)
INFO - root - 2017-12-17 03:43:24.080077: step 10890, loss = 0.10, batch loss = 0.07 (21.0 examples/sec; 0.381 sec/batch; 34h:03m:18s remains)
INFO - root - 2017-12-17 03:43:27.791483: step 10900, loss = 0.11, batch loss = 0.07 (21.0 examples/sec; 0.381 sec/batch; 34h:03m:18s remains)
INFO - root - 2017-12-17 03:43:31.647913: step 10910, loss = 0.21, batch loss = 0.18 (22.1 examples/sec; 0.362 sec/batch; 32h:18m:39s remains)
INFO - root - 2017-12-17 03:43:35.302902: step 10920, loss = 0.11, batch loss = 0.08 (21.7 examples/sec; 0.369 sec/batch; 32h:59m:14s remains)
INFO - root - 2017-12-17 03:43:38.964787: step 10930, loss = 0.16, batch loss = 0.13 (21.5 examples/sec; 0.372 sec/batch; 33h:13m:51s remains)
INFO - root - 2017-12-17 03:43:42.667750: step 10940, loss = 0.12, batch loss = 0.09 (22.1 examples/sec; 0.361 sec/batch; 32h:16m:48s remains)
INFO - root - 2017-12-17 03:43:46.392384: step 10950, loss = 0.11, batch loss = 0.07 (21.5 examples/sec; 0.371 sec/batch; 33h:09m:42s remains)
INFO - root - 2017-12-17 03:43:50.076205: step 10960, loss = 0.12, batch loss = 0.09 (21.2 examples/sec; 0.378 sec/batch; 33h:44m:36s remains)
INFO - root - 2017-12-17 03:43:53.757541: step 10970, loss = 0.19, batch loss = 0.16 (21.0 examples/sec; 0.382 sec/batch; 34h:04m:34s remains)
INFO - root - 2017-12-17 03:43:57.525261: step 10980, loss = 0.09, batch loss = 0.06 (20.8 examples/sec; 0.384 sec/batch; 34h:18m:31s remains)
INFO - root - 2017-12-17 03:44:01.246352: step 10990, loss = 0.11, batch loss = 0.07 (21.9 examples/sec; 0.366 sec/batch; 32h:40m:34s remains)
INFO - root - 2017-12-17 03:44:04.801754: step 11000, loss = 0.11, batch loss = 0.07 (21.6 examples/sec; 0.371 sec/batch; 33h:08m:55s remains)
INFO - root - 2017-12-17 03:44:08.569605: step 11010, loss = 0.12, batch loss = 0.08 (22.7 examples/sec; 0.353 sec/batch; 31h:32m:25s remains)
INFO - root - 2017-12-17 03:44:12.292960: step 11020, loss = 0.17, batch loss = 0.13 (21.5 examples/sec; 0.373 sec/batch; 33h:17m:21s remains)
INFO - root - 2017-12-17 03:44:16.062375: step 11030, loss = 0.14, batch loss = 0.11 (21.4 examples/sec; 0.374 sec/batch; 33h:22m:27s remains)
INFO - root - 2017-12-17 03:44:19.788152: step 11040, loss = 0.13, batch loss = 0.10 (21.2 examples/sec; 0.377 sec/batch; 33h:42m:01s remains)
INFO - root - 2017-12-17 03:44:23.569447: step 11050, loss = 0.09, batch loss = 0.06 (21.6 examples/sec; 0.370 sec/batch; 33h:04m:54s remains)
INFO - root - 2017-12-17 03:44:27.260760: step 11060, loss = 0.12, batch loss = 0.08 (22.0 examples/sec; 0.363 sec/batch; 32h:26m:50s remains)
INFO - root - 2017-12-17 03:44:30.911787: step 11070, loss = 0.13, batch loss = 0.09 (21.4 examples/sec; 0.374 sec/batch; 33h:21m:47s remains)
INFO - root - 2017-12-17 03:44:34.623648: step 11080, loss = 0.12, batch loss = 0.08 (21.8 examples/sec; 0.368 sec/batch; 32h:49m:30s remains)
INFO - root - 2017-12-17 03:44:38.366847: step 11090, loss = 0.11, batch loss = 0.07 (22.1 examples/sec; 0.363 sec/batch; 32h:22m:17s remains)
INFO - root - 2017-12-17 03:44:42.107553: step 11100, loss = 0.10, batch loss = 0.06 (21.4 examples/sec; 0.373 sec/batch; 33h:19m:29s remains)
INFO - root - 2017-12-17 03:44:46.124210: step 11110, loss = 0.24, batch loss = 0.20 (20.1 examples/sec; 0.399 sec/batch; 35h:34m:58s remains)
INFO - root - 2017-12-17 03:44:49.992255: step 11120, loss = 0.18, batch loss = 0.14 (20.5 examples/sec; 0.390 sec/batch; 34h:47m:56s remains)
INFO - root - 2017-12-17 03:44:53.792385: step 11130, loss = 0.13, batch loss = 0.09 (21.5 examples/sec; 0.372 sec/batch; 33h:12m:30s remains)
INFO - root - 2017-12-17 03:44:57.566305: step 11140, loss = 0.13, batch loss = 0.09 (20.3 examples/sec; 0.393 sec/batch; 35h:07m:23s remains)
INFO - root - 2017-12-17 03:45:01.320747: step 11150, loss = 0.12, batch loss = 0.08 (22.1 examples/sec; 0.362 sec/batch; 32h:19m:48s remains)
INFO - root - 2017-12-17 03:45:05.082157: step 11160, loss = 0.11, batch loss = 0.07 (21.4 examples/sec; 0.374 sec/batch; 33h:21m:03s remains)
INFO - root - 2017-12-17 03:45:08.747232: step 11170, loss = 0.14, batch loss = 0.10 (20.7 examples/sec; 0.387 sec/batch; 34h:32m:31s remains)
INFO - root - 2017-12-17 03:45:12.565057: step 11180, loss = 0.12, batch loss = 0.08 (21.9 examples/sec; 0.365 sec/batch; 32h:34m:04s remains)
INFO - root - 2017-12-17 03:45:16.292097: step 11190, loss = 0.10, batch loss = 0.07 (22.1 examples/sec; 0.363 sec/batch; 32h:22m:47s remains)
INFO - root - 2017-12-17 03:45:20.157088: step 11200, loss = 0.13, batch loss = 0.09 (20.4 examples/sec; 0.392 sec/batch; 34h:57m:17s remains)
INFO - root - 2017-12-17 03:45:24.116404: step 11210, loss = 0.17, batch loss = 0.13 (21.7 examples/sec; 0.368 sec/batch; 32h:51m:43s remains)
INFO - root - 2017-12-17 03:45:27.816693: step 11220, loss = 0.13, batch loss = 0.09 (21.9 examples/sec; 0.366 sec/batch; 32h:39m:58s remains)
INFO - root - 2017-12-17 03:45:31.575874: step 11230, loss = 0.10, batch loss = 0.06 (21.8 examples/sec; 0.368 sec/batch; 32h:48m:43s remains)
INFO - root - 2017-12-17 03:45:35.213590: step 11240, loss = 0.11, batch loss = 0.08 (21.6 examples/sec; 0.371 sec/batch; 33h:07m:36s remains)
INFO - root - 2017-12-17 03:45:38.902131: step 11250, loss = 0.12, batch loss = 0.08 (21.5 examples/sec; 0.372 sec/batch; 33h:13m:08s remains)
INFO - root - 2017-12-17 03:45:42.569194: step 11260, loss = 0.12, batch loss = 0.09 (21.5 examples/sec; 0.373 sec/batch; 33h:15m:32s remains)
INFO - root - 2017-12-17 03:45:46.286465: step 11270, loss = 0.10, batch loss = 0.06 (23.2 examples/sec; 0.346 sec/batch; 30h:49m:53s remains)
INFO - root - 2017-12-17 03:45:50.011509: step 11280, loss = 0.14, batch loss = 0.10 (22.8 examples/sec; 0.350 sec/batch; 31h:15m:47s remains)
INFO - root - 2017-12-17 03:45:53.634581: step 11290, loss = 0.16, batch loss = 0.12 (23.2 examples/sec; 0.345 sec/batch; 30h:48m:20s remains)
INFO - root - 2017-12-17 03:45:57.375227: step 11300, loss = 0.14, batch loss = 0.10 (21.5 examples/sec; 0.372 sec/batch; 33h:10m:56s remains)
INFO - root - 2017-12-17 03:46:01.251546: step 11310, loss = 0.12, batch loss = 0.08 (22.2 examples/sec; 0.360 sec/batch; 32h:05m:41s remains)
INFO - root - 2017-12-17 03:46:04.926950: step 11320, loss = 0.10, batch loss = 0.06 (23.1 examples/sec; 0.346 sec/batch; 30h:53m:23s remains)
INFO - root - 2017-12-17 03:46:08.599614: step 11330, loss = 0.17, batch loss = 0.13 (21.9 examples/sec; 0.366 sec/batch; 32h:37m:07s remains)
INFO - root - 2017-12-17 03:46:11.749804: step 11340, loss = 0.10, batch loss = 0.06 (26.1 examples/sec; 0.306 sec/batch; 27h:20m:07s remains)
INFO - root - 2017-12-17 03:46:14.956542: step 11350, loss = 0.12, batch loss = 0.08 (27.3 examples/sec; 0.293 sec/batch; 26h:09m:19s remains)
INFO - root - 2017-12-17 03:46:18.556865: step 11360, loss = 0.16, batch loss = 0.13 (20.6 examples/sec; 0.388 sec/batch; 34h:36m:33s remains)
INFO - root - 2017-12-17 03:46:22.251583: step 11370, loss = 0.11, batch loss = 0.07 (21.8 examples/sec; 0.368 sec/batch; 32h:47m:39s remains)
INFO - root - 2017-12-17 03:46:25.936583: step 11380, loss = 0.10, batch loss = 0.06 (21.4 examples/sec; 0.375 sec/batch; 33h:25m:18s remains)
INFO - root - 2017-12-17 03:46:29.609050: step 11390, loss = 0.16, batch loss = 0.13 (21.3 examples/sec; 0.375 sec/batch; 33h:28m:53s remains)
INFO - root - 2017-12-17 03:46:33.305403: step 11400, loss = 0.10, batch loss = 0.06 (21.2 examples/sec; 0.378 sec/batch; 33h:42m:38s remains)
INFO - root - 2017-12-17 03:46:37.266507: step 11410, loss = 0.11, batch loss = 0.07 (20.5 examples/sec; 0.391 sec/batch; 34h:51m:50s remains)
INFO - root - 2017-12-17 03:46:40.764544: step 11420, loss = 0.12, batch loss = 0.08 (26.6 examples/sec; 0.300 sec/batch; 26h:46m:42s remains)
INFO - root - 2017-12-17 03:46:43.919477: step 11430, loss = 0.14, batch loss = 0.10 (25.4 examples/sec; 0.315 sec/batch; 28h:04m:28s remains)
INFO - root - 2017-12-17 03:46:47.333739: step 11440, loss = 0.22, batch loss = 0.18 (21.2 examples/sec; 0.377 sec/batch; 33h:37m:00s remains)
INFO - root - 2017-12-17 03:46:50.987281: step 11450, loss = 0.10, batch loss = 0.06 (23.2 examples/sec; 0.346 sec/batch; 30h:48m:47s remains)
INFO - root - 2017-12-17 03:46:54.578271: step 11460, loss = 0.13, batch loss = 0.09 (22.8 examples/sec; 0.351 sec/batch; 31h:20m:37s remains)
INFO - root - 2017-12-17 03:46:58.237820: step 11470, loss = 0.14, batch loss = 0.10 (22.6 examples/sec; 0.354 sec/batch; 31h:33m:18s remains)
INFO - root - 2017-12-17 03:47:01.900389: step 11480, loss = 0.10, batch loss = 0.06 (21.8 examples/sec; 0.368 sec/batch; 32h:47m:54s remains)
INFO - root - 2017-12-17 03:47:05.556138: step 11490, loss = 0.16, batch loss = 0.12 (21.0 examples/sec; 0.381 sec/batch; 33h:58m:12s remains)
INFO - root - 2017-12-17 03:47:09.272104: step 11500, loss = 0.12, batch loss = 0.08 (20.8 examples/sec; 0.384 sec/batch; 34h:15m:00s remains)
INFO - root - 2017-12-17 03:47:13.235442: step 11510, loss = 0.13, batch loss = 0.09 (21.3 examples/sec; 0.375 sec/batch; 33h:28m:19s remains)
INFO - root - 2017-12-17 03:47:17.037559: step 11520, loss = 0.15, batch loss = 0.12 (21.3 examples/sec; 0.375 sec/batch; 33h:26m:15s remains)
INFO - root - 2017-12-17 03:47:20.755867: step 11530, loss = 0.13, batch loss = 0.09 (21.5 examples/sec; 0.371 sec/batch; 33h:06m:01s remains)
INFO - root - 2017-12-17 03:47:24.495969: step 11540, loss = 0.14, batch loss = 0.10 (21.0 examples/sec; 0.381 sec/batch; 33h:57m:49s remains)
INFO - root - 2017-12-17 03:47:28.161445: step 11550, loss = 0.12, batch loss = 0.08 (22.4 examples/sec; 0.356 sec/batch; 31h:46m:38s remains)
INFO - root - 2017-12-17 03:47:31.930373: step 11560, loss = 0.12, batch loss = 0.08 (21.1 examples/sec; 0.380 sec/batch; 33h:50m:18s remains)
INFO - root - 2017-12-17 03:47:35.704619: step 11570, loss = 0.11, batch loss = 0.08 (21.8 examples/sec; 0.366 sec/batch; 32h:39m:43s remains)
INFO - root - 2017-12-17 03:47:39.464203: step 11580, loss = 0.16, batch loss = 0.12 (22.0 examples/sec; 0.363 sec/batch; 32h:22m:15s remains)
INFO - root - 2017-12-17 03:47:43.158646: step 11590, loss = 0.11, batch loss = 0.07 (21.7 examples/sec; 0.369 sec/batch; 32h:51m:08s remains)
INFO - root - 2017-12-17 03:47:46.882216: step 11600, loss = 0.10, batch loss = 0.06 (21.8 examples/sec; 0.367 sec/batch; 32h:40m:59s remains)
INFO - root - 2017-12-17 03:47:50.825750: step 11610, loss = 0.12, batch loss = 0.09 (20.1 examples/sec; 0.397 sec/batch; 35h:24m:50s remains)
INFO - root - 2017-12-17 03:47:54.591309: step 11620, loss = 0.12, batch loss = 0.09 (21.4 examples/sec; 0.374 sec/batch; 33h:20m:23s remains)
INFO - root - 2017-12-17 03:47:57.545796: step 11630, loss = 0.14, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 19h:29m:32s remains)
INFO - root - 2017-12-17 03:47:59.884439: step 11640, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 19h:48m:54s remains)
INFO - root - 2017-12-17 03:48:02.100480: step 11650, loss = 0.09, batch loss = 0.06 (34.9 examples/sec; 0.229 sec/batch; 20h:26m:06s remains)
INFO - root - 2017-12-17 03:48:04.354449: step 11660, loss = 0.11, batch loss = 0.07 (33.9 examples/sec; 0.236 sec/batch; 21h:00m:46s remains)
INFO - root - 2017-12-17 03:48:06.616586: step 11670, loss = 0.12, batch loss = 0.08 (35.4 examples/sec; 0.226 sec/batch; 20h:07m:31s remains)
INFO - root - 2017-12-17 03:48:08.864638: step 11680, loss = 0.14, batch loss = 0.10 (34.7 examples/sec; 0.230 sec/batch; 20h:32m:20s remains)
INFO - root - 2017-12-17 03:48:11.121188: step 11690, loss = 0.15, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 20h:08m:25s remains)
INFO - root - 2017-12-17 03:48:13.363245: step 11700, loss = 0.12, batch loss = 0.08 (35.3 examples/sec; 0.226 sec/batch; 20h:11m:00s remains)
INFO - root - 2017-12-17 03:48:15.754774: step 11710, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 19h:58m:18s remains)
INFO - root - 2017-12-17 03:48:18.010161: step 11720, loss = 0.17, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 19h:45m:36s remains)
INFO - root - 2017-12-17 03:48:20.263074: step 11730, loss = 0.18, batch loss = 0.14 (36.1 examples/sec; 0.222 sec/batch; 19h:45m:21s remains)
INFO - root - 2017-12-17 03:48:22.533365: step 11740, loss = 0.12, batch loss = 0.08 (34.9 examples/sec; 0.230 sec/batch; 20h:26m:56s remains)
INFO - root - 2017-12-17 03:48:24.809756: step 11750, loss = 0.11, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 19h:31m:14s remains)
INFO - root - 2017-12-17 03:48:27.110313: step 11760, loss = 0.25, batch loss = 0.22 (35.9 examples/sec; 0.223 sec/batch; 19h:51m:47s remains)
INFO - root - 2017-12-17 03:48:29.367211: step 11770, loss = 0.11, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 19h:37m:49s remains)
INFO - root - 2017-12-17 03:48:31.555930: step 11780, loss = 0.11, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 19h:45m:26s remains)
INFO - root - 2017-12-17 03:48:33.788663: step 11790, loss = 0.11, batch loss = 0.08 (36.7 examples/sec; 0.218 sec/batch; 19h:24m:01s remains)
INFO - root - 2017-12-17 03:48:36.016884: step 11800, loss = 0.11, batch loss = 0.08 (35.1 examples/sec; 0.228 sec/batch; 20h:18m:48s remains)
INFO - root - 2017-12-17 03:48:38.401124: step 11810, loss = 0.12, batch loss = 0.09 (36.7 examples/sec; 0.218 sec/batch; 19h:25m:37s remains)
INFO - root - 2017-12-17 03:48:40.636932: step 11820, loss = 0.12, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:48m:05s remains)
INFO - root - 2017-12-17 03:48:42.908485: step 11830, loss = 0.14, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 19h:46m:34s remains)
INFO - root - 2017-12-17 03:48:45.141040: step 11840, loss = 0.15, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 19h:51m:34s remains)
INFO - root - 2017-12-17 03:48:47.354322: step 11850, loss = 0.15, batch loss = 0.11 (35.8 examples/sec; 0.223 sec/batch; 19h:53m:59s remains)
INFO - root - 2017-12-17 03:48:49.562340: step 11860, loss = 0.11, batch loss = 0.07 (37.1 examples/sec; 0.216 sec/batch; 19h:13m:20s remains)
INFO - root - 2017-12-17 03:48:51.796012: step 11870, loss = 0.09, batch loss = 0.05 (36.7 examples/sec; 0.218 sec/batch; 19h:24m:28s remains)
INFO - root - 2017-12-17 03:48:54.053665: step 11880, loss = 0.20, batch loss = 0.16 (36.1 examples/sec; 0.221 sec/batch; 19h:43m:17s remains)
INFO - root - 2017-12-17 03:48:56.274257: step 11890, loss = 0.13, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 19h:40m:58s remains)
INFO - root - 2017-12-17 03:48:58.472108: step 11900, loss = 0.13, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 19h:42m:09s remains)
INFO - root - 2017-12-17 03:49:00.799496: step 11910, loss = 0.13, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 19h:36m:36s remains)
INFO - root - 2017-12-17 03:49:03.009345: step 11920, loss = 0.12, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 19h:35m:13s remains)
INFO - root - 2017-12-17 03:49:05.247575: step 11930, loss = 0.12, batch loss = 0.08 (35.2 examples/sec; 0.227 sec/batch; 20h:15m:26s remains)
INFO - root - 2017-12-17 03:49:07.493302: step 11940, loss = 0.10, batch loss = 0.06 (34.9 examples/sec; 0.229 sec/batch; 20h:24m:30s remains)
INFO - root - 2017-12-17 03:49:09.716976: step 11950, loss = 0.13, batch loss = 0.09 (34.9 examples/sec; 0.229 sec/batch; 20h:25m:28s remains)
INFO - root - 2017-12-17 03:49:11.921387: step 11960, loss = 0.10, batch loss = 0.07 (37.0 examples/sec; 0.216 sec/batch; 19h:13m:40s remains)
INFO - root - 2017-12-17 03:49:14.154870: step 11970, loss = 0.12, batch loss = 0.08 (33.9 examples/sec; 0.236 sec/batch; 20h:58m:55s remains)
INFO - root - 2017-12-17 03:49:16.408453: step 11980, loss = 0.16, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 19h:40m:50s remains)
INFO - root - 2017-12-17 03:49:18.609509: step 11990, loss = 0.14, batch loss = 0.10 (37.3 examples/sec; 0.214 sec/batch; 19h:05m:30s remains)
INFO - root - 2017-12-17 03:49:20.842300: step 12000, loss = 0.11, batch loss = 0.08 (36.7 examples/sec; 0.218 sec/batch; 19h:25m:34s remains)
INFO - root - 2017-12-17 03:49:23.208709: step 12010, loss = 0.09, batch loss = 0.05 (36.1 examples/sec; 0.221 sec/batch; 19h:42m:40s remains)
INFO - root - 2017-12-17 03:49:25.460608: step 12020, loss = 0.15, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 20h:20m:21s remains)
INFO - root - 2017-12-17 03:49:27.739082: step 12030, loss = 0.12, batch loss = 0.09 (33.7 examples/sec; 0.237 sec/batch; 21h:06m:25s remains)
INFO - root - 2017-12-17 03:49:30.022262: step 12040, loss = 0.14, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 19h:31m:32s remains)
INFO - root - 2017-12-17 03:49:32.284442: step 12050, loss = 0.11, batch loss = 0.07 (36.8 examples/sec; 0.218 sec/batch; 19h:21m:53s remains)
INFO - root - 2017-12-17 03:49:34.527267: step 12060, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 20h:13m:25s remains)
INFO - root - 2017-12-17 03:49:36.772448: step 12070, loss = 0.13, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 19h:54m:35s remains)
INFO - root - 2017-12-17 03:49:39.019936: step 12080, loss = 0.17, batch loss = 0.14 (36.8 examples/sec; 0.217 sec/batch; 19h:20m:18s remains)
INFO - root - 2017-12-17 03:49:41.205847: step 12090, loss = 0.16, batch loss = 0.13 (36.6 examples/sec; 0.218 sec/batch; 19h:26m:35s remains)
INFO - root - 2017-12-17 03:49:43.443096: step 12100, loss = 0.09, batch loss = 0.05 (36.7 examples/sec; 0.218 sec/batch; 19h:24m:00s remains)
INFO - root - 2017-12-17 03:49:45.808528: step 12110, loss = 0.16, batch loss = 0.12 (34.7 examples/sec; 0.230 sec/batch; 20h:30m:29s remains)
INFO - root - 2017-12-17 03:49:48.052524: step 12120, loss = 0.12, batch loss = 0.08 (34.7 examples/sec; 0.231 sec/batch; 20h:31m:14s remains)
INFO - root - 2017-12-17 03:49:50.297147: step 12130, loss = 0.12, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 19h:45m:25s remains)
INFO - root - 2017-12-17 03:49:52.521466: step 12140, loss = 0.17, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 19h:45m:25s remains)
INFO - root - 2017-12-17 03:49:54.735921: step 12150, loss = 0.11, batch loss = 0.07 (37.5 examples/sec; 0.214 sec/batch; 19h:00m:04s remains)
INFO - root - 2017-12-17 03:49:56.925464: step 12160, loss = 0.15, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 19h:28m:40s remains)
INFO - root - 2017-12-17 03:49:59.120988: step 12170, loss = 0.12, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 19h:33m:49s remains)
INFO - root - 2017-12-17 03:50:01.400422: step 12180, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 19h:44m:20s remains)
INFO - root - 2017-12-17 03:50:03.630434: step 12190, loss = 0.11, batch loss = 0.07 (35.3 examples/sec; 0.226 sec/batch; 20h:08m:27s remains)
INFO - root - 2017-12-17 03:50:05.897584: step 12200, loss = 0.12, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:47m:15s remains)
INFO - root - 2017-12-17 03:50:08.252758: step 12210, loss = 0.11, batch loss = 0.08 (37.2 examples/sec; 0.215 sec/batch; 19h:07m:02s remains)
INFO - root - 2017-12-17 03:50:10.489675: step 12220, loss = 0.11, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 19h:50m:08s remains)
INFO - root - 2017-12-17 03:50:12.700719: step 12230, loss = 0.17, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 19h:32m:52s remains)
INFO - root - 2017-12-17 03:50:14.906140: step 12240, loss = 0.15, batch loss = 0.11 (35.3 examples/sec; 0.226 sec/batch; 20h:07m:58s remains)
INFO - root - 2017-12-17 03:50:17.164415: step 12250, loss = 0.15, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 20h:38m:00s remains)
INFO - root - 2017-12-17 03:50:19.384132: step 12260, loss = 0.12, batch loss = 0.08 (36.8 examples/sec; 0.218 sec/batch; 19h:21m:46s remains)
INFO - root - 2017-12-17 03:50:21.650935: step 12270, loss = 0.14, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 20h:35m:56s remains)
INFO - root - 2017-12-17 03:50:23.905643: step 12280, loss = 0.10, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 19h:27m:30s remains)
INFO - root - 2017-12-17 03:50:26.164844: step 12290, loss = 0.13, batch loss = 0.10 (34.0 examples/sec; 0.235 sec/batch; 20h:56m:17s remains)
INFO - root - 2017-12-17 03:50:28.407064: step 12300, loss = 0.13, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:48m:22s remains)
INFO - root - 2017-12-17 03:50:30.756977: step 12310, loss = 0.11, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 19h:33m:12s remains)
INFO - root - 2017-12-17 03:50:33.004492: step 12320, loss = 0.12, batch loss = 0.08 (37.0 examples/sec; 0.216 sec/batch; 19h:13m:34s remains)
INFO - root - 2017-12-17 03:50:35.241148: step 12330, loss = 0.11, batch loss = 0.07 (35.0 examples/sec; 0.228 sec/batch; 20h:18m:28s remains)
INFO - root - 2017-12-17 03:50:37.493806: step 12340, loss = 0.12, batch loss = 0.08 (36.9 examples/sec; 0.217 sec/batch; 19h:18m:09s remains)
INFO - root - 2017-12-17 03:50:39.768124: step 12350, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 19h:42m:46s remains)
INFO - root - 2017-12-17 03:50:41.974310: step 12360, loss = 0.11, batch loss = 0.08 (36.6 examples/sec; 0.218 sec/batch; 19h:25m:14s remains)
INFO - root - 2017-12-17 03:50:44.240856: step 12370, loss = 0.13, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:45m:56s remains)
INFO - root - 2017-12-17 03:50:46.477660: step 12380, loss = 0.11, batch loss = 0.07 (35.1 examples/sec; 0.228 sec/batch; 20h:17m:14s remains)
INFO - root - 2017-12-17 03:50:48.756797: step 12390, loss = 0.11, batch loss = 0.07 (34.7 examples/sec; 0.231 sec/batch; 20h:31m:16s remains)
INFO - root - 2017-12-17 03:50:51.031544: step 12400, loss = 0.15, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 20h:01m:54s remains)
INFO - root - 2017-12-17 03:50:53.409345: step 12410, loss = 0.12, batch loss = 0.08 (36.0 examples/sec; 0.223 sec/batch; 19h:47m:08s remains)
INFO - root - 2017-12-17 03:50:55.654285: step 12420, loss = 0.12, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 19h:49m:12s remains)
INFO - root - 2017-12-17 03:50:57.887814: step 12430, loss = 0.10, batch loss = 0.07 (35.1 examples/sec; 0.228 sec/batch; 20h:15m:44s remains)
INFO - root - 2017-12-17 03:51:00.108578: step 12440, loss = 0.13, batch loss = 0.09 (34.5 examples/sec; 0.232 sec/batch; 20h:37m:31s remains)
INFO - root - 2017-12-17 03:51:02.363025: step 12450, loss = 0.14, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 19h:27m:30s remains)
INFO - root - 2017-12-17 03:51:04.577332: step 12460, loss = 0.13, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 19h:49m:49s remains)
INFO - root - 2017-12-17 03:51:06.781614: step 12470, loss = 0.15, batch loss = 0.11 (36.8 examples/sec; 0.218 sec/batch; 19h:20m:47s remains)
INFO - root - 2017-12-17 03:51:09.025111: step 12480, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.224 sec/batch; 19h:53m:31s remains)
INFO - root - 2017-12-17 03:51:11.245520: step 12490, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 19h:55m:10s remains)
INFO - root - 2017-12-17 03:51:13.491111: step 12500, loss = 0.09, batch loss = 0.06 (35.3 examples/sec; 0.227 sec/batch; 20h:09m:15s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-12500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-12500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 03:51:16.472396: step 12510, loss = 0.09, batch loss = 0.06 (35.6 examples/sec; 0.225 sec/batch; 19h:58m:05s remains)
INFO - root - 2017-12-17 03:51:18.760710: step 12520, loss = 0.12, batch loss = 0.09 (34.2 examples/sec; 0.234 sec/batch; 20h:46m:11s remains)
INFO - root - 2017-12-17 03:51:21.022016: step 12530, loss = 0.12, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 19h:58m:33s remains)
INFO - root - 2017-12-17 03:51:23.275830: step 12540, loss = 0.11, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 19h:41m:11s remains)
INFO - root - 2017-12-17 03:51:25.490833: step 12550, loss = 0.14, batch loss = 0.10 (36.9 examples/sec; 0.217 sec/batch; 19h:15m:46s remains)
INFO - root - 2017-12-17 03:51:27.713073: step 12560, loss = 0.10, batch loss = 0.07 (35.0 examples/sec; 0.228 sec/batch; 20h:17m:16s remains)
INFO - root - 2017-12-17 03:51:29.967200: step 12570, loss = 0.12, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 19h:27m:07s remains)
INFO - root - 2017-12-17 03:51:32.216892: step 12580, loss = 0.17, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 19h:54m:25s remains)
INFO - root - 2017-12-17 03:51:34.414465: step 12590, loss = 0.10, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 19h:26m:21s remains)
INFO - root - 2017-12-17 03:51:36.620458: step 12600, loss = 0.13, batch loss = 0.10 (36.7 examples/sec; 0.218 sec/batch; 19h:23m:13s remains)
INFO - root - 2017-12-17 03:51:38.952295: step 12610, loss = 0.12, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 19h:43m:14s remains)
INFO - root - 2017-12-17 03:51:41.196279: step 12620, loss = 0.10, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 19h:24m:57s remains)
INFO - root - 2017-12-17 03:51:43.423573: step 12630, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 19h:34m:08s remains)
INFO - root - 2017-12-17 03:51:45.672853: step 12640, loss = 0.14, batch loss = 0.11 (37.1 examples/sec; 0.216 sec/batch; 19h:09m:11s remains)
INFO - root - 2017-12-17 03:51:47.953276: step 12650, loss = 0.13, batch loss = 0.09 (34.6 examples/sec; 0.231 sec/batch; 20h:31m:22s remains)
INFO - root - 2017-12-17 03:51:50.176927: step 12660, loss = 0.14, batch loss = 0.10 (36.7 examples/sec; 0.218 sec/batch; 19h:21m:56s remains)
INFO - root - 2017-12-17 03:51:52.364454: step 12670, loss = 0.11, batch loss = 0.08 (35.6 examples/sec; 0.224 sec/batch; 19h:56m:36s remains)
INFO - root - 2017-12-17 03:51:54.624212: step 12680, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.224 sec/batch; 19h:56m:29s remains)
INFO - root - 2017-12-17 03:51:56.841329: step 12690, loss = 0.12, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 19h:30m:05s remains)
INFO - root - 2017-12-17 03:51:59.087351: step 12700, loss = 0.12, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 19h:38m:27s remains)
INFO - root - 2017-12-17 03:52:01.427608: step 12710, loss = 0.13, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 19h:27m:13s remains)
INFO - root - 2017-12-17 03:52:03.661282: step 12720, loss = 0.19, batch loss = 0.16 (36.0 examples/sec; 0.222 sec/batch; 19h:43m:37s remains)
INFO - root - 2017-12-17 03:52:05.889923: step 12730, loss = 0.12, batch loss = 0.08 (37.8 examples/sec; 0.212 sec/batch; 18h:48m:12s remains)
INFO - root - 2017-12-17 03:52:08.117402: step 12740, loss = 0.10, batch loss = 0.06 (37.1 examples/sec; 0.216 sec/batch; 19h:10m:14s remains)
INFO - root - 2017-12-17 03:52:10.371063: step 12750, loss = 0.09, batch loss = 0.05 (35.3 examples/sec; 0.227 sec/batch; 20h:08m:32s remains)
INFO - root - 2017-12-17 03:52:12.638054: step 12760, loss = 0.11, batch loss = 0.07 (33.5 examples/sec; 0.239 sec/batch; 21h:12m:38s remains)
INFO - root - 2017-12-17 03:52:14.888461: step 12770, loss = 0.11, batch loss = 0.07 (34.8 examples/sec; 0.230 sec/batch; 20h:25m:35s remains)
INFO - root - 2017-12-17 03:52:17.139218: step 12780, loss = 0.13, batch loss = 0.09 (35.1 examples/sec; 0.228 sec/batch; 20h:15m:52s remains)
INFO - root - 2017-12-17 03:52:19.407193: step 12790, loss = 0.14, batch loss = 0.10 (35.8 examples/sec; 0.223 sec/batch; 19h:50m:41s remains)
INFO - root - 2017-12-17 03:52:21.662637: step 12800, loss = 0.20, batch loss = 0.16 (35.4 examples/sec; 0.226 sec/batch; 20h:03m:53s remains)
INFO - root - 2017-12-17 03:52:24.026500: step 12810, loss = 0.14, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 19h:55m:07s remains)
INFO - root - 2017-12-17 03:52:26.297177: step 12820, loss = 0.12, batch loss = 0.08 (35.2 examples/sec; 0.228 sec/batch; 20h:12m:19s remains)
INFO - root - 2017-12-17 03:52:28.540999: step 12830, loss = 0.12, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 19h:48m:07s remains)
INFO - root - 2017-12-17 03:52:30.753188: step 12840, loss = 0.14, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 19h:28m:18s remains)
INFO - root - 2017-12-17 03:52:32.964298: step 12850, loss = 0.18, batch loss = 0.14 (35.8 examples/sec; 0.224 sec/batch; 19h:50m:44s remains)
INFO - root - 2017-12-17 03:52:35.246569: step 12860, loss = 0.10, batch loss = 0.06 (34.5 examples/sec; 0.232 sec/batch; 20h:34m:48s remains)
INFO - root - 2017-12-17 03:52:37.503309: step 12870, loss = 0.13, batch loss = 0.09 (34.6 examples/sec; 0.231 sec/batch; 20h:30m:52s remains)
INFO - root - 2017-12-17 03:52:39.746817: step 12880, loss = 0.13, batch loss = 0.09 (36.3 examples/sec; 0.220 sec/batch; 19h:32m:24s remains)
INFO - root - 2017-12-17 03:52:41.993310: step 12890, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 19h:37m:57s remains)
INFO - root - 2017-12-17 03:52:44.198270: step 12900, loss = 0.11, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 19h:40m:25s remains)
INFO - root - 2017-12-17 03:52:46.544131: step 12910, loss = 0.11, batch loss = 0.07 (35.4 examples/sec; 0.226 sec/batch; 20h:03m:03s remains)
INFO - root - 2017-12-17 03:52:48.786707: step 12920, loss = 0.12, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 19h:38m:32s remains)
INFO - root - 2017-12-17 03:52:51.018006: step 12930, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.223 sec/batch; 19h:49m:58s remains)
INFO - root - 2017-12-17 03:52:53.265901: step 12940, loss = 0.13, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 20h:03m:03s remains)
INFO - root - 2017-12-17 03:52:55.496777: step 12950, loss = 0.13, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:44m:14s remains)
INFO - root - 2017-12-17 03:52:57.791992: step 12960, loss = 0.15, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 20h:13m:25s remains)
INFO - root - 2017-12-17 03:53:00.083938: step 12970, loss = 0.10, batch loss = 0.06 (35.3 examples/sec; 0.227 sec/batch; 20h:06m:43s remains)
INFO - root - 2017-12-17 03:53:02.355744: step 12980, loss = 0.09, batch loss = 0.06 (35.4 examples/sec; 0.226 sec/batch; 20h:03m:45s remains)
INFO - root - 2017-12-17 03:53:04.630560: step 12990, loss = 0.12, batch loss = 0.08 (33.6 examples/sec; 0.238 sec/batch; 21h:08m:28s remains)
INFO - root - 2017-12-17 03:53:06.847856: step 13000, loss = 0.14, batch loss = 0.11 (36.7 examples/sec; 0.218 sec/batch; 19h:21m:57s remains)
INFO - root - 2017-12-17 03:53:09.264694: step 13010, loss = 0.11, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 19h:24m:12s remains)
INFO - root - 2017-12-17 03:53:11.473114: step 13020, loss = 0.10, batch loss = 0.06 (35.1 examples/sec; 0.228 sec/batch; 20h:15m:09s remains)
INFO - root - 2017-12-17 03:53:13.716359: step 13030, loss = 0.12, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 19h:24m:22s remains)
INFO - root - 2017-12-17 03:53:15.935005: step 13040, loss = 0.13, batch loss = 0.09 (35.5 examples/sec; 0.225 sec/batch; 19h:58m:42s remains)
INFO - root - 2017-12-17 03:53:18.178408: step 13050, loss = 0.11, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 19h:52m:28s remains)
INFO - root - 2017-12-17 03:53:20.388637: step 13060, loss = 0.11, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 19h:27m:59s remains)
INFO - root - 2017-12-17 03:53:22.606515: step 13070, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 19h:53m:04s remains)
INFO - root - 2017-12-17 03:53:24.859013: step 13080, loss = 0.11, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 19h:54m:28s remains)
INFO - root - 2017-12-17 03:53:27.085307: step 13090, loss = 0.17, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 19h:51m:27s remains)
INFO - root - 2017-12-17 03:53:29.304890: step 13100, loss = 0.15, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 19h:29m:46s remains)
INFO - root - 2017-12-17 03:53:31.636241: step 13110, loss = 0.10, batch loss = 0.07 (37.2 examples/sec; 0.215 sec/batch; 19h:03m:50s remains)
INFO - root - 2017-12-17 03:53:33.871533: step 13120, loss = 0.14, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 20h:09m:11s remains)
INFO - root - 2017-12-17 03:53:36.099924: step 13130, loss = 0.12, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 19h:37m:21s remains)
INFO - root - 2017-12-17 03:53:38.315781: step 13140, loss = 0.12, batch loss = 0.09 (34.5 examples/sec; 0.232 sec/batch; 20h:35m:51s remains)
INFO - root - 2017-12-17 03:53:40.562768: step 13150, loss = 0.10, batch loss = 0.06 (37.0 examples/sec; 0.216 sec/batch; 19h:10m:41s remains)
INFO - root - 2017-12-17 03:53:42.807330: step 13160, loss = 0.14, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 19h:47m:04s remains)
INFO - root - 2017-12-17 03:53:45.068851: step 13170, loss = 0.10, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 19h:35m:41s remains)
INFO - root - 2017-12-17 03:53:47.336509: step 13180, loss = 0.13, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 19h:50m:29s remains)
INFO - root - 2017-12-17 03:53:49.557754: step 13190, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 19h:53m:05s remains)
INFO - root - 2017-12-17 03:53:51.791667: step 13200, loss = 0.10, batch loss = 0.06 (35.0 examples/sec; 0.228 sec/batch; 20h:15m:52s remains)
INFO - root - 2017-12-17 03:53:54.181555: step 13210, loss = 0.15, batch loss = 0.11 (36.3 examples/sec; 0.220 sec/batch; 19h:32m:33s remains)
INFO - root - 2017-12-17 03:53:56.434092: step 13220, loss = 0.13, batch loss = 0.09 (33.9 examples/sec; 0.236 sec/batch; 20h:57m:23s remains)
INFO - root - 2017-12-17 03:53:58.671004: step 13230, loss = 0.10, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 19h:25m:03s remains)
INFO - root - 2017-12-17 03:54:00.883124: step 13240, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 19h:32m:26s remains)
INFO - root - 2017-12-17 03:54:03.119857: step 13250, loss = 0.12, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 19h:34m:44s remains)
INFO - root - 2017-12-17 03:54:05.344105: step 13260, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 19h:53m:40s remains)
INFO - root - 2017-12-17 03:54:07.559521: step 13270, loss = 0.14, batch loss = 0.10 (36.7 examples/sec; 0.218 sec/batch; 19h:19m:08s remains)
INFO - root - 2017-12-17 03:54:09.795340: step 13280, loss = 0.17, batch loss = 0.14 (35.2 examples/sec; 0.227 sec/batch; 20h:07m:56s remains)
INFO - root - 2017-12-17 03:54:12.069617: step 13290, loss = 0.11, batch loss = 0.08 (34.4 examples/sec; 0.233 sec/batch; 20h:37m:13s remains)
INFO - root - 2017-12-17 03:54:14.322964: step 13300, loss = 0.15, batch loss = 0.11 (33.9 examples/sec; 0.236 sec/batch; 20h:54m:33s remains)
INFO - root - 2017-12-17 03:54:16.672853: step 13310, loss = 0.13, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 19h:30m:45s remains)
INFO - root - 2017-12-17 03:54:18.912247: step 13320, loss = 0.17, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 20h:00m:57s remains)
INFO - root - 2017-12-17 03:54:21.175357: step 13330, loss = 0.10, batch loss = 0.06 (37.1 examples/sec; 0.215 sec/batch; 19h:06m:16s remains)
INFO - root - 2017-12-17 03:54:23.399118: step 13340, loss = 0.13, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 19h:42m:09s remains)
INFO - root - 2017-12-17 03:54:25.688191: step 13350, loss = 0.11, batch loss = 0.07 (34.0 examples/sec; 0.235 sec/batch; 20h:52m:28s remains)
INFO - root - 2017-12-17 03:54:27.902951: step 13360, loss = 0.12, batch loss = 0.08 (36.7 examples/sec; 0.218 sec/batch; 19h:20m:19s remains)
INFO - root - 2017-12-17 03:54:30.112813: step 13370, loss = 0.10, batch loss = 0.07 (35.5 examples/sec; 0.225 sec/batch; 19h:57m:21s remains)
INFO - root - 2017-12-17 03:54:32.359112: step 13380, loss = 0.12, batch loss = 0.08 (35.3 examples/sec; 0.227 sec/batch; 20h:06m:42s remains)
INFO - root - 2017-12-17 03:54:34.564101: step 13390, loss = 0.15, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 19h:33m:58s remains)
INFO - root - 2017-12-17 03:54:36.773776: step 13400, loss = 0.12, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 19h:54m:53s remains)
INFO - root - 2017-12-17 03:54:39.146727: step 13410, loss = 0.13, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 19h:33m:43s remains)
INFO - root - 2017-12-17 03:54:41.374180: step 13420, loss = 0.11, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 19h:22m:51s remains)
INFO - root - 2017-12-17 03:54:43.600692: step 13430, loss = 0.12, batch loss = 0.08 (35.5 examples/sec; 0.225 sec/batch; 19h:57m:59s remains)
INFO - root - 2017-12-17 03:54:45.839909: step 13440, loss = 0.12, batch loss = 0.08 (35.3 examples/sec; 0.227 sec/batch; 20h:04m:38s remains)
INFO - root - 2017-12-17 03:54:48.057458: step 13450, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 19h:40m:46s remains)
INFO - root - 2017-12-17 03:54:50.272935: step 13460, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.221 sec/batch; 19h:32m:49s remains)
INFO - root - 2017-12-17 03:54:52.517489: step 13470, loss = 0.15, batch loss = 0.12 (35.5 examples/sec; 0.226 sec/batch; 19h:59m:16s remains)
INFO - root - 2017-12-17 03:54:54.770417: step 13480, loss = 0.11, batch loss = 0.07 (33.3 examples/sec; 0.240 sec/batch; 21h:16m:46s remains)
INFO - root - 2017-12-17 03:54:57.069682: step 13490, loss = 0.11, batch loss = 0.07 (35.1 examples/sec; 0.228 sec/batch; 20h:11m:43s remains)
INFO - root - 2017-12-17 03:54:59.290233: step 13500, loss = 0.11, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 19h:19m:22s remains)
INFO - root - 2017-12-17 03:55:01.618219: step 13510, loss = 0.11, batch loss = 0.08 (35.2 examples/sec; 0.227 sec/batch; 20h:07m:22s remains)
INFO - root - 2017-12-17 03:55:03.847651: step 13520, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 20h:07m:06s remains)
INFO - root - 2017-12-17 03:55:06.112786: step 13530, loss = 0.12, batch loss = 0.08 (34.8 examples/sec; 0.230 sec/batch; 20h:21m:31s remains)
INFO - root - 2017-12-17 03:55:08.337315: step 13540, loss = 0.10, batch loss = 0.07 (34.9 examples/sec; 0.229 sec/batch; 20h:18m:37s remains)
INFO - root - 2017-12-17 03:55:10.571247: step 13550, loss = 0.16, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 19h:44m:52s remains)
INFO - root - 2017-12-17 03:55:12.815360: step 13560, loss = 0.14, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 19h:22m:00s remains)
INFO - root - 2017-12-17 03:55:15.065168: step 13570, loss = 0.13, batch loss = 0.10 (35.1 examples/sec; 0.228 sec/batch; 20h:11m:28s remains)
INFO - root - 2017-12-17 03:55:17.332081: step 13580, loss = 0.09, batch loss = 0.06 (34.5 examples/sec; 0.232 sec/batch; 20h:31m:49s remains)
INFO - root - 2017-12-17 03:55:19.575344: step 13590, loss = 0.26, batch loss = 0.22 (36.0 examples/sec; 0.222 sec/batch; 19h:41m:29s remains)
INFO - root - 2017-12-17 03:55:21.839766: step 13600, loss = 0.12, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 19h:50m:05s remains)
INFO - root - 2017-12-17 03:55:24.168732: step 13610, loss = 0.13, batch loss = 0.10 (34.2 examples/sec; 0.234 sec/batch; 20h:44m:30s remains)
INFO - root - 2017-12-17 03:55:26.405493: step 13620, loss = 0.14, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 19h:35m:02s remains)
INFO - root - 2017-12-17 03:55:28.666247: step 13630, loss = 0.13, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 19h:53m:38s remains)
INFO - root - 2017-12-17 03:55:30.986238: step 13640, loss = 0.15, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 20h:19m:02s remains)
INFO - root - 2017-12-17 03:55:33.246609: step 13650, loss = 0.19, batch loss = 0.16 (35.0 examples/sec; 0.229 sec/batch; 20h:15m:28s remains)
INFO - root - 2017-12-17 03:55:35.456679: step 13660, loss = 0.16, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 19h:48m:48s remains)
INFO - root - 2017-12-17 03:55:37.692097: step 13670, loss = 0.12, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 19h:54m:32s remains)
INFO - root - 2017-12-17 03:55:39.920296: step 13680, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 19h:34m:39s remains)
INFO - root - 2017-12-17 03:55:42.157385: step 13690, loss = 0.13, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 19h:29m:15s remains)
INFO - root - 2017-12-17 03:55:44.385003: step 13700, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 19h:38m:33s remains)
INFO - root - 2017-12-17 03:55:46.728353: step 13710, loss = 0.12, batch loss = 0.09 (35.8 examples/sec; 0.224 sec/batch; 19h:48m:54s remains)
INFO - root - 2017-12-17 03:55:48.943233: step 13720, loss = 0.12, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:39m:39s remains)
INFO - root - 2017-12-17 03:55:51.198874: step 13730, loss = 0.10, batch loss = 0.06 (35.4 examples/sec; 0.226 sec/batch; 20h:01m:40s remains)
INFO - root - 2017-12-17 03:55:53.453101: step 13740, loss = 0.14, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 19h:49m:00s remains)
INFO - root - 2017-12-17 03:55:55.713871: step 13750, loss = 0.15, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 19h:38m:23s remains)
INFO - root - 2017-12-17 03:55:57.987432: step 13760, loss = 0.10, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 19h:43m:41s remains)
INFO - root - 2017-12-17 03:56:00.199650: step 13770, loss = 0.10, batch loss = 0.06 (34.3 examples/sec; 0.233 sec/batch; 20h:40m:07s remains)
INFO - root - 2017-12-17 03:56:02.441070: step 13780, loss = 0.12, batch loss = 0.09 (34.6 examples/sec; 0.231 sec/batch; 20h:28m:28s remains)
INFO - root - 2017-12-17 03:56:04.731697: step 13790, loss = 0.11, batch loss = 0.07 (34.0 examples/sec; 0.235 sec/batch; 20h:48m:22s remains)
INFO - root - 2017-12-17 03:56:07.037959: step 13800, loss = 0.11, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 19h:54m:13s remains)
INFO - root - 2017-12-17 03:56:09.450477: step 13810, loss = 0.10, batch loss = 0.07 (35.5 examples/sec; 0.225 sec/batch; 19h:57m:37s remains)
INFO - root - 2017-12-17 03:56:11.672362: step 13820, loss = 0.14, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 19h:42m:21s remains)
INFO - root - 2017-12-17 03:56:13.881719: step 13830, loss = 0.17, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 19h:41m:24s remains)
INFO - root - 2017-12-17 03:56:16.113425: step 13840, loss = 0.11, batch loss = 0.08 (34.5 examples/sec; 0.232 sec/batch; 20h:32m:50s remains)
INFO - root - 2017-12-17 03:56:18.332550: step 13850, loss = 0.08, batch loss = 0.05 (36.2 examples/sec; 0.221 sec/batch; 19h:33m:30s remains)
INFO - root - 2017-12-17 03:56:20.592119: step 13860, loss = 0.11, batch loss = 0.08 (35.6 examples/sec; 0.224 sec/batch; 19h:52m:09s remains)
INFO - root - 2017-12-17 03:56:22.818157: step 13870, loss = 0.12, batch loss = 0.08 (36.3 examples/sec; 0.221 sec/batch; 19h:31m:09s remains)
INFO - root - 2017-12-17 03:56:25.045297: step 13880, loss = 0.12, batch loss = 0.08 (36.8 examples/sec; 0.217 sec/batch; 19h:13m:23s remains)
INFO - root - 2017-12-17 03:56:27.284857: step 13890, loss = 0.11, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 19h:38m:46s remains)
INFO - root - 2017-12-17 03:56:29.537189: step 13900, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 19h:33m:22s remains)
INFO - root - 2017-12-17 03:56:31.906583: step 13910, loss = 0.11, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 19h:49m:42s remains)
INFO - root - 2017-12-17 03:56:34.188470: step 13920, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 20h:05m:09s remains)
INFO - root - 2017-12-17 03:56:36.432595: step 13930, loss = 0.14, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 19h:53m:43s remains)
INFO - root - 2017-12-17 03:56:38.750848: step 13940, loss = 0.11, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 19h:36m:48s remains)
INFO - root - 2017-12-17 03:56:40.973256: step 13950, loss = 0.09, batch loss = 0.06 (37.2 examples/sec; 0.215 sec/batch; 19h:00m:29s remains)
INFO - root - 2017-12-17 03:56:43.195680: step 13960, loss = 0.10, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 19h:44m:25s remains)
INFO - root - 2017-12-17 03:56:45.438953: step 13970, loss = 0.11, batch loss = 0.08 (34.1 examples/sec; 0.234 sec/batch; 20h:44m:12s remains)
INFO - root - 2017-12-17 03:56:47.699264: step 13980, loss = 0.10, batch loss = 0.06 (33.5 examples/sec; 0.239 sec/batch; 21h:08m:21s remains)
INFO - root - 2017-12-17 03:56:49.940320: step 13990, loss = 0.10, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 19h:43m:54s remains)
INFO - root - 2017-12-17 03:56:52.156841: step 14000, loss = 0.13, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:44m:17s remains)
INFO - root - 2017-12-17 03:56:54.509546: step 14010, loss = 0.13, batch loss = 0.09 (35.5 examples/sec; 0.225 sec/batch; 19h:56m:01s remains)
INFO - root - 2017-12-17 03:56:56.808777: step 14020, loss = 0.12, batch loss = 0.09 (34.4 examples/sec; 0.233 sec/batch; 20h:35m:30s remains)
INFO - root - 2017-12-17 03:56:59.027568: step 14030, loss = 0.09, batch loss = 0.06 (34.7 examples/sec; 0.231 sec/batch; 20h:25m:04s remains)
INFO - root - 2017-12-17 03:57:01.319278: step 14040, loss = 0.13, batch loss = 0.10 (37.1 examples/sec; 0.216 sec/batch; 19h:05m:43s remains)
INFO - root - 2017-12-17 03:57:03.553546: step 14050, loss = 0.14, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 20h:32m:23s remains)
INFO - root - 2017-12-17 03:57:05.773490: step 14060, loss = 0.14, batch loss = 0.11 (35.2 examples/sec; 0.227 sec/batch; 20h:07m:01s remains)
INFO - root - 2017-12-17 03:57:08.014869: step 14070, loss = 0.13, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 19h:21m:31s remains)
INFO - root - 2017-12-17 03:57:10.266428: step 14080, loss = 0.09, batch loss = 0.06 (34.5 examples/sec; 0.232 sec/batch; 20h:30m:37s remains)
INFO - root - 2017-12-17 03:57:12.518746: step 14090, loss = 0.13, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 19h:46m:47s remains)
INFO - root - 2017-12-17 03:57:14.769200: step 14100, loss = 0.10, batch loss = 0.06 (34.9 examples/sec; 0.229 sec/batch; 20h:16m:56s remains)
INFO - root - 2017-12-17 03:57:17.137441: step 14110, loss = 0.13, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 19h:27m:39s remains)
INFO - root - 2017-12-17 03:57:19.364524: step 14120, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 20h:06m:38s remains)
INFO - root - 2017-12-17 03:57:21.621725: step 14130, loss = 0.13, batch loss = 0.10 (37.6 examples/sec; 0.213 sec/batch; 18h:48m:39s remains)
INFO - root - 2017-12-17 03:57:23.887380: step 14140, loss = 0.11, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 19h:26m:20s remains)
INFO - root - 2017-12-17 03:57:26.105792: step 14150, loss = 0.11, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 19h:18m:00s remains)
INFO - root - 2017-12-17 03:57:28.372928: step 14160, loss = 0.13, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 19h:48m:25s remains)
INFO - root - 2017-12-17 03:57:30.616892: step 14170, loss = 0.11, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 19h:27m:13s remains)
INFO - root - 2017-12-17 03:57:32.862627: step 14180, loss = 0.12, batch loss = 0.09 (35.1 examples/sec; 0.228 sec/batch; 20h:09m:02s remains)
INFO - root - 2017-12-17 03:57:35.099544: step 14190, loss = 0.09, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 19h:22m:24s remains)
INFO - root - 2017-12-17 03:57:37.368278: step 14200, loss = 0.12, batch loss = 0.09 (34.8 examples/sec; 0.230 sec/batch; 20h:21m:08s remains)
INFO - root - 2017-12-17 03:57:39.741317: step 14210, loss = 0.11, batch loss = 0.08 (34.5 examples/sec; 0.232 sec/batch; 20h:30m:05s remains)
INFO - root - 2017-12-17 03:57:41.968426: step 14220, loss = 0.10, batch loss = 0.06 (35.3 examples/sec; 0.226 sec/batch; 20h:01m:15s remains)
INFO - root - 2017-12-17 03:57:44.171894: step 14230, loss = 0.12, batch loss = 0.08 (37.2 examples/sec; 0.215 sec/batch; 19h:00m:34s remains)
INFO - root - 2017-12-17 03:57:46.392680: step 14240, loss = 0.13, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 20h:19m:26s remains)
INFO - root - 2017-12-17 03:57:48.638074: step 14250, loss = 0.15, batch loss = 0.11 (36.6 examples/sec; 0.219 sec/batch; 19h:20m:28s remains)
INFO - root - 2017-12-17 03:57:50.892360: step 14260, loss = 0.12, batch loss = 0.09 (34.8 examples/sec; 0.230 sec/batch; 20h:20m:25s remains)
INFO - root - 2017-12-17 03:57:53.140241: step 14270, loss = 0.14, batch loss = 0.10 (37.0 examples/sec; 0.216 sec/batch; 19h:05m:57s remains)
INFO - root - 2017-12-17 03:57:55.343223: step 14280, loss = 0.12, batch loss = 0.09 (37.0 examples/sec; 0.216 sec/batch; 19h:06m:28s remains)
INFO - root - 2017-12-17 03:57:57.554785: step 14290, loss = 0.15, batch loss = 0.11 (36.7 examples/sec; 0.218 sec/batch; 19h:17m:21s remains)
INFO - root - 2017-12-17 03:57:59.751456: step 14300, loss = 0.14, batch loss = 0.10 (36.8 examples/sec; 0.217 sec/batch; 19h:12m:02s remains)
INFO - root - 2017-12-17 03:58:02.098308: step 14310, loss = 0.10, batch loss = 0.07 (37.1 examples/sec; 0.216 sec/batch; 19h:03m:51s remains)
INFO - root - 2017-12-17 03:58:04.344260: step 14320, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 20h:06m:09s remains)
INFO - root - 2017-12-17 03:58:06.574337: step 14330, loss = 0.13, batch loss = 0.09 (37.3 examples/sec; 0.215 sec/batch; 18h:58m:19s remains)
INFO - root - 2017-12-17 03:58:08.837881: step 14340, loss = 0.13, batch loss = 0.10 (36.1 examples/sec; 0.221 sec/batch; 19h:33m:31s remains)
INFO - root - 2017-12-17 03:58:11.053804: step 14350, loss = 0.13, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 19h:28m:52s remains)
INFO - root - 2017-12-17 03:58:13.251588: step 14360, loss = 0.10, batch loss = 0.06 (37.0 examples/sec; 0.216 sec/batch; 19h:07m:54s remains)
INFO - root - 2017-12-17 03:58:15.496495: step 14370, loss = 0.12, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 19h:47m:24s remains)
INFO - root - 2017-12-17 03:58:17.691278: step 14380, loss = 0.13, batch loss = 0.09 (35.8 examples/sec; 0.224 sec/batch; 19h:45m:41s remains)
INFO - root - 2017-12-17 03:58:19.942712: step 14390, loss = 0.14, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 20h:01m:20s remains)
INFO - root - 2017-12-17 03:58:22.156691: step 14400, loss = 0.10, batch loss = 0.06 (35.4 examples/sec; 0.226 sec/batch; 19h:56m:26s remains)
INFO - root - 2017-12-17 03:58:24.502169: step 14410, loss = 0.09, batch loss = 0.05 (36.1 examples/sec; 0.221 sec/batch; 19h:34m:02s remains)
INFO - root - 2017-12-17 03:58:26.731025: step 14420, loss = 0.11, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 19h:51m:28s remains)
INFO - root - 2017-12-17 03:58:28.981707: step 14430, loss = 0.12, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 19h:31m:46s remains)
INFO - root - 2017-12-17 03:58:31.220307: step 14440, loss = 0.10, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 19h:25m:48s remains)
INFO - root - 2017-12-17 03:58:33.495046: step 14450, loss = 0.13, batch loss = 0.09 (34.6 examples/sec; 0.231 sec/batch; 20h:24m:17s remains)
INFO - root - 2017-12-17 03:58:35.732960: step 14460, loss = 0.11, batch loss = 0.08 (34.6 examples/sec; 0.231 sec/batch; 20h:25m:55s remains)
INFO - root - 2017-12-17 03:58:37.994877: step 14470, loss = 0.11, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 19h:20m:18s remains)
INFO - root - 2017-12-17 03:58:40.245735: step 14480, loss = 0.12, batch loss = 0.08 (34.4 examples/sec; 0.233 sec/batch; 20h:33m:57s remains)
INFO - root - 2017-12-17 03:58:42.482428: step 14490, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 19h:45m:52s remains)
INFO - root - 2017-12-17 03:58:44.745026: step 14500, loss = 0.11, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 19h:51m:18s remains)
INFO - root - 2017-12-17 03:58:47.091690: step 14510, loss = 0.11, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 19h:21m:54s remains)
INFO - root - 2017-12-17 03:58:49.286067: step 14520, loss = 0.15, batch loss = 0.11 (36.9 examples/sec; 0.217 sec/batch; 19h:09m:07s remains)
INFO - root - 2017-12-17 03:58:51.520731: step 14530, loss = 0.12, batch loss = 0.09 (35.3 examples/sec; 0.227 sec/batch; 20h:00m:43s remains)
INFO - root - 2017-12-17 03:58:53.789319: step 14540, loss = 0.11, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 20h:02m:48s remains)
INFO - root - 2017-12-17 03:58:56.014413: step 14550, loss = 0.11, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 19h:50m:00s remains)
INFO - root - 2017-12-17 03:58:58.253135: step 14560, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 19h:45m:15s remains)
INFO - root - 2017-12-17 03:59:00.484304: step 14570, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.224 sec/batch; 19h:44m:36s remains)
INFO - root - 2017-12-17 03:59:02.709056: step 14580, loss = 0.15, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 20h:14m:12s remains)
INFO - root - 2017-12-17 03:59:04.958739: step 14590, loss = 0.10, batch loss = 0.06 (35.8 examples/sec; 0.224 sec/batch; 19h:44m:37s remains)
INFO - root - 2017-12-17 03:59:07.182891: step 14600, loss = 0.12, batch loss = 0.08 (36.8 examples/sec; 0.217 sec/batch; 19h:11m:04s remains)
INFO - root - 2017-12-17 03:59:09.550056: step 14610, loss = 0.11, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 19h:19m:34s remains)
INFO - root - 2017-12-17 03:59:11.809481: step 14620, loss = 0.11, batch loss = 0.07 (34.5 examples/sec; 0.232 sec/batch; 20h:29m:44s remains)
INFO - root - 2017-12-17 03:59:14.054895: step 14630, loss = 0.12, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 19h:48m:34s remains)
INFO - root - 2017-12-17 03:59:16.298321: step 14640, loss = 0.12, batch loss = 0.08 (34.6 examples/sec; 0.231 sec/batch; 20h:24m:17s remains)
INFO - root - 2017-12-17 03:59:18.567826: step 14650, loss = 0.14, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 20h:16m:10s remains)
INFO - root - 2017-12-17 03:59:20.819940: step 14660, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 19h:47m:45s remains)
INFO - root - 2017-12-17 03:59:23.052923: step 14670, loss = 0.10, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 19h:21m:08s remains)
INFO - root - 2017-12-17 03:59:25.265569: step 14680, loss = 0.10, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 19h:41m:48s remains)
INFO - root - 2017-12-17 03:59:27.517841: step 14690, loss = 0.11, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 19h:38m:25s remains)
INFO - root - 2017-12-17 03:59:29.759888: step 14700, loss = 0.16, batch loss = 0.12 (35.3 examples/sec; 0.226 sec/batch; 19h:58m:59s remains)
INFO - root - 2017-12-17 03:59:32.143906: step 14710, loss = 0.11, batch loss = 0.08 (36.3 examples/sec; 0.220 sec/batch; 19h:27m:41s remains)
INFO - root - 2017-12-17 03:59:34.352531: step 14720, loss = 0.11, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 19h:13m:41s remains)
INFO - root - 2017-12-17 03:59:36.582962: step 14730, loss = 0.11, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 19h:34m:15s remains)
INFO - root - 2017-12-17 03:59:38.797661: step 14740, loss = 0.12, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 19h:21m:07s remains)
INFO - root - 2017-12-17 03:59:41.004964: step 14750, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 19h:27m:03s remains)
INFO - root - 2017-12-17 03:59:43.213583: step 14760, loss = 0.10, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 19h:33m:36s remains)
INFO - root - 2017-12-17 03:59:45.464941: step 14770, loss = 0.13, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 19h:31m:06s remains)
INFO - root - 2017-12-17 03:59:47.707660: step 14780, loss = 0.13, batch loss = 0.09 (35.0 examples/sec; 0.229 sec/batch; 20h:11m:12s remains)
INFO - root - 2017-12-17 03:59:49.959829: step 14790, loss = 0.15, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 19h:25m:10s remains)
INFO - root - 2017-12-17 03:59:52.199328: step 14800, loss = 0.11, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 19h:36m:58s remains)
INFO - root - 2017-12-17 03:59:54.596472: step 14810, loss = 0.14, batch loss = 0.10 (34.3 examples/sec; 0.234 sec/batch; 20h:36m:23s remains)
INFO - root - 2017-12-17 03:59:56.865399: step 14820, loss = 0.09, batch loss = 0.05 (35.4 examples/sec; 0.226 sec/batch; 19h:58m:11s remains)
INFO - root - 2017-12-17 03:59:59.103464: step 14830, loss = 0.11, batch loss = 0.07 (35.4 examples/sec; 0.226 sec/batch; 19h:55m:01s remains)
INFO - root - 2017-12-17 04:00:01.338473: step 14840, loss = 0.14, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 19h:25m:59s remains)
INFO - root - 2017-12-17 04:00:03.575413: step 14850, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 19h:29m:33s remains)
INFO - root - 2017-12-17 04:00:05.822009: step 14860, loss = 0.09, batch loss = 0.05 (35.8 examples/sec; 0.224 sec/batch; 19h:43m:42s remains)
INFO - root - 2017-12-17 04:00:08.066051: step 14870, loss = 0.10, batch loss = 0.06 (34.8 examples/sec; 0.230 sec/batch; 20h:18m:30s remains)
INFO - root - 2017-12-17 04:00:10.335583: step 14880, loss = 0.12, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:35m:33s remains)
INFO - root - 2017-12-17 04:00:12.597850: step 14890, loss = 0.09, batch loss = 0.06 (35.2 examples/sec; 0.227 sec/batch; 20h:01m:32s remains)
INFO - root - 2017-12-17 04:00:14.840836: step 14900, loss = 0.10, batch loss = 0.07 (35.4 examples/sec; 0.226 sec/batch; 19h:56m:15s remains)
INFO - root - 2017-12-17 04:00:17.202612: step 14910, loss = 0.11, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 19h:38m:08s remains)
INFO - root - 2017-12-17 04:00:19.431117: step 14920, loss = 0.11, batch loss = 0.07 (35.5 examples/sec; 0.225 sec/batch; 19h:52m:47s remains)
INFO - root - 2017-12-17 04:00:21.677427: step 14930, loss = 0.11, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 19h:30m:43s remains)
INFO - root - 2017-12-17 04:00:23.908976: step 14940, loss = 0.12, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 19h:20m:26s remains)
INFO - root - 2017-12-17 04:00:26.154041: step 14950, loss = 0.12, batch loss = 0.09 (35.3 examples/sec; 0.226 sec/batch; 19h:58m:40s remains)
INFO - root - 2017-12-17 04:00:28.377937: step 14960, loss = 0.12, batch loss = 0.09 (36.3 examples/sec; 0.220 sec/batch; 19h:25m:18s remains)
INFO - root - 2017-12-17 04:00:30.576436: step 14970, loss = 0.13, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 20h:00m:56s remains)
INFO - root - 2017-12-17 04:00:32.862055: step 14980, loss = 0.11, batch loss = 0.07 (35.5 examples/sec; 0.225 sec/batch; 19h:51m:26s remains)
INFO - root - 2017-12-17 04:00:35.088375: step 14990, loss = 0.12, batch loss = 0.08 (35.3 examples/sec; 0.227 sec/batch; 20h:00m:04s remains)
INFO - root - 2017-12-17 04:00:37.321830: step 15000, loss = 0.11, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 19h:24m:54s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-15000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-15000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 04:00:40.197372: step 15010, loss = 0.12, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 19h:38m:50s remains)
INFO - root - 2017-12-17 04:00:42.389192: step 15020, loss = 0.15, batch loss = 0.11 (36.6 examples/sec; 0.219 sec/batch; 19h:18m:08s remains)
INFO - root - 2017-12-17 04:00:44.643615: step 15030, loss = 0.11, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 19h:26m:04s remains)
INFO - root - 2017-12-17 04:00:46.869552: step 15040, loss = 0.09, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 19h:40m:01s remains)
INFO - root - 2017-12-17 04:00:49.110074: step 15050, loss = 0.11, batch loss = 0.07 (34.7 examples/sec; 0.230 sec/batch; 20h:19m:31s remains)
INFO - root - 2017-12-17 04:00:51.369922: step 15060, loss = 0.10, batch loss = 0.06 (35.6 examples/sec; 0.225 sec/batch; 19h:47m:49s remains)
INFO - root - 2017-12-17 04:00:53.659394: step 15070, loss = 0.12, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 19h:29m:59s remains)
INFO - root - 2017-12-17 04:00:55.893894: step 15080, loss = 0.18, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 19h:30m:13s remains)
INFO - root - 2017-12-17 04:00:58.113484: step 15090, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 19h:36m:42s remains)
INFO - root - 2017-12-17 04:01:00.347104: step 15100, loss = 0.13, batch loss = 0.09 (36.3 examples/sec; 0.220 sec/batch; 19h:25m:14s remains)
INFO - root - 2017-12-17 04:01:02.695975: step 15110, loss = 0.12, batch loss = 0.09 (36.8 examples/sec; 0.217 sec/batch; 19h:10m:03s remains)
INFO - root - 2017-12-17 04:01:04.951649: step 15120, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.224 sec/batch; 19h:42m:34s remains)
INFO - root - 2017-12-17 04:01:07.209995: step 15130, loss = 0.13, batch loss = 0.09 (34.5 examples/sec; 0.232 sec/batch; 20h:27m:43s remains)
INFO - root - 2017-12-17 04:01:09.472537: step 15140, loss = 0.14, batch loss = 0.11 (34.1 examples/sec; 0.234 sec/batch; 20h:39m:36s remains)
INFO - root - 2017-12-17 04:01:11.668609: step 15150, loss = 0.12, batch loss = 0.08 (37.2 examples/sec; 0.215 sec/batch; 18h:56m:13s remains)
INFO - root - 2017-12-17 04:01:13.868759: step 15160, loss = 0.11, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 19h:46m:14s remains)
INFO - root - 2017-12-17 04:01:16.087368: step 15170, loss = 0.10, batch loss = 0.07 (36.6 examples/sec; 0.218 sec/batch; 19h:15m:06s remains)
INFO - root - 2017-12-17 04:01:18.314827: step 15180, loss = 0.17, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 19h:37m:31s remains)
INFO - root - 2017-12-17 04:01:20.528196: step 15190, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 19h:45m:18s remains)
INFO - root - 2017-12-17 04:01:22.788957: step 15200, loss = 0.12, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 19h:37m:35s remains)
INFO - root - 2017-12-17 04:01:25.135707: step 15210, loss = 0.16, batch loss = 0.12 (36.8 examples/sec; 0.218 sec/batch; 19h:10m:19s remains)
INFO - root - 2017-12-17 04:01:27.317358: step 15220, loss = 0.11, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 19h:28m:15s remains)
INFO - root - 2017-12-17 04:01:29.541345: step 15230, loss = 0.11, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 19h:47m:40s remains)
INFO - root - 2017-12-17 04:01:31.747185: step 15240, loss = 0.20, batch loss = 0.17 (36.5 examples/sec; 0.219 sec/batch; 19h:20m:01s remains)
INFO - root - 2017-12-17 04:01:33.968126: step 15250, loss = 0.13, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 19h:23m:05s remains)
INFO - root - 2017-12-17 04:01:36.197401: step 15260, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 19h:29m:50s remains)
INFO - root - 2017-12-17 04:01:38.416403: step 15270, loss = 0.14, batch loss = 0.10 (36.3 examples/sec; 0.221 sec/batch; 19h:26m:05s remains)
INFO - root - 2017-12-17 04:01:40.634731: step 15280, loss = 0.14, batch loss = 0.10 (37.3 examples/sec; 0.215 sec/batch; 18h:54m:13s remains)
INFO - root - 2017-12-17 04:01:42.868968: step 15290, loss = 0.12, batch loss = 0.08 (37.1 examples/sec; 0.216 sec/batch; 19h:00m:38s remains)
INFO - root - 2017-12-17 04:01:45.117198: step 15300, loss = 0.09, batch loss = 0.06 (35.2 examples/sec; 0.227 sec/batch; 20h:00m:51s remains)
INFO - root - 2017-12-17 04:01:47.458177: step 15310, loss = 0.10, batch loss = 0.07 (37.4 examples/sec; 0.214 sec/batch; 18h:50m:46s remains)
INFO - root - 2017-12-17 04:01:49.656020: step 15320, loss = 0.10, batch loss = 0.06 (36.8 examples/sec; 0.217 sec/batch; 19h:08m:54s remains)
INFO - root - 2017-12-17 04:01:51.857303: step 15330, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.223 sec/batch; 19h:40m:13s remains)
INFO - root - 2017-12-17 04:01:54.085975: step 15340, loss = 0.13, batch loss = 0.09 (36.9 examples/sec; 0.217 sec/batch; 19h:05m:52s remains)
INFO - root - 2017-12-17 04:01:56.291778: step 15350, loss = 0.11, batch loss = 0.07 (36.8 examples/sec; 0.218 sec/batch; 19h:10m:01s remains)
INFO - root - 2017-12-17 04:01:58.533663: step 15360, loss = 0.14, batch loss = 0.10 (35.3 examples/sec; 0.226 sec/batch; 19h:56m:56s remains)
INFO - root - 2017-12-17 04:02:00.797495: step 15370, loss = 0.13, batch loss = 0.09 (35.8 examples/sec; 0.224 sec/batch; 19h:42m:25s remains)
INFO - root - 2017-12-17 04:02:03.005795: step 15380, loss = 0.14, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 19h:21m:16s remains)
INFO - root - 2017-12-17 04:02:05.200307: step 15390, loss = 0.11, batch loss = 0.07 (37.4 examples/sec; 0.214 sec/batch; 18h:49m:34s remains)
INFO - root - 2017-12-17 04:02:07.406554: step 15400, loss = 0.10, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 19h:45m:56s remains)
INFO - root - 2017-12-17 04:02:09.762169: step 15410, loss = 0.17, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 19h:27m:38s remains)
INFO - root - 2017-12-17 04:02:12.018606: step 15420, loss = 0.13, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 20h:13m:19s remains)
INFO - root - 2017-12-17 04:02:14.260203: step 15430, loss = 0.14, batch loss = 0.10 (34.5 examples/sec; 0.232 sec/batch; 20h:24m:19s remains)
INFO - root - 2017-12-17 04:02:16.476378: step 15440, loss = 0.13, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:34m:45s remains)
INFO - root - 2017-12-17 04:02:18.698580: step 15450, loss = 0.11, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 19h:21m:11s remains)
INFO - root - 2017-12-17 04:02:20.918493: step 15460, loss = 0.14, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 19h:17m:06s remains)
INFO - root - 2017-12-17 04:02:23.172341: step 15470, loss = 0.09, batch loss = 0.05 (36.5 examples/sec; 0.219 sec/batch; 19h:18m:34s remains)
INFO - root - 2017-12-17 04:02:25.388326: step 15480, loss = 0.12, batch loss = 0.09 (35.0 examples/sec; 0.229 sec/batch; 20h:07m:35s remains)
INFO - root - 2017-12-17 04:02:27.631497: step 15490, loss = 0.11, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 19h:33m:36s remains)
INFO - root - 2017-12-17 04:02:29.888587: step 15500, loss = 0.11, batch loss = 0.07 (35.0 examples/sec; 0.228 sec/batch; 20h:06m:47s remains)
INFO - root - 2017-12-17 04:02:32.228098: step 15510, loss = 0.20, batch loss = 0.16 (36.0 examples/sec; 0.222 sec/batch; 19h:33m:19s remains)
INFO - root - 2017-12-17 04:02:34.488261: step 15520, loss = 0.12, batch loss = 0.09 (35.1 examples/sec; 0.228 sec/batch; 20h:04m:30s remains)
INFO - root - 2017-12-17 04:02:36.765066: step 15530, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 19h:30m:12s remains)
INFO - root - 2017-12-17 04:02:38.966324: step 15540, loss = 0.11, batch loss = 0.08 (36.7 examples/sec; 0.218 sec/batch; 19h:10m:44s remains)
INFO - root - 2017-12-17 04:02:41.172314: step 15550, loss = 0.11, batch loss = 0.07 (36.3 examples/sec; 0.221 sec/batch; 19h:25m:28s remains)
INFO - root - 2017-12-17 04:02:43.393248: step 15560, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 19h:22m:45s remains)
INFO - root - 2017-12-17 04:02:45.619920: step 15570, loss = 0.10, batch loss = 0.06 (35.2 examples/sec; 0.227 sec/batch; 20h:00m:32s remains)
INFO - root - 2017-12-17 04:02:47.822827: step 15580, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 19h:41m:10s remains)
INFO - root - 2017-12-17 04:02:50.073419: step 15590, loss = 0.10, batch loss = 0.07 (35.3 examples/sec; 0.227 sec/batch; 19h:57m:51s remains)
INFO - root - 2017-12-17 04:02:52.312798: step 15600, loss = 0.14, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:36m:09s remains)
INFO - root - 2017-12-17 04:02:54.672323: step 15610, loss = 0.11, batch loss = 0.08 (36.3 examples/sec; 0.221 sec/batch; 19h:25m:00s remains)
INFO - root - 2017-12-17 04:02:56.921664: step 15620, loss = 0.13, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 19h:49m:31s remains)
INFO - root - 2017-12-17 04:02:59.156216: step 15630, loss = 0.11, batch loss = 0.08 (37.0 examples/sec; 0.217 sec/batch; 19h:03m:23s remains)
INFO - root - 2017-12-17 04:03:01.352728: step 15640, loss = 0.16, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 19h:23m:58s remains)
INFO - root - 2017-12-17 04:03:03.610757: step 15650, loss = 0.11, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 19h:46m:23s remains)
INFO - root - 2017-12-17 04:03:05.856663: step 15660, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 19h:26m:38s remains)
INFO - root - 2017-12-17 04:03:08.112376: step 15670, loss = 0.12, batch loss = 0.08 (34.8 examples/sec; 0.230 sec/batch; 20h:12m:40s remains)
INFO - root - 2017-12-17 04:03:10.340109: step 15680, loss = 0.10, batch loss = 0.07 (36.8 examples/sec; 0.217 sec/batch; 19h:08m:12s remains)
INFO - root - 2017-12-17 04:03:12.563502: step 15690, loss = 0.11, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 19h:19m:46s remains)
INFO - root - 2017-12-17 04:03:14.800487: step 15700, loss = 0.15, batch loss = 0.11 (36.7 examples/sec; 0.218 sec/batch; 19h:11m:17s remains)
INFO - root - 2017-12-17 04:03:17.171196: step 15710, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.223 sec/batch; 19h:39m:49s remains)
INFO - root - 2017-12-17 04:03:19.399082: step 15720, loss = 0.15, batch loss = 0.11 (36.7 examples/sec; 0.218 sec/batch; 19h:10m:59s remains)
INFO - root - 2017-12-17 04:03:21.623173: step 15730, loss = 0.11, batch loss = 0.08 (36.3 examples/sec; 0.221 sec/batch; 19h:24m:45s remains)
INFO - root - 2017-12-17 04:03:23.827943: step 15740, loss = 0.14, batch loss = 0.10 (37.1 examples/sec; 0.216 sec/batch; 18h:58m:05s remains)
INFO - root - 2017-12-17 04:03:25.998536: step 15750, loss = 0.13, batch loss = 0.10 (37.1 examples/sec; 0.215 sec/batch; 18h:56m:51s remains)
INFO - root - 2017-12-17 04:03:28.231740: step 15760, loss = 0.10, batch loss = 0.07 (34.5 examples/sec; 0.232 sec/batch; 20h:23m:48s remains)
INFO - root - 2017-12-17 04:03:30.422390: step 15770, loss = 0.15, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 19h:25m:23s remains)
INFO - root - 2017-12-17 04:03:32.608409: step 15780, loss = 0.09, batch loss = 0.06 (37.5 examples/sec; 0.213 sec/batch; 18h:45m:44s remains)
INFO - root - 2017-12-17 04:03:34.843397: step 15790, loss = 0.16, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 20h:06m:30s remains)
INFO - root - 2017-12-17 04:03:37.074920: step 15800, loss = 0.12, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 19h:15m:00s remains)
INFO - root - 2017-12-17 04:03:39.428855: step 15810, loss = 0.09, batch loss = 0.05 (37.0 examples/sec; 0.216 sec/batch; 18h:59m:41s remains)
INFO - root - 2017-12-17 04:03:41.666590: step 15820, loss = 0.10, batch loss = 0.06 (38.0 examples/sec; 0.210 sec/batch; 18h:30m:57s remains)
INFO - root - 2017-12-17 04:03:43.874221: step 15830, loss = 0.11, batch loss = 0.07 (35.4 examples/sec; 0.226 sec/batch; 19h:51m:17s remains)
INFO - root - 2017-12-17 04:03:46.090146: step 15840, loss = 0.10, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 19h:09m:17s remains)
INFO - root - 2017-12-17 04:03:48.320382: step 15850, loss = 0.11, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 19h:19m:08s remains)
INFO - root - 2017-12-17 04:03:50.529010: step 15860, loss = 0.16, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 19h:21m:57s remains)
INFO - root - 2017-12-17 04:03:52.746226: step 15870, loss = 0.12, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 19h:45m:41s remains)
INFO - root - 2017-12-17 04:03:55.005078: step 15880, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.224 sec/batch; 19h:39m:34s remains)
INFO - root - 2017-12-17 04:03:57.222821: step 15890, loss = 0.09, batch loss = 0.06 (35.8 examples/sec; 0.223 sec/batch; 19h:39m:07s remains)
INFO - root - 2017-12-17 04:03:59.435950: step 15900, loss = 0.11, batch loss = 0.08 (38.4 examples/sec; 0.208 sec/batch; 18h:18m:23s remains)
INFO - root - 2017-12-17 04:04:01.777095: step 15910, loss = 0.12, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 19h:36m:26s remains)
INFO - root - 2017-12-17 04:04:04.020549: step 15920, loss = 0.10, batch loss = 0.06 (35.4 examples/sec; 0.226 sec/batch; 19h:52m:43s remains)
INFO - root - 2017-12-17 04:04:06.209017: step 15930, loss = 0.09, batch loss = 0.05 (37.4 examples/sec; 0.214 sec/batch; 18h:49m:41s remains)
INFO - root - 2017-12-17 04:04:08.492493: step 15940, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.221 sec/batch; 19h:23m:30s remains)
INFO - root - 2017-12-17 04:04:10.709559: step 15950, loss = 0.10, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 19h:25m:06s remains)
INFO - root - 2017-12-17 04:04:12.933799: step 15960, loss = 0.14, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 19h:40m:09s remains)
INFO - root - 2017-12-17 04:04:15.173543: step 15970, loss = 0.08, batch loss = 0.05 (35.9 examples/sec; 0.223 sec/batch; 19h:34m:43s remains)
INFO - root - 2017-12-17 04:04:17.401236: step 15980, loss = 0.10, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 19h:15m:15s remains)
INFO - root - 2017-12-17 04:04:19.642551: step 15990, loss = 0.10, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 19h:31m:21s remains)
INFO - root - 2017-12-17 04:04:21.836693: step 16000, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 19h:29m:53s remains)
INFO - root - 2017-12-17 04:04:24.186794: step 16010, loss = 0.11, batch loss = 0.07 (35.1 examples/sec; 0.228 sec/batch; 20h:02m:43s remains)
INFO - root - 2017-12-17 04:04:26.453554: step 16020, loss = 0.12, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:33m:16s remains)
INFO - root - 2017-12-17 04:04:28.672216: step 16030, loss = 0.11, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 19h:16m:37s remains)
INFO - root - 2017-12-17 04:04:30.947260: step 16040, loss = 0.16, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 19h:20m:03s remains)
INFO - root - 2017-12-17 04:04:33.159560: step 16050, loss = 0.14, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 19h:55m:33s remains)
INFO - root - 2017-12-17 04:04:35.397341: step 16060, loss = 0.12, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 19h:26m:42s remains)
INFO - root - 2017-12-17 04:04:37.591533: step 16070, loss = 0.10, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 19h:13m:16s remains)
INFO - root - 2017-12-17 04:04:39.815312: step 16080, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.224 sec/batch; 19h:39m:06s remains)
INFO - root - 2017-12-17 04:04:42.044272: step 16090, loss = 0.10, batch loss = 0.07 (35.0 examples/sec; 0.229 sec/batch; 20h:07m:05s remains)
INFO - root - 2017-12-17 04:04:44.279906: step 16100, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.223 sec/batch; 19h:38m:04s remains)
INFO - root - 2017-12-17 04:04:46.659808: step 16110, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 19h:28m:52s remains)
INFO - root - 2017-12-17 04:04:48.902688: step 16120, loss = 0.09, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 19h:16m:46s remains)
INFO - root - 2017-12-17 04:04:51.105549: step 16130, loss = 0.11, batch loss = 0.07 (37.0 examples/sec; 0.216 sec/batch; 18h:59m:49s remains)
INFO - root - 2017-12-17 04:04:53.349996: step 16140, loss = 0.10, batch loss = 0.07 (36.8 examples/sec; 0.218 sec/batch; 19h:07m:19s remains)
INFO - root - 2017-12-17 04:04:56.022182: step 16150, loss = 0.09, batch loss = 0.05 (21.4 examples/sec; 0.374 sec/batch; 32h:53m:36s remains)
INFO - root - 2017-12-17 04:04:59.781770: step 16160, loss = 0.14, batch loss = 0.10 (22.3 examples/sec; 0.359 sec/batch; 31h:32m:53s remains)
INFO - root - 2017-12-17 04:05:03.469326: step 16170, loss = 0.15, batch loss = 0.12 (21.2 examples/sec; 0.378 sec/batch; 33h:10m:27s remains)
INFO - root - 2017-12-17 04:05:07.152465: step 16180, loss = 0.11, batch loss = 0.08 (22.0 examples/sec; 0.363 sec/batch; 31h:53m:39s remains)
INFO - root - 2017-12-17 04:05:10.952003: step 16190, loss = 0.10, batch loss = 0.06 (21.2 examples/sec; 0.377 sec/batch; 33h:05m:23s remains)
INFO - root - 2017-12-17 04:05:14.748920: step 16200, loss = 0.09, batch loss = 0.06 (22.3 examples/sec; 0.359 sec/batch; 31h:30m:08s remains)
INFO - root - 2017-12-17 04:05:18.650491: step 16210, loss = 0.13, batch loss = 0.10 (21.6 examples/sec; 0.370 sec/batch; 32h:28m:38s remains)
INFO - root - 2017-12-17 04:05:22.380591: step 16220, loss = 0.16, batch loss = 0.12 (21.1 examples/sec; 0.379 sec/batch; 33h:17m:14s remains)
INFO - root - 2017-12-17 04:05:26.128241: step 16230, loss = 0.14, batch loss = 0.10 (21.8 examples/sec; 0.367 sec/batch; 32h:12m:19s remains)
INFO - root - 2017-12-17 04:05:29.854645: step 16240, loss = 0.10, batch loss = 0.07 (20.4 examples/sec; 0.393 sec/batch; 34h:30m:32s remains)
INFO - root - 2017-12-17 04:05:33.533180: step 16250, loss = 0.10, batch loss = 0.07 (22.2 examples/sec; 0.360 sec/batch; 31h:37m:45s remains)
INFO - root - 2017-12-17 04:05:37.167034: step 16260, loss = 0.13, batch loss = 0.10 (21.6 examples/sec; 0.370 sec/batch; 32h:31m:12s remains)
INFO - root - 2017-12-17 04:05:40.837415: step 16270, loss = 0.14, batch loss = 0.10 (21.7 examples/sec; 0.368 sec/batch; 32h:21m:01s remains)
INFO - root - 2017-12-17 04:05:44.533684: step 16280, loss = 0.10, batch loss = 0.06 (22.7 examples/sec; 0.353 sec/batch; 30h:58m:01s remains)
INFO - root - 2017-12-17 04:05:48.081664: step 16290, loss = 0.10, batch loss = 0.07 (23.3 examples/sec; 0.344 sec/batch; 30h:13m:22s remains)
INFO - root - 2017-12-17 04:05:51.623194: step 16300, loss = 0.13, batch loss = 0.10 (21.8 examples/sec; 0.367 sec/batch; 32h:16m:31s remains)
INFO - root - 2017-12-17 04:05:55.579783: step 16310, loss = 0.10, batch loss = 0.07 (21.1 examples/sec; 0.380 sec/batch; 33h:21m:27s remains)
INFO - root - 2017-12-17 04:05:59.285633: step 16320, loss = 0.10, batch loss = 0.06 (21.6 examples/sec; 0.370 sec/batch; 32h:32m:18s remains)
INFO - root - 2017-12-17 04:06:02.951122: step 16330, loss = 0.11, batch loss = 0.07 (23.4 examples/sec; 0.342 sec/batch; 30h:04m:26s remains)
INFO - root - 2017-12-17 04:06:06.680402: step 16340, loss = 0.12, batch loss = 0.09 (22.0 examples/sec; 0.364 sec/batch; 31h:59m:07s remains)
INFO - root - 2017-12-17 04:06:10.321898: step 16350, loss = 0.10, batch loss = 0.07 (21.8 examples/sec; 0.367 sec/batch; 32h:14m:04s remains)
INFO - root - 2017-12-17 04:06:13.937365: step 16360, loss = 0.13, batch loss = 0.09 (24.6 examples/sec; 0.325 sec/batch; 28h:32m:19s remains)
INFO - root - 2017-12-17 04:06:17.628240: step 16370, loss = 0.16, batch loss = 0.12 (22.7 examples/sec; 0.353 sec/batch; 30h:58m:36s remains)
INFO - root - 2017-12-17 04:06:21.252241: step 16380, loss = 0.09, batch loss = 0.06 (25.3 examples/sec; 0.316 sec/batch; 27h:46m:16s remains)
INFO - root - 2017-12-17 04:06:25.015460: step 16390, loss = 0.14, batch loss = 0.11 (20.0 examples/sec; 0.401 sec/batch; 35h:10m:30s remains)
INFO - root - 2017-12-17 04:06:28.755767: step 16400, loss = 0.09, batch loss = 0.06 (21.1 examples/sec; 0.378 sec/batch; 33h:13m:23s remains)
INFO - root - 2017-12-17 04:06:32.711078: step 16410, loss = 0.10, batch loss = 0.07 (20.4 examples/sec; 0.392 sec/batch; 34h:23m:05s remains)
INFO - root - 2017-12-17 04:06:36.381147: step 16420, loss = 0.11, batch loss = 0.08 (21.3 examples/sec; 0.375 sec/batch; 32h:56m:35s remains)
INFO - root - 2017-12-17 04:06:40.070961: step 16430, loss = 0.13, batch loss = 0.10 (21.6 examples/sec; 0.371 sec/batch; 32h:33m:59s remains)
INFO - root - 2017-12-17 04:06:43.754746: step 16440, loss = 0.12, batch loss = 0.09 (22.1 examples/sec; 0.361 sec/batch; 31h:44m:12s remains)
INFO - root - 2017-12-17 04:06:47.528691: step 16450, loss = 0.10, batch loss = 0.07 (21.0 examples/sec; 0.380 sec/batch; 33h:22m:47s remains)
INFO - root - 2017-12-17 04:06:51.296984: step 16460, loss = 0.10, batch loss = 0.06 (21.0 examples/sec; 0.381 sec/batch; 33h:26m:38s remains)
INFO - root - 2017-12-17 04:06:54.947466: step 16470, loss = 0.09, batch loss = 0.05 (21.4 examples/sec; 0.374 sec/batch; 32h:49m:31s remains)
INFO - root - 2017-12-17 04:06:58.668569: step 16480, loss = 0.12, batch loss = 0.09 (21.7 examples/sec; 0.368 sec/batch; 32h:20m:42s remains)
INFO - root - 2017-12-17 04:07:02.435426: step 16490, loss = 0.11, batch loss = 0.08 (20.6 examples/sec; 0.389 sec/batch; 34h:08m:49s remains)
INFO - root - 2017-12-17 04:07:06.276616: step 16500, loss = 0.15, batch loss = 0.11 (21.6 examples/sec; 0.371 sec/batch; 32h:33m:49s remains)
INFO - root - 2017-12-17 04:07:10.146946: step 16510, loss = 0.11, batch loss = 0.08 (21.2 examples/sec; 0.377 sec/batch; 33h:06m:29s remains)
INFO - root - 2017-12-17 04:07:13.864036: step 16520, loss = 0.14, batch loss = 0.10 (21.8 examples/sec; 0.368 sec/batch; 32h:16m:40s remains)
INFO - root - 2017-12-17 04:07:17.628011: step 16530, loss = 0.15, batch loss = 0.11 (21.4 examples/sec; 0.373 sec/batch; 32h:44m:45s remains)
INFO - root - 2017-12-17 04:07:21.279775: step 16540, loss = 0.11, batch loss = 0.07 (21.3 examples/sec; 0.376 sec/batch; 33h:02m:27s remains)
INFO - root - 2017-12-17 04:07:24.957365: step 16550, loss = 0.10, batch loss = 0.06 (20.3 examples/sec; 0.394 sec/batch; 34h:35m:37s remains)
INFO - root - 2017-12-17 04:07:28.587711: step 16560, loss = 0.11, batch loss = 0.08 (21.8 examples/sec; 0.367 sec/batch; 32h:14m:54s remains)
INFO - root - 2017-12-17 04:07:32.226718: step 16570, loss = 0.16, batch loss = 0.12 (21.9 examples/sec; 0.365 sec/batch; 32h:03m:15s remains)
INFO - root - 2017-12-17 04:07:36.016325: step 16580, loss = 0.12, batch loss = 0.09 (19.9 examples/sec; 0.401 sec/batch; 35h:11m:45s remains)
INFO - root - 2017-12-17 04:07:39.702736: step 16590, loss = 0.12, batch loss = 0.09 (21.9 examples/sec; 0.365 sec/batch; 32h:02m:31s remains)
INFO - root - 2017-12-17 04:07:43.420823: step 16600, loss = 0.12, batch loss = 0.08 (21.8 examples/sec; 0.367 sec/batch; 32h:11m:50s remains)
INFO - root - 2017-12-17 04:07:47.340125: step 16610, loss = 0.11, batch loss = 0.08 (22.7 examples/sec; 0.353 sec/batch; 30h:59m:03s remains)
INFO - root - 2017-12-17 04:07:51.076210: step 16620, loss = 0.10, batch loss = 0.06 (21.8 examples/sec; 0.367 sec/batch; 32h:11m:43s remains)
INFO - root - 2017-12-17 04:07:54.812020: step 16630, loss = 0.13, batch loss = 0.10 (21.6 examples/sec; 0.370 sec/batch; 32h:25m:46s remains)
INFO - root - 2017-12-17 04:07:58.533336: step 16640, loss = 0.11, batch loss = 0.07 (21.8 examples/sec; 0.367 sec/batch; 32h:12m:22s remains)
INFO - root - 2017-12-17 04:08:02.246002: step 16650, loss = 0.08, batch loss = 0.05 (20.9 examples/sec; 0.382 sec/batch; 33h:31m:31s remains)
INFO - root - 2017-12-17 04:08:05.899374: step 16660, loss = 0.10, batch loss = 0.06 (21.5 examples/sec; 0.372 sec/batch; 32h:37m:41s remains)
INFO - root - 2017-12-17 04:08:09.551576: step 16670, loss = 0.12, batch loss = 0.09 (21.5 examples/sec; 0.373 sec/batch; 32h:40m:54s remains)
INFO - root - 2017-12-17 04:08:13.202473: step 16680, loss = 0.12, batch loss = 0.08 (21.3 examples/sec; 0.376 sec/batch; 32h:59m:28s remains)
INFO - root - 2017-12-17 04:08:16.937751: step 16690, loss = 0.16, batch loss = 0.12 (24.5 examples/sec; 0.327 sec/batch; 28h:39m:31s remains)
INFO - root - 2017-12-17 04:08:20.660948: step 16700, loss = 0.08, batch loss = 0.05 (21.8 examples/sec; 0.367 sec/batch; 32h:14m:06s remains)
INFO - root - 2017-12-17 04:08:24.481124: step 16710, loss = 0.10, batch loss = 0.06 (23.1 examples/sec; 0.346 sec/batch; 30h:23m:03s remains)
INFO - root - 2017-12-17 04:08:28.137815: step 16720, loss = 0.17, batch loss = 0.13 (22.3 examples/sec; 0.358 sec/batch; 31h:24m:53s remains)
INFO - root - 2017-12-17 04:08:31.870419: step 16730, loss = 0.12, batch loss = 0.09 (21.9 examples/sec; 0.365 sec/batch; 32h:00m:18s remains)
INFO - root - 2017-12-17 04:08:35.615314: step 16740, loss = 0.09, batch loss = 0.05 (21.6 examples/sec; 0.370 sec/batch; 32h:25m:54s remains)
INFO - root - 2017-12-17 04:08:39.291654: step 16750, loss = 0.14, batch loss = 0.10 (21.0 examples/sec; 0.381 sec/batch; 33h:24m:02s remains)
INFO - root - 2017-12-17 04:08:43.050273: step 16760, loss = 0.11, batch loss = 0.08 (21.3 examples/sec; 0.375 sec/batch; 32h:52m:20s remains)
INFO - root - 2017-12-17 04:08:46.648218: step 16770, loss = 0.11, batch loss = 0.07 (20.9 examples/sec; 0.383 sec/batch; 33h:34m:13s remains)
INFO - root - 2017-12-17 04:08:50.341407: step 16780, loss = 0.11, batch loss = 0.07 (22.3 examples/sec; 0.360 sec/batch; 31h:31m:52s remains)
INFO - root - 2017-12-17 04:08:54.101192: step 16790, loss = 0.11, batch loss = 0.08 (21.6 examples/sec; 0.371 sec/batch; 32h:30m:36s remains)
INFO - root - 2017-12-17 04:08:57.668233: step 16800, loss = 0.13, batch loss = 0.09 (23.9 examples/sec; 0.335 sec/batch; 29h:21m:08s remains)
INFO - root - 2017-12-17 04:09:01.522752: step 16810, loss = 0.10, batch loss = 0.07 (20.8 examples/sec; 0.384 sec/batch; 33h:41m:55s remains)
INFO - root - 2017-12-17 04:09:05.297292: step 16820, loss = 0.09, batch loss = 0.05 (22.0 examples/sec; 0.364 sec/batch; 31h:53m:50s remains)
INFO - root - 2017-12-17 04:09:08.928355: step 16830, loss = 0.15, batch loss = 0.11 (23.4 examples/sec; 0.342 sec/batch; 30h:00m:15s remains)
INFO - root - 2017-12-17 04:09:12.705381: step 16840, loss = 0.12, batch loss = 0.09 (20.7 examples/sec; 0.386 sec/batch; 33h:49m:06s remains)
INFO - root - 2017-12-17 04:09:16.432952: step 16850, loss = 0.11, batch loss = 0.08 (20.5 examples/sec; 0.390 sec/batch; 34h:09m:48s remains)
INFO - root - 2017-12-17 04:09:20.143429: step 16860, loss = 0.23, batch loss = 0.19 (21.5 examples/sec; 0.372 sec/batch; 32h:37m:31s remains)
INFO - root - 2017-12-17 04:09:23.906113: step 16870, loss = 0.10, batch loss = 0.06 (20.5 examples/sec; 0.390 sec/batch; 34h:09m:20s remains)
INFO - root - 2017-12-17 04:09:27.599137: step 16880, loss = 0.09, batch loss = 0.06 (22.0 examples/sec; 0.363 sec/batch; 31h:49m:59s remains)
INFO - root - 2017-12-17 04:09:31.343003: step 16890, loss = 0.10, batch loss = 0.07 (21.6 examples/sec; 0.370 sec/batch; 32h:28m:32s remains)
INFO - root - 2017-12-17 04:09:35.098051: step 16900, loss = 0.16, batch loss = 0.12 (21.2 examples/sec; 0.378 sec/batch; 33h:07m:53s remains)
INFO - root - 2017-12-17 04:09:39.059294: step 16910, loss = 0.11, batch loss = 0.07 (20.1 examples/sec; 0.397 sec/batch; 34h:48m:42s remains)
INFO - root - 2017-12-17 04:09:42.871732: step 16920, loss = 0.13, batch loss = 0.10 (21.2 examples/sec; 0.377 sec/batch; 33h:04m:47s remains)
INFO - root - 2017-12-17 04:09:46.806463: step 16930, loss = 0.11, batch loss = 0.07 (20.8 examples/sec; 0.385 sec/batch; 33h:44m:09s remains)
INFO - root - 2017-12-17 04:09:50.700672: step 16940, loss = 0.11, batch loss = 0.07 (19.7 examples/sec; 0.407 sec/batch; 35h:39m:34s remains)
INFO - root - 2017-12-17 04:09:54.501523: step 16950, loss = 0.10, batch loss = 0.07 (21.1 examples/sec; 0.379 sec/batch; 33h:11m:11s remains)
INFO - root - 2017-12-17 04:09:58.310183: step 16960, loss = 0.12, batch loss = 0.08 (21.3 examples/sec; 0.376 sec/batch; 32h:59m:07s remains)
INFO - root - 2017-12-17 04:10:02.147123: step 16970, loss = 0.14, batch loss = 0.11 (20.8 examples/sec; 0.385 sec/batch; 33h:44m:21s remains)
INFO - root - 2017-12-17 04:10:05.984414: step 16980, loss = 0.10, batch loss = 0.07 (22.0 examples/sec; 0.364 sec/batch; 31h:55m:10s remains)
INFO - root - 2017-12-17 04:10:09.474744: step 16990, loss = 0.10, batch loss = 0.06 (21.7 examples/sec; 0.369 sec/batch; 32h:18m:59s remains)
INFO - root - 2017-12-17 04:10:13.302163: step 17000, loss = 0.11, batch loss = 0.07 (21.0 examples/sec; 0.380 sec/batch; 33h:19m:55s remains)
INFO - root - 2017-12-17 04:10:17.333280: step 17010, loss = 0.11, batch loss = 0.08 (21.0 examples/sec; 0.380 sec/batch; 33h:20m:25s remains)
INFO - root - 2017-12-17 04:10:21.147023: step 17020, loss = 0.10, batch loss = 0.07 (19.9 examples/sec; 0.403 sec/batch; 35h:17m:26s remains)
INFO - root - 2017-12-17 04:10:24.930542: step 17030, loss = 0.08, batch loss = 0.05 (20.9 examples/sec; 0.382 sec/batch; 33h:27m:47s remains)
INFO - root - 2017-12-17 04:10:28.823614: step 17040, loss = 0.16, batch loss = 0.13 (19.8 examples/sec; 0.404 sec/batch; 35h:23m:29s remains)
INFO - root - 2017-12-17 04:10:32.604934: step 17050, loss = 0.13, batch loss = 0.09 (21.5 examples/sec; 0.373 sec/batch; 32h:40m:42s remains)
INFO - root - 2017-12-17 04:10:36.465131: step 17060, loss = 0.14, batch loss = 0.11 (20.9 examples/sec; 0.382 sec/batch; 33h:28m:14s remains)
INFO - root - 2017-12-17 04:10:40.222819: step 17070, loss = 0.11, batch loss = 0.08 (20.9 examples/sec; 0.382 sec/batch; 33h:29m:03s remains)
INFO - root - 2017-12-17 04:10:44.008227: step 17080, loss = 0.10, batch loss = 0.06 (19.4 examples/sec; 0.413 sec/batch; 36h:10m:35s remains)
INFO - root - 2017-12-17 04:10:47.769700: step 17090, loss = 0.10, batch loss = 0.06 (20.9 examples/sec; 0.383 sec/batch; 33h:33m:05s remains)
INFO - root - 2017-12-17 04:10:51.592431: step 17100, loss = 0.12, batch loss = 0.08 (20.1 examples/sec; 0.399 sec/batch; 34h:57m:11s remains)
INFO - root - 2017-12-17 04:10:55.622482: step 17110, loss = 0.09, batch loss = 0.06 (21.2 examples/sec; 0.377 sec/batch; 33h:03m:40s remains)
INFO - root - 2017-12-17 04:10:59.400807: step 17120, loss = 0.14, batch loss = 0.11 (21.7 examples/sec; 0.369 sec/batch; 32h:20m:00s remains)
INFO - root - 2017-12-17 04:11:03.242035: step 17130, loss = 0.13, batch loss = 0.09 (21.2 examples/sec; 0.378 sec/batch; 33h:06m:29s remains)
INFO - root - 2017-12-17 04:11:07.039756: step 17140, loss = 0.12, batch loss = 0.08 (21.5 examples/sec; 0.372 sec/batch; 32h:32m:57s remains)
INFO - root - 2017-12-17 04:11:10.740014: step 17150, loss = 0.10, batch loss = 0.07 (21.3 examples/sec; 0.376 sec/batch; 32h:55m:02s remains)
INFO - root - 2017-12-17 04:11:14.589191: step 17160, loss = 0.12, batch loss = 0.08 (21.5 examples/sec; 0.371 sec/batch; 32h:31m:34s remains)
INFO - root - 2017-12-17 04:11:18.407671: step 17170, loss = 0.10, batch loss = 0.07 (22.8 examples/sec; 0.351 sec/batch; 30h:42m:03s remains)
INFO - root - 2017-12-17 04:11:22.154468: step 17180, loss = 0.09, batch loss = 0.06 (22.8 examples/sec; 0.352 sec/batch; 30h:47m:59s remains)
INFO - root - 2017-12-17 04:11:25.963891: step 17190, loss = 0.10, batch loss = 0.07 (21.2 examples/sec; 0.377 sec/batch; 33h:00m:56s remains)
INFO - root - 2017-12-17 04:11:29.758009: step 17200, loss = 0.20, batch loss = 0.17 (20.1 examples/sec; 0.398 sec/batch; 34h:50m:14s remains)
INFO - root - 2017-12-17 04:11:33.788174: step 17210, loss = 0.10, batch loss = 0.07 (21.6 examples/sec; 0.370 sec/batch; 32h:23m:12s remains)
INFO - root - 2017-12-17 04:11:37.582710: step 17220, loss = 0.10, batch loss = 0.06 (20.2 examples/sec; 0.396 sec/batch; 34h:39m:37s remains)
INFO - root - 2017-12-17 04:11:41.351753: step 17230, loss = 0.15, batch loss = 0.12 (21.3 examples/sec; 0.376 sec/batch; 32h:54m:55s remains)
INFO - root - 2017-12-17 04:11:45.126954: step 17240, loss = 0.11, batch loss = 0.07 (21.5 examples/sec; 0.372 sec/batch; 32h:35m:08s remains)
INFO - root - 2017-12-17 04:11:48.887450: step 17250, loss = 0.12, batch loss = 0.08 (21.0 examples/sec; 0.381 sec/batch; 33h:21m:40s remains)
INFO - root - 2017-12-17 04:11:52.641499: step 17260, loss = 0.18, batch loss = 0.15 (22.6 examples/sec; 0.354 sec/batch; 30h:59m:42s remains)
INFO - root - 2017-12-17 04:11:56.416006: step 17270, loss = 0.13, batch loss = 0.09 (20.7 examples/sec; 0.386 sec/batch; 33h:49m:08s remains)
INFO - root - 2017-12-17 04:12:00.174241: step 17280, loss = 0.09, batch loss = 0.05 (21.5 examples/sec; 0.373 sec/batch; 32h:38m:49s remains)
INFO - root - 2017-12-17 04:12:03.916411: step 17290, loss = 0.12, batch loss = 0.08 (21.5 examples/sec; 0.372 sec/batch; 32h:33m:34s remains)
INFO - root - 2017-12-17 04:12:07.715900: step 17300, loss = 0.09, batch loss = 0.06 (19.8 examples/sec; 0.405 sec/batch; 35h:25m:01s remains)
INFO - root - 2017-12-17 04:12:11.801392: step 17310, loss = 0.11, batch loss = 0.07 (20.6 examples/sec; 0.388 sec/batch; 33h:57m:32s remains)
INFO - root - 2017-12-17 04:12:15.607823: step 17320, loss = 0.11, batch loss = 0.07 (21.4 examples/sec; 0.374 sec/batch; 32h:42m:50s remains)
INFO - root - 2017-12-17 04:12:19.397061: step 17330, loss = 0.09, batch loss = 0.06 (21.0 examples/sec; 0.381 sec/batch; 33h:21m:20s remains)
INFO - root - 2017-12-17 04:12:23.141617: step 17340, loss = 0.10, batch loss = 0.07 (20.8 examples/sec; 0.385 sec/batch; 33h:42m:03s remains)
INFO - root - 2017-12-17 04:12:26.999117: step 17350, loss = 0.12, batch loss = 0.08 (20.8 examples/sec; 0.385 sec/batch; 33h:40m:00s remains)
INFO - root - 2017-12-17 04:12:30.751005: step 17360, loss = 0.09, batch loss = 0.06 (21.3 examples/sec; 0.376 sec/batch; 32h:55m:31s remains)
INFO - root - 2017-12-17 04:12:34.594269: step 17370, loss = 0.11, batch loss = 0.07 (20.8 examples/sec; 0.385 sec/batch; 33h:42m:23s remains)
INFO - root - 2017-12-17 04:12:38.357469: step 17380, loss = 0.11, batch loss = 0.07 (21.8 examples/sec; 0.367 sec/batch; 32h:07m:32s remains)
INFO - root - 2017-12-17 04:12:42.141526: step 17390, loss = 0.11, batch loss = 0.08 (21.3 examples/sec; 0.376 sec/batch; 32h:53m:41s remains)
INFO - root - 2017-12-17 04:12:45.900034: step 17400, loss = 0.23, batch loss = 0.19 (20.7 examples/sec; 0.386 sec/batch; 33h:46m:32s remains)
INFO - root - 2017-12-17 04:12:49.865545: step 17410, loss = 0.13, batch loss = 0.10 (20.3 examples/sec; 0.394 sec/batch; 34h:26m:53s remains)
INFO - root - 2017-12-17 04:12:53.662156: step 17420, loss = 0.15, batch loss = 0.11 (21.4 examples/sec; 0.373 sec/batch; 32h:39m:09s remains)
INFO - root - 2017-12-17 04:12:57.515019: step 17430, loss = 0.11, batch loss = 0.08 (20.7 examples/sec; 0.387 sec/batch; 33h:53m:25s remains)
INFO - root - 2017-12-17 04:13:01.298035: step 17440, loss = 0.11, batch loss = 0.07 (21.2 examples/sec; 0.377 sec/batch; 32h:57m:01s remains)
INFO - root - 2017-12-17 04:13:05.144089: step 17450, loss = 0.09, batch loss = 0.05 (20.3 examples/sec; 0.394 sec/batch; 34h:30m:44s remains)
INFO - root - 2017-12-17 04:13:08.917111: step 17460, loss = 0.14, batch loss = 0.11 (21.4 examples/sec; 0.374 sec/batch; 32h:43m:15s remains)
INFO - root - 2017-12-17 04:13:12.707296: step 17470, loss = 0.11, batch loss = 0.08 (21.8 examples/sec; 0.366 sec/batch; 32h:04m:00s remains)
INFO - root - 2017-12-17 04:13:16.421282: step 17480, loss = 0.14, batch loss = 0.11 (20.6 examples/sec; 0.389 sec/batch; 33h:59m:56s remains)
INFO - root - 2017-12-17 04:13:20.215752: step 17490, loss = 0.11, batch loss = 0.08 (19.7 examples/sec; 0.407 sec/batch; 35h:35m:03s remains)
INFO - root - 2017-12-17 04:13:23.808657: step 17500, loss = 0.11, batch loss = 0.08 (22.5 examples/sec; 0.355 sec/batch; 31h:05m:20s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-17500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-17500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 04:13:28.480712: step 17510, loss = 0.13, batch loss = 0.10 (22.4 examples/sec; 0.357 sec/batch; 31h:12m:51s remains)
INFO - root - 2017-12-17 04:13:32.207031: step 17520, loss = 0.10, batch loss = 0.07 (21.7 examples/sec; 0.369 sec/batch; 32h:14m:54s remains)
INFO - root - 2017-12-17 04:13:35.953502: step 17530, loss = 0.11, batch loss = 0.07 (20.7 examples/sec; 0.387 sec/batch; 33h:53m:36s remains)
INFO - root - 2017-12-17 04:13:39.682979: step 17540, loss = 0.13, batch loss = 0.09 (21.4 examples/sec; 0.374 sec/batch; 32h:45m:46s remains)
INFO - root - 2017-12-17 04:13:43.394457: step 17550, loss = 0.10, batch loss = 0.06 (21.6 examples/sec; 0.370 sec/batch; 32h:23m:02s remains)
INFO - root - 2017-12-17 04:13:47.094091: step 17560, loss = 0.16, batch loss = 0.12 (21.0 examples/sec; 0.380 sec/batch; 33h:15m:22s remains)
INFO - root - 2017-12-17 04:13:50.910135: step 17570, loss = 0.11, batch loss = 0.07 (21.1 examples/sec; 0.379 sec/batch; 33h:11m:29s remains)
INFO - root - 2017-12-17 04:13:54.682811: step 17580, loss = 0.11, batch loss = 0.08 (21.8 examples/sec; 0.367 sec/batch; 32h:07m:01s remains)
INFO - root - 2017-12-17 04:13:58.360912: step 17590, loss = 0.10, batch loss = 0.07 (21.7 examples/sec; 0.368 sec/batch; 32h:12m:40s remains)
INFO - root - 2017-12-17 04:14:02.163230: step 17600, loss = 0.10, batch loss = 0.07 (20.7 examples/sec; 0.386 sec/batch; 33h:47m:10s remains)
INFO - root - 2017-12-17 04:14:06.110758: step 17610, loss = 0.11, batch loss = 0.08 (21.2 examples/sec; 0.377 sec/batch; 33h:00m:04s remains)
INFO - root - 2017-12-17 04:14:09.802411: step 17620, loss = 0.11, batch loss = 0.07 (22.6 examples/sec; 0.354 sec/batch; 30h:58m:18s remains)
INFO - root - 2017-12-17 04:14:13.521645: step 17630, loss = 0.16, batch loss = 0.13 (22.3 examples/sec; 0.358 sec/batch; 31h:19m:56s remains)
INFO - root - 2017-12-17 04:14:17.212093: step 17640, loss = 0.11, batch loss = 0.08 (21.6 examples/sec; 0.371 sec/batch; 32h:25m:04s remains)
INFO - root - 2017-12-17 04:14:20.860265: step 17650, loss = 0.12, batch loss = 0.08 (21.1 examples/sec; 0.379 sec/batch; 33h:08m:20s remains)
INFO - root - 2017-12-17 04:14:24.660335: step 17660, loss = 0.09, batch loss = 0.05 (20.6 examples/sec; 0.388 sec/batch; 33h:58m:11s remains)
INFO - root - 2017-12-17 04:14:28.436253: step 17670, loss = 0.11, batch loss = 0.07 (20.8 examples/sec; 0.384 sec/batch; 33h:34m:35s remains)
INFO - root - 2017-12-17 04:14:32.211466: step 17680, loss = 0.11, batch loss = 0.08 (20.4 examples/sec; 0.393 sec/batch; 34h:20m:56s remains)
INFO - root - 2017-12-17 04:14:36.016583: step 17690, loss = 0.08, batch loss = 0.05 (21.0 examples/sec; 0.381 sec/batch; 33h:21m:08s remains)
INFO - root - 2017-12-17 04:14:39.820565: step 17700, loss = 0.13, batch loss = 0.09 (20.2 examples/sec; 0.396 sec/batch; 34h:37m:25s remains)
INFO - root - 2017-12-17 04:14:43.820219: step 17710, loss = 0.12, batch loss = 0.08 (20.7 examples/sec; 0.386 sec/batch; 33h:45m:06s remains)
INFO - root - 2017-12-17 04:14:47.543494: step 17720, loss = 0.10, batch loss = 0.07 (21.6 examples/sec; 0.370 sec/batch; 32h:20m:26s remains)
INFO - root - 2017-12-17 04:14:51.242036: step 17730, loss = 0.10, batch loss = 0.06 (22.2 examples/sec; 0.361 sec/batch; 31h:33m:46s remains)
INFO - root - 2017-12-17 04:14:54.983786: step 17740, loss = 0.19, batch loss = 0.15 (20.9 examples/sec; 0.383 sec/batch; 33h:30m:10s remains)
INFO - root - 2017-12-17 04:14:58.786656: step 17750, loss = 0.10, batch loss = 0.06 (20.3 examples/sec; 0.394 sec/batch; 34h:25m:16s remains)
INFO - root - 2017-12-17 04:15:02.519417: step 17760, loss = 0.11, batch loss = 0.07 (21.0 examples/sec; 0.380 sec/batch; 33h:14m:43s remains)
INFO - root - 2017-12-17 04:15:06.165557: step 17770, loss = 0.09, batch loss = 0.06 (22.6 examples/sec; 0.354 sec/batch; 30h:54m:25s remains)
INFO - root - 2017-12-17 04:15:09.889537: step 17780, loss = 0.10, batch loss = 0.07 (20.6 examples/sec; 0.389 sec/batch; 34h:00m:47s remains)
INFO - root - 2017-12-17 04:15:13.737671: step 17790, loss = 0.12, batch loss = 0.09 (21.8 examples/sec; 0.367 sec/batch; 32h:07m:09s remains)
INFO - root - 2017-12-17 04:15:17.545119: step 17800, loss = 0.16, batch loss = 0.12 (20.5 examples/sec; 0.390 sec/batch; 34h:07m:32s remains)
INFO - root - 2017-12-17 04:15:21.496140: step 17810, loss = 0.12, batch loss = 0.09 (21.3 examples/sec; 0.376 sec/batch; 32h:53m:59s remains)
INFO - root - 2017-12-17 04:15:25.187534: step 17820, loss = 0.13, batch loss = 0.09 (21.1 examples/sec; 0.379 sec/batch; 33h:09m:54s remains)
INFO - root - 2017-12-17 04:15:28.902006: step 17830, loss = 0.12, batch loss = 0.09 (21.9 examples/sec; 0.366 sec/batch; 31h:59m:18s remains)
INFO - root - 2017-12-17 04:15:32.637017: step 17840, loss = 0.11, batch loss = 0.08 (20.8 examples/sec; 0.384 sec/batch; 33h:32m:52s remains)
INFO - root - 2017-12-17 04:15:36.431083: step 17850, loss = 0.08, batch loss = 0.05 (20.8 examples/sec; 0.384 sec/batch; 33h:36m:22s remains)
INFO - root - 2017-12-17 04:15:40.176954: step 17860, loss = 0.10, batch loss = 0.06 (20.7 examples/sec; 0.386 sec/batch; 33h:45m:23s remains)
INFO - root - 2017-12-17 04:15:44.094033: step 17870, loss = 0.11, batch loss = 0.08 (20.2 examples/sec; 0.396 sec/batch; 34h:34m:03s remains)
INFO - root - 2017-12-17 04:15:47.826690: step 17880, loss = 0.09, batch loss = 0.06 (21.5 examples/sec; 0.371 sec/batch; 32h:27m:54s remains)
INFO - root - 2017-12-17 04:15:51.539904: step 17890, loss = 0.09, batch loss = 0.05 (20.8 examples/sec; 0.384 sec/batch; 33h:35m:51s remains)
INFO - root - 2017-12-17 04:15:55.310580: step 17900, loss = 0.10, batch loss = 0.06 (21.7 examples/sec; 0.369 sec/batch; 32h:12m:23s remains)
INFO - root - 2017-12-17 04:15:59.205068: step 17910, loss = 0.10, batch loss = 0.07 (21.3 examples/sec; 0.375 sec/batch; 32h:47m:46s remains)
INFO - root - 2017-12-17 04:16:02.920645: step 17920, loss = 0.18, batch loss = 0.14 (21.9 examples/sec; 0.365 sec/batch; 31h:55m:23s remains)
INFO - root - 2017-12-17 04:16:06.672537: step 17930, loss = 0.13, batch loss = 0.10 (22.4 examples/sec; 0.357 sec/batch; 31h:12m:27s remains)
INFO - root - 2017-12-17 04:16:10.188818: step 17940, loss = 0.14, batch loss = 0.11 (23.0 examples/sec; 0.347 sec/batch; 30h:19m:38s remains)
INFO - root - 2017-12-17 04:16:13.920428: step 17950, loss = 0.18, batch loss = 0.14 (21.0 examples/sec; 0.381 sec/batch; 33h:18m:03s remains)
INFO - root - 2017-12-17 04:16:17.676199: step 17960, loss = 0.10, batch loss = 0.07 (21.5 examples/sec; 0.372 sec/batch; 32h:29m:50s remains)
INFO - root - 2017-12-17 04:16:21.376510: step 17970, loss = 0.10, batch loss = 0.06 (21.9 examples/sec; 0.366 sec/batch; 31h:58m:23s remains)
INFO - root - 2017-12-17 04:16:25.141876: step 17980, loss = 0.11, batch loss = 0.07 (22.1 examples/sec; 0.362 sec/batch; 31h:35m:37s remains)
INFO - root - 2017-12-17 04:16:28.769968: step 17990, loss = 0.11, batch loss = 0.08 (21.9 examples/sec; 0.365 sec/batch; 31h:53m:05s remains)
INFO - root - 2017-12-17 04:16:32.482509: step 18000, loss = 0.10, batch loss = 0.06 (21.1 examples/sec; 0.380 sec/batch; 33h:11m:58s remains)
INFO - root - 2017-12-17 04:16:36.378715: step 18010, loss = 0.13, batch loss = 0.10 (21.9 examples/sec; 0.365 sec/batch; 31h:51m:49s remains)
INFO - root - 2017-12-17 04:16:40.069333: step 18020, loss = 0.12, batch loss = 0.08 (21.9 examples/sec; 0.366 sec/batch; 31h:55m:59s remains)
INFO - root - 2017-12-17 04:16:43.770359: step 18030, loss = 0.13, batch loss = 0.09 (21.4 examples/sec; 0.375 sec/batch; 32h:43m:07s remains)
INFO - root - 2017-12-17 04:16:47.567915: step 18040, loss = 0.11, batch loss = 0.07 (21.4 examples/sec; 0.374 sec/batch; 32h:39m:57s remains)
INFO - root - 2017-12-17 04:16:51.392462: step 18050, loss = 0.11, batch loss = 0.07 (21.5 examples/sec; 0.373 sec/batch; 32h:33m:12s remains)
INFO - root - 2017-12-17 04:16:55.208275: step 18060, loss = 0.09, batch loss = 0.06 (20.6 examples/sec; 0.389 sec/batch; 33h:59m:52s remains)
INFO - root - 2017-12-17 04:16:59.035919: step 18070, loss = 0.14, batch loss = 0.10 (21.3 examples/sec; 0.376 sec/batch; 32h:50m:17s remains)
INFO - root - 2017-12-17 04:17:02.769026: step 18080, loss = 0.15, batch loss = 0.12 (21.2 examples/sec; 0.377 sec/batch; 32h:53m:43s remains)
INFO - root - 2017-12-17 04:17:06.511929: step 18090, loss = 0.11, batch loss = 0.08 (21.4 examples/sec; 0.375 sec/batch; 32h:43m:04s remains)
INFO - root - 2017-12-17 04:17:10.252657: step 18100, loss = 0.10, batch loss = 0.07 (22.2 examples/sec; 0.360 sec/batch; 31h:27m:01s remains)
INFO - root - 2017-12-17 04:17:14.199611: step 18110, loss = 0.10, batch loss = 0.07 (20.3 examples/sec; 0.393 sec/batch; 34h:20m:10s remains)
INFO - root - 2017-12-17 04:17:17.991053: step 18120, loss = 0.12, batch loss = 0.08 (21.6 examples/sec; 0.371 sec/batch; 32h:22m:13s remains)
INFO - root - 2017-12-17 04:17:21.767100: step 18130, loss = 0.13, batch loss = 0.09 (21.4 examples/sec; 0.373 sec/batch; 32h:36m:45s remains)
INFO - root - 2017-12-17 04:17:25.543418: step 18140, loss = 0.09, batch loss = 0.06 (19.8 examples/sec; 0.403 sec/batch; 35h:13m:58s remains)
INFO - root - 2017-12-17 04:17:29.442375: step 18150, loss = 0.12, batch loss = 0.09 (22.1 examples/sec; 0.362 sec/batch; 31h:38m:06s remains)
INFO - root - 2017-12-17 04:17:33.203310: step 18160, loss = 0.13, batch loss = 0.09 (21.2 examples/sec; 0.378 sec/batch; 32h:57m:54s remains)
INFO - root - 2017-12-17 04:17:36.968400: step 18170, loss = 0.13, batch loss = 0.10 (20.8 examples/sec; 0.384 sec/batch; 33h:33m:27s remains)
INFO - root - 2017-12-17 04:17:40.711975: step 18180, loss = 0.10, batch loss = 0.07 (21.0 examples/sec; 0.382 sec/batch; 33h:20m:18s remains)
INFO - root - 2017-12-17 04:17:44.526329: step 18190, loss = 0.11, batch loss = 0.08 (21.2 examples/sec; 0.377 sec/batch; 32h:54m:38s remains)
INFO - root - 2017-12-17 04:17:48.288634: step 18200, loss = 0.14, batch loss = 0.10 (20.8 examples/sec; 0.384 sec/batch; 33h:33m:53s remains)
INFO - root - 2017-12-17 04:17:52.307490: step 18210, loss = 0.10, batch loss = 0.07 (20.5 examples/sec; 0.390 sec/batch; 34h:04m:07s remains)
INFO - root - 2017-12-17 04:17:56.203139: step 18220, loss = 0.11, batch loss = 0.08 (19.8 examples/sec; 0.404 sec/batch; 35h:17m:02s remains)
INFO - root - 2017-12-17 04:17:59.958600: step 18230, loss = 0.14, batch loss = 0.10 (21.0 examples/sec; 0.380 sec/batch; 33h:10m:59s remains)
INFO - root - 2017-12-17 04:18:03.702278: step 18240, loss = 0.12, batch loss = 0.09 (21.3 examples/sec; 0.376 sec/batch; 32h:47m:49s remains)
INFO - root - 2017-12-17 04:18:07.523535: step 18250, loss = 0.13, batch loss = 0.09 (20.7 examples/sec; 0.387 sec/batch; 33h:46m:29s remains)
INFO - root - 2017-12-17 04:18:11.277520: step 18260, loss = 0.10, batch loss = 0.07 (22.7 examples/sec; 0.352 sec/batch; 30h:42m:59s remains)
INFO - root - 2017-12-17 04:18:15.040185: step 18270, loss = 0.13, batch loss = 0.10 (21.1 examples/sec; 0.380 sec/batch; 33h:09m:01s remains)
INFO - root - 2017-12-17 04:18:18.764405: step 18280, loss = 0.09, batch loss = 0.06 (21.8 examples/sec; 0.367 sec/batch; 31h:59m:47s remains)
INFO - root - 2017-12-17 04:18:22.512679: step 18290, loss = 0.09, batch loss = 0.06 (21.3 examples/sec; 0.376 sec/batch; 32h:50m:31s remains)
INFO - root - 2017-12-17 04:18:26.160885: step 18300, loss = 0.12, batch loss = 0.09 (21.4 examples/sec; 0.374 sec/batch; 32h:37m:22s remains)
INFO - root - 2017-12-17 04:18:30.078484: step 18310, loss = 0.11, batch loss = 0.07 (22.2 examples/sec; 0.360 sec/batch; 31h:26m:23s remains)
INFO - root - 2017-12-17 04:18:33.794351: step 18320, loss = 0.11, batch loss = 0.08 (22.1 examples/sec; 0.363 sec/batch; 31h:39m:10s remains)
INFO - root - 2017-12-17 04:18:37.608181: step 18330, loss = 0.10, batch loss = 0.07 (20.6 examples/sec; 0.389 sec/batch; 33h:57m:09s remains)
INFO - root - 2017-12-17 04:18:41.391249: step 18340, loss = 0.13, batch loss = 0.10 (21.3 examples/sec; 0.376 sec/batch; 32h:47m:07s remains)
INFO - root - 2017-12-17 04:18:45.119621: step 18350, loss = 0.10, batch loss = 0.06 (21.2 examples/sec; 0.378 sec/batch; 32h:58m:55s remains)
INFO - root - 2017-12-17 04:18:48.833475: step 18360, loss = 0.12, batch loss = 0.09 (20.2 examples/sec; 0.396 sec/batch; 34h:31m:34s remains)
INFO - root - 2017-12-17 04:18:52.609984: step 18370, loss = 0.13, batch loss = 0.10 (21.9 examples/sec; 0.365 sec/batch; 31h:48m:30s remains)
INFO - root - 2017-12-17 04:18:56.367434: step 18380, loss = 0.13, batch loss = 0.09 (20.1 examples/sec; 0.397 sec/batch; 34h:39m:30s remains)
INFO - root - 2017-12-17 04:19:00.175587: step 18390, loss = 0.13, batch loss = 0.09 (20.7 examples/sec; 0.387 sec/batch; 33h:45m:46s remains)
INFO - root - 2017-12-17 04:19:03.874886: step 18400, loss = 0.12, batch loss = 0.08 (21.3 examples/sec; 0.375 sec/batch; 32h:43m:44s remains)
INFO - root - 2017-12-17 04:19:07.791232: step 18410, loss = 0.10, batch loss = 0.06 (21.7 examples/sec; 0.368 sec/batch; 32h:07m:58s remains)
INFO - root - 2017-12-17 04:19:11.649460: step 18420, loss = 0.11, batch loss = 0.08 (20.5 examples/sec; 0.390 sec/batch; 34h:02m:33s remains)
INFO - root - 2017-12-17 04:19:15.462355: step 18430, loss = 0.12, batch loss = 0.09 (20.4 examples/sec; 0.392 sec/batch; 34h:13m:55s remains)
INFO - root - 2017-12-17 04:19:19.028802: step 18440, loss = 0.12, batch loss = 0.08 (22.4 examples/sec; 0.358 sec/batch; 31h:12m:51s remains)
INFO - root - 2017-12-17 04:19:22.786857: step 18450, loss = 0.11, batch loss = 0.08 (21.5 examples/sec; 0.373 sec/batch; 32h:30m:32s remains)
INFO - root - 2017-12-17 04:19:26.559444: step 18460, loss = 0.10, batch loss = 0.07 (20.8 examples/sec; 0.384 sec/batch; 33h:29m:48s remains)
INFO - root - 2017-12-17 04:19:30.236105: step 18470, loss = 0.11, batch loss = 0.07 (22.3 examples/sec; 0.359 sec/batch; 31h:21m:09s remains)
INFO - root - 2017-12-17 04:19:33.945701: step 18480, loss = 0.13, batch loss = 0.10 (22.1 examples/sec; 0.363 sec/batch; 31h:37m:37s remains)
INFO - root - 2017-12-17 04:19:37.668432: step 18490, loss = 0.24, batch loss = 0.20 (21.5 examples/sec; 0.372 sec/batch; 32h:25m:00s remains)
INFO - root - 2017-12-17 04:19:41.444174: step 18500, loss = 0.10, batch loss = 0.06 (20.5 examples/sec; 0.391 sec/batch; 34h:05m:47s remains)
INFO - root - 2017-12-17 04:19:45.398891: step 18510, loss = 0.12, batch loss = 0.08 (21.3 examples/sec; 0.375 sec/batch; 32h:41m:06s remains)
INFO - root - 2017-12-17 04:19:49.096158: step 18520, loss = 0.11, batch loss = 0.07 (20.5 examples/sec; 0.390 sec/batch; 33h:58m:36s remains)
INFO - root - 2017-12-17 04:19:52.725267: step 18530, loss = 0.10, batch loss = 0.07 (22.5 examples/sec; 0.355 sec/batch; 30h:59m:09s remains)
INFO - root - 2017-12-17 04:19:56.441744: step 18540, loss = 0.10, batch loss = 0.06 (21.3 examples/sec; 0.376 sec/batch; 32h:49m:52s remains)
INFO - root - 2017-12-17 04:20:00.177878: step 18550, loss = 0.15, batch loss = 0.12 (21.7 examples/sec; 0.369 sec/batch; 32h:12m:53s remains)
INFO - root - 2017-12-17 04:20:03.853262: step 18560, loss = 0.09, batch loss = 0.06 (22.8 examples/sec; 0.351 sec/batch; 30h:35m:48s remains)
INFO - root - 2017-12-17 04:20:07.599533: step 18570, loss = 0.12, batch loss = 0.08 (22.5 examples/sec; 0.356 sec/batch; 31h:04m:27s remains)
INFO - root - 2017-12-17 04:20:11.319254: step 18580, loss = 0.11, batch loss = 0.07 (21.3 examples/sec; 0.375 sec/batch; 32h:41m:27s remains)
INFO - root - 2017-12-17 04:20:15.056121: step 18590, loss = 0.10, batch loss = 0.07 (22.1 examples/sec; 0.363 sec/batch; 31h:37m:40s remains)
INFO - root - 2017-12-17 04:20:18.779017: step 18600, loss = 0.11, batch loss = 0.08 (24.3 examples/sec; 0.329 sec/batch; 28h:42m:28s remains)
INFO - root - 2017-12-17 04:20:22.629070: step 18610, loss = 0.15, batch loss = 0.12 (23.4 examples/sec; 0.341 sec/batch; 29h:46m:32s remains)
INFO - root - 2017-12-17 04:20:26.378006: step 18620, loss = 0.10, batch loss = 0.07 (21.6 examples/sec; 0.370 sec/batch; 32h:16m:33s remains)
INFO - root - 2017-12-17 04:20:30.025354: step 18630, loss = 0.12, batch loss = 0.08 (20.9 examples/sec; 0.382 sec/batch; 33h:18m:01s remains)
INFO - root - 2017-12-17 04:20:33.753065: step 18640, loss = 0.15, batch loss = 0.11 (21.6 examples/sec; 0.370 sec/batch; 32h:14m:41s remains)
INFO - root - 2017-12-17 04:20:37.482547: step 18650, loss = 0.11, batch loss = 0.08 (20.9 examples/sec; 0.384 sec/batch; 33h:26m:38s remains)
INFO - root - 2017-12-17 04:20:41.227256: step 18660, loss = 0.11, batch loss = 0.07 (21.9 examples/sec; 0.366 sec/batch; 31h:53m:25s remains)
INFO - root - 2017-12-17 04:20:44.932513: step 18670, loss = 0.17, batch loss = 0.13 (20.9 examples/sec; 0.383 sec/batch; 33h:21m:59s remains)
INFO - root - 2017-12-17 04:20:48.607456: step 18680, loss = 0.11, batch loss = 0.07 (22.2 examples/sec; 0.360 sec/batch; 31h:24m:05s remains)
INFO - root - 2017-12-17 04:20:52.314115: step 18690, loss = 0.11, batch loss = 0.08 (21.9 examples/sec; 0.366 sec/batch; 31h:51m:57s remains)
INFO - root - 2017-12-17 04:20:56.091844: step 18700, loss = 0.11, batch loss = 0.08 (21.4 examples/sec; 0.374 sec/batch; 32h:35m:47s remains)
INFO - root - 2017-12-17 04:21:00.009335: step 18710, loss = 0.12, batch loss = 0.09 (20.6 examples/sec; 0.389 sec/batch; 33h:52m:25s remains)
INFO - root - 2017-12-17 04:21:03.708162: step 18720, loss = 0.10, batch loss = 0.07 (21.6 examples/sec; 0.370 sec/batch; 32h:14m:44s remains)
INFO - root - 2017-12-17 04:21:07.319974: step 18730, loss = 0.09, batch loss = 0.06 (21.7 examples/sec; 0.368 sec/batch; 32h:05m:58s remains)
INFO - root - 2017-12-17 04:21:11.055982: step 18740, loss = 0.13, batch loss = 0.09 (20.8 examples/sec; 0.384 sec/batch; 33h:27m:04s remains)
INFO - root - 2017-12-17 04:21:14.746498: step 18750, loss = 0.11, batch loss = 0.08 (21.8 examples/sec; 0.367 sec/batch; 32h:01m:10s remains)
INFO - root - 2017-12-17 04:21:18.444706: step 18760, loss = 0.15, batch loss = 0.11 (20.1 examples/sec; 0.398 sec/batch; 34h:43m:16s remains)
INFO - root - 2017-12-17 04:21:22.128480: step 18770, loss = 0.11, batch loss = 0.07 (22.0 examples/sec; 0.363 sec/batch; 31h:40m:08s remains)
INFO - root - 2017-12-17 04:21:25.888162: step 18780, loss = 0.10, batch loss = 0.07 (21.2 examples/sec; 0.377 sec/batch; 32h:49m:43s remains)
INFO - root - 2017-12-17 04:21:29.589297: step 18790, loss = 0.12, batch loss = 0.08 (21.5 examples/sec; 0.372 sec/batch; 32h:23m:14s remains)
INFO - root - 2017-12-17 04:21:33.289955: step 18800, loss = 0.13, batch loss = 0.09 (21.8 examples/sec; 0.368 sec/batch; 32h:02m:35s remains)
INFO - root - 2017-12-17 04:21:37.195640: step 18810, loss = 0.12, batch loss = 0.08 (21.2 examples/sec; 0.378 sec/batch; 32h:55m:06s remains)
INFO - root - 2017-12-17 04:21:40.831840: step 18820, loss = 0.11, batch loss = 0.08 (21.8 examples/sec; 0.367 sec/batch; 31h:59m:41s remains)
INFO - root - 2017-12-17 04:21:44.505467: step 18830, loss = 0.10, batch loss = 0.07 (21.1 examples/sec; 0.379 sec/batch; 33h:02m:53s remains)
INFO - root - 2017-12-17 04:21:48.135880: step 18840, loss = 0.10, batch loss = 0.07 (22.1 examples/sec; 0.362 sec/batch; 31h:31m:48s remains)
INFO - root - 2017-12-17 04:21:51.896217: step 18850, loss = 0.10, batch loss = 0.07 (20.7 examples/sec; 0.387 sec/batch; 33h:45m:02s remains)
INFO - root - 2017-12-17 04:21:55.614099: step 18860, loss = 0.12, batch loss = 0.09 (20.5 examples/sec; 0.389 sec/batch; 33h:55m:27s remains)
INFO - root - 2017-12-17 04:21:59.314326: step 18870, loss = 0.17, batch loss = 0.14 (22.2 examples/sec; 0.361 sec/batch; 31h:26m:58s remains)
INFO - root - 2017-12-17 04:22:02.961131: step 18880, loss = 0.12, batch loss = 0.08 (20.5 examples/sec; 0.391 sec/batch; 34h:03m:09s remains)
INFO - root - 2017-12-17 04:22:06.750925: step 18890, loss = 0.10, batch loss = 0.06 (20.9 examples/sec; 0.384 sec/batch; 33h:24m:51s remains)
INFO - root - 2017-12-17 04:22:10.513194: step 18900, loss = 0.12, batch loss = 0.08 (20.4 examples/sec; 0.393 sec/batch; 34h:14m:31s remains)
INFO - root - 2017-12-17 04:22:14.401214: step 18910, loss = 0.10, batch loss = 0.07 (21.4 examples/sec; 0.375 sec/batch; 32h:37m:53s remains)
INFO - root - 2017-12-17 04:22:18.120435: step 18920, loss = 0.12, batch loss = 0.09 (21.6 examples/sec; 0.370 sec/batch; 32h:13m:07s remains)
INFO - root - 2017-12-17 04:22:21.852867: step 18930, loss = 0.09, batch loss = 0.06 (21.8 examples/sec; 0.367 sec/batch; 31h:59m:48s remains)
INFO - root - 2017-12-17 04:22:25.619586: step 18940, loss = 0.10, batch loss = 0.07 (21.4 examples/sec; 0.373 sec/batch; 32h:29m:11s remains)
INFO - root - 2017-12-17 04:22:29.378745: step 18950, loss = 0.11, batch loss = 0.08 (21.0 examples/sec; 0.382 sec/batch; 33h:14m:58s remains)
INFO - root - 2017-12-17 04:22:33.093676: step 18960, loss = 0.11, batch loss = 0.08 (22.1 examples/sec; 0.362 sec/batch; 31h:31m:55s remains)
INFO - root - 2017-12-17 04:22:36.887255: step 18970, loss = 0.11, batch loss = 0.07 (20.3 examples/sec; 0.395 sec/batch; 34h:23m:31s remains)
INFO - root - 2017-12-17 04:22:40.634135: step 18980, loss = 0.12, batch loss = 0.09 (21.1 examples/sec; 0.379 sec/batch; 33h:01m:49s remains)
INFO - root - 2017-12-17 04:22:44.361025: step 18990, loss = 0.09, batch loss = 0.05 (22.0 examples/sec; 0.364 sec/batch; 31h:41m:20s remains)
INFO - root - 2017-12-17 04:22:48.135484: step 19000, loss = 0.09, batch loss = 0.06 (21.9 examples/sec; 0.366 sec/batch; 31h:50m:09s remains)
INFO - root - 2017-12-17 04:22:52.084277: step 19010, loss = 0.10, batch loss = 0.07 (21.2 examples/sec; 0.378 sec/batch; 32h:54m:49s remains)
INFO - root - 2017-12-17 04:22:55.754521: step 19020, loss = 0.11, batch loss = 0.07 (21.3 examples/sec; 0.376 sec/batch; 32h:46m:50s remains)
INFO - root - 2017-12-17 04:22:59.439460: step 19030, loss = 0.10, batch loss = 0.07 (21.9 examples/sec; 0.365 sec/batch; 31h:49m:13s remains)
INFO - root - 2017-12-17 04:23:03.214080: step 19040, loss = 0.09, batch loss = 0.06 (20.7 examples/sec; 0.387 sec/batch; 33h:42m:56s remains)
INFO - root - 2017-12-17 04:23:06.959710: step 19050, loss = 0.10, batch loss = 0.07 (21.6 examples/sec; 0.370 sec/batch; 32h:11m:44s remains)
INFO - root - 2017-12-17 04:23:10.734241: step 19060, loss = 0.10, batch loss = 0.07 (21.4 examples/sec; 0.374 sec/batch; 32h:31m:20s remains)
INFO - root - 2017-12-17 04:23:14.451727: step 19070, loss = 0.10, batch loss = 0.07 (21.0 examples/sec; 0.382 sec/batch; 33h:13m:16s remains)
INFO - root - 2017-12-17 04:23:18.232673: step 19080, loss = 0.10, batch loss = 0.07 (22.1 examples/sec; 0.362 sec/batch; 31h:30m:03s remains)
INFO - root - 2017-12-17 04:23:22.001239: step 19090, loss = 0.11, batch loss = 0.07 (21.0 examples/sec; 0.382 sec/batch; 33h:13m:02s remains)
INFO - root - 2017-12-17 04:23:25.794709: step 19100, loss = 0.09, batch loss = 0.06 (21.4 examples/sec; 0.374 sec/batch; 32h:34m:58s remains)
INFO - root - 2017-12-17 04:23:29.805268: step 19110, loss = 0.11, batch loss = 0.08 (21.2 examples/sec; 0.377 sec/batch; 32h:49m:13s remains)
INFO - root - 2017-12-17 04:23:33.454149: step 19120, loss = 0.10, batch loss = 0.07 (21.0 examples/sec; 0.382 sec/batch; 33h:12m:57s remains)
INFO - root - 2017-12-17 04:23:37.193514: step 19130, loss = 0.09, batch loss = 0.06 (21.1 examples/sec; 0.380 sec/batch; 33h:02m:38s remains)
INFO - root - 2017-12-17 04:23:40.990420: step 19140, loss = 0.11, batch loss = 0.07 (21.8 examples/sec; 0.368 sec/batch; 31h:59m:51s remains)
INFO - root - 2017-12-17 04:23:44.744045: step 19150, loss = 0.12, batch loss = 0.09 (20.5 examples/sec; 0.390 sec/batch; 33h:56m:00s remains)
INFO - root - 2017-12-17 04:23:48.545218: step 19160, loss = 0.08, batch loss = 0.05 (20.8 examples/sec; 0.385 sec/batch; 33h:28m:14s remains)
INFO - root - 2017-12-17 04:23:52.209148: step 19170, loss = 0.12, batch loss = 0.08 (20.5 examples/sec; 0.391 sec/batch; 34h:00m:08s remains)
INFO - root - 2017-12-17 04:23:55.872538: step 19180, loss = 0.10, batch loss = 0.06 (21.2 examples/sec; 0.378 sec/batch; 32h:54m:40s remains)
INFO - root - 2017-12-17 04:23:59.635874: step 19190, loss = 0.11, batch loss = 0.08 (20.6 examples/sec; 0.389 sec/batch; 33h:52m:01s remains)
INFO - root - 2017-12-17 04:24:03.370208: step 19200, loss = 0.15, batch loss = 0.11 (23.1 examples/sec; 0.347 sec/batch; 30h:11m:09s remains)
INFO - root - 2017-12-17 04:24:07.310237: step 19210, loss = 0.09, batch loss = 0.06 (20.5 examples/sec; 0.390 sec/batch; 33h:55m:20s remains)
INFO - root - 2017-12-17 04:24:11.123772: step 19220, loss = 0.15, batch loss = 0.12 (22.2 examples/sec; 0.361 sec/batch; 31h:22m:57s remains)
INFO - root - 2017-12-17 04:24:14.816417: step 19230, loss = 0.11, batch loss = 0.07 (21.7 examples/sec; 0.369 sec/batch; 32h:05m:45s remains)
INFO - root - 2017-12-17 04:24:18.475410: step 19240, loss = 0.13, batch loss = 0.10 (21.7 examples/sec; 0.369 sec/batch; 32h:06m:46s remains)
INFO - root - 2017-12-17 04:24:22.261244: step 19250, loss = 0.15, batch loss = 0.12 (20.5 examples/sec; 0.391 sec/batch; 34h:01m:56s remains)
INFO - root - 2017-12-17 04:24:26.007038: step 19260, loss = 0.10, batch loss = 0.07 (21.4 examples/sec; 0.373 sec/batch; 32h:27m:42s remains)
INFO - root - 2017-12-17 04:24:29.690476: step 19270, loss = 0.14, batch loss = 0.10 (20.8 examples/sec; 0.385 sec/batch; 33h:30m:53s remains)
INFO - root - 2017-12-17 04:24:33.473807: step 19280, loss = 0.15, batch loss = 0.11 (21.1 examples/sec; 0.380 sec/batch; 33h:01m:41s remains)
INFO - root - 2017-12-17 04:24:37.288728: step 19290, loss = 0.10, batch loss = 0.07 (20.9 examples/sec; 0.383 sec/batch; 33h:18m:57s remains)
INFO - root - 2017-12-17 04:24:41.086948: step 19300, loss = 0.11, batch loss = 0.08 (20.8 examples/sec; 0.385 sec/batch; 33h:31m:24s remains)
INFO - root - 2017-12-17 04:24:45.019650: step 19310, loss = 0.11, batch loss = 0.07 (21.4 examples/sec; 0.374 sec/batch; 32h:32m:45s remains)
INFO - root - 2017-12-17 04:24:48.705157: step 19320, loss = 0.09, batch loss = 0.05 (21.3 examples/sec; 0.376 sec/batch; 32h:41m:05s remains)
INFO - root - 2017-12-17 04:24:52.460760: step 19330, loss = 0.11, batch loss = 0.08 (21.4 examples/sec; 0.373 sec/batch; 32h:27m:07s remains)
INFO - root - 2017-12-17 04:24:56.169000: step 19340, loss = 0.08, batch loss = 0.05 (21.2 examples/sec; 0.377 sec/batch; 32h:49m:19s remains)
INFO - root - 2017-12-17 04:24:59.886266: step 19350, loss = 0.10, batch loss = 0.07 (21.8 examples/sec; 0.368 sec/batch; 31h:58m:06s remains)
INFO - root - 2017-12-17 04:25:03.558847: step 19360, loss = 0.10, batch loss = 0.06 (22.4 examples/sec; 0.356 sec/batch; 31h:00m:16s remains)
INFO - root - 2017-12-17 04:25:07.210885: step 19370, loss = 0.11, batch loss = 0.07 (22.6 examples/sec; 0.354 sec/batch; 30h:47m:18s remains)
INFO - root - 2017-12-17 04:25:10.834776: step 19380, loss = 0.11, batch loss = 0.07 (23.4 examples/sec; 0.342 sec/batch; 29h:43m:31s remains)
INFO - root - 2017-12-17 04:25:14.531342: step 19390, loss = 0.12, batch loss = 0.09 (20.3 examples/sec; 0.394 sec/batch; 34h:13m:43s remains)
INFO - root - 2017-12-17 04:25:18.220870: step 19400, loss = 0.10, batch loss = 0.07 (21.7 examples/sec; 0.368 sec/batch; 32h:00m:38s remains)
INFO - root - 2017-12-17 04:25:22.077353: step 19410, loss = 0.11, batch loss = 0.08 (21.7 examples/sec; 0.369 sec/batch; 32h:04m:36s remains)
INFO - root - 2017-12-17 04:25:25.838450: step 19420, loss = 0.10, batch loss = 0.07 (21.1 examples/sec; 0.380 sec/batch; 33h:02m:55s remains)
INFO - root - 2017-12-17 04:25:29.639608: step 19430, loss = 0.10, batch loss = 0.07 (21.2 examples/sec; 0.377 sec/batch; 32h:47m:33s remains)
INFO - root - 2017-12-17 04:25:33.350684: step 19440, loss = 0.11, batch loss = 0.07 (22.0 examples/sec; 0.364 sec/batch; 31h:37m:55s remains)
INFO - root - 2017-12-17 04:25:37.105822: step 19450, loss = 0.17, batch loss = 0.13 (20.6 examples/sec; 0.389 sec/batch; 33h:50m:42s remains)
INFO - root - 2017-12-17 04:25:40.730492: step 19460, loss = 0.15, batch loss = 0.12 (22.5 examples/sec; 0.356 sec/batch; 30h:58m:18s remains)
INFO - root - 2017-12-17 04:25:44.458024: step 19470, loss = 0.10, batch loss = 0.06 (21.9 examples/sec; 0.365 sec/batch; 31h:44m:37s remains)
INFO - root - 2017-12-17 04:25:48.228950: step 19480, loss = 0.11, batch loss = 0.08 (20.8 examples/sec; 0.385 sec/batch; 33h:27m:59s remains)
INFO - root - 2017-12-17 04:25:51.909589: step 19490, loss = 0.12, batch loss = 0.08 (21.4 examples/sec; 0.373 sec/batch; 32h:28m:23s remains)
INFO - root - 2017-12-17 04:25:55.631216: step 19500, loss = 0.11, batch loss = 0.07 (21.0 examples/sec; 0.382 sec/batch; 33h:10m:51s remains)
INFO - root - 2017-12-17 04:25:59.592439: step 19510, loss = 0.14, batch loss = 0.10 (22.6 examples/sec; 0.354 sec/batch; 30h:44m:07s remains)
INFO - root - 2017-12-17 04:26:03.289607: step 19520, loss = 0.09, batch loss = 0.06 (21.2 examples/sec; 0.378 sec/batch; 32h:51m:26s remains)
INFO - root - 2017-12-17 04:26:06.916706: step 19530, loss = 0.12, batch loss = 0.09 (20.7 examples/sec; 0.387 sec/batch; 33h:37m:21s remains)
INFO - root - 2017-12-17 04:26:10.662000: step 19540, loss = 0.09, batch loss = 0.06 (24.1 examples/sec; 0.332 sec/batch; 28h:50m:13s remains)
INFO - root - 2017-12-17 04:26:14.397907: step 19550, loss = 0.14, batch loss = 0.11 (20.8 examples/sec; 0.385 sec/batch; 33h:27m:53s remains)
INFO - root - 2017-12-17 04:26:18.195334: step 19560, loss = 0.11, batch loss = 0.08 (21.5 examples/sec; 0.373 sec/batch; 32h:23m:10s remains)
INFO - root - 2017-12-17 04:26:21.927811: step 19570, loss = 0.11, batch loss = 0.08 (21.9 examples/sec; 0.366 sec/batch; 31h:47m:56s remains)
INFO - root - 2017-12-17 04:26:25.709351: step 19580, loss = 0.10, batch loss = 0.06 (20.9 examples/sec; 0.382 sec/batch; 33h:12m:26s remains)
INFO - root - 2017-12-17 04:26:29.408206: step 19590, loss = 0.14, batch loss = 0.11 (23.5 examples/sec; 0.341 sec/batch; 29h:36m:59s remains)
INFO - root - 2017-12-17 04:26:33.160560: step 19600, loss = 0.11, batch loss = 0.08 (21.0 examples/sec; 0.382 sec/batch; 33h:09m:42s remains)
INFO - root - 2017-12-17 04:26:37.128745: step 19610, loss = 0.10, batch loss = 0.07 (21.5 examples/sec; 0.371 sec/batch; 32h:16m:16s remains)
INFO - root - 2017-12-17 04:26:40.903158: step 19620, loss = 0.11, batch loss = 0.07 (20.8 examples/sec; 0.384 sec/batch; 33h:21m:18s remains)
INFO - root - 2017-12-17 04:26:44.635718: step 19630, loss = 0.14, batch loss = 0.11 (20.9 examples/sec; 0.383 sec/batch; 33h:15m:40s remains)
INFO - root - 2017-12-17 04:26:48.377710: step 19640, loss = 0.10, batch loss = 0.06 (20.8 examples/sec; 0.384 sec/batch; 33h:20m:56s remains)
INFO - root - 2017-12-17 04:26:52.235980: step 19650, loss = 0.10, batch loss = 0.07 (21.0 examples/sec; 0.381 sec/batch; 33h:05m:19s remains)
INFO - root - 2017-12-17 04:26:55.981771: step 19660, loss = 0.11, batch loss = 0.08 (21.7 examples/sec; 0.368 sec/batch; 31h:58m:01s remains)
INFO - root - 2017-12-17 04:26:59.751177: step 19670, loss = 0.12, batch loss = 0.08 (21.6 examples/sec; 0.370 sec/batch; 32h:10m:09s remains)
INFO - root - 2017-12-17 04:27:03.523092: step 19680, loss = 0.11, batch loss = 0.07 (21.1 examples/sec; 0.380 sec/batch; 33h:01m:17s remains)
INFO - root - 2017-12-17 04:27:07.217868: step 19690, loss = 0.13, batch loss = 0.10 (21.7 examples/sec; 0.369 sec/batch; 32h:05m:52s remains)
INFO - root - 2017-12-17 04:27:11.007933: step 19700, loss = 0.10, batch loss = 0.07 (21.8 examples/sec; 0.367 sec/batch; 31h:52m:07s remains)
INFO - root - 2017-12-17 04:27:14.897036: step 19710, loss = 0.11, batch loss = 0.08 (20.5 examples/sec; 0.391 sec/batch; 33h:56m:08s remains)
INFO - root - 2017-12-17 04:27:18.615890: step 19720, loss = 0.13, batch loss = 0.10 (20.8 examples/sec; 0.385 sec/batch; 33h:24m:45s remains)
INFO - root - 2017-12-17 04:27:22.294106: step 19730, loss = 0.11, batch loss = 0.08 (23.3 examples/sec; 0.344 sec/batch; 29h:53m:13s remains)
INFO - root - 2017-12-17 04:27:25.984009: step 19740, loss = 0.12, batch loss = 0.09 (21.6 examples/sec; 0.370 sec/batch; 32h:08m:38s remains)
INFO - root - 2017-12-17 04:27:29.672555: step 19750, loss = 0.11, batch loss = 0.08 (20.5 examples/sec; 0.389 sec/batch; 33h:50m:13s remains)
INFO - root - 2017-12-17 04:27:33.342480: step 19760, loss = 0.12, batch loss = 0.09 (21.8 examples/sec; 0.367 sec/batch; 31h:52m:52s remains)
INFO - root - 2017-12-17 04:27:37.126419: step 19770, loss = 0.09, batch loss = 0.06 (21.9 examples/sec; 0.366 sec/batch; 31h:46m:03s remains)
INFO - root - 2017-12-17 04:27:40.872112: step 19780, loss = 0.13, batch loss = 0.09 (21.5 examples/sec; 0.372 sec/batch; 32h:18m:00s remains)
INFO - root - 2017-12-17 04:27:44.630907: step 19790, loss = 0.12, batch loss = 0.08 (21.1 examples/sec; 0.380 sec/batch; 32h:59m:20s remains)
INFO - root - 2017-12-17 04:27:48.346582: step 19800, loss = 0.11, batch loss = 0.08 (21.6 examples/sec; 0.370 sec/batch; 32h:08m:01s remains)
INFO - root - 2017-12-17 04:27:52.230001: step 19810, loss = 0.10, batch loss = 0.07 (21.4 examples/sec; 0.374 sec/batch; 32h:27m:49s remains)
INFO - root - 2017-12-17 04:27:55.990622: step 19820, loss = 0.13, batch loss = 0.10 (23.7 examples/sec; 0.337 sec/batch; 29h:17m:42s remains)
INFO - root - 2017-12-17 04:27:59.698872: step 19830, loss = 0.11, batch loss = 0.08 (21.2 examples/sec; 0.378 sec/batch; 32h:47m:17s remains)
INFO - root - 2017-12-17 04:28:03.458280: step 19840, loss = 0.11, batch loss = 0.07 (21.8 examples/sec; 0.368 sec/batch; 31h:55m:57s remains)
INFO - root - 2017-12-17 04:28:07.136778: step 19850, loss = 0.09, batch loss = 0.06 (20.8 examples/sec; 0.384 sec/batch; 33h:20m:41s remains)
INFO - root - 2017-12-17 04:28:10.878364: step 19860, loss = 0.10, batch loss = 0.07 (21.1 examples/sec; 0.379 sec/batch; 32h:57m:14s remains)
INFO - root - 2017-12-17 04:28:14.655784: step 19870, loss = 0.12, batch loss = 0.09 (20.2 examples/sec; 0.396 sec/batch; 34h:22m:03s remains)
INFO - root - 2017-12-17 04:28:18.411837: step 19880, loss = 0.09, batch loss = 0.06 (21.9 examples/sec; 0.366 sec/batch; 31h:45m:30s remains)
INFO - root - 2017-12-17 04:28:22.146378: step 19890, loss = 0.12, batch loss = 0.09 (21.1 examples/sec; 0.380 sec/batch; 32h:57m:22s remains)
INFO - root - 2017-12-17 04:28:25.889787: step 19900, loss = 0.09, batch loss = 0.06 (21.6 examples/sec; 0.370 sec/batch; 32h:09m:08s remains)
INFO - root - 2017-12-17 04:28:29.862621: step 19910, loss = 0.10, batch loss = 0.06 (20.8 examples/sec; 0.385 sec/batch; 33h:25m:40s remains)
INFO - root - 2017-12-17 04:28:33.555333: step 19920, loss = 0.12, batch loss = 0.08 (22.7 examples/sec; 0.352 sec/batch; 30h:32m:27s remains)
INFO - root - 2017-12-17 04:28:37.223858: step 19930, loss = 0.10, batch loss = 0.07 (21.5 examples/sec; 0.372 sec/batch; 32h:16m:20s remains)
INFO - root - 2017-12-17 04:28:40.888794: step 19940, loss = 0.09, batch loss = 0.06 (20.7 examples/sec; 0.387 sec/batch; 33h:34m:50s remains)
INFO - root - 2017-12-17 04:28:44.601956: step 19950, loss = 0.09, batch loss = 0.06 (21.5 examples/sec; 0.372 sec/batch; 32h:16m:18s remains)
INFO - root - 2017-12-17 04:28:48.304559: step 19960, loss = 0.10, batch loss = 0.07 (20.9 examples/sec; 0.382 sec/batch; 33h:10m:54s remains)
INFO - root - 2017-12-17 04:28:52.063926: step 19970, loss = 0.12, batch loss = 0.08 (21.3 examples/sec; 0.375 sec/batch; 32h:33m:22s remains)
INFO - root - 2017-12-17 04:28:55.800382: step 19980, loss = 0.10, batch loss = 0.06 (21.2 examples/sec; 0.378 sec/batch; 32h:47m:19s remains)
INFO - root - 2017-12-17 04:28:59.605028: step 19990, loss = 0.09, batch loss = 0.06 (20.6 examples/sec; 0.388 sec/batch; 33h:39m:45s remains)
INFO - root - 2017-12-17 04:29:03.320148: step 20000, loss = 0.12, batch loss = 0.08 (21.1 examples/sec; 0.379 sec/batch; 32h:51m:39s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-20000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-20000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 04:29:07.741799: step 20010, loss = 0.09, batch loss = 0.06 (22.3 examples/sec; 0.359 sec/batch; 31h:08m:07s remains)
INFO - root - 2017-12-17 04:29:11.494190: step 20020, loss = 0.10, batch loss = 0.06 (21.5 examples/sec; 0.372 sec/batch; 32h:16m:17s remains)
INFO - root - 2017-12-17 04:29:15.232969: step 20030, loss = 0.10, batch loss = 0.06 (21.7 examples/sec; 0.369 sec/batch; 32h:04m:15s remains)
INFO - root - 2017-12-17 04:29:18.960724: step 20040, loss = 0.12, batch loss = 0.09 (22.0 examples/sec; 0.363 sec/batch; 31h:31m:16s remains)
INFO - root - 2017-12-17 04:29:22.678644: step 20050, loss = 0.11, batch loss = 0.08 (21.9 examples/sec; 0.365 sec/batch; 31h:39m:26s remains)
INFO - root - 2017-12-17 04:29:26.382470: step 20060, loss = 0.10, batch loss = 0.07 (21.4 examples/sec; 0.374 sec/batch; 32h:26m:13s remains)
INFO - root - 2017-12-17 04:29:30.125119: step 20070, loss = 0.12, batch loss = 0.09 (22.0 examples/sec; 0.364 sec/batch; 31h:35m:47s remains)
INFO - root - 2017-12-17 04:29:33.571462: step 20080, loss = 0.15, batch loss = 0.11 (36.3 examples/sec; 0.220 sec/batch; 19h:07m:42s remains)
INFO - root - 2017-12-17 04:29:35.931860: step 20090, loss = 0.10, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 19h:00m:37s remains)
INFO - root - 2017-12-17 04:29:38.176076: step 20100, loss = 0.11, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 18h:58m:55s remains)
INFO - root - 2017-12-17 04:29:40.548801: step 20110, loss = 0.08, batch loss = 0.05 (37.4 examples/sec; 0.214 sec/batch; 18h:33m:59s remains)
INFO - root - 2017-12-17 04:29:42.782135: step 20120, loss = 0.10, batch loss = 0.06 (36.8 examples/sec; 0.217 sec/batch; 18h:51m:22s remains)
INFO - root - 2017-12-17 04:29:44.994042: step 20130, loss = 0.12, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 19h:04m:44s remains)
INFO - root - 2017-12-17 04:29:47.174203: step 20140, loss = 0.08, batch loss = 0.05 (37.1 examples/sec; 0.215 sec/batch; 18h:41m:36s remains)
INFO - root - 2017-12-17 04:29:49.375794: step 20150, loss = 0.14, batch loss = 0.10 (36.7 examples/sec; 0.218 sec/batch; 18h:54m:34s remains)
INFO - root - 2017-12-17 04:29:51.595679: step 20160, loss = 0.10, batch loss = 0.07 (36.9 examples/sec; 0.217 sec/batch; 18h:49m:11s remains)
INFO - root - 2017-12-17 04:29:53.844957: step 20170, loss = 0.09, batch loss = 0.05 (36.4 examples/sec; 0.220 sec/batch; 19h:02m:59s remains)
INFO - root - 2017-12-17 04:29:56.053617: step 20180, loss = 0.09, batch loss = 0.06 (37.1 examples/sec; 0.216 sec/batch; 18h:42m:12s remains)
INFO - root - 2017-12-17 04:29:58.254051: step 20190, loss = 0.11, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 19h:07m:20s remains)
INFO - root - 2017-12-17 04:30:00.532124: step 20200, loss = 0.16, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 19h:31m:19s remains)
INFO - root - 2017-12-17 04:30:02.861032: step 20210, loss = 0.11, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 19h:11m:32s remains)
INFO - root - 2017-12-17 04:30:05.098952: step 20220, loss = 0.23, batch loss = 0.20 (35.1 examples/sec; 0.228 sec/batch; 19h:45m:36s remains)
INFO - root - 2017-12-17 04:30:07.349281: step 20230, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 19h:30m:02s remains)
INFO - root - 2017-12-17 04:30:09.606835: step 20240, loss = 0.13, batch loss = 0.09 (34.3 examples/sec; 0.233 sec/batch; 20h:12m:47s remains)
INFO - root - 2017-12-17 04:30:11.786047: step 20250, loss = 0.10, batch loss = 0.07 (38.3 examples/sec; 0.209 sec/batch; 18h:05m:53s remains)
INFO - root - 2017-12-17 04:30:13.984267: step 20260, loss = 0.13, batch loss = 0.09 (34.5 examples/sec; 0.232 sec/batch; 20h:07m:48s remains)
INFO - root - 2017-12-17 04:30:16.245584: step 20270, loss = 0.13, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:18m:19s remains)
INFO - root - 2017-12-17 04:30:18.486154: step 20280, loss = 0.11, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 18h:57m:40s remains)
INFO - root - 2017-12-17 04:30:20.693625: step 20290, loss = 0.08, batch loss = 0.05 (35.6 examples/sec; 0.225 sec/batch; 19h:29m:34s remains)
INFO - root - 2017-12-17 04:30:22.916141: step 20300, loss = 0.09, batch loss = 0.05 (34.7 examples/sec; 0.230 sec/batch; 19h:58m:58s remains)
INFO - root - 2017-12-17 04:30:25.267401: step 20310, loss = 0.11, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 18h:58m:50s remains)
INFO - root - 2017-12-17 04:30:27.493276: step 20320, loss = 0.16, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 19h:17m:59s remains)
INFO - root - 2017-12-17 04:30:29.747458: step 20330, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 19h:02m:04s remains)
INFO - root - 2017-12-17 04:30:31.962331: step 20340, loss = 0.16, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 19h:06m:40s remains)
INFO - root - 2017-12-17 04:30:34.235040: step 20350, loss = 0.09, batch loss = 0.05 (34.7 examples/sec; 0.230 sec/batch; 19h:58m:00s remains)
INFO - root - 2017-12-17 04:30:36.443466: step 20360, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.223 sec/batch; 19h:21m:54s remains)
INFO - root - 2017-12-17 04:30:38.665852: step 20370, loss = 0.08, batch loss = 0.05 (35.5 examples/sec; 0.226 sec/batch; 19h:33m:16s remains)
INFO - root - 2017-12-17 04:30:40.873686: step 20380, loss = 0.14, batch loss = 0.11 (36.3 examples/sec; 0.221 sec/batch; 19h:07m:23s remains)
INFO - root - 2017-12-17 04:30:43.059709: step 20390, loss = 0.11, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 19h:16m:20s remains)
INFO - root - 2017-12-17 04:30:45.291957: step 20400, loss = 0.09, batch loss = 0.05 (35.1 examples/sec; 0.228 sec/batch; 19h:44m:34s remains)
INFO - root - 2017-12-17 04:30:47.657653: step 20410, loss = 0.12, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 19h:28m:11s remains)
INFO - root - 2017-12-17 04:30:49.895087: step 20420, loss = 0.10, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 19h:20m:40s remains)
INFO - root - 2017-12-17 04:30:52.108195: step 20430, loss = 0.09, batch loss = 0.06 (36.9 examples/sec; 0.217 sec/batch; 18h:47m:28s remains)
INFO - root - 2017-12-17 04:30:54.355114: step 20440, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 19h:28m:26s remains)
INFO - root - 2017-12-17 04:30:56.528030: step 20450, loss = 0.12, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 19h:08m:02s remains)
INFO - root - 2017-12-17 04:30:58.736012: step 20460, loss = 0.08, batch loss = 0.05 (35.3 examples/sec; 0.227 sec/batch; 19h:39m:11s remains)
INFO - root - 2017-12-17 04:31:00.944308: step 20470, loss = 0.15, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 19h:28m:59s remains)
INFO - root - 2017-12-17 04:31:03.140696: step 20480, loss = 0.14, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 19h:02m:23s remains)
INFO - root - 2017-12-17 04:31:05.388399: step 20490, loss = 0.10, batch loss = 0.07 (35.4 examples/sec; 0.226 sec/batch; 19h:35m:14s remains)
INFO - root - 2017-12-17 04:31:07.632934: step 20500, loss = 0.17, batch loss = 0.13 (35.8 examples/sec; 0.224 sec/batch; 19h:23m:29s remains)
INFO - root - 2017-12-17 04:31:10.020579: step 20510, loss = 0.15, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 19h:29m:03s remains)
INFO - root - 2017-12-17 04:31:12.256571: step 20520, loss = 0.15, batch loss = 0.11 (36.7 examples/sec; 0.218 sec/batch; 18h:53m:28s remains)
INFO - root - 2017-12-17 04:31:14.503045: step 20530, loss = 0.11, batch loss = 0.08 (34.6 examples/sec; 0.231 sec/batch; 20h:01m:35s remains)
INFO - root - 2017-12-17 04:31:16.720600: step 20540, loss = 0.13, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 19h:13m:47s remains)
INFO - root - 2017-12-17 04:31:18.975007: step 20550, loss = 0.11, batch loss = 0.08 (35.0 examples/sec; 0.229 sec/batch; 19h:48m:29s remains)
INFO - root - 2017-12-17 04:31:21.229322: step 20560, loss = 0.09, batch loss = 0.05 (35.9 examples/sec; 0.223 sec/batch; 19h:19m:36s remains)
INFO - root - 2017-12-17 04:31:23.457141: step 20570, loss = 0.11, batch loss = 0.08 (35.2 examples/sec; 0.227 sec/batch; 19h:40m:09s remains)
INFO - root - 2017-12-17 04:31:25.671207: step 20580, loss = 0.17, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 19h:50m:14s remains)
INFO - root - 2017-12-17 04:31:27.906178: step 20590, loss = 0.12, batch loss = 0.08 (36.3 examples/sec; 0.221 sec/batch; 19h:06m:50s remains)
INFO - root - 2017-12-17 04:31:30.126640: step 20600, loss = 0.11, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 18h:59m:00s remains)
INFO - root - 2017-12-17 04:31:32.495365: step 20610, loss = 0.10, batch loss = 0.06 (34.5 examples/sec; 0.232 sec/batch; 20h:05m:09s remains)
INFO - root - 2017-12-17 04:31:34.715854: step 20620, loss = 0.14, batch loss = 0.10 (37.2 examples/sec; 0.215 sec/batch; 18h:36m:38s remains)
INFO - root - 2017-12-17 04:31:36.921647: step 20630, loss = 0.13, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 19h:03m:37s remains)
INFO - root - 2017-12-17 04:31:39.167802: step 20640, loss = 0.09, batch loss = 0.05 (36.0 examples/sec; 0.222 sec/batch; 19h:15m:09s remains)
INFO - root - 2017-12-17 04:31:41.389107: step 20650, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 19h:26m:06s remains)
INFO - root - 2017-12-17 04:31:43.634241: step 20660, loss = 0.09, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 19h:14m:14s remains)
INFO - root - 2017-12-17 04:31:45.891286: step 20670, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 19h:22m:58s remains)
INFO - root - 2017-12-17 04:31:48.085334: step 20680, loss = 0.09, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 18h:59m:15s remains)
INFO - root - 2017-12-17 04:31:50.350985: step 20690, loss = 0.10, batch loss = 0.06 (34.8 examples/sec; 0.230 sec/batch; 19h:53m:20s remains)
INFO - root - 2017-12-17 04:31:52.594922: step 20700, loss = 0.12, batch loss = 0.09 (35.0 examples/sec; 0.228 sec/batch; 19h:47m:18s remains)
INFO - root - 2017-12-17 04:31:54.960776: step 20710, loss = 0.12, batch loss = 0.09 (35.5 examples/sec; 0.225 sec/batch; 19h:29m:43s remains)
INFO - root - 2017-12-17 04:31:57.204604: step 20720, loss = 0.09, batch loss = 0.06 (36.6 examples/sec; 0.219 sec/batch; 18h:56m:42s remains)
INFO - root - 2017-12-17 04:31:59.427771: step 20730, loss = 0.18, batch loss = 0.15 (36.8 examples/sec; 0.218 sec/batch; 18h:50m:52s remains)
INFO - root - 2017-12-17 04:32:01.627296: step 20740, loss = 0.09, batch loss = 0.06 (35.8 examples/sec; 0.223 sec/batch; 19h:19m:55s remains)
INFO - root - 2017-12-17 04:32:03.869494: step 20750, loss = 0.09, batch loss = 0.06 (34.3 examples/sec; 0.233 sec/batch; 20h:10m:47s remains)
INFO - root - 2017-12-17 04:32:06.117749: step 20760, loss = 0.12, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 19h:06m:42s remains)
INFO - root - 2017-12-17 04:32:08.366138: step 20770, loss = 0.12, batch loss = 0.08 (36.3 examples/sec; 0.220 sec/batch; 19h:03m:28s remains)
INFO - root - 2017-12-17 04:32:10.584761: step 20780, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 19h:05m:18s remains)
INFO - root - 2017-12-17 04:32:12.839812: step 20790, loss = 0.09, batch loss = 0.06 (35.8 examples/sec; 0.223 sec/batch; 19h:19m:47s remains)
INFO - root - 2017-12-17 04:32:15.084387: step 20800, loss = 0.10, batch loss = 0.06 (35.1 examples/sec; 0.228 sec/batch; 19h:45m:24s remains)
INFO - root - 2017-12-17 04:32:17.465871: step 20810, loss = 0.12, batch loss = 0.09 (33.9 examples/sec; 0.236 sec/batch; 20h:27m:33s remains)
INFO - root - 2017-12-17 04:32:19.724393: step 20820, loss = 0.13, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 18h:55m:17s remains)
INFO - root - 2017-12-17 04:32:21.963928: step 20830, loss = 0.12, batch loss = 0.08 (34.9 examples/sec; 0.229 sec/batch; 19h:51m:13s remains)
INFO - root - 2017-12-17 04:32:24.176845: step 20840, loss = 0.12, batch loss = 0.09 (34.7 examples/sec; 0.231 sec/batch; 19h:59m:13s remains)
INFO - root - 2017-12-17 04:32:26.413613: step 20850, loss = 0.11, batch loss = 0.08 (36.1 examples/sec; 0.222 sec/batch; 19h:11m:32s remains)
INFO - root - 2017-12-17 04:32:28.651508: step 20860, loss = 0.09, batch loss = 0.05 (35.7 examples/sec; 0.224 sec/batch; 19h:24m:20s remains)
INFO - root - 2017-12-17 04:32:30.872911: step 20870, loss = 0.15, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 19h:23m:25s remains)
INFO - root - 2017-12-17 04:32:33.135351: step 20880, loss = 0.14, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 19h:13m:48s remains)
INFO - root - 2017-12-17 04:32:35.394531: step 20890, loss = 0.11, batch loss = 0.08 (34.9 examples/sec; 0.229 sec/batch; 19h:51m:11s remains)
INFO - root - 2017-12-17 04:32:37.604868: step 20900, loss = 0.13, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 19h:02m:47s remains)
INFO - root - 2017-12-17 04:32:39.956749: step 20910, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.223 sec/batch; 19h:20m:37s remains)
INFO - root - 2017-12-17 04:32:42.211607: step 20920, loss = 0.10, batch loss = 0.06 (34.6 examples/sec; 0.231 sec/batch; 20h:01m:43s remains)
INFO - root - 2017-12-17 04:32:44.457973: step 20930, loss = 0.11, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 19h:27m:33s remains)
INFO - root - 2017-12-17 04:32:46.738297: step 20940, loss = 0.13, batch loss = 0.09 (34.7 examples/sec; 0.231 sec/batch; 19h:57m:41s remains)
INFO - root - 2017-12-17 04:32:48.957684: step 20950, loss = 0.14, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 19h:13m:33s remains)
INFO - root - 2017-12-17 04:32:51.227373: step 20960, loss = 0.19, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 19h:39m:22s remains)
INFO - root - 2017-12-17 04:32:53.452441: step 20970, loss = 0.14, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 19h:08m:41s remains)
INFO - root - 2017-12-17 04:32:55.701405: step 20980, loss = 0.11, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 19h:01m:13s remains)
INFO - root - 2017-12-17 04:32:57.954559: step 20990, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 19h:13m:35s remains)
INFO - root - 2017-12-17 04:33:00.152756: step 21000, loss = 0.11, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 19h:10m:38s remains)
INFO - root - 2017-12-17 04:33:02.502275: step 21010, loss = 0.10, batch loss = 0.07 (37.5 examples/sec; 0.213 sec/batch; 18h:27m:18s remains)
INFO - root - 2017-12-17 04:33:04.710935: step 21020, loss = 0.10, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 18h:52m:06s remains)
INFO - root - 2017-12-17 04:33:07.022813: step 21030, loss = 0.09, batch loss = 0.06 (35.2 examples/sec; 0.227 sec/batch; 19h:38m:18s remains)
INFO - root - 2017-12-17 04:33:09.269056: step 21040, loss = 0.11, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 19h:27m:38s remains)
INFO - root - 2017-12-17 04:33:11.508819: step 21050, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.221 sec/batch; 19h:04m:44s remains)
INFO - root - 2017-12-17 04:33:13.724153: step 21060, loss = 0.12, batch loss = 0.09 (34.8 examples/sec; 0.230 sec/batch; 19h:52m:27s remains)
INFO - root - 2017-12-17 04:33:15.969657: step 21070, loss = 0.10, batch loss = 0.06 (34.7 examples/sec; 0.230 sec/batch; 19h:56m:22s remains)
INFO - root - 2017-12-17 04:33:18.184894: step 21080, loss = 0.10, batch loss = 0.07 (36.8 examples/sec; 0.218 sec/batch; 18h:49m:31s remains)
INFO - root - 2017-12-17 04:33:20.419411: step 21090, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 19h:14m:46s remains)
INFO - root - 2017-12-17 04:33:22.655484: step 21100, loss = 0.11, batch loss = 0.07 (35.5 examples/sec; 0.225 sec/batch; 19h:29m:20s remains)
INFO - root - 2017-12-17 04:33:25.093515: step 21110, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.228 sec/batch; 19h:40m:55s remains)
INFO - root - 2017-12-17 04:33:27.327906: step 21120, loss = 0.10, batch loss = 0.07 (34.9 examples/sec; 0.229 sec/batch; 19h:48m:16s remains)
INFO - root - 2017-12-17 04:33:29.577434: step 21130, loss = 0.11, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 19h:07m:38s remains)
INFO - root - 2017-12-17 04:33:31.822604: step 21140, loss = 0.12, batch loss = 0.09 (35.8 examples/sec; 0.223 sec/batch; 19h:18m:14s remains)
INFO - root - 2017-12-17 04:33:34.128919: step 21150, loss = 0.10, batch loss = 0.07 (34.4 examples/sec; 0.233 sec/batch; 20h:07m:00s remains)
INFO - root - 2017-12-17 04:33:36.364992: step 21160, loss = 0.14, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 19h:05m:48s remains)
INFO - root - 2017-12-17 04:33:38.619518: step 21170, loss = 0.09, batch loss = 0.06 (35.0 examples/sec; 0.229 sec/batch; 19h:47m:41s remains)
INFO - root - 2017-12-17 04:33:40.854117: step 21180, loss = 0.09, batch loss = 0.06 (35.0 examples/sec; 0.229 sec/batch; 19h:47m:00s remains)
INFO - root - 2017-12-17 04:33:43.115115: step 21190, loss = 0.12, batch loss = 0.08 (36.6 examples/sec; 0.218 sec/batch; 18h:52m:47s remains)
INFO - root - 2017-12-17 04:33:45.354336: step 21200, loss = 0.13, batch loss = 0.10 (36.1 examples/sec; 0.221 sec/batch; 19h:08m:15s remains)
INFO - root - 2017-12-17 04:33:47.719862: step 21210, loss = 0.12, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 18h:55m:55s remains)
INFO - root - 2017-12-17 04:33:49.960587: step 21220, loss = 0.11, batch loss = 0.08 (35.4 examples/sec; 0.226 sec/batch; 19h:33m:05s remains)
INFO - root - 2017-12-17 04:33:52.207375: step 21230, loss = 0.12, batch loss = 0.09 (35.8 examples/sec; 0.224 sec/batch; 19h:20m:14s remains)
INFO - root - 2017-12-17 04:33:54.468605: step 21240, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 19h:11m:18s remains)
INFO - root - 2017-12-17 04:33:56.744906: step 21250, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.223 sec/batch; 19h:18m:09s remains)
INFO - root - 2017-12-17 04:33:58.958914: step 21260, loss = 0.10, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 18h:56m:00s remains)
INFO - root - 2017-12-17 04:34:01.186883: step 21270, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.221 sec/batch; 19h:04m:02s remains)
INFO - root - 2017-12-17 04:34:03.458759: step 21280, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 19h:02m:00s remains)
INFO - root - 2017-12-17 04:34:05.698338: step 21290, loss = 0.24, batch loss = 0.20 (36.4 examples/sec; 0.220 sec/batch; 19h:00m:22s remains)
INFO - root - 2017-12-17 04:34:07.920836: step 21300, loss = 0.12, batch loss = 0.09 (36.3 examples/sec; 0.220 sec/batch; 19h:02m:29s remains)
INFO - root - 2017-12-17 04:34:10.300211: step 21310, loss = 0.13, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 18h:59m:37s remains)
INFO - root - 2017-12-17 04:34:12.525884: step 21320, loss = 0.11, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 19h:25m:59s remains)
INFO - root - 2017-12-17 04:34:14.761580: step 21330, loss = 0.10, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 19h:06m:46s remains)
INFO - root - 2017-12-17 04:34:16.997246: step 21340, loss = 0.11, batch loss = 0.08 (35.3 examples/sec; 0.227 sec/batch; 19h:36m:53s remains)
INFO - root - 2017-12-17 04:34:19.263332: step 21350, loss = 0.12, batch loss = 0.09 (36.3 examples/sec; 0.220 sec/batch; 19h:01m:52s remains)
INFO - root - 2017-12-17 04:34:21.507270: step 21360, loss = 0.09, batch loss = 0.05 (36.7 examples/sec; 0.218 sec/batch; 18h:49m:42s remains)
INFO - root - 2017-12-17 04:34:23.726509: step 21370, loss = 0.09, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 18h:51m:40s remains)
INFO - root - 2017-12-17 04:34:25.966787: step 21380, loss = 0.09, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 19h:05m:37s remains)
INFO - root - 2017-12-17 04:34:28.210941: step 21390, loss = 0.12, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 19h:12m:26s remains)
INFO - root - 2017-12-17 04:34:30.463246: step 21400, loss = 0.12, batch loss = 0.08 (35.5 examples/sec; 0.225 sec/batch; 19h:29m:07s remains)
INFO - root - 2017-12-17 04:34:32.800313: step 21410, loss = 0.15, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 19h:25m:12s remains)
INFO - root - 2017-12-17 04:34:35.003514: step 21420, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 19h:23m:16s remains)
INFO - root - 2017-12-17 04:34:37.269838: step 21430, loss = 0.11, batch loss = 0.07 (33.8 examples/sec; 0.236 sec/batch; 20h:25m:53s remains)
INFO - root - 2017-12-17 04:34:39.526454: step 21440, loss = 0.08, batch loss = 0.04 (36.2 examples/sec; 0.221 sec/batch; 19h:05m:44s remains)
INFO - root - 2017-12-17 04:34:41.742550: step 21450, loss = 0.14, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 19h:09m:36s remains)
INFO - root - 2017-12-17 04:34:44.013890: step 21460, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:58m:48s remains)
INFO - root - 2017-12-17 04:34:46.208072: step 21470, loss = 0.15, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 18h:58m:22s remains)
INFO - root - 2017-12-17 04:34:48.426038: step 21480, loss = 0.09, batch loss = 0.06 (35.8 examples/sec; 0.223 sec/batch; 19h:18m:18s remains)
INFO - root - 2017-12-17 04:34:50.655850: step 21490, loss = 0.11, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 19h:25m:55s remains)
INFO - root - 2017-12-17 04:34:52.888262: step 21500, loss = 0.11, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 18h:59m:45s remains)
INFO - root - 2017-12-17 04:34:55.289492: step 21510, loss = 0.09, batch loss = 0.05 (35.9 examples/sec; 0.223 sec/batch; 19h:13m:45s remains)
INFO - root - 2017-12-17 04:34:57.512539: step 21520, loss = 0.12, batch loss = 0.08 (36.8 examples/sec; 0.217 sec/batch; 18h:46m:41s remains)
INFO - root - 2017-12-17 04:34:59.738191: step 21530, loss = 0.14, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 19h:30m:00s remains)
INFO - root - 2017-12-17 04:35:01.992358: step 21540, loss = 0.09, batch loss = 0.06 (37.5 examples/sec; 0.213 sec/batch; 18h:26m:08s remains)
INFO - root - 2017-12-17 04:35:04.233102: step 21550, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 19h:18m:35s remains)
INFO - root - 2017-12-17 04:35:06.475500: step 21560, loss = 0.10, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 19h:20m:08s remains)
INFO - root - 2017-12-17 04:35:08.794788: step 21570, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 19h:05m:32s remains)
INFO - root - 2017-12-17 04:35:11.033882: step 21580, loss = 0.11, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 19h:14m:55s remains)
INFO - root - 2017-12-17 04:35:13.251962: step 21590, loss = 0.11, batch loss = 0.08 (36.1 examples/sec; 0.222 sec/batch; 19h:07m:50s remains)
INFO - root - 2017-12-17 04:35:15.489008: step 21600, loss = 0.10, batch loss = 0.06 (35.5 examples/sec; 0.225 sec/batch; 19h:26m:59s remains)
INFO - root - 2017-12-17 04:35:17.835890: step 21610, loss = 0.13, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:10m:38s remains)
INFO - root - 2017-12-17 04:35:20.047644: step 21620, loss = 0.13, batch loss = 0.10 (35.8 examples/sec; 0.223 sec/batch; 19h:16m:17s remains)
INFO - root - 2017-12-17 04:35:22.254341: step 21630, loss = 0.09, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 18h:56m:20s remains)
INFO - root - 2017-12-17 04:35:24.468288: step 21640, loss = 0.14, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 18h:55m:50s remains)
INFO - root - 2017-12-17 04:35:26.705521: step 21650, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 19h:06m:19s remains)
INFO - root - 2017-12-17 04:35:28.907788: step 21660, loss = 0.12, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 18h:57m:31s remains)
INFO - root - 2017-12-17 04:35:31.132253: step 21670, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 19h:21m:16s remains)
INFO - root - 2017-12-17 04:35:33.371046: step 21680, loss = 0.13, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 19h:29m:11s remains)
INFO - root - 2017-12-17 04:35:35.606257: step 21690, loss = 0.10, batch loss = 0.06 (37.2 examples/sec; 0.215 sec/batch; 18h:33m:04s remains)
INFO - root - 2017-12-17 04:35:37.861656: step 21700, loss = 0.11, batch loss = 0.08 (35.4 examples/sec; 0.226 sec/batch; 19h:30m:15s remains)
INFO - root - 2017-12-17 04:35:40.216945: step 21710, loss = 0.11, batch loss = 0.08 (34.7 examples/sec; 0.231 sec/batch; 19h:55m:19s remains)
INFO - root - 2017-12-17 04:35:42.460806: step 21720, loss = 0.11, batch loss = 0.08 (35.3 examples/sec; 0.226 sec/batch; 19h:32m:50s remains)
INFO - root - 2017-12-17 04:35:44.686175: step 21730, loss = 0.09, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 18h:55m:40s remains)
INFO - root - 2017-12-17 04:35:46.924188: step 21740, loss = 0.13, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:14m:10s remains)
INFO - root - 2017-12-17 04:35:49.151456: step 21750, loss = 0.08, batch loss = 0.05 (35.7 examples/sec; 0.224 sec/batch; 19h:21m:49s remains)
INFO - root - 2017-12-17 04:35:51.398516: step 21760, loss = 0.11, batch loss = 0.08 (35.1 examples/sec; 0.228 sec/batch; 19h:41m:37s remains)
INFO - root - 2017-12-17 04:35:53.650205: step 21770, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 19h:36m:52s remains)
INFO - root - 2017-12-17 04:35:55.858517: step 21780, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 19h:08m:09s remains)
INFO - root - 2017-12-17 04:35:58.115728: step 21790, loss = 0.15, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 19h:33m:02s remains)
INFO - root - 2017-12-17 04:36:00.342932: step 21800, loss = 0.12, batch loss = 0.08 (36.3 examples/sec; 0.220 sec/batch; 19h:00m:00s remains)
INFO - root - 2017-12-17 04:36:02.739039: step 21810, loss = 0.17, batch loss = 0.14 (35.3 examples/sec; 0.227 sec/batch; 19h:33m:25s remains)
INFO - root - 2017-12-17 04:36:04.975027: step 21820, loss = 0.14, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 18h:52m:46s remains)
INFO - root - 2017-12-17 04:36:07.236488: step 21830, loss = 0.10, batch loss = 0.07 (35.3 examples/sec; 0.227 sec/batch; 19h:34m:56s remains)
INFO - root - 2017-12-17 04:36:09.474793: step 21840, loss = 0.14, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 18h:54m:29s remains)
INFO - root - 2017-12-17 04:36:11.769562: step 21850, loss = 0.11, batch loss = 0.08 (34.6 examples/sec; 0.231 sec/batch; 19h:56m:29s remains)
INFO - root - 2017-12-17 04:36:14.028033: step 21860, loss = 0.11, batch loss = 0.07 (35.0 examples/sec; 0.229 sec/batch; 19h:43m:57s remains)
INFO - root - 2017-12-17 04:36:16.249908: step 21870, loss = 0.09, batch loss = 0.06 (35.1 examples/sec; 0.228 sec/batch; 19h:38m:25s remains)
INFO - root - 2017-12-17 04:36:18.522885: step 21880, loss = 0.10, batch loss = 0.06 (34.4 examples/sec; 0.232 sec/batch; 20h:02m:23s remains)
INFO - root - 2017-12-17 04:36:20.764579: step 21890, loss = 0.11, batch loss = 0.07 (34.8 examples/sec; 0.230 sec/batch; 19h:49m:56s remains)
INFO - root - 2017-12-17 04:36:23.033426: step 21900, loss = 0.10, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 19h:14m:39s remains)
INFO - root - 2017-12-17 04:36:25.383433: step 21910, loss = 0.13, batch loss = 0.09 (34.0 examples/sec; 0.235 sec/batch; 20h:17m:49s remains)
INFO - root - 2017-12-17 04:36:27.630634: step 21920, loss = 0.18, batch loss = 0.14 (37.0 examples/sec; 0.216 sec/batch; 18h:37m:56s remains)
INFO - root - 2017-12-17 04:36:29.878186: step 21930, loss = 0.09, batch loss = 0.05 (37.1 examples/sec; 0.216 sec/batch; 18h:36m:57s remains)
INFO - root - 2017-12-17 04:36:32.108003: step 21940, loss = 0.09, batch loss = 0.05 (36.0 examples/sec; 0.222 sec/batch; 19h:11m:17s remains)
INFO - root - 2017-12-17 04:36:34.300480: step 21950, loss = 0.11, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 19h:00m:05s remains)
INFO - root - 2017-12-17 04:36:36.546047: step 21960, loss = 0.14, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 18h:54m:53s remains)
INFO - root - 2017-12-17 04:36:38.788526: step 21970, loss = 0.08, batch loss = 0.05 (34.9 examples/sec; 0.229 sec/batch; 19h:44m:53s remains)
INFO - root - 2017-12-17 04:36:41.044650: step 21980, loss = 0.14, batch loss = 0.10 (34.1 examples/sec; 0.234 sec/batch; 20h:13m:06s remains)
INFO - root - 2017-12-17 04:36:43.244623: step 21990, loss = 0.13, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 18h:50m:51s remains)
INFO - root - 2017-12-17 04:36:45.444293: step 22000, loss = 0.09, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 18h:47m:33s remains)
INFO - root - 2017-12-17 04:36:47.770068: step 22010, loss = 0.09, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 18h:54m:37s remains)
INFO - root - 2017-12-17 04:36:50.000406: step 22020, loss = 0.11, batch loss = 0.08 (36.3 examples/sec; 0.220 sec/batch; 18h:59m:45s remains)
INFO - root - 2017-12-17 04:36:52.216643: step 22030, loss = 0.09, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 18h:53m:15s remains)
INFO - root - 2017-12-17 04:36:54.489952: step 22040, loss = 0.10, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 19h:21m:04s remains)
INFO - root - 2017-12-17 04:36:56.749599: step 22050, loss = 0.09, batch loss = 0.06 (34.8 examples/sec; 0.230 sec/batch; 19h:48m:03s remains)
INFO - root - 2017-12-17 04:36:58.980290: step 22060, loss = 0.16, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 19h:25m:26s remains)
INFO - root - 2017-12-17 04:37:01.242664: step 22070, loss = 0.20, batch loss = 0.17 (36.5 examples/sec; 0.219 sec/batch; 18h:54m:06s remains)
INFO - root - 2017-12-17 04:37:03.481482: step 22080, loss = 0.11, batch loss = 0.08 (36.3 examples/sec; 0.220 sec/batch; 19h:00m:00s remains)
INFO - root - 2017-12-17 04:37:05.696656: step 22090, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 19h:00m:07s remains)
INFO - root - 2017-12-17 04:37:07.904852: step 22100, loss = 0.08, batch loss = 0.05 (35.9 examples/sec; 0.223 sec/batch; 19h:12m:43s remains)
INFO - root - 2017-12-17 04:37:10.248273: step 22110, loss = 0.11, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 18h:50m:40s remains)
INFO - root - 2017-12-17 04:37:12.452352: step 22120, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 19h:16m:20s remains)
INFO - root - 2017-12-17 04:37:14.677317: step 22130, loss = 0.09, batch loss = 0.06 (36.6 examples/sec; 0.218 sec/batch; 18h:49m:54s remains)
INFO - root - 2017-12-17 04:37:16.919643: step 22140, loss = 0.09, batch loss = 0.06 (35.4 examples/sec; 0.226 sec/batch; 19h:29m:03s remains)
INFO - root - 2017-12-17 04:37:19.162795: step 22150, loss = 0.11, batch loss = 0.08 (36.3 examples/sec; 0.220 sec/batch; 18h:58m:40s remains)
INFO - root - 2017-12-17 04:37:21.358026: step 22160, loss = 0.12, batch loss = 0.08 (36.8 examples/sec; 0.217 sec/batch; 18h:42m:56s remains)
INFO - root - 2017-12-17 04:37:23.573610: step 22170, loss = 0.08, batch loss = 0.05 (37.0 examples/sec; 0.216 sec/batch; 18h:39m:04s remains)
INFO - root - 2017-12-17 04:37:25.782460: step 22180, loss = 0.10, batch loss = 0.06 (35.2 examples/sec; 0.227 sec/batch; 19h:36m:07s remains)
INFO - root - 2017-12-17 04:37:28.039179: step 22190, loss = 0.12, batch loss = 0.09 (34.9 examples/sec; 0.229 sec/batch; 19h:46m:42s remains)
INFO - root - 2017-12-17 04:37:30.248053: step 22200, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.221 sec/batch; 19h:04m:40s remains)
INFO - root - 2017-12-17 04:37:32.593474: step 22210, loss = 0.10, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 19h:13m:44s remains)
INFO - root - 2017-12-17 04:37:34.884378: step 22220, loss = 0.10, batch loss = 0.07 (30.4 examples/sec; 0.263 sec/batch; 22h:39m:28s remains)
INFO - root - 2017-12-17 04:37:37.075113: step 22230, loss = 0.15, batch loss = 0.12 (37.1 examples/sec; 0.216 sec/batch; 18h:36m:07s remains)
INFO - root - 2017-12-17 04:37:39.283242: step 22240, loss = 0.11, batch loss = 0.07 (37.4 examples/sec; 0.214 sec/batch; 18h:25m:32s remains)
INFO - root - 2017-12-17 04:37:41.526912: step 22250, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 19h:19m:25s remains)
INFO - root - 2017-12-17 04:37:43.714501: step 22260, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.221 sec/batch; 19h:00m:15s remains)
INFO - root - 2017-12-17 04:37:45.962327: step 22270, loss = 0.14, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 19h:38m:55s remains)
INFO - root - 2017-12-17 04:37:48.211939: step 22280, loss = 0.10, batch loss = 0.06 (34.5 examples/sec; 0.232 sec/batch; 19h:58m:00s remains)
INFO - root - 2017-12-17 04:37:50.447832: step 22290, loss = 0.11, batch loss = 0.08 (35.0 examples/sec; 0.229 sec/batch; 19h:42m:29s remains)
INFO - root - 2017-12-17 04:37:52.691665: step 22300, loss = 0.09, batch loss = 0.06 (33.9 examples/sec; 0.236 sec/batch; 20h:18m:29s remains)
INFO - root - 2017-12-17 04:37:55.062910: step 22310, loss = 0.12, batch loss = 0.08 (35.5 examples/sec; 0.225 sec/batch; 19h:24m:47s remains)
INFO - root - 2017-12-17 04:37:57.301267: step 22320, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 19h:07m:35s remains)
INFO - root - 2017-12-17 04:37:59.554617: step 22330, loss = 0.10, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 18h:50m:13s remains)
INFO - root - 2017-12-17 04:38:01.784410: step 22340, loss = 0.14, batch loss = 0.11 (36.8 examples/sec; 0.217 sec/batch; 18h:43m:18s remains)
INFO - root - 2017-12-17 04:38:04.004017: step 22350, loss = 0.12, batch loss = 0.08 (35.4 examples/sec; 0.226 sec/batch; 19h:28m:23s remains)
INFO - root - 2017-12-17 04:38:06.270201: step 22360, loss = 0.10, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 19h:17m:33s remains)
INFO - root - 2017-12-17 04:38:08.562435: step 22370, loss = 0.10, batch loss = 0.07 (33.8 examples/sec; 0.237 sec/batch; 20h:25m:04s remains)
INFO - root - 2017-12-17 04:38:10.820623: step 22380, loss = 0.10, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 19h:07m:39s remains)
INFO - root - 2017-12-17 04:38:13.052068: step 22390, loss = 0.10, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 18h:45m:08s remains)
INFO - root - 2017-12-17 04:38:15.271740: step 22400, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 19h:16m:51s remains)
INFO - root - 2017-12-17 04:38:17.611460: step 22410, loss = 0.09, batch loss = 0.05 (36.0 examples/sec; 0.222 sec/batch; 19h:08m:05s remains)
INFO - root - 2017-12-17 04:38:19.849011: step 22420, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 18h:59m:07s remains)
INFO - root - 2017-12-17 04:38:22.097061: step 22430, loss = 0.08, batch loss = 0.05 (35.4 examples/sec; 0.226 sec/batch; 19h:26m:32s remains)
INFO - root - 2017-12-17 04:38:24.374285: step 22440, loss = 0.10, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 19h:19m:10s remains)
INFO - root - 2017-12-17 04:38:26.635792: step 22450, loss = 0.13, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 18h:55m:54s remains)
INFO - root - 2017-12-17 04:38:28.858322: step 22460, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 19h:16m:34s remains)
INFO - root - 2017-12-17 04:38:31.101150: step 22470, loss = 0.17, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 18h:59m:00s remains)
INFO - root - 2017-12-17 04:38:33.319752: step 22480, loss = 0.09, batch loss = 0.06 (35.5 examples/sec; 0.225 sec/batch; 19h:23m:28s remains)
INFO - root - 2017-12-17 04:38:35.554903: step 22490, loss = 0.12, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:08m:36s remains)
INFO - root - 2017-12-17 04:38:37.750362: step 22500, loss = 0.10, batch loss = 0.06 (37.0 examples/sec; 0.216 sec/batch; 18h:37m:43s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-22500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-22500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 04:38:40.935985: step 22510, loss = 0.12, batch loss = 0.09 (35.1 examples/sec; 0.228 sec/batch; 19h:37m:59s remains)
INFO - root - 2017-12-17 04:38:43.178405: step 22520, loss = 0.14, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 19h:16m:50s remains)
INFO - root - 2017-12-17 04:38:45.399632: step 22530, loss = 0.10, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 18h:51m:25s remains)
INFO - root - 2017-12-17 04:38:47.648700: step 22540, loss = 0.09, batch loss = 0.06 (35.5 examples/sec; 0.226 sec/batch; 19h:25m:42s remains)
INFO - root - 2017-12-17 04:38:49.900382: step 22550, loss = 0.09, batch loss = 0.06 (35.6 examples/sec; 0.225 sec/batch; 19h:21m:21s remains)
INFO - root - 2017-12-17 04:38:52.129626: step 22560, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 18h:58m:32s remains)
INFO - root - 2017-12-17 04:38:54.335143: step 22570, loss = 0.11, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 19h:16m:13s remains)
INFO - root - 2017-12-17 04:38:56.529907: step 22580, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 18h:58m:07s remains)
INFO - root - 2017-12-17 04:38:58.771132: step 22590, loss = 0.15, batch loss = 0.12 (35.8 examples/sec; 0.223 sec/batch; 19h:13m:11s remains)
INFO - root - 2017-12-17 04:39:00.955485: step 22600, loss = 0.11, batch loss = 0.07 (37.8 examples/sec; 0.211 sec/batch; 18h:12m:21s remains)
INFO - root - 2017-12-17 04:39:03.292940: step 22610, loss = 0.10, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 18h:55m:21s remains)
INFO - root - 2017-12-17 04:39:05.496459: step 22620, loss = 0.13, batch loss = 0.10 (36.8 examples/sec; 0.217 sec/batch; 18h:42m:46s remains)
INFO - root - 2017-12-17 04:39:07.768359: step 22630, loss = 0.09, batch loss = 0.05 (34.2 examples/sec; 0.234 sec/batch; 20h:06m:24s remains)
INFO - root - 2017-12-17 04:39:10.022671: step 22640, loss = 0.11, batch loss = 0.08 (36.3 examples/sec; 0.220 sec/batch; 18h:58m:07s remains)
INFO - root - 2017-12-17 04:39:12.257406: step 22650, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 19h:33m:19s remains)
INFO - root - 2017-12-17 04:39:14.457171: step 22660, loss = 0.12, batch loss = 0.09 (37.1 examples/sec; 0.215 sec/batch; 18h:32m:18s remains)
INFO - root - 2017-12-17 04:39:16.668447: step 22670, loss = 0.10, batch loss = 0.06 (35.2 examples/sec; 0.227 sec/batch; 19h:33m:16s remains)
INFO - root - 2017-12-17 04:39:18.926080: step 22680, loss = 0.13, batch loss = 0.09 (34.7 examples/sec; 0.230 sec/batch; 19h:49m:52s remains)
INFO - root - 2017-12-17 04:39:21.174001: step 22690, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 19h:14m:13s remains)
INFO - root - 2017-12-17 04:39:23.362685: step 22700, loss = 0.09, batch loss = 0.06 (37.3 examples/sec; 0.215 sec/batch; 18h:28m:44s remains)
INFO - root - 2017-12-17 04:39:25.706350: step 22710, loss = 0.09, batch loss = 0.05 (36.4 examples/sec; 0.220 sec/batch; 18h:53m:29s remains)
INFO - root - 2017-12-17 04:39:27.933111: step 22720, loss = 0.10, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 19h:12m:00s remains)
INFO - root - 2017-12-17 04:39:30.172612: step 22730, loss = 0.10, batch loss = 0.07 (36.9 examples/sec; 0.217 sec/batch; 18h:38m:27s remains)
INFO - root - 2017-12-17 04:39:32.365478: step 22740, loss = 0.12, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 18h:49m:42s remains)
INFO - root - 2017-12-17 04:39:34.622669: step 22750, loss = 0.12, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 19h:26m:08s remains)
INFO - root - 2017-12-17 04:39:36.852542: step 22760, loss = 0.10, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 19h:00m:33s remains)
INFO - root - 2017-12-17 04:39:39.092969: step 22770, loss = 0.08, batch loss = 0.05 (34.4 examples/sec; 0.233 sec/batch; 20h:01m:35s remains)
INFO - root - 2017-12-17 04:39:41.379302: step 22780, loss = 0.11, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 19h:21m:22s remains)
INFO - root - 2017-12-17 04:39:43.596124: step 22790, loss = 0.14, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 18h:53m:20s remains)
INFO - root - 2017-12-17 04:39:45.785077: step 22800, loss = 0.11, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 18h:48m:08s remains)
INFO - root - 2017-12-17 04:39:48.118526: step 22810, loss = 0.11, batch loss = 0.08 (35.4 examples/sec; 0.226 sec/batch; 19h:25m:26s remains)
INFO - root - 2017-12-17 04:39:50.396086: step 22820, loss = 0.11, batch loss = 0.08 (35.2 examples/sec; 0.227 sec/batch; 19h:32m:43s remains)
INFO - root - 2017-12-17 04:39:52.664860: step 22830, loss = 0.12, batch loss = 0.09 (34.1 examples/sec; 0.235 sec/batch; 20h:11m:46s remains)
INFO - root - 2017-12-17 04:39:54.879898: step 22840, loss = 0.14, batch loss = 0.11 (37.4 examples/sec; 0.214 sec/batch; 18h:24m:29s remains)
INFO - root - 2017-12-17 04:39:57.089884: step 22850, loss = 0.12, batch loss = 0.08 (36.1 examples/sec; 0.222 sec/batch; 19h:03m:58s remains)
INFO - root - 2017-12-17 04:39:59.292291: step 22860, loss = 0.09, batch loss = 0.06 (37.1 examples/sec; 0.216 sec/batch; 18h:33m:03s remains)
INFO - root - 2017-12-17 04:40:01.522715: step 22870, loss = 0.11, batch loss = 0.07 (34.9 examples/sec; 0.230 sec/batch; 19h:44m:28s remains)
INFO - root - 2017-12-17 04:40:03.768817: step 22880, loss = 0.13, batch loss = 0.09 (35.8 examples/sec; 0.223 sec/batch; 19h:11m:55s remains)
INFO - root - 2017-12-17 04:40:05.984757: step 22890, loss = 0.12, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 18h:51m:53s remains)
INFO - root - 2017-12-17 04:40:08.211418: step 22900, loss = 0.14, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 19h:24m:52s remains)
INFO - root - 2017-12-17 04:40:10.551520: step 22910, loss = 0.09, batch loss = 0.06 (34.7 examples/sec; 0.231 sec/batch; 19h:50m:18s remains)
INFO - root - 2017-12-17 04:40:12.744235: step 22920, loss = 0.13, batch loss = 0.10 (34.7 examples/sec; 0.231 sec/batch; 19h:49m:21s remains)
INFO - root - 2017-12-17 04:40:14.981604: step 22930, loss = 0.11, batch loss = 0.07 (38.0 examples/sec; 0.210 sec/batch; 18h:04m:48s remains)
INFO - root - 2017-12-17 04:40:17.181431: step 22940, loss = 0.09, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 18h:54m:12s remains)
INFO - root - 2017-12-17 04:40:19.393878: step 22950, loss = 0.11, batch loss = 0.07 (35.4 examples/sec; 0.226 sec/batch; 19h:25m:04s remains)
INFO - root - 2017-12-17 04:40:21.599461: step 22960, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 19h:15m:38s remains)
INFO - root - 2017-12-17 04:40:23.833868: step 22970, loss = 0.12, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 19h:06m:07s remains)
INFO - root - 2017-12-17 04:40:26.067485: step 22980, loss = 0.18, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 18h:58m:43s remains)
INFO - root - 2017-12-17 04:40:28.269190: step 22990, loss = 0.10, batch loss = 0.07 (36.9 examples/sec; 0.217 sec/batch; 18h:39m:19s remains)
INFO - root - 2017-12-17 04:40:30.489394: step 23000, loss = 0.24, batch loss = 0.20 (36.7 examples/sec; 0.218 sec/batch; 18h:44m:47s remains)
INFO - root - 2017-12-17 04:40:32.868560: step 23010, loss = 0.16, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 18h:55m:35s remains)
INFO - root - 2017-12-17 04:40:35.085199: step 23020, loss = 0.09, batch loss = 0.06 (35.5 examples/sec; 0.225 sec/batch; 19h:22m:34s remains)
INFO - root - 2017-12-17 04:40:37.349891: step 23030, loss = 0.13, batch loss = 0.10 (36.8 examples/sec; 0.217 sec/batch; 18h:40m:45s remains)
INFO - root - 2017-12-17 04:40:39.578169: step 23040, loss = 0.17, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 18h:55m:15s remains)
INFO - root - 2017-12-17 04:40:41.762753: step 23050, loss = 0.11, batch loss = 0.08 (36.7 examples/sec; 0.218 sec/batch; 18h:43m:19s remains)
INFO - root - 2017-12-17 04:40:44.026009: step 23060, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.223 sec/batch; 19h:12m:09s remains)
INFO - root - 2017-12-17 04:40:46.230826: step 23070, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:52m:50s remains)
INFO - root - 2017-12-17 04:40:48.441794: step 23080, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 19h:13m:13s remains)
INFO - root - 2017-12-17 04:40:50.704908: step 23090, loss = 0.16, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:26m:42s remains)
INFO - root - 2017-12-17 04:40:52.921339: step 23100, loss = 0.08, batch loss = 0.05 (36.6 examples/sec; 0.219 sec/batch; 18h:48m:32s remains)
INFO - root - 2017-12-17 04:40:55.252090: step 23110, loss = 0.13, batch loss = 0.10 (37.3 examples/sec; 0.214 sec/batch; 18h:24m:47s remains)
INFO - root - 2017-12-17 04:40:57.481286: step 23120, loss = 0.12, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 18h:54m:47s remains)
INFO - root - 2017-12-17 04:40:59.729904: step 23130, loss = 0.09, batch loss = 0.06 (35.1 examples/sec; 0.228 sec/batch; 19h:34m:36s remains)
INFO - root - 2017-12-17 04:41:01.932137: step 23140, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:53m:53s remains)
INFO - root - 2017-12-17 04:41:04.152813: step 23150, loss = 0.13, batch loss = 0.10 (35.0 examples/sec; 0.229 sec/batch; 19h:39m:44s remains)
INFO - root - 2017-12-17 04:41:06.377974: step 23160, loss = 0.11, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 18h:58m:47s remains)
INFO - root - 2017-12-17 04:41:08.646166: step 23170, loss = 0.14, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 18h:48m:40s remains)
INFO - root - 2017-12-17 04:41:10.858632: step 23180, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 19h:06m:23s remains)
INFO - root - 2017-12-17 04:41:13.092824: step 23190, loss = 0.08, batch loss = 0.04 (36.4 examples/sec; 0.220 sec/batch; 18h:54m:31s remains)
INFO - root - 2017-12-17 04:41:15.294277: step 23200, loss = 0.11, batch loss = 0.08 (37.1 examples/sec; 0.216 sec/batch; 18h:32m:09s remains)
INFO - root - 2017-12-17 04:41:17.658735: step 23210, loss = 0.10, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 19h:08m:17s remains)
INFO - root - 2017-12-17 04:41:19.915587: step 23220, loss = 0.10, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 19h:14m:00s remains)
INFO - root - 2017-12-17 04:41:22.137143: step 23230, loss = 0.09, batch loss = 0.05 (36.6 examples/sec; 0.219 sec/batch; 18h:47m:02s remains)
INFO - root - 2017-12-17 04:41:24.354643: step 23240, loss = 0.11, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 19h:06m:24s remains)
INFO - root - 2017-12-17 04:41:26.554395: step 23250, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 18h:55m:11s remains)
INFO - root - 2017-12-17 04:41:28.765793: step 23260, loss = 0.14, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 18h:52m:10s remains)
INFO - root - 2017-12-17 04:41:31.030525: step 23270, loss = 0.12, batch loss = 0.08 (36.1 examples/sec; 0.222 sec/batch; 19h:02m:56s remains)
INFO - root - 2017-12-17 04:41:33.261344: step 23280, loss = 0.14, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 18h:46m:11s remains)
INFO - root - 2017-12-17 04:41:35.496214: step 23290, loss = 0.09, batch loss = 0.05 (36.6 examples/sec; 0.219 sec/batch; 18h:46m:49s remains)
INFO - root - 2017-12-17 04:41:37.754528: step 23300, loss = 0.10, batch loss = 0.06 (35.5 examples/sec; 0.226 sec/batch; 19h:22m:30s remains)
INFO - root - 2017-12-17 04:41:40.107169: step 23310, loss = 0.14, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 18h:50m:43s remains)
INFO - root - 2017-12-17 04:41:42.342562: step 23320, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.221 sec/batch; 18h:57m:04s remains)
INFO - root - 2017-12-17 04:41:44.580189: step 23330, loss = 0.12, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 19h:08m:05s remains)
INFO - root - 2017-12-17 04:41:46.824670: step 23340, loss = 0.12, batch loss = 0.09 (36.1 examples/sec; 0.222 sec/batch; 19h:01m:43s remains)
INFO - root - 2017-12-17 04:41:49.059940: step 23350, loss = 0.09, batch loss = 0.06 (34.1 examples/sec; 0.235 sec/batch; 20h:08m:52s remains)
INFO - root - 2017-12-17 04:41:51.311375: step 23360, loss = 0.11, batch loss = 0.08 (36.3 examples/sec; 0.221 sec/batch; 18h:56m:28s remains)
INFO - root - 2017-12-17 04:41:53.522619: step 23370, loss = 0.08, batch loss = 0.05 (35.9 examples/sec; 0.223 sec/batch; 19h:08m:31s remains)
INFO - root - 2017-12-17 04:41:55.718623: step 23380, loss = 0.09, batch loss = 0.05 (35.9 examples/sec; 0.223 sec/batch; 19h:07m:31s remains)
INFO - root - 2017-12-17 04:41:57.913847: step 23390, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.223 sec/batch; 19h:10m:28s remains)
INFO - root - 2017-12-17 04:42:00.184021: step 23400, loss = 0.11, batch loss = 0.07 (35.1 examples/sec; 0.228 sec/batch; 19h:34m:55s remains)
INFO - root - 2017-12-17 04:42:02.595867: step 23410, loss = 0.12, batch loss = 0.09 (32.9 examples/sec; 0.243 sec/batch; 20h:53m:08s remains)
INFO - root - 2017-12-17 04:42:04.838907: step 23420, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:58m:18s remains)
INFO - root - 2017-12-17 04:42:07.053476: step 23430, loss = 0.13, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 19h:12m:43s remains)
INFO - root - 2017-12-17 04:42:09.266237: step 23440, loss = 0.12, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 18h:51m:54s remains)
INFO - root - 2017-12-17 04:42:11.444972: step 23450, loss = 0.10, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 18h:44m:12s remains)
INFO - root - 2017-12-17 04:42:13.647211: step 23460, loss = 0.11, batch loss = 0.08 (36.8 examples/sec; 0.217 sec/batch; 18h:40m:11s remains)
INFO - root - 2017-12-17 04:42:15.877412: step 23470, loss = 0.11, batch loss = 0.08 (34.4 examples/sec; 0.233 sec/batch; 19h:59m:31s remains)
INFO - root - 2017-12-17 04:42:18.113534: step 23480, loss = 0.12, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:03m:53s remains)
INFO - root - 2017-12-17 04:42:20.309576: step 23490, loss = 0.10, batch loss = 0.06 (36.6 examples/sec; 0.218 sec/batch; 18h:45m:03s remains)
INFO - root - 2017-12-17 04:42:22.525997: step 23500, loss = 0.09, batch loss = 0.06 (35.6 examples/sec; 0.224 sec/batch; 19h:15m:52s remains)
INFO - root - 2017-12-17 04:42:24.921947: step 23510, loss = 0.19, batch loss = 0.16 (36.0 examples/sec; 0.222 sec/batch; 19h:03m:35s remains)
INFO - root - 2017-12-17 04:42:27.184701: step 23520, loss = 0.12, batch loss = 0.09 (36.3 examples/sec; 0.221 sec/batch; 18h:56m:02s remains)
INFO - root - 2017-12-17 04:42:29.375085: step 23530, loss = 0.10, batch loss = 0.07 (37.2 examples/sec; 0.215 sec/batch; 18h:26m:38s remains)
INFO - root - 2017-12-17 04:42:31.589613: step 23540, loss = 0.14, batch loss = 0.11 (35.8 examples/sec; 0.223 sec/batch; 19h:09m:43s remains)
INFO - root - 2017-12-17 04:42:33.795096: step 23550, loss = 0.18, batch loss = 0.15 (37.6 examples/sec; 0.213 sec/batch; 18h:14m:52s remains)
INFO - root - 2017-12-17 04:42:36.021850: step 23560, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 19h:11m:14s remains)
INFO - root - 2017-12-17 04:42:38.254876: step 23570, loss = 0.13, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 19h:16m:31s remains)
INFO - root - 2017-12-17 04:42:40.504348: step 23580, loss = 0.10, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 18h:58m:59s remains)
INFO - root - 2017-12-17 04:42:42.743819: step 23590, loss = 0.10, batch loss = 0.06 (36.9 examples/sec; 0.217 sec/batch; 18h:37m:27s remains)
INFO - root - 2017-12-17 04:42:44.949804: step 23600, loss = 0.10, batch loss = 0.06 (36.8 examples/sec; 0.217 sec/batch; 18h:39m:15s remains)
INFO - root - 2017-12-17 04:42:47.307136: step 23610, loss = 0.10, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 19h:14m:26s remains)
INFO - root - 2017-12-17 04:42:49.537167: step 23620, loss = 0.12, batch loss = 0.09 (34.3 examples/sec; 0.233 sec/batch; 20h:01m:43s remains)
INFO - root - 2017-12-17 04:42:51.751636: step 23630, loss = 0.11, batch loss = 0.07 (34.7 examples/sec; 0.230 sec/batch; 19h:46m:13s remains)
INFO - root - 2017-12-17 04:42:53.975818: step 23640, loss = 0.13, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 18h:46m:21s remains)
INFO - root - 2017-12-17 04:42:56.177874: step 23650, loss = 0.11, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:49m:53s remains)
INFO - root - 2017-12-17 04:42:58.385355: step 23660, loss = 0.11, batch loss = 0.07 (36.6 examples/sec; 0.218 sec/batch; 18h:44m:28s remains)
INFO - root - 2017-12-17 04:43:00.600848: step 23670, loss = 0.09, batch loss = 0.06 (34.6 examples/sec; 0.231 sec/batch; 19h:48m:28s remains)
INFO - root - 2017-12-17 04:43:02.875942: step 23680, loss = 0.10, batch loss = 0.07 (34.9 examples/sec; 0.229 sec/batch; 19h:40m:36s remains)
INFO - root - 2017-12-17 04:43:05.158070: step 23690, loss = 0.09, batch loss = 0.06 (34.1 examples/sec; 0.235 sec/batch; 20h:07m:20s remains)
INFO - root - 2017-12-17 04:43:07.379546: step 23700, loss = 0.11, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 19h:04m:19s remains)
INFO - root - 2017-12-17 04:43:09.750331: step 23710, loss = 0.11, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 18h:49m:08s remains)
INFO - root - 2017-12-17 04:43:11.967964: step 23720, loss = 0.11, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 18h:47m:13s remains)
INFO - root - 2017-12-17 04:43:14.207646: step 23730, loss = 0.12, batch loss = 0.08 (35.5 examples/sec; 0.226 sec/batch; 19h:20m:55s remains)
INFO - root - 2017-12-17 04:43:16.435654: step 23740, loss = 0.08, batch loss = 0.05 (34.0 examples/sec; 0.235 sec/batch; 20h:09m:16s remains)
INFO - root - 2017-12-17 04:43:18.671007: step 23750, loss = 0.10, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 18h:56m:08s remains)
INFO - root - 2017-12-17 04:43:20.891329: step 23760, loss = 0.13, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:07m:44s remains)
INFO - root - 2017-12-17 04:43:23.149531: step 23770, loss = 0.12, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 18h:46m:25s remains)
INFO - root - 2017-12-17 04:43:25.370890: step 23780, loss = 0.11, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 19h:12m:26s remains)
INFO - root - 2017-12-17 04:43:27.557444: step 23790, loss = 0.12, batch loss = 0.08 (37.0 examples/sec; 0.216 sec/batch; 18h:31m:06s remains)
INFO - root - 2017-12-17 04:43:29.744220: step 23800, loss = 0.13, batch loss = 0.09 (36.8 examples/sec; 0.217 sec/batch; 18h:38m:05s remains)
INFO - root - 2017-12-17 04:43:32.101714: step 23810, loss = 0.12, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 18h:45m:05s remains)
INFO - root - 2017-12-17 04:43:34.291763: step 23820, loss = 0.10, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 19h:04m:57s remains)
INFO - root - 2017-12-17 04:43:36.497681: step 23830, loss = 0.11, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 19h:01m:58s remains)
INFO - root - 2017-12-17 04:43:38.728022: step 23840, loss = 0.11, batch loss = 0.08 (35.5 examples/sec; 0.225 sec/batch; 19h:18m:00s remains)
INFO - root - 2017-12-17 04:43:40.985109: step 23850, loss = 0.09, batch loss = 0.06 (34.8 examples/sec; 0.230 sec/batch; 19h:42m:03s remains)
INFO - root - 2017-12-17 04:43:43.198582: step 23860, loss = 0.13, batch loss = 0.10 (37.1 examples/sec; 0.215 sec/batch; 18h:28m:18s remains)
INFO - root - 2017-12-17 04:43:45.421439: step 23870, loss = 0.11, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 19h:14m:47s remains)
INFO - root - 2017-12-17 04:43:47.603674: step 23880, loss = 0.11, batch loss = 0.07 (37.6 examples/sec; 0.213 sec/batch; 18h:14m:43s remains)
INFO - root - 2017-12-17 04:43:49.824451: step 23890, loss = 0.10, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 18h:41m:36s remains)
INFO - root - 2017-12-17 04:43:52.065848: step 23900, loss = 0.13, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 18h:44m:50s remains)
INFO - root - 2017-12-17 04:43:54.403688: step 23910, loss = 0.13, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:03m:38s remains)
INFO - root - 2017-12-17 04:43:56.626320: step 23920, loss = 0.08, batch loss = 0.05 (35.8 examples/sec; 0.223 sec/batch; 19h:08m:56s remains)
INFO - root - 2017-12-17 04:43:58.834456: step 23930, loss = 0.16, batch loss = 0.13 (36.1 examples/sec; 0.221 sec/batch; 18h:58m:29s remains)
INFO - root - 2017-12-17 04:44:01.060102: step 23940, loss = 0.10, batch loss = 0.07 (35.5 examples/sec; 0.225 sec/batch; 19h:19m:14s remains)
INFO - root - 2017-12-17 04:44:03.327791: step 23950, loss = 0.10, batch loss = 0.07 (34.6 examples/sec; 0.231 sec/batch; 19h:47m:59s remains)
INFO - root - 2017-12-17 04:44:05.569358: step 23960, loss = 0.12, batch loss = 0.09 (36.3 examples/sec; 0.220 sec/batch; 18h:53m:08s remains)
INFO - root - 2017-12-17 04:44:07.825362: step 23970, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.223 sec/batch; 19h:07m:42s remains)
INFO - root - 2017-12-17 04:44:10.048300: step 23980, loss = 0.11, batch loss = 0.07 (36.6 examples/sec; 0.218 sec/batch; 18h:43m:30s remains)
INFO - root - 2017-12-17 04:44:12.286747: step 23990, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:49m:23s remains)
INFO - root - 2017-12-17 04:44:14.521746: step 24000, loss = 0.09, batch loss = 0.05 (37.5 examples/sec; 0.213 sec/batch; 18h:15m:29s remains)
INFO - root - 2017-12-17 04:44:16.849593: step 24010, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 19h:09m:25s remains)
INFO - root - 2017-12-17 04:44:19.075023: step 24020, loss = 0.11, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 18h:47m:34s remains)
INFO - root - 2017-12-17 04:44:21.313084: step 24030, loss = 0.09, batch loss = 0.06 (35.5 examples/sec; 0.226 sec/batch; 19h:19m:50s remains)
INFO - root - 2017-12-17 04:44:23.518306: step 24040, loss = 0.09, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 19h:03m:17s remains)
INFO - root - 2017-12-17 04:44:25.777005: step 24050, loss = 0.10, batch loss = 0.06 (35.2 examples/sec; 0.227 sec/batch; 19h:28m:25s remains)
INFO - root - 2017-12-17 04:44:27.967340: step 24060, loss = 0.09, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 19h:05m:29s remains)
INFO - root - 2017-12-17 04:44:30.153886: step 24070, loss = 0.18, batch loss = 0.15 (37.6 examples/sec; 0.213 sec/batch; 18h:14m:55s remains)
INFO - root - 2017-12-17 04:44:32.370672: step 24080, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:56m:09s remains)
INFO - root - 2017-12-17 04:44:34.599572: step 24090, loss = 0.14, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 19h:40m:05s remains)
INFO - root - 2017-12-17 04:44:36.839687: step 24100, loss = 0.12, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:02m:17s remains)
INFO - root - 2017-12-17 04:44:39.178782: step 24110, loss = 0.11, batch loss = 0.08 (37.3 examples/sec; 0.214 sec/batch; 18h:22m:16s remains)
INFO - root - 2017-12-17 04:44:41.424730: step 24120, loss = 0.11, batch loss = 0.07 (35.3 examples/sec; 0.226 sec/batch; 19h:23m:55s remains)
INFO - root - 2017-12-17 04:44:43.671543: step 24130, loss = 0.10, batch loss = 0.07 (32.6 examples/sec; 0.245 sec/batch; 20h:59m:31s remains)
INFO - root - 2017-12-17 04:44:45.872352: step 24140, loss = 0.08, batch loss = 0.05 (37.0 examples/sec; 0.217 sec/batch; 18h:32m:42s remains)
INFO - root - 2017-12-17 04:44:48.090416: step 24150, loss = 0.10, batch loss = 0.06 (35.6 examples/sec; 0.225 sec/batch; 19h:16m:07s remains)
INFO - root - 2017-12-17 04:44:50.310745: step 24160, loss = 0.10, batch loss = 0.07 (37.8 examples/sec; 0.212 sec/batch; 18h:07m:11s remains)
INFO - root - 2017-12-17 04:44:52.493521: step 24170, loss = 0.08, batch loss = 0.05 (35.3 examples/sec; 0.227 sec/batch; 19h:24m:53s remains)
INFO - root - 2017-12-17 04:44:54.738770: step 24180, loss = 0.10, batch loss = 0.07 (37.2 examples/sec; 0.215 sec/batch; 18h:23m:47s remains)
INFO - root - 2017-12-17 04:44:56.963796: step 24190, loss = 0.13, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 19h:16m:57s remains)
INFO - root - 2017-12-17 04:44:59.178786: step 24200, loss = 0.13, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 18h:49m:45s remains)
INFO - root - 2017-12-17 04:45:01.539926: step 24210, loss = 0.15, batch loss = 0.11 (36.8 examples/sec; 0.218 sec/batch; 18h:37m:51s remains)
INFO - root - 2017-12-17 04:45:03.757053: step 24220, loss = 0.12, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 18h:43m:43s remains)
INFO - root - 2017-12-17 04:45:05.999377: step 24230, loss = 0.14, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 19h:17m:15s remains)
INFO - root - 2017-12-17 04:45:08.233224: step 24240, loss = 0.11, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 18h:44m:07s remains)
INFO - root - 2017-12-17 04:45:10.459004: step 24250, loss = 0.11, batch loss = 0.08 (36.3 examples/sec; 0.220 sec/batch; 18h:51m:16s remains)
INFO - root - 2017-12-17 04:45:12.682340: step 24260, loss = 0.11, batch loss = 0.08 (36.8 examples/sec; 0.217 sec/batch; 18h:35m:50s remains)
INFO - root - 2017-12-17 04:45:14.902165: step 24270, loss = 0.12, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 18h:56m:09s remains)
INFO - root - 2017-12-17 04:45:17.110716: step 24280, loss = 0.09, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 18h:39m:58s remains)
INFO - root - 2017-12-17 04:45:19.361433: step 24290, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:48m:47s remains)
INFO - root - 2017-12-17 04:45:21.547113: step 24300, loss = 0.12, batch loss = 0.09 (36.8 examples/sec; 0.217 sec/batch; 18h:37m:02s remains)
INFO - root - 2017-12-17 04:45:23.935429: step 24310, loss = 0.13, batch loss = 0.09 (35.8 examples/sec; 0.223 sec/batch; 19h:06m:22s remains)
INFO - root - 2017-12-17 04:45:26.159133: step 24320, loss = 0.12, batch loss = 0.09 (35.1 examples/sec; 0.228 sec/batch; 19h:29m:47s remains)
INFO - root - 2017-12-17 04:45:28.348740: step 24330, loss = 0.15, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 18h:49m:41s remains)
INFO - root - 2017-12-17 04:45:30.598510: step 24340, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.224 sec/batch; 19h:12m:45s remains)
INFO - root - 2017-12-17 04:45:32.792892: step 24350, loss = 0.16, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 19h:11m:38s remains)
INFO - root - 2017-12-17 04:45:35.044816: step 24360, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:56m:15s remains)
INFO - root - 2017-12-17 04:45:37.265672: step 24370, loss = 0.09, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 18h:49m:43s remains)
INFO - root - 2017-12-17 04:45:39.476323: step 24380, loss = 0.10, batch loss = 0.07 (34.2 examples/sec; 0.234 sec/batch; 20h:02m:25s remains)
INFO - root - 2017-12-17 04:45:41.712401: step 24390, loss = 0.10, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 19h:04m:13s remains)
INFO - root - 2017-12-17 04:45:43.948704: step 24400, loss = 0.11, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 18h:54m:37s remains)
INFO - root - 2017-12-17 04:45:46.285266: step 24410, loss = 0.10, batch loss = 0.07 (34.2 examples/sec; 0.234 sec/batch; 20h:00m:37s remains)
INFO - root - 2017-12-17 04:45:48.526899: step 24420, loss = 0.10, batch loss = 0.07 (35.3 examples/sec; 0.227 sec/batch; 19h:24m:43s remains)
INFO - root - 2017-12-17 04:45:50.747424: step 24430, loss = 0.17, batch loss = 0.14 (37.1 examples/sec; 0.216 sec/batch; 18h:28m:36s remains)
INFO - root - 2017-12-17 04:45:52.977323: step 24440, loss = 0.11, batch loss = 0.07 (35.6 examples/sec; 0.224 sec/batch; 19h:12m:13s remains)
INFO - root - 2017-12-17 04:45:55.222568: step 24450, loss = 0.10, batch loss = 0.06 (34.7 examples/sec; 0.231 sec/batch; 19h:43m:39s remains)
INFO - root - 2017-12-17 04:45:57.433202: step 24460, loss = 0.12, batch loss = 0.09 (36.1 examples/sec; 0.222 sec/batch; 18h:57m:45s remains)
INFO - root - 2017-12-17 04:45:59.655487: step 24470, loss = 0.12, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 18h:43m:33s remains)
INFO - root - 2017-12-17 04:46:01.905201: step 24480, loss = 0.18, batch loss = 0.15 (34.3 examples/sec; 0.233 sec/batch; 19h:57m:11s remains)
INFO - root - 2017-12-17 04:46:04.105733: step 24490, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 18h:57m:16s remains)
INFO - root - 2017-12-17 04:46:06.335072: step 24500, loss = 0.14, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 19h:10m:21s remains)
INFO - root - 2017-12-17 04:46:08.749675: step 24510, loss = 0.08, batch loss = 0.05 (34.4 examples/sec; 0.232 sec/batch; 19h:52m:57s remains)
INFO - root - 2017-12-17 04:46:11.020641: step 24520, loss = 0.10, batch loss = 0.06 (35.2 examples/sec; 0.227 sec/batch; 19h:27m:03s remains)
INFO - root - 2017-12-17 04:46:13.259859: step 24530, loss = 0.12, batch loss = 0.08 (35.8 examples/sec; 0.224 sec/batch; 19h:08m:03s remains)
INFO - root - 2017-12-17 04:46:15.448130: step 24540, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 19h:00m:35s remains)
INFO - root - 2017-12-17 04:46:17.650625: step 24550, loss = 0.11, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 18h:49m:16s remains)
INFO - root - 2017-12-17 04:46:19.860716: step 24560, loss = 0.13, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 19h:27m:02s remains)
INFO - root - 2017-12-17 04:46:22.098142: step 24570, loss = 0.09, batch loss = 0.06 (37.0 examples/sec; 0.216 sec/batch; 18h:29m:57s remains)
INFO - root - 2017-12-17 04:46:24.308331: step 24580, loss = 0.11, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 19h:14m:01s remains)
INFO - root - 2017-12-17 04:46:26.539642: step 24590, loss = 0.10, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 19h:02m:37s remains)
INFO - root - 2017-12-17 04:46:28.795095: step 24600, loss = 0.11, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 18h:44m:25s remains)
INFO - root - 2017-12-17 04:46:31.199781: step 24610, loss = 0.12, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:01m:03s remains)
INFO - root - 2017-12-17 04:46:33.425690: step 24620, loss = 0.12, batch loss = 0.09 (37.1 examples/sec; 0.216 sec/batch; 18h:26m:03s remains)
INFO - root - 2017-12-17 04:46:35.667193: step 24630, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:55m:14s remains)
INFO - root - 2017-12-17 04:46:37.922119: step 24640, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.221 sec/batch; 18h:51m:58s remains)
INFO - root - 2017-12-17 04:46:40.154112: step 24650, loss = 0.13, batch loss = 0.10 (34.9 examples/sec; 0.229 sec/batch; 19h:37m:21s remains)
INFO - root - 2017-12-17 04:46:42.384616: step 24660, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:48m:02s remains)
INFO - root - 2017-12-17 04:46:44.550092: step 24670, loss = 0.12, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 18h:41m:58s remains)
INFO - root - 2017-12-17 04:46:46.750176: step 24680, loss = 0.12, batch loss = 0.09 (36.7 examples/sec; 0.218 sec/batch; 18h:39m:11s remains)
INFO - root - 2017-12-17 04:46:48.974998: step 24690, loss = 0.12, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 19h:01m:22s remains)
INFO - root - 2017-12-17 04:46:51.187979: step 24700, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 19h:06m:42s remains)
INFO - root - 2017-12-17 04:46:53.537172: step 24710, loss = 0.09, batch loss = 0.05 (35.5 examples/sec; 0.226 sec/batch; 19h:17m:28s remains)
INFO - root - 2017-12-17 04:46:55.749557: step 24720, loss = 0.12, batch loss = 0.09 (36.1 examples/sec; 0.221 sec/batch; 18h:55m:53s remains)
INFO - root - 2017-12-17 04:46:57.962187: step 24730, loss = 0.09, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 18h:58m:28s remains)
INFO - root - 2017-12-17 04:47:00.189465: step 24740, loss = 0.11, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:47m:28s remains)
INFO - root - 2017-12-17 04:47:02.408538: step 24750, loss = 0.09, batch loss = 0.06 (34.4 examples/sec; 0.232 sec/batch; 19h:51m:53s remains)
INFO - root - 2017-12-17 04:47:04.635170: step 24760, loss = 0.09, batch loss = 0.05 (36.1 examples/sec; 0.221 sec/batch; 18h:56m:00s remains)
INFO - root - 2017-12-17 04:47:06.845237: step 24770, loss = 0.10, batch loss = 0.06 (36.9 examples/sec; 0.217 sec/batch; 18h:31m:29s remains)
INFO - root - 2017-12-17 04:47:09.085758: step 24780, loss = 0.12, batch loss = 0.09 (37.0 examples/sec; 0.216 sec/batch; 18h:30m:09s remains)
INFO - root - 2017-12-17 04:47:11.291176: step 24790, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 18h:50m:46s remains)
INFO - root - 2017-12-17 04:47:13.503805: step 24800, loss = 0.10, batch loss = 0.07 (37.0 examples/sec; 0.216 sec/batch; 18h:27m:32s remains)
INFO - root - 2017-12-17 04:47:15.843932: step 24810, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:48m:32s remains)
INFO - root - 2017-12-17 04:47:18.056025: step 24820, loss = 0.11, batch loss = 0.08 (36.1 examples/sec; 0.222 sec/batch; 18h:56m:59s remains)
INFO - root - 2017-12-17 04:47:20.271858: step 24830, loss = 0.09, batch loss = 0.05 (35.7 examples/sec; 0.224 sec/batch; 19h:07m:42s remains)
INFO - root - 2017-12-17 04:47:22.513448: step 24840, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 18h:48m:43s remains)
INFO - root - 2017-12-17 04:47:24.746333: step 24850, loss = 0.13, batch loss = 0.09 (36.0 examples/sec; 0.223 sec/batch; 19h:00m:59s remains)
INFO - root - 2017-12-17 04:47:27.042030: step 24860, loss = 0.09, batch loss = 0.06 (33.7 examples/sec; 0.238 sec/batch; 20h:18m:52s remains)
INFO - root - 2017-12-17 04:47:29.267649: step 24870, loss = 0.14, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 18h:52m:05s remains)
INFO - root - 2017-12-17 04:47:31.467479: step 24880, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 19h:07m:13s remains)
INFO - root - 2017-12-17 04:47:33.713608: step 24890, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 18h:48m:29s remains)
INFO - root - 2017-12-17 04:47:35.919016: step 24900, loss = 0.12, batch loss = 0.08 (36.9 examples/sec; 0.217 sec/batch; 18h:30m:21s remains)
INFO - root - 2017-12-17 04:47:38.281013: step 24910, loss = 0.10, batch loss = 0.06 (35.6 examples/sec; 0.225 sec/batch; 19h:11m:10s remains)
INFO - root - 2017-12-17 04:47:40.496524: step 24920, loss = 0.11, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 19h:25m:43s remains)
INFO - root - 2017-12-17 04:47:42.719212: step 24930, loss = 0.16, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 19h:38m:21s remains)
INFO - root - 2017-12-17 04:47:44.943051: step 24940, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 19h:08m:01s remains)
INFO - root - 2017-12-17 04:47:47.161739: step 24950, loss = 0.12, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 19h:13m:25s remains)
INFO - root - 2017-12-17 04:47:49.391825: step 24960, loss = 0.10, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 18h:36m:52s remains)
INFO - root - 2017-12-17 04:47:51.575837: step 24970, loss = 0.10, batch loss = 0.07 (36.8 examples/sec; 0.217 sec/batch; 18h:33m:05s remains)
INFO - root - 2017-12-17 04:47:53.769748: step 24980, loss = 0.08, batch loss = 0.04 (36.3 examples/sec; 0.220 sec/batch; 18h:48m:46s remains)
INFO - root - 2017-12-17 04:47:55.980026: step 24990, loss = 0.14, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 19h:28m:16s remains)
INFO - root - 2017-12-17 04:47:58.162892: step 25000, loss = 0.11, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 18h:37m:45s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-25000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-25000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 04:48:01.017563: step 25010, loss = 0.10, batch loss = 0.06 (35.0 examples/sec; 0.229 sec/batch; 19h:31m:34s remains)
INFO - root - 2017-12-17 04:48:03.264829: step 25020, loss = 0.12, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 19h:11m:14s remains)
INFO - root - 2017-12-17 04:48:05.502694: step 25030, loss = 0.10, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 18h:57m:40s remains)
INFO - root - 2017-12-17 04:48:07.730154: step 25040, loss = 0.08, batch loss = 0.05 (35.6 examples/sec; 0.224 sec/batch; 19h:10m:10s remains)
INFO - root - 2017-12-17 04:48:09.962978: step 25050, loss = 0.14, batch loss = 0.10 (36.7 examples/sec; 0.218 sec/batch; 18h:37m:21s remains)
INFO - root - 2017-12-17 04:48:12.189329: step 25060, loss = 0.13, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 19h:17m:48s remains)
INFO - root - 2017-12-17 04:48:14.415058: step 25070, loss = 0.09, batch loss = 0.06 (35.2 examples/sec; 0.227 sec/batch; 19h:24m:17s remains)
INFO - root - 2017-12-17 04:48:16.649230: step 25080, loss = 0.20, batch loss = 0.17 (36.9 examples/sec; 0.217 sec/batch; 18h:30m:17s remains)
INFO - root - 2017-12-17 04:48:18.948993: step 25090, loss = 0.10, batch loss = 0.06 (33.6 examples/sec; 0.238 sec/batch; 20h:18m:30s remains)
INFO - root - 2017-12-17 04:48:21.163151: step 25100, loss = 0.11, batch loss = 0.07 (36.8 examples/sec; 0.217 sec/batch; 18h:33m:32s remains)
INFO - root - 2017-12-17 04:48:23.603458: step 25110, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 19h:09m:02s remains)
INFO - root - 2017-12-17 04:48:25.827351: step 25120, loss = 0.11, batch loss = 0.08 (37.0 examples/sec; 0.216 sec/batch; 18h:27m:48s remains)
INFO - root - 2017-12-17 04:48:28.094496: step 25130, loss = 0.12, batch loss = 0.09 (35.2 examples/sec; 0.227 sec/batch; 19h:24m:17s remains)
INFO - root - 2017-12-17 04:48:30.289065: step 25140, loss = 0.09, batch loss = 0.06 (37.8 examples/sec; 0.212 sec/batch; 18h:04m:43s remains)
INFO - root - 2017-12-17 04:48:32.544407: step 25150, loss = 0.14, batch loss = 0.11 (35.0 examples/sec; 0.229 sec/batch; 19h:31m:55s remains)
INFO - root - 2017-12-17 04:48:34.774561: step 25160, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 19h:10m:23s remains)
INFO - root - 2017-12-17 04:48:37.018734: step 25170, loss = 0.14, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 19h:17m:23s remains)
INFO - root - 2017-12-17 04:48:39.244134: step 25180, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 19h:09m:14s remains)
INFO - root - 2017-12-17 04:48:41.499293: step 25190, loss = 0.11, batch loss = 0.07 (36.3 examples/sec; 0.221 sec/batch; 18h:49m:33s remains)
INFO - root - 2017-12-17 04:48:43.693534: step 25200, loss = 0.14, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 19h:05m:18s remains)
INFO - root - 2017-12-17 04:48:46.054697: step 25210, loss = 0.16, batch loss = 0.13 (37.1 examples/sec; 0.216 sec/batch; 18h:25m:20s remains)
INFO - root - 2017-12-17 04:48:48.286775: step 25220, loss = 0.15, batch loss = 0.12 (36.6 examples/sec; 0.218 sec/batch; 18h:38m:47s remains)
INFO - root - 2017-12-17 04:48:50.505259: step 25230, loss = 0.11, batch loss = 0.08 (35.0 examples/sec; 0.229 sec/batch; 19h:31m:52s remains)
INFO - root - 2017-12-17 04:48:52.740060: step 25240, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 19h:06m:34s remains)
INFO - root - 2017-12-17 04:48:54.950402: step 25250, loss = 0.08, batch loss = 0.05 (35.9 examples/sec; 0.223 sec/batch; 19h:00m:55s remains)
INFO - root - 2017-12-17 04:48:57.164019: step 25260, loss = 0.12, batch loss = 0.09 (35.8 examples/sec; 0.223 sec/batch; 19h:02m:44s remains)
INFO - root - 2017-12-17 04:48:59.378966: step 25270, loss = 0.13, batch loss = 0.09 (37.8 examples/sec; 0.212 sec/batch; 18h:04m:13s remains)
INFO - root - 2017-12-17 04:49:01.597241: step 25280, loss = 0.09, batch loss = 0.06 (35.6 examples/sec; 0.224 sec/batch; 19h:09m:05s remains)
INFO - root - 2017-12-17 04:49:03.863589: step 25290, loss = 0.10, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 18h:39m:34s remains)
INFO - root - 2017-12-17 04:49:06.126276: step 25300, loss = 0.14, batch loss = 0.11 (37.3 examples/sec; 0.215 sec/batch; 18h:18m:33s remains)
INFO - root - 2017-12-17 04:49:08.429132: step 25310, loss = 0.15, batch loss = 0.12 (37.8 examples/sec; 0.212 sec/batch; 18h:04m:05s remains)
INFO - root - 2017-12-17 04:49:10.625300: step 25320, loss = 0.09, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 18h:56m:16s remains)
INFO - root - 2017-12-17 04:49:12.817822: step 25330, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.221 sec/batch; 18h:49m:11s remains)
INFO - root - 2017-12-17 04:49:15.054454: step 25340, loss = 0.10, batch loss = 0.07 (37.0 examples/sec; 0.216 sec/batch; 18h:25m:51s remains)
INFO - root - 2017-12-17 04:49:17.237615: step 25350, loss = 0.08, batch loss = 0.05 (37.4 examples/sec; 0.214 sec/batch; 18h:15m:56s remains)
INFO - root - 2017-12-17 04:49:19.468559: step 25360, loss = 0.11, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 18h:39m:57s remains)
INFO - root - 2017-12-17 04:49:21.676315: step 25370, loss = 0.13, batch loss = 0.10 (37.0 examples/sec; 0.216 sec/batch; 18h:27m:54s remains)
INFO - root - 2017-12-17 04:49:23.893296: step 25380, loss = 0.12, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 18h:51m:44s remains)
INFO - root - 2017-12-17 04:49:26.114691: step 25390, loss = 0.09, batch loss = 0.05 (35.9 examples/sec; 0.223 sec/batch; 19h:00m:58s remains)
INFO - root - 2017-12-17 04:49:28.353226: step 25400, loss = 0.13, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 19h:09m:30s remains)
INFO - root - 2017-12-17 04:49:30.676761: step 25410, loss = 0.08, batch loss = 0.05 (36.5 examples/sec; 0.219 sec/batch; 18h:40m:21s remains)
INFO - root - 2017-12-17 04:49:32.844180: step 25420, loss = 0.12, batch loss = 0.08 (37.3 examples/sec; 0.214 sec/batch; 18h:16m:47s remains)
INFO - root - 2017-12-17 04:49:35.046803: step 25430, loss = 0.13, batch loss = 0.10 (37.5 examples/sec; 0.213 sec/batch; 18h:12m:12s remains)
INFO - root - 2017-12-17 04:49:37.247542: step 25440, loss = 0.10, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 18h:49m:44s remains)
INFO - root - 2017-12-17 04:49:39.435666: step 25450, loss = 0.13, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:00m:58s remains)
INFO - root - 2017-12-17 04:49:41.610841: step 25460, loss = 0.11, batch loss = 0.07 (37.0 examples/sec; 0.216 sec/batch; 18h:26m:04s remains)
INFO - root - 2017-12-17 04:49:43.821700: step 25470, loss = 0.12, batch loss = 0.09 (36.3 examples/sec; 0.221 sec/batch; 18h:48m:57s remains)
INFO - root - 2017-12-17 04:49:46.075518: step 25480, loss = 0.11, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:45m:13s remains)
INFO - root - 2017-12-17 04:49:48.324329: step 25490, loss = 0.10, batch loss = 0.06 (35.6 examples/sec; 0.225 sec/batch; 19h:10m:05s remains)
INFO - root - 2017-12-17 04:49:50.569972: step 25500, loss = 0.11, batch loss = 0.07 (34.4 examples/sec; 0.233 sec/batch; 19h:50m:48s remains)
INFO - root - 2017-12-17 04:49:52.917109: step 25510, loss = 0.14, batch loss = 0.10 (34.5 examples/sec; 0.232 sec/batch; 19h:46m:41s remains)
INFO - root - 2017-12-17 04:49:55.141982: step 25520, loss = 0.10, batch loss = 0.07 (35.5 examples/sec; 0.226 sec/batch; 19h:14m:14s remains)
INFO - root - 2017-12-17 04:49:57.349112: step 25530, loss = 0.11, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 18h:38m:04s remains)
INFO - root - 2017-12-17 04:49:59.575871: step 25540, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 18h:46m:43s remains)
INFO - root - 2017-12-17 04:50:01.791691: step 25550, loss = 0.11, batch loss = 0.08 (36.3 examples/sec; 0.221 sec/batch; 18h:48m:51s remains)
INFO - root - 2017-12-17 04:50:04.044996: step 25560, loss = 0.20, batch loss = 0.16 (34.0 examples/sec; 0.235 sec/batch; 20h:03m:34s remains)
INFO - root - 2017-12-17 04:50:06.292029: step 25570, loss = 0.10, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 18h:33m:39s remains)
INFO - root - 2017-12-17 04:50:08.526138: step 25580, loss = 0.09, batch loss = 0.05 (36.1 examples/sec; 0.222 sec/batch; 18h:54m:56s remains)
INFO - root - 2017-12-17 04:50:10.756891: step 25590, loss = 0.13, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 18h:40m:51s remains)
INFO - root - 2017-12-17 04:50:12.995349: step 25600, loss = 0.10, batch loss = 0.07 (37.1 examples/sec; 0.216 sec/batch; 18h:22m:24s remains)
INFO - root - 2017-12-17 04:50:15.306470: step 25610, loss = 0.12, batch loss = 0.09 (37.0 examples/sec; 0.216 sec/batch; 18h:26m:26s remains)
INFO - root - 2017-12-17 04:50:17.571809: step 25620, loss = 0.09, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 18h:59m:00s remains)
INFO - root - 2017-12-17 04:50:19.800212: step 25630, loss = 0.08, batch loss = 0.05 (36.8 examples/sec; 0.217 sec/batch; 18h:31m:57s remains)
INFO - root - 2017-12-17 04:50:22.016459: step 25640, loss = 0.15, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 19h:11m:07s remains)
INFO - root - 2017-12-17 04:50:24.243136: step 25650, loss = 0.15, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 18h:46m:28s remains)
INFO - root - 2017-12-17 04:50:26.475402: step 25660, loss = 0.12, batch loss = 0.08 (35.3 examples/sec; 0.226 sec/batch; 19h:17m:54s remains)
INFO - root - 2017-12-17 04:50:28.699047: step 25670, loss = 0.10, batch loss = 0.07 (35.3 examples/sec; 0.227 sec/batch; 19h:19m:46s remains)
INFO - root - 2017-12-17 04:50:30.923625: step 25680, loss = 0.10, batch loss = 0.06 (35.6 examples/sec; 0.225 sec/batch; 19h:09m:23s remains)
INFO - root - 2017-12-17 04:50:33.161379: step 25690, loss = 0.11, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:45m:23s remains)
INFO - root - 2017-12-17 04:50:35.387026: step 25700, loss = 0.16, batch loss = 0.13 (36.7 examples/sec; 0.218 sec/batch; 18h:35m:33s remains)
INFO - root - 2017-12-17 04:50:37.746411: step 25710, loss = 0.11, batch loss = 0.08 (33.8 examples/sec; 0.237 sec/batch; 20h:10m:16s remains)
INFO - root - 2017-12-17 04:50:40.014254: step 25720, loss = 0.09, batch loss = 0.05 (35.8 examples/sec; 0.224 sec/batch; 19h:02m:52s remains)
INFO - root - 2017-12-17 04:50:42.217932: step 25730, loss = 0.09, batch loss = 0.05 (35.4 examples/sec; 0.226 sec/batch; 19h:15m:29s remains)
INFO - root - 2017-12-17 04:50:44.435953: step 25740, loss = 0.10, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 18h:49m:33s remains)
INFO - root - 2017-12-17 04:50:46.658448: step 25750, loss = 0.12, batch loss = 0.09 (37.2 examples/sec; 0.215 sec/batch; 18h:19m:53s remains)
INFO - root - 2017-12-17 04:50:48.865963: step 25760, loss = 0.09, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 18h:51m:00s remains)
INFO - root - 2017-12-17 04:50:51.093433: step 25770, loss = 0.12, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 19h:04m:31s remains)
INFO - root - 2017-12-17 04:50:53.293391: step 25780, loss = 0.13, batch loss = 0.09 (35.8 examples/sec; 0.224 sec/batch; 19h:02m:53s remains)
INFO - root - 2017-12-17 04:50:55.519540: step 25790, loss = 0.10, batch loss = 0.06 (33.7 examples/sec; 0.237 sec/batch; 20h:12m:17s remains)
INFO - root - 2017-12-17 04:50:57.778545: step 25800, loss = 0.10, batch loss = 0.06 (34.9 examples/sec; 0.229 sec/batch; 19h:30m:59s remains)
INFO - root - 2017-12-17 04:51:00.116883: step 25810, loss = 0.09, batch loss = 0.05 (35.7 examples/sec; 0.224 sec/batch; 19h:05m:16s remains)
INFO - root - 2017-12-17 04:51:02.367096: step 25820, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 19h:04m:38s remains)
INFO - root - 2017-12-17 04:51:04.615394: step 25830, loss = 0.13, batch loss = 0.10 (36.8 examples/sec; 0.217 sec/batch; 18h:31m:07s remains)
INFO - root - 2017-12-17 04:51:06.860012: step 25840, loss = 0.11, batch loss = 0.08 (34.5 examples/sec; 0.232 sec/batch; 19h:46m:25s remains)
INFO - root - 2017-12-17 04:51:09.123118: step 25850, loss = 0.11, batch loss = 0.08 (35.2 examples/sec; 0.227 sec/batch; 19h:21m:31s remains)
INFO - root - 2017-12-17 04:51:11.366950: step 25860, loss = 0.13, batch loss = 0.09 (36.6 examples/sec; 0.218 sec/batch; 18h:36m:27s remains)
INFO - root - 2017-12-17 04:51:13.587992: step 25870, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 18h:56m:45s remains)
INFO - root - 2017-12-17 04:51:15.808218: step 25880, loss = 0.13, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 19h:00m:00s remains)
INFO - root - 2017-12-17 04:51:18.049932: step 25890, loss = 0.10, batch loss = 0.06 (36.6 examples/sec; 0.219 sec/batch; 18h:36m:52s remains)
INFO - root - 2017-12-17 04:51:20.267679: step 25900, loss = 0.12, batch loss = 0.09 (35.8 examples/sec; 0.223 sec/batch; 19h:01m:12s remains)
INFO - root - 2017-12-17 04:51:22.594925: step 25910, loss = 0.12, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 18h:43m:13s remains)
INFO - root - 2017-12-17 04:51:24.844703: step 25920, loss = 0.11, batch loss = 0.08 (34.9 examples/sec; 0.229 sec/batch; 19h:32m:16s remains)
INFO - root - 2017-12-17 04:51:27.074463: step 25930, loss = 0.10, batch loss = 0.06 (35.8 examples/sec; 0.223 sec/batch; 19h:00m:40s remains)
INFO - root - 2017-12-17 04:51:29.285848: step 25940, loss = 0.09, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 18h:34m:55s remains)
INFO - root - 2017-12-17 04:51:31.518606: step 25950, loss = 0.11, batch loss = 0.08 (34.7 examples/sec; 0.230 sec/batch; 19h:37m:29s remains)
INFO - root - 2017-12-17 04:51:33.720026: step 25960, loss = 0.09, batch loss = 0.06 (36.6 examples/sec; 0.218 sec/batch; 18h:35m:45s remains)
INFO - root - 2017-12-17 04:51:35.940664: step 25970, loss = 0.12, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 18h:50m:09s remains)
INFO - root - 2017-12-17 04:51:38.146931: step 25980, loss = 0.12, batch loss = 0.09 (36.3 examples/sec; 0.221 sec/batch; 18h:47m:19s remains)
INFO - root - 2017-12-17 04:51:40.326382: step 25990, loss = 0.08, batch loss = 0.05 (36.8 examples/sec; 0.218 sec/batch; 18h:31m:20s remains)
INFO - root - 2017-12-17 04:51:42.542451: step 26000, loss = 0.10, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 18h:38m:43s remains)
INFO - root - 2017-12-17 04:51:44.895565: step 26010, loss = 0.11, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 18h:59m:45s remains)
INFO - root - 2017-12-17 04:51:47.121778: step 26020, loss = 0.15, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 18h:50m:21s remains)
INFO - root - 2017-12-17 04:51:49.322578: step 26030, loss = 0.13, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 19h:02m:46s remains)
INFO - root - 2017-12-17 04:51:51.553905: step 26040, loss = 0.10, batch loss = 0.06 (34.7 examples/sec; 0.231 sec/batch; 19h:37m:43s remains)
INFO - root - 2017-12-17 04:51:53.803761: step 26050, loss = 0.13, batch loss = 0.10 (34.3 examples/sec; 0.233 sec/batch; 19h:52m:03s remains)
INFO - root - 2017-12-17 04:51:56.033848: step 26060, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 18h:45m:07s remains)
INFO - root - 2017-12-17 04:51:58.259586: step 26070, loss = 0.12, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 18h:55m:03s remains)
INFO - root - 2017-12-17 04:52:00.491892: step 26080, loss = 0.14, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 18h:44m:23s remains)
INFO - root - 2017-12-17 04:52:02.726214: step 26090, loss = 0.18, batch loss = 0.15 (36.6 examples/sec; 0.219 sec/batch; 18h:36m:18s remains)
INFO - root - 2017-12-17 04:52:04.917982: step 26100, loss = 0.10, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 18h:58m:46s remains)
INFO - root - 2017-12-17 04:52:07.249670: step 26110, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.221 sec/batch; 18h:46m:54s remains)
INFO - root - 2017-12-17 04:52:09.498834: step 26120, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 19h:07m:05s remains)
INFO - root - 2017-12-17 04:52:11.734650: step 26130, loss = 0.12, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 19h:06m:58s remains)
INFO - root - 2017-12-17 04:52:13.992626: step 26140, loss = 0.10, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 18h:33m:59s remains)
INFO - root - 2017-12-17 04:52:16.245892: step 26150, loss = 0.09, batch loss = 0.05 (35.5 examples/sec; 0.225 sec/batch; 19h:10m:32s remains)
INFO - root - 2017-12-17 04:52:18.472509: step 26160, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 19h:04m:39s remains)
INFO - root - 2017-12-17 04:52:20.707212: step 26170, loss = 0.09, batch loss = 0.06 (37.0 examples/sec; 0.216 sec/batch; 18h:23m:28s remains)
INFO - root - 2017-12-17 04:52:22.914262: step 26180, loss = 0.11, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 18h:47m:57s remains)
INFO - root - 2017-12-17 04:52:25.135757: step 26190, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:48m:27s remains)
INFO - root - 2017-12-17 04:52:27.354560: step 26200, loss = 0.09, batch loss = 0.05 (35.1 examples/sec; 0.228 sec/batch; 19h:24m:57s remains)
INFO - root - 2017-12-17 04:52:29.729424: step 26210, loss = 0.13, batch loss = 0.10 (36.1 examples/sec; 0.221 sec/batch; 18h:50m:26s remains)
INFO - root - 2017-12-17 04:52:31.955088: step 26220, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.221 sec/batch; 18h:46m:13s remains)
INFO - root - 2017-12-17 04:52:34.155124: step 26230, loss = 0.12, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 18h:37m:35s remains)
INFO - root - 2017-12-17 04:52:36.380326: step 26240, loss = 0.09, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 18h:33m:28s remains)
INFO - root - 2017-12-17 04:52:38.601568: step 26250, loss = 0.09, batch loss = 0.05 (35.3 examples/sec; 0.227 sec/batch; 19h:17m:07s remains)
INFO - root - 2017-12-17 04:52:40.803298: step 26260, loss = 0.12, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 18h:36m:06s remains)
INFO - root - 2017-12-17 04:52:43.042192: step 26270, loss = 0.11, batch loss = 0.08 (35.3 examples/sec; 0.227 sec/batch; 19h:16m:52s remains)
INFO - root - 2017-12-17 04:52:45.280247: step 26280, loss = 0.14, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 18h:41m:22s remains)
INFO - root - 2017-12-17 04:52:47.503730: step 26290, loss = 0.14, batch loss = 0.10 (35.0 examples/sec; 0.229 sec/batch; 19h:28m:09s remains)
INFO - root - 2017-12-17 04:52:49.726696: step 26300, loss = 0.14, batch loss = 0.11 (36.3 examples/sec; 0.220 sec/batch; 18h:45m:01s remains)
INFO - root - 2017-12-17 04:52:52.043806: step 26310, loss = 0.11, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 18h:37m:54s remains)
INFO - root - 2017-12-17 04:52:54.248490: step 26320, loss = 0.09, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 18h:58m:29s remains)
INFO - root - 2017-12-17 04:52:56.480683: step 26330, loss = 0.13, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 19h:13m:29s remains)
INFO - root - 2017-12-17 04:52:58.710230: step 26340, loss = 0.09, batch loss = 0.06 (36.9 examples/sec; 0.217 sec/batch; 18h:24m:58s remains)
INFO - root - 2017-12-17 04:53:00.908391: step 26350, loss = 0.08, batch loss = 0.05 (36.2 examples/sec; 0.221 sec/batch; 18h:46m:30s remains)
INFO - root - 2017-12-17 04:53:03.129165: step 26360, loss = 0.09, batch loss = 0.05 (36.4 examples/sec; 0.220 sec/batch; 18h:41m:17s remains)
INFO - root - 2017-12-17 04:53:05.354831: step 26370, loss = 0.20, batch loss = 0.17 (35.9 examples/sec; 0.223 sec/batch; 18h:56m:45s remains)
INFO - root - 2017-12-17 04:53:07.588146: step 26380, loss = 0.13, batch loss = 0.09 (36.7 examples/sec; 0.218 sec/batch; 18h:32m:08s remains)
INFO - root - 2017-12-17 04:53:09.812899: step 26390, loss = 0.10, batch loss = 0.07 (37.5 examples/sec; 0.213 sec/batch; 18h:07m:41s remains)
INFO - root - 2017-12-17 04:53:12.009975: step 26400, loss = 0.14, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 19h:11m:19s remains)
INFO - root - 2017-12-17 04:53:14.348025: step 26410, loss = 0.11, batch loss = 0.08 (36.0 examples/sec; 0.223 sec/batch; 18h:55m:07s remains)
INFO - root - 2017-12-17 04:53:16.607400: step 26420, loss = 0.08, batch loss = 0.05 (34.1 examples/sec; 0.234 sec/batch; 19h:55m:45s remains)
INFO - root - 2017-12-17 04:53:18.875761: step 26430, loss = 0.12, batch loss = 0.08 (34.1 examples/sec; 0.234 sec/batch; 19h:55m:11s remains)
INFO - root - 2017-12-17 04:53:21.117214: step 26440, loss = 0.10, batch loss = 0.06 (36.1 examples/sec; 0.221 sec/batch; 18h:49m:47s remains)
INFO - root - 2017-12-17 04:53:23.362978: step 26450, loss = 0.10, batch loss = 0.07 (35.5 examples/sec; 0.225 sec/batch; 19h:08m:28s remains)
INFO - root - 2017-12-17 04:53:25.573402: step 26460, loss = 0.10, batch loss = 0.06 (35.6 examples/sec; 0.225 sec/batch; 19h:06m:50s remains)
INFO - root - 2017-12-17 04:53:27.806917: step 26470, loss = 0.12, batch loss = 0.08 (34.3 examples/sec; 0.233 sec/batch; 19h:49m:42s remains)
INFO - root - 2017-12-17 04:53:30.032045: step 26480, loss = 0.12, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 18h:40m:58s remains)
INFO - root - 2017-12-17 04:53:32.269902: step 26490, loss = 0.11, batch loss = 0.08 (37.2 examples/sec; 0.215 sec/batch; 18h:18m:09s remains)
INFO - root - 2017-12-17 04:53:34.472125: step 26500, loss = 0.11, batch loss = 0.08 (35.3 examples/sec; 0.227 sec/batch; 19h:16m:00s remains)
INFO - root - 2017-12-17 04:53:36.875692: step 26510, loss = 0.08, batch loss = 0.05 (34.8 examples/sec; 0.230 sec/batch; 19h:32m:19s remains)
INFO - root - 2017-12-17 04:53:39.082213: step 26520, loss = 0.10, batch loss = 0.06 (36.1 examples/sec; 0.221 sec/batch; 18h:48m:34s remains)
INFO - root - 2017-12-17 04:53:41.297482: step 26530, loss = 0.10, batch loss = 0.07 (37.0 examples/sec; 0.216 sec/batch; 18h:21m:53s remains)
INFO - root - 2017-12-17 04:53:43.532246: step 26540, loss = 0.10, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 18h:30m:29s remains)
INFO - root - 2017-12-17 04:53:45.729113: step 26550, loss = 0.13, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 18h:51m:27s remains)
INFO - root - 2017-12-17 04:53:47.954009: step 26560, loss = 0.09, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 18h:40m:40s remains)
INFO - root - 2017-12-17 04:53:50.175141: step 26570, loss = 0.09, batch loss = 0.06 (35.5 examples/sec; 0.225 sec/batch; 19h:09m:30s remains)
INFO - root - 2017-12-17 04:53:52.385244: step 26580, loss = 0.09, batch loss = 0.06 (35.6 examples/sec; 0.225 sec/batch; 19h:05m:21s remains)
INFO - root - 2017-12-17 04:53:54.561544: step 26590, loss = 0.12, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 18h:47m:52s remains)
INFO - root - 2017-12-17 04:53:56.748073: step 26600, loss = 0.19, batch loss = 0.15 (37.0 examples/sec; 0.216 sec/batch; 18h:23m:40s remains)
INFO - root - 2017-12-17 04:53:59.062907: step 26610, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:48m:01s remains)
INFO - root - 2017-12-17 04:54:01.301563: step 26620, loss = 0.10, batch loss = 0.06 (35.4 examples/sec; 0.226 sec/batch; 19h:13m:20s remains)
INFO - root - 2017-12-17 04:54:03.523223: step 26630, loss = 0.10, batch loss = 0.07 (34.9 examples/sec; 0.229 sec/batch; 19h:26m:57s remains)
INFO - root - 2017-12-17 04:54:05.795982: step 26640, loss = 0.10, batch loss = 0.07 (35.4 examples/sec; 0.226 sec/batch; 19h:10m:30s remains)
INFO - root - 2017-12-17 04:54:07.965410: step 26650, loss = 0.13, batch loss = 0.09 (36.8 examples/sec; 0.217 sec/batch; 18h:27m:31s remains)
INFO - root - 2017-12-17 04:54:10.180507: step 26660, loss = 0.09, batch loss = 0.05 (37.2 examples/sec; 0.215 sec/batch; 18h:15m:15s remains)
INFO - root - 2017-12-17 04:54:12.369340: step 26670, loss = 0.13, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 18h:52m:11s remains)
INFO - root - 2017-12-17 04:54:14.615946: step 26680, loss = 0.10, batch loss = 0.06 (35.4 examples/sec; 0.226 sec/batch; 19h:11m:52s remains)
INFO - root - 2017-12-17 04:54:16.860586: step 26690, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:40m:14s remains)
INFO - root - 2017-12-17 04:54:19.077502: step 26700, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 18h:43m:47s remains)
INFO - root - 2017-12-17 04:54:21.442040: step 26710, loss = 0.11, batch loss = 0.08 (34.4 examples/sec; 0.233 sec/batch; 19h:45m:49s remains)
INFO - root - 2017-12-17 04:54:23.687716: step 26720, loss = 0.10, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 19h:01m:26s remains)
INFO - root - 2017-12-17 04:54:25.934959: step 26730, loss = 0.12, batch loss = 0.09 (34.2 examples/sec; 0.234 sec/batch; 19h:52m:06s remains)
INFO - root - 2017-12-17 04:54:28.124207: step 26740, loss = 0.10, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 18h:51m:49s remains)
INFO - root - 2017-12-17 04:54:30.340418: step 26750, loss = 0.10, batch loss = 0.07 (37.1 examples/sec; 0.216 sec/batch; 18h:18m:15s remains)
INFO - root - 2017-12-17 04:54:32.562361: step 26760, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:44m:57s remains)
INFO - root - 2017-12-17 04:54:34.781100: step 26770, loss = 0.12, batch loss = 0.08 (35.8 examples/sec; 0.223 sec/batch; 18h:58m:26s remains)
INFO - root - 2017-12-17 04:54:36.997801: step 26780, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.223 sec/batch; 18h:57m:49s remains)
INFO - root - 2017-12-17 04:54:39.221955: step 26790, loss = 0.09, batch loss = 0.05 (36.5 examples/sec; 0.219 sec/batch; 18h:36m:40s remains)
INFO - root - 2017-12-17 04:54:41.424448: step 26800, loss = 0.15, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 18h:39m:33s remains)
INFO - root - 2017-12-17 04:54:43.793210: step 26810, loss = 0.12, batch loss = 0.09 (36.3 examples/sec; 0.221 sec/batch; 18h:43m:42s remains)
INFO - root - 2017-12-17 04:54:46.017106: step 26820, loss = 0.12, batch loss = 0.09 (34.5 examples/sec; 0.232 sec/batch; 19h:39m:47s remains)
INFO - root - 2017-12-17 04:54:48.240571: step 26830, loss = 0.09, batch loss = 0.06 (33.3 examples/sec; 0.240 sec/batch; 20h:23m:03s remains)
INFO - root - 2017-12-17 04:54:50.518912: step 26840, loss = 0.19, batch loss = 0.15 (35.5 examples/sec; 0.226 sec/batch; 19h:09m:37s remains)
INFO - root - 2017-12-17 04:54:52.771296: step 26850, loss = 0.13, batch loss = 0.10 (34.9 examples/sec; 0.230 sec/batch; 19h:29m:21s remains)
INFO - root - 2017-12-17 04:54:55.063658: step 26860, loss = 0.10, batch loss = 0.07 (35.4 examples/sec; 0.226 sec/batch; 19h:10m:44s remains)
INFO - root - 2017-12-17 04:54:58.097881: step 26870, loss = 0.11, batch loss = 0.07 (21.0 examples/sec; 0.380 sec/batch; 32h:17m:28s remains)
INFO - root - 2017-12-17 04:55:01.819036: step 26880, loss = 0.12, batch loss = 0.09 (21.0 examples/sec; 0.381 sec/batch; 32h:19m:16s remains)
INFO - root - 2017-12-17 04:55:05.610090: step 26890, loss = 0.09, batch loss = 0.06 (21.3 examples/sec; 0.376 sec/batch; 31h:53m:28s remains)
INFO - root - 2017-12-17 04:55:09.280282: step 26900, loss = 0.12, batch loss = 0.08 (21.5 examples/sec; 0.371 sec/batch; 31h:31m:22s remains)
INFO - root - 2017-12-17 04:55:13.271902: step 26910, loss = 0.09, batch loss = 0.06 (21.0 examples/sec; 0.381 sec/batch; 32h:18m:01s remains)
INFO - root - 2017-12-17 04:55:17.017337: step 26920, loss = 0.11, batch loss = 0.07 (22.5 examples/sec; 0.356 sec/batch; 30h:11m:59s remains)
INFO - root - 2017-12-17 04:55:20.736594: step 26930, loss = 0.10, batch loss = 0.07 (21.6 examples/sec; 0.370 sec/batch; 31h:23m:58s remains)
INFO - root - 2017-12-17 04:55:24.553016: step 26940, loss = 0.09, batch loss = 0.05 (22.1 examples/sec; 0.362 sec/batch; 30h:43m:25s remains)
INFO - root - 2017-12-17 04:55:28.336230: step 26950, loss = 0.10, batch loss = 0.06 (20.9 examples/sec; 0.383 sec/batch; 32h:30m:24s remains)
INFO - root - 2017-12-17 04:55:32.043518: step 26960, loss = 0.11, batch loss = 0.07 (21.5 examples/sec; 0.372 sec/batch; 31h:35m:25s remains)
INFO - root - 2017-12-17 04:55:35.595914: step 26970, loss = 0.10, batch loss = 0.06 (21.5 examples/sec; 0.373 sec/batch; 31h:37m:07s remains)
INFO - root - 2017-12-17 04:55:39.259242: step 26980, loss = 0.10, batch loss = 0.07 (22.1 examples/sec; 0.361 sec/batch; 30h:39m:31s remains)
INFO - root - 2017-12-17 04:55:42.900935: step 26990, loss = 0.09, batch loss = 0.05 (20.6 examples/sec; 0.389 sec/batch; 32h:59m:40s remains)
INFO - root - 2017-12-17 04:55:46.531078: step 27000, loss = 0.10, batch loss = 0.06 (21.5 examples/sec; 0.372 sec/batch; 31h:33m:17s remains)
INFO - root - 2017-12-17 04:55:50.318052: step 27010, loss = 0.11, batch loss = 0.08 (22.2 examples/sec; 0.361 sec/batch; 30h:35m:57s remains)
INFO - root - 2017-12-17 04:55:53.886255: step 27020, loss = 0.19, batch loss = 0.16 (22.5 examples/sec; 0.356 sec/batch; 30h:11m:16s remains)
INFO - root - 2017-12-17 04:55:57.583426: step 27030, loss = 0.12, batch loss = 0.08 (22.1 examples/sec; 0.362 sec/batch; 30h:44m:01s remains)
INFO - root - 2017-12-17 04:56:01.447985: step 27040, loss = 0.09, batch loss = 0.06 (19.7 examples/sec; 0.405 sec/batch; 34h:22m:36s remains)
INFO - root - 2017-12-17 04:56:05.140292: step 27050, loss = 0.12, batch loss = 0.08 (22.0 examples/sec; 0.364 sec/batch; 30h:52m:40s remains)
INFO - root - 2017-12-17 04:56:08.784289: step 27060, loss = 0.13, batch loss = 0.09 (21.8 examples/sec; 0.366 sec/batch; 31h:04m:09s remains)
INFO - root - 2017-12-17 04:56:12.359014: step 27070, loss = 0.11, batch loss = 0.08 (24.1 examples/sec; 0.332 sec/batch; 28h:10m:47s remains)
INFO - root - 2017-12-17 04:56:15.983235: step 27080, loss = 0.10, batch loss = 0.06 (22.2 examples/sec; 0.361 sec/batch; 30h:35m:20s remains)
INFO - root - 2017-12-17 04:56:19.684016: step 27090, loss = 0.11, batch loss = 0.07 (22.7 examples/sec; 0.352 sec/batch; 29h:53m:05s remains)
INFO - root - 2017-12-17 04:56:23.279705: step 27100, loss = 0.09, batch loss = 0.06 (21.1 examples/sec; 0.379 sec/batch; 32h:10m:48s remains)
INFO - root - 2017-12-17 04:56:27.196279: step 27110, loss = 0.20, batch loss = 0.17 (21.7 examples/sec; 0.369 sec/batch; 31h:17m:38s remains)
INFO - root - 2017-12-17 04:56:30.889484: step 27120, loss = 0.08, batch loss = 0.04 (21.7 examples/sec; 0.369 sec/batch; 31h:15m:52s remains)
INFO - root - 2017-12-17 04:56:34.658797: step 27130, loss = 0.10, batch loss = 0.07 (21.4 examples/sec; 0.374 sec/batch; 31h:44m:27s remains)
INFO - root - 2017-12-17 04:56:38.365527: step 27140, loss = 0.09, batch loss = 0.06 (21.3 examples/sec; 0.376 sec/batch; 31h:52m:27s remains)
INFO - root - 2017-12-17 04:56:42.086010: step 27150, loss = 0.12, batch loss = 0.08 (21.2 examples/sec; 0.378 sec/batch; 32h:02m:25s remains)
INFO - root - 2017-12-17 04:56:45.798337: step 27160, loss = 0.12, batch loss = 0.09 (22.3 examples/sec; 0.359 sec/batch; 30h:29m:19s remains)
INFO - root - 2017-12-17 04:56:49.557656: step 27170, loss = 0.17, batch loss = 0.13 (21.0 examples/sec; 0.381 sec/batch; 32h:18m:13s remains)
INFO - root - 2017-12-17 04:56:53.269241: step 27180, loss = 0.10, batch loss = 0.07 (21.0 examples/sec; 0.380 sec/batch; 32h:15m:48s remains)
INFO - root - 2017-12-17 04:56:57.043301: step 27190, loss = 0.09, batch loss = 0.06 (22.2 examples/sec; 0.361 sec/batch; 30h:35m:06s remains)
INFO - root - 2017-12-17 04:57:00.770877: step 27200, loss = 0.08, batch loss = 0.05 (21.3 examples/sec; 0.376 sec/batch; 31h:51m:19s remains)
INFO - root - 2017-12-17 04:57:04.711519: step 27210, loss = 0.09, batch loss = 0.05 (21.2 examples/sec; 0.377 sec/batch; 31h:55m:46s remains)
INFO - root - 2017-12-17 04:57:08.482326: step 27220, loss = 0.09, batch loss = 0.06 (20.9 examples/sec; 0.384 sec/batch; 32h:31m:55s remains)
INFO - root - 2017-12-17 04:57:12.277147: step 27230, loss = 0.11, batch loss = 0.08 (22.1 examples/sec; 0.362 sec/batch; 30h:43m:50s remains)
INFO - root - 2017-12-17 04:57:16.049530: step 27240, loss = 0.17, batch loss = 0.13 (21.9 examples/sec; 0.365 sec/batch; 30h:54m:30s remains)
INFO - root - 2017-12-17 04:57:19.700761: step 27250, loss = 0.12, batch loss = 0.09 (22.6 examples/sec; 0.355 sec/batch; 30h:04m:51s remains)
INFO - root - 2017-12-17 04:57:23.396198: step 27260, loss = 0.10, batch loss = 0.07 (21.8 examples/sec; 0.367 sec/batch; 31h:04m:53s remains)
INFO - root - 2017-12-17 04:57:27.159213: step 27270, loss = 0.10, batch loss = 0.06 (21.6 examples/sec; 0.370 sec/batch; 31h:22m:42s remains)
INFO - root - 2017-12-17 04:57:30.865611: step 27280, loss = 0.10, batch loss = 0.07 (21.6 examples/sec; 0.370 sec/batch; 31h:23m:48s remains)
INFO - root - 2017-12-17 04:57:34.587585: step 27290, loss = 0.10, batch loss = 0.06 (20.7 examples/sec; 0.387 sec/batch; 32h:46m:06s remains)
INFO - root - 2017-12-17 04:57:38.274484: step 27300, loss = 0.09, batch loss = 0.06 (22.3 examples/sec; 0.359 sec/batch; 30h:25m:46s remains)
INFO - root - 2017-12-17 04:57:42.158730: step 27310, loss = 0.12, batch loss = 0.09 (20.8 examples/sec; 0.385 sec/batch; 32h:39m:54s remains)
INFO - root - 2017-12-17 04:57:45.899268: step 27320, loss = 0.13, batch loss = 0.10 (20.7 examples/sec; 0.387 sec/batch; 32h:50m:05s remains)
INFO - root - 2017-12-17 04:57:49.631706: step 27330, loss = 0.10, batch loss = 0.07 (20.3 examples/sec; 0.393 sec/batch; 33h:19m:28s remains)
INFO - root - 2017-12-17 04:57:53.429940: step 27340, loss = 0.14, batch loss = 0.10 (21.8 examples/sec; 0.367 sec/batch; 31h:07m:20s remains)
INFO - root - 2017-12-17 04:57:57.206714: step 27350, loss = 0.13, batch loss = 0.10 (21.8 examples/sec; 0.367 sec/batch; 31h:07m:37s remains)
INFO - root - 2017-12-17 04:58:00.995319: step 27360, loss = 0.17, batch loss = 0.13 (22.0 examples/sec; 0.363 sec/batch; 30h:48m:19s remains)
INFO - root - 2017-12-17 04:58:04.759883: step 27370, loss = 0.11, batch loss = 0.08 (20.7 examples/sec; 0.386 sec/batch; 32h:42m:31s remains)
INFO - root - 2017-12-17 04:58:08.536207: step 27380, loss = 0.16, batch loss = 0.13 (20.4 examples/sec; 0.392 sec/batch; 33h:14m:33s remains)
INFO - root - 2017-12-17 04:58:12.313230: step 27390, loss = 0.11, batch loss = 0.08 (20.9 examples/sec; 0.383 sec/batch; 32h:30m:06s remains)
INFO - root - 2017-12-17 04:58:16.016187: step 27400, loss = 0.10, batch loss = 0.07 (21.3 examples/sec; 0.376 sec/batch; 31h:52m:51s remains)
INFO - root - 2017-12-17 04:58:20.016878: step 27410, loss = 0.11, batch loss = 0.07 (20.6 examples/sec; 0.389 sec/batch; 32h:56m:07s remains)
INFO - root - 2017-12-17 04:58:23.773073: step 27420, loss = 0.13, batch loss = 0.10 (21.4 examples/sec; 0.373 sec/batch; 31h:37m:41s remains)
INFO - root - 2017-12-17 04:58:27.543632: step 27430, loss = 0.10, batch loss = 0.06 (21.4 examples/sec; 0.373 sec/batch; 31h:38m:07s remains)
INFO - root - 2017-12-17 04:58:31.401267: step 27440, loss = 0.09, batch loss = 0.06 (21.0 examples/sec; 0.380 sec/batch; 32h:14m:14s remains)
INFO - root - 2017-12-17 04:58:35.240560: step 27450, loss = 0.12, batch loss = 0.09 (21.5 examples/sec; 0.371 sec/batch; 31h:27m:55s remains)
INFO - root - 2017-12-17 04:58:38.982363: step 27460, loss = 0.10, batch loss = 0.07 (21.8 examples/sec; 0.368 sec/batch; 31h:08m:44s remains)
INFO - root - 2017-12-17 04:58:42.707617: step 27470, loss = 0.11, batch loss = 0.07 (22.0 examples/sec; 0.363 sec/batch; 30h:46m:58s remains)
INFO - root - 2017-12-17 04:58:46.447333: step 27480, loss = 0.11, batch loss = 0.07 (21.8 examples/sec; 0.367 sec/batch; 31h:04m:52s remains)
INFO - root - 2017-12-17 04:58:50.204053: step 27490, loss = 0.11, batch loss = 0.07 (20.8 examples/sec; 0.384 sec/batch; 32h:32m:40s remains)
INFO - root - 2017-12-17 04:58:53.809680: step 27500, loss = 0.09, batch loss = 0.05 (23.4 examples/sec; 0.342 sec/batch; 29h:00m:27s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-27500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-27500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 04:58:58.214557: step 27510, loss = 0.10, batch loss = 0.06 (21.4 examples/sec; 0.373 sec/batch; 31h:36m:04s remains)
INFO - root - 2017-12-17 04:59:01.996339: step 27520, loss = 0.10, batch loss = 0.06 (20.7 examples/sec; 0.387 sec/batch; 32h:47m:45s remains)
INFO - root - 2017-12-17 04:59:05.752646: step 27530, loss = 0.09, batch loss = 0.06 (22.2 examples/sec; 0.361 sec/batch; 30h:34m:06s remains)
INFO - root - 2017-12-17 04:59:09.536399: step 27540, loss = 0.13, batch loss = 0.10 (21.1 examples/sec; 0.379 sec/batch; 32h:05m:49s remains)
INFO - root - 2017-12-17 04:59:13.316914: step 27550, loss = 0.14, batch loss = 0.10 (20.7 examples/sec; 0.387 sec/batch; 32h:47m:04s remains)
INFO - root - 2017-12-17 04:59:17.029356: step 27560, loss = 0.09, batch loss = 0.05 (21.2 examples/sec; 0.378 sec/batch; 32h:00m:36s remains)
INFO - root - 2017-12-17 04:59:20.736764: step 27570, loss = 0.09, batch loss = 0.06 (21.5 examples/sec; 0.373 sec/batch; 31h:34m:56s remains)
INFO - root - 2017-12-17 04:59:24.452417: step 27580, loss = 0.13, batch loss = 0.10 (21.1 examples/sec; 0.379 sec/batch; 32h:08m:08s remains)
INFO - root - 2017-12-17 04:59:28.151656: step 27590, loss = 0.12, batch loss = 0.08 (21.2 examples/sec; 0.378 sec/batch; 31h:59m:38s remains)
INFO - root - 2017-12-17 04:59:31.892945: step 27600, loss = 0.09, batch loss = 0.06 (21.9 examples/sec; 0.365 sec/batch; 30h:56m:23s remains)
INFO - root - 2017-12-17 04:59:35.800465: step 27610, loss = 0.15, batch loss = 0.12 (22.0 examples/sec; 0.364 sec/batch; 30h:47m:51s remains)
INFO - root - 2017-12-17 04:59:39.553704: step 27620, loss = 0.10, batch loss = 0.07 (20.5 examples/sec; 0.390 sec/batch; 33h:00m:13s remains)
INFO - root - 2017-12-17 04:59:43.296187: step 27630, loss = 0.11, batch loss = 0.07 (21.8 examples/sec; 0.367 sec/batch; 31h:04m:00s remains)
INFO - root - 2017-12-17 04:59:46.965464: step 27640, loss = 0.17, batch loss = 0.13 (22.1 examples/sec; 0.363 sec/batch; 30h:42m:44s remains)
INFO - root - 2017-12-17 04:59:50.630494: step 27650, loss = 0.12, batch loss = 0.08 (22.3 examples/sec; 0.358 sec/batch; 30h:18m:56s remains)
INFO - root - 2017-12-17 04:59:54.329075: step 27660, loss = 0.11, batch loss = 0.08 (22.2 examples/sec; 0.360 sec/batch; 30h:29m:18s remains)
INFO - root - 2017-12-17 04:59:58.068864: step 27670, loss = 0.09, batch loss = 0.06 (21.2 examples/sec; 0.377 sec/batch; 31h:55m:41s remains)
INFO - root - 2017-12-17 05:00:01.556254: step 27680, loss = 0.10, batch loss = 0.07 (21.3 examples/sec; 0.376 sec/batch; 31h:52m:01s remains)
INFO - root - 2017-12-17 05:00:05.390068: step 27690, loss = 0.14, batch loss = 0.11 (19.8 examples/sec; 0.404 sec/batch; 34h:11m:07s remains)
INFO - root - 2017-12-17 05:00:09.240302: step 27700, loss = 0.17, batch loss = 0.14 (20.6 examples/sec; 0.388 sec/batch; 32h:52m:25s remains)
INFO - root - 2017-12-17 05:00:13.164904: step 27710, loss = 0.09, batch loss = 0.06 (21.0 examples/sec; 0.381 sec/batch; 32h:16m:28s remains)
INFO - root - 2017-12-17 05:00:17.050251: step 27720, loss = 0.10, batch loss = 0.07 (21.2 examples/sec; 0.377 sec/batch; 31h:57m:25s remains)
INFO - root - 2017-12-17 05:00:20.847199: step 27730, loss = 0.11, batch loss = 0.08 (20.2 examples/sec; 0.396 sec/batch; 33h:33m:57s remains)
INFO - root - 2017-12-17 05:00:24.598273: step 27740, loss = 0.11, batch loss = 0.08 (22.6 examples/sec; 0.354 sec/batch; 29h:56m:09s remains)
INFO - root - 2017-12-17 05:00:28.366847: step 27750, loss = 0.22, batch loss = 0.18 (21.1 examples/sec; 0.379 sec/batch; 32h:04m:12s remains)
INFO - root - 2017-12-17 05:00:32.081372: step 27760, loss = 0.10, batch loss = 0.07 (21.1 examples/sec; 0.380 sec/batch; 32h:08m:24s remains)
INFO - root - 2017-12-17 05:00:35.835883: step 27770, loss = 0.10, batch loss = 0.06 (20.5 examples/sec; 0.391 sec/batch; 33h:03m:55s remains)
INFO - root - 2017-12-17 05:00:39.532975: step 27780, loss = 0.11, batch loss = 0.08 (21.2 examples/sec; 0.378 sec/batch; 31h:59m:35s remains)
INFO - root - 2017-12-17 05:00:43.296018: step 27790, loss = 0.12, batch loss = 0.09 (20.9 examples/sec; 0.382 sec/batch; 32h:21m:50s remains)
INFO - root - 2017-12-17 05:00:47.094796: step 27800, loss = 0.11, batch loss = 0.07 (20.6 examples/sec; 0.388 sec/batch; 32h:49m:20s remains)
INFO - root - 2017-12-17 05:00:51.064673: step 27810, loss = 0.12, batch loss = 0.09 (21.1 examples/sec; 0.379 sec/batch; 32h:04m:44s remains)
INFO - root - 2017-12-17 05:00:54.778631: step 27820, loss = 0.12, batch loss = 0.09 (21.2 examples/sec; 0.377 sec/batch; 31h:54m:16s remains)
INFO - root - 2017-12-17 05:00:58.502940: step 27830, loss = 0.08, batch loss = 0.05 (22.8 examples/sec; 0.351 sec/batch; 29h:40m:54s remains)
INFO - root - 2017-12-17 05:01:02.225978: step 27840, loss = 0.09, batch loss = 0.06 (21.1 examples/sec; 0.380 sec/batch; 32h:07m:32s remains)
INFO - root - 2017-12-17 05:01:06.014976: step 27850, loss = 0.11, batch loss = 0.08 (21.4 examples/sec; 0.373 sec/batch; 31h:34m:40s remains)
INFO - root - 2017-12-17 05:01:09.806739: step 27860, loss = 0.10, batch loss = 0.07 (21.2 examples/sec; 0.378 sec/batch; 31h:59m:26s remains)
INFO - root - 2017-12-17 05:01:13.584190: step 27870, loss = 0.10, batch loss = 0.06 (20.8 examples/sec; 0.385 sec/batch; 32h:33m:40s remains)
INFO - root - 2017-12-17 05:01:17.349908: step 27880, loss = 0.10, batch loss = 0.07 (21.2 examples/sec; 0.378 sec/batch; 31h:57m:38s remains)
INFO - root - 2017-12-17 05:01:21.072109: step 27890, loss = 0.15, batch loss = 0.11 (20.1 examples/sec; 0.398 sec/batch; 33h:41m:50s remains)
INFO - root - 2017-12-17 05:01:24.822360: step 27900, loss = 0.12, batch loss = 0.09 (20.5 examples/sec; 0.390 sec/batch; 32h:58m:04s remains)
INFO - root - 2017-12-17 05:01:28.780570: step 27910, loss = 0.13, batch loss = 0.10 (23.3 examples/sec; 0.344 sec/batch; 29h:05m:43s remains)
INFO - root - 2017-12-17 05:01:32.486190: step 27920, loss = 0.11, batch loss = 0.07 (21.7 examples/sec; 0.368 sec/batch; 31h:08m:56s remains)
INFO - root - 2017-12-17 05:01:36.237102: step 27930, loss = 0.10, batch loss = 0.07 (22.5 examples/sec; 0.355 sec/batch; 30h:02m:07s remains)
INFO - root - 2017-12-17 05:01:40.002021: step 27940, loss = 0.09, batch loss = 0.05 (21.9 examples/sec; 0.365 sec/batch; 30h:54m:01s remains)
INFO - root - 2017-12-17 05:01:43.743123: step 27950, loss = 0.13, batch loss = 0.09 (21.4 examples/sec; 0.374 sec/batch; 31h:37m:08s remains)
INFO - root - 2017-12-17 05:01:47.522016: step 27960, loss = 0.11, batch loss = 0.07 (20.3 examples/sec; 0.394 sec/batch; 33h:18m:53s remains)
INFO - root - 2017-12-17 05:01:51.259912: step 27970, loss = 0.11, batch loss = 0.08 (21.3 examples/sec; 0.376 sec/batch; 31h:48m:02s remains)
INFO - root - 2017-12-17 05:01:55.032189: step 27980, loss = 0.09, batch loss = 0.06 (21.5 examples/sec; 0.372 sec/batch; 31h:30m:04s remains)
INFO - root - 2017-12-17 05:01:58.852804: step 27990, loss = 0.12, batch loss = 0.08 (20.0 examples/sec; 0.401 sec/batch; 33h:54m:37s remains)
INFO - root - 2017-12-17 05:02:02.611836: step 28000, loss = 0.10, batch loss = 0.06 (21.7 examples/sec; 0.368 sec/batch; 31h:07m:59s remains)
INFO - root - 2017-12-17 05:02:06.557907: step 28010, loss = 0.10, batch loss = 0.07 (21.2 examples/sec; 0.377 sec/batch; 31h:53m:59s remains)
INFO - root - 2017-12-17 05:02:10.247768: step 28020, loss = 0.11, batch loss = 0.08 (21.3 examples/sec; 0.376 sec/batch; 31h:48m:05s remains)
INFO - root - 2017-12-17 05:02:14.015302: step 28030, loss = 0.09, batch loss = 0.06 (22.5 examples/sec; 0.355 sec/batch; 30h:02m:41s remains)
INFO - root - 2017-12-17 05:02:17.767126: step 28040, loss = 0.10, batch loss = 0.07 (21.0 examples/sec; 0.381 sec/batch; 32h:13m:35s remains)
INFO - root - 2017-12-17 05:02:21.605273: step 28050, loss = 0.11, batch loss = 0.08 (20.5 examples/sec; 0.390 sec/batch; 32h:57m:27s remains)
INFO - root - 2017-12-17 05:02:25.318941: step 28060, loss = 0.10, batch loss = 0.07 (21.3 examples/sec; 0.375 sec/batch; 31h:41m:19s remains)
INFO - root - 2017-12-17 05:02:29.048246: step 28070, loss = 0.13, batch loss = 0.09 (21.6 examples/sec; 0.370 sec/batch; 31h:18m:42s remains)
INFO - root - 2017-12-17 05:02:32.807063: step 28080, loss = 0.11, batch loss = 0.08 (22.3 examples/sec; 0.359 sec/batch; 30h:22m:42s remains)
INFO - root - 2017-12-17 05:02:36.541248: step 28090, loss = 0.10, batch loss = 0.07 (22.2 examples/sec; 0.360 sec/batch; 30h:26m:40s remains)
INFO - root - 2017-12-17 05:02:40.316946: step 28100, loss = 0.10, batch loss = 0.07 (21.4 examples/sec; 0.375 sec/batch; 31h:40m:16s remains)
INFO - root - 2017-12-17 05:02:44.345454: step 28110, loss = 0.12, batch loss = 0.08 (20.6 examples/sec; 0.388 sec/batch; 32h:47m:05s remains)
INFO - root - 2017-12-17 05:02:48.069351: step 28120, loss = 0.11, batch loss = 0.08 (21.4 examples/sec; 0.375 sec/batch; 31h:40m:39s remains)
INFO - root - 2017-12-17 05:02:51.790979: step 28130, loss = 0.10, batch loss = 0.07 (21.3 examples/sec; 0.376 sec/batch; 31h:46m:34s remains)
INFO - root - 2017-12-17 05:02:55.515981: step 28140, loss = 0.08, batch loss = 0.05 (21.3 examples/sec; 0.376 sec/batch; 31h:46m:50s remains)
INFO - root - 2017-12-17 05:02:59.304082: step 28150, loss = 0.10, batch loss = 0.07 (20.7 examples/sec; 0.386 sec/batch; 32h:36m:43s remains)
INFO - root - 2017-12-17 05:03:02.929288: step 28160, loss = 0.11, batch loss = 0.07 (21.5 examples/sec; 0.371 sec/batch; 31h:23m:57s remains)
INFO - root - 2017-12-17 05:03:06.735372: step 28170, loss = 0.10, batch loss = 0.07 (20.8 examples/sec; 0.384 sec/batch; 32h:27m:42s remains)
INFO - root - 2017-12-17 05:03:10.499967: step 28180, loss = 0.11, batch loss = 0.08 (21.8 examples/sec; 0.367 sec/batch; 31h:00m:24s remains)
INFO - root - 2017-12-17 05:03:14.242417: step 28190, loss = 0.08, batch loss = 0.04 (21.9 examples/sec; 0.365 sec/batch; 30h:50m:40s remains)
INFO - root - 2017-12-17 05:03:17.889677: step 28200, loss = 0.10, batch loss = 0.06 (23.2 examples/sec; 0.344 sec/batch; 29h:06m:08s remains)
INFO - root - 2017-12-17 05:03:21.746839: step 28210, loss = 0.11, batch loss = 0.07 (22.9 examples/sec; 0.350 sec/batch; 29h:33m:53s remains)
INFO - root - 2017-12-17 05:03:25.462343: step 28220, loss = 0.09, batch loss = 0.05 (21.0 examples/sec; 0.380 sec/batch; 32h:08m:27s remains)
INFO - root - 2017-12-17 05:03:29.215934: step 28230, loss = 0.13, batch loss = 0.09 (20.7 examples/sec; 0.386 sec/batch; 32h:38m:55s remains)
INFO - root - 2017-12-17 05:03:32.884678: step 28240, loss = 0.10, batch loss = 0.07 (21.3 examples/sec; 0.376 sec/batch; 31h:45m:38s remains)
INFO - root - 2017-12-17 05:03:36.504847: step 28250, loss = 0.11, batch loss = 0.07 (22.1 examples/sec; 0.362 sec/batch; 30h:33m:11s remains)
INFO - root - 2017-12-17 05:03:40.237598: step 28260, loss = 0.09, batch loss = 0.06 (21.6 examples/sec; 0.370 sec/batch; 31h:16m:41s remains)
INFO - root - 2017-12-17 05:03:43.931461: step 28270, loss = 0.10, batch loss = 0.07 (21.7 examples/sec; 0.369 sec/batch; 31h:09m:10s remains)
INFO - root - 2017-12-17 05:03:47.706718: step 28280, loss = 0.11, batch loss = 0.08 (21.3 examples/sec; 0.376 sec/batch; 31h:44m:30s remains)
INFO - root - 2017-12-17 05:03:51.392090: step 28290, loss = 0.09, batch loss = 0.05 (21.3 examples/sec; 0.375 sec/batch; 31h:41m:44s remains)
INFO - root - 2017-12-17 05:03:55.087647: step 28300, loss = 0.11, batch loss = 0.07 (22.0 examples/sec; 0.363 sec/batch; 30h:40m:39s remains)
INFO - root - 2017-12-17 05:03:58.956597: step 28310, loss = 0.10, batch loss = 0.06 (21.0 examples/sec; 0.382 sec/batch; 32h:14m:54s remains)
INFO - root - 2017-12-17 05:04:02.612142: step 28320, loss = 0.10, batch loss = 0.07 (21.8 examples/sec; 0.366 sec/batch; 30h:56m:48s remains)
INFO - root - 2017-12-17 05:04:06.201010: step 28330, loss = 0.10, batch loss = 0.06 (22.7 examples/sec; 0.353 sec/batch; 29h:47m:39s remains)
INFO - root - 2017-12-17 05:04:09.860401: step 28340, loss = 0.09, batch loss = 0.05 (20.7 examples/sec; 0.386 sec/batch; 32h:34m:33s remains)
INFO - root - 2017-12-17 05:04:13.561810: step 28350, loss = 0.10, batch loss = 0.06 (21.8 examples/sec; 0.367 sec/batch; 30h:59m:45s remains)
INFO - root - 2017-12-17 05:04:17.251214: step 28360, loss = 0.10, batch loss = 0.06 (23.1 examples/sec; 0.347 sec/batch; 29h:18m:15s remains)
INFO - root - 2017-12-17 05:04:20.868883: step 28370, loss = 0.10, batch loss = 0.07 (22.9 examples/sec; 0.349 sec/batch; 29h:30m:18s remains)
INFO - root - 2017-12-17 05:04:24.511975: step 28380, loss = 0.13, batch loss = 0.10 (21.3 examples/sec; 0.375 sec/batch; 31h:42m:18s remains)
INFO - root - 2017-12-17 05:04:28.171608: step 28390, loss = 0.13, batch loss = 0.10 (22.3 examples/sec; 0.359 sec/batch; 30h:19m:28s remains)
INFO - root - 2017-12-17 05:04:31.918185: step 28400, loss = 0.11, batch loss = 0.07 (21.8 examples/sec; 0.366 sec/batch; 30h:56m:24s remains)
INFO - root - 2017-12-17 05:04:35.852683: step 28410, loss = 0.10, batch loss = 0.07 (21.5 examples/sec; 0.372 sec/batch; 31h:25m:34s remains)
INFO - root - 2017-12-17 05:04:39.523887: step 28420, loss = 0.08, batch loss = 0.05 (21.2 examples/sec; 0.377 sec/batch; 31h:48m:46s remains)
INFO - root - 2017-12-17 05:04:43.261743: step 28430, loss = 0.18, batch loss = 0.14 (20.9 examples/sec; 0.383 sec/batch; 32h:19m:37s remains)
INFO - root - 2017-12-17 05:04:46.888793: step 28440, loss = 0.11, batch loss = 0.07 (21.0 examples/sec; 0.381 sec/batch; 32h:10m:42s remains)
INFO - root - 2017-12-17 05:04:50.643358: step 28450, loss = 0.11, batch loss = 0.07 (21.1 examples/sec; 0.378 sec/batch; 31h:57m:30s remains)
INFO - root - 2017-12-17 05:04:54.379575: step 28460, loss = 0.11, batch loss = 0.08 (20.7 examples/sec; 0.387 sec/batch; 32h:41m:18s remains)
INFO - root - 2017-12-17 05:04:58.132313: step 28470, loss = 0.09, batch loss = 0.06 (21.9 examples/sec; 0.365 sec/batch; 30h:49m:27s remains)
INFO - root - 2017-12-17 05:05:01.821625: step 28480, loss = 0.10, batch loss = 0.06 (21.7 examples/sec; 0.368 sec/batch; 31h:04m:55s remains)
INFO - root - 2017-12-17 05:05:05.512939: step 28490, loss = 0.10, batch loss = 0.07 (21.7 examples/sec; 0.369 sec/batch; 31h:07m:15s remains)
INFO - root - 2017-12-17 05:05:09.216466: step 28500, loss = 0.11, batch loss = 0.08 (21.0 examples/sec; 0.381 sec/batch; 32h:11m:57s remains)
INFO - root - 2017-12-17 05:05:13.117528: step 28510, loss = 0.09, batch loss = 0.06 (21.8 examples/sec; 0.367 sec/batch; 31h:01m:55s remains)
INFO - root - 2017-12-17 05:05:16.815217: step 28520, loss = 0.10, batch loss = 0.07 (21.8 examples/sec; 0.366 sec/batch; 30h:55m:14s remains)
INFO - root - 2017-12-17 05:05:20.516059: step 28530, loss = 0.10, batch loss = 0.07 (21.7 examples/sec; 0.368 sec/batch; 31h:04m:53s remains)
INFO - root - 2017-12-17 05:05:24.191686: step 28540, loss = 0.12, batch loss = 0.09 (22.1 examples/sec; 0.361 sec/batch; 30h:30m:16s remains)
INFO - root - 2017-12-17 05:05:27.939219: step 28550, loss = 0.12, batch loss = 0.09 (21.6 examples/sec; 0.370 sec/batch; 31h:16m:32s remains)
INFO - root - 2017-12-17 05:05:31.688247: step 28560, loss = 0.12, batch loss = 0.08 (21.6 examples/sec; 0.370 sec/batch; 31h:16m:12s remains)
INFO - root - 2017-12-17 05:05:35.359810: step 28570, loss = 0.09, batch loss = 0.06 (21.5 examples/sec; 0.372 sec/batch; 31h:24m:21s remains)
INFO - root - 2017-12-17 05:05:39.024984: step 28580, loss = 0.14, batch loss = 0.10 (21.9 examples/sec; 0.366 sec/batch; 30h:53m:17s remains)
INFO - root - 2017-12-17 05:05:42.711148: step 28590, loss = 0.13, batch loss = 0.10 (21.8 examples/sec; 0.367 sec/batch; 30h:58m:22s remains)
INFO - root - 2017-12-17 05:05:46.256079: step 28600, loss = 0.13, batch loss = 0.10 (32.6 examples/sec; 0.245 sec/batch; 20h:41m:07s remains)
INFO - root - 2017-12-17 05:05:50.171703: step 28610, loss = 0.10, batch loss = 0.06 (21.6 examples/sec; 0.370 sec/batch; 31h:13m:52s remains)
INFO - root - 2017-12-17 05:05:53.880317: step 28620, loss = 0.10, batch loss = 0.07 (20.9 examples/sec; 0.383 sec/batch; 32h:20m:31s remains)
INFO - root - 2017-12-17 05:05:57.523916: step 28630, loss = 0.09, batch loss = 0.05 (22.3 examples/sec; 0.359 sec/batch; 30h:20m:06s remains)
INFO - root - 2017-12-17 05:06:01.196347: step 28640, loss = 0.09, batch loss = 0.05 (22.7 examples/sec; 0.352 sec/batch; 29h:44m:52s remains)
INFO - root - 2017-12-17 05:06:04.778764: step 28650, loss = 0.10, batch loss = 0.07 (21.7 examples/sec; 0.369 sec/batch; 31h:06m:10s remains)
INFO - root - 2017-12-17 05:06:08.406518: step 28660, loss = 0.11, batch loss = 0.08 (23.3 examples/sec; 0.344 sec/batch; 29h:01m:07s remains)
INFO - root - 2017-12-17 05:06:11.981164: step 28670, loss = 0.10, batch loss = 0.07 (21.2 examples/sec; 0.377 sec/batch; 31h:50m:36s remains)
INFO - root - 2017-12-17 05:06:15.544971: step 28680, loss = 0.16, batch loss = 0.12 (22.5 examples/sec; 0.355 sec/batch; 29h:59m:05s remains)
INFO - root - 2017-12-17 05:06:19.148316: step 28690, loss = 0.11, batch loss = 0.08 (21.4 examples/sec; 0.375 sec/batch; 31h:37m:14s remains)
INFO - root - 2017-12-17 05:06:22.748138: step 28700, loss = 0.11, batch loss = 0.08 (24.6 examples/sec; 0.326 sec/batch; 27h:29m:08s remains)
INFO - root - 2017-12-17 05:06:26.620591: step 28710, loss = 0.11, batch loss = 0.07 (21.0 examples/sec; 0.380 sec/batch; 32h:05m:10s remains)
INFO - root - 2017-12-17 05:06:30.380729: step 28720, loss = 0.15, batch loss = 0.12 (21.4 examples/sec; 0.374 sec/batch; 31h:31m:27s remains)
INFO - root - 2017-12-17 05:06:34.115735: step 28730, loss = 0.12, batch loss = 0.09 (22.1 examples/sec; 0.362 sec/batch; 30h:30m:18s remains)
INFO - root - 2017-12-17 05:06:37.903323: step 28740, loss = 0.10, batch loss = 0.07 (20.4 examples/sec; 0.391 sec/batch; 33h:00m:52s remains)
INFO - root - 2017-12-17 05:06:41.661486: step 28750, loss = 0.08, batch loss = 0.05 (21.4 examples/sec; 0.374 sec/batch; 31h:32m:13s remains)
INFO - root - 2017-12-17 05:06:45.389828: step 28760, loss = 0.10, batch loss = 0.07 (21.3 examples/sec; 0.376 sec/batch; 31h:43m:33s remains)
INFO - root - 2017-12-17 05:06:49.045218: step 28770, loss = 0.11, batch loss = 0.07 (21.3 examples/sec; 0.375 sec/batch; 31h:37m:26s remains)
INFO - root - 2017-12-17 05:06:52.723414: step 28780, loss = 0.11, batch loss = 0.07 (22.2 examples/sec; 0.361 sec/batch; 30h:26m:33s remains)
INFO - root - 2017-12-17 05:06:56.415481: step 28790, loss = 0.10, batch loss = 0.07 (22.6 examples/sec; 0.355 sec/batch; 29h:54m:55s remains)
INFO - root - 2017-12-17 05:07:00.134450: step 28800, loss = 0.09, batch loss = 0.05 (21.0 examples/sec; 0.381 sec/batch; 32h:09m:33s remains)
INFO - root - 2017-12-17 05:07:04.078087: step 28810, loss = 0.14, batch loss = 0.10 (21.6 examples/sec; 0.370 sec/batch; 31h:15m:06s remains)
INFO - root - 2017-12-17 05:07:07.780021: step 28820, loss = 0.09, batch loss = 0.06 (20.8 examples/sec; 0.384 sec/batch; 32h:22m:37s remains)
INFO - root - 2017-12-17 05:07:11.477588: step 28830, loss = 0.09, batch loss = 0.05 (21.2 examples/sec; 0.377 sec/batch; 31h:46m:52s remains)
INFO - root - 2017-12-17 05:07:15.229756: step 28840, loss = 0.10, batch loss = 0.07 (21.4 examples/sec; 0.374 sec/batch; 31h:31m:22s remains)
INFO - root - 2017-12-17 05:07:18.987795: step 28850, loss = 0.08, batch loss = 0.05 (20.6 examples/sec; 0.387 sec/batch; 32h:41m:01s remains)
INFO - root - 2017-12-17 05:07:22.680361: step 28860, loss = 0.15, batch loss = 0.12 (21.7 examples/sec; 0.369 sec/batch; 31h:07m:09s remains)
INFO - root - 2017-12-17 05:07:26.463565: step 28870, loss = 0.11, batch loss = 0.08 (21.5 examples/sec; 0.372 sec/batch; 31h:22m:11s remains)
INFO - root - 2017-12-17 05:07:30.301616: step 28880, loss = 0.10, batch loss = 0.07 (21.2 examples/sec; 0.378 sec/batch; 31h:51m:46s remains)
INFO - root - 2017-12-17 05:07:34.001872: step 28890, loss = 0.10, batch loss = 0.07 (21.2 examples/sec; 0.378 sec/batch; 31h:52m:14s remains)
INFO - root - 2017-12-17 05:07:37.732422: step 28900, loss = 0.15, batch loss = 0.12 (22.5 examples/sec; 0.355 sec/batch; 29h:57m:41s remains)
INFO - root - 2017-12-17 05:07:41.619155: step 28910, loss = 0.09, batch loss = 0.06 (22.6 examples/sec; 0.354 sec/batch; 29h:50m:23s remains)
INFO - root - 2017-12-17 05:07:45.316945: step 28920, loss = 0.10, batch loss = 0.07 (21.4 examples/sec; 0.375 sec/batch; 31h:35m:15s remains)
INFO - root - 2017-12-17 05:07:49.110137: step 28930, loss = 0.11, batch loss = 0.08 (20.1 examples/sec; 0.397 sec/batch; 33h:29m:16s remains)
INFO - root - 2017-12-17 05:07:52.800441: step 28940, loss = 0.18, batch loss = 0.14 (22.1 examples/sec; 0.362 sec/batch; 30h:32m:28s remains)
INFO - root - 2017-12-17 05:07:56.492194: step 28950, loss = 0.11, batch loss = 0.08 (22.1 examples/sec; 0.362 sec/batch; 30h:29m:41s remains)
INFO - root - 2017-12-17 05:08:00.180325: step 28960, loss = 0.12, batch loss = 0.08 (21.4 examples/sec; 0.375 sec/batch; 31h:35m:34s remains)
INFO - root - 2017-12-17 05:08:03.870073: step 28970, loss = 0.09, batch loss = 0.06 (22.0 examples/sec; 0.363 sec/batch; 30h:36m:27s remains)
INFO - root - 2017-12-17 05:08:07.585859: step 28980, loss = 0.17, batch loss = 0.14 (21.4 examples/sec; 0.374 sec/batch; 31h:29m:42s remains)
INFO - root - 2017-12-17 05:08:11.356506: step 28990, loss = 0.11, batch loss = 0.08 (20.9 examples/sec; 0.383 sec/batch; 32h:19m:40s remains)
INFO - root - 2017-12-17 05:08:15.078306: step 29000, loss = 0.09, batch loss = 0.06 (22.0 examples/sec; 0.364 sec/batch; 30h:40m:16s remains)
INFO - root - 2017-12-17 05:08:18.980420: step 29010, loss = 0.11, batch loss = 0.07 (22.2 examples/sec; 0.361 sec/batch; 30h:26m:07s remains)
INFO - root - 2017-12-17 05:08:22.655098: step 29020, loss = 0.12, batch loss = 0.09 (23.0 examples/sec; 0.347 sec/batch; 29h:17m:14s remains)
INFO - root - 2017-12-17 05:08:26.351832: step 29030, loss = 0.14, batch loss = 0.11 (22.8 examples/sec; 0.351 sec/batch; 29h:34m:38s remains)
INFO - root - 2017-12-17 05:08:30.058020: step 29040, loss = 0.09, batch loss = 0.06 (20.7 examples/sec; 0.386 sec/batch; 32h:31m:46s remains)
INFO - root - 2017-12-17 05:08:33.781075: step 29050, loss = 0.10, batch loss = 0.07 (22.3 examples/sec; 0.359 sec/batch; 30h:15m:44s remains)
INFO - root - 2017-12-17 05:08:37.556303: step 29060, loss = 0.10, batch loss = 0.06 (21.0 examples/sec; 0.381 sec/batch; 32h:07m:12s remains)
INFO - root - 2017-12-17 05:08:41.285733: step 29070, loss = 0.10, batch loss = 0.07 (21.2 examples/sec; 0.377 sec/batch; 31h:48m:23s remains)
INFO - root - 2017-12-17 05:08:44.991266: step 29080, loss = 0.17, batch loss = 0.13 (21.4 examples/sec; 0.373 sec/batch; 31h:27m:29s remains)
INFO - root - 2017-12-17 05:08:48.710897: step 29090, loss = 0.08, batch loss = 0.05 (23.3 examples/sec; 0.343 sec/batch; 28h:52m:57s remains)
INFO - root - 2017-12-17 05:08:52.307698: step 29100, loss = 0.11, batch loss = 0.08 (22.0 examples/sec; 0.363 sec/batch; 30h:37m:33s remains)
INFO - root - 2017-12-17 05:08:56.159870: step 29110, loss = 0.11, batch loss = 0.07 (22.5 examples/sec; 0.356 sec/batch; 29h:58m:37s remains)
INFO - root - 2017-12-17 05:08:59.879317: step 29120, loss = 0.15, batch loss = 0.11 (21.4 examples/sec; 0.374 sec/batch; 31h:31m:58s remains)
INFO - root - 2017-12-17 05:09:03.583373: step 29130, loss = 0.12, batch loss = 0.09 (21.8 examples/sec; 0.367 sec/batch; 30h:55m:07s remains)
INFO - root - 2017-12-17 05:09:07.321014: step 29140, loss = 0.12, batch loss = 0.09 (23.0 examples/sec; 0.348 sec/batch; 29h:21m:46s remains)
INFO - root - 2017-12-17 05:09:11.022606: step 29150, loss = 0.10, batch loss = 0.07 (21.9 examples/sec; 0.365 sec/batch; 30h:45m:55s remains)
INFO - root - 2017-12-17 05:09:14.759791: step 29160, loss = 0.10, batch loss = 0.07 (21.3 examples/sec; 0.375 sec/batch; 31h:35m:23s remains)
INFO - root - 2017-12-17 05:09:18.503326: step 29170, loss = 0.09, batch loss = 0.06 (21.3 examples/sec; 0.375 sec/batch; 31h:36m:53s remains)
INFO - root - 2017-12-17 05:09:22.252057: step 29180, loss = 0.11, batch loss = 0.08 (20.2 examples/sec; 0.396 sec/batch; 33h:21m:13s remains)
INFO - root - 2017-12-17 05:09:25.860476: step 29190, loss = 0.15, batch loss = 0.11 (22.5 examples/sec; 0.355 sec/batch; 29h:55m:56s remains)
INFO - root - 2017-12-17 05:09:29.590931: step 29200, loss = 0.12, batch loss = 0.08 (22.4 examples/sec; 0.357 sec/batch; 30h:04m:19s remains)
INFO - root - 2017-12-17 05:09:33.749589: step 29210, loss = 0.08, batch loss = 0.05 (16.1 examples/sec; 0.497 sec/batch; 41h:52m:05s remains)
INFO - root - 2017-12-17 05:09:38.999946: step 29220, loss = 0.10, batch loss = 0.07 (15.1 examples/sec; 0.528 sec/batch; 44h:30m:26s remains)
INFO - root - 2017-12-17 05:09:43.734973: step 29230, loss = 0.09, batch loss = 0.06 (21.5 examples/sec; 0.372 sec/batch; 31h:21m:52s remains)
INFO - root - 2017-12-17 05:09:47.633892: step 29240, loss = 0.09, batch loss = 0.06 (21.8 examples/sec; 0.368 sec/batch; 30h:58m:42s remains)
INFO - root - 2017-12-17 05:09:51.346771: step 29250, loss = 0.09, batch loss = 0.06 (21.3 examples/sec; 0.376 sec/batch; 31h:41m:19s remains)
INFO - root - 2017-12-17 05:09:55.098766: step 29260, loss = 0.10, batch loss = 0.07 (21.1 examples/sec; 0.378 sec/batch; 31h:52m:24s remains)
INFO - root - 2017-12-17 05:09:58.590501: step 29270, loss = 0.12, batch loss = 0.08 (32.4 examples/sec; 0.247 sec/batch; 20h:46m:10s remains)
INFO - root - 2017-12-17 05:10:02.281450: step 29280, loss = 0.14, batch loss = 0.11 (21.3 examples/sec; 0.375 sec/batch; 31h:36m:49s remains)
INFO - root - 2017-12-17 05:10:05.951807: step 29290, loss = 0.12, batch loss = 0.09 (21.1 examples/sec; 0.380 sec/batch; 31h:58m:10s remains)
INFO - root - 2017-12-17 05:10:09.628459: step 29300, loss = 0.12, batch loss = 0.09 (21.0 examples/sec; 0.381 sec/batch; 32h:06m:23s remains)
INFO - root - 2017-12-17 05:10:13.507189: step 29310, loss = 0.13, batch loss = 0.10 (21.3 examples/sec; 0.375 sec/batch; 31h:36m:56s remains)
INFO - root - 2017-12-17 05:10:17.218815: step 29320, loss = 0.10, batch loss = 0.07 (21.4 examples/sec; 0.373 sec/batch; 31h:25m:27s remains)
INFO - root - 2017-12-17 05:10:20.923713: step 29330, loss = 0.10, batch loss = 0.07 (21.1 examples/sec; 0.378 sec/batch; 31h:52m:27s remains)
INFO - root - 2017-12-17 05:10:24.624307: step 29340, loss = 0.12, batch loss = 0.09 (21.1 examples/sec; 0.379 sec/batch; 31h:52m:54s remains)
INFO - root - 2017-12-17 05:10:28.315568: step 29350, loss = 0.15, batch loss = 0.12 (22.2 examples/sec; 0.360 sec/batch; 30h:16m:58s remains)
INFO - root - 2017-12-17 05:10:31.916738: step 29360, loss = 0.10, batch loss = 0.06 (21.7 examples/sec; 0.369 sec/batch; 31h:03m:36s remains)
INFO - root - 2017-12-17 05:10:35.570754: step 29370, loss = 0.14, batch loss = 0.10 (21.2 examples/sec; 0.377 sec/batch; 31h:42m:28s remains)
INFO - root - 2017-12-17 05:10:39.190664: step 29380, loss = 0.11, batch loss = 0.07 (22.6 examples/sec; 0.354 sec/batch; 29h:49m:53s remains)
INFO - root - 2017-12-17 05:10:42.873493: step 29390, loss = 0.12, batch loss = 0.08 (21.5 examples/sec; 0.371 sec/batch; 31h:16m:37s remains)
INFO - root - 2017-12-17 05:10:46.502163: step 29400, loss = 0.10, batch loss = 0.07 (22.2 examples/sec; 0.361 sec/batch; 30h:23m:48s remains)
INFO - root - 2017-12-17 05:10:50.449127: step 29410, loss = 0.15, batch loss = 0.11 (20.6 examples/sec; 0.389 sec/batch; 32h:43m:48s remains)
INFO - root - 2017-12-17 05:10:54.078034: step 29420, loss = 0.10, batch loss = 0.07 (22.1 examples/sec; 0.361 sec/batch; 30h:25m:19s remains)
INFO - root - 2017-12-17 05:10:57.651895: step 29430, loss = 0.11, batch loss = 0.07 (23.9 examples/sec; 0.335 sec/batch; 28h:11m:24s remains)
INFO - root - 2017-12-17 05:11:01.311915: step 29440, loss = 0.09, batch loss = 0.06 (20.4 examples/sec; 0.392 sec/batch; 33h:01m:19s remains)
INFO - root - 2017-12-17 05:11:05.019476: step 29450, loss = 0.09, batch loss = 0.06 (22.3 examples/sec; 0.359 sec/batch; 30h:14m:42s remains)
INFO - root - 2017-12-17 05:11:08.798816: step 29460, loss = 0.09, batch loss = 0.06 (21.8 examples/sec; 0.367 sec/batch; 30h:53m:32s remains)
INFO - root - 2017-12-17 05:11:12.592426: step 29470, loss = 0.11, batch loss = 0.07 (21.3 examples/sec; 0.376 sec/batch; 31h:39m:55s remains)
INFO - root - 2017-12-17 05:11:16.377072: step 29480, loss = 0.09, batch loss = 0.06 (21.1 examples/sec; 0.380 sec/batch; 31h:57m:42s remains)
INFO - root - 2017-12-17 05:11:20.132526: step 29490, loss = 0.10, batch loss = 0.07 (21.0 examples/sec; 0.380 sec/batch; 32h:00m:27s remains)
INFO - root - 2017-12-17 05:11:23.787886: step 29500, loss = 0.09, batch loss = 0.05 (23.9 examples/sec; 0.335 sec/batch; 28h:12m:05s remains)
INFO - root - 2017-12-17 05:11:27.776934: step 29510, loss = 0.09, batch loss = 0.06 (21.4 examples/sec; 0.373 sec/batch; 31h:24m:16s remains)
INFO - root - 2017-12-17 05:11:31.492320: step 29520, loss = 0.09, batch loss = 0.06 (20.0 examples/sec; 0.399 sec/batch; 33h:34m:54s remains)
INFO - root - 2017-12-17 05:11:35.315578: step 29530, loss = 0.09, batch loss = 0.05 (20.4 examples/sec; 0.393 sec/batch; 33h:02m:39s remains)
INFO - root - 2017-12-17 05:11:39.107861: step 29540, loss = 0.11, batch loss = 0.07 (20.9 examples/sec; 0.382 sec/batch; 32h:08m:51s remains)
INFO - root - 2017-12-17 05:11:42.887337: step 29550, loss = 0.10, batch loss = 0.07 (21.3 examples/sec; 0.375 sec/batch; 31h:34m:28s remains)
INFO - root - 2017-12-17 05:11:46.834288: step 29560, loss = 0.09, batch loss = 0.05 (15.9 examples/sec; 0.502 sec/batch; 42h:13m:27s remains)
INFO - root - 2017-12-17 05:11:50.657256: step 29570, loss = 0.11, batch loss = 0.08 (20.7 examples/sec; 0.386 sec/batch; 32h:27m:20s remains)
INFO - root - 2017-12-17 05:11:54.401099: step 29580, loss = 0.12, batch loss = 0.08 (22.1 examples/sec; 0.362 sec/batch; 30h:27m:15s remains)
INFO - root - 2017-12-17 05:11:58.205959: step 29590, loss = 0.15, batch loss = 0.12 (20.9 examples/sec; 0.382 sec/batch; 32h:09m:07s remains)
INFO - root - 2017-12-17 05:12:02.032620: step 29600, loss = 0.12, batch loss = 0.09 (21.5 examples/sec; 0.372 sec/batch; 31h:20m:00s remains)
INFO - root - 2017-12-17 05:12:05.976277: step 29610, loss = 0.10, batch loss = 0.07 (20.7 examples/sec; 0.386 sec/batch; 32h:29m:12s remains)
INFO - root - 2017-12-17 05:12:09.836771: step 29620, loss = 0.11, batch loss = 0.08 (21.4 examples/sec; 0.374 sec/batch; 31h:26m:06s remains)
INFO - root - 2017-12-17 05:12:13.641984: step 29630, loss = 0.10, batch loss = 0.07 (20.9 examples/sec; 0.382 sec/batch; 32h:10m:46s remains)
INFO - root - 2017-12-17 05:12:17.388481: step 29640, loss = 0.08, batch loss = 0.05 (21.0 examples/sec; 0.381 sec/batch; 32h:04m:15s remains)
INFO - root - 2017-12-17 05:12:21.191987: step 29650, loss = 0.13, batch loss = 0.10 (21.5 examples/sec; 0.373 sec/batch; 31h:21m:28s remains)
INFO - root - 2017-12-17 05:12:25.020537: step 29660, loss = 0.12, batch loss = 0.09 (19.3 examples/sec; 0.414 sec/batch; 34h:47m:44s remains)
INFO - root - 2017-12-17 05:12:28.753054: step 29670, loss = 0.10, batch loss = 0.07 (20.5 examples/sec; 0.390 sec/batch; 32h:46m:05s remains)
INFO - root - 2017-12-17 05:12:32.571990: step 29680, loss = 0.10, batch loss = 0.06 (21.9 examples/sec; 0.365 sec/batch; 30h:42m:31s remains)
INFO - root - 2017-12-17 05:12:36.367494: step 29690, loss = 0.12, batch loss = 0.09 (21.2 examples/sec; 0.377 sec/batch; 31h:44m:53s remains)
INFO - root - 2017-12-17 05:12:40.073601: step 29700, loss = 0.10, batch loss = 0.06 (21.2 examples/sec; 0.377 sec/batch; 31h:44m:25s remains)
INFO - root - 2017-12-17 05:12:44.041242: step 29710, loss = 0.10, batch loss = 0.07 (20.3 examples/sec; 0.394 sec/batch; 33h:05m:54s remains)
INFO - root - 2017-12-17 05:12:47.751169: step 29720, loss = 0.09, batch loss = 0.06 (21.9 examples/sec; 0.365 sec/batch; 30h:43m:06s remains)
INFO - root - 2017-12-17 05:12:51.402585: step 29730, loss = 0.12, batch loss = 0.08 (21.7 examples/sec; 0.368 sec/batch; 30h:56m:35s remains)
INFO - root - 2017-12-17 05:12:55.247845: step 29740, loss = 0.12, batch loss = 0.09 (16.6 examples/sec; 0.481 sec/batch; 40h:29m:38s remains)
INFO - root - 2017-12-17 05:12:59.102193: step 29750, loss = 0.11, batch loss = 0.08 (20.9 examples/sec; 0.383 sec/batch; 32h:14m:40s remains)
INFO - root - 2017-12-17 05:13:02.781392: step 29760, loss = 0.12, batch loss = 0.08 (24.4 examples/sec; 0.328 sec/batch; 27h:33m:59s remains)
INFO - root - 2017-12-17 05:13:06.512901: step 29770, loss = 0.10, batch loss = 0.07 (23.8 examples/sec; 0.336 sec/batch; 28h:16m:27s remains)
INFO - root - 2017-12-17 05:13:10.261769: step 29780, loss = 0.11, batch loss = 0.07 (21.9 examples/sec; 0.366 sec/batch; 30h:45m:28s remains)
INFO - root - 2017-12-17 05:13:14.008555: step 29790, loss = 0.09, batch loss = 0.06 (21.2 examples/sec; 0.378 sec/batch; 31h:45m:08s remains)
INFO - root - 2017-12-17 05:13:17.844359: step 29800, loss = 0.10, batch loss = 0.07 (21.1 examples/sec; 0.379 sec/batch; 31h:53m:14s remains)
INFO - root - 2017-12-17 05:13:21.781898: step 29810, loss = 0.11, batch loss = 0.08 (21.3 examples/sec; 0.376 sec/batch; 31h:39m:11s remains)
INFO - root - 2017-12-17 05:13:25.506389: step 29820, loss = 0.11, batch loss = 0.07 (20.7 examples/sec; 0.386 sec/batch; 32h:26m:10s remains)
INFO - root - 2017-12-17 05:13:29.182168: step 29830, loss = 0.12, batch loss = 0.09 (22.0 examples/sec; 0.363 sec/batch; 30h:32m:23s remains)
INFO - root - 2017-12-17 05:13:32.881874: step 29840, loss = 0.16, batch loss = 0.12 (20.8 examples/sec; 0.384 sec/batch; 32h:15m:55s remains)
INFO - root - 2017-12-17 05:13:36.547334: step 29850, loss = 0.13, batch loss = 0.10 (21.5 examples/sec; 0.371 sec/batch; 31h:13m:07s remains)
INFO - root - 2017-12-17 05:13:40.306691: step 29860, loss = 0.23, batch loss = 0.20 (21.3 examples/sec; 0.376 sec/batch; 31h:35m:54s remains)
INFO - root - 2017-12-17 05:13:44.095143: step 29870, loss = 0.11, batch loss = 0.08 (21.3 examples/sec; 0.375 sec/batch; 31h:31m:19s remains)
INFO - root - 2017-12-17 05:13:48.542144: step 29880, loss = 0.09, batch loss = 0.06 (14.3 examples/sec; 0.558 sec/batch; 46h:53m:15s remains)
INFO - root - 2017-12-17 05:13:53.973856: step 29890, loss = 0.14, batch loss = 0.11 (14.8 examples/sec; 0.542 sec/batch; 45h:34m:07s remains)
INFO - root - 2017-12-17 05:13:59.402081: step 29900, loss = 0.12, batch loss = 0.09 (15.0 examples/sec; 0.534 sec/batch; 44h:54m:30s remains)
INFO - root - 2017-12-17 05:14:05.216067: step 29910, loss = 0.14, batch loss = 0.10 (14.5 examples/sec; 0.550 sec/batch; 46h:15m:39s remains)
INFO - root - 2017-12-17 05:14:10.705599: step 29920, loss = 0.11, batch loss = 0.08 (14.3 examples/sec; 0.558 sec/batch; 46h:52m:26s remains)
INFO - root - 2017-12-17 05:14:16.154309: step 29930, loss = 0.12, batch loss = 0.08 (14.7 examples/sec; 0.543 sec/batch; 45h:35m:52s remains)
INFO - root - 2017-12-17 05:14:21.679197: step 29940, loss = 0.11, batch loss = 0.08 (14.4 examples/sec; 0.554 sec/batch; 46h:34m:22s remains)
INFO - root - 2017-12-17 05:14:26.919322: step 29950, loss = 0.10, batch loss = 0.07 (17.7 examples/sec; 0.453 sec/batch; 38h:05m:04s remains)
INFO - root - 2017-12-17 05:14:30.805108: step 29960, loss = 0.11, batch loss = 0.08 (21.8 examples/sec; 0.367 sec/batch; 30h:52m:45s remains)
INFO - root - 2017-12-17 05:14:34.480467: step 29970, loss = 0.12, batch loss = 0.09 (22.9 examples/sec; 0.349 sec/batch; 29h:21m:55s remains)
INFO - root - 2017-12-17 05:14:38.151815: step 29980, loss = 0.09, batch loss = 0.05 (21.5 examples/sec; 0.371 sec/batch; 31h:12m:35s remains)
INFO - root - 2017-12-17 05:14:41.806236: step 29990, loss = 0.13, batch loss = 0.09 (21.5 examples/sec; 0.372 sec/batch; 31h:15m:05s remains)
INFO - root - 2017-12-17 05:14:45.510371: step 30000, loss = 0.14, batch loss = 0.11 (22.2 examples/sec; 0.361 sec/batch; 30h:18m:53s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-30000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-30000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 05:14:50.048040: step 30010, loss = 0.10, batch loss = 0.07 (21.7 examples/sec; 0.369 sec/batch; 31h:00m:29s remains)
INFO - root - 2017-12-17 05:14:53.779377: step 30020, loss = 0.10, batch loss = 0.06 (21.1 examples/sec; 0.379 sec/batch; 31h:50m:56s remains)
INFO - root - 2017-12-17 05:14:57.447558: step 30030, loss = 0.10, batch loss = 0.06 (22.3 examples/sec; 0.359 sec/batch; 30h:07m:55s remains)
INFO - root - 2017-12-17 05:15:01.603935: step 30040, loss = 0.11, batch loss = 0.08 (14.9 examples/sec; 0.538 sec/batch; 45h:10m:05s remains)
INFO - root - 2017-12-17 05:15:06.739062: step 30050, loss = 0.15, batch loss = 0.11 (16.0 examples/sec; 0.500 sec/batch; 41h:58m:21s remains)
INFO - root - 2017-12-17 05:15:11.854764: step 30060, loss = 0.10, batch loss = 0.07 (15.1 examples/sec; 0.530 sec/batch; 44h:31m:02s remains)
INFO - root - 2017-12-17 05:15:16.915642: step 30070, loss = 0.09, batch loss = 0.06 (15.7 examples/sec; 0.509 sec/batch; 42h:43m:50s remains)
INFO - root - 2017-12-17 05:15:21.995248: step 30080, loss = 0.09, batch loss = 0.06 (16.5 examples/sec; 0.486 sec/batch; 40h:48m:03s remains)
INFO - root - 2017-12-17 05:15:27.122813: step 30090, loss = 0.10, batch loss = 0.07 (15.3 examples/sec; 0.522 sec/batch; 43h:51m:48s remains)
INFO - root - 2017-12-17 05:15:32.175501: step 30100, loss = 0.12, batch loss = 0.09 (16.3 examples/sec; 0.489 sec/batch; 41h:06m:45s remains)
INFO - root - 2017-12-17 05:15:37.478692: step 30110, loss = 0.10, batch loss = 0.07 (15.9 examples/sec; 0.502 sec/batch; 42h:11m:38s remains)
INFO - root - 2017-12-17 05:15:42.620725: step 30120, loss = 0.09, batch loss = 0.06 (15.0 examples/sec; 0.534 sec/batch; 44h:51m:26s remains)
INFO - root - 2017-12-17 05:15:47.764628: step 30130, loss = 0.09, batch loss = 0.05 (15.0 examples/sec; 0.533 sec/batch; 44h:43m:56s remains)
INFO - root - 2017-12-17 05:15:52.849640: step 30140, loss = 0.11, batch loss = 0.08 (15.4 examples/sec; 0.518 sec/batch; 43h:30m:27s remains)
INFO - root - 2017-12-17 05:15:57.842185: step 30150, loss = 0.13, batch loss = 0.10 (16.3 examples/sec; 0.490 sec/batch; 41h:09m:56s remains)
INFO - root - 2017-12-17 05:16:02.762446: step 30160, loss = 0.16, batch loss = 0.13 (16.5 examples/sec; 0.484 sec/batch; 40h:40m:29s remains)
INFO - root - 2017-12-17 05:16:07.100602: step 30170, loss = 0.09, batch loss = 0.05 (22.4 examples/sec; 0.357 sec/batch; 29h:59m:55s remains)
INFO - root - 2017-12-17 05:16:10.761218: step 30180, loss = 0.13, batch loss = 0.09 (21.4 examples/sec; 0.373 sec/batch; 31h:20m:19s remains)
INFO - root - 2017-12-17 05:16:14.587436: step 30190, loss = 0.13, batch loss = 0.10 (20.3 examples/sec; 0.394 sec/batch; 33h:04m:37s remains)
INFO - root - 2017-12-17 05:16:18.378386: step 30200, loss = 0.12, batch loss = 0.08 (21.1 examples/sec; 0.379 sec/batch; 31h:47m:24s remains)
INFO - root - 2017-12-17 05:16:22.365936: step 30210, loss = 0.13, batch loss = 0.10 (21.5 examples/sec; 0.372 sec/batch; 31h:16m:34s remains)
INFO - root - 2017-12-17 05:16:26.103740: step 30220, loss = 0.10, batch loss = 0.06 (20.5 examples/sec; 0.391 sec/batch; 32h:50m:21s remains)
INFO - root - 2017-12-17 05:16:29.886497: step 30230, loss = 0.10, batch loss = 0.07 (21.4 examples/sec; 0.373 sec/batch; 31h:20m:54s remains)
INFO - root - 2017-12-17 05:16:33.679066: step 30240, loss = 0.11, batch loss = 0.07 (21.5 examples/sec; 0.372 sec/batch; 31h:14m:23s remains)
INFO - root - 2017-12-17 05:16:37.395258: step 30250, loss = 0.11, batch loss = 0.07 (21.6 examples/sec; 0.370 sec/batch; 31h:02m:05s remains)
INFO - root - 2017-12-17 05:16:41.055350: step 30260, loss = 0.09, batch loss = 0.05 (21.6 examples/sec; 0.371 sec/batch; 31h:09m:50s remains)
INFO - root - 2017-12-17 05:16:44.767075: step 30270, loss = 0.10, batch loss = 0.07 (22.0 examples/sec; 0.363 sec/batch; 30h:30m:33s remains)
INFO - root - 2017-12-17 05:16:48.441730: step 30280, loss = 0.14, batch loss = 0.10 (21.3 examples/sec; 0.375 sec/batch; 31h:29m:01s remains)
INFO - root - 2017-12-17 05:16:52.139293: step 30290, loss = 0.09, batch loss = 0.06 (21.0 examples/sec; 0.381 sec/batch; 31h:58m:59s remains)
INFO - root - 2017-12-17 05:16:55.942359: step 30300, loss = 0.08, batch loss = 0.05 (21.7 examples/sec; 0.368 sec/batch; 30h:54m:30s remains)
INFO - root - 2017-12-17 05:16:59.866326: step 30310, loss = 0.11, batch loss = 0.07 (21.8 examples/sec; 0.367 sec/batch; 30h:48m:58s remains)
INFO - root - 2017-12-17 05:17:03.507443: step 30320, loss = 0.10, batch loss = 0.06 (23.7 examples/sec; 0.338 sec/batch; 28h:20m:51s remains)
INFO - root - 2017-12-17 05:17:07.268203: step 30330, loss = 0.11, batch loss = 0.08 (21.8 examples/sec; 0.367 sec/batch; 30h:45m:54s remains)
INFO - root - 2017-12-17 05:17:10.895815: step 30340, loss = 0.13, batch loss = 0.09 (22.0 examples/sec; 0.364 sec/batch; 30h:33m:14s remains)
INFO - root - 2017-12-17 05:17:14.529677: step 30350, loss = 0.13, batch loss = 0.09 (22.3 examples/sec; 0.359 sec/batch; 30h:06m:42s remains)
INFO - root - 2017-12-17 05:17:18.249600: step 30360, loss = 0.09, batch loss = 0.06 (22.3 examples/sec; 0.360 sec/batch; 30h:10m:34s remains)
INFO - root - 2017-12-17 05:17:21.922659: step 30370, loss = 0.09, batch loss = 0.06 (21.7 examples/sec; 0.369 sec/batch; 30h:56m:31s remains)
INFO - root - 2017-12-17 05:17:25.531050: step 30380, loss = 0.08, batch loss = 0.05 (21.6 examples/sec; 0.371 sec/batch; 31h:08m:40s remains)
INFO - root - 2017-12-17 05:17:29.142100: step 30390, loss = 0.16, batch loss = 0.12 (21.9 examples/sec; 0.365 sec/batch; 30h:39m:39s remains)
INFO - root - 2017-12-17 05:17:32.832074: step 30400, loss = 0.11, batch loss = 0.08 (21.3 examples/sec; 0.376 sec/batch; 31h:33m:50s remains)
INFO - root - 2017-12-17 05:17:36.761354: step 30410, loss = 0.09, batch loss = 0.05 (21.8 examples/sec; 0.367 sec/batch; 30h:46m:32s remains)
INFO - root - 2017-12-17 05:17:40.445511: step 30420, loss = 0.11, batch loss = 0.08 (21.1 examples/sec; 0.379 sec/batch; 31h:48m:24s remains)
INFO - root - 2017-12-17 05:17:44.137911: step 30430, loss = 0.09, batch loss = 0.06 (21.3 examples/sec; 0.376 sec/batch; 31h:34m:02s remains)
INFO - root - 2017-12-17 05:17:47.788154: step 30440, loss = 0.10, batch loss = 0.06 (21.9 examples/sec; 0.365 sec/batch; 30h:38m:22s remains)
INFO - root - 2017-12-17 05:17:51.444538: step 30450, loss = 0.11, batch loss = 0.08 (22.5 examples/sec; 0.356 sec/batch; 29h:49m:42s remains)
INFO - root - 2017-12-17 05:17:55.155711: step 30460, loss = 0.08, batch loss = 0.05 (21.1 examples/sec; 0.378 sec/batch; 31h:44m:58s remains)
INFO - root - 2017-12-17 05:17:58.921028: step 30470, loss = 0.09, batch loss = 0.06 (20.0 examples/sec; 0.401 sec/batch; 33h:38m:18s remains)
INFO - root - 2017-12-17 05:18:02.671763: step 30480, loss = 0.13, batch loss = 0.09 (21.2 examples/sec; 0.378 sec/batch; 31h:42m:12s remains)
INFO - root - 2017-12-17 05:18:06.344642: step 30490, loss = 0.09, batch loss = 0.06 (24.7 examples/sec; 0.323 sec/batch; 27h:07m:59s remains)
INFO - root - 2017-12-17 05:18:09.990948: step 30500, loss = 0.14, batch loss = 0.10 (21.9 examples/sec; 0.365 sec/batch; 30h:35m:35s remains)
INFO - root - 2017-12-17 05:18:13.902426: step 30510, loss = 0.12, batch loss = 0.09 (20.8 examples/sec; 0.385 sec/batch; 32h:19m:09s remains)
INFO - root - 2017-12-17 05:18:17.590684: step 30520, loss = 0.09, batch loss = 0.06 (21.5 examples/sec; 0.371 sec/batch; 31h:09m:37s remains)
INFO - root - 2017-12-17 05:18:21.280278: step 30530, loss = 0.12, batch loss = 0.09 (22.5 examples/sec; 0.355 sec/batch; 29h:47m:26s remains)
INFO - root - 2017-12-17 05:18:24.986008: step 30540, loss = 0.14, batch loss = 0.11 (21.4 examples/sec; 0.374 sec/batch; 31h:21m:26s remains)
INFO - root - 2017-12-17 05:18:28.752985: step 30550, loss = 0.10, batch loss = 0.07 (21.2 examples/sec; 0.378 sec/batch; 31h:40m:04s remains)
INFO - root - 2017-12-17 05:18:32.531385: step 30560, loss = 0.12, batch loss = 0.09 (21.9 examples/sec; 0.365 sec/batch; 30h:36m:10s remains)
INFO - root - 2017-12-17 05:18:36.244843: step 30570, loss = 0.17, batch loss = 0.13 (21.9 examples/sec; 0.365 sec/batch; 30h:37m:17s remains)
INFO - root - 2017-12-17 05:18:39.991240: step 30580, loss = 0.10, batch loss = 0.07 (21.3 examples/sec; 0.376 sec/batch; 31h:30m:35s remains)
INFO - root - 2017-12-17 05:18:43.744152: step 30590, loss = 0.09, batch loss = 0.05 (20.2 examples/sec; 0.396 sec/batch; 33h:12m:54s remains)
INFO - root - 2017-12-17 05:18:47.509656: step 30600, loss = 0.14, batch loss = 0.10 (21.4 examples/sec; 0.374 sec/batch; 31h:23m:43s remains)
INFO - root - 2017-12-17 05:18:51.393304: step 30610, loss = 0.11, batch loss = 0.07 (22.7 examples/sec; 0.352 sec/batch; 29h:33m:34s remains)
INFO - root - 2017-12-17 05:18:55.133740: step 30620, loss = 0.10, batch loss = 0.07 (21.9 examples/sec; 0.366 sec/batch; 30h:42m:04s remains)
INFO - root - 2017-12-17 05:18:58.827367: step 30630, loss = 0.09, batch loss = 0.06 (22.7 examples/sec; 0.352 sec/batch; 29h:31m:50s remains)
INFO - root - 2017-12-17 05:19:02.526858: step 30640, loss = 0.12, batch loss = 0.08 (21.2 examples/sec; 0.377 sec/batch; 31h:38m:13s remains)
INFO - root - 2017-12-17 05:19:06.153047: step 30650, loss = 0.11, batch loss = 0.08 (21.3 examples/sec; 0.376 sec/batch; 31h:29m:21s remains)
INFO - root - 2017-12-17 05:19:09.847148: step 30660, loss = 0.11, batch loss = 0.08 (21.9 examples/sec; 0.365 sec/batch; 30h:37m:27s remains)
INFO - root - 2017-12-17 05:19:13.565941: step 30670, loss = 0.13, batch loss = 0.10 (21.2 examples/sec; 0.378 sec/batch; 31h:41m:39s remains)
INFO - root - 2017-12-17 05:19:17.165680: step 30680, loss = 0.09, batch loss = 0.06 (21.9 examples/sec; 0.365 sec/batch; 30h:34m:50s remains)
INFO - root - 2017-12-17 05:19:20.451427: step 30690, loss = 0.12, batch loss = 0.09 (37.6 examples/sec; 0.213 sec/batch; 17h:50m:22s remains)
INFO - root - 2017-12-17 05:19:22.811800: step 30700, loss = 0.10, batch loss = 0.07 (36.6 examples/sec; 0.218 sec/batch; 18h:18m:59s remains)
INFO - root - 2017-12-17 05:19:25.171995: step 30710, loss = 0.11, batch loss = 0.08 (35.5 examples/sec; 0.225 sec/batch; 18h:52m:51s remains)
INFO - root - 2017-12-17 05:19:27.394735: step 30720, loss = 0.11, batch loss = 0.08 (34.5 examples/sec; 0.232 sec/batch; 19h:26m:23s remains)
INFO - root - 2017-12-17 05:19:29.664099: step 30730, loss = 0.11, batch loss = 0.08 (35.1 examples/sec; 0.228 sec/batch; 19h:05m:36s remains)
INFO - root - 2017-12-17 05:19:31.931137: step 30740, loss = 0.18, batch loss = 0.15 (37.4 examples/sec; 0.214 sec/batch; 17h:54m:55s remains)
INFO - root - 2017-12-17 05:19:34.182624: step 30750, loss = 0.10, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 18h:40m:12s remains)
INFO - root - 2017-12-17 05:19:36.378395: step 30760, loss = 0.11, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 18h:36m:02s remains)
INFO - root - 2017-12-17 05:19:38.622115: step 30770, loss = 0.09, batch loss = 0.05 (36.3 examples/sec; 0.220 sec/batch; 18h:28m:20s remains)
INFO - root - 2017-12-17 05:19:40.819783: step 30780, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 18h:48m:12s remains)
INFO - root - 2017-12-17 05:19:43.015996: step 30790, loss = 0.14, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 19h:22m:38s remains)
INFO - root - 2017-12-17 05:19:45.256626: step 30800, loss = 0.12, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 18h:24m:29s remains)
INFO - root - 2017-12-17 05:19:47.594753: step 30810, loss = 0.11, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 18h:36m:16s remains)
INFO - root - 2017-12-17 05:19:49.826138: step 30820, loss = 0.12, batch loss = 0.09 (36.7 examples/sec; 0.218 sec/batch; 18h:16m:05s remains)
INFO - root - 2017-12-17 05:19:52.066013: step 30830, loss = 0.12, batch loss = 0.08 (35.0 examples/sec; 0.229 sec/batch; 19h:09m:54s remains)
INFO - root - 2017-12-17 05:19:54.304620: step 30840, loss = 0.08, batch loss = 0.05 (36.7 examples/sec; 0.218 sec/batch; 18h:15m:54s remains)
INFO - root - 2017-12-17 05:19:56.543026: step 30850, loss = 0.11, batch loss = 0.08 (36.8 examples/sec; 0.218 sec/batch; 18h:13m:39s remains)
INFO - root - 2017-12-17 05:19:58.754844: step 30860, loss = 0.09, batch loss = 0.05 (36.5 examples/sec; 0.219 sec/batch; 18h:21m:11s remains)
INFO - root - 2017-12-17 05:20:00.986314: step 30870, loss = 0.11, batch loss = 0.08 (36.7 examples/sec; 0.218 sec/batch; 18h:15m:35s remains)
INFO - root - 2017-12-17 05:20:03.230428: step 30880, loss = 0.12, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 18h:38m:13s remains)
INFO - root - 2017-12-17 05:20:05.461876: step 30890, loss = 0.08, batch loss = 0.04 (36.1 examples/sec; 0.222 sec/batch; 18h:35m:25s remains)
INFO - root - 2017-12-17 05:20:07.700415: step 30900, loss = 0.15, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 19h:06m:53s remains)
INFO - root - 2017-12-17 05:20:10.060609: step 30910, loss = 0.15, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 19h:25m:12s remains)
INFO - root - 2017-12-17 05:20:12.270877: step 30920, loss = 0.12, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 18h:31m:34s remains)
INFO - root - 2017-12-17 05:20:14.507004: step 30930, loss = 0.10, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 18h:20m:27s remains)
INFO - root - 2017-12-17 05:20:16.748337: step 30940, loss = 0.11, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 18h:33m:20s remains)
INFO - root - 2017-12-17 05:20:18.968390: step 30950, loss = 0.09, batch loss = 0.06 (35.3 examples/sec; 0.227 sec/batch; 18h:59m:25s remains)
INFO - root - 2017-12-17 05:20:21.207948: step 30960, loss = 0.13, batch loss = 0.10 (35.3 examples/sec; 0.226 sec/batch; 18h:58m:06s remains)
INFO - root - 2017-12-17 05:20:23.481808: step 30970, loss = 0.15, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 18h:50m:43s remains)
INFO - root - 2017-12-17 05:20:25.718533: step 30980, loss = 0.09, batch loss = 0.06 (34.8 examples/sec; 0.230 sec/batch; 19h:15m:05s remains)
INFO - root - 2017-12-17 05:20:27.941117: step 30990, loss = 0.10, batch loss = 0.07 (35.0 examples/sec; 0.229 sec/batch; 19h:10m:14s remains)
INFO - root - 2017-12-17 05:20:30.179600: step 31000, loss = 0.10, batch loss = 0.07 (35.1 examples/sec; 0.228 sec/batch; 19h:04m:03s remains)
INFO - root - 2017-12-17 05:20:32.530396: step 31010, loss = 0.09, batch loss = 0.06 (37.0 examples/sec; 0.216 sec/batch; 18h:07m:45s remains)
INFO - root - 2017-12-17 05:20:34.736397: step 31020, loss = 0.14, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 18h:59m:44s remains)
INFO - root - 2017-12-17 05:20:37.019083: step 31030, loss = 0.10, batch loss = 0.07 (33.2 examples/sec; 0.241 sec/batch; 20h:09m:50s remains)
INFO - root - 2017-12-17 05:20:39.319107: step 31040, loss = 0.10, batch loss = 0.07 (34.7 examples/sec; 0.231 sec/batch; 19h:18m:42s remains)
INFO - root - 2017-12-17 05:20:41.566678: step 31050, loss = 0.14, batch loss = 0.11 (37.1 examples/sec; 0.216 sec/batch; 18h:03m:05s remains)
INFO - root - 2017-12-17 05:20:43.831501: step 31060, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 18h:43m:50s remains)
INFO - root - 2017-12-17 05:20:46.086963: step 31070, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.221 sec/batch; 18h:28m:05s remains)
INFO - root - 2017-12-17 05:20:48.265477: step 31080, loss = 0.12, batch loss = 0.09 (36.8 examples/sec; 0.217 sec/batch; 18h:10m:37s remains)
INFO - root - 2017-12-17 05:20:50.504485: step 31090, loss = 0.09, batch loss = 0.06 (35.1 examples/sec; 0.228 sec/batch; 19h:05m:02s remains)
INFO - root - 2017-12-17 05:20:52.734484: step 31100, loss = 0.13, batch loss = 0.10 (36.6 examples/sec; 0.218 sec/batch; 18h:17m:08s remains)
INFO - root - 2017-12-17 05:20:55.064834: step 31110, loss = 0.11, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 18h:18m:39s remains)
INFO - root - 2017-12-17 05:20:57.294221: step 31120, loss = 0.11, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 18h:36m:41s remains)
INFO - root - 2017-12-17 05:20:59.502770: step 31130, loss = 0.12, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 18h:24m:54s remains)
INFO - root - 2017-12-17 05:21:01.697262: step 31140, loss = 0.09, batch loss = 0.06 (36.8 examples/sec; 0.217 sec/batch; 18h:10m:44s remains)
INFO - root - 2017-12-17 05:21:03.924132: step 31150, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.223 sec/batch; 18h:42m:18s remains)
INFO - root - 2017-12-17 05:21:06.148613: step 31160, loss = 0.13, batch loss = 0.09 (35.8 examples/sec; 0.223 sec/batch; 18h:42m:06s remains)
INFO - root - 2017-12-17 05:21:08.441903: step 31170, loss = 0.12, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 18h:35m:26s remains)
INFO - root - 2017-12-17 05:21:10.666686: step 31180, loss = 0.10, batch loss = 0.06 (36.1 examples/sec; 0.221 sec/batch; 18h:31m:55s remains)
INFO - root - 2017-12-17 05:21:12.893897: step 31190, loss = 0.08, batch loss = 0.05 (36.7 examples/sec; 0.218 sec/batch; 18h:13m:31s remains)
INFO - root - 2017-12-17 05:21:15.080469: step 31200, loss = 0.10, batch loss = 0.07 (37.0 examples/sec; 0.216 sec/batch; 18h:06m:25s remains)
INFO - root - 2017-12-17 05:21:17.418122: step 31210, loss = 0.09, batch loss = 0.06 (37.0 examples/sec; 0.216 sec/batch; 18h:06m:17s remains)
INFO - root - 2017-12-17 05:21:19.651763: step 31220, loss = 0.12, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 18h:22m:31s remains)
INFO - root - 2017-12-17 05:21:21.913477: step 31230, loss = 0.12, batch loss = 0.09 (35.2 examples/sec; 0.227 sec/batch; 19h:02m:16s remains)
INFO - root - 2017-12-17 05:21:24.181943: step 31240, loss = 0.12, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 18h:54m:57s remains)
INFO - root - 2017-12-17 05:21:26.425422: step 31250, loss = 0.09, batch loss = 0.06 (35.5 examples/sec; 0.225 sec/batch; 18h:51m:15s remains)
INFO - root - 2017-12-17 05:21:28.663437: step 31260, loss = 0.13, batch loss = 0.10 (36.9 examples/sec; 0.217 sec/batch; 18h:09m:57s remains)
INFO - root - 2017-12-17 05:21:30.927129: step 31270, loss = 0.12, batch loss = 0.09 (34.4 examples/sec; 0.232 sec/batch; 19h:26m:41s remains)
INFO - root - 2017-12-17 05:21:33.181412: step 31280, loss = 0.09, batch loss = 0.05 (36.5 examples/sec; 0.219 sec/batch; 18h:18m:53s remains)
INFO - root - 2017-12-17 05:21:35.417637: step 31290, loss = 0.09, batch loss = 0.05 (36.4 examples/sec; 0.220 sec/batch; 18h:24m:21s remains)
INFO - root - 2017-12-17 05:21:37.797092: step 31300, loss = 0.11, batch loss = 0.07 (37.1 examples/sec; 0.216 sec/batch; 18h:02m:09s remains)
INFO - root - 2017-12-17 05:21:40.202438: step 31310, loss = 0.08, batch loss = 0.05 (35.5 examples/sec; 0.225 sec/batch; 18h:50m:23s remains)
INFO - root - 2017-12-17 05:21:42.466213: step 31320, loss = 0.09, batch loss = 0.06 (35.5 examples/sec; 0.225 sec/batch; 18h:49m:39s remains)
INFO - root - 2017-12-17 05:21:44.697385: step 31330, loss = 0.11, batch loss = 0.07 (33.5 examples/sec; 0.239 sec/batch; 19h:58m:52s remains)
INFO - root - 2017-12-17 05:21:46.918092: step 31340, loss = 0.14, batch loss = 0.10 (37.0 examples/sec; 0.216 sec/batch; 18h:04m:56s remains)
INFO - root - 2017-12-17 05:21:49.130622: step 31350, loss = 0.11, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 18h:21m:21s remains)
INFO - root - 2017-12-17 05:21:51.327354: step 31360, loss = 0.09, batch loss = 0.06 (36.6 examples/sec; 0.219 sec/batch; 18h:18m:19s remains)
INFO - root - 2017-12-17 05:21:53.601410: step 31370, loss = 0.10, batch loss = 0.07 (34.4 examples/sec; 0.233 sec/batch; 19h:27m:13s remains)
INFO - root - 2017-12-17 05:21:55.844284: step 31380, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 18h:24m:59s remains)
INFO - root - 2017-12-17 05:21:58.102347: step 31390, loss = 0.10, batch loss = 0.06 (35.4 examples/sec; 0.226 sec/batch; 18h:54m:27s remains)
INFO - root - 2017-12-17 05:22:00.293888: step 31400, loss = 0.14, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 18h:47m:19s remains)
INFO - root - 2017-12-17 05:22:02.672206: step 31410, loss = 0.09, batch loss = 0.05 (34.6 examples/sec; 0.231 sec/batch; 19h:21m:17s remains)
INFO - root - 2017-12-17 05:22:04.923786: step 31420, loss = 0.13, batch loss = 0.09 (34.9 examples/sec; 0.229 sec/batch; 19h:10m:11s remains)
INFO - root - 2017-12-17 05:22:07.165058: step 31430, loss = 0.08, batch loss = 0.05 (36.6 examples/sec; 0.219 sec/batch; 18h:16m:43s remains)
INFO - root - 2017-12-17 05:22:09.373575: step 31440, loss = 0.10, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 18h:18m:18s remains)
INFO - root - 2017-12-17 05:22:11.608404: step 31450, loss = 0.10, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 18h:42m:53s remains)
INFO - root - 2017-12-17 05:22:13.866974: step 31460, loss = 0.10, batch loss = 0.07 (34.7 examples/sec; 0.231 sec/batch; 19h:16m:52s remains)
INFO - root - 2017-12-17 05:22:16.113918: step 31470, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 18h:24m:49s remains)
INFO - root - 2017-12-17 05:22:18.342762: step 31480, loss = 0.11, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 18h:17m:09s remains)
INFO - root - 2017-12-17 05:22:20.572745: step 31490, loss = 0.09, batch loss = 0.06 (36.8 examples/sec; 0.218 sec/batch; 18h:11m:28s remains)
INFO - root - 2017-12-17 05:22:22.794539: step 31500, loss = 0.10, batch loss = 0.06 (35.6 examples/sec; 0.225 sec/batch; 18h:46m:25s remains)
INFO - root - 2017-12-17 05:22:25.166756: step 31510, loss = 0.10, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 18h:28m:33s remains)
INFO - root - 2017-12-17 05:22:27.399761: step 31520, loss = 0.11, batch loss = 0.08 (37.9 examples/sec; 0.211 sec/batch; 17h:38m:39s remains)
INFO - root - 2017-12-17 05:22:29.591869: step 31530, loss = 0.10, batch loss = 0.07 (34.9 examples/sec; 0.229 sec/batch; 19h:10m:38s remains)
INFO - root - 2017-12-17 05:22:31.791470: step 31540, loss = 0.09, batch loss = 0.06 (35.0 examples/sec; 0.228 sec/batch; 19h:06m:09s remains)
INFO - root - 2017-12-17 05:22:34.005907: step 31550, loss = 0.09, batch loss = 0.05 (35.5 examples/sec; 0.225 sec/batch; 18h:49m:55s remains)
INFO - root - 2017-12-17 05:22:36.221005: step 31560, loss = 0.12, batch loss = 0.08 (35.8 examples/sec; 0.224 sec/batch; 18h:41m:34s remains)
INFO - root - 2017-12-17 05:22:38.475527: step 31570, loss = 0.13, batch loss = 0.09 (34.9 examples/sec; 0.229 sec/batch; 19h:09m:00s remains)
INFO - root - 2017-12-17 05:22:40.690887: step 31580, loss = 0.11, batch loss = 0.07 (37.1 examples/sec; 0.215 sec/batch; 18h:00m:38s remains)
INFO - root - 2017-12-17 05:22:42.897699: step 31590, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 18h:24m:41s remains)
INFO - root - 2017-12-17 05:22:45.155160: step 31600, loss = 0.11, batch loss = 0.07 (34.9 examples/sec; 0.229 sec/batch; 19h:09m:47s remains)
INFO - root - 2017-12-17 05:22:47.524746: step 31610, loss = 0.12, batch loss = 0.08 (36.3 examples/sec; 0.220 sec/batch; 18h:24m:36s remains)
INFO - root - 2017-12-17 05:22:49.742309: step 31620, loss = 0.09, batch loss = 0.06 (36.6 examples/sec; 0.218 sec/batch; 18h:14m:44s remains)
INFO - root - 2017-12-17 05:22:51.952010: step 31630, loss = 0.12, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 18h:42m:24s remains)
INFO - root - 2017-12-17 05:22:54.163981: step 31640, loss = 0.09, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 18h:22m:56s remains)
INFO - root - 2017-12-17 05:22:56.380059: step 31650, loss = 0.11, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 18h:16m:28s remains)
INFO - root - 2017-12-17 05:22:58.600450: step 31660, loss = 0.09, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 18h:22m:01s remains)
INFO - root - 2017-12-17 05:23:00.788551: step 31670, loss = 0.09, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 18h:13m:46s remains)
INFO - root - 2017-12-17 05:23:02.985531: step 31680, loss = 0.12, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 18h:43m:20s remains)
INFO - root - 2017-12-17 05:23:05.206122: step 31690, loss = 0.13, batch loss = 0.09 (36.9 examples/sec; 0.217 sec/batch; 18h:08m:15s remains)
INFO - root - 2017-12-17 05:23:07.412995: step 31700, loss = 0.10, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 18h:18m:31s remains)
INFO - root - 2017-12-17 05:23:09.841757: step 31710, loss = 0.12, batch loss = 0.09 (34.3 examples/sec; 0.233 sec/batch; 19h:29m:16s remains)
INFO - root - 2017-12-17 05:23:12.067939: step 31720, loss = 0.11, batch loss = 0.08 (34.8 examples/sec; 0.230 sec/batch; 19h:12m:42s remains)
INFO - root - 2017-12-17 05:23:14.312290: step 31730, loss = 0.12, batch loss = 0.08 (36.6 examples/sec; 0.218 sec/batch; 18h:14m:48s remains)
INFO - root - 2017-12-17 05:23:16.492723: step 31740, loss = 0.11, batch loss = 0.08 (37.6 examples/sec; 0.213 sec/batch; 17h:45m:42s remains)
INFO - root - 2017-12-17 05:23:18.677413: step 31750, loss = 0.14, batch loss = 0.11 (35.2 examples/sec; 0.227 sec/batch; 18h:58m:37s remains)
INFO - root - 2017-12-17 05:23:20.907675: step 31760, loss = 0.10, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 18h:41m:51s remains)
INFO - root - 2017-12-17 05:23:23.132959: step 31770, loss = 0.12, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 18h:42m:15s remains)
INFO - root - 2017-12-17 05:23:25.382707: step 31780, loss = 0.09, batch loss = 0.06 (34.7 examples/sec; 0.230 sec/batch; 19h:15m:03s remains)
INFO - root - 2017-12-17 05:23:27.607032: step 31790, loss = 0.12, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 18h:17m:54s remains)
INFO - root - 2017-12-17 05:23:29.845806: step 31800, loss = 0.09, batch loss = 0.05 (37.5 examples/sec; 0.213 sec/batch; 17h:48m:10s remains)
INFO - root - 2017-12-17 05:23:32.157616: step 31810, loss = 0.12, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 18h:22m:56s remains)
INFO - root - 2017-12-17 05:23:34.356795: step 31820, loss = 0.12, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 18h:51m:22s remains)
INFO - root - 2017-12-17 05:23:36.579979: step 31830, loss = 0.13, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 18h:20m:35s remains)
INFO - root - 2017-12-17 05:23:38.772825: step 31840, loss = 0.15, batch loss = 0.11 (36.6 examples/sec; 0.219 sec/batch; 18h:15m:14s remains)
INFO - root - 2017-12-17 05:23:40.990874: step 31850, loss = 0.12, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 18h:36m:04s remains)
INFO - root - 2017-12-17 05:23:43.215334: step 31860, loss = 0.15, batch loss = 0.11 (34.7 examples/sec; 0.230 sec/batch; 19h:14m:29s remains)
INFO - root - 2017-12-17 05:23:45.440178: step 31870, loss = 0.08, batch loss = 0.05 (36.8 examples/sec; 0.217 sec/batch; 18h:08m:17s remains)
INFO - root - 2017-12-17 05:23:47.634637: step 31880, loss = 0.09, batch loss = 0.06 (35.5 examples/sec; 0.225 sec/batch; 18h:48m:28s remains)
INFO - root - 2017-12-17 05:23:49.865509: step 31890, loss = 0.15, batch loss = 0.11 (36.8 examples/sec; 0.217 sec/batch; 18h:08m:27s remains)
INFO - root - 2017-12-17 05:23:52.102637: step 31900, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 18h:32m:53s remains)
INFO - root - 2017-12-17 05:23:54.461451: step 31910, loss = 0.09, batch loss = 0.06 (37.3 examples/sec; 0.214 sec/batch; 17h:53m:25s remains)
INFO - root - 2017-12-17 05:23:56.651741: step 31920, loss = 0.10, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 18h:28m:26s remains)
INFO - root - 2017-12-17 05:23:58.882527: step 31930, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 18h:32m:30s remains)
INFO - root - 2017-12-17 05:24:01.067897: step 31940, loss = 0.09, batch loss = 0.05 (36.6 examples/sec; 0.218 sec/batch; 18h:14m:08s remains)
INFO - root - 2017-12-17 05:24:03.261744: step 31950, loss = 0.13, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 18h:18m:57s remains)
INFO - root - 2017-12-17 05:24:05.512677: step 31960, loss = 0.11, batch loss = 0.08 (35.5 examples/sec; 0.225 sec/batch; 18h:48m:10s remains)
INFO - root - 2017-12-17 05:24:07.728343: step 31970, loss = 0.13, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 18h:26m:47s remains)
INFO - root - 2017-12-17 05:24:09.961714: step 31980, loss = 0.12, batch loss = 0.08 (35.8 examples/sec; 0.223 sec/batch; 18h:38m:20s remains)
INFO - root - 2017-12-17 05:24:12.215786: step 31990, loss = 0.11, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 18h:36m:33s remains)
INFO - root - 2017-12-17 05:24:14.432139: step 32000, loss = 0.09, batch loss = 0.06 (37.2 examples/sec; 0.215 sec/batch; 17h:57m:29s remains)
INFO - root - 2017-12-17 05:24:16.773219: step 32010, loss = 0.10, batch loss = 0.06 (37.3 examples/sec; 0.214 sec/batch; 17h:53m:40s remains)
INFO - root - 2017-12-17 05:24:19.044241: step 32020, loss = 0.09, batch loss = 0.05 (34.6 examples/sec; 0.231 sec/batch; 19h:16m:47s remains)
INFO - root - 2017-12-17 05:24:21.271782: step 32030, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 18h:29m:20s remains)
INFO - root - 2017-12-17 05:24:23.468128: step 32040, loss = 0.11, batch loss = 0.08 (36.8 examples/sec; 0.217 sec/batch; 18h:07m:24s remains)
INFO - root - 2017-12-17 05:24:25.692487: step 32050, loss = 0.18, batch loss = 0.15 (36.7 examples/sec; 0.218 sec/batch; 18h:12m:21s remains)
INFO - root - 2017-12-17 05:24:27.909168: step 32060, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:25m:15s remains)
INFO - root - 2017-12-17 05:24:30.138076: step 32070, loss = 0.14, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 18h:46m:25s remains)
INFO - root - 2017-12-17 05:24:32.358140: step 32080, loss = 0.15, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:31m:34s remains)
INFO - root - 2017-12-17 05:24:34.622565: step 32090, loss = 0.13, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 18h:44m:02s remains)
INFO - root - 2017-12-17 05:24:36.851296: step 32100, loss = 0.11, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 18h:31m:46s remains)
INFO - root - 2017-12-17 05:24:39.211096: step 32110, loss = 0.16, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:33m:22s remains)
INFO - root - 2017-12-17 05:24:41.430851: step 32120, loss = 0.09, batch loss = 0.06 (36.8 examples/sec; 0.217 sec/batch; 18h:08m:30s remains)
INFO - root - 2017-12-17 05:24:43.601713: step 32130, loss = 0.09, batch loss = 0.05 (38.1 examples/sec; 0.210 sec/batch; 17h:30m:44s remains)
INFO - root - 2017-12-17 05:24:45.809560: step 32140, loss = 0.09, batch loss = 0.06 (36.6 examples/sec; 0.218 sec/batch; 18h:13m:19s remains)
INFO - root - 2017-12-17 05:24:47.987855: step 32150, loss = 0.10, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 18h:11m:27s remains)
INFO - root - 2017-12-17 05:24:50.185714: step 32160, loss = 0.13, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 19h:09m:48s remains)
INFO - root - 2017-12-17 05:24:52.420337: step 32170, loss = 0.10, batch loss = 0.07 (34.2 examples/sec; 0.234 sec/batch; 19h:31m:18s remains)
INFO - root - 2017-12-17 05:24:54.660452: step 32180, loss = 0.16, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 18h:56m:52s remains)
INFO - root - 2017-12-17 05:24:56.875910: step 32190, loss = 0.09, batch loss = 0.05 (35.7 examples/sec; 0.224 sec/batch; 18h:40m:12s remains)
INFO - root - 2017-12-17 05:24:59.113404: step 32200, loss = 0.11, batch loss = 0.08 (35.5 examples/sec; 0.225 sec/batch; 18h:47m:31s remains)
INFO - root - 2017-12-17 05:25:01.451735: step 32210, loss = 0.09, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 18h:31m:26s remains)
INFO - root - 2017-12-17 05:25:03.677338: step 32220, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 18h:39m:57s remains)
INFO - root - 2017-12-17 05:25:05.876049: step 32230, loss = 0.11, batch loss = 0.08 (37.2 examples/sec; 0.215 sec/batch; 17h:54m:51s remains)
INFO - root - 2017-12-17 05:25:08.106329: step 32240, loss = 0.12, batch loss = 0.08 (34.9 examples/sec; 0.229 sec/batch; 19h:08m:12s remains)
INFO - root - 2017-12-17 05:25:10.355108: step 32250, loss = 0.13, batch loss = 0.09 (36.9 examples/sec; 0.217 sec/batch; 18h:04m:16s remains)
INFO - root - 2017-12-17 05:25:12.555239: step 32260, loss = 0.09, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 18h:19m:42s remains)
INFO - root - 2017-12-17 05:25:14.768690: step 32270, loss = 0.09, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 18h:09m:56s remains)
INFO - root - 2017-12-17 05:25:16.997043: step 32280, loss = 0.09, batch loss = 0.06 (35.3 examples/sec; 0.226 sec/batch; 18h:52m:55s remains)
INFO - root - 2017-12-17 05:25:19.186893: step 32290, loss = 0.11, batch loss = 0.07 (36.6 examples/sec; 0.218 sec/batch; 18h:12m:21s remains)
INFO - root - 2017-12-17 05:25:21.384733: step 32300, loss = 0.12, batch loss = 0.08 (36.3 examples/sec; 0.220 sec/batch; 18h:21m:39s remains)
INFO - root - 2017-12-17 05:25:23.700575: step 32310, loss = 0.10, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 18h:14m:37s remains)
INFO - root - 2017-12-17 05:25:25.935367: step 32320, loss = 0.14, batch loss = 0.10 (35.0 examples/sec; 0.229 sec/batch; 19h:04m:10s remains)
INFO - root - 2017-12-17 05:25:28.171891: step 32330, loss = 0.09, batch loss = 0.06 (37.4 examples/sec; 0.214 sec/batch; 17h:51m:18s remains)
INFO - root - 2017-12-17 05:25:30.406181: step 32340, loss = 0.10, batch loss = 0.06 (37.0 examples/sec; 0.216 sec/batch; 18h:00m:45s remains)
INFO - root - 2017-12-17 05:25:32.609097: step 32350, loss = 0.12, batch loss = 0.09 (35.3 examples/sec; 0.227 sec/batch; 18h:54m:40s remains)
INFO - root - 2017-12-17 05:25:34.830731: step 32360, loss = 0.12, batch loss = 0.09 (36.1 examples/sec; 0.222 sec/batch; 18h:29m:37s remains)
INFO - root - 2017-12-17 05:25:37.060092: step 32370, loss = 0.10, batch loss = 0.06 (35.1 examples/sec; 0.228 sec/batch; 19h:00m:48s remains)
INFO - root - 2017-12-17 05:25:39.290859: step 32380, loss = 0.11, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 18h:21m:22s remains)
INFO - root - 2017-12-17 05:25:41.484460: step 32390, loss = 0.12, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 18h:19m:08s remains)
INFO - root - 2017-12-17 05:25:43.741660: step 32400, loss = 0.11, batch loss = 0.08 (34.6 examples/sec; 0.231 sec/batch; 19h:15m:07s remains)
INFO - root - 2017-12-17 05:25:46.113669: step 32410, loss = 0.11, batch loss = 0.08 (37.2 examples/sec; 0.215 sec/batch; 17h:57m:00s remains)
INFO - root - 2017-12-17 05:25:48.330395: step 32420, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.221 sec/batch; 18h:27m:04s remains)
INFO - root - 2017-12-17 05:25:50.544991: step 32430, loss = 0.10, batch loss = 0.06 (35.5 examples/sec; 0.225 sec/batch; 18h:46m:15s remains)
INFO - root - 2017-12-17 05:25:52.762054: step 32440, loss = 0.16, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 19h:20m:38s remains)
INFO - root - 2017-12-17 05:25:54.984069: step 32450, loss = 0.12, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 18h:39m:44s remains)
INFO - root - 2017-12-17 05:25:57.219938: step 32460, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 18h:30m:18s remains)
INFO - root - 2017-12-17 05:25:59.477321: step 32470, loss = 0.11, batch loss = 0.07 (34.9 examples/sec; 0.229 sec/batch; 19h:07m:18s remains)
INFO - root - 2017-12-17 05:26:01.721000: step 32480, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:43m:35s remains)
INFO - root - 2017-12-17 05:26:03.910144: step 32490, loss = 0.17, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 18h:21m:03s remains)
INFO - root - 2017-12-17 05:26:06.115222: step 32500, loss = 0.10, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 18h:13m:27s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-32500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-32500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 05:26:09.012774: step 32510, loss = 0.12, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 18h:33m:42s remains)
INFO - root - 2017-12-17 05:26:11.232950: step 32520, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 18h:55m:25s remains)
INFO - root - 2017-12-17 05:26:13.430546: step 32530, loss = 0.10, batch loss = 0.06 (37.5 examples/sec; 0.214 sec/batch; 17h:47m:28s remains)
INFO - root - 2017-12-17 05:26:15.639033: step 32540, loss = 0.09, batch loss = 0.06 (35.6 examples/sec; 0.225 sec/batch; 18h:42m:42s remains)
INFO - root - 2017-12-17 05:26:17.858627: step 32550, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:24m:54s remains)
INFO - root - 2017-12-17 05:26:20.096945: step 32560, loss = 0.10, batch loss = 0.06 (35.4 examples/sec; 0.226 sec/batch; 18h:49m:25s remains)
INFO - root - 2017-12-17 05:26:22.294741: step 32570, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 18h:27m:47s remains)
INFO - root - 2017-12-17 05:26:24.536355: step 32580, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:42m:36s remains)
INFO - root - 2017-12-17 05:26:26.758810: step 32590, loss = 0.08, batch loss = 0.05 (36.5 examples/sec; 0.219 sec/batch; 18h:16m:03s remains)
INFO - root - 2017-12-17 05:26:28.966001: step 32600, loss = 0.11, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:43m:30s remains)
INFO - root - 2017-12-17 05:26:31.297786: step 32610, loss = 0.09, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 18h:35m:18s remains)
INFO - root - 2017-12-17 05:26:33.511886: step 32620, loss = 0.13, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 18h:43m:32s remains)
INFO - root - 2017-12-17 05:26:35.746279: step 32630, loss = 0.08, batch loss = 0.05 (35.2 examples/sec; 0.227 sec/batch; 18h:56m:20s remains)
INFO - root - 2017-12-17 05:26:37.985095: step 32640, loss = 0.08, batch loss = 0.05 (34.9 examples/sec; 0.229 sec/batch; 19h:06m:48s remains)
INFO - root - 2017-12-17 05:26:40.201427: step 32650, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:24m:13s remains)
INFO - root - 2017-12-17 05:26:42.452463: step 32660, loss = 0.12, batch loss = 0.09 (34.6 examples/sec; 0.231 sec/batch; 19h:14m:37s remains)
INFO - root - 2017-12-17 05:26:44.653211: step 32670, loss = 0.12, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 18h:40m:44s remains)
INFO - root - 2017-12-17 05:26:46.885559: step 32680, loss = 0.11, batch loss = 0.08 (34.4 examples/sec; 0.233 sec/batch; 19h:22m:57s remains)
INFO - root - 2017-12-17 05:26:49.094367: step 32690, loss = 0.09, batch loss = 0.06 (36.6 examples/sec; 0.219 sec/batch; 18h:13m:03s remains)
INFO - root - 2017-12-17 05:26:51.322859: step 32700, loss = 0.10, batch loss = 0.07 (34.9 examples/sec; 0.230 sec/batch; 19h:06m:58s remains)
INFO - root - 2017-12-17 05:26:53.683969: step 32710, loss = 0.10, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 18h:18m:21s remains)
INFO - root - 2017-12-17 05:26:55.873972: step 32720, loss = 0.12, batch loss = 0.09 (36.3 examples/sec; 0.220 sec/batch; 18h:20m:49s remains)
INFO - root - 2017-12-17 05:26:58.095852: step 32730, loss = 0.11, batch loss = 0.08 (36.8 examples/sec; 0.218 sec/batch; 18h:06m:48s remains)
INFO - root - 2017-12-17 05:27:00.308685: step 32740, loss = 0.09, batch loss = 0.06 (35.2 examples/sec; 0.227 sec/batch; 18h:55m:27s remains)
INFO - root - 2017-12-17 05:27:02.546228: step 32750, loss = 0.10, batch loss = 0.06 (35.6 examples/sec; 0.225 sec/batch; 18h:42m:12s remains)
INFO - root - 2017-12-17 05:27:04.770397: step 32760, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:23m:59s remains)
INFO - root - 2017-12-17 05:27:06.977420: step 32770, loss = 0.15, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:29m:31s remains)
INFO - root - 2017-12-17 05:27:09.177786: step 32780, loss = 0.11, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 18h:14m:40s remains)
INFO - root - 2017-12-17 05:27:11.381575: step 32790, loss = 0.11, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 18h:11m:48s remains)
INFO - root - 2017-12-17 05:27:13.678313: step 32800, loss = 0.10, batch loss = 0.06 (35.3 examples/sec; 0.227 sec/batch; 18h:51m:49s remains)
INFO - root - 2017-12-17 05:27:16.061531: step 32810, loss = 0.10, batch loss = 0.07 (34.2 examples/sec; 0.234 sec/batch; 19h:29m:04s remains)
INFO - root - 2017-12-17 05:27:18.326768: step 32820, loss = 0.08, batch loss = 0.05 (35.4 examples/sec; 0.226 sec/batch; 18h:47m:54s remains)
INFO - root - 2017-12-17 05:27:20.539242: step 32830, loss = 0.11, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 18h:33m:16s remains)
INFO - root - 2017-12-17 05:27:22.767655: step 32840, loss = 0.09, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 18h:24m:58s remains)
INFO - root - 2017-12-17 05:27:24.975151: step 32850, loss = 0.13, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 19h:09m:36s remains)
INFO - root - 2017-12-17 05:27:27.201695: step 32860, loss = 0.15, batch loss = 0.11 (36.6 examples/sec; 0.218 sec/batch; 18h:11m:08s remains)
INFO - root - 2017-12-17 05:27:29.453245: step 32870, loss = 0.15, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 18h:52m:30s remains)
INFO - root - 2017-12-17 05:27:31.635206: step 32880, loss = 0.10, batch loss = 0.07 (36.8 examples/sec; 0.217 sec/batch; 18h:06m:00s remains)
INFO - root - 2017-12-17 05:27:33.849987: step 32890, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:42m:07s remains)
INFO - root - 2017-12-17 05:27:36.076270: step 32900, loss = 0.16, batch loss = 0.12 (37.1 examples/sec; 0.216 sec/batch; 17h:57m:14s remains)
INFO - root - 2017-12-17 05:27:38.426885: step 32910, loss = 0.09, batch loss = 0.06 (35.4 examples/sec; 0.226 sec/batch; 18h:48m:27s remains)
INFO - root - 2017-12-17 05:27:40.681934: step 32920, loss = 0.13, batch loss = 0.10 (36.0 examples/sec; 0.223 sec/batch; 18h:30m:58s remains)
INFO - root - 2017-12-17 05:27:42.919106: step 32930, loss = 0.11, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 18h:23m:41s remains)
INFO - root - 2017-12-17 05:27:45.140999: step 32940, loss = 0.22, batch loss = 0.19 (37.1 examples/sec; 0.216 sec/batch; 17h:57m:43s remains)
INFO - root - 2017-12-17 05:27:47.405559: step 32950, loss = 0.12, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 18h:37m:56s remains)
INFO - root - 2017-12-17 05:27:49.638480: step 32960, loss = 0.12, batch loss = 0.09 (35.8 examples/sec; 0.223 sec/batch; 18h:34m:51s remains)
INFO - root - 2017-12-17 05:27:51.849768: step 32970, loss = 0.09, batch loss = 0.05 (36.6 examples/sec; 0.218 sec/batch; 18h:10m:16s remains)
INFO - root - 2017-12-17 05:27:54.060249: step 32980, loss = 0.10, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 18h:31m:29s remains)
INFO - root - 2017-12-17 05:27:56.300291: step 32990, loss = 0.13, batch loss = 0.10 (36.9 examples/sec; 0.217 sec/batch; 18h:01m:29s remains)
INFO - root - 2017-12-17 05:27:58.528302: step 33000, loss = 0.13, batch loss = 0.09 (35.3 examples/sec; 0.227 sec/batch; 18h:51m:24s remains)
INFO - root - 2017-12-17 05:28:00.877425: step 33010, loss = 0.10, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 18h:15m:49s remains)
INFO - root - 2017-12-17 05:28:03.184420: step 33020, loss = 0.12, batch loss = 0.08 (33.7 examples/sec; 0.237 sec/batch; 19h:44m:17s remains)
INFO - root - 2017-12-17 05:28:05.404793: step 33030, loss = 0.10, batch loss = 0.06 (36.6 examples/sec; 0.219 sec/batch; 18h:11m:38s remains)
INFO - root - 2017-12-17 05:28:07.613400: step 33040, loss = 0.14, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 18h:14m:30s remains)
INFO - root - 2017-12-17 05:28:09.808258: step 33050, loss = 0.09, batch loss = 0.06 (37.3 examples/sec; 0.215 sec/batch; 17h:51m:49s remains)
INFO - root - 2017-12-17 05:28:12.007426: step 33060, loss = 0.09, batch loss = 0.05 (35.5 examples/sec; 0.225 sec/batch; 18h:43m:34s remains)
INFO - root - 2017-12-17 05:28:14.232956: step 33070, loss = 0.11, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 18h:28m:09s remains)
INFO - root - 2017-12-17 05:28:16.457836: step 33080, loss = 0.13, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 18h:51m:57s remains)
INFO - root - 2017-12-17 05:28:18.655207: step 33090, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 18h:38m:33s remains)
INFO - root - 2017-12-17 05:28:20.882572: step 33100, loss = 0.10, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 18h:26m:22s remains)
INFO - root - 2017-12-17 05:28:23.231004: step 33110, loss = 0.09, batch loss = 0.06 (35.2 examples/sec; 0.227 sec/batch; 18h:52m:55s remains)
INFO - root - 2017-12-17 05:28:25.474922: step 33120, loss = 0.09, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 18h:15m:53s remains)
INFO - root - 2017-12-17 05:28:27.700150: step 33130, loss = 0.14, batch loss = 0.11 (37.0 examples/sec; 0.216 sec/batch; 17h:57m:46s remains)
INFO - root - 2017-12-17 05:28:29.931347: step 33140, loss = 0.12, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 18h:40m:44s remains)
INFO - root - 2017-12-17 05:28:32.229297: step 33150, loss = 0.12, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 18h:21m:12s remains)
INFO - root - 2017-12-17 05:28:34.435139: step 33160, loss = 0.09, batch loss = 0.05 (34.9 examples/sec; 0.229 sec/batch; 19h:02m:36s remains)
INFO - root - 2017-12-17 05:28:36.624794: step 33170, loss = 0.09, batch loss = 0.06 (36.8 examples/sec; 0.217 sec/batch; 18h:03m:15s remains)
INFO - root - 2017-12-17 05:28:38.862326: step 33180, loss = 0.13, batch loss = 0.09 (36.1 examples/sec; 0.221 sec/batch; 18h:24m:09s remains)
INFO - root - 2017-12-17 05:28:41.104946: step 33190, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.224 sec/batch; 18h:36m:06s remains)
INFO - root - 2017-12-17 05:28:43.301604: step 33200, loss = 0.08, batch loss = 0.05 (36.9 examples/sec; 0.217 sec/batch; 18h:02m:33s remains)
INFO - root - 2017-12-17 05:28:45.632295: step 33210, loss = 0.11, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 18h:25m:11s remains)
INFO - root - 2017-12-17 05:28:47.877228: step 33220, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:16m:13s remains)
INFO - root - 2017-12-17 05:28:50.099406: step 33230, loss = 0.11, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 18h:32m:37s remains)
INFO - root - 2017-12-17 05:28:52.325722: step 33240, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.223 sec/batch; 18h:29m:53s remains)
INFO - root - 2017-12-17 05:28:54.559837: step 33250, loss = 0.09, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 18h:07m:36s remains)
INFO - root - 2017-12-17 05:28:56.776294: step 33260, loss = 0.11, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 18h:31m:21s remains)
INFO - root - 2017-12-17 05:28:58.964337: step 33270, loss = 0.12, batch loss = 0.09 (37.0 examples/sec; 0.216 sec/batch; 17h:59m:33s remains)
INFO - root - 2017-12-17 05:29:01.170327: step 33280, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 18h:18m:29s remains)
INFO - root - 2017-12-17 05:29:03.370804: step 33290, loss = 0.16, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 18h:07m:51s remains)
INFO - root - 2017-12-17 05:29:05.584888: step 33300, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.224 sec/batch; 18h:34m:45s remains)
INFO - root - 2017-12-17 05:29:07.970670: step 33310, loss = 0.09, batch loss = 0.06 (34.9 examples/sec; 0.229 sec/batch; 19h:02m:22s remains)
INFO - root - 2017-12-17 05:29:10.186823: step 33320, loss = 0.12, batch loss = 0.09 (37.1 examples/sec; 0.215 sec/batch; 17h:54m:02s remains)
INFO - root - 2017-12-17 05:29:12.412523: step 33330, loss = 0.13, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 18h:14m:53s remains)
INFO - root - 2017-12-17 05:29:14.632728: step 33340, loss = 0.10, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 18h:11m:14s remains)
INFO - root - 2017-12-17 05:29:16.833009: step 33350, loss = 0.09, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 18h:08m:08s remains)
INFO - root - 2017-12-17 05:29:19.071781: step 33360, loss = 0.09, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 18h:21m:59s remains)
INFO - root - 2017-12-17 05:29:21.263382: step 33370, loss = 0.09, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 18h:21m:24s remains)
INFO - root - 2017-12-17 05:29:23.533496: step 33380, loss = 0.21, batch loss = 0.17 (37.5 examples/sec; 0.213 sec/batch; 17h:42m:58s remains)
INFO - root - 2017-12-17 05:29:25.737986: step 33390, loss = 0.10, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 18h:11m:55s remains)
INFO - root - 2017-12-17 05:29:27.988605: step 33400, loss = 0.13, batch loss = 0.09 (36.3 examples/sec; 0.220 sec/batch; 18h:18m:38s remains)
INFO - root - 2017-12-17 05:29:30.333970: step 33410, loss = 0.11, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 18h:53m:57s remains)
INFO - root - 2017-12-17 05:29:32.576719: step 33420, loss = 0.09, batch loss = 0.06 (37.0 examples/sec; 0.216 sec/batch; 17h:57m:33s remains)
INFO - root - 2017-12-17 05:29:34.763999: step 33430, loss = 0.14, batch loss = 0.11 (37.1 examples/sec; 0.216 sec/batch; 17h:55m:43s remains)
INFO - root - 2017-12-17 05:29:37.008654: step 33440, loss = 0.10, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 18h:13m:21s remains)
INFO - root - 2017-12-17 05:29:39.233888: step 33450, loss = 0.10, batch loss = 0.06 (35.8 examples/sec; 0.224 sec/batch; 18h:34m:50s remains)
INFO - root - 2017-12-17 05:29:41.442184: step 33460, loss = 0.15, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:47m:30s remains)
INFO - root - 2017-12-17 05:29:43.653622: step 33470, loss = 0.11, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 18h:20m:12s remains)
INFO - root - 2017-12-17 05:29:45.881958: step 33480, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 18h:51m:24s remains)
INFO - root - 2017-12-17 05:29:48.087359: step 33490, loss = 0.15, batch loss = 0.12 (37.0 examples/sec; 0.216 sec/batch; 17h:57m:26s remains)
INFO - root - 2017-12-17 05:29:50.290446: step 33500, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 18h:18m:30s remains)
INFO - root - 2017-12-17 05:29:52.630372: step 33510, loss = 0.09, batch loss = 0.05 (35.4 examples/sec; 0.226 sec/batch; 18h:45m:48s remains)
INFO - root - 2017-12-17 05:29:54.840509: step 33520, loss = 0.13, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 18h:24m:06s remains)
INFO - root - 2017-12-17 05:29:57.112443: step 33530, loss = 0.10, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 18h:37m:39s remains)
INFO - root - 2017-12-17 05:29:59.311960: step 33540, loss = 0.10, batch loss = 0.07 (37.0 examples/sec; 0.216 sec/batch; 17h:57m:55s remains)
INFO - root - 2017-12-17 05:30:01.537548: step 33550, loss = 0.08, batch loss = 0.05 (34.1 examples/sec; 0.235 sec/batch; 19h:28m:56s remains)
INFO - root - 2017-12-17 05:30:03.767432: step 33560, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:19m:50s remains)
INFO - root - 2017-12-17 05:30:05.937955: step 33570, loss = 0.11, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 18h:17m:39s remains)
INFO - root - 2017-12-17 05:30:08.195581: step 33580, loss = 0.09, batch loss = 0.06 (36.6 examples/sec; 0.219 sec/batch; 18h:09m:08s remains)
INFO - root - 2017-12-17 05:30:10.427183: step 33590, loss = 0.09, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 18h:28m:14s remains)
INFO - root - 2017-12-17 05:30:12.667376: step 33600, loss = 0.12, batch loss = 0.08 (35.8 examples/sec; 0.224 sec/batch; 18h:34m:30s remains)
INFO - root - 2017-12-17 05:30:15.028323: step 33610, loss = 0.10, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 18h:12m:08s remains)
INFO - root - 2017-12-17 05:30:17.258771: step 33620, loss = 0.11, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 18h:28m:01s remains)
INFO - root - 2017-12-17 05:30:19.521290: step 33630, loss = 0.12, batch loss = 0.08 (37.0 examples/sec; 0.216 sec/batch; 17h:58m:19s remains)
INFO - root - 2017-12-17 05:30:21.699149: step 33640, loss = 0.10, batch loss = 0.07 (37.1 examples/sec; 0.215 sec/batch; 17h:53m:17s remains)
INFO - root - 2017-12-17 05:30:23.902457: step 33650, loss = 0.12, batch loss = 0.08 (37.0 examples/sec; 0.216 sec/batch; 17h:57m:06s remains)
INFO - root - 2017-12-17 05:30:26.111540: step 33660, loss = 0.13, batch loss = 0.09 (35.1 examples/sec; 0.228 sec/batch; 18h:54m:08s remains)
INFO - root - 2017-12-17 05:30:28.331580: step 33670, loss = 0.36, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 18h:30m:47s remains)
INFO - root - 2017-12-17 05:30:30.503615: step 33680, loss = 0.11, batch loss = 0.07 (36.8 examples/sec; 0.217 sec/batch; 18h:03m:01s remains)
INFO - root - 2017-12-17 05:30:32.741287: step 33690, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 18h:23m:13s remains)
INFO - root - 2017-12-17 05:30:34.956985: step 33700, loss = 0.11, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 18h:25m:36s remains)
INFO - root - 2017-12-17 05:30:37.394138: step 33710, loss = 0.11, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 18h:35m:05s remains)
INFO - root - 2017-12-17 05:30:39.594442: step 33720, loss = 0.09, batch loss = 0.06 (33.4 examples/sec; 0.239 sec/batch; 19h:51m:27s remains)
INFO - root - 2017-12-17 05:30:41.791723: step 33730, loss = 0.13, batch loss = 0.10 (35.5 examples/sec; 0.226 sec/batch; 18h:43m:18s remains)
INFO - root - 2017-12-17 05:30:43.977819: step 33740, loss = 0.10, batch loss = 0.07 (36.9 examples/sec; 0.217 sec/batch; 17h:58m:54s remains)
INFO - root - 2017-12-17 05:30:46.196452: step 33750, loss = 0.12, batch loss = 0.09 (36.8 examples/sec; 0.217 sec/batch; 18h:02m:33s remains)
INFO - root - 2017-12-17 05:30:48.400658: step 33760, loss = 0.11, batch loss = 0.08 (37.2 examples/sec; 0.215 sec/batch; 17h:52m:10s remains)
INFO - root - 2017-12-17 05:30:50.647723: step 33770, loss = 0.10, batch loss = 0.06 (36.1 examples/sec; 0.221 sec/batch; 18h:22m:00s remains)
INFO - root - 2017-12-17 05:30:52.872626: step 33780, loss = 0.12, batch loss = 0.08 (35.5 examples/sec; 0.225 sec/batch; 18h:41m:55s remains)
INFO - root - 2017-12-17 05:30:55.100250: step 33790, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.223 sec/batch; 18h:32m:11s remains)
INFO - root - 2017-12-17 05:30:57.338793: step 33800, loss = 0.09, batch loss = 0.06 (35.0 examples/sec; 0.229 sec/batch; 18h:59m:10s remains)
INFO - root - 2017-12-17 05:30:59.719955: step 33810, loss = 0.11, batch loss = 0.08 (35.1 examples/sec; 0.228 sec/batch; 18h:55m:50s remains)
INFO - root - 2017-12-17 05:31:01.961312: step 33820, loss = 0.11, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:14m:10s remains)
INFO - root - 2017-12-17 05:31:04.190164: step 33830, loss = 0.11, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 18h:11m:22s remains)
INFO - root - 2017-12-17 05:31:06.402814: step 33840, loss = 0.10, batch loss = 0.06 (35.4 examples/sec; 0.226 sec/batch; 18h:43m:50s remains)
INFO - root - 2017-12-17 05:31:08.660657: step 33850, loss = 0.11, batch loss = 0.07 (35.3 examples/sec; 0.227 sec/batch; 18h:48m:39s remains)
INFO - root - 2017-12-17 05:31:10.851386: step 33860, loss = 0.14, batch loss = 0.11 (36.7 examples/sec; 0.218 sec/batch; 18h:06m:20s remains)
INFO - root - 2017-12-17 05:31:13.044479: step 33870, loss = 0.08, batch loss = 0.05 (36.2 examples/sec; 0.221 sec/batch; 18h:18m:41s remains)
INFO - root - 2017-12-17 05:31:15.252074: step 33880, loss = 0.13, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 18h:16m:51s remains)
INFO - root - 2017-12-17 05:31:17.459629: step 33890, loss = 0.09, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 18h:27m:44s remains)
INFO - root - 2017-12-17 05:31:19.693969: step 33900, loss = 0.09, batch loss = 0.05 (35.0 examples/sec; 0.228 sec/batch; 18h:56m:23s remains)
INFO - root - 2017-12-17 05:31:22.088888: step 33910, loss = 0.13, batch loss = 0.09 (36.3 examples/sec; 0.221 sec/batch; 18h:17m:37s remains)
INFO - root - 2017-12-17 05:31:24.372043: step 33920, loss = 0.10, batch loss = 0.06 (37.2 examples/sec; 0.215 sec/batch; 17h:50m:13s remains)
INFO - root - 2017-12-17 05:31:26.575627: step 33930, loss = 0.10, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 18h:29m:59s remains)
INFO - root - 2017-12-17 05:31:28.802605: step 33940, loss = 0.13, batch loss = 0.10 (36.6 examples/sec; 0.218 sec/batch; 18h:06m:24s remains)
INFO - root - 2017-12-17 05:31:30.989600: step 33950, loss = 0.16, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 18h:33m:44s remains)
INFO - root - 2017-12-17 05:31:33.204534: step 33960, loss = 0.09, batch loss = 0.06 (34.9 examples/sec; 0.229 sec/batch; 18h:59m:11s remains)
INFO - root - 2017-12-17 05:31:35.415695: step 33970, loss = 0.09, batch loss = 0.06 (36.4 examples/sec; 0.219 sec/batch; 18h:12m:01s remains)
INFO - root - 2017-12-17 05:31:37.707472: step 33980, loss = 0.10, batch loss = 0.07 (33.2 examples/sec; 0.241 sec/batch; 19h:59m:10s remains)
INFO - root - 2017-12-17 05:31:40.022036: step 33990, loss = 0.13, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 18h:43m:59s remains)
INFO - root - 2017-12-17 05:31:42.264606: step 34000, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.223 sec/batch; 18h:30m:48s remains)
INFO - root - 2017-12-17 05:31:44.591324: step 34010, loss = 0.12, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 18h:34m:19s remains)
INFO - root - 2017-12-17 05:31:46.803304: step 34020, loss = 0.11, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 18h:16m:39s remains)
INFO - root - 2017-12-17 05:31:49.036216: step 34030, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 18h:50m:20s remains)
INFO - root - 2017-12-17 05:31:51.245595: step 34040, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.221 sec/batch; 18h:21m:45s remains)
INFO - root - 2017-12-17 05:31:53.566904: step 34050, loss = 0.09, batch loss = 0.06 (34.4 examples/sec; 0.233 sec/batch; 19h:17m:55s remains)
INFO - root - 2017-12-17 05:31:55.776604: step 34060, loss = 0.17, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 18h:15m:52s remains)
INFO - root - 2017-12-17 05:31:57.991456: step 34070, loss = 0.09, batch loss = 0.05 (36.3 examples/sec; 0.220 sec/batch; 18h:16m:05s remains)
INFO - root - 2017-12-17 05:32:00.180819: step 34080, loss = 0.11, batch loss = 0.07 (37.1 examples/sec; 0.216 sec/batch; 17h:53m:25s remains)
INFO - root - 2017-12-17 05:32:02.401293: step 34090, loss = 0.09, batch loss = 0.06 (35.6 examples/sec; 0.225 sec/batch; 18h:38m:46s remains)
INFO - root - 2017-12-17 05:32:04.614842: step 34100, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 18h:16m:05s remains)
INFO - root - 2017-12-17 05:32:07.040067: step 34110, loss = 0.13, batch loss = 0.09 (35.5 examples/sec; 0.225 sec/batch; 18h:39m:30s remains)
INFO - root - 2017-12-17 05:32:09.280044: step 34120, loss = 0.11, batch loss = 0.08 (34.8 examples/sec; 0.230 sec/batch; 19h:03m:51s remains)
INFO - root - 2017-12-17 05:32:11.500107: step 34130, loss = 0.12, batch loss = 0.08 (35.2 examples/sec; 0.227 sec/batch; 18h:49m:09s remains)
INFO - root - 2017-12-17 05:32:13.718435: step 34140, loss = 0.12, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 18h:24m:50s remains)
INFO - root - 2017-12-17 05:32:15.953282: step 34150, loss = 0.10, batch loss = 0.07 (34.6 examples/sec; 0.231 sec/batch; 19h:09m:06s remains)
INFO - root - 2017-12-17 05:32:18.262156: step 34160, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:20m:01s remains)
INFO - root - 2017-12-17 05:32:20.505286: step 34170, loss = 0.10, batch loss = 0.07 (37.0 examples/sec; 0.216 sec/batch; 17h:53m:58s remains)
INFO - root - 2017-12-17 05:32:22.731873: step 34180, loss = 0.12, batch loss = 0.08 (36.7 examples/sec; 0.218 sec/batch; 18h:03m:57s remains)
INFO - root - 2017-12-17 05:32:24.977872: step 34190, loss = 0.12, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 18h:08m:16s remains)
INFO - root - 2017-12-17 05:32:27.172686: step 34200, loss = 0.10, batch loss = 0.06 (36.1 examples/sec; 0.221 sec/batch; 18h:21m:12s remains)
INFO - root - 2017-12-17 05:32:29.486684: step 34210, loss = 0.11, batch loss = 0.08 (37.0 examples/sec; 0.216 sec/batch; 17h:54m:58s remains)
INFO - root - 2017-12-17 05:32:31.705169: step 34220, loss = 0.10, batch loss = 0.06 (36.9 examples/sec; 0.217 sec/batch; 17h:58m:49s remains)
INFO - root - 2017-12-17 05:32:33.979776: step 34230, loss = 0.14, batch loss = 0.10 (34.6 examples/sec; 0.231 sec/batch; 19h:08m:35s remains)
INFO - root - 2017-12-17 05:32:36.220835: step 34240, loss = 0.08, batch loss = 0.05 (36.0 examples/sec; 0.222 sec/batch; 18h:25m:24s remains)
INFO - root - 2017-12-17 05:32:38.458160: step 34250, loss = 0.10, batch loss = 0.07 (35.3 examples/sec; 0.226 sec/batch; 18h:45m:27s remains)
INFO - root - 2017-12-17 05:32:40.678105: step 34260, loss = 0.12, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 18h:19m:47s remains)
INFO - root - 2017-12-17 05:32:42.913878: step 34270, loss = 0.12, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 18h:09m:54s remains)
INFO - root - 2017-12-17 05:32:45.129407: step 34280, loss = 0.12, batch loss = 0.08 (36.3 examples/sec; 0.220 sec/batch; 18h:15m:42s remains)
INFO - root - 2017-12-17 05:32:47.394613: step 34290, loss = 0.11, batch loss = 0.07 (35.0 examples/sec; 0.228 sec/batch; 18h:55m:29s remains)
INFO - root - 2017-12-17 05:32:49.626328: step 34300, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.223 sec/batch; 18h:29m:36s remains)
INFO - root - 2017-12-17 05:32:51.971267: step 34310, loss = 0.13, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 18h:24m:30s remains)
INFO - root - 2017-12-17 05:32:54.181092: step 34320, loss = 0.13, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 18h:14m:29s remains)
INFO - root - 2017-12-17 05:32:56.418944: step 34330, loss = 0.09, batch loss = 0.06 (36.9 examples/sec; 0.217 sec/batch; 17h:57m:51s remains)
INFO - root - 2017-12-17 05:32:58.606464: step 34340, loss = 0.14, batch loss = 0.11 (37.5 examples/sec; 0.214 sec/batch; 17h:41m:07s remains)
INFO - root - 2017-12-17 05:33:00.857804: step 34350, loss = 0.12, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 18h:36m:34s remains)
INFO - root - 2017-12-17 05:33:03.066515: step 34360, loss = 0.12, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 18h:37m:21s remains)
INFO - root - 2017-12-17 05:33:05.248466: step 34370, loss = 0.11, batch loss = 0.07 (37.6 examples/sec; 0.213 sec/batch; 17h:36m:58s remains)
INFO - root - 2017-12-17 05:33:07.439528: step 34380, loss = 0.11, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 18h:03m:52s remains)
INFO - root - 2017-12-17 05:33:09.632171: step 34390, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 18h:15m:10s remains)
INFO - root - 2017-12-17 05:33:11.853502: step 34400, loss = 0.14, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 18h:08m:24s remains)
INFO - root - 2017-12-17 05:33:14.198279: step 34410, loss = 0.10, batch loss = 0.06 (36.9 examples/sec; 0.217 sec/batch; 17h:55m:44s remains)
INFO - root - 2017-12-17 05:33:16.418612: step 34420, loss = 0.14, batch loss = 0.11 (35.5 examples/sec; 0.226 sec/batch; 18h:40m:36s remains)
INFO - root - 2017-12-17 05:33:18.643293: step 34430, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:11m:02s remains)
INFO - root - 2017-12-17 05:33:20.869047: step 34440, loss = 0.11, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 18h:26m:28s remains)
INFO - root - 2017-12-17 05:33:23.092507: step 34450, loss = 0.12, batch loss = 0.08 (36.8 examples/sec; 0.218 sec/batch; 18h:01m:16s remains)
INFO - root - 2017-12-17 05:33:25.321141: step 34460, loss = 0.12, batch loss = 0.09 (37.2 examples/sec; 0.215 sec/batch; 17h:48m:44s remains)
INFO - root - 2017-12-17 05:33:27.576018: step 34470, loss = 0.13, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 18h:46m:28s remains)
INFO - root - 2017-12-17 05:33:29.795524: step 34480, loss = 0.09, batch loss = 0.06 (34.9 examples/sec; 0.230 sec/batch; 18h:59m:56s remains)
INFO - root - 2017-12-17 05:33:32.049879: step 34490, loss = 0.11, batch loss = 0.07 (36.8 examples/sec; 0.218 sec/batch; 18h:01m:06s remains)
INFO - root - 2017-12-17 05:33:34.300728: step 34500, loss = 0.13, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:34m:12s remains)
INFO - root - 2017-12-17 05:33:36.690618: step 34510, loss = 0.20, batch loss = 0.16 (36.1 examples/sec; 0.221 sec/batch; 18h:19m:48s remains)
INFO - root - 2017-12-17 05:33:38.976320: step 34520, loss = 0.11, batch loss = 0.08 (36.1 examples/sec; 0.222 sec/batch; 18h:22m:01s remains)
INFO - root - 2017-12-17 05:33:41.192853: step 34530, loss = 0.13, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 18h:28m:01s remains)
INFO - root - 2017-12-17 05:33:43.416014: step 34540, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.221 sec/batch; 18h:19m:38s remains)
INFO - root - 2017-12-17 05:33:45.591990: step 34550, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 18h:13m:03s remains)
INFO - root - 2017-12-17 05:33:47.815801: step 34560, loss = 0.11, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 18h:23m:07s remains)
INFO - root - 2017-12-17 05:33:50.014252: step 34570, loss = 0.11, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 18h:24m:01s remains)
INFO - root - 2017-12-17 05:33:52.235981: step 34580, loss = 0.11, batch loss = 0.08 (35.3 examples/sec; 0.227 sec/batch; 18h:46m:44s remains)
INFO - root - 2017-12-17 05:33:54.412204: step 34590, loss = 0.09, batch loss = 0.05 (37.6 examples/sec; 0.213 sec/batch; 17h:36m:46s remains)
INFO - root - 2017-12-17 05:33:56.617473: step 34600, loss = 0.09, batch loss = 0.06 (38.3 examples/sec; 0.209 sec/batch; 17h:18m:25s remains)
INFO - root - 2017-12-17 05:33:58.990424: step 34610, loss = 0.11, batch loss = 0.07 (34.9 examples/sec; 0.229 sec/batch; 18h:58m:42s remains)
INFO - root - 2017-12-17 05:34:01.262213: step 34620, loss = 0.10, batch loss = 0.07 (34.9 examples/sec; 0.229 sec/batch; 18h:57m:10s remains)
INFO - root - 2017-12-17 05:34:03.505653: step 34630, loss = 0.11, batch loss = 0.07 (35.4 examples/sec; 0.226 sec/batch; 18h:43m:18s remains)
INFO - root - 2017-12-17 05:34:05.703862: step 34640, loss = 0.14, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:33m:39s remains)
INFO - root - 2017-12-17 05:34:07.967681: step 34650, loss = 0.11, batch loss = 0.07 (34.8 examples/sec; 0.230 sec/batch; 19h:01m:24s remains)
INFO - root - 2017-12-17 05:34:10.210550: step 34660, loss = 0.09, batch loss = 0.06 (34.7 examples/sec; 0.230 sec/batch; 19h:03m:13s remains)
INFO - root - 2017-12-17 05:34:12.462960: step 34670, loss = 0.10, batch loss = 0.07 (35.0 examples/sec; 0.228 sec/batch; 18h:53m:06s remains)
INFO - root - 2017-12-17 05:34:14.694271: step 34680, loss = 0.14, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 18h:38m:39s remains)
INFO - root - 2017-12-17 05:34:16.894053: step 34690, loss = 0.11, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 18h:06m:19s remains)
INFO - root - 2017-12-17 05:34:19.166512: step 34700, loss = 0.09, batch loss = 0.06 (35.8 examples/sec; 0.223 sec/batch; 18h:28m:39s remains)
INFO - root - 2017-12-17 05:34:21.514181: step 34710, loss = 0.08, batch loss = 0.05 (35.2 examples/sec; 0.227 sec/batch; 18h:47m:48s remains)
INFO - root - 2017-12-17 05:34:23.767806: step 34720, loss = 0.13, batch loss = 0.09 (36.9 examples/sec; 0.217 sec/batch; 17h:56m:56s remains)
INFO - root - 2017-12-17 05:34:25.966132: step 34730, loss = 0.10, batch loss = 0.06 (35.6 examples/sec; 0.224 sec/batch; 18h:33m:57s remains)
INFO - root - 2017-12-17 05:34:28.155773: step 34740, loss = 0.10, batch loss = 0.07 (36.9 examples/sec; 0.217 sec/batch; 17h:54m:28s remains)
INFO - root - 2017-12-17 05:34:30.396374: step 34750, loss = 0.12, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 18h:30m:36s remains)
INFO - root - 2017-12-17 05:34:32.636091: step 34760, loss = 0.09, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 18h:07m:33s remains)
INFO - root - 2017-12-17 05:34:34.869580: step 34770, loss = 0.13, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 18h:31m:49s remains)
INFO - root - 2017-12-17 05:34:37.066109: step 34780, loss = 0.12, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 18h:11m:00s remains)
INFO - root - 2017-12-17 05:34:39.282755: step 34790, loss = 0.07, batch loss = 0.04 (37.0 examples/sec; 0.216 sec/batch; 17h:52m:03s remains)
INFO - root - 2017-12-17 05:34:41.488693: step 34800, loss = 0.11, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 18h:11m:11s remains)
INFO - root - 2017-12-17 05:34:43.867203: step 34810, loss = 0.12, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 18h:31m:17s remains)
INFO - root - 2017-12-17 05:34:46.110622: step 34820, loss = 0.11, batch loss = 0.08 (35.5 examples/sec; 0.225 sec/batch; 18h:36m:42s remains)
INFO - root - 2017-12-17 05:34:48.354594: step 34830, loss = 0.12, batch loss = 0.09 (35.5 examples/sec; 0.225 sec/batch; 18h:36m:48s remains)
INFO - root - 2017-12-17 05:34:50.580053: step 34840, loss = 0.10, batch loss = 0.07 (37.4 examples/sec; 0.214 sec/batch; 17h:41m:10s remains)
INFO - root - 2017-12-17 05:34:52.789968: step 34850, loss = 0.12, batch loss = 0.08 (36.1 examples/sec; 0.222 sec/batch; 18h:19m:35s remains)
INFO - root - 2017-12-17 05:34:55.042444: step 34860, loss = 0.12, batch loss = 0.08 (34.4 examples/sec; 0.232 sec/batch; 19h:12m:05s remains)
INFO - root - 2017-12-17 05:34:57.303732: step 34870, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:35m:53s remains)
INFO - root - 2017-12-17 05:34:59.607470: step 34880, loss = 0.11, batch loss = 0.08 (35.3 examples/sec; 0.226 sec/batch; 18h:42m:44s remains)
INFO - root - 2017-12-17 05:35:01.823056: step 34890, loss = 0.11, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 18h:07m:28s remains)
INFO - root - 2017-12-17 05:35:04.068516: step 34900, loss = 0.13, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 18h:09m:49s remains)
INFO - root - 2017-12-17 05:35:06.433472: step 34910, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 18h:19m:31s remains)
INFO - root - 2017-12-17 05:35:08.660918: step 34920, loss = 0.08, batch loss = 0.05 (36.8 examples/sec; 0.217 sec/batch; 17h:57m:22s remains)
INFO - root - 2017-12-17 05:35:10.888425: step 34930, loss = 0.16, batch loss = 0.13 (34.7 examples/sec; 0.231 sec/batch; 19h:04m:42s remains)
INFO - root - 2017-12-17 05:35:13.092259: step 34940, loss = 0.10, batch loss = 0.07 (37.8 examples/sec; 0.212 sec/batch; 17h:30m:57s remains)
INFO - root - 2017-12-17 05:35:15.311856: step 34950, loss = 0.09, batch loss = 0.06 (35.0 examples/sec; 0.229 sec/batch; 18h:54m:48s remains)
INFO - root - 2017-12-17 05:35:17.560674: step 34960, loss = 0.11, batch loss = 0.08 (36.1 examples/sec; 0.222 sec/batch; 18h:18m:31s remains)
INFO - root - 2017-12-17 05:35:19.788715: step 34970, loss = 0.13, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 18h:12m:16s remains)
INFO - root - 2017-12-17 05:35:22.028702: step 34980, loss = 0.12, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 18h:05m:05s remains)
INFO - root - 2017-12-17 05:35:24.228019: step 34990, loss = 0.09, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 18h:21m:10s remains)
INFO - root - 2017-12-17 05:35:26.446653: step 35000, loss = 0.13, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 18h:07m:28s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-35000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-35000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 05:35:29.516432: step 35010, loss = 0.09, batch loss = 0.05 (36.2 examples/sec; 0.221 sec/batch; 18h:16m:37s remains)
INFO - root - 2017-12-17 05:35:31.725871: step 35020, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:17m:08s remains)
INFO - root - 2017-12-17 05:35:33.917140: step 35030, loss = 0.13, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 18h:25m:05s remains)
INFO - root - 2017-12-17 05:35:36.125029: step 35040, loss = 0.15, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:23m:01s remains)
INFO - root - 2017-12-17 05:35:38.354444: step 35050, loss = 0.16, batch loss = 0.12 (36.8 examples/sec; 0.217 sec/batch; 17h:58m:07s remains)
INFO - root - 2017-12-17 05:35:40.601554: step 35060, loss = 0.12, batch loss = 0.09 (35.5 examples/sec; 0.225 sec/batch; 18h:37m:50s remains)
INFO - root - 2017-12-17 05:35:42.861180: step 35070, loss = 0.08, batch loss = 0.05 (34.6 examples/sec; 0.231 sec/batch; 19h:06m:18s remains)
INFO - root - 2017-12-17 05:35:45.078440: step 35080, loss = 0.09, batch loss = 0.05 (36.3 examples/sec; 0.220 sec/batch; 18h:11m:37s remains)
INFO - root - 2017-12-17 05:35:47.274791: step 35090, loss = 0.10, batch loss = 0.06 (37.4 examples/sec; 0.214 sec/batch; 17h:39m:19s remains)
INFO - root - 2017-12-17 05:35:49.529839: step 35100, loss = 0.11, batch loss = 0.08 (34.9 examples/sec; 0.229 sec/batch; 18h:56m:04s remains)
INFO - root - 2017-12-17 05:35:51.893194: step 35110, loss = 0.11, batch loss = 0.08 (36.1 examples/sec; 0.221 sec/batch; 18h:17m:12s remains)
INFO - root - 2017-12-17 05:35:54.149094: step 35120, loss = 0.11, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 18h:33m:54s remains)
INFO - root - 2017-12-17 05:35:56.362521: step 35130, loss = 0.09, batch loss = 0.05 (36.7 examples/sec; 0.218 sec/batch; 17h:59m:39s remains)
INFO - root - 2017-12-17 05:35:58.598695: step 35140, loss = 0.12, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 18h:07m:39s remains)
INFO - root - 2017-12-17 05:36:00.812977: step 35150, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:14m:47s remains)
INFO - root - 2017-12-17 05:36:03.090557: step 35160, loss = 0.09, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 18h:06m:37s remains)
INFO - root - 2017-12-17 05:36:05.304259: step 35170, loss = 0.13, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 18h:45m:58s remains)
INFO - root - 2017-12-17 05:36:07.546054: step 35180, loss = 0.10, batch loss = 0.07 (34.7 examples/sec; 0.230 sec/batch; 19h:01m:18s remains)
INFO - root - 2017-12-17 05:36:09.807303: step 35190, loss = 0.09, batch loss = 0.06 (34.6 examples/sec; 0.231 sec/batch; 19h:04m:52s remains)
INFO - root - 2017-12-17 05:36:12.080703: step 35200, loss = 0.09, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 18h:20m:51s remains)
INFO - root - 2017-12-17 05:36:14.537332: step 35210, loss = 0.11, batch loss = 0.07 (37.3 examples/sec; 0.214 sec/batch; 17h:41m:35s remains)
INFO - root - 2017-12-17 05:36:16.948017: step 35220, loss = 0.15, batch loss = 0.12 (36.1 examples/sec; 0.221 sec/batch; 18h:17m:12s remains)
INFO - root - 2017-12-17 05:36:19.186919: step 35230, loss = 0.09, batch loss = 0.05 (36.8 examples/sec; 0.218 sec/batch; 17h:58m:24s remains)
INFO - root - 2017-12-17 05:36:21.415721: step 35240, loss = 0.16, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 18h:25m:07s remains)
INFO - root - 2017-12-17 05:36:23.636196: step 35250, loss = 0.14, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:30m:41s remains)
INFO - root - 2017-12-17 05:36:25.866255: step 35260, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.221 sec/batch; 18h:16m:21s remains)
INFO - root - 2017-12-17 05:36:28.141012: step 35270, loss = 0.09, batch loss = 0.06 (35.2 examples/sec; 0.227 sec/batch; 18h:46m:29s remains)
INFO - root - 2017-12-17 05:36:30.414359: step 35280, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 18h:29m:36s remains)
INFO - root - 2017-12-17 05:36:32.624111: step 35290, loss = 0.12, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 18h:29m:45s remains)
INFO - root - 2017-12-17 05:36:34.852575: step 35300, loss = 0.08, batch loss = 0.05 (35.4 examples/sec; 0.226 sec/batch; 18h:39m:28s remains)
INFO - root - 2017-12-17 05:36:37.225450: step 35310, loss = 0.10, batch loss = 0.07 (34.7 examples/sec; 0.230 sec/batch; 19h:01m:13s remains)
INFO - root - 2017-12-17 05:36:39.467223: step 35320, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:13m:45s remains)
INFO - root - 2017-12-17 05:36:41.703821: step 35330, loss = 0.10, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 18h:23m:30s remains)
INFO - root - 2017-12-17 05:36:43.930630: step 35340, loss = 0.08, batch loss = 0.05 (36.0 examples/sec; 0.222 sec/batch; 18h:21m:54s remains)
INFO - root - 2017-12-17 05:36:46.170770: step 35350, loss = 0.09, batch loss = 0.05 (36.0 examples/sec; 0.222 sec/batch; 18h:21m:52s remains)
INFO - root - 2017-12-17 05:36:48.398048: step 35360, loss = 0.10, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 18h:06m:05s remains)
INFO - root - 2017-12-17 05:36:50.601812: step 35370, loss = 0.09, batch loss = 0.05 (35.4 examples/sec; 0.226 sec/batch; 18h:40m:42s remains)
INFO - root - 2017-12-17 05:36:52.823388: step 35380, loss = 0.11, batch loss = 0.07 (33.4 examples/sec; 0.239 sec/batch; 19h:45m:53s remains)
INFO - root - 2017-12-17 05:36:55.097240: step 35390, loss = 0.08, batch loss = 0.04 (35.8 examples/sec; 0.223 sec/batch; 18h:26m:40s remains)
INFO - root - 2017-12-17 05:36:57.315451: step 35400, loss = 0.11, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 18h:05m:07s remains)
INFO - root - 2017-12-17 05:36:59.695586: step 35410, loss = 0.14, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 18h:06m:25s remains)
INFO - root - 2017-12-17 05:37:01.899617: step 35420, loss = 0.11, batch loss = 0.08 (36.9 examples/sec; 0.217 sec/batch; 17h:52m:34s remains)
INFO - root - 2017-12-17 05:37:04.098308: step 35430, loss = 0.13, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:29m:16s remains)
INFO - root - 2017-12-17 05:37:06.346563: step 35440, loss = 0.17, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 18h:10m:09s remains)
INFO - root - 2017-12-17 05:37:08.578915: step 35450, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:32m:30s remains)
INFO - root - 2017-12-17 05:37:10.795541: step 35460, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 18h:10m:38s remains)
INFO - root - 2017-12-17 05:37:12.991176: step 35470, loss = 0.09, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 17h:59m:27s remains)
INFO - root - 2017-12-17 05:37:15.188801: step 35480, loss = 0.13, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 18h:05m:44s remains)
INFO - root - 2017-12-17 05:37:17.447771: step 35490, loss = 0.15, batch loss = 0.11 (34.1 examples/sec; 0.235 sec/batch; 19h:21m:17s remains)
INFO - root - 2017-12-17 05:37:19.633594: step 35500, loss = 0.13, batch loss = 0.09 (37.1 examples/sec; 0.215 sec/batch; 17h:46m:20s remains)
INFO - root - 2017-12-17 05:37:21.962380: step 35510, loss = 0.09, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 18h:21m:48s remains)
INFO - root - 2017-12-17 05:37:24.194559: step 35520, loss = 0.13, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 18h:57m:27s remains)
INFO - root - 2017-12-17 05:37:26.427932: step 35530, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 18h:09m:19s remains)
INFO - root - 2017-12-17 05:37:28.683682: step 35540, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 18h:19m:28s remains)
INFO - root - 2017-12-17 05:37:30.909253: step 35550, loss = 0.10, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 18h:18m:09s remains)
INFO - root - 2017-12-17 05:37:33.102174: step 35560, loss = 0.12, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 18h:01m:49s remains)
INFO - root - 2017-12-17 05:37:35.346138: step 35570, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 18h:17m:00s remains)
INFO - root - 2017-12-17 05:37:37.573371: step 35580, loss = 0.11, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 18h:02m:25s remains)
INFO - root - 2017-12-17 05:37:39.776404: step 35590, loss = 0.10, batch loss = 0.07 (37.1 examples/sec; 0.216 sec/batch; 17h:47m:54s remains)
INFO - root - 2017-12-17 05:37:42.010552: step 35600, loss = 0.10, batch loss = 0.06 (34.9 examples/sec; 0.229 sec/batch; 18h:53m:02s remains)
INFO - root - 2017-12-17 05:37:44.391500: step 35610, loss = 0.14, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 18h:57m:10s remains)
INFO - root - 2017-12-17 05:37:46.621389: step 35620, loss = 0.13, batch loss = 0.10 (36.7 examples/sec; 0.218 sec/batch; 17h:59m:45s remains)
INFO - root - 2017-12-17 05:37:48.896271: step 35630, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 18h:28m:18s remains)
INFO - root - 2017-12-17 05:37:51.150922: step 35640, loss = 0.13, batch loss = 0.10 (37.0 examples/sec; 0.216 sec/batch; 17h:49m:04s remains)
INFO - root - 2017-12-17 05:37:53.370033: step 35650, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 18h:27m:53s remains)
INFO - root - 2017-12-17 05:37:55.650132: step 35660, loss = 0.11, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 18h:23m:52s remains)
INFO - root - 2017-12-17 05:37:57.871635: step 35670, loss = 0.11, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 18h:06m:36s remains)
INFO - root - 2017-12-17 05:38:00.083261: step 35680, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:08m:32s remains)
INFO - root - 2017-12-17 05:38:02.332137: step 35690, loss = 0.09, batch loss = 0.06 (35.5 examples/sec; 0.225 sec/batch; 18h:35m:08s remains)
INFO - root - 2017-12-17 05:38:04.539508: step 35700, loss = 0.10, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 18h:03m:58s remains)
INFO - root - 2017-12-17 05:38:06.870356: step 35710, loss = 0.08, batch loss = 0.05 (37.4 examples/sec; 0.214 sec/batch; 17h:39m:28s remains)
INFO - root - 2017-12-17 05:38:09.093708: step 35720, loss = 0.14, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 18h:14m:09s remains)
INFO - root - 2017-12-17 05:38:11.309674: step 35730, loss = 0.09, batch loss = 0.06 (35.2 examples/sec; 0.227 sec/batch; 18h:43m:31s remains)
INFO - root - 2017-12-17 05:38:13.544013: step 35740, loss = 0.09, batch loss = 0.05 (36.8 examples/sec; 0.217 sec/batch; 17h:54m:18s remains)
INFO - root - 2017-12-17 05:38:15.815866: step 35750, loss = 0.17, batch loss = 0.14 (36.1 examples/sec; 0.221 sec/batch; 18h:15m:17s remains)
INFO - root - 2017-12-17 05:38:18.033912: step 35760, loss = 0.11, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 18h:01m:05s remains)
INFO - root - 2017-12-17 05:38:20.248164: step 35770, loss = 0.10, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 18h:04m:13s remains)
INFO - root - 2017-12-17 05:38:22.473013: step 35780, loss = 0.14, batch loss = 0.10 (35.8 examples/sec; 0.223 sec/batch; 18h:23m:45s remains)
INFO - root - 2017-12-17 05:38:24.733339: step 35790, loss = 0.10, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 18h:16m:38s remains)
INFO - root - 2017-12-17 05:38:26.958551: step 35800, loss = 0.10, batch loss = 0.06 (34.9 examples/sec; 0.229 sec/batch; 18h:52m:32s remains)
INFO - root - 2017-12-17 05:38:29.337262: step 35810, loss = 0.11, batch loss = 0.08 (37.4 examples/sec; 0.214 sec/batch; 17h:38m:46s remains)
INFO - root - 2017-12-17 05:38:31.525647: step 35820, loss = 0.17, batch loss = 0.14 (36.7 examples/sec; 0.218 sec/batch; 17h:59m:13s remains)
INFO - root - 2017-12-17 05:38:33.756541: step 35830, loss = 0.15, batch loss = 0.12 (37.1 examples/sec; 0.216 sec/batch; 17h:45m:33s remains)
INFO - root - 2017-12-17 05:38:35.959936: step 35840, loss = 0.11, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 18h:06m:35s remains)
INFO - root - 2017-12-17 05:38:38.168924: step 35850, loss = 0.11, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 18h:20m:19s remains)
INFO - root - 2017-12-17 05:38:40.354547: step 35860, loss = 0.13, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 18h:09m:16s remains)
INFO - root - 2017-12-17 05:38:42.559762: step 35870, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.223 sec/batch; 18h:23m:13s remains)
INFO - root - 2017-12-17 05:38:44.783727: step 35880, loss = 0.12, batch loss = 0.09 (36.3 examples/sec; 0.221 sec/batch; 18h:10m:44s remains)
INFO - root - 2017-12-17 05:38:46.959931: step 35890, loss = 0.12, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 18h:05m:10s remains)
INFO - root - 2017-12-17 05:38:49.135126: step 35900, loss = 0.12, batch loss = 0.08 (36.8 examples/sec; 0.218 sec/batch; 17h:56m:03s remains)
INFO - root - 2017-12-17 05:38:51.504079: step 35910, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 18h:15m:49s remains)
INFO - root - 2017-12-17 05:38:53.713161: step 35920, loss = 0.09, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 18h:20m:39s remains)
INFO - root - 2017-12-17 05:38:55.919545: step 35930, loss = 0.09, batch loss = 0.05 (35.1 examples/sec; 0.228 sec/batch; 18h:45m:18s remains)
INFO - root - 2017-12-17 05:38:58.150353: step 35940, loss = 0.10, batch loss = 0.07 (36.9 examples/sec; 0.217 sec/batch; 17h:50m:28s remains)
INFO - root - 2017-12-17 05:39:00.343489: step 35950, loss = 0.10, batch loss = 0.07 (37.1 examples/sec; 0.216 sec/batch; 17h:45m:16s remains)
INFO - root - 2017-12-17 05:39:02.569738: step 35960, loss = 0.14, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 18h:08m:04s remains)
INFO - root - 2017-12-17 05:39:04.774797: step 35970, loss = 0.18, batch loss = 0.14 (36.8 examples/sec; 0.217 sec/batch; 17h:54m:33s remains)
INFO - root - 2017-12-17 05:39:06.981936: step 35980, loss = 0.11, batch loss = 0.07 (36.8 examples/sec; 0.218 sec/batch; 17h:55m:23s remains)
INFO - root - 2017-12-17 05:39:09.245808: step 35990, loss = 0.13, batch loss = 0.10 (35.1 examples/sec; 0.228 sec/batch; 18h:46m:57s remains)
INFO - root - 2017-12-17 05:39:11.435333: step 36000, loss = 0.16, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 17h:57m:52s remains)
INFO - root - 2017-12-17 05:39:13.808279: step 36010, loss = 0.11, batch loss = 0.07 (36.9 examples/sec; 0.217 sec/batch; 17h:51m:53s remains)
INFO - root - 2017-12-17 05:39:16.045031: step 36020, loss = 0.10, batch loss = 0.06 (36.1 examples/sec; 0.221 sec/batch; 18h:13m:45s remains)
INFO - root - 2017-12-17 05:39:18.271020: step 36030, loss = 0.13, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 18h:16m:56s remains)
INFO - root - 2017-12-17 05:39:20.462352: step 36040, loss = 0.10, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 18h:04m:07s remains)
INFO - root - 2017-12-17 05:39:22.701472: step 36050, loss = 0.10, batch loss = 0.07 (34.8 examples/sec; 0.230 sec/batch; 18h:56m:19s remains)
INFO - root - 2017-12-17 05:39:24.917058: step 36060, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 18h:14m:59s remains)
INFO - root - 2017-12-17 05:39:27.158791: step 36070, loss = 0.09, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 18h:21m:53s remains)
INFO - root - 2017-12-17 05:39:29.389886: step 36080, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.223 sec/batch; 18h:22m:58s remains)
INFO - root - 2017-12-17 05:39:31.623240: step 36090, loss = 0.10, batch loss = 0.06 (34.7 examples/sec; 0.230 sec/batch; 18h:57m:31s remains)
INFO - root - 2017-12-17 05:39:33.858313: step 36100, loss = 0.20, batch loss = 0.17 (35.5 examples/sec; 0.225 sec/batch; 18h:31m:45s remains)
INFO - root - 2017-12-17 05:39:36.182199: step 36110, loss = 0.10, batch loss = 0.07 (37.5 examples/sec; 0.214 sec/batch; 17h:35m:07s remains)
INFO - root - 2017-12-17 05:39:38.400472: step 36120, loss = 0.15, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 18h:15m:00s remains)
INFO - root - 2017-12-17 05:39:40.599888: step 36130, loss = 0.11, batch loss = 0.08 (37.5 examples/sec; 0.213 sec/batch; 17h:33m:58s remains)
INFO - root - 2017-12-17 05:39:42.824233: step 36140, loss = 0.18, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 18h:20m:09s remains)
INFO - root - 2017-12-17 05:39:45.062485: step 36150, loss = 0.10, batch loss = 0.07 (33.9 examples/sec; 0.236 sec/batch; 19h:24m:56s remains)
INFO - root - 2017-12-17 05:39:47.312095: step 36160, loss = 0.11, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 18h:29m:55s remains)
INFO - root - 2017-12-17 05:39:49.549026: step 36170, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.224 sec/batch; 18h:25m:06s remains)
INFO - root - 2017-12-17 05:39:51.751127: step 36180, loss = 0.08, batch loss = 0.05 (36.9 examples/sec; 0.217 sec/batch; 17h:50m:23s remains)
INFO - root - 2017-12-17 05:39:53.983402: step 36190, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 18h:14m:32s remains)
INFO - root - 2017-12-17 05:39:56.201336: step 36200, loss = 0.10, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 18h:02m:31s remains)
INFO - root - 2017-12-17 05:39:58.551177: step 36210, loss = 0.10, batch loss = 0.06 (36.6 examples/sec; 0.219 sec/batch; 18h:00m:06s remains)
INFO - root - 2017-12-17 05:40:00.758149: step 36220, loss = 0.10, batch loss = 0.07 (35.3 examples/sec; 0.226 sec/batch; 18h:37m:37s remains)
INFO - root - 2017-12-17 05:40:02.936295: step 36230, loss = 0.17, batch loss = 0.13 (35.6 examples/sec; 0.224 sec/batch; 18h:28m:05s remains)
INFO - root - 2017-12-17 05:40:05.159042: step 36240, loss = 0.12, batch loss = 0.08 (35.3 examples/sec; 0.226 sec/batch; 18h:37m:36s remains)
INFO - root - 2017-12-17 05:40:07.396185: step 36250, loss = 0.10, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 18h:02m:07s remains)
INFO - root - 2017-12-17 05:40:09.625589: step 36260, loss = 0.14, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 18h:53m:34s remains)
INFO - root - 2017-12-17 05:40:11.820219: step 36270, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:28m:40s remains)
INFO - root - 2017-12-17 05:40:14.017442: step 36280, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:12m:20s remains)
INFO - root - 2017-12-17 05:40:16.243558: step 36290, loss = 0.14, batch loss = 0.11 (37.2 examples/sec; 0.215 sec/batch; 17h:42m:04s remains)
INFO - root - 2017-12-17 05:40:18.486398: step 36300, loss = 0.09, batch loss = 0.06 (34.4 examples/sec; 0.232 sec/batch; 19h:07m:21s remains)
INFO - root - 2017-12-17 05:40:20.839759: step 36310, loss = 0.11, batch loss = 0.08 (35.5 examples/sec; 0.225 sec/batch; 18h:31m:55s remains)
INFO - root - 2017-12-17 05:40:23.020862: step 36320, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 18h:07m:12s remains)
INFO - root - 2017-12-17 05:40:25.236461: step 36330, loss = 0.15, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 18h:03m:58s remains)
INFO - root - 2017-12-17 05:40:27.430947: step 36340, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 18h:06m:26s remains)
INFO - root - 2017-12-17 05:40:29.636642: step 36350, loss = 0.12, batch loss = 0.09 (35.8 examples/sec; 0.223 sec/batch; 18h:22m:42s remains)
INFO - root - 2017-12-17 05:40:31.838203: step 36360, loss = 0.10, batch loss = 0.07 (38.3 examples/sec; 0.209 sec/batch; 17h:10m:35s remains)
INFO - root - 2017-12-17 05:40:34.062649: step 36370, loss = 0.12, batch loss = 0.09 (35.8 examples/sec; 0.224 sec/batch; 18h:24m:05s remains)
INFO - root - 2017-12-17 05:40:36.300554: step 36380, loss = 0.15, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:45m:40s remains)
INFO - root - 2017-12-17 05:40:38.502104: step 36390, loss = 0.11, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 18h:00m:26s remains)
INFO - root - 2017-12-17 05:40:40.705526: step 36400, loss = 0.14, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:24m:24s remains)
INFO - root - 2017-12-17 05:40:43.059362: step 36410, loss = 0.09, batch loss = 0.06 (36.9 examples/sec; 0.217 sec/batch; 17h:49m:18s remains)
INFO - root - 2017-12-17 05:40:45.288641: step 36420, loss = 0.09, batch loss = 0.06 (36.8 examples/sec; 0.217 sec/batch; 17h:52m:50s remains)
INFO - root - 2017-12-17 05:40:47.486519: step 36430, loss = 0.11, batch loss = 0.08 (37.0 examples/sec; 0.216 sec/batch; 17h:45m:55s remains)
INFO - root - 2017-12-17 05:40:49.683057: step 36440, loss = 0.10, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 17h:55m:08s remains)
INFO - root - 2017-12-17 05:40:51.893678: step 36450, loss = 0.12, batch loss = 0.08 (35.4 examples/sec; 0.226 sec/batch; 18h:35m:38s remains)
INFO - root - 2017-12-17 05:40:54.128332: step 36460, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 18h:26m:47s remains)
INFO - root - 2017-12-17 05:40:56.357135: step 36470, loss = 0.13, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 18h:14m:55s remains)
INFO - root - 2017-12-17 05:40:58.591280: step 36480, loss = 0.18, batch loss = 0.15 (35.0 examples/sec; 0.228 sec/batch; 18h:46m:23s remains)
INFO - root - 2017-12-17 05:41:00.833545: step 36490, loss = 0.10, batch loss = 0.07 (34.5 examples/sec; 0.232 sec/batch; 19h:04m:51s remains)
INFO - root - 2017-12-17 05:41:03.107808: step 36500, loss = 0.12, batch loss = 0.09 (35.6 examples/sec; 0.224 sec/batch; 18h:27m:07s remains)
INFO - root - 2017-12-17 05:41:05.446261: step 36510, loss = 0.12, batch loss = 0.08 (37.7 examples/sec; 0.212 sec/batch; 17h:25m:35s remains)
INFO - root - 2017-12-17 05:41:07.696778: step 36520, loss = 0.12, batch loss = 0.09 (34.2 examples/sec; 0.234 sec/batch; 19h:15m:11s remains)
INFO - root - 2017-12-17 05:41:09.962424: step 36530, loss = 0.10, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 18h:25m:05s remains)
INFO - root - 2017-12-17 05:41:12.154394: step 36540, loss = 0.10, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 17h:56m:26s remains)
INFO - root - 2017-12-17 05:41:14.398975: step 36550, loss = 0.13, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 18h:24m:44s remains)
INFO - root - 2017-12-17 05:41:16.661723: step 36560, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.228 sec/batch; 18h:42m:19s remains)
INFO - root - 2017-12-17 05:41:18.901877: step 36570, loss = 0.11, batch loss = 0.08 (34.7 examples/sec; 0.231 sec/batch; 18h:57m:13s remains)
INFO - root - 2017-12-17 05:41:21.118218: step 36580, loss = 0.16, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 18h:06m:59s remains)
INFO - root - 2017-12-17 05:41:23.356566: step 36590, loss = 0.10, batch loss = 0.07 (35.0 examples/sec; 0.229 sec/batch; 18h:48m:49s remains)
INFO - root - 2017-12-17 05:41:25.593989: step 36600, loss = 0.17, batch loss = 0.13 (35.5 examples/sec; 0.226 sec/batch; 18h:32m:20s remains)
INFO - root - 2017-12-17 05:41:27.958455: step 36610, loss = 0.09, batch loss = 0.05 (36.2 examples/sec; 0.221 sec/batch; 18h:08m:41s remains)
INFO - root - 2017-12-17 05:41:30.191961: step 36620, loss = 0.13, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 18h:34m:15s remains)
INFO - root - 2017-12-17 05:41:32.395992: step 36630, loss = 0.12, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 18h:19m:44s remains)
INFO - root - 2017-12-17 05:41:34.662799: step 36640, loss = 0.13, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 18h:04m:16s remains)
INFO - root - 2017-12-17 05:41:36.886187: step 36650, loss = 0.11, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 18h:02m:53s remains)
INFO - root - 2017-12-17 05:41:39.176652: step 36660, loss = 0.08, batch loss = 0.05 (35.2 examples/sec; 0.228 sec/batch; 18h:42m:01s remains)
INFO - root - 2017-12-17 05:41:41.423071: step 36670, loss = 0.10, batch loss = 0.06 (36.1 examples/sec; 0.221 sec/batch; 18h:11m:27s remains)
INFO - root - 2017-12-17 05:41:43.691647: step 36680, loss = 0.15, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 17h:59m:47s remains)
INFO - root - 2017-12-17 05:41:45.939567: step 36690, loss = 0.10, batch loss = 0.06 (35.6 examples/sec; 0.225 sec/batch; 18h:28m:31s remains)
INFO - root - 2017-12-17 05:41:48.196140: step 36700, loss = 0.11, batch loss = 0.08 (35.3 examples/sec; 0.226 sec/batch; 18h:36m:32s remains)
INFO - root - 2017-12-17 05:41:50.577107: step 36710, loss = 0.12, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 18h:33m:13s remains)
INFO - root - 2017-12-17 05:41:52.780996: step 36720, loss = 0.13, batch loss = 0.09 (35.0 examples/sec; 0.228 sec/batch; 18h:45m:45s remains)
INFO - root - 2017-12-17 05:41:55.056455: step 36730, loss = 0.09, batch loss = 0.05 (36.5 examples/sec; 0.219 sec/batch; 18h:01m:29s remains)
INFO - root - 2017-12-17 05:41:57.306699: step 36740, loss = 0.15, batch loss = 0.11 (34.2 examples/sec; 0.234 sec/batch; 19h:12m:40s remains)
INFO - root - 2017-12-17 05:41:59.583328: step 36750, loss = 0.12, batch loss = 0.09 (34.2 examples/sec; 0.234 sec/batch; 19h:11m:58s remains)
INFO - root - 2017-12-17 05:42:01.826733: step 36760, loss = 0.10, batch loss = 0.07 (33.9 examples/sec; 0.236 sec/batch; 19h:22m:00s remains)
INFO - root - 2017-12-17 05:42:04.064022: step 36770, loss = 0.11, batch loss = 0.07 (35.6 examples/sec; 0.224 sec/batch; 18h:26m:13s remains)
INFO - root - 2017-12-17 05:42:06.308212: step 36780, loss = 0.10, batch loss = 0.07 (35.1 examples/sec; 0.228 sec/batch; 18h:42m:50s remains)
INFO - root - 2017-12-17 05:42:08.555022: step 36790, loss = 0.10, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 18h:03m:45s remains)
INFO - root - 2017-12-17 05:42:10.803683: step 36800, loss = 0.12, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 18h:02m:18s remains)
INFO - root - 2017-12-17 05:42:13.194886: step 36810, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:02m:49s remains)
INFO - root - 2017-12-17 05:42:15.418558: step 36820, loss = 0.11, batch loss = 0.08 (35.1 examples/sec; 0.228 sec/batch; 18h:41m:42s remains)
INFO - root - 2017-12-17 05:42:17.680116: step 36830, loss = 0.12, batch loss = 0.09 (34.1 examples/sec; 0.235 sec/batch; 19h:17m:15s remains)
INFO - root - 2017-12-17 05:42:19.892597: step 36840, loss = 0.09, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 18h:04m:07s remains)
INFO - root - 2017-12-17 05:42:22.157322: step 36850, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:28m:45s remains)
INFO - root - 2017-12-17 05:42:24.395322: step 36860, loss = 0.13, batch loss = 0.10 (35.5 examples/sec; 0.226 sec/batch; 18h:31m:26s remains)
INFO - root - 2017-12-17 05:42:26.651046: step 36870, loss = 0.12, batch loss = 0.09 (34.7 examples/sec; 0.230 sec/batch; 18h:55m:17s remains)
INFO - root - 2017-12-17 05:42:28.884762: step 36880, loss = 0.13, batch loss = 0.09 (36.1 examples/sec; 0.221 sec/batch; 18h:11m:14s remains)
INFO - root - 2017-12-17 05:42:31.091431: step 36890, loss = 0.09, batch loss = 0.05 (35.6 examples/sec; 0.224 sec/batch; 18h:25m:44s remains)
INFO - root - 2017-12-17 05:42:33.327653: step 36900, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:08m:47s remains)
INFO - root - 2017-12-17 05:42:35.725845: step 36910, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:26m:05s remains)
INFO - root - 2017-12-17 05:42:37.997906: step 36920, loss = 0.11, batch loss = 0.08 (34.4 examples/sec; 0.232 sec/batch; 19h:04m:56s remains)
INFO - root - 2017-12-17 05:42:40.274623: step 36930, loss = 0.11, batch loss = 0.08 (35.4 examples/sec; 0.226 sec/batch; 18h:34m:05s remains)
INFO - root - 2017-12-17 05:42:42.522244: step 36940, loss = 0.10, batch loss = 0.06 (34.8 examples/sec; 0.230 sec/batch; 18h:53m:24s remains)
INFO - root - 2017-12-17 05:42:44.788780: step 36950, loss = 0.08, batch loss = 0.04 (35.2 examples/sec; 0.228 sec/batch; 18h:40m:47s remains)
INFO - root - 2017-12-17 05:42:47.001899: step 36960, loss = 0.13, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 18h:36m:35s remains)
INFO - root - 2017-12-17 05:42:49.241355: step 36970, loss = 0.12, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 18h:15m:18s remains)
INFO - root - 2017-12-17 05:42:51.461734: step 36980, loss = 0.11, batch loss = 0.08 (36.1 examples/sec; 0.221 sec/batch; 18h:10m:57s remains)
INFO - root - 2017-12-17 05:42:53.679048: step 36990, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:07m:54s remains)
INFO - root - 2017-12-17 05:42:55.924390: step 37000, loss = 0.12, batch loss = 0.08 (34.9 examples/sec; 0.229 sec/batch; 18h:50m:13s remains)
INFO - root - 2017-12-17 05:42:58.276108: step 37010, loss = 0.13, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:24m:14s remains)
INFO - root - 2017-12-17 05:43:00.515676: step 37020, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:09m:39s remains)
INFO - root - 2017-12-17 05:43:02.783301: step 37030, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.221 sec/batch; 18h:06m:01s remains)
INFO - root - 2017-12-17 05:43:05.031502: step 37040, loss = 0.08, batch loss = 0.05 (36.2 examples/sec; 0.221 sec/batch; 18h:07m:42s remains)
INFO - root - 2017-12-17 05:43:07.227700: step 37050, loss = 0.10, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 18h:16m:09s remains)
INFO - root - 2017-12-17 05:43:09.468271: step 37060, loss = 0.12, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 18h:18m:20s remains)
INFO - root - 2017-12-17 05:43:11.732699: step 37070, loss = 0.11, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 18h:10m:50s remains)
INFO - root - 2017-12-17 05:43:13.938110: step 37080, loss = 0.10, batch loss = 0.06 (37.1 examples/sec; 0.216 sec/batch; 17h:43m:05s remains)
INFO - root - 2017-12-17 05:43:16.151361: step 37090, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 18h:11m:01s remains)
INFO - root - 2017-12-17 05:43:18.386863: step 37100, loss = 0.08, batch loss = 0.05 (35.0 examples/sec; 0.229 sec/batch; 18h:46m:47s remains)
INFO - root - 2017-12-17 05:43:20.762945: step 37110, loss = 0.09, batch loss = 0.05 (34.9 examples/sec; 0.229 sec/batch; 18h:48m:10s remains)
INFO - root - 2017-12-17 05:43:23.041135: step 37120, loss = 0.10, batch loss = 0.07 (35.4 examples/sec; 0.226 sec/batch; 18h:32m:35s remains)
INFO - root - 2017-12-17 05:43:25.259643: step 37130, loss = 0.12, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 18h:12m:33s remains)
INFO - root - 2017-12-17 05:43:27.485158: step 37140, loss = 0.11, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:01m:03s remains)
INFO - root - 2017-12-17 05:43:29.716805: step 37150, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 18h:21m:13s remains)
INFO - root - 2017-12-17 05:43:31.968322: step 37160, loss = 0.10, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 18h:07m:40s remains)
INFO - root - 2017-12-17 05:43:34.221220: step 37170, loss = 0.10, batch loss = 0.07 (34.4 examples/sec; 0.232 sec/batch; 19h:03m:43s remains)
INFO - root - 2017-12-17 05:43:36.473242: step 37180, loss = 0.11, batch loss = 0.08 (35.1 examples/sec; 0.228 sec/batch; 18h:41m:48s remains)
INFO - root - 2017-12-17 05:43:38.708970: step 37190, loss = 0.11, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 17h:55m:53s remains)
INFO - root - 2017-12-17 05:43:40.957127: step 37200, loss = 0.11, batch loss = 0.08 (35.6 examples/sec; 0.224 sec/batch; 18h:24m:27s remains)
INFO - root - 2017-12-17 05:43:43.335043: step 37210, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:07m:32s remains)
INFO - root - 2017-12-17 05:43:45.568876: step 37220, loss = 0.10, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 18h:07m:36s remains)
INFO - root - 2017-12-17 05:43:47.798196: step 37230, loss = 0.12, batch loss = 0.09 (35.8 examples/sec; 0.224 sec/batch; 18h:20m:25s remains)
INFO - root - 2017-12-17 05:43:50.024228: step 37240, loss = 0.13, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 17h:55m:44s remains)
INFO - root - 2017-12-17 05:43:52.253426: step 37250, loss = 0.14, batch loss = 0.11 (37.6 examples/sec; 0.213 sec/batch; 17h:28m:10s remains)
INFO - root - 2017-12-17 05:43:54.503759: step 37260, loss = 0.12, batch loss = 0.09 (34.9 examples/sec; 0.229 sec/batch; 18h:46m:43s remains)
INFO - root - 2017-12-17 05:43:56.742172: step 37270, loss = 0.15, batch loss = 0.12 (36.6 examples/sec; 0.219 sec/batch; 17h:56m:25s remains)
INFO - root - 2017-12-17 05:43:58.986425: step 37280, loss = 0.11, batch loss = 0.07 (35.5 examples/sec; 0.225 sec/batch; 18h:28m:57s remains)
INFO - root - 2017-12-17 05:44:01.225609: step 37290, loss = 0.13, batch loss = 0.10 (34.5 examples/sec; 0.232 sec/batch; 19h:01m:03s remains)
INFO - root - 2017-12-17 05:44:03.458891: step 37300, loss = 0.09, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 18h:16m:49s remains)
INFO - root - 2017-12-17 05:44:05.801411: step 37310, loss = 0.10, batch loss = 0.06 (34.8 examples/sec; 0.230 sec/batch; 18h:50m:18s remains)
INFO - root - 2017-12-17 05:44:08.056238: step 37320, loss = 0.12, batch loss = 0.08 (34.9 examples/sec; 0.229 sec/batch; 18h:47m:26s remains)
INFO - root - 2017-12-17 05:44:10.291813: step 37330, loss = 0.11, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 18h:22m:33s remains)
INFO - root - 2017-12-17 05:44:12.502278: step 37340, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 18h:14m:22s remains)
INFO - root - 2017-12-17 05:44:14.749636: step 37350, loss = 0.12, batch loss = 0.09 (35.5 examples/sec; 0.225 sec/batch; 18h:27m:07s remains)
INFO - root - 2017-12-17 05:44:17.021293: step 37360, loss = 0.09, batch loss = 0.06 (34.9 examples/sec; 0.230 sec/batch; 18h:48m:55s remains)
INFO - root - 2017-12-17 05:44:19.278228: step 37370, loss = 0.11, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:24m:47s remains)
INFO - root - 2017-12-17 05:44:21.503633: step 37380, loss = 0.13, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 17h:55m:11s remains)
INFO - root - 2017-12-17 05:44:23.752646: step 37390, loss = 0.11, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 18h:16m:49s remains)
INFO - root - 2017-12-17 05:44:25.994557: step 37400, loss = 0.10, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 17h:55m:59s remains)
INFO - root - 2017-12-17 05:44:28.403234: step 37410, loss = 0.09, batch loss = 0.05 (35.2 examples/sec; 0.228 sec/batch; 18h:39m:17s remains)
INFO - root - 2017-12-17 05:44:30.625510: step 37420, loss = 0.11, batch loss = 0.08 (35.1 examples/sec; 0.228 sec/batch; 18h:40m:06s remains)
INFO - root - 2017-12-17 05:44:32.846087: step 37430, loss = 0.09, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 18h:15m:58s remains)
INFO - root - 2017-12-17 05:44:35.089848: step 37440, loss = 0.10, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 18h:22m:37s remains)
INFO - root - 2017-12-17 05:44:37.318750: step 37450, loss = 0.17, batch loss = 0.13 (34.7 examples/sec; 0.230 sec/batch; 18h:53m:22s remains)
INFO - root - 2017-12-17 05:44:39.612424: step 37460, loss = 0.10, batch loss = 0.07 (33.9 examples/sec; 0.236 sec/batch; 19h:18m:59s remains)
INFO - root - 2017-12-17 05:44:41.844752: step 37470, loss = 0.10, batch loss = 0.06 (36.8 examples/sec; 0.217 sec/batch; 17h:48m:57s remains)
INFO - root - 2017-12-17 05:44:44.071047: step 37480, loss = 0.08, batch loss = 0.05 (34.9 examples/sec; 0.229 sec/batch; 18h:47m:30s remains)
INFO - root - 2017-12-17 05:44:46.311380: step 37490, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 18h:01m:13s remains)
INFO - root - 2017-12-17 05:44:48.541625: step 37500, loss = 0.19, batch loss = 0.15 (36.5 examples/sec; 0.219 sec/batch; 17h:58m:12s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-37500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-37500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 05:44:51.378624: step 37510, loss = 0.11, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 18h:06m:22s remains)
INFO - root - 2017-12-17 05:44:53.575077: step 37520, loss = 0.08, batch loss = 0.05 (37.2 examples/sec; 0.215 sec/batch; 17h:37m:13s remains)
INFO - root - 2017-12-17 05:44:55.766385: step 37530, loss = 0.10, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 18h:00m:48s remains)
INFO - root - 2017-12-17 05:44:57.979827: step 37540, loss = 0.13, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 18h:00m:43s remains)
INFO - root - 2017-12-17 05:45:00.221407: step 37550, loss = 0.13, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 18h:10m:16s remains)
INFO - root - 2017-12-17 05:45:02.467713: step 37560, loss = 0.13, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:22m:40s remains)
INFO - root - 2017-12-17 05:45:04.709558: step 37570, loss = 0.11, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 17h:51m:38s remains)
INFO - root - 2017-12-17 05:45:06.917738: step 37580, loss = 0.12, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 18h:06m:32s remains)
INFO - root - 2017-12-17 05:45:09.165697: step 37590, loss = 0.11, batch loss = 0.08 (35.2 examples/sec; 0.227 sec/batch; 18h:36m:47s remains)
INFO - root - 2017-12-17 05:45:11.409209: step 37600, loss = 0.19, batch loss = 0.15 (36.4 examples/sec; 0.220 sec/batch; 17h:59m:36s remains)
INFO - root - 2017-12-17 05:45:13.734803: step 37610, loss = 0.09, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 18h:00m:17s remains)
INFO - root - 2017-12-17 05:45:15.957645: step 37620, loss = 0.12, batch loss = 0.08 (36.1 examples/sec; 0.222 sec/batch; 18h:08m:46s remains)
INFO - root - 2017-12-17 05:45:18.231209: step 37630, loss = 0.08, batch loss = 0.05 (36.1 examples/sec; 0.221 sec/batch; 18h:07m:47s remains)
INFO - root - 2017-12-17 05:45:20.466788: step 37640, loss = 0.12, batch loss = 0.09 (37.4 examples/sec; 0.214 sec/batch; 17h:32m:05s remains)
INFO - root - 2017-12-17 05:45:22.706606: step 37650, loss = 0.12, batch loss = 0.08 (35.5 examples/sec; 0.225 sec/batch; 18h:26m:48s remains)
INFO - root - 2017-12-17 05:45:24.936176: step 37660, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 18h:09m:00s remains)
INFO - root - 2017-12-17 05:45:27.180894: step 37670, loss = 0.11, batch loss = 0.08 (35.5 examples/sec; 0.225 sec/batch; 18h:26m:10s remains)
INFO - root - 2017-12-17 05:45:29.435977: step 37680, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 18h:12m:44s remains)
INFO - root - 2017-12-17 05:45:31.673643: step 37690, loss = 0.13, batch loss = 0.09 (36.3 examples/sec; 0.220 sec/batch; 18h:03m:03s remains)
INFO - root - 2017-12-17 05:45:33.900979: step 37700, loss = 0.15, batch loss = 0.11 (36.8 examples/sec; 0.217 sec/batch; 17h:47m:33s remains)
INFO - root - 2017-12-17 05:45:36.260094: step 37710, loss = 0.13, batch loss = 0.09 (35.2 examples/sec; 0.227 sec/batch; 18h:35m:19s remains)
INFO - root - 2017-12-17 05:45:38.502038: step 37720, loss = 0.10, batch loss = 0.07 (37.3 examples/sec; 0.215 sec/batch; 17h:34m:37s remains)
INFO - root - 2017-12-17 05:45:40.743055: step 37730, loss = 0.10, batch loss = 0.06 (35.1 examples/sec; 0.228 sec/batch; 18h:39m:58s remains)
INFO - root - 2017-12-17 05:45:42.966312: step 37740, loss = 0.12, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 18h:24m:07s remains)
INFO - root - 2017-12-17 05:45:45.176675: step 37750, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.224 sec/batch; 18h:18m:43s remains)
INFO - root - 2017-12-17 05:45:47.402130: step 37760, loss = 0.11, batch loss = 0.08 (34.6 examples/sec; 0.231 sec/batch; 18h:56m:46s remains)
INFO - root - 2017-12-17 05:45:49.633541: step 37770, loss = 0.10, batch loss = 0.07 (35.4 examples/sec; 0.226 sec/batch; 18h:29m:25s remains)
INFO - root - 2017-12-17 05:45:51.878911: step 37780, loss = 0.10, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 18h:19m:16s remains)
INFO - root - 2017-12-17 05:45:54.138231: step 37790, loss = 0.10, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 17h:49m:49s remains)
INFO - root - 2017-12-17 05:45:56.350306: step 37800, loss = 0.11, batch loss = 0.08 (36.7 examples/sec; 0.218 sec/batch; 17h:51m:59s remains)
INFO - root - 2017-12-17 05:45:58.692339: step 37810, loss = 0.11, batch loss = 0.07 (34.7 examples/sec; 0.230 sec/batch; 18h:50m:48s remains)
INFO - root - 2017-12-17 05:46:00.925647: step 37820, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.221 sec/batch; 18h:03m:40s remains)
INFO - root - 2017-12-17 05:46:03.137700: step 37830, loss = 0.11, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 18h:11m:29s remains)
INFO - root - 2017-12-17 05:46:05.347073: step 37840, loss = 0.11, batch loss = 0.07 (36.6 examples/sec; 0.218 sec/batch; 17h:52m:40s remains)
INFO - root - 2017-12-17 05:46:07.559035: step 37850, loss = 0.10, batch loss = 0.06 (35.6 examples/sec; 0.224 sec/batch; 18h:22m:18s remains)
INFO - root - 2017-12-17 05:46:09.815909: step 37860, loss = 0.12, batch loss = 0.09 (36.7 examples/sec; 0.218 sec/batch; 17h:48m:59s remains)
INFO - root - 2017-12-17 05:46:12.053175: step 37870, loss = 0.08, batch loss = 0.05 (35.5 examples/sec; 0.225 sec/batch; 18h:25m:11s remains)
INFO - root - 2017-12-17 05:46:14.285279: step 37880, loss = 0.11, batch loss = 0.08 (36.6 examples/sec; 0.218 sec/batch; 17h:52m:37s remains)
INFO - root - 2017-12-17 05:46:16.534934: step 37890, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 18h:21m:27s remains)
INFO - root - 2017-12-17 05:46:18.757192: step 37900, loss = 0.13, batch loss = 0.09 (34.7 examples/sec; 0.230 sec/batch; 18h:50m:25s remains)
INFO - root - 2017-12-17 05:46:21.188473: step 37910, loss = 0.09, batch loss = 0.06 (34.4 examples/sec; 0.232 sec/batch; 19h:01m:29s remains)
INFO - root - 2017-12-17 05:46:23.457445: step 37920, loss = 0.09, batch loss = 0.06 (35.5 examples/sec; 0.225 sec/batch; 18h:26m:36s remains)
INFO - root - 2017-12-17 05:46:25.674109: step 37930, loss = 0.13, batch loss = 0.10 (37.1 examples/sec; 0.216 sec/batch; 17h:38m:24s remains)
INFO - root - 2017-12-17 05:46:27.915919: step 37940, loss = 0.17, batch loss = 0.14 (35.6 examples/sec; 0.224 sec/batch; 18h:22m:00s remains)
INFO - root - 2017-12-17 05:46:30.145886: step 37950, loss = 0.09, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 17h:59m:00s remains)
INFO - root - 2017-12-17 05:46:32.433159: step 37960, loss = 0.12, batch loss = 0.09 (34.5 examples/sec; 0.232 sec/batch; 18h:57m:16s remains)
INFO - root - 2017-12-17 05:46:34.667190: step 37970, loss = 0.10, batch loss = 0.06 (35.0 examples/sec; 0.229 sec/batch; 18h:42m:49s remains)
INFO - root - 2017-12-17 05:46:36.896671: step 37980, loss = 0.10, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 17h:56m:52s remains)
INFO - root - 2017-12-17 05:46:39.111800: step 37990, loss = 0.14, batch loss = 0.10 (36.8 examples/sec; 0.217 sec/batch; 17h:46m:52s remains)
INFO - root - 2017-12-17 05:46:41.330245: step 38000, loss = 0.11, batch loss = 0.08 (35.1 examples/sec; 0.228 sec/batch; 18h:37m:52s remains)
INFO - root - 2017-12-17 05:46:43.720448: step 38010, loss = 0.11, batch loss = 0.07 (34.8 examples/sec; 0.230 sec/batch; 18h:48m:57s remains)
INFO - root - 2017-12-17 05:46:45.941013: step 38020, loss = 0.13, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 17h:55m:28s remains)
INFO - root - 2017-12-17 05:46:48.172446: step 38030, loss = 0.09, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 17h:59m:16s remains)
INFO - root - 2017-12-17 05:46:50.399739: step 38040, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:03m:26s remains)
INFO - root - 2017-12-17 05:46:52.622217: step 38050, loss = 0.11, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 17h:58m:00s remains)
INFO - root - 2017-12-17 05:46:54.866031: step 38060, loss = 0.21, batch loss = 0.18 (35.7 examples/sec; 0.224 sec/batch; 18h:20m:15s remains)
INFO - root - 2017-12-17 05:46:57.104530: step 38070, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 18h:00m:36s remains)
INFO - root - 2017-12-17 05:46:59.317499: step 38080, loss = 0.15, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 18h:05m:27s remains)
INFO - root - 2017-12-17 05:47:01.556560: step 38090, loss = 0.14, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:38m:39s remains)
INFO - root - 2017-12-17 05:47:03.767691: step 38100, loss = 0.12, batch loss = 0.09 (36.8 examples/sec; 0.217 sec/batch; 17h:46m:43s remains)
INFO - root - 2017-12-17 05:47:06.151522: step 38110, loss = 0.10, batch loss = 0.07 (36.9 examples/sec; 0.217 sec/batch; 17h:44m:39s remains)
INFO - root - 2017-12-17 05:47:08.389144: step 38120, loss = 0.10, batch loss = 0.07 (35.5 examples/sec; 0.225 sec/batch; 18h:24m:13s remains)
INFO - root - 2017-12-17 05:47:10.660367: step 38130, loss = 0.11, batch loss = 0.08 (36.7 examples/sec; 0.218 sec/batch; 17h:49m:30s remains)
INFO - root - 2017-12-17 05:47:12.880349: step 38140, loss = 0.13, batch loss = 0.10 (36.7 examples/sec; 0.218 sec/batch; 17h:48m:10s remains)
INFO - root - 2017-12-17 05:47:15.083034: step 38150, loss = 0.23, batch loss = 0.19 (36.1 examples/sec; 0.221 sec/batch; 18h:06m:32s remains)
INFO - root - 2017-12-17 05:47:17.310236: step 38160, loss = 0.09, batch loss = 0.06 (34.7 examples/sec; 0.230 sec/batch; 18h:50m:38s remains)
INFO - root - 2017-12-17 05:47:19.590979: step 38170, loss = 0.12, batch loss = 0.09 (33.2 examples/sec; 0.241 sec/batch; 19h:42m:35s remains)
INFO - root - 2017-12-17 05:47:21.859426: step 38180, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 18h:00m:51s remains)
INFO - root - 2017-12-17 05:47:24.076774: step 38190, loss = 0.10, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 17h:57m:49s remains)
INFO - root - 2017-12-17 05:47:26.273306: step 38200, loss = 0.13, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 17h:53m:09s remains)
INFO - root - 2017-12-17 05:47:28.628060: step 38210, loss = 0.12, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 18h:14m:08s remains)
INFO - root - 2017-12-17 05:47:30.864226: step 38220, loss = 0.12, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 18h:03m:42s remains)
INFO - root - 2017-12-17 05:47:33.084019: step 38230, loss = 0.13, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 18h:00m:28s remains)
INFO - root - 2017-12-17 05:47:35.316212: step 38240, loss = 0.11, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:22m:29s remains)
INFO - root - 2017-12-17 05:47:37.550257: step 38250, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 18h:09m:26s remains)
INFO - root - 2017-12-17 05:47:39.836166: step 38260, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 18h:18m:50s remains)
INFO - root - 2017-12-17 05:47:42.071213: step 38270, loss = 0.11, batch loss = 0.07 (36.3 examples/sec; 0.221 sec/batch; 18h:01m:46s remains)
INFO - root - 2017-12-17 05:47:44.301790: step 38280, loss = 0.10, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 18h:07m:43s remains)
INFO - root - 2017-12-17 05:47:46.546774: step 38290, loss = 0.09, batch loss = 0.05 (34.5 examples/sec; 0.232 sec/batch; 18h:56m:54s remains)
INFO - root - 2017-12-17 05:47:48.785697: step 38300, loss = 0.13, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:18m:54s remains)
INFO - root - 2017-12-17 05:47:51.164072: step 38310, loss = 0.14, batch loss = 0.11 (36.3 examples/sec; 0.220 sec/batch; 17h:59m:10s remains)
INFO - root - 2017-12-17 05:47:53.413437: step 38320, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 18h:33m:01s remains)
INFO - root - 2017-12-17 05:47:55.622662: step 38330, loss = 0.14, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 17h:56m:25s remains)
INFO - root - 2017-12-17 05:47:57.871982: step 38340, loss = 0.09, batch loss = 0.06 (37.0 examples/sec; 0.216 sec/batch; 17h:39m:36s remains)
INFO - root - 2017-12-17 05:48:00.122165: step 38350, loss = 0.12, batch loss = 0.09 (35.8 examples/sec; 0.223 sec/batch; 18h:14m:58s remains)
INFO - root - 2017-12-17 05:48:02.394531: step 38360, loss = 0.13, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 18h:16m:47s remains)
INFO - root - 2017-12-17 05:48:04.624648: step 38370, loss = 0.14, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:44m:21s remains)
INFO - root - 2017-12-17 05:48:06.910600: step 38380, loss = 0.11, batch loss = 0.08 (33.5 examples/sec; 0.239 sec/batch; 19h:29m:53s remains)
INFO - root - 2017-12-17 05:48:09.191029: step 38390, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:22m:03s remains)
INFO - root - 2017-12-17 05:48:11.377899: step 38400, loss = 0.10, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 18h:12m:47s remains)
INFO - root - 2017-12-17 05:48:13.749225: step 38410, loss = 0.11, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 17h:55m:17s remains)
INFO - root - 2017-12-17 05:48:15.962120: step 38420, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 18h:16m:05s remains)
INFO - root - 2017-12-17 05:48:18.169990: step 38430, loss = 0.09, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 17h:57m:45s remains)
INFO - root - 2017-12-17 05:48:20.410171: step 38440, loss = 0.12, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 18h:03m:10s remains)
INFO - root - 2017-12-17 05:48:22.622096: step 38450, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.221 sec/batch; 18h:05m:17s remains)
INFO - root - 2017-12-17 05:48:24.844752: step 38460, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 18h:16m:30s remains)
INFO - root - 2017-12-17 05:48:27.092666: step 38470, loss = 0.11, batch loss = 0.08 (34.2 examples/sec; 0.234 sec/batch; 19h:07m:06s remains)
INFO - root - 2017-12-17 05:48:29.391091: step 38480, loss = 0.14, batch loss = 0.10 (34.9 examples/sec; 0.229 sec/batch; 18h:42m:06s remains)
INFO - root - 2017-12-17 05:48:31.646123: step 38490, loss = 0.10, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 18h:19m:12s remains)
INFO - root - 2017-12-17 05:48:33.921606: step 38500, loss = 0.10, batch loss = 0.07 (34.7 examples/sec; 0.231 sec/batch; 18h:51m:01s remains)
INFO - root - 2017-12-17 05:48:36.325250: step 38510, loss = 0.09, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 18h:10m:05s remains)
INFO - root - 2017-12-17 05:48:38.542123: step 38520, loss = 0.10, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 18h:13m:06s remains)
INFO - root - 2017-12-17 05:48:40.748625: step 38530, loss = 0.17, batch loss = 0.14 (36.4 examples/sec; 0.220 sec/batch; 17h:56m:09s remains)
INFO - root - 2017-12-17 05:48:42.977531: step 38540, loss = 0.09, batch loss = 0.06 (35.1 examples/sec; 0.228 sec/batch; 18h:37m:20s remains)
INFO - root - 2017-12-17 05:48:45.189413: step 38550, loss = 0.11, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 17h:49m:05s remains)
INFO - root - 2017-12-17 05:48:47.428691: step 38560, loss = 0.11, batch loss = 0.07 (35.1 examples/sec; 0.228 sec/batch; 18h:35m:50s remains)
INFO - root - 2017-12-17 05:48:49.677894: step 38570, loss = 0.10, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 18h:11m:06s remains)
INFO - root - 2017-12-17 05:48:51.913708: step 38580, loss = 0.10, batch loss = 0.06 (36.9 examples/sec; 0.217 sec/batch; 17h:40m:50s remains)
INFO - root - 2017-12-17 05:48:54.138096: step 38590, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.221 sec/batch; 18h:04m:51s remains)
INFO - root - 2017-12-17 05:48:56.387720: step 38600, loss = 0.11, batch loss = 0.08 (34.7 examples/sec; 0.230 sec/batch; 18h:47m:43s remains)
INFO - root - 2017-12-17 05:48:58.759207: step 38610, loss = 0.10, batch loss = 0.07 (35.0 examples/sec; 0.229 sec/batch; 18h:40m:17s remains)
INFO - root - 2017-12-17 05:49:00.976663: step 38620, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 18h:05m:42s remains)
INFO - root - 2017-12-17 05:49:03.229601: step 38630, loss = 0.12, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 18h:02m:02s remains)
INFO - root - 2017-12-17 05:49:05.428660: step 38640, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:02m:28s remains)
INFO - root - 2017-12-17 05:49:07.680010: step 38650, loss = 0.13, batch loss = 0.10 (35.5 examples/sec; 0.226 sec/batch; 18h:25m:04s remains)
INFO - root - 2017-12-17 05:49:09.938624: step 38660, loss = 0.12, batch loss = 0.09 (35.3 examples/sec; 0.226 sec/batch; 18h:28m:47s remains)
INFO - root - 2017-12-17 05:49:12.135828: step 38670, loss = 0.10, batch loss = 0.06 (36.9 examples/sec; 0.217 sec/batch; 17h:41m:34s remains)
INFO - root - 2017-12-17 05:49:14.341753: step 38680, loss = 0.12, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 18h:26m:10s remains)
INFO - root - 2017-12-17 05:49:16.588922: step 38690, loss = 0.11, batch loss = 0.08 (36.7 examples/sec; 0.218 sec/batch; 17h:47m:22s remains)
INFO - root - 2017-12-17 05:49:18.805821: step 38700, loss = 0.11, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 17h:55m:10s remains)
INFO - root - 2017-12-17 05:49:21.174637: step 38710, loss = 0.15, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 18h:14m:48s remains)
INFO - root - 2017-12-17 05:49:23.425347: step 38720, loss = 0.09, batch loss = 0.06 (35.5 examples/sec; 0.225 sec/batch; 18h:23m:22s remains)
INFO - root - 2017-12-17 05:49:25.634850: step 38730, loss = 0.10, batch loss = 0.06 (36.8 examples/sec; 0.218 sec/batch; 17h:45m:19s remains)
INFO - root - 2017-12-17 05:49:27.804451: step 38740, loss = 0.12, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 18h:02m:50s remains)
INFO - root - 2017-12-17 05:49:30.017838: step 38750, loss = 0.10, batch loss = 0.07 (37.2 examples/sec; 0.215 sec/batch; 17h:33m:14s remains)
INFO - root - 2017-12-17 05:49:32.259427: step 38760, loss = 0.11, batch loss = 0.08 (35.2 examples/sec; 0.227 sec/batch; 18h:33m:21s remains)
INFO - root - 2017-12-17 05:49:34.505177: step 38770, loss = 0.13, batch loss = 0.09 (35.8 examples/sec; 0.223 sec/batch; 18h:12m:55s remains)
INFO - root - 2017-12-17 05:49:36.693707: step 38780, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.221 sec/batch; 18h:00m:04s remains)
INFO - root - 2017-12-17 05:49:38.931322: step 38790, loss = 0.11, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 18h:09m:39s remains)
INFO - root - 2017-12-17 05:49:41.206913: step 38800, loss = 0.11, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 17h:50m:46s remains)
INFO - root - 2017-12-17 05:49:43.537587: step 38810, loss = 0.09, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 18h:08m:59s remains)
INFO - root - 2017-12-17 05:49:45.767899: step 38820, loss = 0.17, batch loss = 0.13 (35.3 examples/sec; 0.226 sec/batch; 18h:27m:50s remains)
INFO - root - 2017-12-17 05:49:47.995004: step 38830, loss = 0.10, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 17h:49m:37s remains)
INFO - root - 2017-12-17 05:49:50.212194: step 38840, loss = 0.09, batch loss = 0.06 (35.4 examples/sec; 0.226 sec/batch; 18h:24m:32s remains)
INFO - root - 2017-12-17 05:49:52.450300: step 38850, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 17h:57m:22s remains)
INFO - root - 2017-12-17 05:49:54.704480: step 38860, loss = 0.08, batch loss = 0.05 (34.4 examples/sec; 0.233 sec/batch; 18h:58m:57s remains)
INFO - root - 2017-12-17 05:49:57.000252: step 38870, loss = 0.13, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 18h:26m:20s remains)
INFO - root - 2017-12-17 05:49:59.234232: step 38880, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.223 sec/batch; 18h:13m:16s remains)
INFO - root - 2017-12-17 05:50:01.460994: step 38890, loss = 0.09, batch loss = 0.05 (36.4 examples/sec; 0.220 sec/batch; 17h:54m:26s remains)
INFO - root - 2017-12-17 05:50:03.697838: step 38900, loss = 0.12, batch loss = 0.09 (34.2 examples/sec; 0.234 sec/batch; 19h:03m:35s remains)
INFO - root - 2017-12-17 05:50:06.015586: step 38910, loss = 0.09, batch loss = 0.05 (35.6 examples/sec; 0.225 sec/batch; 18h:19m:53s remains)
INFO - root - 2017-12-17 05:50:08.228810: step 38920, loss = 0.10, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 17h:56m:19s remains)
INFO - root - 2017-12-17 05:50:10.452527: step 38930, loss = 0.09, batch loss = 0.06 (35.5 examples/sec; 0.225 sec/batch; 18h:21m:26s remains)
INFO - root - 2017-12-17 05:50:12.664222: step 38940, loss = 0.11, batch loss = 0.08 (34.4 examples/sec; 0.233 sec/batch; 18h:58m:01s remains)
INFO - root - 2017-12-17 05:50:14.913521: step 38950, loss = 0.14, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:07m:08s remains)
INFO - root - 2017-12-17 05:50:17.145058: step 38960, loss = 0.12, batch loss = 0.09 (37.1 examples/sec; 0.216 sec/batch; 17h:35m:52s remains)
INFO - root - 2017-12-17 05:50:19.371610: step 38970, loss = 0.14, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:15m:23s remains)
INFO - root - 2017-12-17 05:50:21.610109: step 38980, loss = 0.12, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 18h:07m:43s remains)
INFO - root - 2017-12-17 05:50:23.882377: step 38990, loss = 0.13, batch loss = 0.09 (35.0 examples/sec; 0.228 sec/batch; 18h:37m:27s remains)
INFO - root - 2017-12-17 05:50:26.102762: step 39000, loss = 0.11, batch loss = 0.07 (36.9 examples/sec; 0.217 sec/batch; 17h:41m:03s remains)
INFO - root - 2017-12-17 05:50:28.489526: step 39010, loss = 0.15, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 18h:15m:31s remains)
INFO - root - 2017-12-17 05:50:30.722627: step 39020, loss = 0.11, batch loss = 0.08 (36.1 examples/sec; 0.222 sec/batch; 18h:04m:16s remains)
INFO - root - 2017-12-17 05:50:32.913824: step 39030, loss = 0.10, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 17h:44m:52s remains)
INFO - root - 2017-12-17 05:50:35.144657: step 39040, loss = 0.12, batch loss = 0.08 (35.5 examples/sec; 0.225 sec/batch; 18h:21m:39s remains)
INFO - root - 2017-12-17 05:50:37.394628: step 39050, loss = 0.10, batch loss = 0.07 (35.1 examples/sec; 0.228 sec/batch; 18h:36m:00s remains)
INFO - root - 2017-12-17 05:50:39.722708: step 39060, loss = 0.12, batch loss = 0.08 (31.2 examples/sec; 0.257 sec/batch; 20h:55m:37s remains)
INFO - root - 2017-12-17 05:50:41.948920: step 39070, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 17h:56m:53s remains)
INFO - root - 2017-12-17 05:50:44.165150: step 39080, loss = 0.12, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 18h:00m:50s remains)
INFO - root - 2017-12-17 05:50:46.399845: step 39090, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 18h:01m:40s remains)
INFO - root - 2017-12-17 05:50:48.620730: step 39100, loss = 0.14, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 18h:00m:38s remains)
INFO - root - 2017-12-17 05:50:50.982747: step 39110, loss = 0.11, batch loss = 0.08 (36.1 examples/sec; 0.221 sec/batch; 18h:02m:38s remains)
INFO - root - 2017-12-17 05:50:53.274571: step 39120, loss = 0.10, batch loss = 0.06 (34.6 examples/sec; 0.231 sec/batch; 18h:50m:37s remains)
INFO - root - 2017-12-17 05:50:55.495011: step 39130, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 17h:57m:48s remains)
INFO - root - 2017-12-17 05:50:57.691137: step 39140, loss = 0.10, batch loss = 0.07 (37.2 examples/sec; 0.215 sec/batch; 17h:30m:44s remains)
INFO - root - 2017-12-17 05:50:59.920206: step 39150, loss = 0.11, batch loss = 0.07 (36.9 examples/sec; 0.217 sec/batch; 17h:40m:15s remains)
INFO - root - 2017-12-17 05:51:02.118559: step 39160, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 18h:14m:09s remains)
INFO - root - 2017-12-17 05:51:04.378092: step 39170, loss = 0.12, batch loss = 0.08 (34.7 examples/sec; 0.231 sec/batch; 18h:47m:03s remains)
INFO - root - 2017-12-17 05:51:06.644147: step 39180, loss = 0.11, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 18h:31m:13s remains)
INFO - root - 2017-12-17 05:51:08.906850: step 39190, loss = 0.10, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 18h:09m:09s remains)
INFO - root - 2017-12-17 05:51:11.172144: step 39200, loss = 0.10, batch loss = 0.06 (33.9 examples/sec; 0.236 sec/batch; 19h:12m:08s remains)
INFO - root - 2017-12-17 05:51:13.543692: step 39210, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:17m:25s remains)
INFO - root - 2017-12-17 05:51:15.801837: step 39220, loss = 0.10, batch loss = 0.07 (34.6 examples/sec; 0.231 sec/batch; 18h:49m:09s remains)
INFO - root - 2017-12-17 05:51:18.048017: step 39230, loss = 0.10, batch loss = 0.06 (36.6 examples/sec; 0.219 sec/batch; 17h:48m:52s remains)
INFO - root - 2017-12-17 05:51:20.297373: step 39240, loss = 0.11, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 18h:31m:49s remains)
INFO - root - 2017-12-17 05:51:22.556560: step 39250, loss = 0.11, batch loss = 0.08 (35.5 examples/sec; 0.226 sec/batch; 18h:22m:22s remains)
INFO - root - 2017-12-17 05:51:24.819410: step 39260, loss = 0.10, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 17h:45m:00s remains)
INFO - root - 2017-12-17 05:51:27.048427: step 39270, loss = 0.12, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 17h:53m:15s remains)
INFO - root - 2017-12-17 05:51:29.282095: step 39280, loss = 0.17, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 18h:00m:59s remains)
INFO - root - 2017-12-17 05:51:31.485281: step 39290, loss = 0.12, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 17h:49m:45s remains)
INFO - root - 2017-12-17 05:51:33.695645: step 39300, loss = 0.11, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 18h:18m:55s remains)
INFO - root - 2017-12-17 05:51:36.061259: step 39310, loss = 0.14, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 18h:04m:12s remains)
INFO - root - 2017-12-17 05:51:38.275421: step 39320, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.221 sec/batch; 18h:01m:43s remains)
INFO - root - 2017-12-17 05:51:40.535572: step 39330, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 18h:29m:18s remains)
INFO - root - 2017-12-17 05:51:42.787432: step 39340, loss = 0.11, batch loss = 0.07 (35.3 examples/sec; 0.227 sec/batch; 18h:28m:32s remains)
INFO - root - 2017-12-17 05:51:45.074493: step 39350, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 17h:56m:13s remains)
INFO - root - 2017-12-17 05:51:47.271195: step 39360, loss = 0.10, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 17h:49m:59s remains)
INFO - root - 2017-12-17 05:51:49.496019: step 39370, loss = 0.09, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 18h:07m:43s remains)
INFO - root - 2017-12-17 05:51:51.744171: step 39380, loss = 0.10, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 17h:55m:13s remains)
INFO - root - 2017-12-17 05:51:53.994186: step 39390, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.221 sec/batch; 17h:57m:34s remains)
INFO - root - 2017-12-17 05:51:56.220177: step 39400, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 18h:03m:26s remains)
INFO - root - 2017-12-17 05:51:58.563685: step 39410, loss = 0.12, batch loss = 0.09 (36.4 examples/sec; 0.219 sec/batch; 17h:52m:08s remains)
INFO - root - 2017-12-17 05:52:00.809665: step 39420, loss = 0.10, batch loss = 0.07 (36.6 examples/sec; 0.218 sec/batch; 17h:46m:45s remains)
INFO - root - 2017-12-17 05:52:03.048987: step 39430, loss = 0.11, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 17h:56m:22s remains)
INFO - root - 2017-12-17 05:52:05.283968: step 39440, loss = 0.10, batch loss = 0.07 (35.4 examples/sec; 0.226 sec/batch; 18h:25m:02s remains)
INFO - root - 2017-12-17 05:52:07.496106: step 39450, loss = 0.11, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 18h:03m:03s remains)
INFO - root - 2017-12-17 05:52:09.728827: step 39460, loss = 0.12, batch loss = 0.08 (35.4 examples/sec; 0.226 sec/batch; 18h:24m:17s remains)
INFO - root - 2017-12-17 05:52:11.990457: step 39470, loss = 0.10, batch loss = 0.06 (34.6 examples/sec; 0.231 sec/batch; 18h:50m:03s remains)
INFO - root - 2017-12-17 05:52:14.227824: step 39480, loss = 0.17, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 18h:22m:54s remains)
INFO - root - 2017-12-17 05:52:16.431250: step 39490, loss = 0.09, batch loss = 0.06 (35.8 examples/sec; 0.223 sec/batch; 18h:10m:39s remains)
INFO - root - 2017-12-17 05:52:18.658966: step 39500, loss = 0.12, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 18h:18m:16s remains)
INFO - root - 2017-12-17 05:52:21.003457: step 39510, loss = 0.09, batch loss = 0.05 (35.1 examples/sec; 0.228 sec/batch; 18h:32m:13s remains)
INFO - root - 2017-12-17 05:52:23.227445: step 39520, loss = 0.11, batch loss = 0.08 (36.8 examples/sec; 0.217 sec/batch; 17h:41m:07s remains)
INFO - root - 2017-12-17 05:52:25.434593: step 39530, loss = 0.09, batch loss = 0.06 (36.8 examples/sec; 0.217 sec/batch; 17h:41m:17s remains)
INFO - root - 2017-12-17 05:52:27.687559: step 39540, loss = 0.10, batch loss = 0.07 (34.9 examples/sec; 0.229 sec/batch; 18h:40m:31s remains)
INFO - root - 2017-12-17 05:52:29.934699: step 39550, loss = 0.11, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 18h:09m:24s remains)
INFO - root - 2017-12-17 05:52:32.122360: step 39560, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 18h:11m:53s remains)
INFO - root - 2017-12-17 05:52:34.367437: step 39570, loss = 0.08, batch loss = 0.04 (34.7 examples/sec; 0.231 sec/batch; 18h:45m:50s remains)
INFO - root - 2017-12-17 05:52:36.599099: step 39580, loss = 0.11, batch loss = 0.07 (36.3 examples/sec; 0.221 sec/batch; 17h:57m:20s remains)
INFO - root - 2017-12-17 05:52:38.845677: step 39590, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.221 sec/batch; 17h:56m:30s remains)
INFO - root - 2017-12-17 05:52:41.062811: step 39600, loss = 0.13, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 18h:01m:30s remains)
INFO - root - 2017-12-17 05:52:43.381615: step 39610, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 17h:57m:21s remains)
INFO - root - 2017-12-17 05:52:45.603342: step 39620, loss = 0.13, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 17h:47m:54s remains)
INFO - root - 2017-12-17 05:52:47.831635: step 39630, loss = 0.12, batch loss = 0.08 (36.9 examples/sec; 0.217 sec/batch; 17h:38m:54s remains)
INFO - root - 2017-12-17 05:52:50.067555: step 39640, loss = 0.11, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 17h:57m:59s remains)
INFO - root - 2017-12-17 05:52:52.285629: step 39650, loss = 0.10, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 18h:02m:06s remains)
INFO - root - 2017-12-17 05:52:54.502380: step 39660, loss = 0.10, batch loss = 0.07 (35.4 examples/sec; 0.226 sec/batch; 18h:22m:09s remains)
INFO - root - 2017-12-17 05:52:56.713585: step 39670, loss = 0.10, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 17h:51m:51s remains)
INFO - root - 2017-12-17 05:52:58.941418: step 39680, loss = 0.11, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 17h:53m:41s remains)
INFO - root - 2017-12-17 05:53:01.208361: step 39690, loss = 0.12, batch loss = 0.09 (34.7 examples/sec; 0.230 sec/batch; 18h:44m:05s remains)
INFO - root - 2017-12-17 05:53:03.422006: step 39700, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 18h:11m:08s remains)
INFO - root - 2017-12-17 05:53:05.778355: step 39710, loss = 0.11, batch loss = 0.08 (35.1 examples/sec; 0.228 sec/batch; 18h:33m:25s remains)
INFO - root - 2017-12-17 05:53:08.023831: step 39720, loss = 0.11, batch loss = 0.08 (36.9 examples/sec; 0.217 sec/batch; 17h:38m:35s remains)
INFO - root - 2017-12-17 05:53:10.311338: step 39730, loss = 0.11, batch loss = 0.08 (36.8 examples/sec; 0.217 sec/batch; 17h:39m:23s remains)
INFO - root - 2017-12-17 05:53:12.551245: step 39740, loss = 0.11, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 17h:52m:58s remains)
INFO - root - 2017-12-17 05:53:14.788044: step 39750, loss = 0.09, batch loss = 0.06 (35.1 examples/sec; 0.228 sec/batch; 18h:33m:01s remains)
INFO - root - 2017-12-17 05:53:17.019198: step 39760, loss = 0.09, batch loss = 0.06 (35.2 examples/sec; 0.227 sec/batch; 18h:28m:34s remains)
INFO - root - 2017-12-17 05:53:19.261055: step 39770, loss = 0.09, batch loss = 0.05 (35.7 examples/sec; 0.224 sec/batch; 18h:12m:37s remains)
INFO - root - 2017-12-17 05:53:21.488623: step 39780, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:16m:07s remains)
INFO - root - 2017-12-17 05:53:23.731163: step 39790, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 18h:29m:13s remains)
INFO - root - 2017-12-17 05:53:25.985727: step 39800, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 18h:01m:03s remains)
INFO - root - 2017-12-17 05:53:28.336721: step 39810, loss = 0.11, batch loss = 0.08 (34.5 examples/sec; 0.232 sec/batch; 18h:49m:43s remains)
INFO - root - 2017-12-17 05:53:30.587966: step 39820, loss = 0.11, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 17h:48m:13s remains)
INFO - root - 2017-12-17 05:53:32.797701: step 39830, loss = 0.11, batch loss = 0.07 (35.5 examples/sec; 0.225 sec/batch; 18h:17m:58s remains)
INFO - root - 2017-12-17 05:53:35.024016: step 39840, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:15m:24s remains)
INFO - root - 2017-12-17 05:53:37.270398: step 39850, loss = 0.10, batch loss = 0.06 (34.5 examples/sec; 0.232 sec/batch; 18h:52m:25s remains)
INFO - root - 2017-12-17 05:53:39.510843: step 39860, loss = 0.09, batch loss = 0.05 (36.5 examples/sec; 0.219 sec/batch; 17h:49m:00s remains)
INFO - root - 2017-12-17 05:53:41.703932: step 39870, loss = 0.18, batch loss = 0.14 (35.8 examples/sec; 0.223 sec/batch; 18h:09m:07s remains)
INFO - root - 2017-12-17 05:53:43.920766: step 39880, loss = 0.12, batch loss = 0.08 (35.1 examples/sec; 0.228 sec/batch; 18h:30m:01s remains)
INFO - root - 2017-12-17 05:53:46.156997: step 39890, loss = 0.08, batch loss = 0.05 (35.6 examples/sec; 0.225 sec/batch; 18h:15m:36s remains)
INFO - root - 2017-12-17 05:53:48.420055: step 39900, loss = 0.10, batch loss = 0.07 (34.2 examples/sec; 0.234 sec/batch; 19h:00m:04s remains)
INFO - root - 2017-12-17 05:53:50.841553: step 39910, loss = 0.11, batch loss = 0.07 (34.7 examples/sec; 0.231 sec/batch; 18h:45m:09s remains)
INFO - root - 2017-12-17 05:53:53.053102: step 39920, loss = 0.13, batch loss = 0.09 (37.4 examples/sec; 0.214 sec/batch; 17h:24m:06s remains)
INFO - root - 2017-12-17 05:53:55.267309: step 39930, loss = 0.11, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 18h:03m:27s remains)
INFO - root - 2017-12-17 05:53:57.494103: step 39940, loss = 0.11, batch loss = 0.08 (36.6 examples/sec; 0.218 sec/batch; 17h:44m:27s remains)
INFO - root - 2017-12-17 05:53:59.701700: step 39950, loss = 0.18, batch loss = 0.15 (35.8 examples/sec; 0.223 sec/batch; 18h:08m:49s remains)
INFO - root - 2017-12-17 05:54:01.878632: step 39960, loss = 0.11, batch loss = 0.08 (36.8 examples/sec; 0.217 sec/batch; 17h:40m:26s remains)
INFO - root - 2017-12-17 05:54:04.106460: step 39970, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.221 sec/batch; 17h:55m:18s remains)
INFO - root - 2017-12-17 05:54:06.306913: step 39980, loss = 0.09, batch loss = 0.05 (36.1 examples/sec; 0.222 sec/batch; 18h:00m:57s remains)
INFO - root - 2017-12-17 05:54:08.577346: step 39990, loss = 0.12, batch loss = 0.09 (34.5 examples/sec; 0.232 sec/batch; 18h:50m:13s remains)
INFO - root - 2017-12-17 05:54:10.781295: step 40000, loss = 0.11, batch loss = 0.08 (36.1 examples/sec; 0.222 sec/batch; 18h:00m:21s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-40000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-40000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 05:54:13.798861: step 40010, loss = 0.08, batch loss = 0.05 (36.2 examples/sec; 0.221 sec/batch; 17h:58m:24s remains)
INFO - root - 2017-12-17 05:54:16.000657: step 40020, loss = 0.12, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 18h:04m:28s remains)
INFO - root - 2017-12-17 05:54:18.226237: step 40030, loss = 0.10, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 18h:10m:59s remains)
INFO - root - 2017-12-17 05:54:20.467049: step 40040, loss = 0.10, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 17h:52m:19s remains)
INFO - root - 2017-12-17 05:54:22.713723: step 40050, loss = 0.11, batch loss = 0.08 (34.9 examples/sec; 0.229 sec/batch; 18h:36m:56s remains)
INFO - root - 2017-12-17 05:54:24.931686: step 40060, loss = 0.12, batch loss = 0.08 (36.6 examples/sec; 0.219 sec/batch; 17h:45m:49s remains)
INFO - root - 2017-12-17 05:54:27.141125: step 40070, loss = 0.10, batch loss = 0.06 (36.4 examples/sec; 0.220 sec/batch; 17h:49m:56s remains)
INFO - root - 2017-12-17 05:54:29.377988: step 40080, loss = 0.09, batch loss = 0.06 (35.8 examples/sec; 0.223 sec/batch; 18h:08m:34s remains)
INFO - root - 2017-12-17 05:54:31.629353: step 40090, loss = 0.10, batch loss = 0.06 (35.4 examples/sec; 0.226 sec/batch; 18h:19m:56s remains)
INFO - root - 2017-12-17 05:54:33.868494: step 40100, loss = 0.12, batch loss = 0.08 (36.1 examples/sec; 0.222 sec/batch; 18h:01m:26s remains)
INFO - root - 2017-12-17 05:54:36.224378: step 40110, loss = 0.13, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 18h:14m:45s remains)
INFO - root - 2017-12-17 05:54:38.468599: step 40120, loss = 0.13, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 18h:09m:39s remains)
INFO - root - 2017-12-17 05:54:40.677731: step 40130, loss = 0.11, batch loss = 0.08 (35.5 examples/sec; 0.226 sec/batch; 18h:19m:37s remains)
INFO - root - 2017-12-17 05:54:42.885319: step 40140, loss = 0.09, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 17h:47m:46s remains)
INFO - root - 2017-12-17 05:54:45.129808: step 40150, loss = 0.19, batch loss = 0.16 (35.5 examples/sec; 0.225 sec/batch; 18h:18m:22s remains)
INFO - root - 2017-12-17 05:54:47.384641: step 40160, loss = 0.13, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 17h:59m:24s remains)
INFO - root - 2017-12-17 05:54:49.642078: step 40170, loss = 0.13, batch loss = 0.10 (35.0 examples/sec; 0.228 sec/batch; 18h:33m:12s remains)
INFO - root - 2017-12-17 05:54:51.917337: step 40180, loss = 0.13, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 18h:15m:32s remains)
INFO - root - 2017-12-17 05:54:54.135429: step 40190, loss = 0.11, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 17h:57m:26s remains)
INFO - root - 2017-12-17 05:54:56.391204: step 40200, loss = 0.09, batch loss = 0.05 (35.9 examples/sec; 0.223 sec/batch; 18h:04m:08s remains)
INFO - root - 2017-12-17 05:54:58.731824: step 40210, loss = 0.11, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 17h:41m:07s remains)
INFO - root - 2017-12-17 05:55:00.984385: step 40220, loss = 0.12, batch loss = 0.08 (33.8 examples/sec; 0.237 sec/batch; 19h:13m:08s remains)
INFO - root - 2017-12-17 05:55:03.215017: step 40230, loss = 0.13, batch loss = 0.10 (36.9 examples/sec; 0.217 sec/batch; 17h:36m:17s remains)
INFO - root - 2017-12-17 05:55:05.506288: step 40240, loss = 0.14, batch loss = 0.10 (34.6 examples/sec; 0.231 sec/batch; 18h:44m:51s remains)
INFO - root - 2017-12-17 05:55:07.751205: step 40250, loss = 0.12, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 18h:04m:27s remains)
INFO - root - 2017-12-17 05:55:09.986590: step 40260, loss = 0.14, batch loss = 0.11 (36.3 examples/sec; 0.220 sec/batch; 17h:53m:09s remains)
INFO - root - 2017-12-17 05:55:12.183249: step 40270, loss = 0.14, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 17h:59m:47s remains)
INFO - root - 2017-12-17 05:55:14.398541: step 40280, loss = 0.12, batch loss = 0.09 (34.4 examples/sec; 0.232 sec/batch; 18h:51m:53s remains)
INFO - root - 2017-12-17 05:55:16.650411: step 40290, loss = 0.09, batch loss = 0.06 (34.6 examples/sec; 0.231 sec/batch; 18h:46m:50s remains)
INFO - root - 2017-12-17 05:55:18.896608: step 40300, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.224 sec/batch; 18h:08m:51s remains)
INFO - root - 2017-12-17 05:55:21.227967: step 40310, loss = 0.11, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 18h:11m:07s remains)
INFO - root - 2017-12-17 05:55:23.459263: step 40320, loss = 0.09, batch loss = 0.06 (35.1 examples/sec; 0.228 sec/batch; 18h:29m:40s remains)
INFO - root - 2017-12-17 05:55:25.663723: step 40330, loss = 0.08, batch loss = 0.04 (36.8 examples/sec; 0.217 sec/batch; 17h:38m:40s remains)
INFO - root - 2017-12-17 05:55:27.871838: step 40340, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 17h:58m:47s remains)
INFO - root - 2017-12-17 05:55:30.111630: step 40350, loss = 0.09, batch loss = 0.05 (35.3 examples/sec; 0.227 sec/batch; 18h:24m:18s remains)
INFO - root - 2017-12-17 05:55:32.365590: step 40360, loss = 0.10, batch loss = 0.07 (34.1 examples/sec; 0.235 sec/batch; 19h:03m:43s remains)
INFO - root - 2017-12-17 05:55:34.642334: step 40370, loss = 0.09, batch loss = 0.06 (34.3 examples/sec; 0.233 sec/batch; 18h:54m:33s remains)
INFO - root - 2017-12-17 05:55:36.867448: step 40380, loss = 0.12, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 17h:48m:28s remains)
INFO - root - 2017-12-17 05:55:39.077806: step 40390, loss = 0.09, batch loss = 0.05 (35.8 examples/sec; 0.223 sec/batch; 18h:06m:57s remains)
INFO - root - 2017-12-17 05:55:41.332467: step 40400, loss = 0.12, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 17h:47m:19s remains)
INFO - root - 2017-12-17 05:55:43.708992: step 40410, loss = 0.10, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 18h:02m:00s remains)
INFO - root - 2017-12-17 05:55:45.925623: step 40420, loss = 0.08, batch loss = 0.05 (36.3 examples/sec; 0.221 sec/batch; 17h:53m:54s remains)
INFO - root - 2017-12-17 05:55:48.171883: step 40430, loss = 0.11, batch loss = 0.07 (35.3 examples/sec; 0.227 sec/batch; 18h:23m:56s remains)
INFO - root - 2017-12-17 05:55:50.378018: step 40440, loss = 0.09, batch loss = 0.05 (36.2 examples/sec; 0.221 sec/batch; 17h:56m:53s remains)
INFO - root - 2017-12-17 05:55:52.607317: step 40450, loss = 0.09, batch loss = 0.06 (35.2 examples/sec; 0.228 sec/batch; 18h:27m:28s remains)
INFO - root - 2017-12-17 05:55:54.845323: step 40460, loss = 0.12, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 17h:49m:32s remains)
INFO - root - 2017-12-17 05:55:57.063897: step 40470, loss = 0.11, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 17h:46m:12s remains)
INFO - root - 2017-12-17 05:55:59.314648: step 40480, loss = 0.16, batch loss = 0.13 (34.4 examples/sec; 0.233 sec/batch; 18h:52m:36s remains)
INFO - root - 2017-12-17 05:56:01.595613: step 40490, loss = 0.10, batch loss = 0.07 (32.5 examples/sec; 0.246 sec/batch; 19h:57m:05s remains)
INFO - root - 2017-12-17 05:56:03.830808: step 40500, loss = 0.11, batch loss = 0.08 (34.8 examples/sec; 0.230 sec/batch; 18h:39m:12s remains)
INFO - root - 2017-12-17 05:56:06.186131: step 40510, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 17h:59m:21s remains)
INFO - root - 2017-12-17 05:56:08.410055: step 40520, loss = 0.09, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 18h:00m:48s remains)
INFO - root - 2017-12-17 05:56:10.647096: step 40530, loss = 0.11, batch loss = 0.07 (37.3 examples/sec; 0.214 sec/batch; 17h:23m:06s remains)
INFO - root - 2017-12-17 05:56:12.870927: step 40540, loss = 0.13, batch loss = 0.10 (36.3 examples/sec; 0.221 sec/batch; 17h:53m:38s remains)
INFO - root - 2017-12-17 05:56:15.111017: step 40550, loss = 0.15, batch loss = 0.11 (36.6 examples/sec; 0.219 sec/batch; 17h:43m:56s remains)
INFO - root - 2017-12-17 05:56:17.303674: step 40560, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 18h:10m:23s remains)
INFO - root - 2017-12-17 05:56:19.523639: step 40570, loss = 0.12, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 17h:54m:49s remains)
INFO - root - 2017-12-17 05:56:21.741775: step 40580, loss = 0.11, batch loss = 0.07 (34.6 examples/sec; 0.231 sec/batch; 18h:43m:31s remains)
INFO - root - 2017-12-17 05:56:23.958947: step 40590, loss = 0.11, batch loss = 0.08 (36.9 examples/sec; 0.217 sec/batch; 17h:34m:01s remains)
INFO - root - 2017-12-17 05:56:26.142763: step 40600, loss = 0.08, batch loss = 0.05 (35.8 examples/sec; 0.223 sec/batch; 18h:07m:00s remains)
INFO - root - 2017-12-17 05:56:28.474587: step 40610, loss = 0.11, batch loss = 0.08 (35.2 examples/sec; 0.227 sec/batch; 18h:25m:10s remains)
INFO - root - 2017-12-17 05:56:30.690394: step 40620, loss = 0.09, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 17h:54m:56s remains)
INFO - root - 2017-12-17 05:56:32.903574: step 40630, loss = 0.12, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 18h:02m:15s remains)
INFO - root - 2017-12-17 05:56:35.123530: step 40640, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 18h:11m:13s remains)
INFO - root - 2017-12-17 05:56:37.334298: step 40650, loss = 0.09, batch loss = 0.06 (35.8 examples/sec; 0.224 sec/batch; 18h:08m:16s remains)
INFO - root - 2017-12-17 05:56:39.559963: step 40660, loss = 0.13, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 17h:46m:08s remains)
INFO - root - 2017-12-17 05:56:41.779283: step 40670, loss = 0.10, batch loss = 0.07 (36.7 examples/sec; 0.218 sec/batch; 17h:40m:23s remains)
INFO - root - 2017-12-17 05:56:44.022523: step 40680, loss = 0.12, batch loss = 0.09 (36.1 examples/sec; 0.221 sec/batch; 17h:56m:43s remains)
INFO - root - 2017-12-17 05:56:46.220057: step 40690, loss = 0.11, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 18h:10m:48s remains)
INFO - root - 2017-12-17 05:56:48.479879: step 40700, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 17h:53m:59s remains)
INFO - root - 2017-12-17 05:56:50.846023: step 40710, loss = 0.09, batch loss = 0.06 (34.4 examples/sec; 0.232 sec/batch; 18h:50m:39s remains)
INFO - root - 2017-12-17 05:56:53.135240: step 40720, loss = 0.09, batch loss = 0.06 (35.2 examples/sec; 0.227 sec/batch; 18h:25m:15s remains)
INFO - root - 2017-12-17 05:56:55.337267: step 40730, loss = 0.11, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 18h:01m:25s remains)
INFO - root - 2017-12-17 05:56:57.527885: step 40740, loss = 0.12, batch loss = 0.09 (37.1 examples/sec; 0.216 sec/batch; 17h:28m:16s remains)
INFO - root - 2017-12-17 05:56:59.812028: step 40750, loss = 0.11, batch loss = 0.08 (35.5 examples/sec; 0.225 sec/batch; 18h:16m:20s remains)
INFO - root - 2017-12-17 05:57:02.040922: step 40760, loss = 0.11, batch loss = 0.07 (35.4 examples/sec; 0.226 sec/batch; 18h:18m:04s remains)
INFO - root - 2017-12-17 05:57:04.261599: step 40770, loss = 0.12, batch loss = 0.09 (37.3 examples/sec; 0.214 sec/batch; 17h:22m:25s remains)
INFO - root - 2017-12-17 05:57:06.480940: step 40780, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.224 sec/batch; 18h:07m:07s remains)
INFO - root - 2017-12-17 05:57:08.697361: step 40790, loss = 0.12, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 18h:00m:01s remains)
INFO - root - 2017-12-17 05:57:10.929014: step 40800, loss = 0.11, batch loss = 0.07 (34.0 examples/sec; 0.235 sec/batch; 19h:04m:47s remains)
INFO - root - 2017-12-17 05:57:13.266033: step 40810, loss = 0.09, batch loss = 0.05 (36.6 examples/sec; 0.219 sec/batch; 17h:42m:25s remains)
INFO - root - 2017-12-17 05:57:15.459159: step 40820, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 17h:53m:23s remains)
INFO - root - 2017-12-17 05:57:17.698761: step 40830, loss = 0.09, batch loss = 0.05 (35.9 examples/sec; 0.223 sec/batch; 18h:04m:06s remains)
INFO - root - 2017-12-17 05:57:19.927827: step 40840, loss = 0.11, batch loss = 0.07 (35.9 examples/sec; 0.223 sec/batch; 18h:02m:52s remains)
INFO - root - 2017-12-17 05:57:22.168079: step 40850, loss = 0.11, batch loss = 0.08 (34.9 examples/sec; 0.229 sec/batch; 18h:35m:28s remains)
INFO - root - 2017-12-17 05:57:24.467167: step 40860, loss = 0.12, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 18h:01m:50s remains)
INFO - root - 2017-12-17 05:57:26.672192: step 40870, loss = 0.08, batch loss = 0.05 (36.1 examples/sec; 0.222 sec/batch; 17h:58m:00s remains)
INFO - root - 2017-12-17 05:57:28.908156: step 40880, loss = 0.13, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 17h:58m:43s remains)
INFO - root - 2017-12-17 05:57:31.131734: step 40890, loss = 0.11, batch loss = 0.07 (35.6 examples/sec; 0.224 sec/batch; 18h:10m:55s remains)
INFO - root - 2017-12-17 05:57:33.341466: step 40900, loss = 0.12, batch loss = 0.08 (36.3 examples/sec; 0.220 sec/batch; 17h:50m:04s remains)
INFO - root - 2017-12-17 05:57:35.672965: step 40910, loss = 0.13, batch loss = 0.10 (35.8 examples/sec; 0.223 sec/batch; 18h:05m:15s remains)
INFO - root - 2017-12-17 05:57:37.924369: step 40920, loss = 0.18, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 18h:03m:49s remains)
INFO - root - 2017-12-17 05:57:40.149512: step 40930, loss = 0.11, batch loss = 0.07 (37.0 examples/sec; 0.216 sec/batch; 17h:30m:54s remains)
INFO - root - 2017-12-17 05:57:42.382379: step 40940, loss = 0.11, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 17h:53m:50s remains)
INFO - root - 2017-12-17 05:57:44.605979: step 40950, loss = 0.10, batch loss = 0.07 (36.8 examples/sec; 0.217 sec/batch; 17h:35m:02s remains)
INFO - root - 2017-12-17 05:57:46.807278: step 40960, loss = 0.17, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 18h:18m:34s remains)
INFO - root - 2017-12-17 05:57:49.046530: step 40970, loss = 0.12, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 18h:07m:27s remains)
INFO - root - 2017-12-17 05:57:51.276744: step 40980, loss = 0.10, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 17h:57m:10s remains)
INFO - root - 2017-12-17 05:57:53.489137: step 40990, loss = 0.14, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 18h:06m:02s remains)
INFO - root - 2017-12-17 05:57:55.693564: step 41000, loss = 0.09, batch loss = 0.05 (37.1 examples/sec; 0.216 sec/batch; 17h:28m:08s remains)
INFO - root - 2017-12-17 05:57:58.049078: step 41010, loss = 0.14, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 18h:21m:58s remains)
INFO - root - 2017-12-17 05:58:00.250471: step 41020, loss = 0.09, batch loss = 0.05 (36.7 examples/sec; 0.218 sec/batch; 17h:37m:49s remains)
INFO - root - 2017-12-17 05:58:02.474658: step 41030, loss = 0.09, batch loss = 0.06 (36.6 examples/sec; 0.219 sec/batch; 17h:42m:24s remains)
INFO - root - 2017-12-17 05:58:04.683361: step 41040, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 17h:46m:50s remains)
INFO - root - 2017-12-17 05:58:06.946063: step 41050, loss = 0.12, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 17h:45m:32s remains)
INFO - root - 2017-12-17 05:58:09.168206: step 41060, loss = 0.11, batch loss = 0.08 (37.0 examples/sec; 0.216 sec/batch; 17h:29m:43s remains)
INFO - root - 2017-12-17 05:58:11.389883: step 41070, loss = 0.11, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 18h:01m:29s remains)
INFO - root - 2017-12-17 05:58:13.608106: step 41080, loss = 0.15, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 17h:53m:50s remains)
INFO - root - 2017-12-17 05:58:15.850052: step 41090, loss = 0.10, batch loss = 0.06 (33.7 examples/sec; 0.237 sec/batch; 19h:11m:21s remains)
INFO - root - 2017-12-17 05:58:18.088362: step 41100, loss = 0.14, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 18h:13m:52s remains)
INFO - root - 2017-12-17 05:58:20.424809: step 41110, loss = 0.09, batch loss = 0.05 (36.8 examples/sec; 0.217 sec/batch; 17h:34m:47s remains)
INFO - root - 2017-12-17 05:58:22.645736: step 41120, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 17h:57m:35s remains)
INFO - root - 2017-12-17 05:58:24.904606: step 41130, loss = 0.12, batch loss = 0.09 (35.5 examples/sec; 0.225 sec/batch; 18h:13m:00s remains)
INFO - root - 2017-12-17 05:58:27.165480: step 41140, loss = 0.11, batch loss = 0.07 (35.2 examples/sec; 0.228 sec/batch; 18h:24m:53s remains)
INFO - root - 2017-12-17 05:58:29.420652: step 41150, loss = 0.10, batch loss = 0.07 (35.8 examples/sec; 0.223 sec/batch; 18h:03m:47s remains)
INFO - root - 2017-12-17 05:58:31.645168: step 41160, loss = 0.08, batch loss = 0.05 (36.6 examples/sec; 0.219 sec/batch; 17h:41m:01s remains)
INFO - root - 2017-12-17 05:58:33.855117: step 41170, loss = 0.12, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 17h:59m:38s remains)
INFO - root - 2017-12-17 05:58:36.104785: step 41180, loss = 0.13, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 18h:02m:56s remains)
INFO - root - 2017-12-17 05:58:38.371687: step 41190, loss = 0.14, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 18h:16m:52s remains)
INFO - root - 2017-12-17 05:58:40.600774: step 41200, loss = 0.13, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 17h:57m:53s remains)
INFO - root - 2017-12-17 05:58:42.941582: step 41210, loss = 0.13, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 18h:13m:59s remains)
INFO - root - 2017-12-17 05:58:45.206239: step 41220, loss = 0.12, batch loss = 0.09 (36.7 examples/sec; 0.218 sec/batch; 17h:36m:55s remains)
INFO - root - 2017-12-17 05:58:47.462249: step 41230, loss = 0.10, batch loss = 0.07 (34.6 examples/sec; 0.231 sec/batch; 18h:43m:26s remains)
INFO - root - 2017-12-17 05:58:49.693888: step 41240, loss = 0.09, batch loss = 0.05 (36.6 examples/sec; 0.219 sec/batch; 17h:41m:36s remains)
INFO - root - 2017-12-17 05:58:51.880720: step 41250, loss = 0.10, batch loss = 0.07 (37.5 examples/sec; 0.214 sec/batch; 17h:16m:26s remains)
INFO - root - 2017-12-17 05:58:54.153857: step 41260, loss = 0.12, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 18h:06m:43s remains)
INFO - root - 2017-12-17 05:58:56.368134: step 41270, loss = 0.09, batch loss = 0.06 (37.3 examples/sec; 0.214 sec/batch; 17h:20m:14s remains)
INFO - root - 2017-12-17 05:58:58.620965: step 41280, loss = 0.10, batch loss = 0.07 (37.0 examples/sec; 0.216 sec/batch; 17h:30m:29s remains)
INFO - root - 2017-12-17 05:59:00.843162: step 41290, loss = 0.13, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 18h:05m:19s remains)
INFO - root - 2017-12-17 05:59:03.069230: step 41300, loss = 0.11, batch loss = 0.08 (36.0 examples/sec; 0.223 sec/batch; 17h:59m:57s remains)
INFO - root - 2017-12-17 05:59:05.366408: step 41310, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.221 sec/batch; 17h:54m:32s remains)
INFO - root - 2017-12-17 05:59:07.578189: step 41320, loss = 0.12, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 17h:45m:30s remains)
INFO - root - 2017-12-17 05:59:09.777941: step 41330, loss = 0.10, batch loss = 0.06 (35.5 examples/sec; 0.225 sec/batch; 18h:13m:55s remains)
INFO - root - 2017-12-17 05:59:12.012351: step 41340, loss = 0.13, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 17h:57m:52s remains)
INFO - root - 2017-12-17 05:59:14.245653: step 41350, loss = 0.13, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 17h:58m:49s remains)
INFO - root - 2017-12-17 05:59:16.470005: step 41360, loss = 0.12, batch loss = 0.08 (35.8 examples/sec; 0.223 sec/batch; 18h:03m:51s remains)
INFO - root - 2017-12-17 05:59:18.663814: step 41370, loss = 0.14, batch loss = 0.11 (36.8 examples/sec; 0.217 sec/batch; 17h:33m:53s remains)
INFO - root - 2017-12-17 05:59:20.870481: step 41380, loss = 0.13, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 18h:01m:29s remains)
INFO - root - 2017-12-17 05:59:23.089769: step 41390, loss = 0.11, batch loss = 0.08 (37.1 examples/sec; 0.215 sec/batch; 17h:25m:23s remains)
INFO - root - 2017-12-17 05:59:25.324984: step 41400, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 17h:52m:54s remains)
INFO - root - 2017-12-17 05:59:27.710919: step 41410, loss = 0.09, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 17h:38m:50s remains)
INFO - root - 2017-12-17 05:59:29.904040: step 41420, loss = 0.11, batch loss = 0.07 (37.0 examples/sec; 0.216 sec/batch; 17h:29m:51s remains)
INFO - root - 2017-12-17 05:59:32.155936: step 41430, loss = 0.11, batch loss = 0.07 (35.1 examples/sec; 0.228 sec/batch; 18h:25m:54s remains)
INFO - root - 2017-12-17 05:59:34.378849: step 41440, loss = 0.09, batch loss = 0.05 (35.5 examples/sec; 0.225 sec/batch; 18h:13m:26s remains)
INFO - root - 2017-12-17 05:59:36.642075: step 41450, loss = 0.12, batch loss = 0.08 (35.5 examples/sec; 0.225 sec/batch; 18h:13m:11s remains)
INFO - root - 2017-12-17 05:59:38.853213: step 41460, loss = 0.12, batch loss = 0.09 (37.3 examples/sec; 0.214 sec/batch; 17h:19m:06s remains)
INFO - root - 2017-12-17 05:59:41.048493: step 41470, loss = 0.11, batch loss = 0.08 (36.8 examples/sec; 0.218 sec/batch; 17h:35m:31s remains)
INFO - root - 2017-12-17 05:59:43.287645: step 41480, loss = 0.12, batch loss = 0.09 (34.8 examples/sec; 0.230 sec/batch; 18h:34m:32s remains)
INFO - root - 2017-12-17 05:59:45.525350: step 41490, loss = 0.11, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 17h:56m:33s remains)
INFO - root - 2017-12-17 05:59:47.720446: step 41500, loss = 0.08, batch loss = 0.05 (35.3 examples/sec; 0.227 sec/batch; 18h:18m:34s remains)
INFO - root - 2017-12-17 05:59:50.108661: step 41510, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.227 sec/batch; 18h:20m:45s remains)
INFO - root - 2017-12-17 05:59:52.329147: step 41520, loss = 0.11, batch loss = 0.07 (35.3 examples/sec; 0.227 sec/batch; 18h:20m:30s remains)
INFO - root - 2017-12-17 05:59:54.621242: step 41530, loss = 0.12, batch loss = 0.09 (35.8 examples/sec; 0.223 sec/batch; 18h:03m:02s remains)
INFO - root - 2017-12-17 05:59:56.860591: step 41540, loss = 0.10, batch loss = 0.07 (36.0 examples/sec; 0.222 sec/batch; 17h:58m:24s remains)
INFO - root - 2017-12-17 05:59:59.113225: step 41550, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 18h:06m:52s remains)
INFO - root - 2017-12-17 06:00:01.353796: step 41560, loss = 0.08, batch loss = 0.05 (36.0 examples/sec; 0.222 sec/batch; 17h:57m:10s remains)
INFO - root - 2017-12-17 06:00:03.571147: step 41570, loss = 0.09, batch loss = 0.06 (35.4 examples/sec; 0.226 sec/batch; 18h:14m:40s remains)
INFO - root - 2017-12-17 06:00:05.840520: step 41580, loss = 0.10, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 17h:48m:34s remains)
INFO - root - 2017-12-17 06:00:08.079258: step 41590, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.219 sec/batch; 17h:44m:11s remains)
INFO - root - 2017-12-17 06:00:10.299398: step 41600, loss = 0.10, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 17h:56m:04s remains)
INFO - root - 2017-12-17 06:00:12.606881: step 41610, loss = 0.12, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 17h:40m:46s remains)
INFO - root - 2017-12-17 06:00:14.809879: step 41620, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 17h:48m:11s remains)
INFO - root - 2017-12-17 06:00:17.041338: step 41630, loss = 0.13, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 17h:51m:41s remains)
INFO - root - 2017-12-17 06:00:19.273185: step 41640, loss = 0.09, batch loss = 0.05 (35.3 examples/sec; 0.226 sec/batch; 18h:17m:22s remains)
INFO - root - 2017-12-17 06:00:21.491812: step 41650, loss = 0.13, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 17h:55m:52s remains)
INFO - root - 2017-12-17 06:00:23.702512: step 41660, loss = 0.12, batch loss = 0.09 (36.7 examples/sec; 0.218 sec/batch; 17h:37m:18s remains)
INFO - root - 2017-12-17 06:00:25.911123: step 41670, loss = 0.11, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:08m:30s remains)
INFO - root - 2017-12-17 06:00:28.159993: step 41680, loss = 0.09, batch loss = 0.06 (35.1 examples/sec; 0.228 sec/batch; 18h:25m:58s remains)
INFO - root - 2017-12-17 06:00:30.363040: step 41690, loss = 0.09, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 17h:41m:26s remains)
INFO - root - 2017-12-17 06:00:32.606287: step 41700, loss = 0.10, batch loss = 0.07 (35.0 examples/sec; 0.228 sec/batch; 18h:27m:15s remains)
INFO - root - 2017-12-17 06:00:34.954958: step 41710, loss = 0.13, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 18h:10m:25s remains)
INFO - root - 2017-12-17 06:00:37.151255: step 41720, loss = 0.11, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 17h:41m:49s remains)
INFO - root - 2017-12-17 06:00:39.361486: step 41730, loss = 0.09, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 17h:35m:32s remains)
INFO - root - 2017-12-17 06:00:41.649010: step 41740, loss = 0.11, batch loss = 0.08 (35.3 examples/sec; 0.227 sec/batch; 18h:17m:46s remains)
INFO - root - 2017-12-17 06:00:43.891147: step 41750, loss = 0.12, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 17h:55m:53s remains)
INFO - root - 2017-12-17 06:00:46.139046: step 41760, loss = 0.11, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 17h:43m:00s remains)
INFO - root - 2017-12-17 06:00:48.374068: step 41770, loss = 0.09, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 17h:50m:33s remains)
INFO - root - 2017-12-17 06:00:50.623358: step 41780, loss = 0.09, batch loss = 0.05 (36.3 examples/sec; 0.220 sec/batch; 17h:46m:55s remains)
INFO - root - 2017-12-17 06:00:52.848758: step 41790, loss = 0.11, batch loss = 0.08 (36.7 examples/sec; 0.218 sec/batch; 17h:37m:25s remains)
INFO - root - 2017-12-17 06:00:55.091281: step 41800, loss = 0.12, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 17h:41m:50s remains)
INFO - root - 2017-12-17 06:00:57.458649: step 41810, loss = 0.11, batch loss = 0.07 (36.3 examples/sec; 0.221 sec/batch; 17h:48m:20s remains)
INFO - root - 2017-12-17 06:00:59.687774: step 41820, loss = 0.11, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 17h:39m:24s remains)
INFO - root - 2017-12-17 06:01:01.903340: step 41830, loss = 0.12, batch loss = 0.08 (35.8 examples/sec; 0.224 sec/batch; 18h:03m:59s remains)
INFO - root - 2017-12-17 06:01:04.160408: step 41840, loss = 0.11, batch loss = 0.08 (35.5 examples/sec; 0.226 sec/batch; 18h:13m:09s remains)
INFO - root - 2017-12-17 06:01:06.396567: step 41850, loss = 0.17, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 17h:49m:27s remains)
INFO - root - 2017-12-17 06:01:08.641604: step 41860, loss = 0.11, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 17h:45m:01s remains)
INFO - root - 2017-12-17 06:01:10.905037: step 41870, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 17h:45m:07s remains)
INFO - root - 2017-12-17 06:01:13.193460: step 41880, loss = 0.15, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 17h:45m:41s remains)
INFO - root - 2017-12-17 06:01:15.580836: step 41890, loss = 0.09, batch loss = 0.06 (34.4 examples/sec; 0.232 sec/batch; 18h:45m:46s remains)
INFO - root - 2017-12-17 06:01:17.833245: step 41900, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 17h:53m:48s remains)
INFO - root - 2017-12-17 06:01:20.302567: step 41910, loss = 0.11, batch loss = 0.07 (34.4 examples/sec; 0.233 sec/batch; 18h:47m:54s remains)
INFO - root - 2017-12-17 06:01:22.537374: step 41920, loss = 0.12, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 17h:57m:27s remains)
INFO - root - 2017-12-17 06:01:24.813490: step 41930, loss = 0.17, batch loss = 0.14 (35.3 examples/sec; 0.226 sec/batch; 18h:16m:46s remains)
INFO - root - 2017-12-17 06:01:27.010126: step 41940, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 17h:43m:11s remains)
INFO - root - 2017-12-17 06:01:29.227940: step 41950, loss = 0.12, batch loss = 0.09 (34.3 examples/sec; 0.233 sec/batch; 18h:49m:04s remains)
INFO - root - 2017-12-17 06:01:31.421028: step 41960, loss = 0.09, batch loss = 0.05 (36.1 examples/sec; 0.222 sec/batch; 17h:54m:04s remains)
INFO - root - 2017-12-17 06:01:33.645488: step 41970, loss = 0.10, batch loss = 0.07 (36.8 examples/sec; 0.217 sec/batch; 17h:32m:53s remains)
INFO - root - 2017-12-17 06:01:35.867493: step 41980, loss = 0.10, batch loss = 0.07 (35.6 examples/sec; 0.225 sec/batch; 18h:07m:49s remains)
INFO - root - 2017-12-17 06:01:38.107300: step 41990, loss = 0.11, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 18h:06m:19s remains)
INFO - root - 2017-12-17 06:01:40.297191: step 42000, loss = 0.09, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 17h:40m:02s remains)
INFO - root - 2017-12-17 06:01:42.682541: step 42010, loss = 0.16, batch loss = 0.12 (34.7 examples/sec; 0.231 sec/batch; 18h:36m:02s remains)
INFO - root - 2017-12-17 06:01:44.908968: step 42020, loss = 0.09, batch loss = 0.05 (35.3 examples/sec; 0.227 sec/batch; 18h:17m:09s remains)
INFO - root - 2017-12-17 06:01:47.132432: step 42030, loss = 0.11, batch loss = 0.08 (36.7 examples/sec; 0.218 sec/batch; 17h:35m:39s remains)
INFO - root - 2017-12-17 06:01:49.339994: step 42040, loss = 0.10, batch loss = 0.06 (36.1 examples/sec; 0.221 sec/batch; 17h:51m:40s remains)
INFO - root - 2017-12-17 06:01:51.560530: step 42050, loss = 0.11, batch loss = 0.07 (36.3 examples/sec; 0.220 sec/batch; 17h:46m:33s remains)
INFO - root - 2017-12-17 06:01:53.798214: step 42060, loss = 0.09, batch loss = 0.06 (34.4 examples/sec; 0.232 sec/batch; 18h:44m:45s remains)
INFO - root - 2017-12-17 06:01:56.025277: step 42070, loss = 0.11, batch loss = 0.07 (37.1 examples/sec; 0.216 sec/batch; 17h:25m:04s remains)
INFO - root - 2017-12-17 06:01:58.224419: step 42080, loss = 0.13, batch loss = 0.10 (36.8 examples/sec; 0.218 sec/batch; 17h:33m:21s remains)
INFO - root - 2017-12-17 06:02:00.455257: step 42090, loss = 0.09, batch loss = 0.06 (35.8 examples/sec; 0.223 sec/batch; 18h:01m:08s remains)
INFO - root - 2017-12-17 06:02:02.687671: step 42100, loss = 0.08, batch loss = 0.05 (36.2 examples/sec; 0.221 sec/batch; 17h:50m:05s remains)
INFO - root - 2017-12-17 06:02:05.083527: step 42110, loss = 0.14, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 18h:08m:08s remains)
INFO - root - 2017-12-17 06:02:07.312717: step 42120, loss = 0.12, batch loss = 0.08 (35.5 examples/sec; 0.225 sec/batch; 18h:10m:40s remains)
INFO - root - 2017-12-17 06:02:09.566179: step 42130, loss = 0.09, batch loss = 0.06 (36.8 examples/sec; 0.217 sec/batch; 17h:32m:19s remains)
INFO - root - 2017-12-17 06:02:11.804723: step 42140, loss = 0.10, batch loss = 0.06 (35.4 examples/sec; 0.226 sec/batch; 18h:12m:29s remains)
INFO - root - 2017-12-17 06:02:13.993666: step 42150, loss = 0.09, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 17h:53m:55s remains)
INFO - root - 2017-12-17 06:02:16.192781: step 42160, loss = 0.08, batch loss = 0.05 (35.9 examples/sec; 0.223 sec/batch; 17h:59m:19s remains)
INFO - root - 2017-12-17 06:02:18.426144: step 42170, loss = 0.09, batch loss = 0.06 (35.0 examples/sec; 0.229 sec/batch; 18h:26m:03s remains)
INFO - root - 2017-12-17 06:02:20.646586: step 42180, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.223 sec/batch; 18h:00m:43s remains)
INFO - root - 2017-12-17 06:02:22.899765: step 42190, loss = 0.09, batch loss = 0.05 (35.3 examples/sec; 0.226 sec/batch; 18h:15m:46s remains)
INFO - root - 2017-12-17 06:02:25.081352: step 42200, loss = 0.11, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 17h:37m:53s remains)
INFO - root - 2017-12-17 06:02:27.471401: step 42210, loss = 0.14, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 18h:42m:16s remains)
INFO - root - 2017-12-17 06:02:29.684371: step 42220, loss = 0.11, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 17h:58m:13s remains)
INFO - root - 2017-12-17 06:02:31.873401: step 42230, loss = 0.14, batch loss = 0.11 (36.3 examples/sec; 0.220 sec/batch; 17h:45m:56s remains)
INFO - root - 2017-12-17 06:02:34.121125: step 42240, loss = 0.10, batch loss = 0.07 (34.9 examples/sec; 0.229 sec/batch; 18h:29m:40s remains)
INFO - root - 2017-12-17 06:02:36.342939: step 42250, loss = 0.12, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 17h:41m:24s remains)
INFO - root - 2017-12-17 06:02:38.588136: step 42260, loss = 0.10, batch loss = 0.07 (34.4 examples/sec; 0.233 sec/batch; 18h:46m:16s remains)
INFO - root - 2017-12-17 06:02:40.774097: step 42270, loss = 0.13, batch loss = 0.09 (37.0 examples/sec; 0.216 sec/batch; 17h:25m:11s remains)
INFO - root - 2017-12-17 06:02:43.016916: step 42280, loss = 0.09, batch loss = 0.06 (35.0 examples/sec; 0.228 sec/batch; 18h:24m:23s remains)
INFO - root - 2017-12-17 06:02:45.283788: step 42290, loss = 0.10, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 17h:37m:38s remains)
INFO - root - 2017-12-17 06:02:47.496536: step 42300, loss = 0.13, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 17h:44m:49s remains)
INFO - root - 2017-12-17 06:02:49.850980: step 42310, loss = 0.10, batch loss = 0.07 (35.2 examples/sec; 0.228 sec/batch; 18h:20m:31s remains)
INFO - root - 2017-12-17 06:02:52.096793: step 42320, loss = 0.11, batch loss = 0.07 (35.5 examples/sec; 0.225 sec/batch; 18h:08m:52s remains)
INFO - root - 2017-12-17 06:02:54.314391: step 42330, loss = 0.12, batch loss = 0.08 (36.1 examples/sec; 0.221 sec/batch; 17h:51m:05s remains)
INFO - root - 2017-12-17 06:02:56.543392: step 42340, loss = 0.10, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 17h:56m:34s remains)
INFO - root - 2017-12-17 06:02:58.783684: step 42350, loss = 0.12, batch loss = 0.09 (34.1 examples/sec; 0.235 sec/batch; 18h:54m:41s remains)
INFO - root - 2017-12-17 06:03:01.046463: step 42360, loss = 0.10, batch loss = 0.06 (35.4 examples/sec; 0.226 sec/batch; 18h:12m:03s remains)
INFO - root - 2017-12-17 06:03:03.284134: step 42370, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.220 sec/batch; 17h:44m:41s remains)
INFO - root - 2017-12-17 06:03:05.527462: step 42380, loss = 0.15, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 17h:39m:22s remains)
INFO - root - 2017-12-17 06:03:07.777726: step 42390, loss = 0.09, batch loss = 0.06 (33.3 examples/sec; 0.241 sec/batch; 19h:23m:03s remains)
INFO - root - 2017-12-17 06:03:09.996998: step 42400, loss = 0.11, batch loss = 0.08 (35.8 examples/sec; 0.223 sec/batch; 17h:59m:57s remains)
INFO - root - 2017-12-17 06:03:12.357101: step 42410, loss = 0.09, batch loss = 0.06 (37.2 examples/sec; 0.215 sec/batch; 17h:19m:28s remains)
INFO - root - 2017-12-17 06:03:14.538779: step 42420, loss = 0.10, batch loss = 0.07 (37.1 examples/sec; 0.216 sec/batch; 17h:22m:17s remains)
INFO - root - 2017-12-17 06:03:16.914406: step 42430, loss = 0.15, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 18h:36m:10s remains)
INFO - root - 2017-12-17 06:03:19.149813: step 42440, loss = 0.09, batch loss = 0.06 (34.2 examples/sec; 0.234 sec/batch; 18h:49m:56s remains)
INFO - root - 2017-12-17 06:03:21.385100: step 42450, loss = 0.09, batch loss = 0.05 (36.1 examples/sec; 0.222 sec/batch; 17h:51m:18s remains)
INFO - root - 2017-12-17 06:03:23.657764: step 42460, loss = 0.11, batch loss = 0.08 (32.1 examples/sec; 0.249 sec/batch; 20h:05m:27s remains)
INFO - root - 2017-12-17 06:03:25.882582: step 42470, loss = 0.12, batch loss = 0.09 (36.1 examples/sec; 0.221 sec/batch; 17h:50m:08s remains)
INFO - root - 2017-12-17 06:03:28.121297: step 42480, loss = 0.10, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 18h:02m:05s remains)
INFO - root - 2017-12-17 06:03:30.324282: step 42490, loss = 0.11, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 17h:42m:34s remains)
INFO - root - 2017-12-17 06:03:32.554139: step 42500, loss = 0.10, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 17h:54m:07s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-42500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test1/model.ckpt-42500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 06:03:35.461820: step 42510, loss = 0.10, batch loss = 0.07 (35.7 examples/sec; 0.224 sec/batch; 18h:04m:15s remains)
INFO - root - 2017-12-17 06:03:37.680120: step 42520, loss = 0.09, batch loss = 0.05 (36.4 examples/sec; 0.219 sec/batch; 17h:40m:49s remains)
INFO - root - 2017-12-17 06:03:39.890639: step 42530, loss = 0.11, batch loss = 0.08 (35.0 examples/sec; 0.228 sec/batch; 18h:23m:14s remains)
INFO - root - 2017-12-17 06:03:42.113110: step 42540, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 18h:02m:32s remains)
INFO - root - 2017-12-17 06:03:44.357231: step 42550, loss = 0.13, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 17h:46m:37s remains)
INFO - root - 2017-12-17 06:03:46.595974: step 42560, loss = 0.11, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 17h:55m:09s remains)
INFO - root - 2017-12-17 06:03:48.868810: step 42570, loss = 0.11, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 17h:48m:14s remains)
INFO - root - 2017-12-17 06:03:51.111058: step 42580, loss = 0.14, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:02m:48s remains)
INFO - root - 2017-12-17 06:03:53.396199: step 42590, loss = 0.12, batch loss = 0.08 (35.2 examples/sec; 0.227 sec/batch; 18h:18m:22s remains)
INFO - root - 2017-12-17 06:03:55.592276: step 42600, loss = 0.11, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 17h:43m:10s remains)
INFO - root - 2017-12-17 06:03:57.924411: step 42610, loss = 0.14, batch loss = 0.10 (36.9 examples/sec; 0.217 sec/batch; 17h:26m:46s remains)
INFO - root - 2017-12-17 06:04:00.133556: step 42620, loss = 0.09, batch loss = 0.06 (36.5 examples/sec; 0.219 sec/batch; 17h:38m:41s remains)
INFO - root - 2017-12-17 06:04:02.384541: step 42630, loss = 0.13, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 17h:56m:01s remains)
INFO - root - 2017-12-17 06:04:04.647780: step 42640, loss = 0.18, batch loss = 0.15 (34.1 examples/sec; 0.235 sec/batch; 18h:54m:35s remains)
INFO - root - 2017-12-17 06:04:06.931889: step 42650, loss = 0.09, batch loss = 0.06 (35.7 examples/sec; 0.224 sec/batch; 18h:03m:12s remains)
INFO - root - 2017-12-17 06:04:09.152493: step 42660, loss = 0.11, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 17h:42m:05s remains)
INFO - root - 2017-12-17 06:04:11.410183: step 42670, loss = 0.10, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 17h:40m:51s remains)
INFO - root - 2017-12-17 06:04:13.608293: step 42680, loss = 0.09, batch loss = 0.05 (35.8 examples/sec; 0.223 sec/batch; 17h:59m:21s remains)
INFO - root - 2017-12-17 06:04:15.841781: step 42690, loss = 0.09, batch loss = 0.06 (36.0 examples/sec; 0.223 sec/batch; 17h:54m:45s remains)
INFO - root - 2017-12-17 06:04:18.097624: step 42700, loss = 0.11, batch loss = 0.08 (35.3 examples/sec; 0.227 sec/batch; 18h:14m:10s remains)
INFO - root - 2017-12-17 06:04:20.435655: step 42710, loss = 0.11, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 17h:40m:19s remains)
INFO - root - 2017-12-17 06:04:22.645130: step 42720, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.221 sec/batch; 17h:48m:49s remains)
INFO - root - 2017-12-17 06:04:24.889230: step 42730, loss = 0.12, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 18h:06m:17s remains)
INFO - root - 2017-12-17 06:04:27.098723: step 42740, loss = 0.09, batch loss = 0.06 (34.8 examples/sec; 0.230 sec/batch; 18h:28m:36s remains)
INFO - root - 2017-12-17 06:04:29.404868: step 42750, loss = 0.11, batch loss = 0.07 (35.0 examples/sec; 0.228 sec/batch; 18h:22m:28s remains)
INFO - root - 2017-12-17 06:04:31.646647: step 42760, loss = 0.10, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 17h:37m:49s remains)
INFO - root - 2017-12-17 06:04:33.866664: step 42770, loss = 0.11, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 17h:41m:31s remains)
INFO - root - 2017-12-17 06:04:36.085610: step 42780, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.221 sec/batch; 17h:49m:32s remains)
INFO - root - 2017-12-17 06:04:38.310609: step 42790, loss = 0.16, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 18h:20m:00s remains)
INFO - root - 2017-12-17 06:04:40.551888: step 42800, loss = 0.12, batch loss = 0.08 (35.3 examples/sec; 0.227 sec/batch; 18h:14m:08s remains)
INFO - root - 2017-12-17 06:04:42.956730: step 42810, loss = 0.11, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 17h:56m:10s remains)
INFO - root - 2017-12-17 06:04:45.172917: step 42820, loss = 0.10, batch loss = 0.07 (37.8 examples/sec; 0.211 sec/batch; 17h:00m:39s remains)
INFO - root - 2017-12-17 06:04:47.420428: step 42830, loss = 0.10, batch loss = 0.07 (34.3 examples/sec; 0.233 sec/batch; 18h:45m:53s remains)
INFO - root - 2017-12-17 06:04:49.659659: step 42840, loss = 0.09, batch loss = 0.06 (36.3 examples/sec; 0.221 sec/batch; 17h:44m:50s remains)
INFO - root - 2017-12-17 06:04:51.915409: step 42850, loss = 0.12, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 18h:04m:54s remains)
INFO - root - 2017-12-17 06:04:54.081388: step 42860, loss = 0.14, batch loss = 0.11 (37.2 examples/sec; 0.215 sec/batch; 17h:18m:57s remains)
INFO - root - 2017-12-17 06:04:56.330027: step 42870, loss = 0.10, batch loss = 0.06 (36.6 examples/sec; 0.219 sec/batch; 17h:35m:08s remains)
INFO - root - 2017-12-17 06:04:58.606160: step 42880, loss = 0.14, batch loss = 0.11 (34.3 examples/sec; 0.233 sec/batch; 18h:45m:53s remains)
INFO - root - 2017-12-17 06:05:00.813469: step 42890, loss = 0.10, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 17h:32m:59s remains)
INFO - root - 2017-12-17 06:05:03.021294: step 42900, loss = 0.13, batch loss = 0.09 (35.5 examples/sec; 0.225 sec/batch; 18h:08m:13s remains)
INFO - root - 2017-12-17 06:05:05.410324: step 42910, loss = 0.11, batch loss = 0.07 (35.8 examples/sec; 0.223 sec/batch; 17h:57m:06s remains)
INFO - root - 2017-12-17 06:05:07.633575: step 42920, loss = 0.10, batch loss = 0.07 (36.5 examples/sec; 0.219 sec/batch; 17h:37m:47s remains)
INFO - root - 2017-12-17 06:05:09.854293: step 42930, loss = 0.10, batch loss = 0.07 (37.2 examples/sec; 0.215 sec/batch; 17h:17m:56s remains)
INFO - root - 2017-12-17 06:05:12.049299: step 42940, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 17h:46m:38s remains)
INFO - root - 2017-12-17 06:05:14.295463: step 42950, loss = 0.12, batch loss = 0.09 (35.8 examples/sec; 0.224 sec/batch; 17h:59m:44s remains)
INFO - root - 2017-12-17 06:05:16.499455: step 42960, loss = 0.13, batch loss = 0.09 (36.9 examples/sec; 0.217 sec/batch; 17h:25m:53s remains)
INFO - root - 2017-12-17 06:05:18.721636: step 42970, loss = 0.09, batch loss = 0.06 (34.5 examples/sec; 0.232 sec/batch; 18h:37m:25s remains)
INFO - root - 2017-12-17 06:05:20.917027: step 42980, loss = 0.16, batch loss = 0.13 (36.8 examples/sec; 0.217 sec/batch; 17h:28m:04s remains)
INFO - root - 2017-12-17 06:05:23.143413: step 42990, loss = 0.09, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 17h:46m:00s remains)
INFO - root - 2017-12-17 06:05:25.368419: step 43000, loss = 0.10, batch loss = 0.06 (36.9 examples/sec; 0.217 sec/batch; 17h:25m:41s remains)
INFO - root - 2017-12-17 06:05:27.689027: step 43010, loss = 0.11, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 17h:47m:26s remains)
INFO - root - 2017-12-17 06:05:29.905377: step 43020, loss = 0.09, batch loss = 0.06 (35.2 examples/sec; 0.227 sec/batch; 18h:16m:30s remains)
INFO - root - 2017-12-17 06:05:32.120142: step 43030, loss = 0.09, batch loss = 0.06 (36.7 examples/sec; 0.218 sec/batch; 17h:31m:38s remains)
INFO - root - 2017-12-17 06:05:34.309459: step 43040, loss = 0.10, batch loss = 0.07 (36.1 examples/sec; 0.222 sec/batch; 17h:48m:39s remains)
INFO - root - 2017-12-17 06:05:36.507457: step 43050, loss = 0.09, batch loss = 0.06 (36.8 examples/sec; 0.217 sec/batch; 17h:28m:31s remains)
INFO - root - 2017-12-17 06:05:38.725557: step 43060, loss = 0.08, batch loss = 0.05 (36.7 examples/sec; 0.218 sec/batch; 17h:32m:57s remains)
INFO - root - 2017-12-17 06:05:40.915863: step 43070, loss = 0.09, batch loss = 0.06 (36.0 examples/sec; 0.222 sec/batch; 17h:52m:48s remains)
INFO - root - 2017-12-17 06:05:43.143478: step 43080, loss = 0.12, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 17h:47m:00s remains)
INFO - root - 2017-12-17 06:05:45.412633: step 43090, loss = 0.16, batch loss = 0.12 (36.6 examples/sec; 0.219 sec/batch; 17h:35m:29s remains)
INFO - root - 2017-12-17 06:05:47.612751: step 43100, loss = 0.11, batch loss = 0.07 (36.4 examples/sec; 0.220 sec/batch; 17h:39m:11s remains)
INFO - root - 2017-12-17 06:05:49.956510: step 43110, loss = 0.10, batch loss = 0.07 (36.2 examples/sec; 0.221 sec/batch; 17h:45m:46s remains)
INFO - root - 2017-12-17 06:05:52.193608: step 43120, loss = 0.11, batch loss = 0.08 (36.3 examples/sec; 0.220 sec/batch; 17h:43m:17s remains)
INFO - root - 2017-12-17 06:05:54.397781: step 43130, loss = 0.10, batch loss = 0.07 (35.1 examples/sec; 0.228 sec/batch; 18h:18m:18s remains)
INFO - root - 2017-12-17 06:05:56.631678: step 43140, loss = 0.10, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 17h:53m:12s remains)
INFO - root - 2017-12-17 06:05:58.851604: step 43150, loss = 0.09, batch loss = 0.06 (35.8 examples/sec; 0.224 sec/batch; 17h:58m:08s remains)
INFO - root - 2017-12-17 06:06:01.091334: step 43160, loss = 0.13, batch loss = 0.09 (37.2 examples/sec; 0.215 sec/batch; 17h:16m:39s remains)
INFO - root - 2017-12-17 06:06:03.334391: step 43170, loss = 0.10, batch loss = 0.07 (34.8 examples/sec; 0.230 sec/batch; 18h:29m:27s remains)
INFO - root - 2017-12-17 06:06:05.556036: step 43180, loss = 0.09, batch loss = 0.06 (36.2 examples/sec; 0.221 sec/batch; 17h:44m:45s remains)
INFO - root - 2017-12-17 06:06:07.747931: step 43190, loss = 0.12, batch loss = 0.09 (37.1 examples/sec; 0.215 sec/batch; 17h:18m:33s remains)
INFO - root - 2017-12-17 06:06:09.989298: step 43200, loss = 0.12, batch loss = 0.08 (34.8 examples/sec; 0.230 sec/batch; 18h:28m:37s remains)
INFO - root - 2017-12-17 06:06:12.340501: step 43210, loss = 0.10, batch loss = 0.07 (35.0 examples/sec; 0.229 sec/batch; 18h:22m:41s remains)
INFO - root - 2017-12-17 06:06:14.540423: step 43220, loss = 0.10, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 17h:48m:33s remains)
INFO - root - 2017-12-17 06:06:16.768615: step 43230, loss = 0.13, batch loss = 0.10 (34.7 examples/sec; 0.230 sec/batch; 18h:30m:51s remains)
INFO - root - 2017-12-17 06:06:18.983179: step 43240, loss = 0.12, batch loss = 0.08 (36.3 examples/sec; 0.221 sec/batch; 17h:43m:35s remains)
INFO - root - 2017-12-17 06:06:21.184355: step 43250, loss = 0.09, batch loss = 0.06 (35.1 examples/sec; 0.228 sec/batch; 18h:17m:14s remains)
INFO - root - 2017-12-17 06:06:23.430143: step 43260, loss = 0.12, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 18h:09m:57s remains)
INFO - root - 2017-12-17 06:06:25.664244: step 43270, loss = 0.10, batch loss = 0.07 (34.8 examples/sec; 0.230 sec/batch; 18h:27m:57s remains)
INFO - root - 2017-12-17 06:06:27.899659: step 43280, loss = 0.16, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 18h:18m:54s remains)
INFO - root - 2017-12-17 06:06:30.136162: step 43290, loss = 0.09, batch loss = 0.06 (36.1 examples/sec; 0.222 sec/batch; 17h:49m:24s remains)
INFO - root - 2017-12-17 06:06:32.331165: step 43300, loss = 0.10, batch loss = 0.06 (35.6 examples/sec; 0.224 sec/batch; 18h:01m:57s remains)
INFO - root - 2017-12-17 06:06:34.649585: step 43310, loss = 0.11, batch loss = 0.08 (36.1 examples/sec; 0.222 sec/batch; 17h:49m:22s remains)
INFO - root - 2017-12-17 06:06:36.850612: step 43320, loss = 0.11, batch loss = 0.07 (37.6 examples/sec; 0.213 sec/batch; 17h:06m:24s remains)
INFO - root - 2017-12-17 06:06:39.037444: step 43330, loss = 0.11, batch loss = 0.07 (36.6 examples/sec; 0.219 sec/batch; 17h:34m:31s remains)
INFO - root - 2017-12-17 06:06:41.235707: step 43340, loss = 0.13, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 18h:09m:44s remains)
INFO - root - 2017-12-17 06:06:43.419573: step 43350, loss = 0.10, batch loss = 0.06 (37.0 examples/sec; 0.216 sec/batch; 17h:23m:09s remains)
INFO - root - 2017-12-17 06:06:45.672342: step 43360, loss = 0.09, batch loss = 0.06 (35.0 examples/sec; 0.228 sec/batch; 18h:20m:26s remains)
INFO - root - 2017-12-17 06:06:47.894157: step 43370, loss = 0.13, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 18h:05m:13s remains)
INFO - root - 2017-12-17 06:06:50.103733: step 43380, loss = 0.09, batch loss = 0.06 (35.9 examples/sec; 0.223 sec/batch; 17h:54m:22s remains)
INFO - root - 2017-12-17 06:06:52.370650: step 43390, loss = 0.11, batch loss = 0.08 (34.9 examples/sec; 0.229 sec/batch; 18h:23m:44s remains)
