INFO - Obj-Siam-FC - Running command 'main'
INFO - Obj-Siam-FC - Started run with ID "5"
INFO - root - preproces -- siamese_fc_color
WARNING - root - root is not explicitly specified, using default value: None
INFO - root - For training, we use instance size 255 - 2 * 8 ...
WARNING - root - init_method is not explicitly specified, using default value: None
INFO - root - Model moving average is disabled since decay factor is 0
2017-12-01 02:35:25.032062: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 02:35:25.032100: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 02:35:25.032106: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 02:35:25.032110: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 02:35:25.032114: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 02:35:25.696594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 5791:00:00.0
Total memory: 11.17GiB
Free memory: 11.11GiB
2017-12-01 02:35:25.696633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-12-01 02:35:25.696640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-12-01 02:35:25.696648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 5791:00:00.0)
INFO - root - Restore from last checkpoint: /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-0
INFO:tensorflow:Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-0
INFO - tensorflow - Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-0
INFO - root - Starting threads 0 ...

INFO - root - training for 332500 steps
INFO - root - 2017-12-01 02:35:29.966713: step 10, loss = 0.95, batch loss = 0.67 (52.9 examples/sec; 0.151 sec/batch; 13h:57m:30s remains)
INFO - root - 2017-12-01 02:35:31.556717: step 20, loss = 0.94, batch loss = 0.65 (51.9 examples/sec; 0.154 sec/batch; 14h:13m:28s remains)
INFO - root - 2017-12-01 02:35:33.179639: step 30, loss = 0.89, batch loss = 0.61 (52.5 examples/sec; 0.153 sec/batch; 14h:05m:06s remains)
INFO - root - 2017-12-01 02:35:34.696350: step 40, loss = 0.87, batch loss = 0.58 (53.4 examples/sec; 0.150 sec/batch; 13h:49m:25s remains)
INFO - root - 2017-12-01 02:35:36.250259: step 50, loss = 0.85, batch loss = 0.57 (54.3 examples/sec; 0.147 sec/batch; 13h:36m:03s remains)
INFO - root - 2017-12-01 02:35:37.777108: step 60, loss = 0.87, batch loss = 0.58 (51.9 examples/sec; 0.154 sec/batch; 14h:13m:59s remains)
INFO - root - 2017-12-01 02:35:39.276625: step 70, loss = 0.84, batch loss = 0.55 (53.2 examples/sec; 0.150 sec/batch; 13h:52m:50s remains)
INFO - root - 2017-12-01 02:35:40.793308: step 80, loss = 0.84, batch loss = 0.55 (52.2 examples/sec; 0.153 sec/batch; 14h:08m:47s remains)
INFO - root - 2017-12-01 02:35:42.309078: step 90, loss = 0.83, batch loss = 0.54 (53.3 examples/sec; 0.150 sec/batch; 13h:52m:19s remains)
INFO - root - 2017-12-01 02:35:43.849667: step 100, loss = 0.84, batch loss = 0.55 (51.5 examples/sec; 0.155 sec/batch; 14h:21m:16s remains)
INFO - root - 2017-12-01 02:35:45.503495: step 110, loss = 0.84, batch loss = 0.55 (53.8 examples/sec; 0.149 sec/batch; 13h:43m:57s remains)
INFO - root - 2017-12-01 02:35:47.023612: step 120, loss = 0.81, batch loss = 0.53 (53.3 examples/sec; 0.150 sec/batch; 13h:51m:07s remains)
INFO - root - 2017-12-01 02:35:48.561308: step 130, loss = 0.79, batch loss = 0.51 (49.6 examples/sec; 0.161 sec/batch; 14h:54m:08s remains)
INFO - root - 2017-12-01 02:35:50.083148: step 140, loss = 0.76, batch loss = 0.48 (53.0 examples/sec; 0.151 sec/batch; 13h:56m:15s remains)
INFO - root - 2017-12-01 02:35:51.634568: step 150, loss = 0.87, batch loss = 0.59 (53.5 examples/sec; 0.150 sec/batch; 13h:48m:30s remains)
INFO - root - 2017-12-01 02:35:53.144516: step 160, loss = 0.81, batch loss = 0.52 (53.4 examples/sec; 0.150 sec/batch; 13h:50m:34s remains)
INFO - root - 2017-12-01 02:35:54.653591: step 170, loss = 0.82, batch loss = 0.54 (53.9 examples/sec; 0.148 sec/batch; 13h:42m:16s remains)
INFO - root - 2017-12-01 02:35:56.179627: step 180, loss = 0.82, batch loss = 0.53 (52.1 examples/sec; 0.154 sec/batch; 14h:10m:41s remains)
INFO - root - 2017-12-01 02:35:57.714985: step 190, loss = 0.76, batch loss = 0.48 (51.1 examples/sec; 0.157 sec/batch; 14h:27m:33s remains)
INFO - root - 2017-12-01 02:35:59.237354: step 200, loss = 0.78, batch loss = 0.49 (52.5 examples/sec; 0.152 sec/batch; 14h:03m:32s remains)
INFO - root - 2017-12-01 02:36:00.872480: step 210, loss = 0.76, batch loss = 0.47 (50.8 examples/sec; 0.157 sec/batch; 14h:31m:36s remains)
INFO - root - 2017-12-01 02:36:02.397118: step 220, loss = 0.77, batch loss = 0.49 (53.9 examples/sec; 0.149 sec/batch; 13h:42m:28s remains)
INFO - root - 2017-12-01 02:36:03.912340: step 230, loss = 0.75, batch loss = 0.46 (53.1 examples/sec; 0.151 sec/batch; 13h:54m:22s remains)
INFO - root - 2017-12-01 02:36:05.446553: step 240, loss = 0.74, batch loss = 0.46 (52.6 examples/sec; 0.152 sec/batch; 14h:01m:42s remains)
INFO - root - 2017-12-01 02:36:06.962241: step 250, loss = 0.84, batch loss = 0.56 (53.0 examples/sec; 0.151 sec/batch; 13h:55m:12s remains)
INFO - root - 2017-12-01 02:36:08.471523: step 260, loss = 0.85, batch loss = 0.56 (53.1 examples/sec; 0.151 sec/batch; 13h:54m:31s remains)
INFO - root - 2017-12-01 02:36:10.016102: step 270, loss = 0.78, batch loss = 0.50 (51.0 examples/sec; 0.157 sec/batch; 14h:28m:41s remains)
INFO - root - 2017-12-01 02:36:11.542095: step 280, loss = 0.78, batch loss = 0.50 (52.6 examples/sec; 0.152 sec/batch; 14h:01m:51s remains)
INFO - root - 2017-12-01 02:36:13.069814: step 290, loss = 0.80, batch loss = 0.51 (51.9 examples/sec; 0.154 sec/batch; 14h:12m:50s remains)
INFO - root - 2017-12-01 02:36:14.602594: step 300, loss = 0.78, batch loss = 0.49 (53.0 examples/sec; 0.151 sec/batch; 13h:55m:42s remains)
INFO - root - 2017-12-01 02:36:16.215451: step 310, loss = 0.75, batch loss = 0.46 (50.9 examples/sec; 0.157 sec/batch; 14h:30m:30s remains)
INFO - root - 2017-12-01 02:36:17.753086: step 320, loss = 0.75, batch loss = 0.47 (52.1 examples/sec; 0.154 sec/batch; 14h:10m:17s remains)
INFO - root - 2017-12-01 02:36:19.296416: step 330, loss = 0.72, batch loss = 0.44 (51.3 examples/sec; 0.156 sec/batch; 14h:22m:39s remains)
INFO - root - 2017-12-01 02:36:20.839987: step 340, loss = 0.79, batch loss = 0.51 (51.3 examples/sec; 0.156 sec/batch; 14h:24m:01s remains)
INFO - root - 2017-12-01 02:36:22.392128: step 350, loss = 0.78, batch loss = 0.50 (52.2 examples/sec; 0.153 sec/batch; 14h:08m:18s remains)
INFO - root - 2017-12-01 02:36:23.949812: step 360, loss = 0.87, batch loss = 0.58 (52.4 examples/sec; 0.153 sec/batch; 14h:05m:10s remains)
INFO - root - 2017-12-01 02:36:25.500405: step 370, loss = 0.75, batch loss = 0.46 (51.6 examples/sec; 0.155 sec/batch; 14h:17m:25s remains)
INFO - root - 2017-12-01 02:36:27.022721: step 380, loss = 0.78, batch loss = 0.49 (52.4 examples/sec; 0.153 sec/batch; 14h:05m:31s remains)
INFO - root - 2017-12-01 02:36:28.559262: step 390, loss = 0.78, batch loss = 0.49 (53.4 examples/sec; 0.150 sec/batch; 13h:49m:35s remains)
INFO - root - 2017-12-01 02:36:30.096168: step 400, loss = 0.84, batch loss = 0.56 (53.5 examples/sec; 0.150 sec/batch; 13h:48m:21s remains)
INFO - root - 2017-12-01 02:36:31.673723: step 410, loss = 0.79, batch loss = 0.51 (51.3 examples/sec; 0.156 sec/batch; 14h:22m:57s remains)
INFO - root - 2017-12-01 02:36:33.201755: step 420, loss = 0.75, batch loss = 0.46 (52.5 examples/sec; 0.152 sec/batch; 14h:02m:55s remains)
INFO - root - 2017-12-01 02:36:34.737301: step 430, loss = 0.72, batch loss = 0.44 (51.9 examples/sec; 0.154 sec/batch; 14h:13m:24s remains)
INFO - root - 2017-12-01 02:36:36.283272: step 440, loss = 0.71, batch loss = 0.43 (51.8 examples/sec; 0.154 sec/batch; 14h:14m:08s remains)
INFO - root - 2017-12-01 02:36:37.827768: step 450, loss = 0.73, batch loss = 0.44 (51.8 examples/sec; 0.155 sec/batch; 14h:15m:12s remains)
INFO - root - 2017-12-01 02:36:39.383510: step 460, loss = 0.81, batch loss = 0.53 (49.6 examples/sec; 0.161 sec/batch; 14h:53m:02s remains)
INFO - root - 2017-12-01 02:36:40.930029: step 470, loss = 0.79, batch loss = 0.51 (53.9 examples/sec; 0.149 sec/batch; 13h:41m:56s remains)
INFO - root - 2017-12-01 02:36:42.473728: step 480, loss = 0.75, batch loss = 0.47 (50.6 examples/sec; 0.158 sec/batch; 14h:35m:39s remains)
INFO - root - 2017-12-01 02:36:44.019439: step 490, loss = 0.87, batch loss = 0.59 (51.8 examples/sec; 0.154 sec/batch; 14h:14m:29s remains)
INFO - root - 2017-12-01 02:36:45.556180: step 500, loss = 0.75, batch loss = 0.47 (53.1 examples/sec; 0.151 sec/batch; 13h:53m:47s remains)
INFO - root - 2017-12-01 02:36:47.158401: step 510, loss = 0.74, batch loss = 0.46 (52.1 examples/sec; 0.153 sec/batch; 14h:08m:48s remains)
INFO - root - 2017-12-01 02:36:48.704996: step 520, loss = 0.79, batch loss = 0.51 (50.6 examples/sec; 0.158 sec/batch; 14h:35m:27s remains)
INFO - root - 2017-12-01 02:36:50.259198: step 530, loss = 0.79, batch loss = 0.51 (49.4 examples/sec; 0.162 sec/batch; 14h:55m:21s remains)
INFO - root - 2017-12-01 02:36:51.798313: step 540, loss = 0.70, batch loss = 0.42 (52.4 examples/sec; 0.153 sec/batch; 14h:04m:50s remains)
INFO - root - 2017-12-01 02:36:53.337586: step 550, loss = 0.72, batch loss = 0.44 (52.4 examples/sec; 0.153 sec/batch; 14h:03m:53s remains)
INFO - root - 2017-12-01 02:36:54.895022: step 560, loss = 0.78, batch loss = 0.49 (49.9 examples/sec; 0.160 sec/batch; 14h:46m:31s remains)
INFO - root - 2017-12-01 02:36:56.451580: step 570, loss = 0.74, batch loss = 0.46 (51.4 examples/sec; 0.156 sec/batch; 14h:21m:38s remains)
INFO - root - 2017-12-01 02:36:57.975602: step 580, loss = 0.66, batch loss = 0.37 (52.0 examples/sec; 0.154 sec/batch; 14h:10m:30s remains)
INFO - root - 2017-12-01 02:36:59.553801: step 590, loss = 0.72, batch loss = 0.44 (50.5 examples/sec; 0.158 sec/batch; 14h:36m:16s remains)
INFO - root - 2017-12-01 02:37:01.097604: step 600, loss = 0.67, batch loss = 0.38 (50.2 examples/sec; 0.159 sec/batch; 14h:41m:20s remains)
INFO - root - 2017-12-01 02:37:02.706154: step 610, loss = 0.81, batch loss = 0.53 (54.2 examples/sec; 0.148 sec/batch; 13h:36m:07s remains)
INFO - root - 2017-12-01 02:37:04.267459: step 620, loss = 0.79, batch loss = 0.51 (53.7 examples/sec; 0.149 sec/batch; 13h:43m:26s remains)
INFO - root - 2017-12-01 02:37:05.808614: step 630, loss = 0.67, batch loss = 0.39 (53.0 examples/sec; 0.151 sec/batch; 13h:55m:25s remains)
INFO - root - 2017-12-01 02:37:07.365862: step 640, loss = 0.69, batch loss = 0.41 (51.6 examples/sec; 0.155 sec/batch; 14h:17m:51s remains)
INFO - root - 2017-12-01 02:37:08.921872: step 650, loss = 0.79, batch loss = 0.51 (50.5 examples/sec; 0.158 sec/batch; 14h:36m:11s remains)
INFO - root - 2017-12-01 02:37:10.475789: step 660, loss = 0.71, batch loss = 0.43 (51.0 examples/sec; 0.157 sec/batch; 14h:27m:26s remains)
INFO - root - 2017-12-01 02:37:12.025381: step 670, loss = 0.77, batch loss = 0.48 (51.4 examples/sec; 0.156 sec/batch; 14h:20m:09s remains)
INFO - root - 2017-12-01 02:37:13.565284: step 680, loss = 0.80, batch loss = 0.51 (53.6 examples/sec; 0.149 sec/batch; 13h:45m:35s remains)
INFO - root - 2017-12-01 02:37:15.091930: step 690, loss = 0.78, batch loss = 0.49 (54.8 examples/sec; 0.146 sec/batch; 13h:27m:56s remains)
INFO - root - 2017-12-01 02:37:16.626136: step 700, loss = 0.80, batch loss = 0.52 (53.5 examples/sec; 0.149 sec/batch; 13h:46m:29s remains)
INFO - root - 2017-12-01 02:37:18.279501: step 710, loss = 0.73, batch loss = 0.45 (51.3 examples/sec; 0.156 sec/batch; 14h:22m:11s remains)
INFO - root - 2017-12-01 02:37:19.818795: step 720, loss = 0.77, batch loss = 0.49 (52.1 examples/sec; 0.153 sec/batch; 14h:08m:32s remains)
INFO - root - 2017-12-01 02:37:21.356999: step 730, loss = 0.72, batch loss = 0.44 (53.5 examples/sec; 0.149 sec/batch; 13h:46m:11s remains)
INFO - root - 2017-12-01 02:37:22.899379: step 740, loss = 0.72, batch loss = 0.44 (51.3 examples/sec; 0.156 sec/batch; 14h:21m:40s remains)
INFO - root - 2017-12-01 02:37:24.446264: step 750, loss = 0.67, batch loss = 0.38 (51.3 examples/sec; 0.156 sec/batch; 14h:22m:03s remains)
INFO - root - 2017-12-01 02:37:26.010715: step 760, loss = 0.71, batch loss = 0.42 (51.9 examples/sec; 0.154 sec/batch; 14h:12m:34s remains)
INFO - root - 2017-12-01 02:37:27.540495: step 770, loss = 0.68, batch loss = 0.40 (53.3 examples/sec; 0.150 sec/batch; 13h:49m:34s remains)
INFO - root - 2017-12-01 02:37:29.088157: step 780, loss = 0.73, batch loss = 0.44 (51.7 examples/sec; 0.155 sec/batch; 14h:15m:13s remains)
INFO - root - 2017-12-01 02:37:30.646795: step 790, loss = 0.69, batch loss = 0.41 (52.1 examples/sec; 0.153 sec/batch; 14h:08m:11s remains)
INFO - root - 2017-12-01 02:37:32.174739: step 800, loss = 0.71, batch loss = 0.43 (51.1 examples/sec; 0.157 sec/batch; 14h:26m:03s remains)
INFO - root - 2017-12-01 02:37:33.792046: step 810, loss = 0.75, batch loss = 0.46 (52.0 examples/sec; 0.154 sec/batch; 14h:10m:59s remains)
INFO - root - 2017-12-01 02:37:35.354711: step 820, loss = 0.74, batch loss = 0.46 (49.0 examples/sec; 0.163 sec/batch; 15h:02m:58s remains)
INFO - root - 2017-12-01 02:37:36.886660: step 830, loss = 0.69, batch loss = 0.41 (53.3 examples/sec; 0.150 sec/batch; 13h:49m:12s remains)
INFO - root - 2017-12-01 02:37:38.443041: step 840, loss = 0.78, batch loss = 0.50 (51.1 examples/sec; 0.157 sec/batch; 14h:25m:22s remains)
INFO - root - 2017-12-01 02:37:40.013620: step 850, loss = 0.75, batch loss = 0.46 (49.1 examples/sec; 0.163 sec/batch; 15h:01m:19s remains)
INFO - root - 2017-12-01 02:37:41.564603: step 860, loss = 0.81, batch loss = 0.53 (50.9 examples/sec; 0.157 sec/batch; 14h:28m:56s remains)
INFO - root - 2017-12-01 02:37:43.114729: step 870, loss = 0.75, batch loss = 0.47 (51.5 examples/sec; 0.155 sec/batch; 14h:18m:34s remains)
INFO - root - 2017-12-01 02:37:44.658998: step 880, loss = 0.75, batch loss = 0.47 (51.1 examples/sec; 0.157 sec/batch; 14h:25m:45s remains)
INFO - root - 2017-12-01 02:37:46.214113: step 890, loss = 0.66, batch loss = 0.38 (52.5 examples/sec; 0.152 sec/batch; 14h:02m:11s remains)
INFO - root - 2017-12-01 02:37:47.774818: step 900, loss = 0.70, batch loss = 0.42 (50.4 examples/sec; 0.159 sec/batch; 14h:36m:26s remains)
INFO - root - 2017-12-01 02:37:49.391399: step 910, loss = 0.76, batch loss = 0.48 (51.1 examples/sec; 0.157 sec/batch; 14h:24m:58s remains)
INFO - root - 2017-12-01 02:37:50.937222: step 920, loss = 0.65, batch loss = 0.36 (51.2 examples/sec; 0.156 sec/batch; 14h:24m:01s remains)
INFO - root - 2017-12-01 02:37:52.482875: step 930, loss = 0.76, batch loss = 0.48 (51.9 examples/sec; 0.154 sec/batch; 14h:11m:17s remains)
INFO - root - 2017-12-01 02:37:54.048635: step 940, loss = 0.82, batch loss = 0.54 (52.3 examples/sec; 0.153 sec/batch; 14h:04m:43s remains)
INFO - root - 2017-12-01 02:37:55.619127: step 950, loss = 0.67, batch loss = 0.39 (52.9 examples/sec; 0.151 sec/batch; 13h:55m:20s remains)
INFO - root - 2017-12-01 02:37:57.144205: step 960, loss = 0.74, batch loss = 0.45 (52.4 examples/sec; 0.153 sec/batch; 14h:03m:36s remains)
INFO - root - 2017-12-01 02:37:58.703452: step 970, loss = 0.68, batch loss = 0.39 (50.0 examples/sec; 0.160 sec/batch; 14h:44m:06s remains)
INFO - root - 2017-12-01 02:38:00.279343: step 980, loss = 0.76, batch loss = 0.47 (49.2 examples/sec; 0.163 sec/batch; 14h:58m:00s remains)
INFO - root - 2017-12-01 02:38:01.838046: step 990, loss = 0.71, batch loss = 0.43 (53.7 examples/sec; 0.149 sec/batch; 13h:42m:40s remains)
INFO - root - 2017-12-01 02:38:03.374205: step 1000, loss = 0.75, batch loss = 0.46 (52.3 examples/sec; 0.153 sec/batch; 14h:04m:20s remains)
INFO - root - 2017-12-01 02:38:05.007331: step 1010, loss = 0.70, batch loss = 0.42 (51.2 examples/sec; 0.156 sec/batch; 14h:22m:58s remains)
INFO - root - 2017-12-01 02:38:06.569201: step 1020, loss = 0.76, batch loss = 0.48 (53.5 examples/sec; 0.149 sec/batch; 13h:45m:38s remains)
INFO - root - 2017-12-01 02:38:08.117032: step 1030, loss = 0.68, batch loss = 0.40 (52.8 examples/sec; 0.151 sec/batch; 13h:56m:41s remains)
INFO - root - 2017-12-01 02:38:09.714082: step 1040, loss = 0.71, batch loss = 0.43 (52.3 examples/sec; 0.153 sec/batch; 14h:04m:56s remains)
INFO - root - 2017-12-01 02:38:11.291571: step 1050, loss = 0.69, batch loss = 0.41 (51.1 examples/sec; 0.157 sec/batch; 14h:25m:09s remains)
INFO - root - 2017-12-01 02:38:12.855604: step 1060, loss = 0.68, batch loss = 0.40 (51.4 examples/sec; 0.156 sec/batch; 14h:19m:45s remains)
INFO - root - 2017-12-01 02:38:14.427555: step 1070, loss = 0.73, batch loss = 0.45 (52.2 examples/sec; 0.153 sec/batch; 14h:05m:56s remains)
INFO - root - 2017-12-01 02:38:15.972440: step 1080, loss = 0.72, batch loss = 0.44 (52.7 examples/sec; 0.152 sec/batch; 13h:57m:57s remains)
INFO - root - 2017-12-01 02:38:17.526000: step 1090, loss = 0.70, batch loss = 0.42 (52.9 examples/sec; 0.151 sec/batch; 13h:55m:11s remains)
INFO - root - 2017-12-01 02:38:19.097887: step 1100, loss = 0.80, batch loss = 0.52 (49.8 examples/sec; 0.161 sec/batch; 14h:47m:48s remains)
INFO - root - 2017-12-01 02:38:20.690868: step 1110, loss = 0.65, batch loss = 0.36 (52.1 examples/sec; 0.153 sec/batch; 14h:07m:36s remains)
INFO - root - 2017-12-01 02:38:22.270445: step 1120, loss = 0.74, batch loss = 0.46 (51.8 examples/sec; 0.154 sec/batch; 14h:12m:31s remains)
INFO - root - 2017-12-01 02:38:23.822473: step 1130, loss = 0.66, batch loss = 0.38 (53.0 examples/sec; 0.151 sec/batch; 13h:54m:00s remains)
INFO - root - 2017-12-01 02:38:25.380991: step 1140, loss = 0.71, batch loss = 0.42 (51.5 examples/sec; 0.155 sec/batch; 14h:17m:08s remains)
INFO - root - 2017-12-01 02:38:26.944226: step 1150, loss = 0.66, batch loss = 0.38 (51.9 examples/sec; 0.154 sec/batch; 14h:11m:39s remains)
INFO - root - 2017-12-01 02:38:28.502162: step 1160, loss = 0.64, batch loss = 0.36 (50.7 examples/sec; 0.158 sec/batch; 14h:32m:07s remains)
INFO - root - 2017-12-01 02:38:30.065299: step 1170, loss = 0.77, batch loss = 0.49 (52.6 examples/sec; 0.152 sec/batch; 14h:00m:11s remains)
INFO - root - 2017-12-01 02:38:31.641261: step 1180, loss = 0.73, batch loss = 0.44 (50.9 examples/sec; 0.157 sec/batch; 14h:27m:51s remains)
INFO - root - 2017-12-01 02:38:33.210065: step 1190, loss = 0.77, batch loss = 0.48 (51.3 examples/sec; 0.156 sec/batch; 14h:21m:46s remains)
INFO - root - 2017-12-01 02:38:34.759571: step 1200, loss = 0.74, batch loss = 0.46 (51.5 examples/sec; 0.155 sec/batch; 14h:17m:42s remains)
INFO - root - 2017-12-01 02:38:36.397803: step 1210, loss = 0.65, batch loss = 0.37 (51.2 examples/sec; 0.156 sec/batch; 14h:23m:31s remains)
INFO - root - 2017-12-01 02:38:37.943856: step 1220, loss = 0.69, batch loss = 0.40 (51.7 examples/sec; 0.155 sec/batch; 14h:14m:55s remains)
INFO - root - 2017-12-01 02:38:39.500119: step 1230, loss = 0.70, batch loss = 0.42 (51.3 examples/sec; 0.156 sec/batch; 14h:21m:47s remains)
INFO - root - 2017-12-01 02:38:41.067570: step 1240, loss = 0.73, batch loss = 0.44 (51.7 examples/sec; 0.155 sec/batch; 14h:14m:41s remains)
INFO - root - 2017-12-01 02:38:42.614175: step 1250, loss = 0.73, batch loss = 0.45 (51.7 examples/sec; 0.155 sec/batch; 14h:14m:01s remains)
INFO - root - 2017-12-01 02:38:44.198338: step 1260, loss = 0.69, batch loss = 0.41 (50.9 examples/sec; 0.157 sec/batch; 14h:28m:20s remains)
INFO - root - 2017-12-01 02:38:45.763948: step 1270, loss = 0.78, batch loss = 0.49 (51.7 examples/sec; 0.155 sec/batch; 14h:13m:50s remains)
INFO - root - 2017-12-01 02:38:47.324685: step 1280, loss = 0.74, batch loss = 0.46 (50.8 examples/sec; 0.157 sec/batch; 14h:28m:34s remains)
INFO - root - 2017-12-01 02:38:48.893278: step 1290, loss = 0.67, batch loss = 0.38 (49.0 examples/sec; 0.163 sec/batch; 15h:00m:26s remains)
INFO - root - 2017-12-01 02:38:50.455872: step 1300, loss = 0.71, batch loss = 0.43 (52.3 examples/sec; 0.153 sec/batch; 14h:04m:27s remains)
INFO - root - 2017-12-01 02:38:52.103544: step 1310, loss = 0.69, batch loss = 0.40 (50.2 examples/sec; 0.159 sec/batch; 14h:39m:27s remains)
INFO - root - 2017-12-01 02:38:53.658958: step 1320, loss = 0.71, batch loss = 0.43 (50.6 examples/sec; 0.158 sec/batch; 14h:32m:47s remains)
INFO - root - 2017-12-01 02:38:55.206176: step 1330, loss = 0.71, batch loss = 0.43 (52.6 examples/sec; 0.152 sec/batch; 13h:59m:17s remains)
INFO - root - 2017-12-01 02:38:56.782049: step 1340, loss = 0.70, batch loss = 0.42 (51.7 examples/sec; 0.155 sec/batch; 14h:13m:48s remains)
INFO - root - 2017-12-01 02:38:58.340022: step 1350, loss = 0.72, batch loss = 0.44 (51.8 examples/sec; 0.154 sec/batch; 14h:12m:35s remains)
INFO - root - 2017-12-01 02:38:59.903460: step 1360, loss = 0.63, batch loss = 0.35 (51.7 examples/sec; 0.155 sec/batch; 14h:14m:17s remains)
INFO - root - 2017-12-01 02:39:01.449925: step 1370, loss = 0.82, batch loss = 0.54 (50.6 examples/sec; 0.158 sec/batch; 14h:32m:15s remains)
INFO - root - 2017-12-01 02:39:03.010826: step 1380, loss = 0.74, batch loss = 0.46 (52.3 examples/sec; 0.153 sec/batch; 14h:03m:45s remains)
INFO - root - 2017-12-01 02:39:04.583016: step 1390, loss = 0.68, batch loss = 0.40 (52.1 examples/sec; 0.154 sec/batch; 14h:07m:16s remains)
INFO - root - 2017-12-01 02:39:06.158845: step 1400, loss = 0.83, batch loss = 0.55 (50.2 examples/sec; 0.159 sec/batch; 14h:38m:57s remains)
INFO - root - 2017-12-01 02:39:07.824926: step 1410, loss = 0.66, batch loss = 0.37 (50.9 examples/sec; 0.157 sec/batch; 14h:27m:48s remains)
INFO - root - 2017-12-01 02:39:09.368897: step 1420, loss = 0.67, batch loss = 0.38 (52.4 examples/sec; 0.153 sec/batch; 14h:02m:58s remains)
INFO - root - 2017-12-01 02:39:10.950725: step 1430, loss = 0.66, batch loss = 0.38 (50.0 examples/sec; 0.160 sec/batch; 14h:43m:29s remains)
INFO - root - 2017-12-01 02:39:12.503398: step 1440, loss = 0.69, batch loss = 0.41 (51.9 examples/sec; 0.154 sec/batch; 14h:10m:41s remains)
INFO - root - 2017-12-01 02:39:14.053300: step 1450, loss = 0.67, batch loss = 0.39 (52.1 examples/sec; 0.154 sec/batch; 14h:07m:03s remains)
INFO - root - 2017-12-01 02:39:15.604825: step 1460, loss = 0.71, batch loss = 0.43 (50.9 examples/sec; 0.157 sec/batch; 14h:27m:17s remains)
INFO - root - 2017-12-01 02:39:17.170994: step 1470, loss = 0.66, batch loss = 0.38 (50.8 examples/sec; 0.157 sec/batch; 14h:28m:45s remains)
INFO - root - 2017-12-01 02:39:18.734715: step 1480, loss = 0.69, batch loss = 0.41 (51.7 examples/sec; 0.155 sec/batch; 14h:13m:19s remains)
INFO - root - 2017-12-01 02:39:20.300314: step 1490, loss = 0.66, batch loss = 0.38 (51.8 examples/sec; 0.154 sec/batch; 14h:11m:37s remains)
INFO - root - 2017-12-01 02:39:21.869508: step 1500, loss = 0.72, batch loss = 0.44 (50.4 examples/sec; 0.159 sec/batch; 14h:36m:25s remains)
INFO - root - 2017-12-01 02:39:23.496553: step 1510, loss = 0.71, batch loss = 0.43 (50.4 examples/sec; 0.159 sec/batch; 14h:36m:04s remains)
INFO - root - 2017-12-01 02:39:25.044779: step 1520, loss = 0.70, batch loss = 0.42 (51.3 examples/sec; 0.156 sec/batch; 14h:20m:11s remains)
INFO - root - 2017-12-01 02:39:26.629126: step 1530, loss = 0.63, batch loss = 0.35 (50.9 examples/sec; 0.157 sec/batch; 14h:26m:19s remains)
INFO - root - 2017-12-01 02:39:28.197995: step 1540, loss = 0.72, batch loss = 0.44 (49.0 examples/sec; 0.163 sec/batch; 15h:00m:58s remains)
INFO - root - 2017-12-01 02:39:29.751801: step 1550, loss = 0.81, batch loss = 0.53 (51.8 examples/sec; 0.155 sec/batch; 14h:12m:17s remains)
INFO - root - 2017-12-01 02:39:31.329461: step 1560, loss = 0.63, batch loss = 0.35 (51.1 examples/sec; 0.156 sec/batch; 14h:22m:49s remains)
INFO - root - 2017-12-01 02:39:32.885399: step 1570, loss = 0.72, batch loss = 0.44 (50.2 examples/sec; 0.159 sec/batch; 14h:39m:36s remains)
INFO - root - 2017-12-01 02:39:34.445106: step 1580, loss = 0.72, batch loss = 0.44 (51.6 examples/sec; 0.155 sec/batch; 14h:15m:34s remains)
INFO - root - 2017-12-01 02:39:36.011474: step 1590, loss = 0.72, batch loss = 0.44 (53.5 examples/sec; 0.150 sec/batch; 13h:44m:54s remains)
INFO - root - 2017-12-01 02:39:37.582172: step 1600, loss = 0.69, batch loss = 0.41 (52.2 examples/sec; 0.153 sec/batch; 14h:05m:57s remains)
INFO - root - 2017-12-01 02:39:39.223281: step 1610, loss = 0.64, batch loss = 0.35 (47.3 examples/sec; 0.169 sec/batch; 15h:32m:17s remains)
INFO - root - 2017-12-01 02:39:40.789209: step 1620, loss = 0.64, batch loss = 0.36 (52.3 examples/sec; 0.153 sec/batch; 14h:04m:01s remains)
INFO - root - 2017-12-01 02:39:42.369901: step 1630, loss = 0.64, batch loss = 0.36 (50.9 examples/sec; 0.157 sec/batch; 14h:26m:01s remains)
INFO - root - 2017-12-01 02:39:43.934858: step 1640, loss = 0.69, batch loss = 0.41 (50.8 examples/sec; 0.157 sec/batch; 14h:27m:33s remains)
INFO - root - 2017-12-01 02:39:45.495198: step 1650, loss = 0.70, batch loss = 0.42 (49.8 examples/sec; 0.161 sec/batch; 14h:45m:07s remains)
INFO - root - 2017-12-01 02:39:47.057724: step 1660, loss = 0.58, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 14h:18m:15s remains)
INFO - root - 2017-12-01 02:39:48.637187: step 1670, loss = 0.64, batch loss = 0.35 (52.3 examples/sec; 0.153 sec/batch; 14h:03m:11s remains)
INFO - root - 2017-12-01 02:39:50.198522: step 1680, loss = 0.65, batch loss = 0.37 (50.8 examples/sec; 0.157 sec/batch; 14h:28m:09s remains)
INFO - root - 2017-12-01 02:39:51.747343: step 1690, loss = 0.69, batch loss = 0.41 (50.8 examples/sec; 0.157 sec/batch; 14h:27m:39s remains)
INFO - root - 2017-12-01 02:39:53.311594: step 1700, loss = 0.77, batch loss = 0.49 (51.4 examples/sec; 0.156 sec/batch; 14h:18m:02s remains)
INFO - root - 2017-12-01 02:39:54.973544: step 1710, loss = 0.66, batch loss = 0.38 (51.2 examples/sec; 0.156 sec/batch; 14h:20m:42s remains)
INFO - root - 2017-12-01 02:39:56.536931: step 1720, loss = 0.78, batch loss = 0.50 (51.1 examples/sec; 0.156 sec/batch; 14h:22m:18s remains)
INFO - root - 2017-12-01 02:39:58.093721: step 1730, loss = 0.65, batch loss = 0.37 (52.2 examples/sec; 0.153 sec/batch; 14h:04m:20s remains)
INFO - root - 2017-12-01 02:39:59.673322: step 1740, loss = 0.62, batch loss = 0.34 (50.8 examples/sec; 0.157 sec/batch; 14h:27m:35s remains)
INFO - root - 2017-12-01 02:40:01.245027: step 1750, loss = 0.65, batch loss = 0.37 (49.9 examples/sec; 0.160 sec/batch; 14h:43m:04s remains)
INFO - root - 2017-12-01 02:40:02.818672: step 1760, loss = 0.61, batch loss = 0.33 (51.1 examples/sec; 0.157 sec/batch; 14h:23m:29s remains)
INFO - root - 2017-12-01 02:40:04.380266: step 1770, loss = 0.66, batch loss = 0.38 (51.4 examples/sec; 0.156 sec/batch; 14h:17m:48s remains)
INFO - root - 2017-12-01 02:40:05.942264: step 1780, loss = 0.63, batch loss = 0.35 (51.8 examples/sec; 0.154 sec/batch; 14h:10m:55s remains)
INFO - root - 2017-12-01 02:40:07.508788: step 1790, loss = 0.73, batch loss = 0.44 (51.7 examples/sec; 0.155 sec/batch; 14h:12m:31s remains)
INFO - root - 2017-12-01 02:40:09.070540: step 1800, loss = 0.56, batch loss = 0.28 (50.2 examples/sec; 0.159 sec/batch; 14h:38m:27s remains)
INFO - root - 2017-12-01 02:40:10.717302: step 1810, loss = 0.62, batch loss = 0.34 (50.3 examples/sec; 0.159 sec/batch; 14h:36m:46s remains)
INFO - root - 2017-12-01 02:40:12.286766: step 1820, loss = 0.57, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 14h:25m:34s remains)
INFO - root - 2017-12-01 02:40:13.848108: step 1830, loss = 0.88, batch loss = 0.60 (50.1 examples/sec; 0.160 sec/batch; 14h:39m:57s remains)
INFO - root - 2017-12-01 02:40:15.403389: step 1840, loss = 0.60, batch loss = 0.32 (52.0 examples/sec; 0.154 sec/batch; 14h:08m:30s remains)
INFO - root - 2017-12-01 02:40:16.980009: step 1850, loss = 0.62, batch loss = 0.34 (52.1 examples/sec; 0.154 sec/batch; 14h:06m:00s remains)
INFO - root - 2017-12-01 02:40:18.536621: step 1860, loss = 0.62, batch loss = 0.34 (52.7 examples/sec; 0.152 sec/batch; 13h:56m:07s remains)
INFO - root - 2017-12-01 02:40:20.109664: step 1870, loss = 0.69, batch loss = 0.41 (49.9 examples/sec; 0.160 sec/batch; 14h:43m:57s remains)
INFO - root - 2017-12-01 02:40:21.695323: step 1880, loss = 0.75, batch loss = 0.47 (52.7 examples/sec; 0.152 sec/batch; 13h:56m:44s remains)
INFO - root - 2017-12-01 02:40:23.279982: step 1890, loss = 0.64, batch loss = 0.36 (50.3 examples/sec; 0.159 sec/batch; 14h:36m:51s remains)
INFO - root - 2017-12-01 02:40:24.835754: step 1900, loss = 0.80, batch loss = 0.52 (52.6 examples/sec; 0.152 sec/batch; 13h:57m:27s remains)
INFO - root - 2017-12-01 02:40:26.441724: step 1910, loss = 0.66, batch loss = 0.38 (52.7 examples/sec; 0.152 sec/batch; 13h:55m:40s remains)
INFO - root - 2017-12-01 02:40:28.023699: step 1920, loss = 0.66, batch loss = 0.38 (51.4 examples/sec; 0.156 sec/batch; 14h:17m:43s remains)
INFO - root - 2017-12-01 02:40:29.591649: step 1930, loss = 0.68, batch loss = 0.40 (52.0 examples/sec; 0.154 sec/batch; 14h:07m:02s remains)
INFO - root - 2017-12-01 02:40:31.164233: step 1940, loss = 0.64, batch loss = 0.36 (50.5 examples/sec; 0.159 sec/batch; 14h:33m:35s remains)
INFO - root - 2017-12-01 02:40:32.716658: step 1950, loss = 0.56, batch loss = 0.28 (51.8 examples/sec; 0.154 sec/batch; 14h:11m:09s remains)
INFO - root - 2017-12-01 02:40:34.281583: step 1960, loss = 0.76, batch loss = 0.48 (48.2 examples/sec; 0.166 sec/batch; 15h:13m:26s remains)
INFO - root - 2017-12-01 02:40:35.855945: step 1970, loss = 0.71, batch loss = 0.43 (51.1 examples/sec; 0.156 sec/batch; 14h:21m:43s remains)
INFO - root - 2017-12-01 02:40:37.431258: step 1980, loss = 0.76, batch loss = 0.48 (50.6 examples/sec; 0.158 sec/batch; 14h:30m:18s remains)
INFO - root - 2017-12-01 02:40:39.037651: step 1990, loss = 0.62, batch loss = 0.33 (49.0 examples/sec; 0.163 sec/batch; 15h:00m:00s remains)
INFO - root - 2017-12-01 02:40:40.604963: step 2000, loss = 0.64, batch loss = 0.36 (51.0 examples/sec; 0.157 sec/batch; 14h:24m:43s remains)
INFO - root - 2017-12-01 02:40:42.231881: step 2010, loss = 0.77, batch loss = 0.49 (51.6 examples/sec; 0.155 sec/batch; 14h:14m:28s remains)
INFO - root - 2017-12-01 02:40:43.795900: step 2020, loss = 0.64, batch loss = 0.36 (50.1 examples/sec; 0.160 sec/batch; 14h:39m:22s remains)
INFO - root - 2017-12-01 02:40:45.359319: step 2030, loss = 0.56, batch loss = 0.28 (52.6 examples/sec; 0.152 sec/batch; 13h:57m:54s remains)
INFO - root - 2017-12-01 02:40:46.954582: step 2040, loss = 0.74, batch loss = 0.46 (51.2 examples/sec; 0.156 sec/batch; 14h:19m:51s remains)
INFO - root - 2017-12-01 02:40:48.507719: step 2050, loss = 0.63, batch loss = 0.35 (52.2 examples/sec; 0.153 sec/batch; 14h:04m:38s remains)
INFO - root - 2017-12-01 02:40:50.079181: step 2060, loss = 0.63, batch loss = 0.35 (48.5 examples/sec; 0.165 sec/batch; 15h:08m:00s remains)
INFO - root - 2017-12-01 02:40:51.624932: step 2070, loss = 0.67, batch loss = 0.39 (52.4 examples/sec; 0.153 sec/batch; 14h:01m:21s remains)
INFO - root - 2017-12-01 02:40:53.206482: step 2080, loss = 0.70, batch loss = 0.42 (51.6 examples/sec; 0.155 sec/batch; 14h:14m:37s remains)
INFO - root - 2017-12-01 02:40:54.759289: step 2090, loss = 0.65, batch loss = 0.37 (51.8 examples/sec; 0.155 sec/batch; 14h:11m:15s remains)
INFO - root - 2017-12-01 02:40:56.342628: step 2100, loss = 0.68, batch loss = 0.40 (50.6 examples/sec; 0.158 sec/batch; 14h:29m:53s remains)
INFO - root - 2017-12-01 02:40:57.984848: step 2110, loss = 0.62, batch loss = 0.34 (50.9 examples/sec; 0.157 sec/batch; 14h:25m:22s remains)
INFO - root - 2017-12-01 02:40:59.569516: step 2120, loss = 0.80, batch loss = 0.52 (50.4 examples/sec; 0.159 sec/batch; 14h:33m:36s remains)
INFO - root - 2017-12-01 02:41:01.125149: step 2130, loss = 0.68, batch loss = 0.40 (51.0 examples/sec; 0.157 sec/batch; 14h:23m:47s remains)
INFO - root - 2017-12-01 02:41:02.714558: step 2140, loss = 0.73, batch loss = 0.45 (51.6 examples/sec; 0.155 sec/batch; 14h:14m:05s remains)
INFO - root - 2017-12-01 02:41:04.268481: step 2150, loss = 0.78, batch loss = 0.50 (51.0 examples/sec; 0.157 sec/batch; 14h:24m:23s remains)
INFO - root - 2017-12-01 02:41:05.843659: step 2160, loss = 0.71, batch loss = 0.43 (50.5 examples/sec; 0.158 sec/batch; 14h:31m:23s remains)
INFO - root - 2017-12-01 02:41:07.409806: step 2170, loss = 0.65, batch loss = 0.37 (50.1 examples/sec; 0.160 sec/batch; 14h:39m:55s remains)
INFO - root - 2017-12-01 02:41:09.008515: step 2180, loss = 0.65, batch loss = 0.37 (51.9 examples/sec; 0.154 sec/batch; 14h:08m:39s remains)
INFO - root - 2017-12-01 02:41:10.576413: step 2190, loss = 0.66, batch loss = 0.38 (51.8 examples/sec; 0.154 sec/batch; 14h:09m:37s remains)
INFO - root - 2017-12-01 02:41:12.177382: step 2200, loss = 0.66, batch loss = 0.38 (49.3 examples/sec; 0.162 sec/batch; 14h:54m:01s remains)
INFO - root - 2017-12-01 02:41:13.822883: step 2210, loss = 0.72, batch loss = 0.44 (51.7 examples/sec; 0.155 sec/batch; 14h:11m:39s remains)
INFO - root - 2017-12-01 02:41:15.381077: step 2220, loss = 0.66, batch loss = 0.38 (50.6 examples/sec; 0.158 sec/batch; 14h:31m:01s remains)
INFO - root - 2017-12-01 02:41:16.937392: step 2230, loss = 0.70, batch loss = 0.42 (49.0 examples/sec; 0.163 sec/batch; 14h:58m:57s remains)
INFO - root - 2017-12-01 02:41:18.508982: step 2240, loss = 0.57, batch loss = 0.29 (52.7 examples/sec; 0.152 sec/batch; 13h:55m:07s remains)
INFO - root - 2017-12-01 02:41:20.076378: step 2250, loss = 0.66, batch loss = 0.38 (50.6 examples/sec; 0.158 sec/batch; 14h:30m:17s remains)
INFO - root - 2017-12-01 02:41:21.655231: step 2260, loss = 0.60, batch loss = 0.32 (51.3 examples/sec; 0.156 sec/batch; 14h:18m:07s remains)
INFO - root - 2017-12-01 02:41:23.210372: step 2270, loss = 0.70, batch loss = 0.42 (51.2 examples/sec; 0.156 sec/batch; 14h:19m:41s remains)
INFO - root - 2017-12-01 02:41:24.753033: step 2280, loss = 0.68, batch loss = 0.40 (51.6 examples/sec; 0.155 sec/batch; 14h:12m:58s remains)
INFO - root - 2017-12-01 02:41:26.341651: step 2290, loss = 0.65, batch loss = 0.37 (52.7 examples/sec; 0.152 sec/batch; 13h:56m:09s remains)
INFO - root - 2017-12-01 02:41:27.887285: step 2300, loss = 0.61, batch loss = 0.33 (52.7 examples/sec; 0.152 sec/batch; 13h:55m:13s remains)
INFO - root - 2017-12-01 02:41:29.500916: step 2310, loss = 0.73, batch loss = 0.45 (52.2 examples/sec; 0.153 sec/batch; 14h:03m:53s remains)
INFO - root - 2017-12-01 02:41:31.053332: step 2320, loss = 0.78, batch loss = 0.51 (51.5 examples/sec; 0.155 sec/batch; 14h:15m:09s remains)
INFO - root - 2017-12-01 02:41:32.631026: step 2330, loss = 0.63, batch loss = 0.35 (52.5 examples/sec; 0.152 sec/batch; 13h:58m:10s remains)
INFO - root - 2017-12-01 02:41:34.215895: step 2340, loss = 0.65, batch loss = 0.37 (51.5 examples/sec; 0.155 sec/batch; 14h:14m:31s remains)
INFO - root - 2017-12-01 02:41:35.765170: step 2350, loss = 0.67, batch loss = 0.39 (51.3 examples/sec; 0.156 sec/batch; 14h:17m:25s remains)
INFO - root - 2017-12-01 02:41:37.332623: step 2360, loss = 0.64, batch loss = 0.36 (50.5 examples/sec; 0.158 sec/batch; 14h:31m:03s remains)
INFO - root - 2017-12-01 02:41:38.899440: step 2370, loss = 0.61, batch loss = 0.33 (53.1 examples/sec; 0.151 sec/batch; 13h:48m:53s remains)
INFO - root - 2017-12-01 02:41:40.463470: step 2380, loss = 0.62, batch loss = 0.34 (52.4 examples/sec; 0.153 sec/batch; 14h:00m:10s remains)
INFO - root - 2017-12-01 02:41:42.027065: step 2390, loss = 0.83, batch loss = 0.55 (50.6 examples/sec; 0.158 sec/batch; 14h:30m:11s remains)
INFO - root - 2017-12-01 02:41:43.594528: step 2400, loss = 0.62, batch loss = 0.34 (49.3 examples/sec; 0.162 sec/batch; 14h:52m:54s remains)
INFO - root - 2017-12-01 02:41:45.238516: step 2410, loss = 0.65, batch loss = 0.37 (51.7 examples/sec; 0.155 sec/batch; 14h:12m:00s remains)
INFO - root - 2017-12-01 02:41:46.809373: step 2420, loss = 0.71, batch loss = 0.43 (51.5 examples/sec; 0.155 sec/batch; 14h:14m:20s remains)
INFO - root - 2017-12-01 02:41:48.361384: step 2430, loss = 0.70, batch loss = 0.42 (51.3 examples/sec; 0.156 sec/batch; 14h:17m:35s remains)
INFO - root - 2017-12-01 02:41:49.919831: step 2440, loss = 0.60, batch loss = 0.32 (51.5 examples/sec; 0.155 sec/batch; 14h:14m:50s remains)
INFO - root - 2017-12-01 02:41:51.492430: step 2450, loss = 0.67, batch loss = 0.39 (52.0 examples/sec; 0.154 sec/batch; 14h:06m:17s remains)
INFO - root - 2017-12-01 02:41:53.088413: step 2460, loss = 0.64, batch loss = 0.36 (51.3 examples/sec; 0.156 sec/batch; 14h:17m:42s remains)
INFO - root - 2017-12-01 02:41:54.645890: step 2470, loss = 0.65, batch loss = 0.37 (51.3 examples/sec; 0.156 sec/batch; 14h:17m:22s remains)
INFO - root - 2017-12-01 02:41:56.254209: step 2480, loss = 0.64, batch loss = 0.37 (52.4 examples/sec; 0.153 sec/batch; 13h:59m:41s remains)
INFO - root - 2017-12-01 02:41:57.805437: step 2490, loss = 0.58, batch loss = 0.30 (51.9 examples/sec; 0.154 sec/batch; 14h:07m:37s remains)
INFO - root - 2017-12-01 02:41:59.383588: step 2500, loss = 0.67, batch loss = 0.39 (50.9 examples/sec; 0.157 sec/batch; 14h:24m:12s remains)
INFO - root - 2017-12-01 02:42:01.000248: step 2510, loss = 0.65, batch loss = 0.37 (51.5 examples/sec; 0.155 sec/batch; 14h:14m:41s remains)
INFO - root - 2017-12-01 02:42:02.587092: step 2520, loss = 0.64, batch loss = 0.36 (51.9 examples/sec; 0.154 sec/batch; 14h:08m:14s remains)
INFO - root - 2017-12-01 02:42:04.154641: step 2530, loss = 0.57, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 14h:28m:24s remains)
INFO - root - 2017-12-01 02:42:05.727605: step 2540, loss = 0.62, batch loss = 0.34 (52.3 examples/sec; 0.153 sec/batch; 14h:00m:32s remains)
INFO - root - 2017-12-01 02:42:07.314736: step 2550, loss = 0.63, batch loss = 0.35 (51.4 examples/sec; 0.156 sec/batch; 14h:15m:33s remains)
INFO - root - 2017-12-01 02:42:08.884578: step 2560, loss = 0.74, batch loss = 0.46 (50.9 examples/sec; 0.157 sec/batch; 14h:23m:40s remains)
INFO - root - 2017-12-01 02:42:10.436014: step 2570, loss = 0.81, batch loss = 0.53 (50.6 examples/sec; 0.158 sec/batch; 14h:29m:23s remains)
INFO - root - 2017-12-01 02:42:12.012962: step 2580, loss = 0.69, batch loss = 0.41 (49.1 examples/sec; 0.163 sec/batch; 14h:55m:52s remains)
INFO - root - 2017-12-01 02:42:13.581668: step 2590, loss = 0.61, batch loss = 0.33 (51.5 examples/sec; 0.155 sec/batch; 14h:14m:04s remains)
INFO - root - 2017-12-01 02:42:15.169884: step 2600, loss = 0.75, batch loss = 0.47 (49.9 examples/sec; 0.160 sec/batch; 14h:41m:03s remains)
INFO - root - 2017-12-01 02:42:16.822399: step 2610, loss = 0.59, batch loss = 0.31 (52.5 examples/sec; 0.152 sec/batch; 13h:57m:28s remains)
INFO - root - 2017-12-01 02:42:18.406029: step 2620, loss = 0.67, batch loss = 0.39 (51.2 examples/sec; 0.156 sec/batch; 14h:18m:37s remains)
INFO - root - 2017-12-01 02:42:19.975421: step 2630, loss = 0.64, batch loss = 0.36 (51.8 examples/sec; 0.154 sec/batch; 14h:08m:37s remains)
INFO - root - 2017-12-01 02:42:21.541023: step 2640, loss = 0.64, batch loss = 0.36 (51.6 examples/sec; 0.155 sec/batch; 14h:12m:36s remains)
INFO - root - 2017-12-01 02:42:23.131669: step 2650, loss = 0.61, batch loss = 0.33 (51.9 examples/sec; 0.154 sec/batch; 14h:07m:43s remains)
INFO - root - 2017-12-01 02:42:26.160333: step 2660, loss = 0.61, batch loss = 0.34 (35.9 examples/sec; 0.223 sec/batch; 20h:25m:09s remains)
INFO - root - 2017-12-01 02:42:29.403160: step 2670, loss = 0.64, batch loss = 0.36 (51.4 examples/sec; 0.156 sec/batch; 14h:16m:22s remains)
INFO - root - 2017-12-01 02:42:32.108035: step 2680, loss = 0.63, batch loss = 0.35 (13.4 examples/sec; 0.597 sec/batch; 54h:43m:33s remains)
INFO - root - 2017-12-01 02:42:34.199868: step 2690, loss = 0.68, batch loss = 0.40 (51.6 examples/sec; 0.155 sec/batch; 14h:11m:44s remains)
INFO - root - 2017-12-01 02:42:36.594277: step 2700, loss = 0.74, batch loss = 0.46 (32.2 examples/sec; 0.248 sec/batch; 22h:44m:59s remains)
INFO - root - 2017-12-01 02:42:38.526196: step 2710, loss = 0.74, batch loss = 0.46 (52.6 examples/sec; 0.152 sec/batch; 13h:55m:22s remains)
INFO - root - 2017-12-01 02:42:40.368182: step 2720, loss = 0.62, batch loss = 0.35 (26.0 examples/sec; 0.308 sec/batch; 28h:11m:48s remains)
INFO - root - 2017-12-01 02:42:42.302163: step 2730, loss = 0.61, batch loss = 0.33 (51.0 examples/sec; 0.157 sec/batch; 14h:22m:17s remains)
INFO - root - 2017-12-01 02:42:44.402784: step 2740, loss = 0.63, batch loss = 0.35 (29.1 examples/sec; 0.275 sec/batch; 25h:13m:22s remains)
INFO - root - 2017-12-01 02:42:46.309818: step 2750, loss = 0.59, batch loss = 0.31 (50.4 examples/sec; 0.159 sec/batch; 14h:33m:04s remains)
INFO - root - 2017-12-01 02:42:48.337837: step 2760, loss = 0.66, batch loss = 0.38 (12.6 examples/sec; 0.633 sec/batch; 57h:58m:44s remains)
INFO - root - 2017-12-01 02:42:50.105631: step 2770, loss = 0.67, batch loss = 0.39 (52.3 examples/sec; 0.153 sec/batch; 14h:00m:03s remains)
INFO - root - 2017-12-01 02:42:51.679919: step 2780, loss = 0.64, batch loss = 0.37 (52.3 examples/sec; 0.153 sec/batch; 14h:00m:06s remains)
INFO - root - 2017-12-01 02:42:53.229728: step 2790, loss = 0.63, batch loss = 0.35 (51.9 examples/sec; 0.154 sec/batch; 14h:07m:48s remains)
INFO - root - 2017-12-01 02:42:54.788352: step 2800, loss = 0.64, batch loss = 0.36 (51.6 examples/sec; 0.155 sec/batch; 14h:11m:13s remains)
INFO - root - 2017-12-01 02:42:56.400223: step 2810, loss = 0.60, batch loss = 0.33 (51.3 examples/sec; 0.156 sec/batch; 14h:17m:38s remains)
INFO - root - 2017-12-01 02:42:58.028683: step 2820, loss = 0.65, batch loss = 0.38 (50.7 examples/sec; 0.158 sec/batch; 14h:27m:40s remains)
INFO - root - 2017-12-01 02:42:59.594610: step 2830, loss = 0.64, batch loss = 0.37 (51.7 examples/sec; 0.155 sec/batch; 14h:10m:19s remains)
INFO - root - 2017-12-01 02:43:01.682004: step 2840, loss = 0.70, batch loss = 0.42 (51.0 examples/sec; 0.157 sec/batch; 14h:21m:22s remains)
INFO - root - 2017-12-01 02:43:03.734653: step 2850, loss = 0.62, batch loss = 0.34 (17.8 examples/sec; 0.450 sec/batch; 41h:14m:20s remains)
INFO - root - 2017-12-01 02:43:05.875462: step 2860, loss = 0.73, batch loss = 0.45 (52.6 examples/sec; 0.152 sec/batch; 13h:55m:48s remains)
INFO - root - 2017-12-01 02:43:07.827148: step 2870, loss = 0.65, batch loss = 0.37 (39.7 examples/sec; 0.202 sec/batch; 18h:27m:39s remains)
INFO - root - 2017-12-01 02:43:09.383141: step 2880, loss = 0.66, batch loss = 0.38 (51.2 examples/sec; 0.156 sec/batch; 14h:19m:03s remains)
INFO - root - 2017-12-01 02:43:11.851370: step 2890, loss = 0.56, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 14h:22m:54s remains)
INFO - root - 2017-12-01 02:43:13.633154: step 2900, loss = 0.64, batch loss = 0.36 (50.5 examples/sec; 0.159 sec/batch; 14h:30m:48s remains)
INFO - root - 2017-12-01 02:43:18.523016: step 2910, loss = 0.68, batch loss = 0.40 (51.8 examples/sec; 0.154 sec/batch; 14h:08m:16s remains)
INFO - root - 2017-12-01 02:43:20.075349: step 2920, loss = 0.64, batch loss = 0.36 (50.1 examples/sec; 0.160 sec/batch; 14h:37m:32s remains)
INFO - root - 2017-12-01 02:43:22.312027: step 2930, loss = 0.66, batch loss = 0.39 (51.2 examples/sec; 0.156 sec/batch; 14h:17m:41s remains)
INFO - root - 2017-12-01 02:43:24.138197: step 2940, loss = 0.64, batch loss = 0.36 (52.8 examples/sec; 0.152 sec/batch; 13h:52m:25s remains)
INFO - root - 2017-12-01 02:43:25.696853: step 2950, loss = 0.58, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 14h:11m:32s remains)
INFO - root - 2017-12-01 02:43:27.249105: step 2960, loss = 0.59, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 14h:12m:11s remains)
INFO - root - 2017-12-01 02:43:28.960633: step 2970, loss = 0.71, batch loss = 0.43 (51.9 examples/sec; 0.154 sec/batch; 14h:07m:22s remains)
INFO - root - 2017-12-01 02:43:31.206117: step 2980, loss = 0.68, batch loss = 0.41 (50.0 examples/sec; 0.160 sec/batch; 14h:39m:22s remains)
INFO - root - 2017-12-01 02:43:32.908279: step 2990, loss = 0.59, batch loss = 0.31 (53.2 examples/sec; 0.150 sec/batch; 13h:46m:21s remains)
INFO - root - 2017-12-01 02:43:34.456564: step 3000, loss = 0.66, batch loss = 0.38 (52.8 examples/sec; 0.152 sec/batch; 13h:52m:10s remains)
INFO - root - 2017-12-01 02:43:36.045097: step 3010, loss = 0.76, batch loss = 0.48 (52.5 examples/sec; 0.152 sec/batch; 13h:56m:09s remains)
INFO - root - 2017-12-01 02:43:37.591569: step 3020, loss = 0.66, batch loss = 0.39 (53.1 examples/sec; 0.151 sec/batch; 13h:47m:16s remains)
INFO - root - 2017-12-01 02:43:39.154325: step 3030, loss = 0.65, batch loss = 0.38 (50.6 examples/sec; 0.158 sec/batch; 14h:27m:52s remains)
INFO - root - 2017-12-01 02:43:40.728050: step 3040, loss = 0.63, batch loss = 0.36 (51.9 examples/sec; 0.154 sec/batch; 14h:06m:46s remains)
INFO - root - 2017-12-01 02:43:42.340216: step 3050, loss = 0.67, batch loss = 0.39 (40.3 examples/sec; 0.199 sec/batch; 18h:10m:25s remains)
INFO - root - 2017-12-01 02:43:44.331671: step 3060, loss = 0.65, batch loss = 0.38 (53.4 examples/sec; 0.150 sec/batch; 13h:42m:20s remains)
INFO - root - 2017-12-01 02:43:45.913248: step 3070, loss = 0.72, batch loss = 0.44 (50.1 examples/sec; 0.160 sec/batch; 14h:37m:30s remains)
INFO - root - 2017-12-01 02:43:47.469577: step 3080, loss = 0.65, batch loss = 0.37 (51.5 examples/sec; 0.155 sec/batch; 14h:12m:59s remains)
INFO - root - 2017-12-01 02:43:49.716714: step 3090, loss = 0.62, batch loss = 0.34 (9.4 examples/sec; 0.853 sec/batch; 78h:03m:35s remains)
INFO - root - 2017-12-01 02:43:51.334034: step 3100, loss = 0.66, batch loss = 0.38 (52.5 examples/sec; 0.152 sec/batch; 13h:56m:26s remains)
INFO - root - 2017-12-01 02:43:53.081895: step 3110, loss = 0.62, batch loss = 0.34 (50.2 examples/sec; 0.159 sec/batch; 14h:35m:26s remains)
INFO - root - 2017-12-01 02:43:55.395879: step 3120, loss = 0.65, batch loss = 0.37 (16.0 examples/sec; 0.500 sec/batch; 45h:45m:27s remains)
INFO - root - 2017-12-01 02:43:56.968943: step 3130, loss = 0.56, batch loss = 0.29 (50.8 examples/sec; 0.157 sec/batch; 14h:24m:10s remains)
INFO - root - 2017-12-01 02:43:58.535273: step 3140, loss = 0.56, batch loss = 0.28 (49.8 examples/sec; 0.161 sec/batch; 14h:41m:47s remains)
INFO - root - 2017-12-01 02:44:00.408905: step 3150, loss = 0.54, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 14h:14m:21s remains)
INFO - root - 2017-12-01 02:44:01.955464: step 3160, loss = 0.72, batch loss = 0.44 (50.5 examples/sec; 0.158 sec/batch; 14h:29m:42s remains)
INFO - root - 2017-12-01 02:44:03.989513: step 3170, loss = 0.61, batch loss = 0.33 (39.7 examples/sec; 0.202 sec/batch; 18h:26m:03s remains)
INFO - root - 2017-12-01 02:44:06.002580: step 3180, loss = 0.66, batch loss = 0.38 (33.0 examples/sec; 0.243 sec/batch; 22h:11m:46s remains)
INFO - root - 2017-12-01 02:44:07.829487: step 3190, loss = 0.58, batch loss = 0.30 (42.5 examples/sec; 0.188 sec/batch; 17h:14m:03s remains)
INFO - root - 2017-12-01 02:44:10.519523: step 3200, loss = 0.66, batch loss = 0.38 (53.0 examples/sec; 0.151 sec/batch; 13h:49m:08s remains)
INFO - root - 2017-12-01 02:44:13.329667: step 3210, loss = 0.59, batch loss = 0.31 (53.4 examples/sec; 0.150 sec/batch; 13h:42m:07s remains)
INFO - root - 2017-12-01 02:44:15.138810: step 3220, loss = 0.65, batch loss = 0.37 (33.2 examples/sec; 0.241 sec/batch; 22h:00m:59s remains)
INFO - root - 2017-12-01 02:44:16.914256: step 3230, loss = 0.67, batch loss = 0.39 (48.1 examples/sec; 0.166 sec/batch; 15h:13m:13s remains)
INFO - root - 2017-12-01 02:44:18.630108: step 3240, loss = 0.71, batch loss = 0.44 (50.4 examples/sec; 0.159 sec/batch; 14h:31m:47s remains)
INFO - root - 2017-12-01 02:44:20.619609: step 3250, loss = 0.65, batch loss = 0.38 (29.0 examples/sec; 0.276 sec/batch; 25h:13m:13s remains)
INFO - root - 2017-12-01 02:44:22.187067: step 3260, loss = 0.58, batch loss = 0.30 (52.3 examples/sec; 0.153 sec/batch; 13h:59m:14s remains)
INFO - root - 2017-12-01 02:44:23.748182: step 3270, loss = 0.68, batch loss = 0.40 (52.5 examples/sec; 0.152 sec/batch; 13h:56m:25s remains)
INFO - root - 2017-12-01 02:44:25.632280: step 3280, loss = 0.64, batch loss = 0.36 (53.0 examples/sec; 0.151 sec/batch; 13h:48m:40s remains)
INFO - root - 2017-12-01 02:44:27.187239: step 3290, loss = 0.64, batch loss = 0.36 (50.3 examples/sec; 0.159 sec/batch; 14h:33m:18s remains)
INFO - root - 2017-12-01 02:44:29.015341: step 3300, loss = 0.70, batch loss = 0.43 (51.3 examples/sec; 0.156 sec/batch; 14h:15m:49s remains)
INFO - root - 2017-12-01 02:44:31.517772: step 3310, loss = 0.68, batch loss = 0.40 (51.9 examples/sec; 0.154 sec/batch; 14h:05m:21s remains)
INFO - root - 2017-12-01 02:44:33.066009: step 3320, loss = 0.63, batch loss = 0.35 (51.8 examples/sec; 0.154 sec/batch; 14h:07m:32s remains)
INFO - root - 2017-12-01 02:44:34.684806: step 3330, loss = 0.79, batch loss = 0.51 (50.5 examples/sec; 0.158 sec/batch; 14h:28m:18s remains)
INFO - root - 2017-12-01 02:44:36.234987: step 3340, loss = 0.95, batch loss = 0.68 (51.2 examples/sec; 0.156 sec/batch; 14h:16m:22s remains)
INFO - root - 2017-12-01 02:44:37.807718: step 3350, loss = 0.63, batch loss = 0.35 (49.5 examples/sec; 0.162 sec/batch; 14h:47m:09s remains)
INFO - root - 2017-12-01 02:44:39.629789: step 3360, loss = 0.66, batch loss = 0.39 (20.0 examples/sec; 0.400 sec/batch; 36h:34m:44s remains)
INFO - root - 2017-12-01 02:44:42.231257: step 3370, loss = 0.59, batch loss = 0.32 (30.0 examples/sec; 0.267 sec/batch; 24h:23m:07s remains)
INFO - root - 2017-12-01 02:44:43.850547: step 3380, loss = 0.67, batch loss = 0.39 (50.8 examples/sec; 0.157 sec/batch; 14h:23m:06s remains)
INFO - root - 2017-12-01 02:44:45.405301: step 3390, loss = 0.61, batch loss = 0.34 (50.3 examples/sec; 0.159 sec/batch; 14h:31m:52s remains)
INFO - root - 2017-12-01 02:44:46.959778: step 3400, loss = 0.73, batch loss = 0.45 (49.9 examples/sec; 0.160 sec/batch; 14h:38m:43s remains)
INFO - root - 2017-12-01 02:44:48.569787: step 3410, loss = 0.71, batch loss = 0.43 (52.4 examples/sec; 0.153 sec/batch; 13h:58m:04s remains)
INFO - root - 2017-12-01 02:44:50.150244: step 3420, loss = 0.65, batch loss = 0.37 (51.7 examples/sec; 0.155 sec/batch; 14h:08m:40s remains)
INFO - root - 2017-12-01 02:44:51.693066: step 3430, loss = 0.64, batch loss = 0.37 (50.4 examples/sec; 0.159 sec/batch; 14h:30m:25s remains)
INFO - root - 2017-12-01 02:44:53.247189: step 3440, loss = 0.61, batch loss = 0.33 (51.4 examples/sec; 0.156 sec/batch; 14h:12m:49s remains)
INFO - root - 2017-12-01 02:44:54.798414: step 3450, loss = 0.53, batch loss = 0.26 (50.8 examples/sec; 0.157 sec/batch; 14h:22m:55s remains)
INFO - root - 2017-12-01 02:44:56.347330: step 3460, loss = 0.79, batch loss = 0.51 (51.7 examples/sec; 0.155 sec/batch; 14h:08m:42s remains)
INFO - root - 2017-12-01 02:44:57.916163: step 3470, loss = 0.65, batch loss = 0.37 (51.8 examples/sec; 0.155 sec/batch; 14h:07m:37s remains)
INFO - root - 2017-12-01 02:44:59.483030: step 3480, loss = 0.60, batch loss = 0.32 (52.3 examples/sec; 0.153 sec/batch; 13h:59m:28s remains)
INFO - root - 2017-12-01 02:45:01.397478: step 3490, loss = 0.57, batch loss = 0.29 (51.7 examples/sec; 0.155 sec/batch; 14h:07m:55s remains)
INFO - root - 2017-12-01 02:45:02.964155: step 3500, loss = 0.84, batch loss = 0.56 (49.4 examples/sec; 0.162 sec/batch; 14h:48m:46s remains)
INFO - root - 2017-12-01 02:45:04.920573: step 3510, loss = 0.60, batch loss = 0.33 (51.3 examples/sec; 0.156 sec/batch; 14h:14m:20s remains)
INFO - root - 2017-12-01 02:45:06.513354: step 3520, loss = 0.66, batch loss = 0.38 (50.8 examples/sec; 0.157 sec/batch; 14h:23m:02s remains)
INFO - root - 2017-12-01 02:45:08.056559: step 3530, loss = 0.71, batch loss = 0.44 (52.4 examples/sec; 0.153 sec/batch; 13h:56m:29s remains)
INFO - root - 2017-12-01 02:45:09.609873: step 3540, loss = 0.60, batch loss = 0.32 (50.1 examples/sec; 0.160 sec/batch; 14h:35m:06s remains)
INFO - root - 2017-12-01 02:45:11.177737: step 3550, loss = 0.65, batch loss = 0.37 (51.2 examples/sec; 0.156 sec/batch; 14h:16m:40s remains)
INFO - root - 2017-12-01 02:45:13.183536: step 3560, loss = 0.59, batch loss = 0.32 (25.2 examples/sec; 0.317 sec/batch; 28h:58m:54s remains)
INFO - root - 2017-12-01 02:45:14.833765: step 3570, loss = 0.70, batch loss = 0.43 (50.4 examples/sec; 0.159 sec/batch; 14h:29m:40s remains)
INFO - root - 2017-12-01 02:45:16.387922: step 3580, loss = 0.73, batch loss = 0.46 (50.7 examples/sec; 0.158 sec/batch; 14h:25m:23s remains)
INFO - root - 2017-12-01 02:45:18.144395: step 3590, loss = 0.72, batch loss = 0.45 (22.3 examples/sec; 0.359 sec/batch; 32h:48m:21s remains)
INFO - root - 2017-12-01 02:45:19.684516: step 3600, loss = 0.82, batch loss = 0.54 (51.6 examples/sec; 0.155 sec/batch; 14h:09m:04s remains)
INFO - root - 2017-12-01 02:45:21.952031: step 3610, loss = 0.66, batch loss = 0.38 (51.8 examples/sec; 0.154 sec/batch; 14h:05m:45s remains)
INFO - root - 2017-12-01 02:45:23.501974: step 3620, loss = 0.63, batch loss = 0.36 (50.6 examples/sec; 0.158 sec/batch; 14h:26m:23s remains)
INFO - root - 2017-12-01 02:45:25.053308: step 3630, loss = 0.73, batch loss = 0.46 (50.1 examples/sec; 0.160 sec/batch; 14h:36m:02s remains)
INFO - root - 2017-12-01 02:45:26.614079: step 3640, loss = 0.76, batch loss = 0.49 (52.5 examples/sec; 0.152 sec/batch; 13h:55m:23s remains)
INFO - root - 2017-12-01 02:45:28.158311: step 3650, loss = 0.69, batch loss = 0.41 (53.4 examples/sec; 0.150 sec/batch; 13h:40m:40s remains)
INFO - root - 2017-12-01 02:45:29.727046: step 3660, loss = 0.50, batch loss = 0.22 (50.5 examples/sec; 0.159 sec/batch; 14h:29m:00s remains)
INFO - root - 2017-12-01 02:45:31.291298: step 3670, loss = 0.58, batch loss = 0.30 (51.3 examples/sec; 0.156 sec/batch; 14h:15m:22s remains)
INFO - root - 2017-12-01 02:45:32.832686: step 3680, loss = 0.58, batch loss = 0.31 (51.4 examples/sec; 0.156 sec/batch; 14h:12m:52s remains)
INFO - root - 2017-12-01 02:45:34.384961: step 3690, loss = 0.70, batch loss = 0.42 (51.8 examples/sec; 0.154 sec/batch; 14h:06m:00s remains)
INFO - root - 2017-12-01 02:45:35.944321: step 3700, loss = 0.65, batch loss = 0.37 (50.7 examples/sec; 0.158 sec/batch; 14h:25m:14s remains)
INFO - root - 2017-12-01 02:45:37.587670: step 3710, loss = 0.57, batch loss = 0.29 (49.5 examples/sec; 0.162 sec/batch; 14h:45m:49s remains)
INFO - root - 2017-12-01 02:45:39.151653: step 3720, loss = 0.65, batch loss = 0.37 (51.0 examples/sec; 0.157 sec/batch; 14h:19m:24s remains)
INFO - root - 2017-12-01 02:45:40.879130: step 3730, loss = 0.67, batch loss = 0.40 (50.7 examples/sec; 0.158 sec/batch; 14h:24m:32s remains)
INFO - root - 2017-12-01 02:45:42.432693: step 3740, loss = 0.72, batch loss = 0.44 (49.6 examples/sec; 0.161 sec/batch; 14h:43m:15s remains)
INFO - root - 2017-12-01 02:45:44.009016: step 3750, loss = 0.61, batch loss = 0.33 (51.6 examples/sec; 0.155 sec/batch; 14h:09m:10s remains)
INFO - root - 2017-12-01 02:45:45.577999: step 3760, loss = 0.57, batch loss = 0.29 (51.8 examples/sec; 0.154 sec/batch; 14h:06m:06s remains)
INFO - root - 2017-12-01 02:45:47.164355: step 3770, loss = 0.62, batch loss = 0.35 (51.5 examples/sec; 0.155 sec/batch; 14h:11m:44s remains)
INFO - root - 2017-12-01 02:45:48.745888: step 3780, loss = 0.61, batch loss = 0.33 (51.1 examples/sec; 0.156 sec/batch; 14h:17m:02s remains)
INFO - root - 2017-12-01 02:45:50.304962: step 3790, loss = 0.62, batch loss = 0.34 (52.3 examples/sec; 0.153 sec/batch; 13h:57m:28s remains)
INFO - root - 2017-12-01 02:45:52.055531: step 3800, loss = 0.74, batch loss = 0.46 (50.0 examples/sec; 0.160 sec/batch; 14h:36m:23s remains)
INFO - root - 2017-12-01 02:45:53.662822: step 3810, loss = 0.68, batch loss = 0.41 (52.2 examples/sec; 0.153 sec/batch; 13h:59m:28s remains)
INFO - root - 2017-12-01 02:45:55.259146: step 3820, loss = 0.57, batch loss = 0.29 (48.6 examples/sec; 0.165 sec/batch; 15h:01m:13s remains)
INFO - root - 2017-12-01 02:45:56.814300: step 3830, loss = 0.62, batch loss = 0.34 (50.3 examples/sec; 0.159 sec/batch; 14h:31m:33s remains)
INFO - root - 2017-12-01 02:45:58.358780: step 3840, loss = 0.59, batch loss = 0.32 (53.0 examples/sec; 0.151 sec/batch; 13h:47m:01s remains)
INFO - root - 2017-12-01 02:45:59.928346: step 3850, loss = 0.63, batch loss = 0.35 (53.0 examples/sec; 0.151 sec/batch; 13h:47m:23s remains)
INFO - root - 2017-12-01 02:46:01.592109: step 3860, loss = 0.61, batch loss = 0.34 (50.5 examples/sec; 0.158 sec/batch; 14h:27m:56s remains)
INFO - root - 2017-12-01 02:46:03.159974: step 3870, loss = 0.58, batch loss = 0.31 (50.2 examples/sec; 0.159 sec/batch; 14h:32m:48s remains)
INFO - root - 2017-12-01 02:46:04.713187: step 3880, loss = 0.71, batch loss = 0.44 (51.4 examples/sec; 0.156 sec/batch; 14h:11m:53s remains)
INFO - root - 2017-12-01 02:46:06.262133: step 3890, loss = 0.61, batch loss = 0.34 (52.4 examples/sec; 0.153 sec/batch; 13h:56m:11s remains)
INFO - root - 2017-12-01 02:46:07.897943: step 3900, loss = 0.60, batch loss = 0.33 (53.0 examples/sec; 0.151 sec/batch; 13h:47m:09s remains)
INFO - root - 2017-12-01 02:46:09.554237: step 3910, loss = 0.67, batch loss = 0.39 (51.3 examples/sec; 0.156 sec/batch; 14h:13m:18s remains)
INFO - root - 2017-12-01 02:46:11.142035: step 3920, loss = 0.53, batch loss = 0.25 (47.9 examples/sec; 0.167 sec/batch; 15h:14m:00s remains)
INFO - root - 2017-12-01 02:46:12.736595: step 3930, loss = 0.57, batch loss = 0.29 (52.2 examples/sec; 0.153 sec/batch; 13h:59m:00s remains)
INFO - root - 2017-12-01 02:46:14.293197: step 3940, loss = 0.68, batch loss = 0.41 (51.1 examples/sec; 0.157 sec/batch; 14h:17m:01s remains)
INFO - root - 2017-12-01 02:46:15.831325: step 3950, loss = 0.62, batch loss = 0.35 (50.7 examples/sec; 0.158 sec/batch; 14h:24m:48s remains)
INFO - root - 2017-12-01 02:46:17.393843: step 3960, loss = 0.64, batch loss = 0.36 (51.1 examples/sec; 0.157 sec/batch; 14h:17m:43s remains)
INFO - root - 2017-12-01 02:46:18.945683: step 3970, loss = 0.63, batch loss = 0.35 (50.9 examples/sec; 0.157 sec/batch; 14h:20m:40s remains)
INFO - root - 2017-12-01 02:46:20.499422: step 3980, loss = 0.63, batch loss = 0.36 (52.2 examples/sec; 0.153 sec/batch; 13h:58m:39s remains)
INFO - root - 2017-12-01 02:46:22.045204: step 3990, loss = 0.72, batch loss = 0.44 (53.4 examples/sec; 0.150 sec/batch; 13h:40m:41s remains)
INFO - root - 2017-12-01 02:46:23.622293: step 4000, loss = 0.59, batch loss = 0.31 (50.7 examples/sec; 0.158 sec/batch; 14h:23m:12s remains)
INFO - root - 2017-12-01 02:46:25.268724: step 4010, loss = 0.83, batch loss = 0.56 (50.8 examples/sec; 0.157 sec/batch; 14h:21m:45s remains)
INFO - root - 2017-12-01 02:46:26.858348: step 4020, loss = 0.56, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 14h:04m:12s remains)
INFO - root - 2017-12-01 02:46:28.404757: step 4030, loss = 0.60, batch loss = 0.33 (51.8 examples/sec; 0.155 sec/batch; 14h:05m:50s remains)
INFO - root - 2017-12-01 02:46:29.963607: step 4040, loss = 0.56, batch loss = 0.28 (50.1 examples/sec; 0.160 sec/batch; 14h:33m:36s remains)
INFO - root - 2017-12-01 02:46:31.528370: step 4050, loss = 0.63, batch loss = 0.35 (51.8 examples/sec; 0.154 sec/batch; 14h:04m:49s remains)
INFO - root - 2017-12-01 02:46:33.088997: step 4060, loss = 0.72, batch loss = 0.45 (53.6 examples/sec; 0.149 sec/batch; 13h:36m:51s remains)
INFO - root - 2017-12-01 02:46:34.659597: step 4070, loss = 0.66, batch loss = 0.39 (52.0 examples/sec; 0.154 sec/batch; 14h:01m:31s remains)
INFO - root - 2017-12-01 02:46:36.231674: step 4080, loss = 0.62, batch loss = 0.35 (51.0 examples/sec; 0.157 sec/batch; 14h:18m:02s remains)
INFO - root - 2017-12-01 02:46:37.786285: step 4090, loss = 0.70, batch loss = 0.43 (50.6 examples/sec; 0.158 sec/batch; 14h:25m:58s remains)
INFO - root - 2017-12-01 02:46:39.347999: step 4100, loss = 0.68, batch loss = 0.40 (51.3 examples/sec; 0.156 sec/batch; 14h:14m:20s remains)
INFO - root - 2017-12-01 02:46:41.006701: step 4110, loss = 0.68, batch loss = 0.41 (51.7 examples/sec; 0.155 sec/batch; 14h:07m:06s remains)
INFO - root - 2017-12-01 02:46:42.551095: step 4120, loss = 0.61, batch loss = 0.34 (50.6 examples/sec; 0.158 sec/batch; 14h:24m:47s remains)
INFO - root - 2017-12-01 02:46:44.101396: step 4130, loss = 0.62, batch loss = 0.34 (51.8 examples/sec; 0.154 sec/batch; 14h:04m:42s remains)
INFO - root - 2017-12-01 02:46:45.651523: step 4140, loss = 0.60, batch loss = 0.33 (51.8 examples/sec; 0.154 sec/batch; 14h:04m:46s remains)
INFO - root - 2017-12-01 02:46:47.226429: step 4150, loss = 0.65, batch loss = 0.38 (51.7 examples/sec; 0.155 sec/batch; 14h:07m:18s remains)
INFO - root - 2017-12-01 02:46:48.779080: step 4160, loss = 0.70, batch loss = 0.43 (51.4 examples/sec; 0.156 sec/batch; 14h:12m:07s remains)
INFO - root - 2017-12-01 02:46:50.338899: step 4170, loss = 0.60, batch loss = 0.32 (49.4 examples/sec; 0.162 sec/batch; 14h:45m:40s remains)
INFO - root - 2017-12-01 02:46:51.906072: step 4180, loss = 0.61, batch loss = 0.34 (50.4 examples/sec; 0.159 sec/batch; 14h:28m:43s remains)
INFO - root - 2017-12-01 02:46:53.458336: step 4190, loss = 0.60, batch loss = 0.33 (49.2 examples/sec; 0.162 sec/batch; 14h:49m:04s remains)
INFO - root - 2017-12-01 02:46:55.045619: step 4200, loss = 0.75, batch loss = 0.48 (51.4 examples/sec; 0.156 sec/batch; 14h:11m:12s remains)
INFO - root - 2017-12-01 02:46:56.695506: step 4210, loss = 0.65, batch loss = 0.38 (52.5 examples/sec; 0.152 sec/batch; 13h:53m:49s remains)
INFO - root - 2017-12-01 02:46:58.257690: step 4220, loss = 0.58, batch loss = 0.31 (53.0 examples/sec; 0.151 sec/batch; 13h:45m:45s remains)
INFO - root - 2017-12-01 02:46:59.810315: step 4230, loss = 0.59, batch loss = 0.32 (50.9 examples/sec; 0.157 sec/batch; 14h:20m:11s remains)
INFO - root - 2017-12-01 02:47:01.364724: step 4240, loss = 0.58, batch loss = 0.30 (50.8 examples/sec; 0.157 sec/batch; 14h:20m:51s remains)
INFO - root - 2017-12-01 02:47:02.947124: step 4250, loss = 0.66, batch loss = 0.39 (50.2 examples/sec; 0.159 sec/batch; 14h:31m:15s remains)
INFO - root - 2017-12-01 02:47:04.492071: step 4260, loss = 0.61, batch loss = 0.33 (51.6 examples/sec; 0.155 sec/batch; 14h:08m:27s remains)
INFO - root - 2017-12-01 02:47:06.047114: step 4270, loss = 0.73, batch loss = 0.46 (53.3 examples/sec; 0.150 sec/batch; 13h:41m:45s remains)
INFO - root - 2017-12-01 02:47:07.596535: step 4280, loss = 0.68, batch loss = 0.40 (53.2 examples/sec; 0.150 sec/batch; 13h:42m:47s remains)
INFO - root - 2017-12-01 02:47:09.176665: step 4290, loss = 0.55, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 14h:06m:17s remains)
INFO - root - 2017-12-01 02:47:10.732168: step 4300, loss = 0.62, batch loss = 0.34 (50.2 examples/sec; 0.159 sec/batch; 14h:31m:19s remains)
INFO - root - 2017-12-01 02:47:12.614644: step 4310, loss = 0.80, batch loss = 0.53 (51.8 examples/sec; 0.155 sec/batch; 14h:05m:28s remains)
INFO - root - 2017-12-01 02:47:14.170437: step 4320, loss = 0.65, batch loss = 0.37 (51.4 examples/sec; 0.156 sec/batch; 14h:10m:39s remains)
INFO - root - 2017-12-01 02:47:15.723506: step 4330, loss = 0.59, batch loss = 0.32 (52.4 examples/sec; 0.153 sec/batch; 13h:55m:08s remains)
INFO - root - 2017-12-01 02:47:17.291243: step 4340, loss = 0.64, batch loss = 0.36 (51.9 examples/sec; 0.154 sec/batch; 14h:03m:48s remains)
INFO - root - 2017-12-01 02:47:18.865768: step 4350, loss = 0.64, batch loss = 0.37 (50.3 examples/sec; 0.159 sec/batch; 14h:30m:26s remains)
INFO - root - 2017-12-01 02:47:20.448179: step 4360, loss = 0.67, batch loss = 0.40 (50.7 examples/sec; 0.158 sec/batch; 14h:22m:32s remains)
INFO - root - 2017-12-01 02:47:21.996915: step 4370, loss = 0.54, batch loss = 0.27 (52.4 examples/sec; 0.153 sec/batch; 13h:54m:09s remains)
INFO - root - 2017-12-01 02:47:23.566099: step 4380, loss = 0.74, batch loss = 0.47 (52.8 examples/sec; 0.152 sec/batch; 13h:49m:03s remains)
INFO - root - 2017-12-01 02:47:25.132459: step 4390, loss = 0.82, batch loss = 0.54 (49.8 examples/sec; 0.160 sec/batch; 14h:37m:40s remains)
INFO - root - 2017-12-01 02:47:26.685708: step 4400, loss = 0.59, batch loss = 0.32 (51.9 examples/sec; 0.154 sec/batch; 14h:03m:28s remains)
INFO - root - 2017-12-01 02:47:28.447587: step 4410, loss = 0.63, batch loss = 0.35 (52.5 examples/sec; 0.152 sec/batch; 13h:52m:32s remains)
INFO - root - 2017-12-01 02:47:29.994990: step 4420, loss = 0.59, batch loss = 0.32 (51.1 examples/sec; 0.156 sec/batch; 14h:15m:42s remains)
INFO - root - 2017-12-01 02:47:31.540724: step 4430, loss = 0.67, batch loss = 0.40 (52.6 examples/sec; 0.152 sec/batch; 13h:50m:57s remains)
INFO - root - 2017-12-01 02:47:33.113925: step 4440, loss = 0.72, batch loss = 0.45 (52.6 examples/sec; 0.152 sec/batch; 13h:50m:48s remains)
INFO - root - 2017-12-01 02:47:34.689445: step 4450, loss = 0.72, batch loss = 0.45 (51.9 examples/sec; 0.154 sec/batch; 14h:02m:18s remains)
INFO - root - 2017-12-01 02:47:36.267464: step 4460, loss = 0.57, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 14h:14m:00s remains)
INFO - root - 2017-12-01 02:47:37.830855: step 4470, loss = 0.53, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 14h:08m:51s remains)
INFO - root - 2017-12-01 02:47:39.399616: step 4480, loss = 0.70, batch loss = 0.43 (51.0 examples/sec; 0.157 sec/batch; 14h:17m:56s remains)
INFO - root - 2017-12-01 02:47:40.949701: step 4490, loss = 0.59, batch loss = 0.32 (51.9 examples/sec; 0.154 sec/batch; 14h:02m:03s remains)
INFO - root - 2017-12-01 02:47:42.504394: step 4500, loss = 0.72, batch loss = 0.44 (51.5 examples/sec; 0.155 sec/batch; 14h:08m:24s remains)
INFO - root - 2017-12-01 02:47:44.136049: step 4510, loss = 0.60, batch loss = 0.33 (50.8 examples/sec; 0.157 sec/batch; 14h:20m:14s remains)
INFO - root - 2017-12-01 02:47:45.707731: step 4520, loss = 0.58, batch loss = 0.30 (53.0 examples/sec; 0.151 sec/batch; 13h:45m:01s remains)
INFO - root - 2017-12-01 02:47:47.278370: step 4530, loss = 0.74, batch loss = 0.47 (51.4 examples/sec; 0.156 sec/batch; 14h:10m:03s remains)
INFO - root - 2017-12-01 02:47:48.845392: step 4540, loss = 0.58, batch loss = 0.30 (53.1 examples/sec; 0.151 sec/batch; 13h:43m:05s remains)
INFO - root - 2017-12-01 02:47:50.397983: step 4550, loss = 0.66, batch loss = 0.39 (51.4 examples/sec; 0.156 sec/batch; 14h:10m:59s remains)
INFO - root - 2017-12-01 02:47:51.960116: step 4560, loss = 0.48, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 14h:00m:00s remains)
INFO - root - 2017-12-01 02:47:53.514354: step 4570, loss = 0.59, batch loss = 0.32 (51.0 examples/sec; 0.157 sec/batch; 14h:16m:40s remains)
INFO - root - 2017-12-01 02:47:55.091469: step 4580, loss = 0.69, batch loss = 0.41 (51.5 examples/sec; 0.155 sec/batch; 14h:09m:08s remains)
INFO - root - 2017-12-01 02:47:56.660216: step 4590, loss = 0.62, batch loss = 0.34 (51.1 examples/sec; 0.156 sec/batch; 14h:14m:54s remains)
INFO - root - 2017-12-01 02:47:58.218579: step 4600, loss = 0.62, batch loss = 0.35 (52.1 examples/sec; 0.154 sec/batch; 13h:59m:41s remains)
INFO - root - 2017-12-01 02:47:59.828618: step 4610, loss = 0.57, batch loss = 0.30 (52.1 examples/sec; 0.153 sec/batch; 13h:58m:22s remains)
INFO - root - 2017-12-01 02:48:01.410813: step 4620, loss = 0.61, batch loss = 0.33 (50.6 examples/sec; 0.158 sec/batch; 14h:24m:38s remains)
INFO - root - 2017-12-01 02:48:02.970288: step 4630, loss = 0.69, batch loss = 0.41 (49.4 examples/sec; 0.162 sec/batch; 14h:44m:04s remains)
INFO - root - 2017-12-01 02:48:04.571529: step 4640, loss = 0.65, batch loss = 0.38 (50.6 examples/sec; 0.158 sec/batch; 14h:23m:13s remains)
INFO - root - 2017-12-01 02:48:06.147991: step 4650, loss = 0.58, batch loss = 0.31 (50.6 examples/sec; 0.158 sec/batch; 14h:23m:56s remains)
INFO - root - 2017-12-01 02:48:07.734687: step 4660, loss = 0.57, batch loss = 0.30 (49.3 examples/sec; 0.162 sec/batch; 14h:47m:30s remains)
INFO - root - 2017-12-01 02:48:09.295420: step 4670, loss = 0.66, batch loss = 0.38 (52.1 examples/sec; 0.154 sec/batch; 13h:58m:53s remains)
INFO - root - 2017-12-01 02:48:10.871469: step 4680, loss = 0.60, batch loss = 0.33 (47.7 examples/sec; 0.168 sec/batch; 15h:16m:58s remains)
INFO - root - 2017-12-01 02:48:12.469158: step 4690, loss = 0.66, batch loss = 0.39 (50.3 examples/sec; 0.159 sec/batch; 14h:28m:29s remains)
INFO - root - 2017-12-01 02:48:14.026419: step 4700, loss = 0.63, batch loss = 0.36 (50.3 examples/sec; 0.159 sec/batch; 14h:28m:03s remains)
INFO - root - 2017-12-01 02:48:15.638819: step 4710, loss = 0.71, batch loss = 0.44 (50.8 examples/sec; 0.157 sec/batch; 14h:19m:50s remains)
INFO - root - 2017-12-01 02:48:17.213460: step 4720, loss = 0.55, batch loss = 0.27 (49.8 examples/sec; 0.161 sec/batch; 14h:37m:14s remains)
INFO - root - 2017-12-01 02:48:18.770589: step 4730, loss = 0.60, batch loss = 0.33 (50.0 examples/sec; 0.160 sec/batch; 14h:34m:43s remains)
INFO - root - 2017-12-01 02:48:20.334489: step 4740, loss = 0.64, batch loss = 0.36 (48.7 examples/sec; 0.164 sec/batch; 14h:57m:07s remains)
INFO - root - 2017-12-01 02:48:21.927453: step 4750, loss = 0.60, batch loss = 0.33 (50.4 examples/sec; 0.159 sec/batch; 14h:27m:22s remains)
INFO - root - 2017-12-01 02:48:23.512019: step 4760, loss = 0.57, batch loss = 0.30 (49.8 examples/sec; 0.161 sec/batch; 14h:37m:40s remains)
INFO - root - 2017-12-01 02:48:25.076939: step 4770, loss = 0.67, batch loss = 0.39 (50.0 examples/sec; 0.160 sec/batch; 14h:34m:39s remains)
INFO - root - 2017-12-01 02:48:26.633234: step 4780, loss = 0.54, batch loss = 0.27 (52.6 examples/sec; 0.152 sec/batch; 13h:50m:57s remains)
INFO - root - 2017-12-01 02:48:28.197768: step 4790, loss = 0.66, batch loss = 0.39 (53.2 examples/sec; 0.150 sec/batch; 13h:41m:51s remains)
INFO - root - 2017-12-01 02:48:29.771170: step 4800, loss = 0.71, batch loss = 0.43 (50.8 examples/sec; 0.157 sec/batch; 14h:19m:18s remains)
INFO - root - 2017-12-01 02:48:31.420587: step 4810, loss = 0.69, batch loss = 0.42 (50.6 examples/sec; 0.158 sec/batch; 14h:23m:28s remains)
INFO - root - 2017-12-01 02:48:32.979881: step 4820, loss = 0.59, batch loss = 0.32 (51.7 examples/sec; 0.155 sec/batch; 14h:05m:10s remains)
INFO - root - 2017-12-01 02:48:34.542835: step 4830, loss = 0.72, batch loss = 0.45 (50.9 examples/sec; 0.157 sec/batch; 14h:18m:02s remains)
INFO - root - 2017-12-01 02:48:36.128464: step 4840, loss = 0.55, batch loss = 0.28 (49.1 examples/sec; 0.163 sec/batch; 14h:49m:25s remains)
INFO - root - 2017-12-01 02:48:37.716626: step 4850, loss = 0.51, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 14h:12m:16s remains)
INFO - root - 2017-12-01 02:48:39.299858: step 4860, loss = 0.59, batch loss = 0.32 (50.2 examples/sec; 0.159 sec/batch; 14h:29m:26s remains)
INFO - root - 2017-12-01 02:48:40.870627: step 4870, loss = 0.61, batch loss = 0.34 (49.2 examples/sec; 0.163 sec/batch; 14h:48m:21s remains)
INFO - root - 2017-12-01 02:48:42.451290: step 4880, loss = 0.57, batch loss = 0.30 (52.6 examples/sec; 0.152 sec/batch; 13h:51m:13s remains)
INFO - root - 2017-12-01 02:48:44.021601: step 4890, loss = 0.61, batch loss = 0.34 (50.6 examples/sec; 0.158 sec/batch; 14h:23m:00s remains)
INFO - root - 2017-12-01 02:48:45.582445: step 4900, loss = 0.70, batch loss = 0.43 (51.0 examples/sec; 0.157 sec/batch; 14h:15m:53s remains)
INFO - root - 2017-12-01 02:48:47.207680: step 4910, loss = 0.70, batch loss = 0.43 (48.9 examples/sec; 0.163 sec/batch; 14h:52m:33s remains)
INFO - root - 2017-12-01 02:48:48.778485: step 4920, loss = 0.64, batch loss = 0.37 (50.8 examples/sec; 0.157 sec/batch; 14h:19m:41s remains)
INFO - root - 2017-12-01 02:48:50.355119: step 4930, loss = 0.68, batch loss = 0.41 (51.0 examples/sec; 0.157 sec/batch; 14h:16m:18s remains)
INFO - root - 2017-12-01 02:48:51.924789: step 4940, loss = 0.62, batch loss = 0.35 (49.5 examples/sec; 0.162 sec/batch; 14h:42m:03s remains)
INFO - root - 2017-12-01 02:48:53.516520: step 4950, loss = 0.66, batch loss = 0.38 (52.0 examples/sec; 0.154 sec/batch; 14h:00m:07s remains)
INFO - root - 2017-12-01 02:48:55.072109: step 4960, loss = 0.71, batch loss = 0.44 (51.7 examples/sec; 0.155 sec/batch; 14h:05m:28s remains)
INFO - root - 2017-12-01 02:48:56.684453: step 4970, loss = 0.60, batch loss = 0.33 (49.0 examples/sec; 0.163 sec/batch; 14h:50m:27s remains)
INFO - root - 2017-12-01 02:48:58.233051: step 4980, loss = 0.61, batch loss = 0.34 (51.8 examples/sec; 0.155 sec/batch; 14h:03m:36s remains)
INFO - root - 2017-12-01 02:48:59.820980: step 4990, loss = 0.62, batch loss = 0.34 (51.3 examples/sec; 0.156 sec/batch; 14h:11m:40s remains)
INFO - root - 2017-12-01 02:49:01.389254: step 5000, loss = 0.61, batch loss = 0.34 (50.6 examples/sec; 0.158 sec/batch; 14h:22m:50s remains)
INFO - root - 2017-12-01 02:49:03.013778: step 5010, loss = 0.51, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 14h:04m:52s remains)
INFO - root - 2017-12-01 02:49:04.576370: step 5020, loss = 0.59, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 14h:21m:21s remains)
INFO - root - 2017-12-01 02:49:06.136692: step 5030, loss = 0.60, batch loss = 0.33 (51.4 examples/sec; 0.156 sec/batch; 14h:08m:42s remains)
INFO - root - 2017-12-01 02:49:07.692485: step 5040, loss = 0.74, batch loss = 0.47 (51.0 examples/sec; 0.157 sec/batch; 14h:16m:43s remains)
INFO - root - 2017-12-01 02:49:09.263036: step 5050, loss = 0.59, batch loss = 0.32 (51.4 examples/sec; 0.156 sec/batch; 14h:09m:32s remains)
INFO - root - 2017-12-01 02:49:10.838543: step 5060, loss = 0.67, batch loss = 0.40 (52.9 examples/sec; 0.151 sec/batch; 13h:45m:57s remains)
INFO - root - 2017-12-01 02:49:12.409917: step 5070, loss = 0.58, batch loss = 0.31 (52.4 examples/sec; 0.153 sec/batch; 13h:53m:24s remains)
INFO - root - 2017-12-01 02:49:13.992495: step 5080, loss = 0.71, batch loss = 0.43 (49.8 examples/sec; 0.161 sec/batch; 14h:36m:01s remains)
INFO - root - 2017-12-01 02:49:15.553567: step 5090, loss = 0.65, batch loss = 0.37 (49.6 examples/sec; 0.161 sec/batch; 14h:40m:08s remains)
INFO - root - 2017-12-01 02:49:17.114200: step 5100, loss = 0.56, batch loss = 0.29 (53.3 examples/sec; 0.150 sec/batch; 13h:39m:44s remains)
INFO - root - 2017-12-01 02:49:18.762337: step 5110, loss = 0.66, batch loss = 0.39 (50.1 examples/sec; 0.160 sec/batch; 14h:30m:42s remains)
INFO - root - 2017-12-01 02:49:20.336698: step 5120, loss = 0.64, batch loss = 0.36 (52.1 examples/sec; 0.154 sec/batch; 13h:58m:15s remains)
INFO - root - 2017-12-01 02:49:21.938861: step 5130, loss = 0.72, batch loss = 0.45 (51.0 examples/sec; 0.157 sec/batch; 14h:15m:59s remains)
INFO - root - 2017-12-01 02:49:23.502381: step 5140, loss = 0.65, batch loss = 0.38 (50.1 examples/sec; 0.160 sec/batch; 14h:31m:48s remains)
INFO - root - 2017-12-01 02:49:25.074956: step 5150, loss = 0.57, batch loss = 0.30 (49.7 examples/sec; 0.161 sec/batch; 14h:38m:53s remains)
INFO - root - 2017-12-01 02:49:26.642048: step 5160, loss = 0.65, batch loss = 0.37 (51.9 examples/sec; 0.154 sec/batch; 14h:01m:32s remains)
INFO - root - 2017-12-01 02:49:28.211741: step 5170, loss = 0.62, batch loss = 0.35 (51.8 examples/sec; 0.154 sec/batch; 14h:02m:32s remains)
INFO - root - 2017-12-01 02:49:29.782905: step 5180, loss = 0.53, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 14h:26m:45s remains)
INFO - root - 2017-12-01 02:49:31.346180: step 5190, loss = 0.78, batch loss = 0.51 (50.5 examples/sec; 0.158 sec/batch; 14h:24m:27s remains)
INFO - root - 2017-12-01 02:49:32.923508: step 5200, loss = 0.68, batch loss = 0.41 (51.8 examples/sec; 0.155 sec/batch; 14h:02m:56s remains)
INFO - root - 2017-12-01 02:49:34.553786: step 5210, loss = 0.62, batch loss = 0.35 (50.8 examples/sec; 0.157 sec/batch; 14h:18m:53s remains)
INFO - root - 2017-12-01 02:49:36.120851: step 5220, loss = 0.68, batch loss = 0.40 (50.1 examples/sec; 0.160 sec/batch; 14h:30m:16s remains)
INFO - root - 2017-12-01 02:49:37.698082: step 5230, loss = 0.74, batch loss = 0.47 (52.5 examples/sec; 0.152 sec/batch; 13h:50m:34s remains)
INFO - root - 2017-12-01 02:49:39.248327: step 5240, loss = 0.58, batch loss = 0.31 (53.1 examples/sec; 0.151 sec/batch; 13h:41m:03s remains)
INFO - root - 2017-12-01 02:49:40.853526: step 5250, loss = 0.64, batch loss = 0.37 (47.0 examples/sec; 0.170 sec/batch; 15h:28m:42s remains)
INFO - root - 2017-12-01 02:49:42.423127: step 5260, loss = 0.65, batch loss = 0.38 (52.7 examples/sec; 0.152 sec/batch; 13h:48m:25s remains)
INFO - root - 2017-12-01 02:49:43.972716: step 5270, loss = 0.60, batch loss = 0.32 (52.5 examples/sec; 0.152 sec/batch; 13h:51m:31s remains)
INFO - root - 2017-12-01 02:49:45.554374: step 5280, loss = 0.59, batch loss = 0.32 (51.9 examples/sec; 0.154 sec/batch; 14h:00m:04s remains)
INFO - root - 2017-12-01 02:49:47.137791: step 5290, loss = 0.65, batch loss = 0.37 (50.7 examples/sec; 0.158 sec/batch; 14h:20m:49s remains)
INFO - root - 2017-12-01 02:49:48.685494: step 5300, loss = 0.59, batch loss = 0.32 (53.4 examples/sec; 0.150 sec/batch; 13h:36m:33s remains)
INFO - root - 2017-12-01 02:49:50.301282: step 5310, loss = 0.54, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 14h:03m:41s remains)
INFO - root - 2017-12-01 02:49:51.871902: step 5320, loss = 0.54, batch loss = 0.27 (50.4 examples/sec; 0.159 sec/batch; 14h:26m:12s remains)
INFO - root - 2017-12-01 02:49:53.436958: step 5330, loss = 0.73, batch loss = 0.46 (51.8 examples/sec; 0.154 sec/batch; 14h:02m:04s remains)
INFO - root - 2017-12-01 02:49:54.998780: step 5340, loss = 0.53, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 14h:16m:47s remains)
INFO - root - 2017-12-01 02:49:56.577792: step 5350, loss = 0.53, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 14h:16m:14s remains)
INFO - root - 2017-12-01 02:49:58.169280: step 5360, loss = 0.61, batch loss = 0.34 (49.2 examples/sec; 0.162 sec/batch; 14h:45m:58s remains)
INFO - root - 2017-12-01 02:49:59.743046: step 5370, loss = 0.68, batch loss = 0.41 (49.5 examples/sec; 0.162 sec/batch; 14h:41m:25s remains)
INFO - root - 2017-12-01 02:50:01.322596: step 5380, loss = 0.77, batch loss = 0.50 (52.5 examples/sec; 0.152 sec/batch; 13h:51m:17s remains)
INFO - root - 2017-12-01 02:50:02.896714: step 5390, loss = 0.56, batch loss = 0.29 (49.0 examples/sec; 0.163 sec/batch; 14h:50m:28s remains)
INFO - root - 2017-12-01 02:50:04.474745: step 5400, loss = 0.69, batch loss = 0.42 (49.9 examples/sec; 0.160 sec/batch; 14h:34m:28s remains)
INFO - root - 2017-12-01 02:50:06.133189: step 5410, loss = 0.53, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 14h:25m:17s remains)
INFO - root - 2017-12-01 02:50:07.695452: step 5420, loss = 0.61, batch loss = 0.34 (50.7 examples/sec; 0.158 sec/batch; 14h:20m:41s remains)
INFO - root - 2017-12-01 02:50:09.252552: step 5430, loss = 0.55, batch loss = 0.28 (50.0 examples/sec; 0.160 sec/batch; 14h:32m:45s remains)
INFO - root - 2017-12-01 02:50:10.859683: step 5440, loss = 0.66, batch loss = 0.39 (51.5 examples/sec; 0.155 sec/batch; 14h:06m:28s remains)
INFO - root - 2017-12-01 02:50:12.437373: step 5450, loss = 0.63, batch loss = 0.36 (51.8 examples/sec; 0.154 sec/batch; 14h:01m:41s remains)
INFO - root - 2017-12-01 02:50:14.011694: step 5460, loss = 0.56, batch loss = 0.29 (50.5 examples/sec; 0.158 sec/batch; 14h:23m:38s remains)
INFO - root - 2017-12-01 02:50:15.555241: step 5470, loss = 0.53, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 14h:01m:56s remains)
INFO - root - 2017-12-01 02:50:17.129153: step 5480, loss = 0.59, batch loss = 0.32 (51.5 examples/sec; 0.155 sec/batch; 14h:05m:55s remains)
INFO - root - 2017-12-01 02:50:18.691214: step 5490, loss = 0.60, batch loss = 0.33 (52.1 examples/sec; 0.154 sec/batch; 13h:57m:06s remains)
INFO - root - 2017-12-01 02:50:20.274999: step 5500, loss = 0.58, batch loss = 0.31 (48.6 examples/sec; 0.165 sec/batch; 14h:56m:53s remains)
INFO - root - 2017-12-01 02:50:21.947441: step 5510, loss = 0.71, batch loss = 0.44 (51.3 examples/sec; 0.156 sec/batch; 14h:09m:03s remains)
INFO - root - 2017-12-01 02:50:23.514034: step 5520, loss = 0.54, batch loss = 0.27 (52.6 examples/sec; 0.152 sec/batch; 13h:48m:51s remains)
INFO - root - 2017-12-01 02:50:25.084182: step 5530, loss = 0.63, batch loss = 0.36 (49.4 examples/sec; 0.162 sec/batch; 14h:42m:06s remains)
INFO - root - 2017-12-01 02:50:26.694065: step 5540, loss = 0.59, batch loss = 0.31 (50.3 examples/sec; 0.159 sec/batch; 14h:26m:19s remains)
INFO - root - 2017-12-01 02:50:28.279040: step 5550, loss = 0.66, batch loss = 0.39 (49.5 examples/sec; 0.162 sec/batch; 14h:40m:43s remains)
INFO - root - 2017-12-01 02:50:29.832383: step 5560, loss = 0.57, batch loss = 0.30 (52.9 examples/sec; 0.151 sec/batch; 13h:44m:39s remains)
INFO - root - 2017-12-01 02:50:31.398864: step 5570, loss = 0.55, batch loss = 0.28 (53.2 examples/sec; 0.150 sec/batch; 13h:38m:59s remains)
INFO - root - 2017-12-01 02:50:32.960538: step 5580, loss = 0.60, batch loss = 0.33 (52.4 examples/sec; 0.153 sec/batch; 13h:51m:51s remains)
INFO - root - 2017-12-01 02:50:34.536132: step 5590, loss = 0.56, batch loss = 0.29 (49.3 examples/sec; 0.162 sec/batch; 14h:44m:17s remains)
INFO - root - 2017-12-01 02:50:36.099854: step 5600, loss = 0.57, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 14h:19m:45s remains)
INFO - root - 2017-12-01 02:50:37.757979: step 5610, loss = 0.66, batch loss = 0.39 (52.1 examples/sec; 0.153 sec/batch; 13h:55m:48s remains)
INFO - root - 2017-12-01 02:50:39.311397: step 5620, loss = 0.52, batch loss = 0.25 (50.5 examples/sec; 0.158 sec/batch; 14h:22m:52s remains)
INFO - root - 2017-12-01 02:50:40.871207: step 5630, loss = 0.62, batch loss = 0.35 (48.5 examples/sec; 0.165 sec/batch; 14h:58m:53s remains)
INFO - root - 2017-12-01 02:50:42.429333: step 5640, loss = 0.61, batch loss = 0.34 (51.4 examples/sec; 0.156 sec/batch; 14h:08m:39s remains)
INFO - root - 2017-12-01 02:50:44.018416: step 5650, loss = 0.60, batch loss = 0.33 (49.3 examples/sec; 0.162 sec/batch; 14h:43m:58s remains)
INFO - root - 2017-12-01 02:50:45.595071: step 5660, loss = 0.57, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 14h:11m:45s remains)
INFO - root - 2017-12-01 02:50:47.165621: step 5670, loss = 0.68, batch loss = 0.41 (49.9 examples/sec; 0.160 sec/batch; 14h:33m:41s remains)
INFO - root - 2017-12-01 02:50:48.754236: step 5680, loss = 0.74, batch loss = 0.47 (52.0 examples/sec; 0.154 sec/batch; 13h:57m:38s remains)
INFO - root - 2017-12-01 02:50:50.345079: step 5690, loss = 0.72, batch loss = 0.45 (50.1 examples/sec; 0.160 sec/batch; 14h:29m:25s remains)
INFO - root - 2017-12-01 02:50:51.899310: step 5700, loss = 0.58, batch loss = 0.31 (50.3 examples/sec; 0.159 sec/batch; 14h:27m:04s remains)
INFO - root - 2017-12-01 02:50:53.512121: step 5710, loss = 0.64, batch loss = 0.37 (51.4 examples/sec; 0.156 sec/batch; 14h:07m:13s remains)
INFO - root - 2017-12-01 02:50:55.075752: step 5720, loss = 0.68, batch loss = 0.41 (51.7 examples/sec; 0.155 sec/batch; 14h:03m:16s remains)
INFO - root - 2017-12-01 02:50:56.667541: step 5730, loss = 0.54, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 14h:05m:36s remains)
INFO - root - 2017-12-01 02:50:58.225913: step 5740, loss = 0.84, batch loss = 0.57 (51.1 examples/sec; 0.157 sec/batch; 14h:13m:00s remains)
INFO - root - 2017-12-01 02:50:59.807275: step 5750, loss = 0.58, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 14h:03m:39s remains)
INFO - root - 2017-12-01 02:51:01.356011: step 5760, loss = 0.53, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 13h:58m:35s remains)
INFO - root - 2017-12-01 02:51:02.897011: step 5770, loss = 0.61, batch loss = 0.34 (52.0 examples/sec; 0.154 sec/batch; 13h:57m:46s remains)
INFO - root - 2017-12-01 02:51:04.470622: step 5780, loss = 0.61, batch loss = 0.34 (51.0 examples/sec; 0.157 sec/batch; 14h:14m:40s remains)
INFO - root - 2017-12-01 02:51:06.019274: step 5790, loss = 0.57, batch loss = 0.30 (50.3 examples/sec; 0.159 sec/batch; 14h:25m:11s remains)
INFO - root - 2017-12-01 02:51:07.579062: step 5800, loss = 0.61, batch loss = 0.34 (51.6 examples/sec; 0.155 sec/batch; 14h:04m:33s remains)
INFO - root - 2017-12-01 02:51:09.200785: step 5810, loss = 0.67, batch loss = 0.40 (49.9 examples/sec; 0.160 sec/batch; 14h:33m:07s remains)
INFO - root - 2017-12-01 02:51:10.802612: step 5820, loss = 0.77, batch loss = 0.50 (48.7 examples/sec; 0.164 sec/batch; 14h:54m:39s remains)
INFO - root - 2017-12-01 02:51:12.393300: step 5830, loss = 0.75, batch loss = 0.48 (49.2 examples/sec; 0.163 sec/batch; 14h:46m:09s remains)
INFO - root - 2017-12-01 02:51:13.961710: step 5840, loss = 0.63, batch loss = 0.36 (50.8 examples/sec; 0.158 sec/batch; 14h:17m:47s remains)
INFO - root - 2017-12-01 02:51:15.502771: step 5850, loss = 0.59, batch loss = 0.32 (52.1 examples/sec; 0.154 sec/batch; 13h:56m:10s remains)
INFO - root - 2017-12-01 02:51:17.065332: step 5860, loss = 0.60, batch loss = 0.32 (48.8 examples/sec; 0.164 sec/batch; 14h:53m:21s remains)
INFO - root - 2017-12-01 02:51:18.619305: step 5870, loss = 0.57, batch loss = 0.30 (49.1 examples/sec; 0.163 sec/batch; 14h:47m:20s remains)
INFO - root - 2017-12-01 02:51:20.184723: step 5880, loss = 0.52, batch loss = 0.25 (53.1 examples/sec; 0.151 sec/batch; 13h:40m:14s remains)
INFO - root - 2017-12-01 02:51:21.764827: step 5890, loss = 0.67, batch loss = 0.40 (51.5 examples/sec; 0.155 sec/batch; 14h:06m:16s remains)
INFO - root - 2017-12-01 02:51:23.334805: step 5900, loss = 0.56, batch loss = 0.29 (50.6 examples/sec; 0.158 sec/batch; 14h:20m:50s remains)
INFO - root - 2017-12-01 02:51:24.958277: step 5910, loss = 0.78, batch loss = 0.51 (50.7 examples/sec; 0.158 sec/batch; 14h:19m:19s remains)
INFO - root - 2017-12-01 02:51:26.556052: step 5920, loss = 0.64, batch loss = 0.37 (50.4 examples/sec; 0.159 sec/batch; 14h:24m:43s remains)
INFO - root - 2017-12-01 02:51:28.132254: step 5930, loss = 0.57, batch loss = 0.30 (50.1 examples/sec; 0.160 sec/batch; 14h:29m:44s remains)
INFO - root - 2017-12-01 02:51:29.736085: step 5940, loss = 0.53, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 14h:05m:59s remains)
INFO - root - 2017-12-01 02:51:31.291656: step 5950, loss = 0.51, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 14h:16m:05s remains)
INFO - root - 2017-12-01 02:51:32.887308: step 5960, loss = 0.66, batch loss = 0.39 (48.6 examples/sec; 0.165 sec/batch; 14h:56m:29s remains)
INFO - root - 2017-12-01 02:51:34.458311: step 5970, loss = 0.68, batch loss = 0.41 (52.0 examples/sec; 0.154 sec/batch; 13h:57m:44s remains)
INFO - root - 2017-12-01 02:51:36.011898: step 5980, loss = 0.64, batch loss = 0.37 (50.3 examples/sec; 0.159 sec/batch; 14h:25m:24s remains)
INFO - root - 2017-12-01 02:51:37.590459: step 5990, loss = 0.68, batch loss = 0.41 (50.7 examples/sec; 0.158 sec/batch; 14h:18m:49s remains)
INFO - root - 2017-12-01 02:51:39.154844: step 6000, loss = 0.55, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 14h:07m:45s remains)
INFO - root - 2017-12-01 02:51:40.826799: step 6010, loss = 0.56, batch loss = 0.29 (49.3 examples/sec; 0.162 sec/batch; 14h:42m:08s remains)
INFO - root - 2017-12-01 02:51:42.388622: step 6020, loss = 0.58, batch loss = 0.31 (52.0 examples/sec; 0.154 sec/batch; 13h:57m:39s remains)
INFO - root - 2017-12-01 02:51:43.953540: step 6030, loss = 0.65, batch loss = 0.38 (51.3 examples/sec; 0.156 sec/batch; 14h:09m:07s remains)
INFO - root - 2017-12-01 02:51:45.519563: step 6040, loss = 0.68, batch loss = 0.41 (52.0 examples/sec; 0.154 sec/batch; 13h:56m:25s remains)
INFO - root - 2017-12-01 02:51:47.101240: step 6050, loss = 0.60, batch loss = 0.33 (51.5 examples/sec; 0.155 sec/batch; 14h:05m:07s remains)
INFO - root - 2017-12-01 02:51:48.668678: step 6060, loss = 0.65, batch loss = 0.37 (48.8 examples/sec; 0.164 sec/batch; 14h:51m:38s remains)
INFO - root - 2017-12-01 02:51:50.234456: step 6070, loss = 0.56, batch loss = 0.29 (50.2 examples/sec; 0.159 sec/batch; 14h:26m:23s remains)
INFO - root - 2017-12-01 02:51:51.825672: step 6080, loss = 0.66, batch loss = 0.39 (50.7 examples/sec; 0.158 sec/batch; 14h:17m:41s remains)
INFO - root - 2017-12-01 02:51:53.395840: step 6090, loss = 0.55, batch loss = 0.28 (50.2 examples/sec; 0.159 sec/batch; 14h:26m:29s remains)
INFO - root - 2017-12-01 02:51:54.957654: step 6100, loss = 0.50, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 14h:17m:40s remains)
INFO - root - 2017-12-01 02:51:56.610564: step 6110, loss = 0.58, batch loss = 0.31 (50.5 examples/sec; 0.158 sec/batch; 14h:20m:55s remains)
INFO - root - 2017-12-01 02:51:58.175294: step 6120, loss = 0.60, batch loss = 0.32 (52.0 examples/sec; 0.154 sec/batch; 13h:56m:06s remains)
INFO - root - 2017-12-01 02:51:59.723987: step 6130, loss = 0.58, batch loss = 0.31 (52.6 examples/sec; 0.152 sec/batch; 13h:46m:38s remains)
INFO - root - 2017-12-01 02:52:01.271761: step 6140, loss = 0.60, batch loss = 0.33 (52.2 examples/sec; 0.153 sec/batch; 13h:54m:07s remains)
INFO - root - 2017-12-01 02:52:02.829355: step 6150, loss = 0.58, batch loss = 0.31 (51.7 examples/sec; 0.155 sec/batch; 14h:00m:53s remains)
INFO - root - 2017-12-01 02:52:04.390731: step 6160, loss = 0.61, batch loss = 0.34 (52.4 examples/sec; 0.153 sec/batch; 13h:50m:38s remains)
INFO - root - 2017-12-01 02:52:05.962276: step 6170, loss = 0.55, batch loss = 0.28 (49.4 examples/sec; 0.162 sec/batch; 14h:40m:45s remains)
INFO - root - 2017-12-01 02:52:07.540932: step 6180, loss = 0.62, batch loss = 0.35 (50.8 examples/sec; 0.158 sec/batch; 14h:16m:37s remains)
INFO - root - 2017-12-01 02:52:09.115036: step 6190, loss = 0.74, batch loss = 0.47 (48.3 examples/sec; 0.166 sec/batch; 15h:00m:10s remains)
INFO - root - 2017-12-01 02:52:10.691468: step 6200, loss = 0.69, batch loss = 0.42 (51.8 examples/sec; 0.155 sec/batch; 14h:00m:26s remains)
INFO - root - 2017-12-01 02:52:12.327078: step 6210, loss = 0.77, batch loss = 0.50 (51.0 examples/sec; 0.157 sec/batch; 14h:13m:44s remains)
INFO - root - 2017-12-01 02:52:13.897970: step 6220, loss = 0.59, batch loss = 0.32 (48.5 examples/sec; 0.165 sec/batch; 14h:56m:58s remains)
INFO - root - 2017-12-01 02:52:15.468328: step 6230, loss = 0.68, batch loss = 0.41 (51.1 examples/sec; 0.157 sec/batch; 14h:11m:50s remains)
INFO - root - 2017-12-01 02:52:17.027915: step 6240, loss = 0.62, batch loss = 0.35 (51.0 examples/sec; 0.157 sec/batch; 14h:13m:39s remains)
INFO - root - 2017-12-01 02:52:18.594160: step 6250, loss = 0.76, batch loss = 0.49 (49.6 examples/sec; 0.161 sec/batch; 14h:37m:37s remains)
INFO - root - 2017-12-01 02:52:20.172276: step 6260, loss = 0.58, batch loss = 0.31 (47.8 examples/sec; 0.167 sec/batch; 15h:09m:41s remains)
INFO - root - 2017-12-01 02:52:21.730662: step 6270, loss = 0.48, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 14h:05m:20s remains)
INFO - root - 2017-12-01 02:52:23.285127: step 6280, loss = 0.64, batch loss = 0.37 (51.8 examples/sec; 0.154 sec/batch; 13h:59m:56s remains)
INFO - root - 2017-12-01 02:52:24.860893: step 6290, loss = 0.79, batch loss = 0.52 (51.4 examples/sec; 0.156 sec/batch; 14h:07m:00s remains)
INFO - root - 2017-12-01 02:52:26.438874: step 6300, loss = 0.66, batch loss = 0.39 (52.5 examples/sec; 0.152 sec/batch; 13h:48m:01s remains)
INFO - root - 2017-12-01 02:52:28.076764: step 6310, loss = 0.61, batch loss = 0.34 (52.2 examples/sec; 0.153 sec/batch; 13h:53m:21s remains)
INFO - root - 2017-12-01 02:52:29.631206: step 6320, loss = 0.49, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 14h:07m:09s remains)
INFO - root - 2017-12-01 02:52:31.192698: step 6330, loss = 0.60, batch loss = 0.33 (51.9 examples/sec; 0.154 sec/batch; 13h:57m:48s remains)
INFO - root - 2017-12-01 02:52:32.770597: step 6340, loss = 0.60, batch loss = 0.33 (50.9 examples/sec; 0.157 sec/batch; 14h:14m:01s remains)
INFO - root - 2017-12-01 02:52:34.320763: step 6350, loss = 0.61, batch loss = 0.34 (53.0 examples/sec; 0.151 sec/batch; 13h:40m:57s remains)
INFO - root - 2017-12-01 02:52:35.869319: step 6360, loss = 0.62, batch loss = 0.35 (51.1 examples/sec; 0.156 sec/batch; 14h:10m:19s remains)
INFO - root - 2017-12-01 02:52:37.441538: step 6370, loss = 0.57, batch loss = 0.30 (48.9 examples/sec; 0.164 sec/batch; 14h:49m:49s remains)
INFO - root - 2017-12-01 02:52:38.998474: step 6380, loss = 0.56, batch loss = 0.29 (51.8 examples/sec; 0.154 sec/batch; 13h:58m:50s remains)
INFO - root - 2017-12-01 02:52:40.554966: step 6390, loss = 0.64, batch loss = 0.37 (50.2 examples/sec; 0.159 sec/batch; 14h:26m:52s remains)
INFO - root - 2017-12-01 02:52:42.124352: step 6400, loss = 0.57, batch loss = 0.30 (52.7 examples/sec; 0.152 sec/batch; 13h:44m:31s remains)
INFO - root - 2017-12-01 02:52:43.765244: step 6410, loss = 0.65, batch loss = 0.38 (51.5 examples/sec; 0.155 sec/batch; 14h:03m:32s remains)
INFO - root - 2017-12-01 02:52:45.326317: step 6420, loss = 0.58, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 14h:11m:57s remains)
INFO - root - 2017-12-01 02:52:46.896667: step 6430, loss = 0.57, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 14h:08m:20s remains)
INFO - root - 2017-12-01 02:52:48.466290: step 6440, loss = 0.65, batch loss = 0.38 (50.9 examples/sec; 0.157 sec/batch; 14h:13m:27s remains)
INFO - root - 2017-12-01 02:52:50.039185: step 6450, loss = 0.55, batch loss = 0.28 (49.0 examples/sec; 0.163 sec/batch; 14h:47m:05s remains)
INFO - root - 2017-12-01 02:52:51.621395: step 6460, loss = 0.64, batch loss = 0.37 (51.4 examples/sec; 0.156 sec/batch; 14h:05m:15s remains)
INFO - root - 2017-12-01 02:52:53.168167: step 6470, loss = 0.56, batch loss = 0.29 (52.6 examples/sec; 0.152 sec/batch; 13h:46m:44s remains)
INFO - root - 2017-12-01 02:52:54.721035: step 6480, loss = 0.57, batch loss = 0.30 (51.6 examples/sec; 0.155 sec/batch; 14h:02m:00s remains)
INFO - root - 2017-12-01 02:52:56.301300: step 6490, loss = 0.57, batch loss = 0.30 (50.4 examples/sec; 0.159 sec/batch; 14h:21m:47s remains)
INFO - root - 2017-12-01 02:52:57.871279: step 6500, loss = 0.84, batch loss = 0.57 (50.8 examples/sec; 0.158 sec/batch; 14h:15m:48s remains)
INFO - root - 2017-12-01 02:52:59.495865: step 6510, loss = 0.62, batch loss = 0.35 (51.8 examples/sec; 0.154 sec/batch; 13h:58m:18s remains)
INFO - root - 2017-12-01 02:53:01.057965: step 6520, loss = 0.69, batch loss = 0.42 (50.4 examples/sec; 0.159 sec/batch; 14h:21m:46s remains)
INFO - root - 2017-12-01 02:53:02.624917: step 6530, loss = 0.56, batch loss = 0.29 (49.5 examples/sec; 0.162 sec/batch; 14h:37m:43s remains)
INFO - root - 2017-12-01 02:53:04.192727: step 6540, loss = 0.55, batch loss = 0.28 (49.4 examples/sec; 0.162 sec/batch; 14h:39m:58s remains)
INFO - root - 2017-12-01 02:53:05.755048: step 6550, loss = 0.51, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 14h:23m:27s remains)
INFO - root - 2017-12-01 02:53:07.318279: step 6560, loss = 0.56, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 13h:57m:32s remains)
INFO - root - 2017-12-01 02:53:08.892001: step 6570, loss = 0.62, batch loss = 0.35 (50.8 examples/sec; 0.158 sec/batch; 14h:16m:08s remains)
INFO - root - 2017-12-01 02:53:10.465278: step 6580, loss = 0.56, batch loss = 0.29 (53.4 examples/sec; 0.150 sec/batch; 13h:33m:29s remains)
INFO - root - 2017-12-01 02:53:12.065320: step 6590, loss = 0.60, batch loss = 0.33 (49.6 examples/sec; 0.161 sec/batch; 14h:35m:17s remains)
INFO - root - 2017-12-01 02:53:13.615757: step 6600, loss = 0.55, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 13h:59m:42s remains)
INFO - root - 2017-12-01 02:53:15.227706: step 6610, loss = 0.52, batch loss = 0.25 (53.5 examples/sec; 0.149 sec/batch; 13h:31m:32s remains)
INFO - root - 2017-12-01 02:53:16.787061: step 6620, loss = 0.51, batch loss = 0.24 (52.5 examples/sec; 0.152 sec/batch; 13h:47m:02s remains)
INFO - root - 2017-12-01 02:53:18.342303: step 6630, loss = 0.63, batch loss = 0.36 (51.9 examples/sec; 0.154 sec/batch; 13h:57m:55s remains)
INFO - root - 2017-12-01 02:53:19.903428: step 6640, loss = 0.63, batch loss = 0.36 (51.2 examples/sec; 0.156 sec/batch; 14h:09m:00s remains)
INFO - root - 2017-12-01 02:53:21.476643: step 6650, loss = 0.49, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 14h:15m:11s remains)
INFO - root - 2017-12-01 02:53:23.044333: step 6660, loss = 0.58, batch loss = 0.31 (50.4 examples/sec; 0.159 sec/batch; 14h:22m:08s remains)
INFO - root - 2017-12-01 02:53:24.615422: step 6670, loss = 0.57, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 14h:13m:44s remains)
INFO - root - 2017-12-01 02:53:26.214378: step 6680, loss = 0.59, batch loss = 0.32 (49.3 examples/sec; 0.162 sec/batch; 14h:41m:27s remains)
INFO - root - 2017-12-01 02:53:27.762842: step 6690, loss = 0.57, batch loss = 0.31 (52.0 examples/sec; 0.154 sec/batch; 13h:54m:58s remains)
INFO - root - 2017-12-01 02:53:29.326860: step 6700, loss = 0.68, batch loss = 0.41 (50.3 examples/sec; 0.159 sec/batch; 14h:23m:27s remains)
INFO - root - 2017-12-01 02:53:30.945353: step 6710, loss = 0.57, batch loss = 0.30 (51.3 examples/sec; 0.156 sec/batch; 14h:06m:19s remains)
INFO - root - 2017-12-01 02:53:32.503833: step 6720, loss = 0.74, batch loss = 0.47 (51.3 examples/sec; 0.156 sec/batch; 14h:07m:22s remains)
INFO - root - 2017-12-01 02:53:34.050813: step 6730, loss = 0.67, batch loss = 0.40 (52.3 examples/sec; 0.153 sec/batch; 13h:50m:16s remains)
INFO - root - 2017-12-01 02:53:35.601660: step 6740, loss = 0.58, batch loss = 0.31 (51.5 examples/sec; 0.155 sec/batch; 14h:02m:35s remains)
INFO - root - 2017-12-01 02:53:37.173167: step 6750, loss = 0.75, batch loss = 0.48 (52.5 examples/sec; 0.153 sec/batch; 13h:48m:04s remains)
INFO - root - 2017-12-01 02:53:38.728151: step 6760, loss = 0.61, batch loss = 0.34 (52.3 examples/sec; 0.153 sec/batch; 13h:49m:49s remains)
INFO - root - 2017-12-01 02:53:40.289986: step 6770, loss = 0.56, batch loss = 0.29 (52.3 examples/sec; 0.153 sec/batch; 13h:50m:29s remains)
INFO - root - 2017-12-01 02:53:41.836597: step 6780, loss = 0.61, batch loss = 0.34 (51.4 examples/sec; 0.156 sec/batch; 14h:05m:16s remains)
INFO - root - 2017-12-01 02:53:43.397790: step 6790, loss = 0.57, batch loss = 0.30 (49.4 examples/sec; 0.162 sec/batch; 14h:39m:14s remains)
INFO - root - 2017-12-01 02:53:44.950143: step 6800, loss = 0.71, batch loss = 0.44 (51.4 examples/sec; 0.156 sec/batch; 14h:04m:13s remains)
INFO - root - 2017-12-01 02:53:46.596101: step 6810, loss = 0.58, batch loss = 0.31 (50.6 examples/sec; 0.158 sec/batch; 14h:17m:41s remains)
INFO - root - 2017-12-01 02:53:48.165718: step 6820, loss = 0.72, batch loss = 0.45 (50.3 examples/sec; 0.159 sec/batch; 14h:23m:41s remains)
INFO - root - 2017-12-01 02:53:49.701885: step 6830, loss = 0.62, batch loss = 0.35 (50.4 examples/sec; 0.159 sec/batch; 14h:21m:29s remains)
INFO - root - 2017-12-01 02:53:51.272084: step 6840, loss = 0.58, batch loss = 0.31 (51.9 examples/sec; 0.154 sec/batch; 13h:57m:04s remains)
INFO - root - 2017-12-01 02:53:52.838686: step 6850, loss = 0.55, batch loss = 0.28 (52.3 examples/sec; 0.153 sec/batch; 13h:50m:58s remains)
INFO - root - 2017-12-01 02:53:54.412184: step 6860, loss = 0.57, batch loss = 0.31 (51.4 examples/sec; 0.155 sec/batch; 14h:03m:54s remains)
INFO - root - 2017-12-01 02:53:55.998040: step 6870, loss = 0.52, batch loss = 0.25 (50.1 examples/sec; 0.160 sec/batch; 14h:27m:17s remains)
INFO - root - 2017-12-01 02:53:57.578790: step 6880, loss = 0.56, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 14h:06m:21s remains)
INFO - root - 2017-12-01 02:53:59.141148: step 6890, loss = 0.54, batch loss = 0.27 (51.7 examples/sec; 0.155 sec/batch; 13h:59m:41s remains)
INFO - root - 2017-12-01 02:54:00.715949: step 6900, loss = 0.57, batch loss = 0.30 (51.3 examples/sec; 0.156 sec/batch; 14h:05m:33s remains)
INFO - root - 2017-12-01 02:54:02.348130: step 6910, loss = 0.62, batch loss = 0.35 (52.3 examples/sec; 0.153 sec/batch; 13h:49m:20s remains)
INFO - root - 2017-12-01 02:54:03.909210: step 6920, loss = 0.52, batch loss = 0.26 (49.3 examples/sec; 0.162 sec/batch; 14h:40m:59s remains)
INFO - root - 2017-12-01 02:54:05.474690: step 6930, loss = 0.57, batch loss = 0.30 (51.6 examples/sec; 0.155 sec/batch; 14h:01m:01s remains)
INFO - root - 2017-12-01 02:54:07.035040: step 6940, loss = 0.61, batch loss = 0.34 (52.7 examples/sec; 0.152 sec/batch; 13h:43m:15s remains)
INFO - root - 2017-12-01 02:54:08.611815: step 6950, loss = 0.57, batch loss = 0.30 (52.0 examples/sec; 0.154 sec/batch; 13h:55m:27s remains)
INFO - root - 2017-12-01 02:54:10.177306: step 6960, loss = 0.58, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 14h:11m:39s remains)
INFO - root - 2017-12-01 02:54:11.741620: step 6970, loss = 0.54, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 14h:22m:32s remains)
INFO - root - 2017-12-01 02:54:13.302714: step 6980, loss = 0.70, batch loss = 0.43 (51.1 examples/sec; 0.157 sec/batch; 14h:09m:12s remains)
INFO - root - 2017-12-01 02:54:14.868959: step 6990, loss = 0.57, batch loss = 0.30 (50.2 examples/sec; 0.159 sec/batch; 14h:24m:58s remains)
INFO - root - 2017-12-01 02:54:16.447885: step 7000, loss = 0.57, batch loss = 0.30 (52.1 examples/sec; 0.154 sec/batch; 13h:53m:43s remains)
INFO - root - 2017-12-01 02:54:18.083935: step 7010, loss = 0.63, batch loss = 0.36 (49.6 examples/sec; 0.161 sec/batch; 14h:35m:49s remains)
INFO - root - 2017-12-01 02:54:19.661839: step 7020, loss = 0.69, batch loss = 0.42 (48.0 examples/sec; 0.167 sec/batch; 15h:03m:52s remains)
INFO - root - 2017-12-01 02:54:21.254186: step 7030, loss = 0.59, batch loss = 0.32 (49.3 examples/sec; 0.162 sec/batch; 14h:39m:38s remains)
INFO - root - 2017-12-01 02:54:22.808195: step 7040, loss = 0.51, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 14h:21m:36s remains)
INFO - root - 2017-12-01 02:54:24.380241: step 7050, loss = 0.76, batch loss = 0.49 (50.2 examples/sec; 0.159 sec/batch; 14h:24m:01s remains)
INFO - root - 2017-12-01 02:54:25.934697: step 7060, loss = 0.53, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 14h:02m:46s remains)
INFO - root - 2017-12-01 02:54:27.498568: step 7070, loss = 0.62, batch loss = 0.35 (51.5 examples/sec; 0.155 sec/batch; 14h:02m:31s remains)
INFO - root - 2017-12-01 02:54:29.054244: step 7080, loss = 0.56, batch loss = 0.29 (52.8 examples/sec; 0.152 sec/batch; 13h:41m:46s remains)
INFO - root - 2017-12-01 02:54:30.646571: step 7090, loss = 0.56, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 14h:11m:35s remains)
INFO - root - 2017-12-01 02:54:32.200592: step 7100, loss = 0.67, batch loss = 0.40 (50.0 examples/sec; 0.160 sec/batch; 14h:27m:32s remains)
INFO - root - 2017-12-01 02:54:33.847141: step 7110, loss = 0.68, batch loss = 0.41 (50.5 examples/sec; 0.159 sec/batch; 14h:19m:52s remains)
INFO - root - 2017-12-01 02:54:35.411527: step 7120, loss = 0.59, batch loss = 0.32 (50.8 examples/sec; 0.158 sec/batch; 14h:14m:38s remains)
INFO - root - 2017-12-01 02:54:36.975047: step 7130, loss = 0.64, batch loss = 0.37 (51.5 examples/sec; 0.155 sec/batch; 14h:02m:50s remains)
INFO - root - 2017-12-01 02:54:38.567562: step 7140, loss = 0.77, batch loss = 0.50 (50.5 examples/sec; 0.158 sec/batch; 14h:19m:18s remains)
INFO - root - 2017-12-01 02:54:40.154061: step 7150, loss = 0.55, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 14h:11m:44s remains)
INFO - root - 2017-12-01 02:54:41.719308: step 7160, loss = 0.55, batch loss = 0.29 (51.4 examples/sec; 0.156 sec/batch; 14h:04m:10s remains)
INFO - root - 2017-12-01 02:54:43.277677: step 7170, loss = 0.56, batch loss = 0.29 (52.6 examples/sec; 0.152 sec/batch; 13h:44m:42s remains)
INFO - root - 2017-12-01 02:54:44.837806: step 7180, loss = 0.54, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 14h:04m:28s remains)
INFO - root - 2017-12-01 02:54:46.412802: step 7190, loss = 0.58, batch loss = 0.31 (49.6 examples/sec; 0.161 sec/batch; 14h:35m:14s remains)
INFO - root - 2017-12-01 02:54:47.982883: step 7200, loss = 0.61, batch loss = 0.34 (50.8 examples/sec; 0.157 sec/batch; 14h:13m:12s remains)
INFO - root - 2017-12-01 02:54:49.660725: step 7210, loss = 0.53, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 14h:07m:16s remains)
INFO - root - 2017-12-01 02:54:51.219808: step 7220, loss = 0.74, batch loss = 0.47 (52.2 examples/sec; 0.153 sec/batch; 13h:50m:44s remains)
INFO - root - 2017-12-01 02:54:52.782202: step 7230, loss = 0.60, batch loss = 0.34 (51.7 examples/sec; 0.155 sec/batch; 13h:58m:56s remains)
INFO - root - 2017-12-01 02:54:54.365701: step 7240, loss = 0.58, batch loss = 0.31 (50.0 examples/sec; 0.160 sec/batch; 14h:27m:03s remains)
INFO - root - 2017-12-01 02:54:55.935816: step 7250, loss = 0.54, batch loss = 0.27 (50.0 examples/sec; 0.160 sec/batch; 14h:27m:30s remains)
INFO - root - 2017-12-01 02:54:57.485960: step 7260, loss = 0.61, batch loss = 0.34 (51.6 examples/sec; 0.155 sec/batch; 14h:00m:30s remains)
INFO - root - 2017-12-01 02:54:59.052019: step 7270, loss = 0.53, batch loss = 0.26 (50.3 examples/sec; 0.159 sec/batch; 14h:21m:33s remains)
INFO - root - 2017-12-01 02:55:00.598132: step 7280, loss = 0.52, batch loss = 0.25 (53.6 examples/sec; 0.149 sec/batch; 13h:28m:22s remains)
INFO - root - 2017-12-01 02:55:02.177802: step 7290, loss = 0.50, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 14h:08m:29s remains)
INFO - root - 2017-12-01 02:55:03.741760: step 7300, loss = 0.67, batch loss = 0.40 (51.0 examples/sec; 0.157 sec/batch; 14h:10m:17s remains)
INFO - root - 2017-12-01 02:55:05.356609: step 7310, loss = 0.54, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 14h:01m:39s remains)
INFO - root - 2017-12-01 02:55:06.936637: step 7320, loss = 0.58, batch loss = 0.32 (51.4 examples/sec; 0.156 sec/batch; 14h:04m:08s remains)
INFO - root - 2017-12-01 02:55:08.533165: step 7330, loss = 0.53, batch loss = 0.26 (49.3 examples/sec; 0.162 sec/batch; 14h:39m:58s remains)
INFO - root - 2017-12-01 02:55:10.106794: step 7340, loss = 0.55, batch loss = 0.29 (48.9 examples/sec; 0.164 sec/batch; 14h:46m:16s remains)
INFO - root - 2017-12-01 02:55:11.681585: step 7350, loss = 0.60, batch loss = 0.33 (50.9 examples/sec; 0.157 sec/batch; 14h:12m:02s remains)
INFO - root - 2017-12-01 02:55:13.237934: step 7360, loss = 0.59, batch loss = 0.33 (52.2 examples/sec; 0.153 sec/batch; 13h:50m:16s remains)
INFO - root - 2017-12-01 02:55:14.809624: step 7370, loss = 0.55, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 13h:58m:34s remains)
INFO - root - 2017-12-01 02:55:16.386973: step 7380, loss = 0.56, batch loss = 0.29 (50.4 examples/sec; 0.159 sec/batch; 14h:20m:48s remains)
INFO - root - 2017-12-01 02:55:17.944965: step 7390, loss = 0.61, batch loss = 0.34 (51.8 examples/sec; 0.154 sec/batch; 13h:57m:00s remains)
INFO - root - 2017-12-01 02:55:19.519877: step 7400, loss = 0.55, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 14h:14m:57s remains)
INFO - root - 2017-12-01 02:55:21.142645: step 7410, loss = 0.54, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 14h:09m:09s remains)
INFO - root - 2017-12-01 02:55:22.686684: step 7420, loss = 0.56, batch loss = 0.29 (51.1 examples/sec; 0.157 sec/batch; 14h:08m:13s remains)
INFO - root - 2017-12-01 02:55:24.246273: step 7430, loss = 0.69, batch loss = 0.42 (51.4 examples/sec; 0.156 sec/batch; 14h:03m:11s remains)
INFO - root - 2017-12-01 02:55:25.820045: step 7440, loss = 0.54, batch loss = 0.28 (52.1 examples/sec; 0.154 sec/batch; 13h:52m:13s remains)
INFO - root - 2017-12-01 02:55:27.408822: step 7450, loss = 0.53, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 14h:14m:15s remains)
INFO - root - 2017-12-01 02:55:28.968360: step 7460, loss = 0.50, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 14h:17m:05s remains)
INFO - root - 2017-12-01 02:55:30.540443: step 7470, loss = 0.54, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 13h:50m:48s remains)
INFO - root - 2017-12-01 02:55:32.099866: step 7480, loss = 0.51, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 14h:16m:48s remains)
INFO - root - 2017-12-01 02:55:33.676151: step 7490, loss = 0.59, batch loss = 0.32 (50.9 examples/sec; 0.157 sec/batch; 14h:10m:46s remains)
INFO - root - 2017-12-01 02:55:35.240089: step 7500, loss = 0.60, batch loss = 0.33 (51.4 examples/sec; 0.156 sec/batch; 14h:03m:00s remains)
INFO - root - 2017-12-01 02:55:36.876162: step 7510, loss = 0.69, batch loss = 0.42 (50.7 examples/sec; 0.158 sec/batch; 14h:15m:13s remains)
INFO - root - 2017-12-01 02:55:38.426720: step 7520, loss = 0.53, batch loss = 0.27 (50.2 examples/sec; 0.159 sec/batch; 14h:23m:41s remains)
INFO - root - 2017-12-01 02:55:39.982162: step 7530, loss = 0.63, batch loss = 0.36 (51.2 examples/sec; 0.156 sec/batch; 14h:07m:05s remains)
INFO - root - 2017-12-01 02:55:41.544926: step 7540, loss = 0.61, batch loss = 0.35 (50.8 examples/sec; 0.158 sec/batch; 14h:13m:01s remains)
INFO - root - 2017-12-01 02:55:43.120923: step 7550, loss = 0.58, batch loss = 0.32 (51.9 examples/sec; 0.154 sec/batch; 13h:54m:41s remains)
INFO - root - 2017-12-01 02:55:44.685411: step 7560, loss = 0.55, batch loss = 0.28 (52.7 examples/sec; 0.152 sec/batch; 13h:41m:28s remains)
INFO - root - 2017-12-01 02:55:46.252363: step 7570, loss = 0.63, batch loss = 0.36 (49.6 examples/sec; 0.161 sec/batch; 14h:33m:11s remains)
INFO - root - 2017-12-01 02:55:47.810141: step 7580, loss = 0.58, batch loss = 0.31 (50.0 examples/sec; 0.160 sec/batch; 14h:27m:09s remains)
INFO - root - 2017-12-01 02:55:49.369500: step 7590, loss = 0.56, batch loss = 0.29 (48.3 examples/sec; 0.166 sec/batch; 14h:57m:22s remains)
INFO - root - 2017-12-01 02:55:50.935181: step 7600, loss = 0.70, batch loss = 0.43 (50.0 examples/sec; 0.160 sec/batch; 14h:26m:26s remains)
INFO - root - 2017-12-01 02:55:52.575463: step 7610, loss = 0.76, batch loss = 0.50 (49.2 examples/sec; 0.162 sec/batch; 14h:39m:35s remains)
INFO - root - 2017-12-01 02:55:54.132919: step 7620, loss = 0.56, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 13h:59m:57s remains)
INFO - root - 2017-12-01 02:55:55.712740: step 7630, loss = 0.69, batch loss = 0.42 (49.9 examples/sec; 0.160 sec/batch; 14h:28m:21s remains)
INFO - root - 2017-12-01 02:55:57.273163: step 7640, loss = 0.53, batch loss = 0.26 (52.3 examples/sec; 0.153 sec/batch; 13h:47m:31s remains)
INFO - root - 2017-12-01 02:55:58.852145: step 7650, loss = 0.55, batch loss = 0.29 (50.0 examples/sec; 0.160 sec/batch; 14h:26m:59s remains)
INFO - root - 2017-12-01 02:56:00.426614: step 7660, loss = 0.68, batch loss = 0.41 (50.6 examples/sec; 0.158 sec/batch; 14h:15m:21s remains)
INFO - root - 2017-12-01 02:56:01.967466: step 7670, loss = 0.64, batch loss = 0.37 (52.1 examples/sec; 0.153 sec/batch; 13h:50m:32s remains)
INFO - root - 2017-12-01 02:56:03.550281: step 7680, loss = 0.74, batch loss = 0.47 (51.9 examples/sec; 0.154 sec/batch; 13h:54m:46s remains)
INFO - root - 2017-12-01 02:56:05.126731: step 7690, loss = 0.52, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 14h:15m:31s remains)
INFO - root - 2017-12-01 02:56:06.678693: step 7700, loss = 0.57, batch loss = 0.30 (50.4 examples/sec; 0.159 sec/batch; 14h:19m:13s remains)
INFO - root - 2017-12-01 02:56:08.320240: step 7710, loss = 0.58, batch loss = 0.31 (50.4 examples/sec; 0.159 sec/batch; 14h:19m:53s remains)
INFO - root - 2017-12-01 02:56:09.875324: step 7720, loss = 0.56, batch loss = 0.29 (50.8 examples/sec; 0.157 sec/batch; 14h:11m:53s remains)
INFO - root - 2017-12-01 02:56:11.454615: step 7730, loss = 0.55, batch loss = 0.29 (47.9 examples/sec; 0.167 sec/batch; 15h:03m:34s remains)
INFO - root - 2017-12-01 02:56:13.018109: step 7740, loss = 0.63, batch loss = 0.36 (53.2 examples/sec; 0.150 sec/batch; 13h:33m:58s remains)
INFO - root - 2017-12-01 02:56:14.578205: step 7750, loss = 0.60, batch loss = 0.33 (51.3 examples/sec; 0.156 sec/batch; 14h:04m:46s remains)
INFO - root - 2017-12-01 02:56:16.141914: step 7760, loss = 0.62, batch loss = 0.35 (52.4 examples/sec; 0.153 sec/batch; 13h:46m:13s remains)
INFO - root - 2017-12-01 02:56:17.722819: step 7770, loss = 0.58, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 14h:14m:28s remains)
INFO - root - 2017-12-01 02:56:19.293211: step 7780, loss = 0.54, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 14h:13m:08s remains)
INFO - root - 2017-12-01 02:56:20.860697: step 7790, loss = 0.55, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 13h:58m:39s remains)
INFO - root - 2017-12-01 02:56:22.433199: step 7800, loss = 0.61, batch loss = 0.35 (49.8 examples/sec; 0.161 sec/batch; 14h:29m:47s remains)
INFO - root - 2017-12-01 02:56:24.047410: step 7810, loss = 0.61, batch loss = 0.34 (49.8 examples/sec; 0.161 sec/batch; 14h:29m:22s remains)
INFO - root - 2017-12-01 02:56:25.643169: step 7820, loss = 0.64, batch loss = 0.37 (52.7 examples/sec; 0.152 sec/batch; 13h:41m:20s remains)
INFO - root - 2017-12-01 02:56:27.183622: step 7830, loss = 0.55, batch loss = 0.28 (52.0 examples/sec; 0.154 sec/batch; 13h:52m:07s remains)
INFO - root - 2017-12-01 02:56:28.760321: step 7840, loss = 0.74, batch loss = 0.47 (50.5 examples/sec; 0.158 sec/batch; 14h:17m:31s remains)
INFO - root - 2017-12-01 02:56:30.329777: step 7850, loss = 0.58, batch loss = 0.32 (48.9 examples/sec; 0.164 sec/batch; 14h:45m:46s remains)
INFO - root - 2017-12-01 02:56:31.889146: step 7860, loss = 0.73, batch loss = 0.46 (52.6 examples/sec; 0.152 sec/batch; 13h:42m:36s remains)
INFO - root - 2017-12-01 02:56:33.433522: step 7870, loss = 0.69, batch loss = 0.42 (52.8 examples/sec; 0.151 sec/batch; 13h:39m:18s remains)
INFO - root - 2017-12-01 02:56:35.004361: step 7880, loss = 0.57, batch loss = 0.30 (52.3 examples/sec; 0.153 sec/batch; 13h:47m:11s remains)
INFO - root - 2017-12-01 02:56:36.580577: step 7890, loss = 0.57, batch loss = 0.30 (52.0 examples/sec; 0.154 sec/batch; 13h:51m:56s remains)
INFO - root - 2017-12-01 02:56:38.126512: step 7900, loss = 0.54, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 13h:58m:05s remains)
INFO - root - 2017-12-01 02:56:39.778168: step 7910, loss = 0.55, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 14h:17m:07s remains)
INFO - root - 2017-12-01 02:56:41.363139: step 7920, loss = 0.58, batch loss = 0.32 (52.7 examples/sec; 0.152 sec/batch; 13h:40m:44s remains)
INFO - root - 2017-12-01 02:56:42.909970: step 7930, loss = 0.50, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 13h:40m:32s remains)
INFO - root - 2017-12-01 02:56:44.478955: step 7940, loss = 0.55, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 14h:01m:28s remains)
INFO - root - 2017-12-01 02:56:46.057044: step 7950, loss = 0.61, batch loss = 0.35 (50.8 examples/sec; 0.157 sec/batch; 14h:11m:12s remains)
INFO - root - 2017-12-01 02:56:47.634001: step 7960, loss = 0.69, batch loss = 0.42 (50.6 examples/sec; 0.158 sec/batch; 14h:15m:39s remains)
INFO - root - 2017-12-01 02:56:49.186763: step 7970, loss = 0.48, batch loss = 0.21 (49.6 examples/sec; 0.161 sec/batch; 14h:32m:06s remains)
INFO - root - 2017-12-01 02:56:50.767574: step 7980, loss = 0.65, batch loss = 0.38 (52.1 examples/sec; 0.153 sec/batch; 13h:49m:58s remains)
INFO - root - 2017-12-01 02:56:52.321214: step 7990, loss = 0.65, batch loss = 0.38 (52.2 examples/sec; 0.153 sec/batch; 13h:48m:36s remains)
INFO - root - 2017-12-01 02:56:53.876237: step 8000, loss = 0.52, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 14h:08m:58s remains)
INFO - root - 2017-12-01 02:56:55.525136: step 8010, loss = 0.79, batch loss = 0.52 (51.6 examples/sec; 0.155 sec/batch; 13h:58m:30s remains)
INFO - root - 2017-12-01 02:56:57.138782: step 8020, loss = 0.64, batch loss = 0.38 (51.0 examples/sec; 0.157 sec/batch; 14h:08m:50s remains)
INFO - root - 2017-12-01 02:56:58.686729: step 8030, loss = 0.59, batch loss = 0.32 (52.5 examples/sec; 0.153 sec/batch; 13h:44m:49s remains)
INFO - root - 2017-12-01 02:57:00.244799: step 8040, loss = 0.63, batch loss = 0.36 (51.8 examples/sec; 0.155 sec/batch; 13h:55m:41s remains)
INFO - root - 2017-12-01 02:57:01.822687: step 8050, loss = 0.54, batch loss = 0.27 (51.8 examples/sec; 0.154 sec/batch; 13h:55m:23s remains)
INFO - root - 2017-12-01 02:57:03.380651: step 8060, loss = 0.52, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 13h:58m:39s remains)
INFO - root - 2017-12-01 02:57:04.953053: step 8070, loss = 0.56, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 13h:54m:15s remains)
INFO - root - 2017-12-01 02:57:06.501135: step 8080, loss = 0.53, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 13h:51m:48s remains)
INFO - root - 2017-12-01 02:57:08.065655: step 8090, loss = 0.66, batch loss = 0.39 (51.6 examples/sec; 0.155 sec/batch; 13h:58m:52s remains)
INFO - root - 2017-12-01 02:57:09.655627: step 8100, loss = 0.55, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 13h:59m:07s remains)
INFO - root - 2017-12-01 02:57:11.303146: step 8110, loss = 0.61, batch loss = 0.35 (52.0 examples/sec; 0.154 sec/batch; 13h:51m:18s remains)
INFO - root - 2017-12-01 02:57:12.876189: step 8120, loss = 0.56, batch loss = 0.30 (51.8 examples/sec; 0.154 sec/batch; 13h:54m:38s remains)
INFO - root - 2017-12-01 02:57:14.470302: step 8130, loss = 0.54, batch loss = 0.27 (49.9 examples/sec; 0.160 sec/batch; 14h:27m:07s remains)
INFO - root - 2017-12-01 02:57:16.010326: step 8140, loss = 0.63, batch loss = 0.36 (51.4 examples/sec; 0.156 sec/batch; 14h:01m:54s remains)
INFO - root - 2017-12-01 02:57:17.579099: step 8150, loss = 0.55, batch loss = 0.29 (50.6 examples/sec; 0.158 sec/batch; 14h:14m:10s remains)
INFO - root - 2017-12-01 02:57:19.147086: step 8160, loss = 0.59, batch loss = 0.32 (51.4 examples/sec; 0.156 sec/batch; 14h:00m:52s remains)
INFO - root - 2017-12-01 02:57:20.723648: step 8170, loss = 0.52, batch loss = 0.25 (50.2 examples/sec; 0.159 sec/batch; 14h:21m:22s remains)
INFO - root - 2017-12-01 02:57:22.279473: step 8180, loss = 0.75, batch loss = 0.49 (51.8 examples/sec; 0.154 sec/batch; 13h:54m:10s remains)
INFO - root - 2017-12-01 02:57:23.844479: step 8190, loss = 0.62, batch loss = 0.36 (48.6 examples/sec; 0.165 sec/batch; 14h:50m:10s remains)
INFO - root - 2017-12-01 02:57:25.411153: step 8200, loss = 0.52, batch loss = 0.26 (49.9 examples/sec; 0.160 sec/batch; 14h:26m:19s remains)
INFO - root - 2017-12-01 02:57:27.077782: step 8210, loss = 0.59, batch loss = 0.33 (50.8 examples/sec; 0.158 sec/batch; 14h:11m:54s remains)
INFO - root - 2017-12-01 02:57:28.639714: step 8220, loss = 0.58, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 14h:04m:22s remains)
INFO - root - 2017-12-01 02:57:30.208269: step 8230, loss = 0.73, batch loss = 0.47 (51.5 examples/sec; 0.155 sec/batch; 13h:59m:14s remains)
INFO - root - 2017-12-01 02:57:31.799761: step 8240, loss = 0.69, batch loss = 0.43 (49.8 examples/sec; 0.161 sec/batch; 14h:28m:18s remains)
INFO - root - 2017-12-01 02:57:33.350592: step 8250, loss = 0.53, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 14h:19m:24s remains)
INFO - root - 2017-12-01 02:57:34.904088: step 8260, loss = 0.63, batch loss = 0.37 (51.0 examples/sec; 0.157 sec/batch; 14h:08m:26s remains)
INFO - root - 2017-12-01 02:57:36.485439: step 8270, loss = 0.61, batch loss = 0.35 (50.6 examples/sec; 0.158 sec/batch; 14h:14m:36s remains)
INFO - root - 2017-12-01 02:57:38.065368: step 8280, loss = 0.69, batch loss = 0.43 (50.3 examples/sec; 0.159 sec/batch; 14h:20m:02s remains)
INFO - root - 2017-12-01 02:57:39.618246: step 8290, loss = 0.71, batch loss = 0.44 (51.1 examples/sec; 0.157 sec/batch; 14h:06m:39s remains)
INFO - root - 2017-12-01 02:57:41.180407: step 8300, loss = 0.54, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 13h:59m:21s remains)
INFO - root - 2017-12-01 02:57:42.846299: step 8310, loss = 0.64, batch loss = 0.37 (51.2 examples/sec; 0.156 sec/batch; 14h:04m:38s remains)
INFO - root - 2017-12-01 02:57:44.406151: step 8320, loss = 0.62, batch loss = 0.35 (50.9 examples/sec; 0.157 sec/batch; 14h:09m:49s remains)
INFO - root - 2017-12-01 02:57:45.943227: step 8330, loss = 0.71, batch loss = 0.45 (51.8 examples/sec; 0.155 sec/batch; 13h:55m:03s remains)
INFO - root - 2017-12-01 02:57:47.495329: step 8340, loss = 0.70, batch loss = 0.43 (51.9 examples/sec; 0.154 sec/batch; 13h:53m:28s remains)
INFO - root - 2017-12-01 02:57:49.077481: step 8350, loss = 0.55, batch loss = 0.29 (50.8 examples/sec; 0.158 sec/batch; 14h:10m:59s remains)
INFO - root - 2017-12-01 02:57:50.663638: step 8360, loss = 0.61, batch loss = 0.35 (45.1 examples/sec; 0.177 sec/batch; 15h:58m:09s remains)
INFO - root - 2017-12-01 02:57:52.243512: step 8370, loss = 0.52, batch loss = 0.26 (48.4 examples/sec; 0.165 sec/batch; 14h:52m:41s remains)
INFO - root - 2017-12-01 02:57:53.803108: step 8380, loss = 0.55, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 14h:15m:25s remains)
INFO - root - 2017-12-01 02:57:55.375884: step 8390, loss = 0.60, batch loss = 0.34 (50.5 examples/sec; 0.158 sec/batch; 14h:15m:17s remains)
INFO - root - 2017-12-01 02:57:56.951406: step 8400, loss = 0.54, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 13h:57m:39s remains)
INFO - root - 2017-12-01 02:57:58.561911: step 8410, loss = 0.61, batch loss = 0.35 (51.9 examples/sec; 0.154 sec/batch; 13h:51m:52s remains)
INFO - root - 2017-12-01 02:58:00.130650: step 8420, loss = 0.57, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 14h:12m:09s remains)
INFO - root - 2017-12-01 02:58:01.679267: step 8430, loss = 0.49, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 13h:52m:16s remains)
INFO - root - 2017-12-01 02:58:03.267532: step 8440, loss = 0.68, batch loss = 0.42 (50.2 examples/sec; 0.159 sec/batch; 14h:20m:34s remains)
INFO - root - 2017-12-01 02:58:04.829758: step 8450, loss = 0.60, batch loss = 0.33 (49.2 examples/sec; 0.163 sec/batch; 14h:38m:27s remains)
INFO - root - 2017-12-01 02:58:06.379703: step 8460, loss = 0.53, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 13h:47m:00s remains)
INFO - root - 2017-12-01 02:58:07.946871: step 8470, loss = 0.67, batch loss = 0.40 (50.7 examples/sec; 0.158 sec/batch; 14h:11m:48s remains)
INFO - root - 2017-12-01 02:58:09.520553: step 8480, loss = 0.61, batch loss = 0.34 (49.9 examples/sec; 0.160 sec/batch; 14h:25m:26s remains)
INFO - root - 2017-12-01 02:58:11.079335: step 8490, loss = 0.59, batch loss = 0.32 (51.8 examples/sec; 0.154 sec/batch; 13h:54m:18s remains)
INFO - root - 2017-12-01 02:58:12.626652: step 8500, loss = 0.66, batch loss = 0.39 (50.7 examples/sec; 0.158 sec/batch; 14h:12m:36s remains)
INFO - root - 2017-12-01 02:58:14.285068: step 8510, loss = 0.54, batch loss = 0.27 (50.1 examples/sec; 0.160 sec/batch; 14h:22m:46s remains)
INFO - root - 2017-12-01 02:58:15.846916: step 8520, loss = 0.47, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 14h:11m:14s remains)
INFO - root - 2017-12-01 02:58:17.403973: step 8530, loss = 0.60, batch loss = 0.33 (50.7 examples/sec; 0.158 sec/batch; 14h:12m:22s remains)
INFO - root - 2017-12-01 02:58:18.987913: step 8540, loss = 0.67, batch loss = 0.40 (52.0 examples/sec; 0.154 sec/batch; 13h:50m:33s remains)
INFO - root - 2017-12-01 02:58:20.554021: step 8550, loss = 0.69, batch loss = 0.42 (52.1 examples/sec; 0.153 sec/batch; 13h:48m:40s remains)
INFO - root - 2017-12-01 02:58:22.123909: step 8560, loss = 0.60, batch loss = 0.33 (51.2 examples/sec; 0.156 sec/batch; 14h:02m:55s remains)
INFO - root - 2017-12-01 02:58:23.691825: step 8570, loss = 0.61, batch loss = 0.34 (51.1 examples/sec; 0.157 sec/batch; 14h:05m:51s remains)
INFO - root - 2017-12-01 02:58:25.249423: step 8580, loss = 0.53, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 14h:06m:44s remains)
INFO - root - 2017-12-01 02:58:26.813914: step 8590, loss = 0.62, batch loss = 0.35 (52.8 examples/sec; 0.151 sec/batch; 13h:37m:17s remains)
INFO - root - 2017-12-01 02:58:28.380171: step 8600, loss = 0.62, batch loss = 0.36 (53.2 examples/sec; 0.150 sec/batch; 13h:31m:14s remains)
INFO - root - 2017-12-01 02:58:30.000479: step 8610, loss = 0.50, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 13h:56m:08s remains)
INFO - root - 2017-12-01 02:58:31.612365: step 8620, loss = 0.67, batch loss = 0.41 (46.5 examples/sec; 0.172 sec/batch; 15h:28m:09s remains)
INFO - root - 2017-12-01 02:58:33.199508: step 8630, loss = 0.55, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 14h:01m:03s remains)
INFO - root - 2017-12-01 02:58:34.766772: step 8640, loss = 0.50, batch loss = 0.23 (48.0 examples/sec; 0.167 sec/batch; 14h:59m:06s remains)
INFO - root - 2017-12-01 02:58:36.320781: step 8650, loss = 0.54, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 14h:01m:36s remains)
INFO - root - 2017-12-01 02:58:37.918345: step 8660, loss = 0.58, batch loss = 0.31 (49.5 examples/sec; 0.162 sec/batch; 14h:32m:48s remains)
INFO - root - 2017-12-01 02:58:39.488355: step 8670, loss = 0.53, batch loss = 0.26 (48.3 examples/sec; 0.166 sec/batch; 14h:54m:51s remains)
INFO - root - 2017-12-01 02:58:41.068553: step 8680, loss = 0.59, batch loss = 0.33 (51.5 examples/sec; 0.155 sec/batch; 13h:57m:34s remains)
INFO - root - 2017-12-01 02:58:42.653666: step 8690, loss = 0.59, batch loss = 0.33 (52.4 examples/sec; 0.153 sec/batch; 13h:43m:33s remains)
INFO - root - 2017-12-01 02:58:44.229876: step 8700, loss = 0.54, batch loss = 0.27 (50.2 examples/sec; 0.159 sec/batch; 14h:19m:25s remains)
INFO - root - 2017-12-01 02:58:45.877236: step 8710, loss = 0.67, batch loss = 0.40 (51.8 examples/sec; 0.154 sec/batch; 13h:53m:29s remains)
INFO - root - 2017-12-01 02:58:47.428905: step 8720, loss = 0.49, batch loss = 0.23 (52.9 examples/sec; 0.151 sec/batch; 13h:35m:20s remains)
INFO - root - 2017-12-01 02:58:48.992884: step 8730, loss = 0.68, batch loss = 0.42 (50.2 examples/sec; 0.159 sec/batch; 14h:19m:12s remains)
INFO - root - 2017-12-01 02:58:50.566315: step 8740, loss = 0.51, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 13h:55m:14s remains)
INFO - root - 2017-12-01 02:58:52.128327: step 8750, loss = 0.48, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 13h:55m:30s remains)
INFO - root - 2017-12-01 02:58:53.689478: step 8760, loss = 0.51, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 13h:44m:57s remains)
INFO - root - 2017-12-01 02:58:55.281463: step 8770, loss = 0.51, batch loss = 0.25 (50.0 examples/sec; 0.160 sec/batch; 14h:23m:59s remains)
INFO - root - 2017-12-01 02:58:56.833999: step 8780, loss = 0.49, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 13h:54m:25s remains)
INFO - root - 2017-12-01 02:58:58.401879: step 8790, loss = 0.60, batch loss = 0.34 (52.3 examples/sec; 0.153 sec/batch; 13h:45m:43s remains)
INFO - root - 2017-12-01 02:58:59.967712: step 8800, loss = 0.58, batch loss = 0.31 (52.0 examples/sec; 0.154 sec/batch; 13h:50m:39s remains)
INFO - root - 2017-12-01 02:59:01.569048: step 8810, loss = 0.61, batch loss = 0.35 (51.6 examples/sec; 0.155 sec/batch; 13h:56m:31s remains)
INFO - root - 2017-12-01 02:59:03.126052: step 8820, loss = 0.53, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 13h:58m:47s remains)
INFO - root - 2017-12-01 02:59:04.704999: step 8830, loss = 0.58, batch loss = 0.32 (51.6 examples/sec; 0.155 sec/batch; 13h:56m:09s remains)
INFO - root - 2017-12-01 02:59:06.268271: step 8840, loss = 0.58, batch loss = 0.32 (51.3 examples/sec; 0.156 sec/batch; 14h:01m:59s remains)
INFO - root - 2017-12-01 02:59:07.833292: step 8850, loss = 0.60, batch loss = 0.34 (50.9 examples/sec; 0.157 sec/batch; 14h:07m:35s remains)
INFO - root - 2017-12-01 02:59:09.399236: step 8860, loss = 0.57, batch loss = 0.31 (49.7 examples/sec; 0.161 sec/batch; 14h:28m:01s remains)
INFO - root - 2017-12-01 02:59:10.986841: step 8870, loss = 0.64, batch loss = 0.37 (50.3 examples/sec; 0.159 sec/batch; 14h:17m:17s remains)
INFO - root - 2017-12-01 02:59:12.576135: step 8880, loss = 0.50, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 13h:44m:44s remains)
INFO - root - 2017-12-01 02:59:14.154997: step 8890, loss = 0.58, batch loss = 0.31 (50.5 examples/sec; 0.158 sec/batch; 14h:13m:46s remains)
INFO - root - 2017-12-01 02:59:15.715066: step 8900, loss = 0.70, batch loss = 0.43 (51.7 examples/sec; 0.155 sec/batch; 13h:54m:02s remains)
INFO - root - 2017-12-01 02:59:17.341787: step 8910, loss = 0.63, batch loss = 0.37 (50.9 examples/sec; 0.157 sec/batch; 14h:08m:13s remains)
INFO - root - 2017-12-01 02:59:18.902281: step 8920, loss = 0.66, batch loss = 0.40 (50.6 examples/sec; 0.158 sec/batch; 14h:12m:43s remains)
INFO - root - 2017-12-01 02:59:20.464237: step 8930, loss = 0.71, batch loss = 0.45 (49.7 examples/sec; 0.161 sec/batch; 14h:28m:00s remains)
INFO - root - 2017-12-01 02:59:22.036598: step 8940, loss = 0.57, batch loss = 0.31 (52.6 examples/sec; 0.152 sec/batch; 13h:40m:37s remains)
INFO - root - 2017-12-01 02:59:23.604384: step 8950, loss = 0.49, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 13h:46m:05s remains)
INFO - root - 2017-12-01 02:59:25.176100: step 8960, loss = 0.55, batch loss = 0.29 (48.8 examples/sec; 0.164 sec/batch; 14h:44m:50s remains)
INFO - root - 2017-12-01 02:59:26.735612: step 8970, loss = 0.59, batch loss = 0.32 (49.7 examples/sec; 0.161 sec/batch; 14h:27m:17s remains)
INFO - root - 2017-12-01 02:59:28.302396: step 8980, loss = 0.59, batch loss = 0.32 (51.8 examples/sec; 0.154 sec/batch; 13h:52m:54s remains)
INFO - root - 2017-12-01 02:59:29.856689: step 8990, loss = 0.67, batch loss = 0.41 (52.7 examples/sec; 0.152 sec/batch; 13h:38m:00s remains)
INFO - root - 2017-12-01 02:59:31.448252: step 9000, loss = 0.59, batch loss = 0.32 (50.9 examples/sec; 0.157 sec/batch; 14h:08m:06s remains)
INFO - root - 2017-12-01 02:59:33.081164: step 9010, loss = 0.66, batch loss = 0.40 (50.3 examples/sec; 0.159 sec/batch; 14h:17m:50s remains)
INFO - root - 2017-12-01 02:59:34.665165: step 9020, loss = 0.60, batch loss = 0.34 (50.7 examples/sec; 0.158 sec/batch; 14h:10m:21s remains)
INFO - root - 2017-12-01 02:59:36.225091: step 9030, loss = 0.60, batch loss = 0.34 (51.7 examples/sec; 0.155 sec/batch; 13h:53m:52s remains)
INFO - root - 2017-12-01 02:59:37.784956: step 9040, loss = 0.63, batch loss = 0.37 (51.8 examples/sec; 0.154 sec/batch; 13h:52m:37s remains)
INFO - root - 2017-12-01 02:59:39.337527: step 9050, loss = 0.66, batch loss = 0.39 (52.1 examples/sec; 0.153 sec/batch; 13h:47m:21s remains)
INFO - root - 2017-12-01 02:59:40.934056: step 9060, loss = 0.56, batch loss = 0.30 (52.0 examples/sec; 0.154 sec/batch; 13h:48m:41s remains)
INFO - root - 2017-12-01 02:59:42.488347: step 9070, loss = 0.59, batch loss = 0.32 (50.8 examples/sec; 0.158 sec/batch; 14h:09m:38s remains)
INFO - root - 2017-12-01 02:59:44.046969: step 9080, loss = 0.54, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 14h:04m:33s remains)
INFO - root - 2017-12-01 02:59:45.628039: step 9090, loss = 0.57, batch loss = 0.30 (52.0 examples/sec; 0.154 sec/batch; 13h:49m:03s remains)
INFO - root - 2017-12-01 02:59:47.193333: step 9100, loss = 0.66, batch loss = 0.40 (51.7 examples/sec; 0.155 sec/batch; 13h:54m:05s remains)
INFO - root - 2017-12-01 02:59:48.832474: step 9110, loss = 0.55, batch loss = 0.29 (53.2 examples/sec; 0.150 sec/batch; 13h:30m:03s remains)
INFO - root - 2017-12-01 02:59:50.406819: step 9120, loss = 0.52, batch loss = 0.26 (49.7 examples/sec; 0.161 sec/batch; 14h:27m:40s remains)
INFO - root - 2017-12-01 02:59:51.989837: step 9130, loss = 0.67, batch loss = 0.40 (52.3 examples/sec; 0.153 sec/batch; 13h:43m:48s remains)
INFO - root - 2017-12-01 02:59:53.551689: step 9140, loss = 0.52, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 14h:06m:37s remains)
INFO - root - 2017-12-01 02:59:55.129976: step 9150, loss = 0.61, batch loss = 0.35 (50.3 examples/sec; 0.159 sec/batch; 14h:17m:26s remains)
INFO - root - 2017-12-01 02:59:56.713789: step 9160, loss = 0.56, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 14h:10m:21s remains)
INFO - root - 2017-12-01 02:59:58.286264: step 9170, loss = 0.64, batch loss = 0.37 (52.0 examples/sec; 0.154 sec/batch; 13h:48m:21s remains)
INFO - root - 2017-12-01 02:59:59.889962: step 9180, loss = 0.50, batch loss = 0.24 (48.6 examples/sec; 0.165 sec/batch; 14h:46m:36s remains)
INFO - root - 2017-12-01 03:00:01.447653: step 9190, loss = 0.53, batch loss = 0.27 (53.2 examples/sec; 0.150 sec/batch; 13h:29m:48s remains)
INFO - root - 2017-12-01 03:00:03.016388: step 9200, loss = 0.50, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 14h:13m:41s remains)
INFO - root - 2017-12-01 03:00:04.653704: step 9210, loss = 0.48, batch loss = 0.22 (48.9 examples/sec; 0.163 sec/batch; 14h:40m:40s remains)
INFO - root - 2017-12-01 03:00:06.235617: step 9220, loss = 0.55, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 13h:59m:22s remains)
INFO - root - 2017-12-01 03:00:07.794148: step 9230, loss = 0.66, batch loss = 0.40 (51.6 examples/sec; 0.155 sec/batch; 13h:55m:13s remains)
INFO - root - 2017-12-01 03:00:09.380551: step 9240, loss = 0.65, batch loss = 0.39 (50.8 examples/sec; 0.157 sec/batch; 14h:07m:38s remains)
INFO - root - 2017-12-01 03:00:10.966369: step 9250, loss = 0.52, batch loss = 0.25 (46.4 examples/sec; 0.172 sec/batch; 15h:27m:54s remains)
INFO - root - 2017-12-01 03:00:12.553803: step 9260, loss = 0.64, batch loss = 0.38 (51.5 examples/sec; 0.155 sec/batch; 13h:56m:49s remains)
INFO - root - 2017-12-01 03:00:14.151190: step 9270, loss = 0.60, batch loss = 0.34 (50.6 examples/sec; 0.158 sec/batch; 14h:11m:20s remains)
INFO - root - 2017-12-01 03:00:15.719660: step 9280, loss = 0.58, batch loss = 0.31 (52.6 examples/sec; 0.152 sec/batch; 13h:39m:17s remains)
INFO - root - 2017-12-01 03:00:17.287735: step 9290, loss = 0.51, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 14h:01m:40s remains)
INFO - root - 2017-12-01 03:00:18.897517: step 9300, loss = 0.69, batch loss = 0.43 (50.5 examples/sec; 0.158 sec/batch; 14h:13m:27s remains)
INFO - root - 2017-12-01 03:00:20.577246: step 9310, loss = 0.56, batch loss = 0.29 (51.4 examples/sec; 0.156 sec/batch; 13h:58m:40s remains)
INFO - root - 2017-12-01 03:00:22.144850: step 9320, loss = 0.60, batch loss = 0.34 (50.0 examples/sec; 0.160 sec/batch; 14h:22m:02s remains)
INFO - root - 2017-12-01 03:00:23.728072: step 9330, loss = 0.48, batch loss = 0.22 (51.8 examples/sec; 0.155 sec/batch; 13h:52m:10s remains)
INFO - root - 2017-12-01 03:00:25.292687: step 9340, loss = 0.48, batch loss = 0.21 (50.0 examples/sec; 0.160 sec/batch; 14h:21m:37s remains)
INFO - root - 2017-12-01 03:00:26.861793: step 9350, loss = 0.69, batch loss = 0.43 (51.1 examples/sec; 0.156 sec/batch; 14h:02m:45s remains)
INFO - root - 2017-12-01 03:00:28.416214: step 9360, loss = 0.53, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 14h:00m:13s remains)
INFO - root - 2017-12-01 03:00:29.984702: step 9370, loss = 0.48, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 13h:55m:23s remains)
INFO - root - 2017-12-01 03:00:31.535263: step 9380, loss = 0.66, batch loss = 0.39 (51.7 examples/sec; 0.155 sec/batch; 13h:53m:44s remains)
INFO - root - 2017-12-01 03:00:33.114298: step 9390, loss = 0.56, batch loss = 0.29 (51.7 examples/sec; 0.155 sec/batch; 13h:52m:59s remains)
INFO - root - 2017-12-01 03:00:34.665697: step 9400, loss = 0.69, batch loss = 0.43 (51.0 examples/sec; 0.157 sec/batch; 14h:05m:07s remains)
INFO - root - 2017-12-01 03:00:36.300993: step 9410, loss = 0.60, batch loss = 0.34 (51.6 examples/sec; 0.155 sec/batch; 13h:55m:16s remains)
INFO - root - 2017-12-01 03:00:37.851598: step 9420, loss = 0.68, batch loss = 0.42 (51.4 examples/sec; 0.156 sec/batch; 13h:57m:33s remains)
INFO - root - 2017-12-01 03:00:39.407732: step 9430, loss = 0.57, batch loss = 0.30 (51.8 examples/sec; 0.154 sec/batch; 13h:51m:43s remains)
INFO - root - 2017-12-01 03:00:40.981190: step 9440, loss = 0.61, batch loss = 0.35 (49.4 examples/sec; 0.162 sec/batch; 14h:31m:28s remains)
INFO - root - 2017-12-01 03:00:42.547950: step 9450, loss = 0.71, batch loss = 0.45 (50.8 examples/sec; 0.158 sec/batch; 14h:08m:12s remains)
INFO - root - 2017-12-01 03:00:44.159239: step 9460, loss = 0.52, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 14h:05m:36s remains)
INFO - root - 2017-12-01 03:00:45.719515: step 9470, loss = 0.65, batch loss = 0.39 (51.2 examples/sec; 0.156 sec/batch; 14h:01m:28s remains)
INFO - root - 2017-12-01 03:00:47.280747: step 9480, loss = 0.64, batch loss = 0.38 (50.3 examples/sec; 0.159 sec/batch; 14h:16m:22s remains)
INFO - root - 2017-12-01 03:00:48.837039: step 9490, loss = 0.73, batch loss = 0.46 (50.4 examples/sec; 0.159 sec/batch; 14h:14m:00s remains)
INFO - root - 2017-12-01 03:00:50.401833: step 9500, loss = 0.58, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 13h:54m:19s remains)
INFO - root - 2017-12-01 03:00:52.026410: step 9510, loss = 0.56, batch loss = 0.30 (51.0 examples/sec; 0.157 sec/batch; 14h:03m:47s remains)
INFO - root - 2017-12-01 03:00:53.578492: step 9520, loss = 0.53, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 13h:48m:44s remains)
INFO - root - 2017-12-01 03:00:55.126314: step 9530, loss = 0.59, batch loss = 0.33 (51.4 examples/sec; 0.156 sec/batch; 13h:57m:19s remains)
INFO - root - 2017-12-01 03:00:56.679699: step 9540, loss = 0.66, batch loss = 0.39 (50.9 examples/sec; 0.157 sec/batch; 14h:05m:27s remains)
INFO - root - 2017-12-01 03:00:58.228728: step 9550, loss = 0.68, batch loss = 0.41 (50.0 examples/sec; 0.160 sec/batch; 14h:20m:42s remains)
INFO - root - 2017-12-01 03:00:59.791947: step 9560, loss = 0.49, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 13h:55m:48s remains)
INFO - root - 2017-12-01 03:01:01.386479: step 9570, loss = 0.61, batch loss = 0.35 (49.9 examples/sec; 0.160 sec/batch; 14h:22m:21s remains)
INFO - root - 2017-12-01 03:01:02.971595: step 9580, loss = 0.60, batch loss = 0.34 (48.5 examples/sec; 0.165 sec/batch; 14h:48m:38s remains)
INFO - root - 2017-12-01 03:01:04.559777: step 9590, loss = 0.54, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 13h:53m:31s remains)
INFO - root - 2017-12-01 03:01:06.151746: step 9600, loss = 0.67, batch loss = 0.41 (51.4 examples/sec; 0.156 sec/batch; 13h:57m:06s remains)
INFO - root - 2017-12-01 03:01:07.806394: step 9610, loss = 0.63, batch loss = 0.37 (51.6 examples/sec; 0.155 sec/batch; 13h:54m:05s remains)
INFO - root - 2017-12-01 03:01:09.372632: step 9620, loss = 0.56, batch loss = 0.30 (49.9 examples/sec; 0.160 sec/batch; 14h:23m:06s remains)
INFO - root - 2017-12-01 03:01:10.939435: step 9630, loss = 0.58, batch loss = 0.32 (48.6 examples/sec; 0.165 sec/batch; 14h:45m:32s remains)
INFO - root - 2017-12-01 03:01:12.557221: step 9640, loss = 0.58, batch loss = 0.31 (51.1 examples/sec; 0.157 sec/batch; 14h:03m:00s remains)
INFO - root - 2017-12-01 03:01:14.134535: step 9650, loss = 0.45, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 13h:59m:05s remains)
INFO - root - 2017-12-01 03:01:15.709010: step 9660, loss = 0.61, batch loss = 0.35 (51.4 examples/sec; 0.156 sec/batch; 13h:57m:00s remains)
INFO - root - 2017-12-01 03:01:17.282278: step 9670, loss = 0.62, batch loss = 0.36 (52.3 examples/sec; 0.153 sec/batch; 13h:42m:23s remains)
INFO - root - 2017-12-01 03:01:18.872868: step 9680, loss = 0.44, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 14h:07m:58s remains)
INFO - root - 2017-12-01 03:01:20.433597: step 9690, loss = 0.56, batch loss = 0.30 (51.3 examples/sec; 0.156 sec/batch; 13h:58m:22s remains)
INFO - root - 2017-12-01 03:01:22.001616: step 9700, loss = 0.68, batch loss = 0.42 (50.4 examples/sec; 0.159 sec/batch; 14h:14m:13s remains)
INFO - root - 2017-12-01 03:01:23.631030: step 9710, loss = 0.60, batch loss = 0.33 (52.7 examples/sec; 0.152 sec/batch; 13h:36m:58s remains)
INFO - root - 2017-12-01 03:01:25.209783: step 9720, loss = 0.61, batch loss = 0.35 (50.2 examples/sec; 0.159 sec/batch; 14h:16m:53s remains)
INFO - root - 2017-12-01 03:01:26.811874: step 9730, loss = 0.66, batch loss = 0.40 (51.4 examples/sec; 0.156 sec/batch; 13h:57m:58s remains)
INFO - root - 2017-12-01 03:01:28.388973: step 9740, loss = 0.64, batch loss = 0.38 (49.5 examples/sec; 0.162 sec/batch; 14h:29m:42s remains)
INFO - root - 2017-12-01 03:01:29.950372: step 9750, loss = 0.82, batch loss = 0.56 (50.4 examples/sec; 0.159 sec/batch; 14h:13m:02s remains)
INFO - root - 2017-12-01 03:01:31.512742: step 9760, loss = 0.49, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 14h:16m:31s remains)
INFO - root - 2017-12-01 03:01:33.079302: step 9770, loss = 0.58, batch loss = 0.32 (51.7 examples/sec; 0.155 sec/batch; 13h:53m:00s remains)
INFO - root - 2017-12-01 03:01:34.658522: step 9780, loss = 0.55, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 14h:00m:27s remains)
INFO - root - 2017-12-01 03:01:36.215436: step 9790, loss = 0.63, batch loss = 0.36 (51.9 examples/sec; 0.154 sec/batch; 13h:49m:11s remains)
INFO - root - 2017-12-01 03:01:37.784332: step 9800, loss = 0.55, batch loss = 0.29 (52.0 examples/sec; 0.154 sec/batch; 13h:47m:55s remains)
INFO - root - 2017-12-01 03:01:39.432858: step 9810, loss = 0.53, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 14h:02m:03s remains)
INFO - root - 2017-12-01 03:01:40.992476: step 9820, loss = 0.56, batch loss = 0.30 (50.8 examples/sec; 0.157 sec/batch; 14h:06m:20s remains)
INFO - root - 2017-12-01 03:01:42.555544: step 9830, loss = 0.64, batch loss = 0.37 (50.3 examples/sec; 0.159 sec/batch; 14h:15m:02s remains)
INFO - root - 2017-12-01 03:01:44.125917: step 9840, loss = 0.68, batch loss = 0.42 (49.0 examples/sec; 0.163 sec/batch; 14h:38m:02s remains)
INFO - root - 2017-12-01 03:01:45.692038: step 9850, loss = 0.63, batch loss = 0.37 (52.5 examples/sec; 0.152 sec/batch; 13h:38m:38s remains)
INFO - root - 2017-12-01 03:01:47.264057: step 9860, loss = 0.55, batch loss = 0.29 (50.4 examples/sec; 0.159 sec/batch; 14h:13m:08s remains)
INFO - root - 2017-12-01 03:01:48.816925: step 9870, loss = 0.58, batch loss = 0.32 (50.3 examples/sec; 0.159 sec/batch; 14h:15m:10s remains)
INFO - root - 2017-12-01 03:01:50.379863: step 9880, loss = 0.52, batch loss = 0.26 (49.4 examples/sec; 0.162 sec/batch; 14h:29m:56s remains)
INFO - root - 2017-12-01 03:01:51.944444: step 9890, loss = 0.52, batch loss = 0.26 (50.8 examples/sec; 0.157 sec/batch; 14h:06m:39s remains)
INFO - root - 2017-12-01 03:01:53.523242: step 9900, loss = 0.64, batch loss = 0.38 (51.1 examples/sec; 0.157 sec/batch; 14h:02m:28s remains)
INFO - root - 2017-12-01 03:01:55.152031: step 9910, loss = 0.60, batch loss = 0.34 (49.6 examples/sec; 0.161 sec/batch; 14h:26m:31s remains)
INFO - root - 2017-12-01 03:01:56.723329: step 9920, loss = 0.56, batch loss = 0.30 (53.2 examples/sec; 0.150 sec/batch; 13h:28m:48s remains)
INFO - root - 2017-12-01 03:01:58.286005: step 9930, loss = 0.50, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 13h:50m:05s remains)
INFO - root - 2017-12-01 03:01:59.852760: step 9940, loss = 0.52, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 13h:54m:18s remains)
INFO - root - 2017-12-01 03:02:01.415578: step 9950, loss = 0.72, batch loss = 0.45 (52.4 examples/sec; 0.153 sec/batch; 13h:40m:30s remains)
INFO - root - 2017-12-01 03:02:02.998442: step 9960, loss = 0.52, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 13h:49m:00s remains)
INFO - root - 2017-12-01 03:02:04.586374: step 9970, loss = 0.72, batch loss = 0.46 (51.0 examples/sec; 0.157 sec/batch; 14h:03m:06s remains)
INFO - root - 2017-12-01 03:02:06.149663: step 9980, loss = 0.55, batch loss = 0.29 (49.4 examples/sec; 0.162 sec/batch; 14h:30m:46s remains)
INFO - root - 2017-12-01 03:02:07.728572: step 9990, loss = 0.55, batch loss = 0.29 (50.6 examples/sec; 0.158 sec/batch; 14h:10m:11s remains)
INFO - root - 2017-12-01 03:02:09.312658: step 10000, loss = 0.51, batch loss = 0.25 (51.1 examples/sec; 0.156 sec/batch; 14h:00m:52s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-10000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-10000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-01 03:02:11.314325: step 10010, loss = 0.57, batch loss = 0.31 (52.8 examples/sec; 0.151 sec/batch; 13h:33m:53s remains)
INFO - root - 2017-12-01 03:02:12.895416: step 10020, loss = 0.64, batch loss = 0.38 (51.1 examples/sec; 0.157 sec/batch; 14h:01m:51s remains)
INFO - root - 2017-12-01 03:02:14.561749: step 10030, loss = 0.56, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 13h:55m:47s remains)
INFO - root - 2017-12-01 03:02:16.122817: step 10040, loss = 0.58, batch loss = 0.31 (50.8 examples/sec; 0.158 sec/batch; 14h:06m:58s remains)
INFO - root - 2017-12-01 03:02:17.685866: step 10050, loss = 0.62, batch loss = 0.36 (50.5 examples/sec; 0.158 sec/batch; 14h:10m:32s remains)
INFO - root - 2017-12-01 03:02:19.243623: step 10060, loss = 0.51, batch loss = 0.25 (49.2 examples/sec; 0.163 sec/batch; 14h:33m:41s remains)
INFO - root - 2017-12-01 03:02:20.825704: step 10070, loss = 0.57, batch loss = 0.31 (47.8 examples/sec; 0.167 sec/batch; 14h:58m:40s remains)
INFO - root - 2017-12-01 03:02:22.415120: step 10080, loss = 0.87, batch loss = 0.61 (51.9 examples/sec; 0.154 sec/batch; 13h:47m:53s remains)
INFO - root - 2017-12-01 03:02:24.033000: step 10090, loss = 0.53, batch loss = 0.27 (48.8 examples/sec; 0.164 sec/batch; 14h:41m:04s remains)
INFO - root - 2017-12-01 03:02:25.606181: step 10100, loss = 0.53, batch loss = 0.27 (51.7 examples/sec; 0.155 sec/batch; 13h:50m:44s remains)
INFO - root - 2017-12-01 03:02:27.207927: step 10110, loss = 0.48, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 14h:16m:32s remains)
INFO - root - 2017-12-01 03:02:28.763612: step 10120, loss = 0.56, batch loss = 0.30 (50.8 examples/sec; 0.157 sec/batch; 14h:05m:27s remains)
INFO - root - 2017-12-01 03:02:30.330002: step 10130, loss = 0.54, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 13h:48m:52s remains)
INFO - root - 2017-12-01 03:02:31.909249: step 10140, loss = 0.64, batch loss = 0.38 (50.7 examples/sec; 0.158 sec/batch; 14h:07m:02s remains)
INFO - root - 2017-12-01 03:02:33.475873: step 10150, loss = 0.60, batch loss = 0.34 (51.1 examples/sec; 0.157 sec/batch; 14h:01m:40s remains)
INFO - root - 2017-12-01 03:02:35.043348: step 10160, loss = 0.49, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 13h:57m:33s remains)
INFO - root - 2017-12-01 03:02:36.593104: step 10170, loss = 0.60, batch loss = 0.34 (50.6 examples/sec; 0.158 sec/batch; 14h:08m:47s remains)
INFO - root - 2017-12-01 03:02:38.146899: step 10180, loss = 0.63, batch loss = 0.36 (51.4 examples/sec; 0.156 sec/batch; 13h:56m:10s remains)
INFO - root - 2017-12-01 03:02:39.709218: step 10190, loss = 0.60, batch loss = 0.34 (51.4 examples/sec; 0.156 sec/batch; 13h:56m:15s remains)
INFO - root - 2017-12-01 03:02:41.299576: step 10200, loss = 0.61, batch loss = 0.35 (53.1 examples/sec; 0.151 sec/batch; 13h:28m:49s remains)
INFO - root - 2017-12-01 03:02:42.902710: step 10210, loss = 0.50, batch loss = 0.24 (47.5 examples/sec; 0.168 sec/batch; 15h:04m:28s remains)
INFO - root - 2017-12-01 03:02:44.478729: step 10220, loss = 0.62, batch loss = 0.36 (51.5 examples/sec; 0.155 sec/batch; 13h:54m:17s remains)
INFO - root - 2017-12-01 03:02:46.055219: step 10230, loss = 0.50, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 14h:11m:55s remains)
INFO - root - 2017-12-01 03:02:47.630291: step 10240, loss = 0.55, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 13h:59m:12s remains)
INFO - root - 2017-12-01 03:02:49.189366: step 10250, loss = 0.61, batch loss = 0.35 (50.4 examples/sec; 0.159 sec/batch; 14h:11m:56s remains)
INFO - root - 2017-12-01 03:02:50.745419: step 10260, loss = 0.63, batch loss = 0.37 (53.2 examples/sec; 0.150 sec/batch; 13h:27m:12s remains)
INFO - root - 2017-12-01 03:02:52.303104: step 10270, loss = 0.55, batch loss = 0.29 (51.1 examples/sec; 0.157 sec/batch; 14h:00m:50s remains)
INFO - root - 2017-12-01 03:02:53.883303: step 10280, loss = 0.60, batch loss = 0.34 (51.3 examples/sec; 0.156 sec/batch; 13h:57m:38s remains)
INFO - root - 2017-12-01 03:02:55.449160: step 10290, loss = 0.78, batch loss = 0.52 (49.1 examples/sec; 0.163 sec/batch; 14h:35m:33s remains)
INFO - root - 2017-12-01 03:02:57.011219: step 10300, loss = 0.49, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 13h:58m:59s remains)
INFO - root - 2017-12-01 03:02:58.645148: step 10310, loss = 0.65, batch loss = 0.39 (51.4 examples/sec; 0.156 sec/batch; 13h:55m:43s remains)
INFO - root - 2017-12-01 03:03:00.225161: step 10320, loss = 0.58, batch loss = 0.32 (50.2 examples/sec; 0.159 sec/batch; 14h:15m:04s remains)
INFO - root - 2017-12-01 03:03:01.792368: step 10330, loss = 0.56, batch loss = 0.30 (50.5 examples/sec; 0.158 sec/batch; 14h:10m:55s remains)
INFO - root - 2017-12-01 03:03:03.427854: step 10340, loss = 0.51, batch loss = 0.25 (46.1 examples/sec; 0.174 sec/batch; 15h:32m:37s remains)
INFO - root - 2017-12-01 03:03:04.998467: step 10350, loss = 0.63, batch loss = 0.37 (51.8 examples/sec; 0.154 sec/batch; 13h:49m:27s remains)
INFO - root - 2017-12-01 03:03:06.551502: step 10360, loss = 0.59, batch loss = 0.33 (52.4 examples/sec; 0.153 sec/batch; 13h:39m:12s remains)
INFO - root - 2017-12-01 03:03:08.126216: step 10370, loss = 0.61, batch loss = 0.35 (48.9 examples/sec; 0.164 sec/batch; 14h:38m:33s remains)
INFO - root - 2017-12-01 03:03:09.687333: step 10380, loss = 0.55, batch loss = 0.29 (49.5 examples/sec; 0.162 sec/batch; 14h:27m:04s remains)
INFO - root - 2017-12-01 03:03:11.267056: step 10390, loss = 0.54, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 13h:54m:26s remains)
INFO - root - 2017-12-01 03:03:12.860265: step 10400, loss = 0.47, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 14h:01m:41s remains)
INFO - root - 2017-12-01 03:03:14.490589: step 10410, loss = 0.59, batch loss = 0.33 (52.3 examples/sec; 0.153 sec/batch; 13h:41m:43s remains)
INFO - root - 2017-12-01 03:03:16.061301: step 10420, loss = 0.58, batch loss = 0.32 (49.3 examples/sec; 0.162 sec/batch; 14h:30m:19s remains)
INFO - root - 2017-12-01 03:03:17.648458: step 10430, loss = 0.63, batch loss = 0.37 (52.0 examples/sec; 0.154 sec/batch; 13h:46m:06s remains)
INFO - root - 2017-12-01 03:03:19.225536: step 10440, loss = 0.56, batch loss = 0.30 (51.1 examples/sec; 0.157 sec/batch; 14h:01m:02s remains)
INFO - root - 2017-12-01 03:03:20.793450: step 10450, loss = 0.54, batch loss = 0.28 (49.8 examples/sec; 0.161 sec/batch; 14h:21m:40s remains)
INFO - root - 2017-12-01 03:03:22.366141: step 10460, loss = 0.48, batch loss = 0.22 (48.3 examples/sec; 0.166 sec/batch; 14h:49m:08s remains)
INFO - root - 2017-12-01 03:03:23.966364: step 10470, loss = 0.85, batch loss = 0.59 (51.0 examples/sec; 0.157 sec/batch; 14h:01m:32s remains)
INFO - root - 2017-12-01 03:03:25.575229: step 10480, loss = 0.60, batch loss = 0.34 (50.4 examples/sec; 0.159 sec/batch; 14h:12m:27s remains)
INFO - root - 2017-12-01 03:03:27.137324: step 10490, loss = 0.68, batch loss = 0.42 (52.3 examples/sec; 0.153 sec/batch; 13h:41m:08s remains)
INFO - root - 2017-12-01 03:03:28.752851: step 10500, loss = 0.81, batch loss = 0.55 (49.1 examples/sec; 0.163 sec/batch; 14h:34m:15s remains)
INFO - root - 2017-12-01 03:03:30.372926: step 10510, loss = 0.51, batch loss = 0.25 (50.1 examples/sec; 0.160 sec/batch; 14h:16m:13s remains)
INFO - root - 2017-12-01 03:03:31.928988: step 10520, loss = 0.62, batch loss = 0.36 (51.5 examples/sec; 0.155 sec/batch; 13h:53m:05s remains)
INFO - root - 2017-12-01 03:03:33.472717: step 10530, loss = 0.67, batch loss = 0.41 (51.7 examples/sec; 0.155 sec/batch; 13h:50m:58s remains)
INFO - root - 2017-12-01 03:03:35.038634: step 10540, loss = 0.56, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 14h:02m:55s remains)
INFO - root - 2017-12-01 03:03:36.586386: step 10550, loss = 0.60, batch loss = 0.34 (51.7 examples/sec; 0.155 sec/batch; 13h:50m:01s remains)
INFO - root - 2017-12-01 03:03:38.137538: step 10560, loss = 0.55, batch loss = 0.29 (49.4 examples/sec; 0.162 sec/batch; 14h:29m:39s remains)
INFO - root - 2017-12-01 03:03:39.713718: step 10570, loss = 0.50, batch loss = 0.24 (52.7 examples/sec; 0.152 sec/batch; 13h:35m:06s remains)
INFO - root - 2017-12-01 03:03:41.287512: step 10580, loss = 0.54, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 13h:55m:43s remains)
INFO - root - 2017-12-01 03:03:42.898932: step 10590, loss = 0.60, batch loss = 0.34 (49.2 examples/sec; 0.163 sec/batch; 14h:33m:12s remains)
INFO - root - 2017-12-01 03:03:44.476995: step 10600, loss = 0.58, batch loss = 0.32 (51.5 examples/sec; 0.155 sec/batch; 13h:54m:11s remains)
INFO - root - 2017-12-01 03:03:46.124284: step 10610, loss = 0.51, batch loss = 0.25 (49.6 examples/sec; 0.161 sec/batch; 14h:25m:38s remains)
INFO - root - 2017-12-01 03:03:47.693983: step 10620, loss = 0.67, batch loss = 0.41 (52.3 examples/sec; 0.153 sec/batch; 13h:40m:49s remains)
INFO - root - 2017-12-01 03:03:49.257567: step 10630, loss = 0.58, batch loss = 0.32 (52.4 examples/sec; 0.153 sec/batch; 13h:39m:38s remains)
INFO - root - 2017-12-01 03:03:50.824914: step 10640, loss = 0.66, batch loss = 0.40 (50.7 examples/sec; 0.158 sec/batch; 14h:06m:48s remains)
INFO - root - 2017-12-01 03:03:52.385527: step 10650, loss = 0.60, batch loss = 0.34 (50.7 examples/sec; 0.158 sec/batch; 14h:05m:57s remains)
INFO - root - 2017-12-01 03:03:53.940583: step 10660, loss = 0.55, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 14h:02m:39s remains)
INFO - root - 2017-12-01 03:03:55.497423: step 10670, loss = 0.51, batch loss = 0.25 (53.2 examples/sec; 0.150 sec/batch; 13h:26m:49s remains)
INFO - root - 2017-12-01 03:03:57.052821: step 10680, loss = 0.52, batch loss = 0.26 (52.6 examples/sec; 0.152 sec/batch; 13h:35m:04s remains)
INFO - root - 2017-12-01 03:03:58.622215: step 10690, loss = 0.51, batch loss = 0.25 (52.2 examples/sec; 0.153 sec/batch; 13h:42m:37s remains)
INFO - root - 2017-12-01 03:04:00.184467: step 10700, loss = 0.56, batch loss = 0.30 (49.8 examples/sec; 0.160 sec/batch; 14h:20m:45s remains)
INFO - root - 2017-12-01 03:04:01.821869: step 10710, loss = 0.51, batch loss = 0.25 (52.1 examples/sec; 0.154 sec/batch; 13h:43m:25s remains)
INFO - root - 2017-12-01 03:04:03.411863: step 10720, loss = 0.60, batch loss = 0.34 (46.4 examples/sec; 0.172 sec/batch; 15h:24m:14s remains)
INFO - root - 2017-12-01 03:04:04.959164: step 10730, loss = 0.46, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 14h:01m:59s remains)
INFO - root - 2017-12-01 03:04:06.513421: step 10740, loss = 0.62, batch loss = 0.36 (50.1 examples/sec; 0.160 sec/batch; 14h:16m:03s remains)
INFO - root - 2017-12-01 03:04:08.076952: step 10750, loss = 0.64, batch loss = 0.38 (50.8 examples/sec; 0.157 sec/batch; 14h:03m:42s remains)
INFO - root - 2017-12-01 03:04:09.641306: step 10760, loss = 0.63, batch loss = 0.37 (51.4 examples/sec; 0.156 sec/batch; 13h:55m:24s remains)
INFO - root - 2017-12-01 03:04:11.224667: step 10770, loss = 0.58, batch loss = 0.32 (50.1 examples/sec; 0.160 sec/batch; 14h:16m:53s remains)
INFO - root - 2017-12-01 03:04:12.781469: step 10780, loss = 0.50, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 13h:47m:50s remains)
INFO - root - 2017-12-01 03:04:14.342087: step 10790, loss = 0.54, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 14h:05m:26s remains)
INFO - root - 2017-12-01 03:04:15.901330: step 10800, loss = 0.59, batch loss = 0.34 (53.1 examples/sec; 0.151 sec/batch; 13h:27m:18s remains)
INFO - root - 2017-12-01 03:04:17.570258: step 10810, loss = 0.77, batch loss = 0.51 (49.1 examples/sec; 0.163 sec/batch; 14h:34m:06s remains)
INFO - root - 2017-12-01 03:04:19.149981: step 10820, loss = 0.52, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 13h:50m:23s remains)
INFO - root - 2017-12-01 03:04:20.714036: step 10830, loss = 0.49, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 13h:46m:49s remains)
INFO - root - 2017-12-01 03:04:22.272415: step 10840, loss = 0.56, batch loss = 0.30 (52.4 examples/sec; 0.153 sec/batch; 13h:39m:07s remains)
INFO - root - 2017-12-01 03:04:23.850061: step 10850, loss = 0.67, batch loss = 0.41 (51.0 examples/sec; 0.157 sec/batch; 14h:01m:42s remains)
INFO - root - 2017-12-01 03:04:25.406625: step 10860, loss = 0.55, batch loss = 0.30 (51.7 examples/sec; 0.155 sec/batch; 13h:49m:18s remains)
INFO - root - 2017-12-01 03:04:26.945030: step 10870, loss = 0.56, batch loss = 0.30 (53.0 examples/sec; 0.151 sec/batch; 13h:29m:40s remains)
INFO - root - 2017-12-01 03:04:28.488931: step 10880, loss = 0.49, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 13h:51m:31s remains)
INFO - root - 2017-12-01 03:04:30.064206: step 10890, loss = 0.54, batch loss = 0.28 (50.2 examples/sec; 0.159 sec/batch; 14h:13m:45s remains)
INFO - root - 2017-12-01 03:04:31.646349: step 10900, loss = 0.53, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 14h:02m:43s remains)
INFO - root - 2017-12-01 03:04:33.319185: step 10910, loss = 0.59, batch loss = 0.33 (49.9 examples/sec; 0.160 sec/batch; 14h:19m:27s remains)
INFO - root - 2017-12-01 03:04:34.860344: step 10920, loss = 0.61, batch loss = 0.35 (50.0 examples/sec; 0.160 sec/batch; 14h:17m:11s remains)
INFO - root - 2017-12-01 03:04:36.407776: step 10930, loss = 0.54, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 14h:05m:50s remains)
INFO - root - 2017-12-01 03:04:37.952629: step 10940, loss = 0.65, batch loss = 0.39 (51.3 examples/sec; 0.156 sec/batch; 13h:55m:56s remains)
INFO - root - 2017-12-01 03:04:39.519601: step 10950, loss = 0.51, batch loss = 0.26 (52.8 examples/sec; 0.152 sec/batch; 13h:32m:22s remains)
INFO - root - 2017-12-01 03:04:41.085611: step 10960, loss = 0.59, batch loss = 0.33 (51.8 examples/sec; 0.155 sec/batch; 13h:48m:24s remains)
INFO - root - 2017-12-01 03:04:42.652056: step 10970, loss = 0.59, batch loss = 0.33 (51.6 examples/sec; 0.155 sec/batch; 13h:51m:32s remains)
INFO - root - 2017-12-01 03:04:44.198218: step 10980, loss = 0.58, batch loss = 0.32 (51.0 examples/sec; 0.157 sec/batch; 14h:00m:10s remains)
INFO - root - 2017-12-01 03:04:45.780404: step 10990, loss = 0.51, batch loss = 0.25 (49.6 examples/sec; 0.161 sec/batch; 14h:24m:32s remains)
INFO - root - 2017-12-01 03:04:47.345179: step 11000, loss = 0.62, batch loss = 0.36 (52.5 examples/sec; 0.152 sec/batch; 13h:37m:08s remains)
INFO - root - 2017-12-01 03:04:48.957508: step 11010, loss = 0.64, batch loss = 0.38 (51.6 examples/sec; 0.155 sec/batch; 13h:50m:21s remains)
INFO - root - 2017-12-01 03:04:50.525027: step 11020, loss = 0.55, batch loss = 0.29 (51.4 examples/sec; 0.156 sec/batch; 13h:54m:32s remains)
INFO - root - 2017-12-01 03:04:52.089374: step 11030, loss = 0.86, batch loss = 0.60 (50.9 examples/sec; 0.157 sec/batch; 14h:02m:52s remains)
INFO - root - 2017-12-01 03:04:53.645305: step 11040, loss = 0.47, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 13h:38m:58s remains)
INFO - root - 2017-12-01 03:04:55.200202: step 11050, loss = 0.60, batch loss = 0.35 (51.1 examples/sec; 0.157 sec/batch; 13h:58m:58s remains)
INFO - root - 2017-12-01 03:04:56.750705: step 11060, loss = 0.49, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 13h:45m:30s remains)
INFO - root - 2017-12-01 03:04:58.306627: step 11070, loss = 0.54, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 14h:01m:41s remains)
INFO - root - 2017-12-01 03:04:59.875602: step 11080, loss = 0.53, batch loss = 0.27 (48.0 examples/sec; 0.167 sec/batch; 14h:51m:59s remains)
INFO - root - 2017-12-01 03:05:01.435771: step 11090, loss = 0.59, batch loss = 0.33 (51.8 examples/sec; 0.154 sec/batch; 13h:46m:44s remains)
INFO - root - 2017-12-01 03:05:03.005594: step 11100, loss = 0.61, batch loss = 0.35 (50.5 examples/sec; 0.158 sec/batch; 14h:08m:07s remains)
INFO - root - 2017-12-01 03:05:04.649053: step 11110, loss = 0.51, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 13h:57m:39s remains)
INFO - root - 2017-12-01 03:05:06.213857: step 11120, loss = 0.51, batch loss = 0.25 (53.1 examples/sec; 0.151 sec/batch; 13h:26m:35s remains)
INFO - root - 2017-12-01 03:05:07.776648: step 11130, loss = 0.60, batch loss = 0.34 (51.1 examples/sec; 0.157 sec/batch; 13h:58m:38s remains)
INFO - root - 2017-12-01 03:05:09.339929: step 11140, loss = 0.55, batch loss = 0.29 (51.1 examples/sec; 0.157 sec/batch; 13h:58m:27s remains)
INFO - root - 2017-12-01 03:05:10.923695: step 11150, loss = 0.63, batch loss = 0.38 (48.3 examples/sec; 0.166 sec/batch; 14h:46m:31s remains)
INFO - root - 2017-12-01 03:05:12.485238: step 11160, loss = 0.61, batch loss = 0.35 (49.5 examples/sec; 0.162 sec/batch; 14h:25m:18s remains)
INFO - root - 2017-12-01 03:05:14.066795: step 11170, loss = 0.51, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 13h:39m:02s remains)
INFO - root - 2017-12-01 03:05:15.627948: step 11180, loss = 0.70, batch loss = 0.44 (50.8 examples/sec; 0.157 sec/batch; 14h:02m:39s remains)
INFO - root - 2017-12-01 03:05:17.186913: step 11190, loss = 0.61, batch loss = 0.35 (50.3 examples/sec; 0.159 sec/batch; 14h:12m:16s remains)
INFO - root - 2017-12-01 03:05:18.750310: step 11200, loss = 0.51, batch loss = 0.25 (52.1 examples/sec; 0.153 sec/batch; 13h:41m:30s remains)
INFO - root - 2017-12-01 03:05:20.364561: step 11210, loss = 0.69, batch loss = 0.43 (52.2 examples/sec; 0.153 sec/batch; 13h:41m:18s remains)
INFO - root - 2017-12-01 03:05:21.915378: step 11220, loss = 0.57, batch loss = 0.31 (52.1 examples/sec; 0.154 sec/batch; 13h:42m:58s remains)
INFO - root - 2017-12-01 03:05:23.463106: step 11230, loss = 0.61, batch loss = 0.36 (52.1 examples/sec; 0.154 sec/batch; 13h:42m:22s remains)
INFO - root - 2017-12-01 03:05:25.023622: step 11240, loss = 0.59, batch loss = 0.33 (50.9 examples/sec; 0.157 sec/batch; 14h:01m:52s remains)
INFO - root - 2017-12-01 03:05:26.595274: step 11250, loss = 0.48, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 13h:59m:19s remains)
INFO - root - 2017-12-01 03:05:28.149362: step 11260, loss = 0.51, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 14h:05m:10s remains)
INFO - root - 2017-12-01 03:05:29.697156: step 11270, loss = 0.50, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 13h:58m:43s remains)
INFO - root - 2017-12-01 03:05:31.272830: step 11280, loss = 0.49, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 14h:03m:25s remains)
INFO - root - 2017-12-01 03:05:32.844345: step 11290, loss = 0.51, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 13h:53m:38s remains)
INFO - root - 2017-12-01 03:05:34.391157: step 11300, loss = 0.51, batch loss = 0.25 (52.0 examples/sec; 0.154 sec/batch; 13h:44m:08s remains)
INFO - root - 2017-12-01 03:05:35.997775: step 11310, loss = 0.56, batch loss = 0.30 (52.6 examples/sec; 0.152 sec/batch; 13h:34m:05s remains)
INFO - root - 2017-12-01 03:05:37.698547: step 11320, loss = 0.58, batch loss = 0.32 (51.0 examples/sec; 0.157 sec/batch; 14h:00m:16s remains)
INFO - root - 2017-12-01 03:05:39.253467: step 11330, loss = 0.67, batch loss = 0.41 (52.3 examples/sec; 0.153 sec/batch; 13h:38m:32s remains)
INFO - root - 2017-12-01 03:05:40.819786: step 11340, loss = 0.75, batch loss = 0.49 (51.0 examples/sec; 0.157 sec/batch; 14h:00m:27s remains)
INFO - root - 2017-12-01 03:05:42.399555: step 11350, loss = 0.58, batch loss = 0.32 (51.9 examples/sec; 0.154 sec/batch; 13h:45m:36s remains)
INFO - root - 2017-12-01 03:05:43.958854: step 11360, loss = 0.52, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 13h:56m:58s remains)
INFO - root - 2017-12-01 03:05:45.539726: step 11370, loss = 0.57, batch loss = 0.32 (51.4 examples/sec; 0.156 sec/batch; 13h:53m:30s remains)
INFO - root - 2017-12-01 03:05:47.090958: step 11380, loss = 0.73, batch loss = 0.48 (50.7 examples/sec; 0.158 sec/batch; 14h:04m:59s remains)
INFO - root - 2017-12-01 03:05:48.652737: step 11390, loss = 0.72, batch loss = 0.46 (50.6 examples/sec; 0.158 sec/batch; 14h:05m:46s remains)
INFO - root - 2017-12-01 03:05:50.210654: step 11400, loss = 0.53, batch loss = 0.27 (51.9 examples/sec; 0.154 sec/batch; 13h:45m:20s remains)
INFO - root - 2017-12-01 03:05:51.861465: step 11410, loss = 0.50, batch loss = 0.25 (51.1 examples/sec; 0.156 sec/batch; 13h:57m:08s remains)
INFO - root - 2017-12-01 03:05:53.422167: step 11420, loss = 0.54, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 14h:10m:39s remains)
INFO - root - 2017-12-01 03:05:55.005384: step 11430, loss = 0.55, batch loss = 0.30 (48.3 examples/sec; 0.166 sec/batch; 14h:45m:51s remains)
INFO - root - 2017-12-01 03:05:56.612619: step 11440, loss = 0.53, batch loss = 0.28 (52.0 examples/sec; 0.154 sec/batch; 13h:43m:44s remains)
INFO - root - 2017-12-01 03:05:58.159202: step 11450, loss = 0.61, batch loss = 0.35 (51.3 examples/sec; 0.156 sec/batch; 13h:54m:46s remains)
INFO - root - 2017-12-01 03:05:59.729181: step 11460, loss = 0.58, batch loss = 0.32 (51.2 examples/sec; 0.156 sec/batch; 13h:56m:41s remains)
INFO - root - 2017-12-01 03:06:01.285411: step 11470, loss = 0.48, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 13h:45m:24s remains)
INFO - root - 2017-12-01 03:06:02.851337: step 11480, loss = 0.47, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 13h:52m:03s remains)
INFO - root - 2017-12-01 03:06:04.420202: step 11490, loss = 0.49, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 14h:00m:50s remains)
INFO - root - 2017-12-01 03:06:05.998575: step 11500, loss = 0.57, batch loss = 0.32 (51.2 examples/sec; 0.156 sec/batch; 13h:55m:24s remains)
INFO - root - 2017-12-01 03:06:07.638443: step 11510, loss = 0.50, batch loss = 0.24 (49.6 examples/sec; 0.161 sec/batch; 14h:22m:22s remains)
INFO - root - 2017-12-01 03:06:09.200482: step 11520, loss = 0.58, batch loss = 0.32 (50.8 examples/sec; 0.158 sec/batch; 14h:02m:35s remains)
INFO - root - 2017-12-01 03:06:10.769726: step 11530, loss = 0.66, batch loss = 0.40 (51.3 examples/sec; 0.156 sec/batch; 13h:54m:00s remains)
INFO - root - 2017-12-01 03:06:12.323527: step 11540, loss = 0.54, batch loss = 0.28 (52.1 examples/sec; 0.154 sec/batch; 13h:42m:10s remains)
INFO - root - 2017-12-01 03:06:13.884186: step 11550, loss = 0.53, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 13h:45m:19s remains)
INFO - root - 2017-12-01 03:06:15.456403: step 11560, loss = 0.58, batch loss = 0.32 (51.2 examples/sec; 0.156 sec/batch; 13h:56m:24s remains)
INFO - root - 2017-12-01 03:06:17.019753: step 11570, loss = 0.49, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 14h:00m:23s remains)
INFO - root - 2017-12-01 03:06:18.592201: step 11580, loss = 0.59, batch loss = 0.33 (50.8 examples/sec; 0.157 sec/batch; 14h:01m:58s remains)
INFO - root - 2017-12-01 03:06:20.151113: step 11590, loss = 0.57, batch loss = 0.31 (53.4 examples/sec; 0.150 sec/batch; 13h:21m:53s remains)
INFO - root - 2017-12-01 03:06:21.728285: step 11600, loss = 0.56, batch loss = 0.30 (51.9 examples/sec; 0.154 sec/batch; 13h:44m:44s remains)
INFO - root - 2017-12-01 03:06:23.358627: step 11610, loss = 0.49, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 13h:49m:45s remains)
INFO - root - 2017-12-01 03:06:24.921003: step 11620, loss = 0.53, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 14h:05m:14s remains)
INFO - root - 2017-12-01 03:06:26.483298: step 11630, loss = 0.55, batch loss = 0.29 (52.3 examples/sec; 0.153 sec/batch; 13h:37m:27s remains)
INFO - root - 2017-12-01 03:06:28.036255: step 11640, loss = 0.55, batch loss = 0.30 (52.6 examples/sec; 0.152 sec/batch; 13h:33m:06s remains)
INFO - root - 2017-12-01 03:06:29.582731: step 11650, loss = 0.59, batch loss = 0.33 (51.7 examples/sec; 0.155 sec/batch; 13h:47m:28s remains)
INFO - root - 2017-12-01 03:06:31.139249: step 11660, loss = 0.55, batch loss = 0.29 (50.5 examples/sec; 0.158 sec/batch; 14h:06m:24s remains)
INFO - root - 2017-12-01 03:06:32.682374: step 11670, loss = 0.69, batch loss = 0.44 (48.8 examples/sec; 0.164 sec/batch; 14h:35m:41s remains)
INFO - root - 2017-12-01 03:06:34.246129: step 11680, loss = 0.54, batch loss = 0.28 (53.0 examples/sec; 0.151 sec/batch; 13h:27m:37s remains)
INFO - root - 2017-12-01 03:06:35.806238: step 11690, loss = 0.50, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 13h:47m:57s remains)
INFO - root - 2017-12-01 03:06:37.380792: step 11700, loss = 0.61, batch loss = 0.35 (50.7 examples/sec; 0.158 sec/batch; 14h:04m:05s remains)
INFO - root - 2017-12-01 03:06:39.010286: step 11710, loss = 0.55, batch loss = 0.30 (49.3 examples/sec; 0.162 sec/batch; 14h:26m:53s remains)
INFO - root - 2017-12-01 03:06:40.577687: step 11720, loss = 0.62, batch loss = 0.36 (49.6 examples/sec; 0.161 sec/batch; 14h:22m:26s remains)
INFO - root - 2017-12-01 03:06:42.146340: step 11730, loss = 0.52, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 13h:59m:02s remains)
INFO - root - 2017-12-01 03:06:43.718099: step 11740, loss = 0.57, batch loss = 0.31 (51.1 examples/sec; 0.156 sec/batch; 13h:56m:12s remains)
INFO - root - 2017-12-01 03:06:45.273510: step 11750, loss = 0.54, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 14h:11m:02s remains)
INFO - root - 2017-12-01 03:06:46.847821: step 11760, loss = 0.58, batch loss = 0.32 (52.9 examples/sec; 0.151 sec/batch; 13h:27m:46s remains)
INFO - root - 2017-12-01 03:06:48.405707: step 11770, loss = 0.58, batch loss = 0.32 (50.9 examples/sec; 0.157 sec/batch; 14h:00m:04s remains)
INFO - root - 2017-12-01 03:06:49.985063: step 11780, loss = 0.58, batch loss = 0.33 (51.4 examples/sec; 0.156 sec/batch; 13h:51m:39s remains)
INFO - root - 2017-12-01 03:06:51.531584: step 11790, loss = 0.55, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 13h:49m:55s remains)
INFO - root - 2017-12-01 03:06:53.090490: step 11800, loss = 0.53, batch loss = 0.28 (51.1 examples/sec; 0.157 sec/batch; 13h:57m:02s remains)
INFO - root - 2017-12-01 03:06:54.717483: step 11810, loss = 0.56, batch loss = 0.30 (52.0 examples/sec; 0.154 sec/batch; 13h:42m:05s remains)
INFO - root - 2017-12-01 03:06:56.299776: step 11820, loss = 0.54, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 14h:06m:12s remains)
INFO - root - 2017-12-01 03:06:57.856521: step 11830, loss = 0.51, batch loss = 0.26 (53.1 examples/sec; 0.151 sec/batch; 13h:25m:08s remains)
INFO - root - 2017-12-01 03:06:59.416955: step 11840, loss = 0.66, batch loss = 0.40 (52.4 examples/sec; 0.153 sec/batch; 13h:35m:35s remains)
INFO - root - 2017-12-01 03:07:00.998729: step 11850, loss = 0.63, batch loss = 0.37 (50.8 examples/sec; 0.157 sec/batch; 14h:01m:08s remains)
INFO - root - 2017-12-01 03:07:02.565961: step 11860, loss = 0.44, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 13h:53m:48s remains)
INFO - root - 2017-12-01 03:07:04.127489: step 11870, loss = 0.65, batch loss = 0.39 (51.5 examples/sec; 0.155 sec/batch; 13h:49m:20s remains)
INFO - root - 2017-12-01 03:07:05.691143: step 11880, loss = 0.47, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 13h:55m:30s remains)
INFO - root - 2017-12-01 03:07:07.271651: step 11890, loss = 0.54, batch loss = 0.28 (51.1 examples/sec; 0.157 sec/batch; 13h:56m:52s remains)
INFO - root - 2017-12-01 03:07:08.829753: step 11900, loss = 0.53, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 13h:42m:00s remains)
INFO - root - 2017-12-01 03:07:10.443411: step 11910, loss = 0.64, batch loss = 0.38 (51.8 examples/sec; 0.154 sec/batch; 13h:44m:49s remains)
INFO - root - 2017-12-01 03:07:11.989869: step 11920, loss = 0.55, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 13h:51m:47s remains)
INFO - root - 2017-12-01 03:07:13.565213: step 11930, loss = 0.55, batch loss = 0.30 (50.8 examples/sec; 0.157 sec/batch; 14h:01m:24s remains)
INFO - root - 2017-12-01 03:07:15.155112: step 11940, loss = 0.50, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 13h:52m:11s remains)
INFO - root - 2017-12-01 03:07:16.715666: step 11950, loss = 0.69, batch loss = 0.44 (52.8 examples/sec; 0.151 sec/batch; 13h:29m:10s remains)
INFO - root - 2017-12-01 03:07:18.276488: step 11960, loss = 0.50, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 14h:00m:25s remains)
INFO - root - 2017-12-01 03:07:19.849781: step 11970, loss = 0.54, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 13h:53m:01s remains)
INFO - root - 2017-12-01 03:07:21.441107: step 11980, loss = 0.61, batch loss = 0.36 (49.3 examples/sec; 0.162 sec/batch; 14h:26m:07s remains)
INFO - root - 2017-12-01 03:07:23.022994: step 11990, loss = 0.55, batch loss = 0.29 (50.8 examples/sec; 0.157 sec/batch; 14h:01m:01s remains)
INFO - root - 2017-12-01 03:07:24.600226: step 12000, loss = 0.68, batch loss = 0.43 (50.4 examples/sec; 0.159 sec/batch; 14h:07m:26s remains)
INFO - root - 2017-12-01 03:07:26.206494: step 12010, loss = 0.55, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 13h:59m:09s remains)
INFO - root - 2017-12-01 03:07:27.790300: step 12020, loss = 0.63, batch loss = 0.38 (50.9 examples/sec; 0.157 sec/batch; 14h:00m:02s remains)
INFO - root - 2017-12-01 03:07:29.352767: step 12030, loss = 0.72, batch loss = 0.46 (51.2 examples/sec; 0.156 sec/batch; 13h:54m:50s remains)
INFO - root - 2017-12-01 03:07:30.900428: step 12040, loss = 0.58, batch loss = 0.32 (52.1 examples/sec; 0.154 sec/batch; 13h:40m:34s remains)
INFO - root - 2017-12-01 03:07:32.472368: step 12050, loss = 0.54, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 13h:53m:58s remains)
INFO - root - 2017-12-01 03:07:34.017497: step 12060, loss = 0.59, batch loss = 0.33 (51.4 examples/sec; 0.156 sec/batch; 13h:50m:32s remains)
INFO - root - 2017-12-01 03:07:35.582160: step 12070, loss = 0.56, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 13h:50m:52s remains)
INFO - root - 2017-12-01 03:07:37.153110: step 12080, loss = 0.51, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 13h:51m:32s remains)
INFO - root - 2017-12-01 03:07:38.740539: step 12090, loss = 0.51, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 13h:56m:53s remains)
INFO - root - 2017-12-01 03:07:40.366941: step 12100, loss = 0.60, batch loss = 0.34 (50.4 examples/sec; 0.159 sec/batch; 14h:07m:09s remains)
INFO - root - 2017-12-01 03:07:41.987154: step 12110, loss = 0.69, batch loss = 0.44 (51.6 examples/sec; 0.155 sec/batch; 13h:48m:16s remains)
INFO - root - 2017-12-01 03:07:43.537535: step 12120, loss = 0.54, batch loss = 0.28 (51.1 examples/sec; 0.156 sec/batch; 13h:55m:28s remains)
INFO - root - 2017-12-01 03:07:45.189591: step 12130, loss = 0.63, batch loss = 0.37 (50.5 examples/sec; 0.158 sec/batch; 14h:06m:18s remains)
INFO - root - 2017-12-01 03:07:46.762693: step 12140, loss = 0.50, batch loss = 0.25 (50.8 examples/sec; 0.158 sec/batch; 14h:01m:38s remains)
INFO - root - 2017-12-01 03:07:48.312289: step 12150, loss = 0.50, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 13h:42m:28s remains)
INFO - root - 2017-12-01 03:07:49.860759: step 12160, loss = 0.69, batch loss = 0.44 (52.7 examples/sec; 0.152 sec/batch; 13h:30m:50s remains)
INFO - root - 2017-12-01 03:07:51.423375: step 12170, loss = 0.53, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 13h:45m:27s remains)
INFO - root - 2017-12-01 03:07:52.987750: step 12180, loss = 0.56, batch loss = 0.30 (52.1 examples/sec; 0.154 sec/batch; 13h:40m:03s remains)
INFO - root - 2017-12-01 03:07:54.562173: step 12190, loss = 0.46, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 14h:05m:59s remains)
INFO - root - 2017-12-01 03:07:56.140770: step 12200, loss = 0.55, batch loss = 0.29 (49.2 examples/sec; 0.163 sec/batch; 14h:27m:41s remains)
INFO - root - 2017-12-01 03:07:57.809388: step 12210, loss = 0.55, batch loss = 0.29 (51.7 examples/sec; 0.155 sec/batch; 13h:46m:06s remains)
INFO - root - 2017-12-01 03:07:59.358372: step 12220, loss = 0.52, batch loss = 0.27 (52.6 examples/sec; 0.152 sec/batch; 13h:31m:24s remains)
INFO - root - 2017-12-01 03:08:00.908576: step 12230, loss = 0.53, batch loss = 0.27 (52.4 examples/sec; 0.153 sec/batch; 13h:35m:28s remains)
INFO - root - 2017-12-01 03:08:02.466653: step 12240, loss = 0.66, batch loss = 0.40 (51.5 examples/sec; 0.155 sec/batch; 13h:49m:56s remains)
INFO - root - 2017-12-01 03:08:04.027837: step 12250, loss = 0.53, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 13h:42m:46s remains)
INFO - root - 2017-12-01 03:08:05.600896: step 12260, loss = 0.56, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 13h:56m:47s remains)
INFO - root - 2017-12-01 03:08:07.185621: step 12270, loss = 0.47, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 14h:00m:33s remains)
INFO - root - 2017-12-01 03:08:08.816510: step 12280, loss = 0.52, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 13h:51m:15s remains)
INFO - root - 2017-12-01 03:08:10.374436: step 12290, loss = 0.62, batch loss = 0.37 (51.2 examples/sec; 0.156 sec/batch; 13h:54m:35s remains)
INFO - root - 2017-12-01 03:08:11.957730: step 12300, loss = 0.50, batch loss = 0.25 (49.4 examples/sec; 0.162 sec/batch; 14h:24m:34s remains)
INFO - root - 2017-12-01 03:08:13.581604: step 12310, loss = 0.52, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 13h:42m:52s remains)
INFO - root - 2017-12-01 03:08:15.190895: step 12320, loss = 0.55, batch loss = 0.29 (48.8 examples/sec; 0.164 sec/batch; 14h:35m:00s remains)
INFO - root - 2017-12-01 03:08:16.753077: step 12330, loss = 0.61, batch loss = 0.35 (51.3 examples/sec; 0.156 sec/batch; 13h:51m:49s remains)
INFO - root - 2017-12-01 03:08:18.366461: step 12340, loss = 0.54, batch loss = 0.29 (52.3 examples/sec; 0.153 sec/batch; 13h:36m:40s remains)
INFO - root - 2017-12-01 03:08:19.923886: step 12350, loss = 0.54, batch loss = 0.28 (49.3 examples/sec; 0.162 sec/batch; 14h:25m:00s remains)
INFO - root - 2017-12-01 03:08:21.487517: step 12360, loss = 0.50, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 14h:01m:32s remains)
INFO - root - 2017-12-01 03:08:23.060086: step 12370, loss = 0.69, batch loss = 0.43 (52.0 examples/sec; 0.154 sec/batch; 13h:40m:19s remains)
INFO - root - 2017-12-01 03:08:24.613224: step 12380, loss = 0.59, batch loss = 0.33 (52.5 examples/sec; 0.152 sec/batch; 13h:32m:15s remains)
INFO - root - 2017-12-01 03:08:26.234007: step 12390, loss = 0.56, batch loss = 0.30 (46.3 examples/sec; 0.173 sec/batch; 15h:20m:51s remains)
INFO - root - 2017-12-01 03:08:27.849768: step 12400, loss = 0.59, batch loss = 0.33 (50.8 examples/sec; 0.158 sec/batch; 14h:00m:33s remains)
INFO - root - 2017-12-01 03:08:29.499073: step 12410, loss = 0.54, batch loss = 0.29 (50.5 examples/sec; 0.158 sec/batch; 14h:04m:44s remains)
INFO - root - 2017-12-01 03:08:31.087067: step 12420, loss = 0.50, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 13h:48m:20s remains)
INFO - root - 2017-12-01 03:08:32.678377: step 12430, loss = 0.59, batch loss = 0.33 (52.1 examples/sec; 0.154 sec/batch; 13h:39m:14s remains)
INFO - root - 2017-12-01 03:08:34.234604: step 12440, loss = 0.46, batch loss = 0.21 (48.5 examples/sec; 0.165 sec/batch; 14h:39m:39s remains)
INFO - root - 2017-12-01 03:08:35.820029: step 12450, loss = 0.49, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 14h:02m:07s remains)
INFO - root - 2017-12-01 03:08:37.378051: step 12460, loss = 0.48, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 13h:39m:51s remains)
INFO - root - 2017-12-01 03:08:38.940355: step 12470, loss = 0.60, batch loss = 0.35 (50.9 examples/sec; 0.157 sec/batch; 13h:58m:29s remains)
INFO - root - 2017-12-01 03:08:40.508537: step 12480, loss = 0.55, batch loss = 0.29 (49.6 examples/sec; 0.161 sec/batch; 14h:20m:23s remains)
INFO - root - 2017-12-01 03:08:42.088479: step 12490, loss = 0.55, batch loss = 0.29 (53.3 examples/sec; 0.150 sec/batch; 13h:20m:40s remains)
INFO - root - 2017-12-01 03:08:43.667510: step 12500, loss = 0.60, batch loss = 0.35 (51.5 examples/sec; 0.155 sec/batch; 13h:49m:04s remains)
INFO - root - 2017-12-01 03:08:45.271554: step 12510, loss = 0.53, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 13h:52m:11s remains)
INFO - root - 2017-12-01 03:08:46.829833: step 12520, loss = 0.75, batch loss = 0.50 (51.8 examples/sec; 0.154 sec/batch; 13h:42m:54s remains)
INFO - root - 2017-12-01 03:08:48.394944: step 12530, loss = 0.50, batch loss = 0.24 (49.3 examples/sec; 0.162 sec/batch; 14h:26m:11s remains)
INFO - root - 2017-12-01 03:08:49.933698: step 12540, loss = 0.59, batch loss = 0.33 (51.4 examples/sec; 0.156 sec/batch; 13h:49m:29s remains)
INFO - root - 2017-12-01 03:08:51.507780: step 12550, loss = 0.65, batch loss = 0.39 (50.5 examples/sec; 0.159 sec/batch; 14h:05m:12s remains)
INFO - root - 2017-12-01 03:08:53.072774: step 12560, loss = 0.53, batch loss = 0.28 (50.8 examples/sec; 0.158 sec/batch; 14h:00m:29s remains)
INFO - root - 2017-12-01 03:08:54.626585: step 12570, loss = 0.51, batch loss = 0.25 (49.9 examples/sec; 0.160 sec/batch; 14h:14m:29s remains)
INFO - root - 2017-12-01 03:08:56.216118: step 12580, loss = 0.53, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 13h:46m:32s remains)
INFO - root - 2017-12-01 03:08:57.804186: step 12590, loss = 0.55, batch loss = 0.30 (51.3 examples/sec; 0.156 sec/batch; 13h:51m:57s remains)
INFO - root - 2017-12-01 03:08:59.353105: step 12600, loss = 0.51, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 13h:50m:23s remains)
INFO - root - 2017-12-01 03:09:00.987748: step 12610, loss = 0.52, batch loss = 0.27 (52.4 examples/sec; 0.153 sec/batch; 13h:34m:17s remains)
INFO - root - 2017-12-01 03:09:02.531569: step 12620, loss = 0.50, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 13h:37m:39s remains)
INFO - root - 2017-12-01 03:09:04.102602: step 12630, loss = 0.63, batch loss = 0.38 (51.5 examples/sec; 0.155 sec/batch; 13h:47m:49s remains)
INFO - root - 2017-12-01 03:09:05.666450: step 12640, loss = 0.65, batch loss = 0.40 (51.6 examples/sec; 0.155 sec/batch; 13h:45m:59s remains)
INFO - root - 2017-12-01 03:09:07.227816: step 12650, loss = 0.53, batch loss = 0.27 (53.4 examples/sec; 0.150 sec/batch; 13h:19m:21s remains)
INFO - root - 2017-12-01 03:09:08.791492: step 12660, loss = 0.50, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 13h:51m:14s remains)
INFO - root - 2017-12-01 03:09:10.370353: step 12670, loss = 0.53, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 13h:51m:44s remains)
INFO - root - 2017-12-01 03:09:11.929773: step 12680, loss = 0.62, batch loss = 0.37 (51.6 examples/sec; 0.155 sec/batch; 13h:45m:53s remains)
INFO - root - 2017-12-01 03:09:13.488734: step 12690, loss = 0.59, batch loss = 0.34 (49.7 examples/sec; 0.161 sec/batch; 14h:17m:29s remains)
INFO - root - 2017-12-01 03:09:15.066510: step 12700, loss = 0.50, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 13h:53m:11s remains)
INFO - root - 2017-12-01 03:09:16.702961: step 12710, loss = 0.58, batch loss = 0.33 (50.6 examples/sec; 0.158 sec/batch; 14h:02m:01s remains)
INFO - root - 2017-12-01 03:09:18.257614: step 12720, loss = 0.55, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 14h:00m:41s remains)
INFO - root - 2017-12-01 03:09:19.810032: step 12730, loss = 0.72, batch loss = 0.47 (50.7 examples/sec; 0.158 sec/batch; 14h:00m:27s remains)
INFO - root - 2017-12-01 03:09:21.402061: step 12740, loss = 0.50, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 13h:44m:06s remains)
INFO - root - 2017-12-01 03:09:22.958309: step 12750, loss = 0.56, batch loss = 0.30 (51.0 examples/sec; 0.157 sec/batch; 13h:56m:13s remains)
INFO - root - 2017-12-01 03:09:24.528806: step 12760, loss = 0.56, batch loss = 0.31 (51.4 examples/sec; 0.156 sec/batch; 13h:48m:53s remains)
INFO - root - 2017-12-01 03:09:26.105927: step 12770, loss = 0.57, batch loss = 0.32 (48.3 examples/sec; 0.166 sec/batch; 14h:42m:05s remains)
INFO - root - 2017-12-01 03:09:27.694354: step 12780, loss = 0.60, batch loss = 0.34 (52.4 examples/sec; 0.153 sec/batch; 13h:33m:13s remains)
INFO - root - 2017-12-01 03:09:29.293209: step 12790, loss = 0.60, batch loss = 0.34 (49.6 examples/sec; 0.161 sec/batch; 14h:18m:51s remains)
INFO - root - 2017-12-01 03:09:30.867370: step 12800, loss = 0.47, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 13h:34m:45s remains)
INFO - root - 2017-12-01 03:09:32.521030: step 12810, loss = 0.55, batch loss = 0.30 (51.1 examples/sec; 0.157 sec/batch; 13h:54m:29s remains)
INFO - root - 2017-12-01 03:09:34.068998: step 12820, loss = 0.62, batch loss = 0.36 (51.7 examples/sec; 0.155 sec/batch; 13h:44m:46s remains)
INFO - root - 2017-12-01 03:09:35.668384: step 12830, loss = 0.53, batch loss = 0.28 (53.3 examples/sec; 0.150 sec/batch; 13h:19m:13s remains)
INFO - root - 2017-12-01 03:09:37.228305: step 12840, loss = 0.51, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 13h:55m:00s remains)
INFO - root - 2017-12-01 03:09:38.782821: step 12850, loss = 0.51, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 13h:47m:49s remains)
INFO - root - 2017-12-01 03:09:40.360477: step 12860, loss = 0.50, batch loss = 0.24 (50.8 examples/sec; 0.158 sec/batch; 13h:59m:29s remains)
INFO - root - 2017-12-01 03:09:41.949210: step 12870, loss = 0.68, batch loss = 0.42 (50.6 examples/sec; 0.158 sec/batch; 14h:01m:59s remains)
INFO - root - 2017-12-01 03:09:43.538503: step 12880, loss = 0.49, batch loss = 0.24 (48.2 examples/sec; 0.166 sec/batch; 14h:44m:37s remains)
INFO - root - 2017-12-01 03:09:45.118016: step 12890, loss = 0.81, batch loss = 0.56 (48.8 examples/sec; 0.164 sec/batch; 14h:32m:43s remains)
INFO - root - 2017-12-01 03:09:46.667427: step 12900, loss = 0.51, batch loss = 0.25 (53.2 examples/sec; 0.150 sec/batch; 13h:20m:28s remains)
INFO - root - 2017-12-01 03:09:48.322974: step 12910, loss = 0.50, batch loss = 0.24 (46.8 examples/sec; 0.171 sec/batch; 15h:10m:30s remains)
INFO - root - 2017-12-01 03:09:49.857454: step 12920, loss = 0.67, batch loss = 0.41 (50.3 examples/sec; 0.159 sec/batch; 14h:07m:04s remains)
INFO - root - 2017-12-01 03:09:51.438444: step 12930, loss = 0.55, batch loss = 0.29 (49.3 examples/sec; 0.162 sec/batch; 14h:23m:43s remains)
INFO - root - 2017-12-01 03:09:53.016060: step 12940, loss = 0.59, batch loss = 0.33 (51.7 examples/sec; 0.155 sec/batch; 13h:43m:29s remains)
INFO - root - 2017-12-01 03:09:54.573228: step 12950, loss = 0.68, batch loss = 0.42 (50.7 examples/sec; 0.158 sec/batch; 14h:00m:35s remains)
INFO - root - 2017-12-01 03:09:56.152084: step 12960, loss = 0.52, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 14h:06m:34s remains)
INFO - root - 2017-12-01 03:09:57.720298: step 12970, loss = 0.59, batch loss = 0.34 (52.2 examples/sec; 0.153 sec/batch; 13h:36m:06s remains)
INFO - root - 2017-12-01 03:09:59.288496: step 12980, loss = 0.65, batch loss = 0.40 (50.6 examples/sec; 0.158 sec/batch; 14h:02m:45s remains)
INFO - root - 2017-12-01 03:10:00.863557: step 12990, loss = 0.59, batch loss = 0.33 (50.9 examples/sec; 0.157 sec/batch; 13h:57m:16s remains)
INFO - root - 2017-12-01 03:10:02.429395: step 13000, loss = 0.58, batch loss = 0.33 (50.7 examples/sec; 0.158 sec/batch; 14h:00m:40s remains)
INFO - root - 2017-12-01 03:10:04.091189: step 13010, loss = 0.53, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 13h:56m:26s remains)
INFO - root - 2017-12-01 03:10:05.656933: step 13020, loss = 0.48, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 13h:59m:44s remains)
INFO - root - 2017-12-01 03:10:07.221416: step 13030, loss = 0.52, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 14h:00m:27s remains)
INFO - root - 2017-12-01 03:10:08.815557: step 13040, loss = 0.53, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 13h:46m:02s remains)
INFO - root - 2017-12-01 03:10:10.380924: step 13050, loss = 0.48, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 13h:56m:42s remains)
INFO - root - 2017-12-01 03:10:11.936807: step 13060, loss = 0.49, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 14h:03m:07s remains)
INFO - root - 2017-12-01 03:10:13.481911: step 13070, loss = 0.72, batch loss = 0.47 (52.7 examples/sec; 0.152 sec/batch; 13h:27m:57s remains)
INFO - root - 2017-12-01 03:10:15.052790: step 13080, loss = 0.59, batch loss = 0.34 (50.5 examples/sec; 0.158 sec/batch; 14h:03m:20s remains)
INFO - root - 2017-12-01 03:10:16.619319: step 13090, loss = 0.51, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 13h:40m:04s remains)
INFO - root - 2017-12-01 03:10:18.171266: step 13100, loss = 0.72, batch loss = 0.47 (51.6 examples/sec; 0.155 sec/batch; 13h:44m:48s remains)
INFO - root - 2017-12-01 03:10:19.787560: step 13110, loss = 0.53, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 13h:48m:23s remains)
INFO - root - 2017-12-01 03:10:21.351899: step 13120, loss = 0.62, batch loss = 0.37 (52.4 examples/sec; 0.153 sec/batch; 13h:32m:07s remains)
INFO - root - 2017-12-01 03:10:22.908217: step 13130, loss = 0.61, batch loss = 0.36 (51.2 examples/sec; 0.156 sec/batch; 13h:51m:44s remains)
INFO - root - 2017-12-01 03:10:24.466806: step 13140, loss = 0.51, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 14h:02m:02s remains)
INFO - root - 2017-12-01 03:10:26.053611: step 13150, loss = 0.54, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 13h:48m:00s remains)
INFO - root - 2017-12-01 03:10:27.609506: step 13160, loss = 0.43, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 14h:06m:17s remains)
INFO - root - 2017-12-01 03:10:29.185154: step 13170, loss = 0.54, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 13h:45m:21s remains)
INFO - root - 2017-12-01 03:10:30.755886: step 13180, loss = 0.59, batch loss = 0.33 (51.7 examples/sec; 0.155 sec/batch; 13h:44m:06s remains)
INFO - root - 2017-12-01 03:10:32.319952: step 13190, loss = 0.57, batch loss = 0.31 (51.4 examples/sec; 0.156 sec/batch; 13h:48m:50s remains)
INFO - root - 2017-12-01 03:10:33.888865: step 13200, loss = 0.54, batch loss = 0.28 (50.5 examples/sec; 0.159 sec/batch; 14h:03m:33s remains)
INFO - root - 2017-12-01 03:10:35.494116: step 13210, loss = 0.48, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 13h:29m:58s remains)
INFO - root - 2017-12-01 03:10:37.066375: step 13220, loss = 0.69, batch loss = 0.44 (49.9 examples/sec; 0.160 sec/batch; 14h:13m:45s remains)
INFO - root - 2017-12-01 03:10:38.616714: step 13230, loss = 0.53, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 14h:01m:37s remains)
INFO - root - 2017-12-01 03:10:40.184732: step 13240, loss = 0.62, batch loss = 0.37 (47.3 examples/sec; 0.169 sec/batch; 14h:59m:37s remains)
INFO - root - 2017-12-01 03:10:41.761827: step 13250, loss = 0.54, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 13h:50m:13s remains)
INFO - root - 2017-12-01 03:10:43.318659: step 13260, loss = 0.55, batch loss = 0.30 (52.3 examples/sec; 0.153 sec/batch; 13h:34m:14s remains)
INFO - root - 2017-12-01 03:10:44.898493: step 13270, loss = 0.49, batch loss = 0.24 (49.7 examples/sec; 0.161 sec/batch; 14h:16m:24s remains)
INFO - root - 2017-12-01 03:10:46.462044: step 13280, loss = 0.57, batch loss = 0.31 (52.6 examples/sec; 0.152 sec/batch; 13h:29m:39s remains)
INFO - root - 2017-12-01 03:10:48.035626: step 13290, loss = 0.60, batch loss = 0.35 (52.4 examples/sec; 0.153 sec/batch; 13h:32m:48s remains)
INFO - root - 2017-12-01 03:10:49.595795: step 13300, loss = 0.66, batch loss = 0.41 (53.1 examples/sec; 0.151 sec/batch; 13h:21m:30s remains)
INFO - root - 2017-12-01 03:10:51.199311: step 13310, loss = 0.51, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 13h:50m:02s remains)
INFO - root - 2017-12-01 03:10:52.759211: step 13320, loss = 0.60, batch loss = 0.35 (49.6 examples/sec; 0.161 sec/batch; 14h:18m:01s remains)
INFO - root - 2017-12-01 03:10:54.327521: step 13330, loss = 0.48, batch loss = 0.22 (52.1 examples/sec; 0.153 sec/batch; 13h:36m:27s remains)
INFO - root - 2017-12-01 03:10:55.923612: step 13340, loss = 0.51, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 13h:56m:10s remains)
INFO - root - 2017-12-01 03:10:57.484415: step 13350, loss = 0.56, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 13h:54m:54s remains)
INFO - root - 2017-12-01 03:10:59.043604: step 13360, loss = 0.57, batch loss = 0.31 (50.0 examples/sec; 0.160 sec/batch; 14h:10m:38s remains)
INFO - root - 2017-12-01 03:11:00.605754: step 13370, loss = 0.54, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 13h:45m:52s remains)
INFO - root - 2017-12-01 03:11:02.164946: step 13380, loss = 0.50, batch loss = 0.25 (50.8 examples/sec; 0.158 sec/batch; 13h:57m:51s remains)
INFO - root - 2017-12-01 03:11:03.757160: step 13390, loss = 0.59, batch loss = 0.34 (51.6 examples/sec; 0.155 sec/batch; 13h:44m:52s remains)
INFO - root - 2017-12-01 03:11:05.339630: step 13400, loss = 0.51, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 13h:50m:53s remains)
INFO - root - 2017-12-01 03:11:07.010721: step 13410, loss = 0.52, batch loss = 0.27 (51.1 examples/sec; 0.156 sec/batch; 13h:52m:13s remains)
INFO - root - 2017-12-01 03:11:08.571719: step 13420, loss = 0.48, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 13h:43m:23s remains)
INFO - root - 2017-12-01 03:11:10.132352: step 13430, loss = 0.50, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 14h:03m:58s remains)
INFO - root - 2017-12-01 03:11:11.692983: step 13440, loss = 0.53, batch loss = 0.28 (52.5 examples/sec; 0.152 sec/batch; 13h:29m:41s remains)
INFO - root - 2017-12-01 03:11:13.241709: step 13450, loss = 0.52, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 13h:52m:39s remains)
INFO - root - 2017-12-01 03:11:14.811483: step 13460, loss = 0.45, batch loss = 0.20 (49.7 examples/sec; 0.161 sec/batch; 14h:15m:29s remains)
INFO - root - 2017-12-01 03:11:16.379825: step 13470, loss = 0.49, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 13h:53m:24s remains)
INFO - root - 2017-12-01 03:11:17.939714: step 13480, loss = 0.52, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 13h:38m:20s remains)
INFO - root - 2017-12-01 03:11:19.518209: step 13490, loss = 0.64, batch loss = 0.39 (48.4 examples/sec; 0.165 sec/batch; 14h:38m:11s remains)
INFO - root - 2017-12-01 03:11:21.058377: step 13500, loss = 0.47, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 13h:34m:03s remains)
INFO - root - 2017-12-01 03:11:22.695566: step 13510, loss = 0.49, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 13h:33m:08s remains)
INFO - root - 2017-12-01 03:11:24.299813: step 13520, loss = 0.55, batch loss = 0.30 (52.1 examples/sec; 0.154 sec/batch; 13h:36m:26s remains)
INFO - root - 2017-12-01 03:11:25.862634: step 13530, loss = 0.50, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 13h:59m:08s remains)
INFO - root - 2017-12-01 03:11:27.416180: step 13540, loss = 0.61, batch loss = 0.35 (51.4 examples/sec; 0.156 sec/batch; 13h:47m:48s remains)
INFO - root - 2017-12-01 03:11:28.965857: step 13550, loss = 0.56, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 13h:44m:52s remains)
INFO - root - 2017-12-01 03:11:30.544547: step 13560, loss = 0.49, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 13h:51m:48s remains)
INFO - root - 2017-12-01 03:11:32.133158: step 13570, loss = 0.49, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 13h:46m:46s remains)
INFO - root - 2017-12-01 03:11:33.692739: step 13580, loss = 0.49, batch loss = 0.24 (49.5 examples/sec; 0.162 sec/batch; 14h:19m:48s remains)
INFO - root - 2017-12-01 03:11:35.252224: step 13590, loss = 0.56, batch loss = 0.31 (50.7 examples/sec; 0.158 sec/batch; 13h:58m:56s remains)
INFO - root - 2017-12-01 03:11:36.823248: step 13600, loss = 0.60, batch loss = 0.35 (52.1 examples/sec; 0.154 sec/batch; 13h:36m:16s remains)
INFO - root - 2017-12-01 03:11:38.429796: step 13610, loss = 0.69, batch loss = 0.44 (51.0 examples/sec; 0.157 sec/batch; 13h:52m:55s remains)
INFO - root - 2017-12-01 03:11:39.985564: step 13620, loss = 0.50, batch loss = 0.24 (49.6 examples/sec; 0.161 sec/batch; 14h:16m:32s remains)
INFO - root - 2017-12-01 03:11:41.543255: step 13630, loss = 0.53, batch loss = 0.28 (52.8 examples/sec; 0.152 sec/batch; 13h:25m:31s remains)
INFO - root - 2017-12-01 03:11:43.113838: step 13640, loss = 0.58, batch loss = 0.33 (53.4 examples/sec; 0.150 sec/batch; 13h:16m:22s remains)
INFO - root - 2017-12-01 03:11:44.692431: step 13650, loss = 0.46, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 13h:39m:46s remains)
INFO - root - 2017-12-01 03:11:46.269848: step 13660, loss = 0.77, batch loss = 0.52 (50.0 examples/sec; 0.160 sec/batch; 14h:10m:24s remains)
INFO - root - 2017-12-01 03:11:47.826470: step 13670, loss = 0.62, batch loss = 0.36 (50.9 examples/sec; 0.157 sec/batch; 13h:55m:20s remains)
INFO - root - 2017-12-01 03:11:49.394076: step 13680, loss = 0.54, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 13h:55m:11s remains)
INFO - root - 2017-12-01 03:11:50.951903: step 13690, loss = 0.64, batch loss = 0.39 (51.4 examples/sec; 0.156 sec/batch; 13h:47m:31s remains)
INFO - root - 2017-12-01 03:11:52.535000: step 13700, loss = 0.52, batch loss = 0.26 (51.1 examples/sec; 0.156 sec/batch; 13h:51m:31s remains)
INFO - root - 2017-12-01 03:11:54.169274: step 13710, loss = 0.48, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 13h:34m:20s remains)
INFO - root - 2017-12-01 03:11:55.744617: step 13720, loss = 0.49, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 13h:51m:06s remains)
INFO - root - 2017-12-01 03:11:57.308927: step 13730, loss = 0.54, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 13h:55m:36s remains)
INFO - root - 2017-12-01 03:11:58.869901: step 13740, loss = 0.52, batch loss = 0.27 (50.1 examples/sec; 0.160 sec/batch; 14h:07m:32s remains)
INFO - root - 2017-12-01 03:12:00.437726: step 13750, loss = 0.63, batch loss = 0.37 (48.0 examples/sec; 0.167 sec/batch; 14h:46m:17s remains)
INFO - root - 2017-12-01 03:12:02.001602: step 13760, loss = 0.47, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 13h:39m:59s remains)
INFO - root - 2017-12-01 03:12:03.568043: step 13770, loss = 0.55, batch loss = 0.29 (50.6 examples/sec; 0.158 sec/batch; 14h:00m:22s remains)
INFO - root - 2017-12-01 03:12:05.141731: step 13780, loss = 0.60, batch loss = 0.35 (48.9 examples/sec; 0.163 sec/batch; 14h:28m:25s remains)
INFO - root - 2017-12-01 03:12:06.704368: step 13790, loss = 0.58, batch loss = 0.33 (50.4 examples/sec; 0.159 sec/batch; 14h:03m:23s remains)
INFO - root - 2017-12-01 03:12:08.265317: step 13800, loss = 0.49, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 13h:40m:08s remains)
INFO - root - 2017-12-01 03:12:09.868133: step 13810, loss = 0.53, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 13h:58m:42s remains)
INFO - root - 2017-12-01 03:12:11.428224: step 13820, loss = 0.50, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 13h:50m:27s remains)
INFO - root - 2017-12-01 03:12:13.000138: step 13830, loss = 0.43, batch loss = 0.18 (49.1 examples/sec; 0.163 sec/batch; 14h:25m:52s remains)
INFO - root - 2017-12-01 03:12:14.585908: step 13840, loss = 0.49, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 13h:37m:42s remains)
INFO - root - 2017-12-01 03:12:16.181900: step 13850, loss = 0.45, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 13h:54m:16s remains)
INFO - root - 2017-12-01 03:12:17.759985: step 13860, loss = 0.56, batch loss = 0.30 (52.8 examples/sec; 0.152 sec/batch; 13h:25m:14s remains)
INFO - root - 2017-12-01 03:12:19.327139: step 13870, loss = 0.63, batch loss = 0.38 (50.4 examples/sec; 0.159 sec/batch; 14h:03m:16s remains)
INFO - root - 2017-12-01 03:12:20.890662: step 13880, loss = 0.60, batch loss = 0.34 (52.2 examples/sec; 0.153 sec/batch; 13h:33m:52s remains)
INFO - root - 2017-12-01 03:12:22.456818: step 13890, loss = 0.56, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 13h:50m:03s remains)
INFO - root - 2017-12-01 03:12:24.025040: step 13900, loss = 0.54, batch loss = 0.28 (49.4 examples/sec; 0.162 sec/batch; 14h:20m:09s remains)
INFO - root - 2017-12-01 03:12:25.659756: step 13910, loss = 0.60, batch loss = 0.35 (51.7 examples/sec; 0.155 sec/batch; 13h:41m:50s remains)
INFO - root - 2017-12-01 03:12:27.237208: step 13920, loss = 0.55, batch loss = 0.30 (51.1 examples/sec; 0.156 sec/batch; 13h:50m:35s remains)
INFO - root - 2017-12-01 03:12:28.782269: step 13930, loss = 0.66, batch loss = 0.40 (51.7 examples/sec; 0.155 sec/batch; 13h:41m:33s remains)
INFO - root - 2017-12-01 03:12:30.355505: step 13940, loss = 0.49, batch loss = 0.23 (53.1 examples/sec; 0.151 sec/batch; 13h:20m:27s remains)
INFO - root - 2017-12-01 03:12:31.929254: step 13950, loss = 0.64, batch loss = 0.39 (52.0 examples/sec; 0.154 sec/batch; 13h:36m:14s remains)
INFO - root - 2017-12-01 03:12:33.498428: step 13960, loss = 0.61, batch loss = 0.36 (50.2 examples/sec; 0.159 sec/batch; 14h:05m:32s remains)
INFO - root - 2017-12-01 03:12:35.063597: step 13970, loss = 0.49, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 14h:01m:07s remains)
INFO - root - 2017-12-01 03:12:36.615397: step 13980, loss = 0.54, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 13h:42m:46s remains)
INFO - root - 2017-12-01 03:12:38.185485: step 13990, loss = 0.54, batch loss = 0.29 (49.6 examples/sec; 0.161 sec/batch; 14h:16m:28s remains)
INFO - root - 2017-12-01 03:12:39.761988: step 14000, loss = 0.52, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 13h:53m:40s remains)
INFO - root - 2017-12-01 03:12:41.394149: step 14010, loss = 0.63, batch loss = 0.38 (51.5 examples/sec; 0.155 sec/batch; 13h:45m:18s remains)
INFO - root - 2017-12-01 03:12:42.947922: step 14020, loss = 0.56, batch loss = 0.31 (50.6 examples/sec; 0.158 sec/batch; 13h:59m:55s remains)
INFO - root - 2017-12-01 03:12:44.509882: step 14030, loss = 0.53, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 13h:38m:05s remains)
INFO - root - 2017-12-01 03:12:46.074140: step 14040, loss = 0.53, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 13h:48m:16s remains)
INFO - root - 2017-12-01 03:12:47.636442: step 14050, loss = 0.56, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 13h:54m:59s remains)
INFO - root - 2017-12-01 03:12:49.198978: step 14060, loss = 0.59, batch loss = 0.34 (52.0 examples/sec; 0.154 sec/batch; 13h:36m:23s remains)
INFO - root - 2017-12-01 03:12:50.753698: step 14070, loss = 0.57, batch loss = 0.32 (51.9 examples/sec; 0.154 sec/batch; 13h:38m:05s remains)
INFO - root - 2017-12-01 03:12:52.348420: step 14080, loss = 0.47, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 13h:44m:41s remains)
INFO - root - 2017-12-01 03:12:53.962917: step 14090, loss = 0.49, batch loss = 0.23 (44.9 examples/sec; 0.178 sec/batch; 15h:46m:17s remains)
INFO - root - 2017-12-01 03:12:55.596359: step 14100, loss = 0.59, batch loss = 0.34 (51.1 examples/sec; 0.157 sec/batch; 13h:51m:12s remains)
INFO - root - 2017-12-01 03:12:57.242434: step 14110, loss = 0.56, batch loss = 0.31 (49.7 examples/sec; 0.161 sec/batch; 14h:13m:36s remains)
INFO - root - 2017-12-01 03:12:58.803610: step 14120, loss = 0.67, batch loss = 0.42 (50.9 examples/sec; 0.157 sec/batch; 13h:53m:48s remains)
INFO - root - 2017-12-01 03:13:00.374406: step 14130, loss = 0.71, batch loss = 0.45 (50.8 examples/sec; 0.157 sec/batch; 13h:54m:55s remains)
INFO - root - 2017-12-01 03:13:01.921830: step 14140, loss = 0.53, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 13h:59m:41s remains)
INFO - root - 2017-12-01 03:13:03.495940: step 14150, loss = 0.49, batch loss = 0.24 (49.8 examples/sec; 0.161 sec/batch; 14h:12m:09s remains)
INFO - root - 2017-12-01 03:13:05.063622: step 14160, loss = 0.75, batch loss = 0.50 (52.9 examples/sec; 0.151 sec/batch; 13h:22m:46s remains)
INFO - root - 2017-12-01 03:13:06.612594: step 14170, loss = 0.55, batch loss = 0.30 (51.7 examples/sec; 0.155 sec/batch; 13h:40m:10s remains)
INFO - root - 2017-12-01 03:13:08.158340: step 14180, loss = 0.53, batch loss = 0.27 (50.8 examples/sec; 0.157 sec/batch; 13h:54m:44s remains)
INFO - root - 2017-12-01 03:13:09.707938: step 14190, loss = 0.60, batch loss = 0.34 (51.0 examples/sec; 0.157 sec/batch; 13h:52m:19s remains)
INFO - root - 2017-12-01 03:13:11.269370: step 14200, loss = 0.49, batch loss = 0.24 (50.1 examples/sec; 0.160 sec/batch; 14h:06m:22s remains)
INFO - root - 2017-12-01 03:13:12.929618: step 14210, loss = 0.63, batch loss = 0.37 (51.7 examples/sec; 0.155 sec/batch; 13h:40m:50s remains)
INFO - root - 2017-12-01 03:13:14.486322: step 14220, loss = 0.53, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 13h:51m:24s remains)
INFO - root - 2017-12-01 03:13:16.084426: step 14230, loss = 0.67, batch loss = 0.42 (49.3 examples/sec; 0.162 sec/batch; 14h:20m:15s remains)
INFO - root - 2017-12-01 03:13:17.665921: step 14240, loss = 0.63, batch loss = 0.38 (51.5 examples/sec; 0.155 sec/batch; 13h:43m:33s remains)
INFO - root - 2017-12-01 03:13:19.218206: step 14250, loss = 0.55, batch loss = 0.30 (50.3 examples/sec; 0.159 sec/batch; 14h:04m:15s remains)
INFO - root - 2017-12-01 03:13:20.785112: step 14260, loss = 0.55, batch loss = 0.30 (52.2 examples/sec; 0.153 sec/batch; 13h:32m:23s remains)
INFO - root - 2017-12-01 03:13:22.327913: step 14270, loss = 0.45, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 13h:50m:44s remains)
INFO - root - 2017-12-01 03:13:23.890337: step 14280, loss = 0.46, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 13h:40m:48s remains)
INFO - root - 2017-12-01 03:13:25.470601: step 14290, loss = 0.49, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 13h:36m:03s remains)
INFO - root - 2017-12-01 03:13:27.045759: step 14300, loss = 0.50, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 13h:28m:35s remains)
INFO - root - 2017-12-01 03:13:28.645525: step 14310, loss = 0.50, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 13h:49m:32s remains)
INFO - root - 2017-12-01 03:13:30.210305: step 14320, loss = 0.59, batch loss = 0.34 (51.5 examples/sec; 0.155 sec/batch; 13h:43m:34s remains)
INFO - root - 2017-12-01 03:13:31.804529: step 14330, loss = 0.58, batch loss = 0.33 (51.0 examples/sec; 0.157 sec/batch; 13h:52m:18s remains)
INFO - root - 2017-12-01 03:13:33.347530: step 14340, loss = 0.55, batch loss = 0.30 (49.7 examples/sec; 0.161 sec/batch; 14h:14m:10s remains)
INFO - root - 2017-12-01 03:13:34.907358: step 14350, loss = 0.58, batch loss = 0.33 (50.9 examples/sec; 0.157 sec/batch; 13h:53m:33s remains)
INFO - root - 2017-12-01 03:13:36.479130: step 14360, loss = 0.49, batch loss = 0.24 (49.2 examples/sec; 0.163 sec/batch; 14h:22m:51s remains)
INFO - root - 2017-12-01 03:13:38.055382: step 14370, loss = 0.47, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 13h:38m:36s remains)
INFO - root - 2017-12-01 03:13:39.604944: step 14380, loss = 0.53, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 13h:42m:16s remains)
INFO - root - 2017-12-01 03:13:41.163393: step 14390, loss = 0.57, batch loss = 0.31 (50.6 examples/sec; 0.158 sec/batch; 13h:57m:51s remains)
INFO - root - 2017-12-01 03:13:42.736921: step 14400, loss = 0.47, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 13h:48m:13s remains)
INFO - root - 2017-12-01 03:13:44.407714: step 14410, loss = 0.50, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 13h:41m:30s remains)
INFO - root - 2017-12-01 03:13:45.974403: step 14420, loss = 0.82, batch loss = 0.57 (51.4 examples/sec; 0.156 sec/batch; 13h:45m:34s remains)
INFO - root - 2017-12-01 03:13:47.556167: step 14430, loss = 0.63, batch loss = 0.38 (50.4 examples/sec; 0.159 sec/batch; 14h:00m:53s remains)
INFO - root - 2017-12-01 03:13:49.119527: step 14440, loss = 0.54, batch loss = 0.29 (51.8 examples/sec; 0.155 sec/batch; 13h:39m:11s remains)
INFO - root - 2017-12-01 03:13:50.675782: step 14450, loss = 0.51, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 13h:55m:49s remains)
INFO - root - 2017-12-01 03:13:52.240683: step 14460, loss = 0.50, batch loss = 0.25 (50.5 examples/sec; 0.158 sec/batch; 13h:59m:01s remains)
INFO - root - 2017-12-01 03:13:53.790689: step 14470, loss = 0.56, batch loss = 0.31 (51.1 examples/sec; 0.157 sec/batch; 13h:49m:41s remains)
INFO - root - 2017-12-01 03:13:55.381840: step 14480, loss = 0.58, batch loss = 0.33 (50.5 examples/sec; 0.159 sec/batch; 14h:00m:29s remains)
INFO - root - 2017-12-01 03:13:56.975727: step 14490, loss = 0.54, batch loss = 0.29 (49.8 examples/sec; 0.161 sec/batch; 14h:11m:54s remains)
INFO - root - 2017-12-01 03:13:58.533065: step 14500, loss = 0.55, batch loss = 0.30 (51.3 examples/sec; 0.156 sec/batch; 13h:46m:24s remains)
INFO - root - 2017-12-01 03:14:00.164963: step 14510, loss = 0.56, batch loss = 0.31 (50.8 examples/sec; 0.157 sec/batch; 13h:54m:27s remains)
INFO - root - 2017-12-01 03:14:01.714452: step 14520, loss = 0.57, batch loss = 0.32 (50.6 examples/sec; 0.158 sec/batch; 13h:58m:25s remains)
INFO - root - 2017-12-01 03:14:03.298385: step 14530, loss = 0.67, batch loss = 0.42 (48.5 examples/sec; 0.165 sec/batch; 14h:34m:36s remains)
INFO - root - 2017-12-01 03:14:04.854385: step 14540, loss = 0.54, batch loss = 0.29 (52.4 examples/sec; 0.153 sec/batch; 13h:28m:27s remains)
INFO - root - 2017-12-01 03:14:06.433726: step 14550, loss = 0.49, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 13h:43m:56s remains)
INFO - root - 2017-12-01 03:14:07.980853: step 14560, loss = 0.53, batch loss = 0.28 (51.8 examples/sec; 0.154 sec/batch; 13h:38m:01s remains)
INFO - root - 2017-12-01 03:14:09.551818: step 14570, loss = 0.45, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 14h:10m:21s remains)
INFO - root - 2017-12-01 03:14:11.120364: step 14580, loss = 0.56, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 13h:41m:04s remains)
INFO - root - 2017-12-01 03:14:12.703624: step 14590, loss = 0.62, batch loss = 0.37 (52.1 examples/sec; 0.154 sec/batch; 13h:34m:12s remains)
INFO - root - 2017-12-01 03:14:14.292946: step 14600, loss = 0.63, batch loss = 0.38 (51.0 examples/sec; 0.157 sec/batch; 13h:51m:04s remains)
INFO - root - 2017-12-01 03:14:15.919597: step 14610, loss = 0.54, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 13h:45m:32s remains)
INFO - root - 2017-12-01 03:14:17.484014: step 14620, loss = 0.57, batch loss = 0.32 (51.1 examples/sec; 0.157 sec/batch; 13h:49m:35s remains)
INFO - root - 2017-12-01 03:14:19.044700: step 14630, loss = 0.68, batch loss = 0.43 (50.6 examples/sec; 0.158 sec/batch; 13h:57m:56s remains)
INFO - root - 2017-12-01 03:14:20.618714: step 14640, loss = 0.58, batch loss = 0.33 (49.7 examples/sec; 0.161 sec/batch; 14h:12m:35s remains)
INFO - root - 2017-12-01 03:14:22.178434: step 14650, loss = 0.58, batch loss = 0.33 (53.5 examples/sec; 0.149 sec/batch; 13h:11m:37s remains)
INFO - root - 2017-12-01 03:14:23.751684: step 14660, loss = 0.55, batch loss = 0.30 (52.8 examples/sec; 0.152 sec/batch; 13h:22m:33s remains)
INFO - root - 2017-12-01 03:14:25.320898: step 14670, loss = 0.54, batch loss = 0.29 (49.7 examples/sec; 0.161 sec/batch; 14h:12m:29s remains)
INFO - root - 2017-12-01 03:14:26.899489: step 14680, loss = 0.52, batch loss = 0.27 (53.2 examples/sec; 0.150 sec/batch; 13h:16m:28s remains)
INFO - root - 2017-12-01 03:14:28.452842: step 14690, loss = 0.60, batch loss = 0.35 (51.1 examples/sec; 0.156 sec/batch; 13h:48m:29s remains)
INFO - root - 2017-12-01 03:14:30.017885: step 14700, loss = 0.52, batch loss = 0.27 (52.6 examples/sec; 0.152 sec/batch; 13h:25m:12s remains)
INFO - root - 2017-12-01 03:14:31.668465: step 14710, loss = 0.66, batch loss = 0.41 (52.6 examples/sec; 0.152 sec/batch; 13h:26m:03s remains)
INFO - root - 2017-12-01 03:14:33.236523: step 14720, loss = 0.52, batch loss = 0.27 (50.8 examples/sec; 0.157 sec/batch; 13h:53m:59s remains)
INFO - root - 2017-12-01 03:14:34.801168: step 14730, loss = 0.52, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 13h:52m:37s remains)
INFO - root - 2017-12-01 03:14:36.361018: step 14740, loss = 0.50, batch loss = 0.25 (52.2 examples/sec; 0.153 sec/batch; 13h:30m:55s remains)
INFO - root - 2017-12-01 03:14:37.933027: step 14750, loss = 0.62, batch loss = 0.37 (50.8 examples/sec; 0.158 sec/batch; 13h:54m:12s remains)
INFO - root - 2017-12-01 03:14:39.479300: step 14760, loss = 0.48, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 14h:02m:18s remains)
INFO - root - 2017-12-01 03:14:41.047565: step 14770, loss = 0.52, batch loss = 0.27 (52.3 examples/sec; 0.153 sec/batch; 13h:30m:36s remains)
INFO - root - 2017-12-01 03:14:42.600242: step 14780, loss = 0.52, batch loss = 0.27 (53.1 examples/sec; 0.151 sec/batch; 13h:17m:08s remains)
INFO - root - 2017-12-01 03:14:44.182442: step 14790, loss = 0.53, batch loss = 0.28 (51.1 examples/sec; 0.157 sec/batch; 13h:49m:37s remains)
INFO - root - 2017-12-01 03:14:45.747229: step 14800, loss = 0.66, batch loss = 0.41 (51.1 examples/sec; 0.157 sec/batch; 13h:48m:43s remains)
INFO - root - 2017-12-01 03:14:47.354280: step 14810, loss = 0.46, batch loss = 0.21 (52.9 examples/sec; 0.151 sec/batch; 13h:20m:17s remains)
INFO - root - 2017-12-01 03:14:48.920606: step 14820, loss = 0.53, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 13h:35m:56s remains)
INFO - root - 2017-12-01 03:14:50.501915: step 14830, loss = 0.51, batch loss = 0.26 (46.8 examples/sec; 0.171 sec/batch; 15h:04m:44s remains)
INFO - root - 2017-12-01 03:14:52.055103: step 14840, loss = 0.50, batch loss = 0.25 (50.0 examples/sec; 0.160 sec/batch; 14h:07m:35s remains)
INFO - root - 2017-12-01 03:14:53.616597: step 14850, loss = 0.48, batch loss = 0.23 (51.1 examples/sec; 0.156 sec/batch; 13h:48m:12s remains)
INFO - root - 2017-12-01 03:14:55.167462: step 14860, loss = 0.63, batch loss = 0.38 (50.6 examples/sec; 0.158 sec/batch; 13h:56m:46s remains)
INFO - root - 2017-12-01 03:14:56.759534: step 14870, loss = 0.60, batch loss = 0.35 (51.9 examples/sec; 0.154 sec/batch; 13h:36m:25s remains)
INFO - root - 2017-12-01 03:14:58.335504: step 14880, loss = 0.51, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 13h:39m:22s remains)
INFO - root - 2017-12-01 03:14:59.879228: step 14890, loss = 0.51, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 13h:51m:01s remains)
INFO - root - 2017-12-01 03:15:01.436437: step 14900, loss = 0.50, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 13h:26m:58s remains)
INFO - root - 2017-12-01 03:15:03.069991: step 14910, loss = 0.52, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 13h:52m:26s remains)
INFO - root - 2017-12-01 03:15:04.632955: step 14920, loss = 0.54, batch loss = 0.29 (51.0 examples/sec; 0.157 sec/batch; 13h:50m:48s remains)
INFO - root - 2017-12-01 03:15:06.182437: step 14930, loss = 0.54, batch loss = 0.29 (50.1 examples/sec; 0.160 sec/batch; 14h:05m:34s remains)
INFO - root - 2017-12-01 03:15:07.738441: step 14940, loss = 0.66, batch loss = 0.41 (52.6 examples/sec; 0.152 sec/batch; 13h:24m:14s remains)
INFO - root - 2017-12-01 03:15:09.295931: step 14950, loss = 0.52, batch loss = 0.27 (52.3 examples/sec; 0.153 sec/batch; 13h:30m:04s remains)
INFO - root - 2017-12-01 03:15:10.858232: step 14960, loss = 0.73, batch loss = 0.49 (51.0 examples/sec; 0.157 sec/batch; 13h:49m:39s remains)
INFO - root - 2017-12-01 03:15:12.416170: step 14970, loss = 0.46, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 13h:54m:51s remains)
INFO - root - 2017-12-01 03:15:13.952262: step 14980, loss = 0.78, batch loss = 0.53 (52.0 examples/sec; 0.154 sec/batch; 13h:34m:27s remains)
INFO - root - 2017-12-01 03:15:15.547164: step 14990, loss = 0.53, batch loss = 0.28 (48.6 examples/sec; 0.165 sec/batch; 14h:30m:36s remains)
INFO - root - 2017-12-01 03:15:17.112123: step 15000, loss = 0.51, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 13h:31m:28s remains)
INFO - root - 2017-12-01 03:15:18.732777: step 15010, loss = 0.61, batch loss = 0.36 (51.9 examples/sec; 0.154 sec/batch; 13h:35m:43s remains)
INFO - root - 2017-12-01 03:15:20.287953: step 15020, loss = 0.59, batch loss = 0.34 (51.1 examples/sec; 0.156 sec/batch; 13h:48m:01s remains)
INFO - root - 2017-12-01 03:15:21.848984: step 15030, loss = 0.53, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 13h:50m:55s remains)
INFO - root - 2017-12-01 03:15:23.427867: step 15040, loss = 0.47, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 13h:46m:57s remains)
INFO - root - 2017-12-01 03:15:24.968651: step 15050, loss = 0.54, batch loss = 0.29 (52.6 examples/sec; 0.152 sec/batch; 13h:24m:29s remains)
INFO - root - 2017-12-01 03:15:26.542854: step 15060, loss = 0.48, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 13h:49m:12s remains)
INFO - root - 2017-12-01 03:15:28.101201: step 15070, loss = 0.54, batch loss = 0.30 (53.5 examples/sec; 0.149 sec/batch; 13h:10m:42s remains)
INFO - root - 2017-12-01 03:15:29.662408: step 15080, loss = 0.59, batch loss = 0.34 (51.6 examples/sec; 0.155 sec/batch; 13h:40m:21s remains)
INFO - root - 2017-12-01 03:15:31.229108: step 15090, loss = 0.52, batch loss = 0.27 (52.7 examples/sec; 0.152 sec/batch; 13h:23m:19s remains)
INFO - root - 2017-12-01 03:15:32.812756: step 15100, loss = 0.48, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 13h:44m:44s remains)
INFO - root - 2017-12-01 03:15:34.425022: step 15110, loss = 0.53, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 13h:58m:13s remains)
INFO - root - 2017-12-01 03:15:35.990527: step 15120, loss = 0.49, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 13h:40m:25s remains)
INFO - root - 2017-12-01 03:15:37.558599: step 15130, loss = 0.52, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 13h:42m:38s remains)
INFO - root - 2017-12-01 03:15:39.162239: step 15140, loss = 0.54, batch loss = 0.29 (51.0 examples/sec; 0.157 sec/batch; 13h:50m:24s remains)
INFO - root - 2017-12-01 03:15:40.726715: step 15150, loss = 0.49, batch loss = 0.24 (52.7 examples/sec; 0.152 sec/batch; 13h:22m:52s remains)
INFO - root - 2017-12-01 03:15:42.331392: step 15160, loss = 0.59, batch loss = 0.34 (50.8 examples/sec; 0.157 sec/batch; 13h:52m:35s remains)
INFO - root - 2017-12-01 03:15:43.979640: step 15170, loss = 0.59, batch loss = 0.34 (51.2 examples/sec; 0.156 sec/batch; 13h:45m:43s remains)
INFO - root - 2017-12-01 03:15:45.531842: step 15180, loss = 0.58, batch loss = 0.33 (52.7 examples/sec; 0.152 sec/batch; 13h:22m:42s remains)
INFO - root - 2017-12-01 03:15:47.117132: step 15190, loss = 0.61, batch loss = 0.37 (50.0 examples/sec; 0.160 sec/batch; 14h:06m:56s remains)
INFO - root - 2017-12-01 03:15:48.700293: step 15200, loss = 0.60, batch loss = 0.35 (52.3 examples/sec; 0.153 sec/batch; 13h:28m:40s remains)
INFO - root - 2017-12-01 03:15:50.448370: step 15210, loss = 0.54, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 13h:51m:25s remains)
INFO - root - 2017-12-01 03:15:52.089174: step 15220, loss = 0.60, batch loss = 0.35 (51.5 examples/sec; 0.155 sec/batch; 13h:42m:10s remains)
INFO - root - 2017-12-01 03:15:53.710316: step 15230, loss = 0.55, batch loss = 0.30 (50.1 examples/sec; 0.160 sec/batch; 14h:03m:57s remains)
INFO - root - 2017-12-01 03:15:55.277806: step 15240, loss = 0.49, batch loss = 0.24 (49.1 examples/sec; 0.163 sec/batch; 14h:21m:45s remains)
INFO - root - 2017-12-01 03:15:56.937926: step 15250, loss = 0.56, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 13h:45m:40s remains)
INFO - root - 2017-12-01 03:15:58.504404: step 15260, loss = 0.56, batch loss = 0.31 (50.2 examples/sec; 0.159 sec/batch; 14h:02m:43s remains)
INFO - root - 2017-12-01 03:16:00.067836: step 15270, loss = 0.49, batch loss = 0.24 (49.8 examples/sec; 0.161 sec/batch; 14h:09m:28s remains)
INFO - root - 2017-12-01 03:16:01.635024: step 15280, loss = 0.49, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 13h:23m:47s remains)
INFO - root - 2017-12-01 03:16:03.209918: step 15290, loss = 0.57, batch loss = 0.32 (52.0 examples/sec; 0.154 sec/batch; 13h:33m:18s remains)
INFO - root - 2017-12-01 03:16:04.768109: step 15300, loss = 0.52, batch loss = 0.27 (50.4 examples/sec; 0.159 sec/batch; 13h:58m:52s remains)
INFO - root - 2017-12-01 03:16:06.491235: step 15310, loss = 0.56, batch loss = 0.31 (50.3 examples/sec; 0.159 sec/batch; 14h:01m:16s remains)
INFO - root - 2017-12-01 03:16:08.051234: step 15320, loss = 0.54, batch loss = 0.30 (49.7 examples/sec; 0.161 sec/batch; 14h:10m:32s remains)
INFO - root - 2017-12-01 03:16:09.613932: step 15330, loss = 0.45, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 13h:31m:46s remains)
INFO - root - 2017-12-01 03:16:11.190742: step 15340, loss = 0.58, batch loss = 0.33 (51.0 examples/sec; 0.157 sec/batch; 13h:49m:52s remains)
INFO - root - 2017-12-01 03:16:12.766353: step 15350, loss = 0.58, batch loss = 0.33 (49.8 examples/sec; 0.160 sec/batch; 14h:08m:17s remains)
INFO - root - 2017-12-01 03:16:14.356005: step 15360, loss = 0.56, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 13h:45m:28s remains)
INFO - root - 2017-12-01 03:16:15.939245: step 15370, loss = 0.59, batch loss = 0.34 (50.5 examples/sec; 0.158 sec/batch; 13h:57m:42s remains)
INFO - root - 2017-12-01 03:16:17.499775: step 15380, loss = 0.59, batch loss = 0.34 (51.7 examples/sec; 0.155 sec/batch; 13h:37m:13s remains)
INFO - root - 2017-12-01 03:16:19.064919: step 15390, loss = 0.51, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 13h:55m:16s remains)
INFO - root - 2017-12-01 03:16:20.642764: step 15400, loss = 0.52, batch loss = 0.27 (47.3 examples/sec; 0.169 sec/batch; 14h:53m:45s remains)
INFO - root - 2017-12-01 03:16:22.256358: step 15410, loss = 0.45, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 13h:24m:19s remains)
INFO - root - 2017-12-01 03:16:23.811747: step 15420, loss = 0.56, batch loss = 0.32 (51.1 examples/sec; 0.156 sec/batch; 13h:46m:52s remains)
INFO - root - 2017-12-01 03:16:25.375682: step 15430, loss = 0.48, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 13h:43m:51s remains)
INFO - root - 2017-12-01 03:16:26.943117: step 15440, loss = 0.53, batch loss = 0.28 (53.1 examples/sec; 0.151 sec/batch; 13h:16m:19s remains)
INFO - root - 2017-12-01 03:16:28.511472: step 15450, loss = 0.48, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 13h:51m:03s remains)
INFO - root - 2017-12-01 03:16:30.063002: step 15460, loss = 0.54, batch loss = 0.29 (52.3 examples/sec; 0.153 sec/batch; 13h:28m:14s remains)
INFO - root - 2017-12-01 03:16:31.640203: step 15470, loss = 0.62, batch loss = 0.37 (51.4 examples/sec; 0.156 sec/batch; 13h:42m:51s remains)
INFO - root - 2017-12-01 03:16:33.213913: step 15480, loss = 0.54, batch loss = 0.29 (53.1 examples/sec; 0.151 sec/batch; 13h:15m:22s remains)
INFO - root - 2017-12-01 03:16:34.777246: step 15490, loss = 0.47, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 13h:34m:02s remains)
INFO - root - 2017-12-01 03:16:36.333614: step 15500, loss = 0.53, batch loss = 0.28 (51.8 examples/sec; 0.154 sec/batch; 13h:36m:15s remains)
INFO - root - 2017-12-01 03:16:37.961154: step 15510, loss = 0.64, batch loss = 0.39 (49.2 examples/sec; 0.162 sec/batch; 14h:18m:22s remains)
INFO - root - 2017-12-01 03:16:39.529115: step 15520, loss = 0.55, batch loss = 0.30 (52.2 examples/sec; 0.153 sec/batch; 13h:29m:39s remains)
INFO - root - 2017-12-01 03:16:41.104342: step 15530, loss = 0.51, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 13h:30m:07s remains)
INFO - root - 2017-12-01 03:16:42.664028: step 15540, loss = 0.47, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 13h:34m:58s remains)
INFO - root - 2017-12-01 03:16:44.224284: step 15550, loss = 0.50, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 13h:50m:46s remains)
INFO - root - 2017-12-01 03:16:45.792864: step 15560, loss = 0.60, batch loss = 0.35 (48.7 examples/sec; 0.164 sec/batch; 14h:28m:17s remains)
INFO - root - 2017-12-01 03:16:47.354025: step 15570, loss = 0.48, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 13h:40m:21s remains)
INFO - root - 2017-12-01 03:16:48.913023: step 15580, loss = 0.52, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 13h:55m:11s remains)
INFO - root - 2017-12-01 03:16:50.471695: step 15590, loss = 0.56, batch loss = 0.31 (50.8 examples/sec; 0.157 sec/batch; 13h:51m:14s remains)
INFO - root - 2017-12-01 03:16:52.071655: step 15600, loss = 0.51, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 13h:41m:43s remains)
INFO - root - 2017-12-01 03:16:53.714316: step 15610, loss = 0.57, batch loss = 0.33 (50.9 examples/sec; 0.157 sec/batch; 13h:50m:10s remains)
INFO - root - 2017-12-01 03:16:55.274576: step 15620, loss = 0.54, batch loss = 0.30 (50.8 examples/sec; 0.157 sec/batch; 13h:51m:31s remains)
INFO - root - 2017-12-01 03:16:56.854249: step 15630, loss = 0.61, batch loss = 0.36 (51.6 examples/sec; 0.155 sec/batch; 13h:38m:36s remains)
INFO - root - 2017-12-01 03:16:58.406374: step 15640, loss = 0.47, batch loss = 0.22 (53.0 examples/sec; 0.151 sec/batch; 13h:17m:43s remains)
INFO - root - 2017-12-01 03:17:00.075733: step 15650, loss = 0.50, batch loss = 0.25 (32.7 examples/sec; 0.245 sec/batch; 21h:33m:14s remains)
INFO - root - 2017-12-01 03:17:01.628987: step 15660, loss = 0.48, batch loss = 0.23 (53.4 examples/sec; 0.150 sec/batch; 13h:11m:16s remains)
INFO - root - 2017-12-01 03:17:03.194909: step 15670, loss = 0.44, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 13h:38m:42s remains)
INFO - root - 2017-12-01 03:17:04.861897: step 15680, loss = 0.54, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 13h:37m:52s remains)
INFO - root - 2017-12-01 03:17:06.445981: step 15690, loss = 0.59, batch loss = 0.35 (51.4 examples/sec; 0.156 sec/batch; 13h:42m:13s remains)
INFO - root - 2017-12-01 03:17:08.015032: step 15700, loss = 0.47, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 13h:41m:14s remains)
INFO - root - 2017-12-01 03:17:09.641937: step 15710, loss = 0.48, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 13h:35m:04s remains)
INFO - root - 2017-12-01 03:17:11.219545: step 15720, loss = 0.64, batch loss = 0.39 (50.7 examples/sec; 0.158 sec/batch; 13h:52m:29s remains)
INFO - root - 2017-12-01 03:17:12.771099: step 15730, loss = 0.58, batch loss = 0.33 (51.2 examples/sec; 0.156 sec/batch; 13h:44m:30s remains)
INFO - root - 2017-12-01 03:17:14.330878: step 15740, loss = 0.66, batch loss = 0.41 (49.8 examples/sec; 0.161 sec/batch; 14h:08m:06s remains)
INFO - root - 2017-12-01 03:17:15.930339: step 15750, loss = 0.48, batch loss = 0.24 (48.8 examples/sec; 0.164 sec/batch; 14h:25m:19s remains)
INFO - root - 2017-12-01 03:17:17.515119: step 15760, loss = 0.57, batch loss = 0.32 (51.9 examples/sec; 0.154 sec/batch; 13h:33m:49s remains)
INFO - root - 2017-12-01 03:17:19.077042: step 15770, loss = 0.67, batch loss = 0.42 (50.6 examples/sec; 0.158 sec/batch; 13h:54m:35s remains)
INFO - root - 2017-12-01 03:17:20.652345: step 15780, loss = 0.49, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 13h:36m:49s remains)
INFO - root - 2017-12-01 03:17:22.241538: step 15790, loss = 0.51, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 13h:32m:44s remains)
INFO - root - 2017-12-01 03:17:23.819287: step 15800, loss = 0.57, batch loss = 0.32 (49.8 examples/sec; 0.161 sec/batch; 14h:08m:43s remains)
INFO - root - 2017-12-01 03:17:25.476302: step 15810, loss = 0.57, batch loss = 0.32 (49.8 examples/sec; 0.161 sec/batch; 14h:07m:38s remains)
INFO - root - 2017-12-01 03:17:27.060512: step 15820, loss = 0.62, batch loss = 0.38 (50.9 examples/sec; 0.157 sec/batch; 13h:49m:03s remains)
INFO - root - 2017-12-01 03:17:28.620272: step 15830, loss = 0.48, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 13h:40m:12s remains)
INFO - root - 2017-12-01 03:17:30.184609: step 15840, loss = 0.62, batch loss = 0.37 (53.3 examples/sec; 0.150 sec/batch; 13h:12m:32s remains)
INFO - root - 2017-12-01 03:17:31.747143: step 15850, loss = 0.51, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 13h:39m:27s remains)
INFO - root - 2017-12-01 03:17:33.289729: step 15860, loss = 0.47, batch loss = 0.22 (52.7 examples/sec; 0.152 sec/batch; 13h:20m:40s remains)
INFO - root - 2017-12-01 03:17:34.832450: step 15870, loss = 0.47, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 13h:40m:58s remains)
INFO - root - 2017-12-01 03:17:36.396032: step 15880, loss = 0.61, batch loss = 0.36 (50.5 examples/sec; 0.159 sec/batch; 13h:56m:28s remains)
INFO - root - 2017-12-01 03:17:37.961617: step 15890, loss = 0.63, batch loss = 0.39 (49.8 examples/sec; 0.161 sec/batch; 14h:08m:28s remains)
INFO - root - 2017-12-01 03:17:39.532618: step 15900, loss = 0.57, batch loss = 0.32 (50.2 examples/sec; 0.159 sec/batch; 14h:00m:10s remains)
INFO - root - 2017-12-01 03:17:41.139271: step 15910, loss = 0.53, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 13h:43m:14s remains)
INFO - root - 2017-12-01 03:17:42.691679: step 15920, loss = 0.50, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 13h:36m:19s remains)
INFO - root - 2017-12-01 03:17:44.246116: step 15930, loss = 0.59, batch loss = 0.34 (49.5 examples/sec; 0.161 sec/batch; 14h:12m:02s remains)
INFO - root - 2017-12-01 03:17:45.805684: step 15940, loss = 0.55, batch loss = 0.30 (49.2 examples/sec; 0.162 sec/batch; 14h:17m:10s remains)
INFO - root - 2017-12-01 03:17:47.380014: step 15950, loss = 0.51, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 13h:44m:00s remains)
INFO - root - 2017-12-01 03:17:48.953290: step 15960, loss = 0.65, batch loss = 0.40 (50.9 examples/sec; 0.157 sec/batch; 13h:48m:22s remains)
INFO - root - 2017-12-01 03:17:50.515156: step 15970, loss = 0.58, batch loss = 0.33 (49.6 examples/sec; 0.161 sec/batch; 14h:10m:51s remains)
INFO - root - 2017-12-01 03:17:52.075102: step 15980, loss = 0.52, batch loss = 0.27 (49.6 examples/sec; 0.161 sec/batch; 14h:11m:05s remains)
INFO - root - 2017-12-01 03:17:53.624873: step 15990, loss = 0.60, batch loss = 0.35 (50.0 examples/sec; 0.160 sec/batch; 14h:03m:12s remains)
INFO - root - 2017-12-01 03:17:55.176798: step 16000, loss = 0.66, batch loss = 0.41 (52.0 examples/sec; 0.154 sec/batch; 13h:31m:34s remains)
INFO - root - 2017-12-01 03:17:56.819909: step 16010, loss = 0.49, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 13h:48m:07s remains)
INFO - root - 2017-12-01 03:17:58.386475: step 16020, loss = 0.53, batch loss = 0.28 (50.4 examples/sec; 0.159 sec/batch; 13h:56m:50s remains)
INFO - root - 2017-12-01 03:17:59.941715: step 16030, loss = 0.50, batch loss = 0.25 (53.0 examples/sec; 0.151 sec/batch; 13h:15m:49s remains)
INFO - root - 2017-12-01 03:18:01.530698: step 16040, loss = 0.57, batch loss = 0.33 (51.0 examples/sec; 0.157 sec/batch; 13h:47m:04s remains)
INFO - root - 2017-12-01 03:18:03.087682: step 16050, loss = 0.90, batch loss = 0.65 (50.3 examples/sec; 0.159 sec/batch; 13h:59m:07s remains)
INFO - root - 2017-12-01 03:18:04.655743: step 16060, loss = 0.56, batch loss = 0.31 (51.1 examples/sec; 0.157 sec/batch; 13h:45m:24s remains)
INFO - root - 2017-12-01 03:18:06.203786: step 16070, loss = 0.49, batch loss = 0.24 (52.5 examples/sec; 0.152 sec/batch; 13h:23m:29s remains)
INFO - root - 2017-12-01 03:18:07.796502: step 16080, loss = 0.53, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 13h:37m:54s remains)
INFO - root - 2017-12-01 03:18:09.364728: step 16090, loss = 0.56, batch loss = 0.31 (52.1 examples/sec; 0.153 sec/batch; 13h:29m:23s remains)
INFO - root - 2017-12-01 03:18:10.929873: step 16100, loss = 0.54, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 13h:33m:30s remains)
INFO - root - 2017-12-01 03:18:12.618626: step 16110, loss = 0.67, batch loss = 0.43 (50.1 examples/sec; 0.160 sec/batch; 14h:02m:51s remains)
INFO - root - 2017-12-01 03:18:14.174272: step 16120, loss = 0.58, batch loss = 0.33 (49.7 examples/sec; 0.161 sec/batch; 14h:08m:22s remains)
INFO - root - 2017-12-01 03:18:15.737542: step 16130, loss = 0.49, batch loss = 0.24 (52.1 examples/sec; 0.153 sec/batch; 13h:29m:22s remains)
INFO - root - 2017-12-01 03:18:17.309884: step 16140, loss = 0.46, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 13h:59m:30s remains)
INFO - root - 2017-12-01 03:18:18.865547: step 16150, loss = 0.76, batch loss = 0.51 (51.8 examples/sec; 0.154 sec/batch; 13h:33m:43s remains)
INFO - root - 2017-12-01 03:18:20.419891: step 16160, loss = 0.49, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 13h:46m:07s remains)
INFO - root - 2017-12-01 03:18:21.985125: step 16170, loss = 0.55, batch loss = 0.31 (50.0 examples/sec; 0.160 sec/batch; 14h:04m:20s remains)
INFO - root - 2017-12-01 03:18:23.543427: step 16180, loss = 0.50, batch loss = 0.25 (48.5 examples/sec; 0.165 sec/batch; 14h:28m:49s remains)
INFO - root - 2017-12-01 03:18:25.116451: step 16190, loss = 0.60, batch loss = 0.35 (51.0 examples/sec; 0.157 sec/batch; 13h:47m:18s remains)
INFO - root - 2017-12-01 03:18:26.687808: step 16200, loss = 0.48, batch loss = 0.24 (50.8 examples/sec; 0.158 sec/batch; 13h:50m:33s remains)
INFO - root - 2017-12-01 03:18:28.301276: step 16210, loss = 0.48, batch loss = 0.24 (52.4 examples/sec; 0.153 sec/batch; 13h:24m:54s remains)
INFO - root - 2017-12-01 03:18:29.877518: step 16220, loss = 0.65, batch loss = 0.40 (51.9 examples/sec; 0.154 sec/batch; 13h:33m:07s remains)
INFO - root - 2017-12-01 03:18:31.441040: step 16230, loss = 0.51, batch loss = 0.27 (51.8 examples/sec; 0.155 sec/batch; 13h:34m:39s remains)
INFO - root - 2017-12-01 03:18:33.003942: step 16240, loss = 0.49, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 13h:51m:29s remains)
INFO - root - 2017-12-01 03:18:34.551861: step 16250, loss = 0.45, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 13h:33m:59s remains)
INFO - root - 2017-12-01 03:18:36.128263: step 16260, loss = 0.60, batch loss = 0.35 (52.3 examples/sec; 0.153 sec/batch; 13h:26m:29s remains)
INFO - root - 2017-12-01 03:18:37.713591: step 16270, loss = 0.51, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 13h:37m:02s remains)
INFO - root - 2017-12-01 03:18:39.275978: step 16280, loss = 0.48, batch loss = 0.24 (50.5 examples/sec; 0.159 sec/batch; 13h:55m:35s remains)
INFO - root - 2017-12-01 03:18:40.844268: step 16290, loss = 0.44, batch loss = 0.20 (49.8 examples/sec; 0.161 sec/batch; 14h:06m:47s remains)
INFO - root - 2017-12-01 03:18:42.413378: step 16300, loss = 0.53, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 13h:38m:38s remains)
INFO - root - 2017-12-01 03:18:44.013823: step 16310, loss = 0.47, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 13h:27m:21s remains)
INFO - root - 2017-12-01 03:18:45.581378: step 16320, loss = 0.66, batch loss = 0.41 (49.4 examples/sec; 0.162 sec/batch; 14h:13m:19s remains)
INFO - root - 2017-12-01 03:18:47.139318: step 16330, loss = 0.50, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 13h:42m:24s remains)
INFO - root - 2017-12-01 03:18:48.712489: step 16340, loss = 0.50, batch loss = 0.25 (53.0 examples/sec; 0.151 sec/batch; 13h:15m:25s remains)
INFO - root - 2017-12-01 03:18:50.267916: step 16350, loss = 0.55, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 13h:43m:01s remains)
INFO - root - 2017-12-01 03:18:51.831580: step 16360, loss = 0.67, batch loss = 0.43 (51.3 examples/sec; 0.156 sec/batch; 13h:41m:36s remains)
INFO - root - 2017-12-01 03:18:53.414724: step 16370, loss = 0.61, batch loss = 0.36 (50.7 examples/sec; 0.158 sec/batch; 13h:51m:10s remains)
INFO - root - 2017-12-01 03:18:54.978581: step 16380, loss = 0.62, batch loss = 0.37 (51.7 examples/sec; 0.155 sec/batch; 13h:35m:29s remains)
INFO - root - 2017-12-01 03:18:56.539035: step 16390, loss = 0.54, batch loss = 0.29 (52.1 examples/sec; 0.154 sec/batch; 13h:29m:41s remains)
INFO - root - 2017-12-01 03:18:58.116447: step 16400, loss = 0.55, batch loss = 0.30 (50.4 examples/sec; 0.159 sec/batch; 13h:55m:25s remains)
INFO - root - 2017-12-01 03:18:59.727193: step 16410, loss = 0.44, batch loss = 0.19 (49.3 examples/sec; 0.162 sec/batch; 14h:14m:26s remains)
INFO - root - 2017-12-01 03:19:01.302294: step 16420, loss = 0.52, batch loss = 0.27 (51.7 examples/sec; 0.155 sec/batch; 13h:35m:38s remains)
INFO - root - 2017-12-01 03:19:02.892071: step 16430, loss = 0.51, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 13h:41m:06s remains)
INFO - root - 2017-12-01 03:19:04.453728: step 16440, loss = 0.47, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 13h:53m:48s remains)
INFO - root - 2017-12-01 03:19:06.015764: step 16450, loss = 0.64, batch loss = 0.39 (49.7 examples/sec; 0.161 sec/batch; 14h:07m:33s remains)
INFO - root - 2017-12-01 03:19:07.595701: step 16460, loss = 0.50, batch loss = 0.25 (48.7 examples/sec; 0.164 sec/batch; 14h:26m:08s remains)
INFO - root - 2017-12-01 03:19:09.158266: step 16470, loss = 0.64, batch loss = 0.39 (51.6 examples/sec; 0.155 sec/batch; 13h:36m:04s remains)
INFO - root - 2017-12-01 03:19:10.721076: step 16480, loss = 0.50, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 13h:38m:30s remains)
INFO - root - 2017-12-01 03:19:12.270179: step 16490, loss = 0.48, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 13h:52m:05s remains)
INFO - root - 2017-12-01 03:19:13.828872: step 16500, loss = 0.60, batch loss = 0.36 (51.6 examples/sec; 0.155 sec/batch; 13h:35m:59s remains)
INFO - root - 2017-12-01 03:19:15.480202: step 16510, loss = 0.48, batch loss = 0.23 (49.6 examples/sec; 0.161 sec/batch; 14h:08m:36s remains)
INFO - root - 2017-12-01 03:19:17.095697: step 16520, loss = 0.45, batch loss = 0.20 (48.5 examples/sec; 0.165 sec/batch; 14h:29m:05s remains)
INFO - root - 2017-12-01 03:19:18.727119: step 16530, loss = 0.56, batch loss = 0.32 (50.9 examples/sec; 0.157 sec/batch; 13h:48m:14s remains)
INFO - root - 2017-12-01 03:19:20.311059: step 16540, loss = 0.62, batch loss = 0.37 (44.1 examples/sec; 0.182 sec/batch; 15h:55m:58s remains)
INFO - root - 2017-12-01 03:19:21.867912: step 16550, loss = 0.61, batch loss = 0.36 (52.9 examples/sec; 0.151 sec/batch; 13h:16m:52s remains)
INFO - root - 2017-12-01 03:19:23.442814: step 16560, loss = 0.49, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 13h:34m:24s remains)
INFO - root - 2017-12-01 03:19:25.007072: step 16570, loss = 0.58, batch loss = 0.33 (50.4 examples/sec; 0.159 sec/batch; 13h:55m:25s remains)
INFO - root - 2017-12-01 03:19:26.599672: step 16580, loss = 0.50, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 13h:38m:20s remains)
INFO - root - 2017-12-01 03:19:28.264111: step 16590, loss = 0.50, batch loss = 0.25 (53.6 examples/sec; 0.149 sec/batch; 13h:06m:23s remains)
INFO - root - 2017-12-01 03:19:29.873985: step 16600, loss = 0.66, batch loss = 0.41 (52.6 examples/sec; 0.152 sec/batch; 13h:20m:15s remains)
INFO - root - 2017-12-01 03:19:31.550734: step 16610, loss = 0.54, batch loss = 0.30 (51.8 examples/sec; 0.155 sec/batch; 13h:33m:49s remains)
INFO - root - 2017-12-01 03:19:33.200342: step 16620, loss = 0.63, batch loss = 0.39 (38.2 examples/sec; 0.209 sec/batch; 18h:22m:22s remains)
INFO - root - 2017-12-01 03:19:34.756273: step 16630, loss = 0.58, batch loss = 0.33 (50.9 examples/sec; 0.157 sec/batch; 13h:46m:56s remains)
INFO - root - 2017-12-01 03:19:36.400394: step 16640, loss = 0.57, batch loss = 0.33 (51.6 examples/sec; 0.155 sec/batch; 13h:36m:14s remains)
INFO - root - 2017-12-01 03:19:37.969306: step 16650, loss = 0.65, batch loss = 0.40 (51.2 examples/sec; 0.156 sec/batch; 13h:42m:13s remains)
INFO - root - 2017-12-01 03:19:39.520757: step 16660, loss = 0.51, batch loss = 0.26 (52.6 examples/sec; 0.152 sec/batch; 13h:20m:28s remains)
INFO - root - 2017-12-01 03:19:41.149382: step 16670, loss = 0.46, batch loss = 0.22 (40.2 examples/sec; 0.199 sec/batch; 17h:27m:19s remains)
INFO - root - 2017-12-01 03:19:42.714379: step 16680, loss = 0.51, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 13h:56m:41s remains)
INFO - root - 2017-12-01 03:19:44.303491: step 16690, loss = 0.64, batch loss = 0.39 (43.0 examples/sec; 0.186 sec/batch; 16h:18m:56s remains)
INFO - root - 2017-12-01 03:19:45.895691: step 16700, loss = 0.58, batch loss = 0.33 (51.8 examples/sec; 0.154 sec/batch; 13h:32m:50s remains)
INFO - root - 2017-12-01 03:19:47.500763: step 16710, loss = 0.64, batch loss = 0.40 (51.2 examples/sec; 0.156 sec/batch; 13h:42m:19s remains)
INFO - root - 2017-12-01 03:19:49.049398: step 16720, loss = 0.55, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 13h:37m:22s remains)
INFO - root - 2017-12-01 03:19:50.642015: step 16730, loss = 0.51, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 13h:39m:53s remains)
INFO - root - 2017-12-01 03:19:52.200171: step 16740, loss = 0.51, batch loss = 0.26 (50.8 examples/sec; 0.157 sec/batch; 13h:48m:27s remains)
INFO - root - 2017-12-01 03:19:53.756034: step 16750, loss = 0.55, batch loss = 0.30 (50.5 examples/sec; 0.159 sec/batch; 13h:54m:18s remains)
INFO - root - 2017-12-01 03:19:55.316580: step 16760, loss = 0.51, batch loss = 0.26 (49.3 examples/sec; 0.162 sec/batch; 14h:14m:40s remains)
INFO - root - 2017-12-01 03:19:56.890050: step 16770, loss = 0.47, batch loss = 0.22 (47.9 examples/sec; 0.167 sec/batch; 14h:38m:19s remains)
INFO - root - 2017-12-01 03:19:58.438896: step 16780, loss = 0.47, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 13h:38m:46s remains)
INFO - root - 2017-12-01 03:20:00.002032: step 16790, loss = 0.52, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 13h:50m:24s remains)
INFO - root - 2017-12-01 03:20:01.557183: step 16800, loss = 0.58, batch loss = 0.34 (49.8 examples/sec; 0.161 sec/batch; 14h:05m:17s remains)
INFO - root - 2017-12-01 03:20:03.168576: step 16810, loss = 0.49, batch loss = 0.24 (52.8 examples/sec; 0.152 sec/batch; 13h:17m:55s remains)
INFO - root - 2017-12-01 03:20:04.733962: step 16820, loss = 0.56, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 13h:49m:56s remains)
INFO - root - 2017-12-01 03:20:06.286371: step 16830, loss = 0.56, batch loss = 0.32 (51.5 examples/sec; 0.155 sec/batch; 13h:37m:09s remains)
INFO - root - 2017-12-01 03:20:07.848557: step 16840, loss = 0.45, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 13h:42m:47s remains)
INFO - root - 2017-12-01 03:20:09.396530: step 16850, loss = 0.52, batch loss = 0.28 (49.8 examples/sec; 0.160 sec/batch; 14h:04m:19s remains)
INFO - root - 2017-12-01 03:20:10.974365: step 16860, loss = 0.50, batch loss = 0.25 (48.6 examples/sec; 0.165 sec/batch; 14h:26m:25s remains)
INFO - root - 2017-12-01 03:20:12.525448: step 16870, loss = 0.47, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 13h:51m:13s remains)
INFO - root - 2017-12-01 03:20:14.086563: step 16880, loss = 0.54, batch loss = 0.29 (53.2 examples/sec; 0.150 sec/batch; 13h:11m:23s remains)
INFO - root - 2017-12-01 03:20:15.632976: step 16890, loss = 0.53, batch loss = 0.29 (50.8 examples/sec; 0.158 sec/batch; 13h:48m:47s remains)
INFO - root - 2017-12-01 03:20:17.188334: step 16900, loss = 0.47, batch loss = 0.22 (49.3 examples/sec; 0.162 sec/batch; 14h:14m:17s remains)
INFO - root - 2017-12-01 03:20:18.862715: step 16910, loss = 0.60, batch loss = 0.36 (52.2 examples/sec; 0.153 sec/batch; 13h:25m:44s remains)
INFO - root - 2017-12-01 03:20:20.459104: step 16920, loss = 0.47, batch loss = 0.23 (49.7 examples/sec; 0.161 sec/batch; 14h:06m:26s remains)
INFO - root - 2017-12-01 03:20:22.023413: step 16930, loss = 0.52, batch loss = 0.27 (53.1 examples/sec; 0.151 sec/batch; 13h:11m:41s remains)
INFO - root - 2017-12-01 03:20:23.595412: step 16940, loss = 0.57, batch loss = 0.33 (50.8 examples/sec; 0.157 sec/batch; 13h:47m:59s remains)
INFO - root - 2017-12-01 03:20:25.175131: step 16950, loss = 0.48, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 13h:56m:50s remains)
INFO - root - 2017-12-01 03:20:26.809214: step 16960, loss = 0.54, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 13h:41m:44s remains)
INFO - root - 2017-12-01 03:20:28.466339: step 16970, loss = 0.53, batch loss = 0.28 (48.4 examples/sec; 0.165 sec/batch; 14h:29m:40s remains)
INFO - root - 2017-12-01 03:20:30.133204: step 16980, loss = 0.52, batch loss = 0.28 (52.2 examples/sec; 0.153 sec/batch; 13h:25m:49s remains)
INFO - root - 2017-12-01 03:20:31.690753: step 16990, loss = 0.53, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 13h:55m:53s remains)
INFO - root - 2017-12-01 03:20:33.258231: step 17000, loss = 0.61, batch loss = 0.36 (51.9 examples/sec; 0.154 sec/batch; 13h:30m:22s remains)
INFO - root - 2017-12-01 03:20:34.919593: step 17010, loss = 0.71, batch loss = 0.47 (47.2 examples/sec; 0.169 sec/batch; 14h:51m:07s remains)
INFO - root - 2017-12-01 03:20:36.477272: step 17020, loss = 0.53, batch loss = 0.28 (52.4 examples/sec; 0.153 sec/batch; 13h:23m:02s remains)
INFO - root - 2017-12-01 03:20:38.035772: step 17030, loss = 0.56, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 13h:47m:07s remains)
INFO - root - 2017-12-01 03:20:39.574909: step 17040, loss = 0.51, batch loss = 0.26 (53.1 examples/sec; 0.151 sec/batch; 13h:12m:27s remains)
INFO - root - 2017-12-01 03:20:41.157516: step 17050, loss = 0.71, batch loss = 0.47 (50.6 examples/sec; 0.158 sec/batch; 13h:51m:43s remains)
INFO - root - 2017-12-01 03:20:42.707161: step 17060, loss = 0.62, batch loss = 0.38 (51.5 examples/sec; 0.155 sec/batch; 13h:36m:01s remains)
INFO - root - 2017-12-01 03:20:44.348793: step 17070, loss = 0.55, batch loss = 0.30 (52.0 examples/sec; 0.154 sec/batch; 13h:28m:09s remains)
INFO - root - 2017-12-01 03:20:45.918115: step 17080, loss = 0.69, batch loss = 0.45 (50.6 examples/sec; 0.158 sec/batch; 13h:51m:17s remains)
INFO - root - 2017-12-01 03:20:47.469856: step 17090, loss = 0.53, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 13h:40m:16s remains)
INFO - root - 2017-12-01 03:20:49.019225: step 17100, loss = 0.39, batch loss = 0.14 (52.6 examples/sec; 0.152 sec/batch; 13h:19m:26s remains)
INFO - root - 2017-12-01 03:20:50.662351: step 17110, loss = 0.48, batch loss = 0.24 (50.8 examples/sec; 0.158 sec/batch; 13h:48m:32s remains)
INFO - root - 2017-12-01 03:20:52.239473: step 17120, loss = 0.59, batch loss = 0.35 (52.5 examples/sec; 0.152 sec/batch; 13h:20m:45s remains)
INFO - root - 2017-12-01 03:20:53.797098: step 17130, loss = 0.50, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 13h:44m:44s remains)
INFO - root - 2017-12-01 03:20:55.363595: step 17140, loss = 0.67, batch loss = 0.42 (52.1 examples/sec; 0.153 sec/batch; 13h:26m:26s remains)
INFO - root - 2017-12-01 03:20:56.925657: step 17150, loss = 0.54, batch loss = 0.30 (49.8 examples/sec; 0.161 sec/batch; 14h:04m:24s remains)
INFO - root - 2017-12-01 03:20:58.531167: step 17160, loss = 0.46, batch loss = 0.22 (52.5 examples/sec; 0.153 sec/batch; 13h:21m:30s remains)
INFO - root - 2017-12-01 03:21:00.090558: step 17170, loss = 0.51, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 13h:39m:33s remains)
INFO - root - 2017-12-01 03:21:01.653989: step 17180, loss = 0.52, batch loss = 0.28 (50.3 examples/sec; 0.159 sec/batch; 13h:55m:29s remains)
INFO - root - 2017-12-01 03:21:03.216968: step 17190, loss = 0.60, batch loss = 0.36 (51.0 examples/sec; 0.157 sec/batch; 13h:45m:02s remains)
INFO - root - 2017-12-01 03:21:04.783515: step 17200, loss = 0.74, batch loss = 0.50 (51.2 examples/sec; 0.156 sec/batch; 13h:41m:53s remains)
INFO - root - 2017-12-01 03:21:06.407910: step 17210, loss = 0.54, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 13h:29m:45s remains)
INFO - root - 2017-12-01 03:21:07.981353: step 17220, loss = 0.63, batch loss = 0.39 (53.3 examples/sec; 0.150 sec/batch; 13h:08m:34s remains)
INFO - root - 2017-12-01 03:21:09.534877: step 17230, loss = 0.49, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 13h:23m:19s remains)
INFO - root - 2017-12-01 03:21:11.097448: step 17240, loss = 0.66, batch loss = 0.42 (51.3 examples/sec; 0.156 sec/batch; 13h:38m:41s remains)
INFO - root - 2017-12-01 03:21:12.648335: step 17250, loss = 0.56, batch loss = 0.31 (52.1 examples/sec; 0.153 sec/batch; 13h:26m:30s remains)
INFO - root - 2017-12-01 03:21:14.216216: step 17260, loss = 0.47, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 13h:38m:18s remains)
INFO - root - 2017-12-01 03:21:15.786719: step 17270, loss = 0.54, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 13h:36m:39s remains)
INFO - root - 2017-12-01 03:21:17.367063: step 17280, loss = 0.64, batch loss = 0.39 (49.4 examples/sec; 0.162 sec/batch; 14h:10m:36s remains)
INFO - root - 2017-12-01 03:21:18.923441: step 17290, loss = 0.50, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 13h:48m:08s remains)
INFO - root - 2017-12-01 03:21:20.483939: step 17300, loss = 0.48, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 13h:39m:07s remains)
INFO - root - 2017-12-01 03:21:22.109816: step 17310, loss = 0.60, batch loss = 0.36 (50.7 examples/sec; 0.158 sec/batch; 13h:48m:47s remains)
INFO - root - 2017-12-01 03:21:23.655459: step 17320, loss = 0.72, batch loss = 0.48 (51.6 examples/sec; 0.155 sec/batch; 13h:34m:41s remains)
INFO - root - 2017-12-01 03:21:25.213856: step 17330, loss = 0.44, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 13h:29m:21s remains)
INFO - root - 2017-12-01 03:21:26.783462: step 17340, loss = 0.57, batch loss = 0.33 (51.4 examples/sec; 0.156 sec/batch; 13h:37m:14s remains)
INFO - root - 2017-12-01 03:21:28.388808: step 17350, loss = 0.53, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 13h:39m:04s remains)
INFO - root - 2017-12-01 03:21:29.943296: step 17360, loss = 0.51, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 13h:34m:23s remains)
INFO - root - 2017-12-01 03:21:31.505453: step 17370, loss = 0.55, batch loss = 0.31 (50.5 examples/sec; 0.159 sec/batch; 13h:52m:28s remains)
INFO - root - 2017-12-01 03:21:33.062417: step 17380, loss = 0.47, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 13h:29m:13s remains)
INFO - root - 2017-12-01 03:21:34.635307: step 17390, loss = 0.61, batch loss = 0.37 (48.3 examples/sec; 0.166 sec/batch; 14h:29m:50s remains)
INFO - root - 2017-12-01 03:21:36.206618: step 17400, loss = 0.52, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 13h:24m:18s remains)
INFO - root - 2017-12-01 03:21:37.803098: step 17410, loss = 0.46, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 13h:38m:00s remains)
INFO - root - 2017-12-01 03:21:39.357126: step 17420, loss = 0.63, batch loss = 0.38 (52.4 examples/sec; 0.153 sec/batch; 13h:20m:58s remains)
INFO - root - 2017-12-01 03:21:40.976974: step 17430, loss = 0.64, batch loss = 0.40 (51.1 examples/sec; 0.157 sec/batch; 13h:41m:49s remains)
INFO - root - 2017-12-01 03:21:42.539555: step 17440, loss = 0.54, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 13h:48m:16s remains)
INFO - root - 2017-12-01 03:21:44.097932: step 17450, loss = 0.47, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 13h:45m:01s remains)
INFO - root - 2017-12-01 03:21:45.656783: step 17460, loss = 0.56, batch loss = 0.32 (51.1 examples/sec; 0.156 sec/batch; 13h:41m:26s remains)
INFO - root - 2017-12-01 03:21:47.218625: step 17470, loss = 0.57, batch loss = 0.33 (53.6 examples/sec; 0.149 sec/batch; 13h:04m:06s remains)
INFO - root - 2017-12-01 03:21:48.808603: step 17480, loss = 0.67, batch loss = 0.43 (50.8 examples/sec; 0.158 sec/batch; 13h:47m:32s remains)
INFO - root - 2017-12-01 03:21:50.421062: step 17490, loss = 0.62, batch loss = 0.38 (38.8 examples/sec; 0.206 sec/batch; 18h:03m:17s remains)
INFO - root - 2017-12-01 03:21:51.986310: step 17500, loss = 0.50, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 13h:50m:28s remains)
INFO - root - 2017-12-01 03:21:53.628417: step 17510, loss = 0.62, batch loss = 0.37 (49.1 examples/sec; 0.163 sec/batch; 14h:14m:49s remains)
INFO - root - 2017-12-01 03:21:55.213002: step 17520, loss = 0.51, batch loss = 0.27 (52.5 examples/sec; 0.152 sec/batch; 13h:20m:13s remains)
INFO - root - 2017-12-01 03:21:56.893939: step 17530, loss = 0.53, batch loss = 0.29 (52.3 examples/sec; 0.153 sec/batch; 13h:22m:33s remains)
INFO - root - 2017-12-01 03:21:58.552506: step 17540, loss = 0.50, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 13h:43m:43s remains)
INFO - root - 2017-12-01 03:22:00.127487: step 17550, loss = 0.55, batch loss = 0.31 (52.7 examples/sec; 0.152 sec/batch; 13h:16m:27s remains)
INFO - root - 2017-12-01 03:22:01.713354: step 17560, loss = 0.62, batch loss = 0.37 (50.7 examples/sec; 0.158 sec/batch; 13h:47m:41s remains)
INFO - root - 2017-12-01 03:22:03.269126: step 17570, loss = 0.50, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 13h:38m:53s remains)
INFO - root - 2017-12-01 03:22:04.858758: step 17580, loss = 0.43, batch loss = 0.18 (48.1 examples/sec; 0.166 sec/batch; 14h:32m:06s remains)
INFO - root - 2017-12-01 03:22:06.459117: step 17590, loss = 0.60, batch loss = 0.36 (47.5 examples/sec; 0.169 sec/batch; 14h:44m:28s remains)
INFO - root - 2017-12-01 03:22:08.084140: step 17600, loss = 0.50, batch loss = 0.26 (51.8 examples/sec; 0.155 sec/batch; 13h:31m:14s remains)
INFO - root - 2017-12-01 03:22:09.693484: step 17610, loss = 0.49, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 13h:34m:11s remains)
INFO - root - 2017-12-01 03:22:11.268404: step 17620, loss = 0.60, batch loss = 0.35 (51.0 examples/sec; 0.157 sec/batch; 13h:43m:46s remains)
INFO - root - 2017-12-01 03:22:12.861398: step 17630, loss = 0.48, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 13h:37m:42s remains)
INFO - root - 2017-12-01 03:22:14.436266: step 17640, loss = 0.55, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 13h:35m:21s remains)
INFO - root - 2017-12-01 03:22:16.022390: step 17650, loss = 0.52, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 13h:39m:43s remains)
INFO - root - 2017-12-01 03:22:17.597647: step 17660, loss = 0.46, batch loss = 0.22 (48.7 examples/sec; 0.164 sec/batch; 14h:21m:28s remains)
INFO - root - 2017-12-01 03:22:19.159266: step 17670, loss = 0.44, batch loss = 0.20 (52.8 examples/sec; 0.152 sec/batch; 13h:15m:03s remains)
INFO - root - 2017-12-01 03:22:20.730107: step 17680, loss = 0.49, batch loss = 0.24 (49.5 examples/sec; 0.162 sec/batch; 14h:08m:18s remains)
INFO - root - 2017-12-01 03:22:22.285392: step 17690, loss = 0.52, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 13h:33m:36s remains)
INFO - root - 2017-12-01 03:22:23.875493: step 17700, loss = 0.55, batch loss = 0.31 (50.0 examples/sec; 0.160 sec/batch; 14h:00m:05s remains)
INFO - root - 2017-12-01 03:22:25.514057: step 17710, loss = 0.55, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 13h:39m:50s remains)
INFO - root - 2017-12-01 03:22:27.079102: step 17720, loss = 0.52, batch loss = 0.28 (49.8 examples/sec; 0.160 sec/batch; 14h:01m:57s remains)
INFO - root - 2017-12-01 03:22:28.634353: step 17730, loss = 0.53, batch loss = 0.29 (50.4 examples/sec; 0.159 sec/batch; 13h:53m:24s remains)
INFO - root - 2017-12-01 03:22:30.193965: step 17740, loss = 0.51, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 13h:43m:40s remains)
INFO - root - 2017-12-01 03:22:31.764315: step 17750, loss = 0.49, batch loss = 0.25 (52.7 examples/sec; 0.152 sec/batch; 13h:16m:19s remains)
INFO - root - 2017-12-01 03:22:33.324630: step 17760, loss = 0.52, batch loss = 0.27 (52.4 examples/sec; 0.153 sec/batch; 13h:20m:06s remains)
INFO - root - 2017-12-01 03:22:34.875250: step 17770, loss = 0.48, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 13h:51m:22s remains)
INFO - root - 2017-12-01 03:22:36.435683: step 17780, loss = 0.51, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 13h:52m:17s remains)
INFO - root - 2017-12-01 03:22:37.998343: step 17790, loss = 0.57, batch loss = 0.33 (48.8 examples/sec; 0.164 sec/batch; 14h:19m:24s remains)
INFO - root - 2017-12-01 03:22:39.608667: step 17800, loss = 0.62, batch loss = 0.37 (51.4 examples/sec; 0.156 sec/batch; 13h:36m:38s remains)
INFO - root - 2017-12-01 03:22:41.250211: step 17810, loss = 0.64, batch loss = 0.40 (51.1 examples/sec; 0.157 sec/batch; 13h:40m:53s remains)
INFO - root - 2017-12-01 03:22:42.829726: step 17820, loss = 0.62, batch loss = 0.38 (51.0 examples/sec; 0.157 sec/batch; 13h:42m:02s remains)
INFO - root - 2017-12-01 03:22:44.437709: step 17830, loss = 0.50, batch loss = 0.25 (52.6 examples/sec; 0.152 sec/batch; 13h:17m:05s remains)
INFO - root - 2017-12-01 03:22:45.991588: step 17840, loss = 0.80, batch loss = 0.56 (52.4 examples/sec; 0.153 sec/batch; 13h:20m:10s remains)
INFO - root - 2017-12-01 03:22:47.574298: step 17850, loss = 0.60, batch loss = 0.36 (50.8 examples/sec; 0.157 sec/batch; 13h:45m:34s remains)
INFO - root - 2017-12-01 03:22:49.123122: step 17860, loss = 0.58, batch loss = 0.34 (50.5 examples/sec; 0.158 sec/batch; 13h:50m:14s remains)
INFO - root - 2017-12-01 03:22:50.704301: step 17870, loss = 0.47, batch loss = 0.23 (50.1 examples/sec; 0.160 sec/batch; 13h:57m:51s remains)
INFO - root - 2017-12-01 03:22:52.258149: step 17880, loss = 0.51, batch loss = 0.26 (51.8 examples/sec; 0.155 sec/batch; 13h:30m:16s remains)
INFO - root - 2017-12-01 03:22:53.827836: step 17890, loss = 0.59, batch loss = 0.35 (52.6 examples/sec; 0.152 sec/batch; 13h:17m:26s remains)
INFO - root - 2017-12-01 03:22:55.389032: step 17900, loss = 0.50, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 13h:26m:16s remains)
INFO - root - 2017-12-01 03:22:57.042707: step 17910, loss = 0.53, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 13h:43m:39s remains)
INFO - root - 2017-12-01 03:22:58.617748: step 17920, loss = 0.59, batch loss = 0.35 (52.1 examples/sec; 0.154 sec/batch; 13h:25m:37s remains)
INFO - root - 2017-12-01 03:23:00.182329: step 17930, loss = 0.56, batch loss = 0.32 (52.0 examples/sec; 0.154 sec/batch; 13h:26m:20s remains)
INFO - root - 2017-12-01 03:23:01.764108: step 17940, loss = 0.51, batch loss = 0.27 (50.4 examples/sec; 0.159 sec/batch; 13h:51m:41s remains)
INFO - root - 2017-12-01 03:23:03.323460: step 17950, loss = 0.48, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 13h:26m:54s remains)
INFO - root - 2017-12-01 03:23:04.867159: step 17960, loss = 0.46, batch loss = 0.22 (51.8 examples/sec; 0.155 sec/batch; 13h:30m:19s remains)
INFO - root - 2017-12-01 03:23:06.480181: step 17970, loss = 0.59, batch loss = 0.35 (49.7 examples/sec; 0.161 sec/batch; 14h:03m:29s remains)
INFO - root - 2017-12-01 03:23:08.073879: step 17980, loss = 0.57, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 13h:46m:54s remains)
INFO - root - 2017-12-01 03:23:09.643185: step 17990, loss = 0.50, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 13h:35m:45s remains)
INFO - root - 2017-12-01 03:23:11.211690: step 18000, loss = 0.48, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 13h:23m:57s remains)
INFO - root - 2017-12-01 03:23:12.813937: step 18010, loss = 0.65, batch loss = 0.41 (50.5 examples/sec; 0.158 sec/batch; 13h:49m:31s remains)
INFO - root - 2017-12-01 03:23:14.383200: step 18020, loss = 0.52, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 13h:35m:50s remains)
INFO - root - 2017-12-01 03:23:15.951888: step 18030, loss = 0.52, batch loss = 0.27 (50.5 examples/sec; 0.158 sec/batch; 13h:49m:55s remains)
INFO - root - 2017-12-01 03:23:17.511724: step 18040, loss = 0.46, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 13h:28m:38s remains)
INFO - root - 2017-12-01 03:23:19.066744: step 18050, loss = 0.44, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 13h:46m:06s remains)
INFO - root - 2017-12-01 03:23:20.625677: step 18060, loss = 0.52, batch loss = 0.28 (50.2 examples/sec; 0.159 sec/batch; 13h:55m:27s remains)
INFO - root - 2017-12-01 03:23:22.191815: step 18070, loss = 0.59, batch loss = 0.35 (48.1 examples/sec; 0.166 sec/batch; 14h:31m:17s remains)
INFO - root - 2017-12-01 03:23:23.767768: step 18080, loss = 0.53, batch loss = 0.29 (52.1 examples/sec; 0.154 sec/batch; 13h:24m:51s remains)
INFO - root - 2017-12-01 03:23:25.334656: step 18090, loss = 0.70, batch loss = 0.46 (52.4 examples/sec; 0.153 sec/batch; 13h:20m:39s remains)
INFO - root - 2017-12-01 03:23:26.909643: step 18100, loss = 0.61, batch loss = 0.37 (48.6 examples/sec; 0.164 sec/batch; 14h:21m:49s remains)
INFO - root - 2017-12-01 03:23:28.587389: step 18110, loss = 0.51, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 13h:41m:42s remains)
INFO - root - 2017-12-01 03:23:30.185614: step 18120, loss = 0.48, batch loss = 0.23 (49.2 examples/sec; 0.163 sec/batch; 14h:11m:31s remains)
INFO - root - 2017-12-01 03:23:31.762318: step 18130, loss = 0.53, batch loss = 0.29 (51.7 examples/sec; 0.155 sec/batch; 13h:30m:11s remains)
INFO - root - 2017-12-01 03:23:33.330807: step 18140, loss = 0.54, batch loss = 0.29 (52.0 examples/sec; 0.154 sec/batch; 13h:26m:37s remains)
INFO - root - 2017-12-01 03:23:34.890890: step 18150, loss = 0.72, batch loss = 0.48 (49.7 examples/sec; 0.161 sec/batch; 14h:03m:30s remains)
INFO - root - 2017-12-01 03:23:36.459454: step 18160, loss = 0.50, batch loss = 0.26 (49.8 examples/sec; 0.161 sec/batch; 14h:01m:10s remains)
INFO - root - 2017-12-01 03:23:38.002762: step 18170, loss = 0.51, batch loss = 0.27 (51.2 examples/sec; 0.156 sec/batch; 13h:39m:21s remains)
INFO - root - 2017-12-01 03:23:39.555457: step 18180, loss = 0.59, batch loss = 0.35 (51.1 examples/sec; 0.157 sec/batch; 13h:40m:02s remains)
INFO - root - 2017-12-01 03:23:41.144403: step 18190, loss = 0.47, batch loss = 0.23 (52.1 examples/sec; 0.154 sec/batch; 13h:24m:42s remains)
INFO - root - 2017-12-01 03:23:42.697288: step 18200, loss = 0.54, batch loss = 0.30 (50.8 examples/sec; 0.158 sec/batch; 13h:45m:44s remains)
INFO - root - 2017-12-01 03:23:44.392953: step 18210, loss = 0.57, batch loss = 0.33 (45.9 examples/sec; 0.174 sec/batch; 15h:13m:33s remains)
INFO - root - 2017-12-01 03:23:45.977423: step 18220, loss = 0.52, batch loss = 0.28 (49.3 examples/sec; 0.162 sec/batch; 14h:10m:13s remains)
INFO - root - 2017-12-01 03:23:47.523260: step 18230, loss = 0.48, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 13h:35m:02s remains)
INFO - root - 2017-12-01 03:23:49.087216: step 18240, loss = 0.50, batch loss = 0.26 (53.1 examples/sec; 0.151 sec/batch; 13h:08m:53s remains)
INFO - root - 2017-12-01 03:23:50.666834: step 18250, loss = 0.73, batch loss = 0.48 (51.2 examples/sec; 0.156 sec/batch; 13h:38m:55s remains)
INFO - root - 2017-12-01 03:23:52.254039: step 18260, loss = 0.43, batch loss = 0.19 (49.8 examples/sec; 0.161 sec/batch; 14h:02m:06s remains)
INFO - root - 2017-12-01 03:23:53.799809: step 18270, loss = 0.53, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 13h:27m:46s remains)
INFO - root - 2017-12-01 03:23:55.388585: step 18280, loss = 0.58, batch loss = 0.34 (51.5 examples/sec; 0.155 sec/batch; 13h:32m:59s remains)
INFO - root - 2017-12-01 03:23:56.946203: step 18290, loss = 0.47, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 13h:36m:48s remains)
INFO - root - 2017-12-01 03:23:58.565417: step 18300, loss = 0.48, batch loss = 0.23 (50.4 examples/sec; 0.159 sec/batch; 13h:51m:44s remains)
INFO - root - 2017-12-01 03:24:00.214826: step 18310, loss = 0.58, batch loss = 0.33 (51.6 examples/sec; 0.155 sec/batch; 13h:32m:23s remains)
INFO - root - 2017-12-01 03:24:01.783924: step 18320, loss = 0.54, batch loss = 0.30 (49.9 examples/sec; 0.160 sec/batch; 13h:58m:48s remains)
INFO - root - 2017-12-01 03:24:03.333514: step 18330, loss = 0.57, batch loss = 0.33 (52.3 examples/sec; 0.153 sec/batch; 13h:21m:28s remains)
INFO - root - 2017-12-01 03:24:04.911204: step 18340, loss = 0.62, batch loss = 0.38 (51.1 examples/sec; 0.156 sec/batch; 13h:39m:06s remains)
INFO - root - 2017-12-01 03:24:06.478266: step 18350, loss = 0.49, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 13h:41m:11s remains)
INFO - root - 2017-12-01 03:24:08.032460: step 18360, loss = 0.60, batch loss = 0.36 (50.4 examples/sec; 0.159 sec/batch; 13h:50m:26s remains)
INFO - root - 2017-12-01 03:24:09.614219: step 18370, loss = 0.64, batch loss = 0.40 (49.9 examples/sec; 0.160 sec/batch; 13h:59m:14s remains)
INFO - root - 2017-12-01 03:24:11.206622: step 18380, loss = 0.48, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 13h:26m:40s remains)
INFO - root - 2017-12-01 03:24:12.763896: step 18390, loss = 0.49, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 13h:40m:26s remains)
INFO - root - 2017-12-01 03:24:14.329628: step 18400, loss = 0.51, batch loss = 0.27 (51.7 examples/sec; 0.155 sec/batch; 13h:29m:33s remains)
INFO - root - 2017-12-01 03:24:15.959957: step 18410, loss = 0.60, batch loss = 0.36 (51.7 examples/sec; 0.155 sec/batch; 13h:29m:35s remains)
INFO - root - 2017-12-01 03:24:17.530363: step 18420, loss = 0.61, batch loss = 0.37 (49.7 examples/sec; 0.161 sec/batch; 14h:01m:49s remains)
INFO - root - 2017-12-01 03:24:19.098173: step 18430, loss = 0.47, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 13h:37m:36s remains)
INFO - root - 2017-12-01 03:24:20.669255: step 18440, loss = 0.56, batch loss = 0.32 (48.9 examples/sec; 0.164 sec/batch; 14h:16m:28s remains)
INFO - root - 2017-12-01 03:24:22.241514: step 18450, loss = 0.52, batch loss = 0.27 (51.8 examples/sec; 0.154 sec/batch; 13h:28m:33s remains)
INFO - root - 2017-12-01 03:24:23.805370: step 18460, loss = 0.56, batch loss = 0.32 (52.2 examples/sec; 0.153 sec/batch; 13h:22m:01s remains)
INFO - root - 2017-12-01 03:24:25.376573: step 18470, loss = 0.45, batch loss = 0.20 (49.7 examples/sec; 0.161 sec/batch; 14h:02m:36s remains)
INFO - root - 2017-12-01 03:24:26.938314: step 18480, loss = 0.54, batch loss = 0.30 (52.0 examples/sec; 0.154 sec/batch; 13h:25m:35s remains)
INFO - root - 2017-12-01 03:24:28.505953: step 18490, loss = 0.60, batch loss = 0.36 (52.3 examples/sec; 0.153 sec/batch; 13h:21m:01s remains)
INFO - root - 2017-12-01 03:24:30.064364: step 18500, loss = 0.55, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 13h:32m:41s remains)
INFO - root - 2017-12-01 03:24:31.707503: step 18510, loss = 0.43, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 13h:44m:53s remains)
INFO - root - 2017-12-01 03:24:33.277503: step 18520, loss = 0.53, batch loss = 0.28 (50.8 examples/sec; 0.157 sec/batch; 13h:43m:35s remains)
INFO - root - 2017-12-01 03:24:34.852445: step 18530, loss = 0.56, batch loss = 0.31 (51.8 examples/sec; 0.154 sec/batch; 13h:27m:32s remains)
INFO - root - 2017-12-01 03:24:36.410391: step 18540, loss = 0.44, batch loss = 0.20 (49.2 examples/sec; 0.162 sec/batch; 14h:10m:09s remains)
INFO - root - 2017-12-01 03:24:37.984855: step 18550, loss = 0.60, batch loss = 0.36 (51.0 examples/sec; 0.157 sec/batch; 13h:41m:29s remains)
INFO - root - 2017-12-01 03:24:39.533957: step 18560, loss = 0.57, batch loss = 0.33 (51.4 examples/sec; 0.155 sec/batch; 13h:33m:36s remains)
INFO - root - 2017-12-01 03:24:41.095643: step 18570, loss = 0.51, batch loss = 0.27 (52.4 examples/sec; 0.153 sec/batch; 13h:18m:11s remains)
INFO - root - 2017-12-01 03:24:42.649326: step 18580, loss = 0.50, batch loss = 0.25 (52.4 examples/sec; 0.153 sec/batch; 13h:18m:11s remains)
INFO - root - 2017-12-01 03:24:44.203524: step 18590, loss = 0.43, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 13h:26m:51s remains)
INFO - root - 2017-12-01 03:24:45.775632: step 18600, loss = 0.47, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 13h:53m:15s remains)
INFO - root - 2017-12-01 03:24:47.407823: step 18610, loss = 0.51, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 13h:47m:37s remains)
INFO - root - 2017-12-01 03:24:48.984117: step 18620, loss = 0.47, batch loss = 0.23 (52.1 examples/sec; 0.154 sec/batch; 13h:24m:01s remains)
INFO - root - 2017-12-01 03:24:50.541461: step 18630, loss = 0.66, batch loss = 0.42 (50.8 examples/sec; 0.158 sec/batch; 13h:44m:13s remains)
INFO - root - 2017-12-01 03:24:52.099771: step 18640, loss = 0.52, batch loss = 0.28 (49.9 examples/sec; 0.160 sec/batch; 13h:58m:25s remains)
INFO - root - 2017-12-01 03:24:53.670731: step 18650, loss = 0.56, batch loss = 0.32 (50.3 examples/sec; 0.159 sec/batch; 13h:51m:55s remains)
INFO - root - 2017-12-01 03:24:55.244864: step 18660, loss = 0.46, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 13h:22m:22s remains)
INFO - root - 2017-12-01 03:24:56.842112: step 18670, loss = 0.52, batch loss = 0.28 (50.4 examples/sec; 0.159 sec/batch; 13h:49m:50s remains)
INFO - root - 2017-12-01 03:24:58.402696: step 18680, loss = 0.42, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 13h:33m:37s remains)
INFO - root - 2017-12-01 03:24:59.970705: step 18690, loss = 0.52, batch loss = 0.28 (48.6 examples/sec; 0.164 sec/batch; 14h:20m:11s remains)
INFO - root - 2017-12-01 03:25:01.535603: step 18700, loss = 0.46, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 13h:44m:08s remains)
INFO - root - 2017-12-01 03:25:03.173065: step 18710, loss = 0.51, batch loss = 0.26 (50.0 examples/sec; 0.160 sec/batch; 13h:57m:09s remains)
INFO - root - 2017-12-01 03:25:04.743128: step 18720, loss = 0.51, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 13h:42m:04s remains)
INFO - root - 2017-12-01 03:25:06.305900: step 18730, loss = 0.44, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 13h:25m:08s remains)
INFO - root - 2017-12-01 03:25:07.874657: step 18740, loss = 0.50, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 13h:27m:17s remains)
INFO - root - 2017-12-01 03:25:09.434757: step 18750, loss = 0.44, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 13h:51m:21s remains)
INFO - root - 2017-12-01 03:25:11.011190: step 18760, loss = 0.47, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 13h:21m:16s remains)
INFO - root - 2017-12-01 03:25:12.578427: step 18770, loss = 0.58, batch loss = 0.34 (52.4 examples/sec; 0.153 sec/batch; 13h:18m:33s remains)
INFO - root - 2017-12-01 03:25:14.136676: step 18780, loss = 0.47, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 13h:41m:50s remains)
INFO - root - 2017-12-01 03:25:15.688748: step 18790, loss = 0.59, batch loss = 0.35 (50.8 examples/sec; 0.158 sec/batch; 13h:43m:35s remains)
INFO - root - 2017-12-01 03:25:17.267570: step 18800, loss = 0.53, batch loss = 0.29 (48.8 examples/sec; 0.164 sec/batch; 14h:17m:09s remains)
INFO - root - 2017-12-01 03:25:18.925078: step 18810, loss = 0.76, batch loss = 0.52 (50.0 examples/sec; 0.160 sec/batch; 13h:56m:03s remains)
INFO - root - 2017-12-01 03:25:20.482627: step 18820, loss = 0.57, batch loss = 0.33 (50.0 examples/sec; 0.160 sec/batch; 13h:56m:45s remains)
INFO - root - 2017-12-01 03:25:22.026608: step 18830, loss = 0.46, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 13h:26m:45s remains)
INFO - root - 2017-12-01 03:25:23.595924: step 18840, loss = 0.49, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 13h:39m:14s remains)
INFO - root - 2017-12-01 03:25:25.157208: step 18850, loss = 0.53, batch loss = 0.29 (50.0 examples/sec; 0.160 sec/batch; 13h:57m:05s remains)
INFO - root - 2017-12-01 03:25:26.762989: step 18860, loss = 0.61, batch loss = 0.37 (50.1 examples/sec; 0.160 sec/batch; 13h:53m:56s remains)
INFO - root - 2017-12-01 03:25:28.358403: step 18870, loss = 0.57, batch loss = 0.33 (49.6 examples/sec; 0.161 sec/batch; 14h:02m:23s remains)
INFO - root - 2017-12-01 03:25:29.931564: step 18880, loss = 0.54, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 13h:33m:21s remains)
INFO - root - 2017-12-01 03:25:31.497239: step 18890, loss = 0.47, batch loss = 0.23 (50.8 examples/sec; 0.157 sec/batch; 13h:42m:50s remains)
INFO - root - 2017-12-01 03:25:33.072930: step 18900, loss = 0.69, batch loss = 0.45 (48.7 examples/sec; 0.164 sec/batch; 14h:18m:27s remains)
INFO - root - 2017-12-01 03:25:34.712965: step 18910, loss = 0.55, batch loss = 0.31 (50.7 examples/sec; 0.158 sec/batch; 13h:44m:51s remains)
INFO - root - 2017-12-01 03:25:36.289249: step 18920, loss = 0.50, batch loss = 0.26 (49.9 examples/sec; 0.160 sec/batch; 13h:57m:17s remains)
INFO - root - 2017-12-01 03:25:37.861613: step 18930, loss = 0.60, batch loss = 0.36 (52.2 examples/sec; 0.153 sec/batch; 13h:20m:16s remains)
INFO - root - 2017-12-01 03:25:39.431142: step 18940, loss = 0.56, batch loss = 0.32 (46.6 examples/sec; 0.172 sec/batch; 14h:57m:29s remains)
INFO - root - 2017-12-01 03:25:40.997385: step 18950, loss = 0.51, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 13h:48m:59s remains)
INFO - root - 2017-12-01 03:25:42.564546: step 18960, loss = 0.63, batch loss = 0.39 (50.9 examples/sec; 0.157 sec/batch; 13h:41m:46s remains)
INFO - root - 2017-12-01 03:25:44.108460: step 18970, loss = 0.49, batch loss = 0.25 (52.7 examples/sec; 0.152 sec/batch; 13h:13m:40s remains)
INFO - root - 2017-12-01 03:25:45.669455: step 18980, loss = 0.46, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 13h:34m:54s remains)
INFO - root - 2017-12-01 03:25:47.250173: step 18990, loss = 0.45, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 13h:42m:46s remains)
INFO - root - 2017-12-01 03:25:48.841386: step 19000, loss = 0.50, batch loss = 0.26 (50.1 examples/sec; 0.160 sec/batch; 13h:54m:04s remains)
INFO - root - 2017-12-01 03:25:50.504249: step 19010, loss = 0.50, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 13h:36m:46s remains)
INFO - root - 2017-12-01 03:25:52.057141: step 19020, loss = 0.52, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 13h:43m:37s remains)
INFO - root - 2017-12-01 03:25:53.629333: step 19030, loss = 0.44, batch loss = 0.20 (49.2 examples/sec; 0.163 sec/batch; 14h:09m:27s remains)
INFO - root - 2017-12-01 03:25:55.199256: step 19040, loss = 0.53, batch loss = 0.28 (50.4 examples/sec; 0.159 sec/batch; 13h:49m:30s remains)
INFO - root - 2017-12-01 03:25:56.761962: step 19050, loss = 0.49, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 13h:39m:19s remains)
INFO - root - 2017-12-01 03:25:58.317528: step 19060, loss = 0.44, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 13h:22m:14s remains)
INFO - root - 2017-12-01 03:25:59.886060: step 19070, loss = 0.44, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 13h:31m:40s remains)
INFO - root - 2017-12-01 03:26:01.446123: step 19080, loss = 0.64, batch loss = 0.39 (50.6 examples/sec; 0.158 sec/batch; 13h:45m:59s remains)
INFO - root - 2017-12-01 03:26:03.008664: step 19090, loss = 0.48, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 13h:31m:47s remains)
INFO - root - 2017-12-01 03:26:04.593922: step 19100, loss = 0.58, batch loss = 0.34 (51.3 examples/sec; 0.156 sec/batch; 13h:33m:52s remains)
INFO - root - 2017-12-01 03:26:06.215408: step 19110, loss = 0.53, batch loss = 0.28 (49.1 examples/sec; 0.163 sec/batch; 14h:10m:32s remains)
INFO - root - 2017-12-01 03:26:07.794417: step 19120, loss = 0.62, batch loss = 0.38 (45.6 examples/sec; 0.175 sec/batch; 15h:15m:53s remains)
INFO - root - 2017-12-01 03:26:09.370715: step 19130, loss = 0.55, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 13h:36m:25s remains)
INFO - root - 2017-12-01 03:26:10.949170: step 19140, loss = 0.50, batch loss = 0.26 (48.9 examples/sec; 0.164 sec/batch; 14h:14m:34s remains)
INFO - root - 2017-12-01 03:26:12.515190: step 19150, loss = 0.52, batch loss = 0.28 (50.1 examples/sec; 0.160 sec/batch; 13h:53m:37s remains)
INFO - root - 2017-12-01 03:26:14.073339: step 19160, loss = 0.60, batch loss = 0.36 (51.6 examples/sec; 0.155 sec/batch; 13h:30m:07s remains)
INFO - root - 2017-12-01 03:26:15.655455: step 19170, loss = 0.46, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 13h:46m:28s remains)
INFO - root - 2017-12-01 03:26:17.215876: step 19180, loss = 0.47, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 13h:37m:42s remains)
INFO - root - 2017-12-01 03:26:18.763798: step 19190, loss = 0.47, batch loss = 0.23 (51.8 examples/sec; 0.155 sec/batch; 13h:27m:09s remains)
INFO - root - 2017-12-01 03:26:20.320248: step 19200, loss = 0.45, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 13h:20m:37s remains)
INFO - root - 2017-12-01 03:26:21.936354: step 19210, loss = 0.55, batch loss = 0.31 (50.4 examples/sec; 0.159 sec/batch; 13h:48m:09s remains)
INFO - root - 2017-12-01 03:26:23.500744: step 19220, loss = 0.80, batch loss = 0.56 (50.1 examples/sec; 0.160 sec/batch; 13h:53m:13s remains)
INFO - root - 2017-12-01 03:26:25.071356: step 19230, loss = 0.51, batch loss = 0.27 (49.9 examples/sec; 0.160 sec/batch; 13h:56m:34s remains)
INFO - root - 2017-12-01 03:26:26.634090: step 19240, loss = 0.47, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 13h:27m:51s remains)
INFO - root - 2017-12-01 03:26:28.206360: step 19250, loss = 0.50, batch loss = 0.26 (50.1 examples/sec; 0.160 sec/batch; 13h:52m:57s remains)
INFO - root - 2017-12-01 03:26:29.770754: step 19260, loss = 0.47, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 13h:34m:47s remains)
INFO - root - 2017-12-01 03:26:31.331310: step 19270, loss = 0.50, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 13h:30m:16s remains)
INFO - root - 2017-12-01 03:26:32.904344: step 19280, loss = 0.57, batch loss = 0.33 (51.0 examples/sec; 0.157 sec/batch; 13h:39m:36s remains)
INFO - root - 2017-12-01 03:26:34.481431: step 19290, loss = 0.47, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 13h:32m:09s remains)
INFO - root - 2017-12-01 03:26:36.033378: step 19300, loss = 0.53, batch loss = 0.29 (53.1 examples/sec; 0.151 sec/batch; 13h:06m:52s remains)
INFO - root - 2017-12-01 03:26:37.651232: step 19310, loss = 0.53, batch loss = 0.29 (49.6 examples/sec; 0.161 sec/batch; 14h:01m:38s remains)
INFO - root - 2017-12-01 03:26:39.235184: step 19320, loss = 0.48, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 13h:28m:26s remains)
INFO - root - 2017-12-01 03:26:40.795846: step 19330, loss = 0.57, batch loss = 0.33 (51.5 examples/sec; 0.155 sec/batch; 13h:30m:02s remains)
INFO - root - 2017-12-01 03:26:42.377799: step 19340, loss = 0.45, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 13h:51m:46s remains)
INFO - root - 2017-12-01 03:26:43.946598: step 19350, loss = 0.44, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 13h:56m:37s remains)
INFO - root - 2017-12-01 03:26:45.515739: step 19360, loss = 0.57, batch loss = 0.33 (53.1 examples/sec; 0.151 sec/batch; 13h:06m:30s remains)
INFO - root - 2017-12-01 03:26:47.088196: step 19370, loss = 0.52, batch loss = 0.28 (50.8 examples/sec; 0.157 sec/batch; 13h:41m:51s remains)
INFO - root - 2017-12-01 03:26:48.685141: step 19380, loss = 0.52, batch loss = 0.28 (48.7 examples/sec; 0.164 sec/batch; 14h:17m:26s remains)
INFO - root - 2017-12-01 03:26:50.234860: step 19390, loss = 0.46, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 13h:42m:30s remains)
INFO - root - 2017-12-01 03:26:51.780677: step 19400, loss = 0.51, batch loss = 0.27 (52.1 examples/sec; 0.153 sec/batch; 13h:20m:46s remains)
INFO - root - 2017-12-01 03:26:53.385772: step 19410, loss = 0.52, batch loss = 0.28 (52.3 examples/sec; 0.153 sec/batch; 13h:18m:11s remains)
INFO - root - 2017-12-01 03:26:54.955691: step 19420, loss = 0.50, batch loss = 0.26 (49.7 examples/sec; 0.161 sec/batch; 14h:00m:21s remains)
INFO - root - 2017-12-01 03:26:56.528622: step 19430, loss = 0.46, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 13h:40m:22s remains)
INFO - root - 2017-12-01 03:26:58.100097: step 19440, loss = 0.58, batch loss = 0.34 (52.0 examples/sec; 0.154 sec/batch; 13h:23m:06s remains)
INFO - root - 2017-12-01 03:26:59.656432: step 19450, loss = 0.54, batch loss = 0.30 (51.6 examples/sec; 0.155 sec/batch; 13h:29m:34s remains)
INFO - root - 2017-12-01 03:27:01.228008: step 19460, loss = 0.53, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 13h:33m:39s remains)
INFO - root - 2017-12-01 03:27:02.785387: step 19470, loss = 0.51, batch loss = 0.27 (50.8 examples/sec; 0.157 sec/batch; 13h:41m:07s remains)
INFO - root - 2017-12-01 03:27:04.350496: step 19480, loss = 0.61, batch loss = 0.37 (50.0 examples/sec; 0.160 sec/batch; 13h:55m:02s remains)
INFO - root - 2017-12-01 03:27:05.937941: step 19490, loss = 0.58, batch loss = 0.34 (49.9 examples/sec; 0.160 sec/batch; 13h:56m:02s remains)
INFO - root - 2017-12-01 03:27:07.490141: step 19500, loss = 0.49, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 13h:25m:26s remains)
INFO - root - 2017-12-01 03:27:09.109980: step 19510, loss = 0.48, batch loss = 0.24 (49.3 examples/sec; 0.162 sec/batch; 14h:06m:12s remains)
INFO - root - 2017-12-01 03:27:10.694611: step 19520, loss = 0.67, batch loss = 0.43 (49.7 examples/sec; 0.161 sec/batch; 13h:59m:52s remains)
INFO - root - 2017-12-01 03:27:12.249744: step 19530, loss = 0.64, batch loss = 0.40 (51.7 examples/sec; 0.155 sec/batch; 13h:27m:31s remains)
INFO - root - 2017-12-01 03:27:13.825197: step 19540, loss = 0.57, batch loss = 0.34 (51.6 examples/sec; 0.155 sec/batch; 13h:28m:07s remains)
INFO - root - 2017-12-01 03:27:15.388130: step 19550, loss = 0.45, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 13h:38m:05s remains)
INFO - root - 2017-12-01 03:27:16.963414: step 19560, loss = 0.43, batch loss = 0.19 (50.3 examples/sec; 0.159 sec/batch; 13h:49m:47s remains)
INFO - root - 2017-12-01 03:27:18.556788: step 19570, loss = 0.55, batch loss = 0.31 (51.8 examples/sec; 0.154 sec/batch; 13h:25m:19s remains)
INFO - root - 2017-12-01 03:27:20.135031: step 19580, loss = 0.48, batch loss = 0.24 (50.2 examples/sec; 0.159 sec/batch; 13h:50m:50s remains)
INFO - root - 2017-12-01 03:27:21.708914: step 19590, loss = 0.62, batch loss = 0.38 (50.7 examples/sec; 0.158 sec/batch; 13h:42m:23s remains)
INFO - root - 2017-12-01 03:27:23.266225: step 19600, loss = 0.66, batch loss = 0.42 (51.8 examples/sec; 0.154 sec/batch; 13h:25m:28s remains)
INFO - root - 2017-12-01 03:27:24.881166: step 19610, loss = 0.46, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 13h:37m:40s remains)
INFO - root - 2017-12-01 03:27:26.449154: step 19620, loss = 0.53, batch loss = 0.29 (51.8 examples/sec; 0.155 sec/batch; 13h:25m:58s remains)
INFO - root - 2017-12-01 03:27:28.005786: step 19630, loss = 0.73, batch loss = 0.49 (50.4 examples/sec; 0.159 sec/batch; 13h:47m:24s remains)
INFO - root - 2017-12-01 03:27:29.556417: step 19640, loss = 0.75, batch loss = 0.51 (52.6 examples/sec; 0.152 sec/batch; 13h:13m:27s remains)
INFO - root - 2017-12-01 03:27:31.137225: step 19650, loss = 0.54, batch loss = 0.30 (50.8 examples/sec; 0.158 sec/batch; 13h:41m:49s remains)
INFO - root - 2017-12-01 03:27:32.701025: step 19660, loss = 0.46, batch loss = 0.22 (49.8 examples/sec; 0.160 sec/batch; 13h:56m:46s remains)
INFO - root - 2017-12-01 03:27:34.269387: step 19670, loss = 0.47, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 13h:29m:27s remains)
INFO - root - 2017-12-01 03:27:35.853078: step 19680, loss = 0.59, batch loss = 0.35 (51.5 examples/sec; 0.155 sec/batch; 13h:29m:42s remains)
INFO - root - 2017-12-01 03:27:37.452782: step 19690, loss = 0.46, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 13h:36m:47s remains)
INFO - root - 2017-12-01 03:27:39.010852: step 19700, loss = 0.50, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 13h:29m:57s remains)
INFO - root - 2017-12-01 03:27:40.636477: step 19710, loss = 0.56, batch loss = 0.32 (51.9 examples/sec; 0.154 sec/batch; 13h:24m:07s remains)
INFO - root - 2017-12-01 03:27:42.441786: step 19720, loss = 0.50, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 13h:45m:12s remains)
INFO - root - 2017-12-01 03:27:43.990887: step 19730, loss = 0.55, batch loss = 0.31 (53.0 examples/sec; 0.151 sec/batch; 13h:06m:08s remains)
INFO - root - 2017-12-01 03:27:45.585153: step 19740, loss = 0.50, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 13h:39m:52s remains)
INFO - root - 2017-12-01 03:27:47.172845: step 19750, loss = 0.52, batch loss = 0.28 (50.1 examples/sec; 0.160 sec/batch; 13h:52m:48s remains)
INFO - root - 2017-12-01 03:27:48.732760: step 19760, loss = 0.48, batch loss = 0.24 (53.3 examples/sec; 0.150 sec/batch; 13h:02m:47s remains)
INFO - root - 2017-12-01 03:27:50.302685: step 19770, loss = 0.46, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 13h:47m:02s remains)
INFO - root - 2017-12-01 03:27:51.871492: step 19780, loss = 0.51, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 13h:38m:19s remains)
INFO - root - 2017-12-01 03:27:53.426579: step 19790, loss = 0.65, batch loss = 0.41 (50.3 examples/sec; 0.159 sec/batch; 13h:49m:18s remains)
INFO - root - 2017-12-01 03:27:54.971674: step 19800, loss = 0.48, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 13h:16m:39s remains)
INFO - root - 2017-12-01 03:27:56.627115: step 19810, loss = 0.64, batch loss = 0.40 (48.3 examples/sec; 0.166 sec/batch; 14h:23m:51s remains)
INFO - root - 2017-12-01 03:27:58.172370: step 19820, loss = 0.54, batch loss = 0.30 (50.5 examples/sec; 0.158 sec/batch; 13h:44m:54s remains)
INFO - root - 2017-12-01 03:27:59.727204: step 19830, loss = 0.45, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 13h:49m:19s remains)
INFO - root - 2017-12-01 03:28:01.290359: step 19840, loss = 0.47, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 13h:39m:11s remains)
INFO - root - 2017-12-01 03:28:02.865431: step 19850, loss = 0.57, batch loss = 0.33 (51.6 examples/sec; 0.155 sec/batch; 13h:28m:21s remains)
INFO - root - 2017-12-01 03:28:04.416694: step 19860, loss = 0.56, batch loss = 0.32 (52.6 examples/sec; 0.152 sec/batch; 13h:13m:07s remains)
INFO - root - 2017-12-01 03:28:05.998191: step 19870, loss = 0.50, batch loss = 0.26 (49.4 examples/sec; 0.162 sec/batch; 14h:03m:13s remains)
INFO - root - 2017-12-01 03:28:07.569176: step 19880, loss = 0.53, batch loss = 0.29 (51.4 examples/sec; 0.156 sec/batch; 13h:30m:56s remains)
INFO - root - 2017-12-01 03:28:09.139908: step 19890, loss = 0.53, batch loss = 0.30 (51.9 examples/sec; 0.154 sec/batch; 13h:23m:25s remains)
INFO - root - 2017-12-01 03:28:10.692209: step 19900, loss = 0.55, batch loss = 0.31 (51.9 examples/sec; 0.154 sec/batch; 13h:23m:18s remains)
INFO - root - 2017-12-01 03:28:12.309921: step 19910, loss = 0.52, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 13h:42m:40s remains)
INFO - root - 2017-12-01 03:28:13.868859: step 19920, loss = 0.57, batch loss = 0.33 (51.9 examples/sec; 0.154 sec/batch; 13h:22m:34s remains)
INFO - root - 2017-12-01 03:28:15.438245: step 19930, loss = 0.53, batch loss = 0.29 (52.8 examples/sec; 0.152 sec/batch; 13h:09m:45s remains)
INFO - root - 2017-12-01 03:28:17.007051: step 19940, loss = 0.51, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 13h:21m:01s remains)
INFO - root - 2017-12-01 03:28:18.581671: step 19950, loss = 0.49, batch loss = 0.25 (52.1 examples/sec; 0.154 sec/batch; 13h:20m:29s remains)
INFO - root - 2017-12-01 03:28:20.126706: step 19960, loss = 0.48, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 13h:48m:19s remains)
INFO - root - 2017-12-01 03:28:21.764033: step 19970, loss = 0.54, batch loss = 0.30 (52.6 examples/sec; 0.152 sec/batch; 13h:12m:27s remains)
INFO - root - 2017-12-01 03:28:23.315872: step 19980, loss = 0.49, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 13h:27m:24s remains)
INFO - root - 2017-12-01 03:28:24.872280: step 19990, loss = 0.47, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 13h:47m:52s remains)
INFO - root - 2017-12-01 03:28:26.438566: step 20000, loss = 0.56, batch loss = 0.32 (50.9 examples/sec; 0.157 sec/batch; 13h:38m:21s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-20000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-20000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-01 03:28:28.335567: step 20010, loss = 0.52, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 13h:30m:53s remains)
INFO - root - 2017-12-01 03:28:29.930574: step 20020, loss = 0.50, batch loss = 0.26 (50.8 examples/sec; 0.157 sec/batch; 13h:39m:44s remains)
INFO - root - 2017-12-01 03:28:31.486986: step 20030, loss = 0.47, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 13h:36m:09s remains)
INFO - root - 2017-12-01 03:28:33.046708: step 20040, loss = 0.55, batch loss = 0.31 (49.6 examples/sec; 0.161 sec/batch; 14h:00m:13s remains)
INFO - root - 2017-12-01 03:28:34.612715: step 20050, loss = 0.50, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 13h:21m:49s remains)
INFO - root - 2017-12-01 03:28:36.194844: step 20060, loss = 0.51, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 13h:36m:23s remains)
INFO - root - 2017-12-01 03:28:37.754209: step 20070, loss = 0.49, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 13h:34m:01s remains)
INFO - root - 2017-12-01 03:28:39.349058: step 20080, loss = 0.43, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 13h:51m:18s remains)
INFO - root - 2017-12-01 03:28:40.935004: step 20090, loss = 0.69, batch loss = 0.45 (51.6 examples/sec; 0.155 sec/batch; 13h:27m:59s remains)
INFO - root - 2017-12-01 03:28:42.562099: step 20100, loss = 0.63, batch loss = 0.40 (53.6 examples/sec; 0.149 sec/batch; 12h:57m:08s remains)
INFO - root - 2017-12-01 03:28:44.196625: step 20110, loss = 0.48, batch loss = 0.24 (52.8 examples/sec; 0.152 sec/batch; 13h:09m:13s remains)
INFO - root - 2017-12-01 03:28:45.762706: step 20120, loss = 0.48, batch loss = 0.24 (50.8 examples/sec; 0.158 sec/batch; 13h:40m:08s remains)
INFO - root - 2017-12-01 03:28:47.341609: step 20130, loss = 0.66, batch loss = 0.42 (50.8 examples/sec; 0.157 sec/batch; 13h:39m:51s remains)
INFO - root - 2017-12-01 03:28:48.900238: step 20140, loss = 0.68, batch loss = 0.44 (51.9 examples/sec; 0.154 sec/batch; 13h:23m:00s remains)
INFO - root - 2017-12-01 03:28:50.472246: step 20150, loss = 0.48, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 13h:35m:12s remains)
INFO - root - 2017-12-01 03:28:52.074095: step 20160, loss = 0.44, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 13h:52m:54s remains)
INFO - root - 2017-12-01 03:28:53.627709: step 20170, loss = 0.66, batch loss = 0.42 (50.0 examples/sec; 0.160 sec/batch; 13h:53m:02s remains)
INFO - root - 2017-12-01 03:28:55.211452: step 20180, loss = 0.45, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 13h:35m:10s remains)
INFO - root - 2017-12-01 03:28:56.780803: step 20190, loss = 0.49, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 13h:37m:44s remains)
INFO - root - 2017-12-01 03:28:58.460392: step 20200, loss = 0.51, batch loss = 0.27 (52.5 examples/sec; 0.152 sec/batch; 13h:12m:44s remains)
INFO - root - 2017-12-01 03:29:00.092667: step 20210, loss = 0.54, batch loss = 0.30 (49.1 examples/sec; 0.163 sec/batch; 14h:07m:35s remains)
INFO - root - 2017-12-01 03:29:01.659642: step 20220, loss = 0.52, batch loss = 0.28 (47.6 examples/sec; 0.168 sec/batch; 14h:34m:52s remains)
INFO - root - 2017-12-01 03:29:03.259271: step 20230, loss = 0.58, batch loss = 0.34 (50.3 examples/sec; 0.159 sec/batch; 13h:48m:17s remains)
INFO - root - 2017-12-01 03:29:04.886032: step 20240, loss = 0.47, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 13h:11m:59s remains)
INFO - root - 2017-12-01 03:29:06.445714: step 20250, loss = 0.64, batch loss = 0.40 (51.8 examples/sec; 0.155 sec/batch; 13h:24m:04s remains)
INFO - root - 2017-12-01 03:29:08.089088: step 20260, loss = 0.42, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 13h:53m:31s remains)
INFO - root - 2017-12-01 03:29:09.672286: step 20270, loss = 0.58, batch loss = 0.35 (51.6 examples/sec; 0.155 sec/batch; 13h:26m:32s remains)
INFO - root - 2017-12-01 03:29:11.243105: step 20280, loss = 0.70, batch loss = 0.46 (50.6 examples/sec; 0.158 sec/batch; 13h:41m:56s remains)
INFO - root - 2017-12-01 03:29:12.805140: step 20290, loss = 0.51, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 13h:40m:52s remains)
INFO - root - 2017-12-01 03:29:14.351903: step 20300, loss = 0.59, batch loss = 0.35 (52.7 examples/sec; 0.152 sec/batch; 13h:10m:02s remains)
INFO - root - 2017-12-01 03:29:15.965292: step 20310, loss = 0.52, batch loss = 0.28 (52.4 examples/sec; 0.153 sec/batch; 13h:14m:00s remains)
INFO - root - 2017-12-01 03:29:17.527269: step 20320, loss = 0.64, batch loss = 0.41 (50.4 examples/sec; 0.159 sec/batch; 13h:46m:26s remains)
INFO - root - 2017-12-01 03:29:19.096951: step 20330, loss = 0.58, batch loss = 0.35 (51.3 examples/sec; 0.156 sec/batch; 13h:31m:15s remains)
INFO - root - 2017-12-01 03:29:20.650888: step 20340, loss = 0.49, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 13h:09m:16s remains)
INFO - root - 2017-12-01 03:29:22.218875: step 20350, loss = 0.45, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 13h:16m:28s remains)
INFO - root - 2017-12-01 03:29:23.777849: step 20360, loss = 0.51, batch loss = 0.28 (52.2 examples/sec; 0.153 sec/batch; 13h:17m:38s remains)
INFO - root - 2017-12-01 03:29:25.355912: step 20370, loss = 0.43, batch loss = 0.19 (49.3 examples/sec; 0.162 sec/batch; 14h:04m:07s remains)
INFO - root - 2017-12-01 03:29:26.923918: step 20380, loss = 0.43, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 13h:53m:00s remains)
INFO - root - 2017-12-01 03:29:28.491162: step 20390, loss = 0.66, batch loss = 0.42 (49.6 examples/sec; 0.161 sec/batch; 13h:59m:12s remains)
INFO - root - 2017-12-01 03:29:30.066249: step 20400, loss = 0.53, batch loss = 0.29 (50.6 examples/sec; 0.158 sec/batch; 13h:41m:52s remains)
INFO - root - 2017-12-01 03:29:31.690764: step 20410, loss = 0.53, batch loss = 0.30 (49.8 examples/sec; 0.161 sec/batch; 13h:55m:32s remains)
INFO - root - 2017-12-01 03:29:33.270862: step 20420, loss = 0.54, batch loss = 0.30 (51.8 examples/sec; 0.154 sec/batch; 13h:22m:46s remains)
INFO - root - 2017-12-01 03:29:34.828454: step 20430, loss = 0.54, batch loss = 0.30 (50.8 examples/sec; 0.157 sec/batch; 13h:38m:44s remains)
INFO - root - 2017-12-01 03:29:36.481020: step 20440, loss = 0.56, batch loss = 0.33 (52.4 examples/sec; 0.153 sec/batch; 13h:14m:14s remains)
INFO - root - 2017-12-01 03:29:38.031251: step 20450, loss = 0.52, batch loss = 0.29 (52.8 examples/sec; 0.152 sec/batch; 13h:08m:43s remains)
INFO - root - 2017-12-01 03:29:39.593667: step 20460, loss = 0.48, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 13h:43m:53s remains)
INFO - root - 2017-12-01 03:29:41.194082: step 20470, loss = 0.44, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 13h:45m:08s remains)
INFO - root - 2017-12-01 03:29:42.754679: step 20480, loss = 0.63, batch loss = 0.39 (49.4 examples/sec; 0.162 sec/batch; 14h:02m:54s remains)
INFO - root - 2017-12-01 03:29:44.380051: step 20490, loss = 0.57, batch loss = 0.33 (51.8 examples/sec; 0.154 sec/batch; 13h:23m:10s remains)
INFO - root - 2017-12-01 03:29:45.956957: step 20500, loss = 0.53, batch loss = 0.29 (49.5 examples/sec; 0.162 sec/batch; 14h:00m:20s remains)
INFO - root - 2017-12-01 03:29:47.621484: step 20510, loss = 0.50, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 13h:34m:28s remains)
INFO - root - 2017-12-01 03:29:49.212800: step 20520, loss = 0.45, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 13h:24m:50s remains)
INFO - root - 2017-12-01 03:29:50.779215: step 20530, loss = 0.51, batch loss = 0.27 (53.0 examples/sec; 0.151 sec/batch; 13h:05m:17s remains)
INFO - root - 2017-12-01 03:29:52.344312: step 20540, loss = 0.46, batch loss = 0.23 (53.1 examples/sec; 0.151 sec/batch; 13h:02m:37s remains)
INFO - root - 2017-12-01 03:29:53.905168: step 20550, loss = 0.46, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 13h:22m:32s remains)
INFO - root - 2017-12-01 03:29:55.453458: step 20560, loss = 0.64, batch loss = 0.40 (51.8 examples/sec; 0.155 sec/batch; 13h:23m:34s remains)
INFO - root - 2017-12-01 03:29:57.010431: step 20570, loss = 0.53, batch loss = 0.29 (49.3 examples/sec; 0.162 sec/batch; 14h:03m:46s remains)
INFO - root - 2017-12-01 03:29:58.569387: step 20580, loss = 0.47, batch loss = 0.23 (52.9 examples/sec; 0.151 sec/batch; 13h:05m:36s remains)
INFO - root - 2017-12-01 03:30:00.156845: step 20590, loss = 0.58, batch loss = 0.35 (49.5 examples/sec; 0.162 sec/batch; 14h:00m:12s remains)
INFO - root - 2017-12-01 03:30:01.729863: step 20600, loss = 0.42, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 13h:28m:12s remains)
INFO - root - 2017-12-01 03:30:03.361724: step 20610, loss = 0.48, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 13h:16m:42s remains)
INFO - root - 2017-12-01 03:30:04.942053: step 20620, loss = 0.48, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 13h:29m:35s remains)
INFO - root - 2017-12-01 03:30:06.510101: step 20630, loss = 0.52, batch loss = 0.29 (49.1 examples/sec; 0.163 sec/batch; 14h:07m:20s remains)
INFO - root - 2017-12-01 03:30:08.080489: step 20640, loss = 0.48, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 13h:33m:38s remains)
INFO - root - 2017-12-01 03:30:09.649343: step 20650, loss = 0.44, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 13h:17m:16s remains)
INFO - root - 2017-12-01 03:30:11.215401: step 20660, loss = 0.60, batch loss = 0.36 (51.9 examples/sec; 0.154 sec/batch; 13h:20m:42s remains)
INFO - root - 2017-12-01 03:30:12.781317: step 20670, loss = 0.49, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 13h:28m:48s remains)
INFO - root - 2017-12-01 03:30:14.335470: step 20680, loss = 0.53, batch loss = 0.29 (49.2 examples/sec; 0.163 sec/batch; 14h:05m:27s remains)
INFO - root - 2017-12-01 03:30:15.890026: step 20690, loss = 0.44, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 13h:28m:36s remains)
INFO - root - 2017-12-01 03:30:17.475056: step 20700, loss = 0.58, batch loss = 0.34 (50.8 examples/sec; 0.157 sec/batch; 13h:37m:53s remains)
INFO - root - 2017-12-01 03:30:19.163314: step 20710, loss = 0.57, batch loss = 0.33 (51.5 examples/sec; 0.155 sec/batch; 13h:26m:30s remains)
INFO - root - 2017-12-01 03:30:20.744516: step 20720, loss = 0.43, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 13h:23m:58s remains)
INFO - root - 2017-12-01 03:30:22.317489: step 20730, loss = 0.50, batch loss = 0.26 (51.1 examples/sec; 0.156 sec/batch; 13h:33m:08s remains)
INFO - root - 2017-12-01 03:30:23.861397: step 20740, loss = 0.46, batch loss = 0.23 (52.9 examples/sec; 0.151 sec/batch; 13h:06m:25s remains)
INFO - root - 2017-12-01 03:30:25.441377: step 20750, loss = 0.64, batch loss = 0.40 (49.9 examples/sec; 0.160 sec/batch; 13h:52m:44s remains)
INFO - root - 2017-12-01 03:30:27.002174: step 20760, loss = 0.50, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 13h:19m:11s remains)
INFO - root - 2017-12-01 03:30:28.578813: step 20770, loss = 0.53, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 13h:26m:19s remains)
INFO - root - 2017-12-01 03:30:30.144244: step 20780, loss = 0.45, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 13h:48m:51s remains)
INFO - root - 2017-12-01 03:30:31.699661: step 20790, loss = 0.53, batch loss = 0.30 (49.2 examples/sec; 0.163 sec/batch; 14h:05m:09s remains)
INFO - root - 2017-12-01 03:30:33.265398: step 20800, loss = 0.56, batch loss = 0.32 (52.7 examples/sec; 0.152 sec/batch; 13h:08m:19s remains)
INFO - root - 2017-12-01 03:30:34.888088: step 20810, loss = 0.55, batch loss = 0.32 (51.2 examples/sec; 0.156 sec/batch; 13h:31m:53s remains)
INFO - root - 2017-12-01 03:30:36.446007: step 20820, loss = 0.51, batch loss = 0.27 (52.5 examples/sec; 0.152 sec/batch; 13h:11m:42s remains)
INFO - root - 2017-12-01 03:30:38.010789: step 20830, loss = 0.45, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 13h:40m:19s remains)
INFO - root - 2017-12-01 03:30:39.573323: step 20840, loss = 0.57, batch loss = 0.34 (52.1 examples/sec; 0.153 sec/batch; 13h:16m:50s remains)
INFO - root - 2017-12-01 03:30:41.156829: step 20850, loss = 0.51, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 13h:39m:19s remains)
INFO - root - 2017-12-01 03:30:42.711562: step 20860, loss = 0.48, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 13h:41m:53s remains)
INFO - root - 2017-12-01 03:30:44.266109: step 20870, loss = 0.54, batch loss = 0.31 (52.0 examples/sec; 0.154 sec/batch; 13h:19m:02s remains)
INFO - root - 2017-12-01 03:30:45.825745: step 20880, loss = 0.57, batch loss = 0.33 (51.1 examples/sec; 0.157 sec/batch; 13h:33m:06s remains)
INFO - root - 2017-12-01 03:30:47.410125: step 20890, loss = 0.52, batch loss = 0.28 (52.0 examples/sec; 0.154 sec/batch; 13h:19m:25s remains)
INFO - root - 2017-12-01 03:30:48.974180: step 20900, loss = 0.49, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 13h:37m:00s remains)
INFO - root - 2017-12-01 03:30:50.578068: step 20910, loss = 0.64, batch loss = 0.40 (50.2 examples/sec; 0.159 sec/batch; 13h:47m:35s remains)
INFO - root - 2017-12-01 03:30:52.216398: step 20920, loss = 0.48, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 13h:28m:58s remains)
INFO - root - 2017-12-01 03:30:53.850914: step 20930, loss = 0.65, batch loss = 0.41 (51.2 examples/sec; 0.156 sec/batch; 13h:31m:39s remains)
INFO - root - 2017-12-01 03:30:55.432234: step 20940, loss = 0.57, batch loss = 0.33 (51.8 examples/sec; 0.154 sec/batch; 13h:21m:20s remains)
INFO - root - 2017-12-01 03:30:57.016704: step 20950, loss = 0.55, batch loss = 0.32 (49.1 examples/sec; 0.163 sec/batch; 14h:06m:28s remains)
INFO - root - 2017-12-01 03:30:58.578447: step 20960, loss = 0.52, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 13h:38m:34s remains)
INFO - root - 2017-12-01 03:31:00.143694: step 20970, loss = 0.56, batch loss = 0.32 (49.2 examples/sec; 0.163 sec/batch; 14h:03m:43s remains)
INFO - root - 2017-12-01 03:31:01.714809: step 20980, loss = 0.48, batch loss = 0.25 (50.1 examples/sec; 0.160 sec/batch; 13h:48m:29s remains)
INFO - root - 2017-12-01 03:31:03.288897: step 20990, loss = 0.53, batch loss = 0.29 (49.4 examples/sec; 0.162 sec/batch; 14h:01m:22s remains)
INFO - root - 2017-12-01 03:31:04.858625: step 21000, loss = 0.50, batch loss = 0.26 (52.8 examples/sec; 0.151 sec/batch; 13h:06m:02s remains)
INFO - root - 2017-12-01 03:31:06.499557: step 21010, loss = 0.57, batch loss = 0.33 (51.0 examples/sec; 0.157 sec/batch; 13h:33m:44s remains)
INFO - root - 2017-12-01 03:31:08.071981: step 21020, loss = 0.44, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 13h:42m:04s remains)
INFO - root - 2017-12-01 03:31:09.650145: step 21030, loss = 0.45, batch loss = 0.22 (52.9 examples/sec; 0.151 sec/batch; 13h:05m:22s remains)
INFO - root - 2017-12-01 03:31:11.251260: step 21040, loss = 0.44, batch loss = 0.21 (48.8 examples/sec; 0.164 sec/batch; 14h:11m:21s remains)
INFO - root - 2017-12-01 03:31:12.843606: step 21050, loss = 0.56, batch loss = 0.32 (47.8 examples/sec; 0.168 sec/batch; 14h:29m:33s remains)
INFO - root - 2017-12-01 03:31:14.428538: step 21060, loss = 0.44, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 13h:12m:26s remains)
INFO - root - 2017-12-01 03:31:15.986999: step 21070, loss = 0.51, batch loss = 0.28 (50.0 examples/sec; 0.160 sec/batch; 13h:50m:31s remains)
INFO - root - 2017-12-01 03:31:17.560215: step 21080, loss = 0.41, batch loss = 0.17 (47.7 examples/sec; 0.168 sec/batch; 14h:31m:20s remains)
INFO - root - 2017-12-01 03:31:19.104972: step 21090, loss = 0.45, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 13h:14m:44s remains)
INFO - root - 2017-12-01 03:31:20.682723: step 21100, loss = 0.42, batch loss = 0.18 (52.6 examples/sec; 0.152 sec/batch; 13h:09m:08s remains)
INFO - root - 2017-12-01 03:31:22.345163: step 21110, loss = 0.57, batch loss = 0.33 (50.9 examples/sec; 0.157 sec/batch; 13h:36m:16s remains)
INFO - root - 2017-12-01 03:31:23.925578: step 21120, loss = 0.51, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 13h:18m:31s remains)
INFO - root - 2017-12-01 03:31:25.484147: step 21130, loss = 0.45, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 13h:29m:46s remains)
INFO - root - 2017-12-01 03:31:27.065118: step 21140, loss = 0.47, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 13h:42m:02s remains)
INFO - root - 2017-12-01 03:31:28.637146: step 21150, loss = 0.54, batch loss = 0.30 (50.3 examples/sec; 0.159 sec/batch; 13h:45m:19s remains)
INFO - root - 2017-12-01 03:31:30.209385: step 21160, loss = 0.62, batch loss = 0.39 (51.2 examples/sec; 0.156 sec/batch; 13h:30m:35s remains)
INFO - root - 2017-12-01 03:31:31.770352: step 21170, loss = 0.76, batch loss = 0.53 (51.8 examples/sec; 0.154 sec/batch; 13h:21m:00s remains)
INFO - root - 2017-12-01 03:31:33.333071: step 21180, loss = 0.54, batch loss = 0.31 (50.6 examples/sec; 0.158 sec/batch; 13h:39m:37s remains)
INFO - root - 2017-12-01 03:31:34.890524: step 21190, loss = 0.50, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 13h:29m:48s remains)
INFO - root - 2017-12-01 03:31:36.440226: step 21200, loss = 0.52, batch loss = 0.29 (51.0 examples/sec; 0.157 sec/batch; 13h:33m:42s remains)
INFO - root - 2017-12-01 03:31:38.081892: step 21210, loss = 0.48, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 13h:34m:25s remains)
INFO - root - 2017-12-01 03:31:39.640766: step 21220, loss = 0.62, batch loss = 0.38 (51.2 examples/sec; 0.156 sec/batch; 13h:30m:03s remains)
INFO - root - 2017-12-01 03:31:41.219781: step 21230, loss = 0.44, batch loss = 0.20 (48.4 examples/sec; 0.165 sec/batch; 14h:17m:01s remains)
INFO - root - 2017-12-01 03:31:42.769106: step 21240, loss = 0.63, batch loss = 0.39 (50.4 examples/sec; 0.159 sec/batch; 13h:43m:22s remains)
INFO - root - 2017-12-01 03:31:44.338481: step 21250, loss = 0.48, batch loss = 0.24 (52.7 examples/sec; 0.152 sec/batch; 13h:07m:04s remains)
INFO - root - 2017-12-01 03:31:45.907129: step 21260, loss = 0.61, batch loss = 0.38 (49.7 examples/sec; 0.161 sec/batch; 13h:55m:47s remains)
INFO - root - 2017-12-01 03:31:47.472221: step 21270, loss = 0.55, batch loss = 0.31 (50.7 examples/sec; 0.158 sec/batch; 13h:38m:55s remains)
INFO - root - 2017-12-01 03:31:49.056239: step 21280, loss = 0.46, batch loss = 0.22 (52.8 examples/sec; 0.151 sec/batch; 13h:05m:29s remains)
INFO - root - 2017-12-01 03:31:50.616350: step 21290, loss = 0.59, batch loss = 0.35 (51.1 examples/sec; 0.156 sec/batch; 13h:31m:32s remains)
INFO - root - 2017-12-01 03:31:52.178095: step 21300, loss = 0.47, batch loss = 0.23 (52.1 examples/sec; 0.154 sec/batch; 13h:16m:56s remains)
INFO - root - 2017-12-01 03:31:53.815553: step 21310, loss = 0.55, batch loss = 0.31 (49.9 examples/sec; 0.160 sec/batch; 13h:51m:11s remains)
INFO - root - 2017-12-01 03:31:55.386904: step 21320, loss = 0.49, batch loss = 0.26 (50.5 examples/sec; 0.159 sec/batch; 13h:42m:11s remains)
INFO - root - 2017-12-01 03:31:56.962059: step 21330, loss = 0.53, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 13h:34m:43s remains)
INFO - root - 2017-12-01 03:31:58.521987: step 21340, loss = 0.53, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 13h:30m:08s remains)
INFO - root - 2017-12-01 03:32:00.076078: step 21350, loss = 0.63, batch loss = 0.40 (50.0 examples/sec; 0.160 sec/batch; 13h:49m:35s remains)
INFO - root - 2017-12-01 03:32:01.653288: step 21360, loss = 0.47, batch loss = 0.24 (52.1 examples/sec; 0.154 sec/batch; 13h:16m:47s remains)
INFO - root - 2017-12-01 03:32:03.211006: step 21370, loss = 0.53, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 13h:18m:58s remains)
INFO - root - 2017-12-01 03:32:04.802407: step 21380, loss = 0.48, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 13h:50m:37s remains)
INFO - root - 2017-12-01 03:32:06.356800: step 21390, loss = 0.47, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 13h:21m:50s remains)
INFO - root - 2017-12-01 03:32:07.911085: step 21400, loss = 0.47, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 13h:24m:47s remains)
INFO - root - 2017-12-01 03:32:09.558159: step 21410, loss = 0.46, batch loss = 0.22 (52.4 examples/sec; 0.153 sec/batch; 13h:11m:41s remains)
INFO - root - 2017-12-01 03:32:11.126882: step 21420, loss = 0.53, batch loss = 0.29 (48.6 examples/sec; 0.165 sec/batch; 14h:12m:59s remains)
INFO - root - 2017-12-01 03:32:12.711607: step 21430, loss = 0.56, batch loss = 0.32 (50.8 examples/sec; 0.157 sec/batch; 13h:35m:46s remains)
INFO - root - 2017-12-01 03:32:14.265505: step 21440, loss = 0.90, batch loss = 0.67 (51.7 examples/sec; 0.155 sec/batch; 13h:21m:42s remains)
INFO - root - 2017-12-01 03:32:15.809033: step 21450, loss = 0.44, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 13h:18m:24s remains)
INFO - root - 2017-12-01 03:32:17.373431: step 21460, loss = 0.62, batch loss = 0.38 (52.5 examples/sec; 0.152 sec/batch; 13h:10m:24s remains)
INFO - root - 2017-12-01 03:32:18.948577: step 21470, loss = 0.42, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 13h:43m:02s remains)
INFO - root - 2017-12-01 03:32:20.519619: step 21480, loss = 0.59, batch loss = 0.36 (51.8 examples/sec; 0.154 sec/batch; 13h:19m:53s remains)
INFO - root - 2017-12-01 03:32:22.115915: step 21490, loss = 0.58, batch loss = 0.35 (51.6 examples/sec; 0.155 sec/batch; 13h:23m:46s remains)
INFO - root - 2017-12-01 03:32:23.674207: step 21500, loss = 0.49, batch loss = 0.25 (50.8 examples/sec; 0.157 sec/batch; 13h:36m:21s remains)
INFO - root - 2017-12-01 03:32:25.303242: step 21510, loss = 0.61, batch loss = 0.37 (52.1 examples/sec; 0.153 sec/batch; 13h:15m:28s remains)
INFO - root - 2017-12-01 03:32:26.877873: step 21520, loss = 0.47, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 13h:39m:34s remains)
INFO - root - 2017-12-01 03:32:28.419075: step 21530, loss = 0.44, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 13h:36m:45s remains)
INFO - root - 2017-12-01 03:32:29.979974: step 21540, loss = 0.80, batch loss = 0.56 (49.7 examples/sec; 0.161 sec/batch; 13h:54m:31s remains)
INFO - root - 2017-12-01 03:32:31.538894: step 21550, loss = 0.51, batch loss = 0.27 (51.8 examples/sec; 0.155 sec/batch; 13h:20m:48s remains)
INFO - root - 2017-12-01 03:32:33.104633: step 21560, loss = 0.58, batch loss = 0.34 (52.6 examples/sec; 0.152 sec/batch; 13h:07m:37s remains)
INFO - root - 2017-12-01 03:32:34.669200: step 21570, loss = 0.43, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 13h:20m:01s remains)
INFO - root - 2017-12-01 03:32:36.253825: step 21580, loss = 0.53, batch loss = 0.30 (49.6 examples/sec; 0.161 sec/batch; 13h:56m:24s remains)
INFO - root - 2017-12-01 03:32:37.801506: step 21590, loss = 0.65, batch loss = 0.41 (51.9 examples/sec; 0.154 sec/batch; 13h:18m:11s remains)
INFO - root - 2017-12-01 03:32:39.365152: step 21600, loss = 0.48, batch loss = 0.25 (53.0 examples/sec; 0.151 sec/batch; 13h:01m:28s remains)
INFO - root - 2017-12-01 03:32:40.979267: step 21610, loss = 0.46, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 13h:09m:53s remains)
INFO - root - 2017-12-01 03:32:42.562779: step 21620, loss = 0.66, batch loss = 0.43 (51.3 examples/sec; 0.156 sec/batch; 13h:27m:37s remains)
INFO - root - 2017-12-01 03:32:44.149639: step 21630, loss = 0.51, batch loss = 0.28 (52.1 examples/sec; 0.154 sec/batch; 13h:15m:46s remains)
INFO - root - 2017-12-01 03:32:45.761584: step 21640, loss = 0.56, batch loss = 0.32 (45.2 examples/sec; 0.177 sec/batch; 15h:17m:37s remains)
INFO - root - 2017-12-01 03:32:47.314744: step 21650, loss = 0.55, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 13h:33m:15s remains)
INFO - root - 2017-12-01 03:32:48.864722: step 21660, loss = 0.50, batch loss = 0.27 (50.5 examples/sec; 0.158 sec/batch; 13h:41m:01s remains)
INFO - root - 2017-12-01 03:32:50.438781: step 21670, loss = 0.43, batch loss = 0.20 (48.4 examples/sec; 0.165 sec/batch; 14h:15m:40s remains)
INFO - root - 2017-12-01 03:32:52.017780: step 21680, loss = 0.54, batch loss = 0.30 (51.3 examples/sec; 0.156 sec/batch; 13h:27m:48s remains)
INFO - root - 2017-12-01 03:32:53.577354: step 21690, loss = 0.59, batch loss = 0.36 (50.3 examples/sec; 0.159 sec/batch; 13h:44m:18s remains)
INFO - root - 2017-12-01 03:32:55.138846: step 21700, loss = 0.55, batch loss = 0.31 (51.1 examples/sec; 0.157 sec/batch; 13h:31m:30s remains)
INFO - root - 2017-12-01 03:32:56.791866: step 21710, loss = 0.58, batch loss = 0.34 (50.3 examples/sec; 0.159 sec/batch; 13h:43m:12s remains)
INFO - root - 2017-12-01 03:32:58.370640: step 21720, loss = 0.50, batch loss = 0.26 (46.1 examples/sec; 0.174 sec/batch; 14h:59m:49s remains)
INFO - root - 2017-12-01 03:32:59.918578: step 21730, loss = 0.56, batch loss = 0.33 (52.9 examples/sec; 0.151 sec/batch; 13h:03m:01s remains)
INFO - root - 2017-12-01 03:33:01.496592: step 21740, loss = 0.62, batch loss = 0.39 (51.5 examples/sec; 0.155 sec/batch; 13h:25m:11s remains)
INFO - root - 2017-12-01 03:33:03.047568: step 21750, loss = 0.47, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 13h:37m:41s remains)
INFO - root - 2017-12-01 03:33:04.634930: step 21760, loss = 0.52, batch loss = 0.28 (49.8 examples/sec; 0.161 sec/batch; 13h:51m:38s remains)
INFO - root - 2017-12-01 03:33:06.204122: step 21770, loss = 0.58, batch loss = 0.35 (49.2 examples/sec; 0.163 sec/batch; 14h:02m:09s remains)
INFO - root - 2017-12-01 03:33:07.783076: step 21780, loss = 0.58, batch loss = 0.35 (51.0 examples/sec; 0.157 sec/batch; 13h:32m:10s remains)
INFO - root - 2017-12-01 03:33:09.314458: step 21790, loss = 0.54, batch loss = 0.31 (54.2 examples/sec; 0.148 sec/batch; 12h:44m:22s remains)
INFO - root - 2017-12-01 03:33:10.917997: step 21800, loss = 0.47, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 13h:44m:00s remains)
INFO - root - 2017-12-01 03:33:12.587181: step 21810, loss = 0.53, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 13h:36m:58s remains)
INFO - root - 2017-12-01 03:33:14.161463: step 21820, loss = 0.63, batch loss = 0.40 (50.9 examples/sec; 0.157 sec/batch; 13h:33m:17s remains)
INFO - root - 2017-12-01 03:33:15.735216: step 21830, loss = 0.50, batch loss = 0.27 (52.4 examples/sec; 0.153 sec/batch; 13h:10m:31s remains)
INFO - root - 2017-12-01 03:33:17.312844: step 21840, loss = 0.56, batch loss = 0.32 (50.5 examples/sec; 0.159 sec/batch; 13h:40m:45s remains)
INFO - root - 2017-12-01 03:33:18.880698: step 21850, loss = 0.68, batch loss = 0.44 (50.8 examples/sec; 0.157 sec/batch; 13h:34m:51s remains)
INFO - root - 2017-12-01 03:33:20.479831: step 21860, loss = 0.51, batch loss = 0.27 (49.0 examples/sec; 0.163 sec/batch; 14h:05m:27s remains)
INFO - root - 2017-12-01 03:33:22.035650: step 21870, loss = 0.54, batch loss = 0.30 (52.1 examples/sec; 0.154 sec/batch; 13h:15m:40s remains)
INFO - root - 2017-12-01 03:33:23.611511: step 21880, loss = 0.81, batch loss = 0.57 (50.3 examples/sec; 0.159 sec/batch; 13h:43m:51s remains)
INFO - root - 2017-12-01 03:33:25.171136: step 21890, loss = 0.65, batch loss = 0.42 (50.2 examples/sec; 0.159 sec/batch; 13h:44m:31s remains)
INFO - root - 2017-12-01 03:33:26.740732: step 21900, loss = 0.61, batch loss = 0.38 (50.6 examples/sec; 0.158 sec/batch; 13h:38m:09s remains)
INFO - root - 2017-12-01 03:33:28.364884: step 21910, loss = 0.53, batch loss = 0.30 (52.1 examples/sec; 0.154 sec/batch; 13h:14m:56s remains)
INFO - root - 2017-12-01 03:33:29.946745: step 21920, loss = 0.45, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 13h:33m:17s remains)
INFO - root - 2017-12-01 03:33:31.513151: step 21930, loss = 0.58, batch loss = 0.34 (50.5 examples/sec; 0.158 sec/batch; 13h:39m:51s remains)
INFO - root - 2017-12-01 03:33:33.073863: step 21940, loss = 0.57, batch loss = 0.33 (50.0 examples/sec; 0.160 sec/batch; 13h:47m:26s remains)
INFO - root - 2017-12-01 03:33:34.657861: step 21950, loss = 0.66, batch loss = 0.42 (50.9 examples/sec; 0.157 sec/batch; 13h:32m:45s remains)
INFO - root - 2017-12-01 03:33:36.262467: step 21960, loss = 0.46, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 13h:46m:18s remains)
INFO - root - 2017-12-01 03:33:37.821411: step 21970, loss = 0.54, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 13h:23m:23s remains)
INFO - root - 2017-12-01 03:33:39.372449: step 21980, loss = 0.49, batch loss = 0.25 (52.2 examples/sec; 0.153 sec/batch; 13h:12m:52s remains)
INFO - root - 2017-12-01 03:33:40.949873: step 21990, loss = 0.57, batch loss = 0.33 (50.4 examples/sec; 0.159 sec/batch; 13h:41m:58s remains)
INFO - root - 2017-12-01 03:33:42.521309: step 22000, loss = 0.62, batch loss = 0.39 (50.9 examples/sec; 0.157 sec/batch; 13h:33m:51s remains)
INFO - root - 2017-12-01 03:33:44.160542: step 22010, loss = 0.50, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 13h:25m:05s remains)
INFO - root - 2017-12-01 03:33:45.767217: step 22020, loss = 0.49, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 13h:25m:53s remains)
INFO - root - 2017-12-01 03:33:47.326162: step 22030, loss = 0.49, batch loss = 0.26 (49.9 examples/sec; 0.160 sec/batch; 13h:49m:31s remains)
INFO - root - 2017-12-01 03:33:48.889849: step 22040, loss = 0.52, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 13h:21m:43s remains)
INFO - root - 2017-12-01 03:33:50.444161: step 22050, loss = 0.46, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 13h:16m:24s remains)
INFO - root - 2017-12-01 03:33:52.003948: step 22060, loss = 0.60, batch loss = 0.36 (52.5 examples/sec; 0.152 sec/batch; 13h:08m:28s remains)
INFO - root - 2017-12-01 03:33:53.568551: step 22070, loss = 0.48, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 13h:32m:30s remains)
INFO - root - 2017-12-01 03:33:55.123557: step 22080, loss = 0.46, batch loss = 0.22 (49.8 examples/sec; 0.161 sec/batch; 13h:51m:00s remains)
INFO - root - 2017-12-01 03:33:56.714971: step 22090, loss = 0.48, batch loss = 0.25 (48.7 examples/sec; 0.164 sec/batch; 14h:10m:18s remains)
INFO - root - 2017-12-01 03:33:58.327922: step 22100, loss = 0.65, batch loss = 0.42 (48.4 examples/sec; 0.165 sec/batch; 14h:15m:03s remains)
INFO - root - 2017-12-01 03:33:59.969684: step 22110, loss = 0.59, batch loss = 0.36 (50.9 examples/sec; 0.157 sec/batch; 13h:32m:38s remains)
INFO - root - 2017-12-01 03:34:01.562008: step 22120, loss = 0.56, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 13h:35m:52s remains)
INFO - root - 2017-12-01 03:34:03.149273: step 22130, loss = 0.49, batch loss = 0.25 (50.5 examples/sec; 0.158 sec/batch; 13h:39m:17s remains)
INFO - root - 2017-12-01 03:34:04.710881: step 22140, loss = 0.53, batch loss = 0.29 (51.7 examples/sec; 0.155 sec/batch; 13h:21m:07s remains)
INFO - root - 2017-12-01 03:34:06.285956: step 22150, loss = 0.51, batch loss = 0.27 (48.0 examples/sec; 0.167 sec/batch; 14h:21m:33s remains)
INFO - root - 2017-12-01 03:34:07.854524: step 22160, loss = 0.54, batch loss = 0.31 (50.0 examples/sec; 0.160 sec/batch; 13h:48m:13s remains)
INFO - root - 2017-12-01 03:34:09.423847: step 22170, loss = 0.48, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 13h:24m:33s remains)
INFO - root - 2017-12-01 03:34:10.996537: step 22180, loss = 0.76, batch loss = 0.53 (49.5 examples/sec; 0.162 sec/batch; 13h:55m:52s remains)
INFO - root - 2017-12-01 03:34:12.603762: step 22190, loss = 0.53, batch loss = 0.29 (50.8 examples/sec; 0.157 sec/batch; 13h:33m:50s remains)
INFO - root - 2017-12-01 03:34:14.188798: step 22200, loss = 0.66, batch loss = 0.42 (50.8 examples/sec; 0.158 sec/batch; 13h:34m:49s remains)
INFO - root - 2017-12-01 03:34:15.843767: step 22210, loss = 0.50, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 13h:33m:01s remains)
INFO - root - 2017-12-01 03:34:17.401644: step 22220, loss = 0.45, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 13h:40m:41s remains)
INFO - root - 2017-12-01 03:34:18.970720: step 22230, loss = 0.49, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 13h:37m:40s remains)
INFO - root - 2017-12-01 03:34:20.537442: step 22240, loss = 0.47, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 13h:10m:43s remains)
INFO - root - 2017-12-01 03:34:22.104084: step 22250, loss = 0.51, batch loss = 0.28 (52.6 examples/sec; 0.152 sec/batch; 13h:06m:37s remains)
INFO - root - 2017-12-01 03:34:23.701591: step 22260, loss = 0.52, batch loss = 0.29 (48.5 examples/sec; 0.165 sec/batch; 14h:13m:38s remains)
INFO - root - 2017-12-01 03:34:25.264193: step 22270, loss = 0.55, batch loss = 0.31 (51.3 examples/sec; 0.156 sec/batch; 13h:25m:45s remains)
INFO - root - 2017-12-01 03:34:26.834040: step 22280, loss = 0.49, batch loss = 0.25 (52.4 examples/sec; 0.153 sec/batch; 13h:09m:58s remains)
INFO - root - 2017-12-01 03:34:28.403362: step 22290, loss = 0.42, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 13h:23m:27s remains)
INFO - root - 2017-12-01 03:34:29.970869: step 22300, loss = 0.47, batch loss = 0.23 (50.4 examples/sec; 0.159 sec/batch; 13h:40m:26s remains)
INFO - root - 2017-12-01 03:34:31.622796: step 22310, loss = 0.50, batch loss = 0.26 (50.8 examples/sec; 0.157 sec/batch; 13h:33m:34s remains)
INFO - root - 2017-12-01 03:34:33.194435: step 22320, loss = 0.56, batch loss = 0.33 (51.8 examples/sec; 0.154 sec/batch; 13h:17m:44s remains)
INFO - root - 2017-12-01 03:34:34.761831: step 22330, loss = 0.52, batch loss = 0.29 (50.8 examples/sec; 0.157 sec/batch; 13h:33m:28s remains)
INFO - root - 2017-12-01 03:34:36.329387: step 22340, loss = 0.44, batch loss = 0.21 (53.1 examples/sec; 0.151 sec/batch; 12h:58m:40s remains)
INFO - root - 2017-12-01 03:34:37.892527: step 22350, loss = 0.62, batch loss = 0.39 (51.4 examples/sec; 0.156 sec/batch; 13h:24m:47s remains)
INFO - root - 2017-12-01 03:34:39.459382: step 22360, loss = 0.54, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 13h:20m:55s remains)
INFO - root - 2017-12-01 03:34:41.058686: step 22370, loss = 0.76, batch loss = 0.52 (50.4 examples/sec; 0.159 sec/batch; 13h:39m:45s remains)
INFO - root - 2017-12-01 03:34:42.637456: step 22380, loss = 0.49, batch loss = 0.26 (48.6 examples/sec; 0.165 sec/batch; 14h:10m:49s remains)
INFO - root - 2017-12-01 03:34:44.216794: step 22390, loss = 0.57, batch loss = 0.34 (50.0 examples/sec; 0.160 sec/batch; 13h:46m:54s remains)
INFO - root - 2017-12-01 03:34:45.793756: step 22400, loss = 0.49, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 13h:37m:35s remains)
INFO - root - 2017-12-01 03:34:47.418284: step 22410, loss = 0.53, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 13h:23m:48s remains)
INFO - root - 2017-12-01 03:34:48.990113: step 22420, loss = 0.52, batch loss = 0.28 (50.4 examples/sec; 0.159 sec/batch; 13h:41m:07s remains)
INFO - root - 2017-12-01 03:34:50.560698: step 22430, loss = 0.56, batch loss = 0.33 (50.8 examples/sec; 0.157 sec/batch; 13h:33m:48s remains)
INFO - root - 2017-12-01 03:34:52.125787: step 22440, loss = 0.48, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 13h:47m:56s remains)
INFO - root - 2017-12-01 03:34:53.704809: step 22450, loss = 0.43, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 13h:34m:40s remains)
INFO - root - 2017-12-01 03:34:55.293988: step 22460, loss = 0.57, batch loss = 0.33 (52.2 examples/sec; 0.153 sec/batch; 13h:12m:38s remains)
INFO - root - 2017-12-01 03:34:56.867063: step 22470, loss = 0.61, batch loss = 0.38 (51.7 examples/sec; 0.155 sec/batch; 13h:18m:54s remains)
INFO - root - 2017-12-01 03:34:58.414954: step 22480, loss = 0.52, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 13h:22m:30s remains)
INFO - root - 2017-12-01 03:34:59.977152: step 22490, loss = 0.60, batch loss = 0.37 (49.7 examples/sec; 0.161 sec/batch; 13h:52m:30s remains)
INFO - root - 2017-12-01 03:35:01.552614: step 22500, loss = 0.59, batch loss = 0.36 (51.6 examples/sec; 0.155 sec/batch; 13h:20m:35s remains)
INFO - root - 2017-12-01 03:35:03.179548: step 22510, loss = 0.54, batch loss = 0.31 (48.9 examples/sec; 0.163 sec/batch; 14h:04m:37s remains)
INFO - root - 2017-12-01 03:35:04.759665: step 22520, loss = 0.45, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 13h:33m:33s remains)
INFO - root - 2017-12-01 03:35:06.324779: step 22530, loss = 0.54, batch loss = 0.30 (49.8 examples/sec; 0.161 sec/batch; 13h:50m:31s remains)
INFO - root - 2017-12-01 03:35:07.875553: step 22540, loss = 0.61, batch loss = 0.38 (50.9 examples/sec; 0.157 sec/batch; 13h:31m:23s remains)
INFO - root - 2017-12-01 03:35:09.437134: step 22550, loss = 0.46, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 13h:29m:13s remains)
INFO - root - 2017-12-01 03:35:11.008224: step 22560, loss = 0.54, batch loss = 0.30 (49.7 examples/sec; 0.161 sec/batch; 13h:51m:08s remains)
INFO - root - 2017-12-01 03:35:12.590443: step 22570, loss = 0.49, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 13h:07m:22s remains)
INFO - root - 2017-12-01 03:35:14.156589: step 22580, loss = 0.61, batch loss = 0.37 (50.8 examples/sec; 0.158 sec/batch; 13h:33m:56s remains)
INFO - root - 2017-12-01 03:35:15.716418: step 22590, loss = 0.44, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 13h:39m:35s remains)
INFO - root - 2017-12-01 03:35:17.277128: step 22600, loss = 0.45, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 13h:43m:20s remains)
INFO - root - 2017-12-01 03:35:18.939128: step 22610, loss = 0.52, batch loss = 0.29 (51.4 examples/sec; 0.156 sec/batch; 13h:24m:15s remains)
INFO - root - 2017-12-01 03:35:20.497911: step 22620, loss = 0.51, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 13h:34m:36s remains)
INFO - root - 2017-12-01 03:35:22.069443: step 22630, loss = 0.53, batch loss = 0.30 (49.4 examples/sec; 0.162 sec/batch; 13h:56m:51s remains)
INFO - root - 2017-12-01 03:35:23.645168: step 22640, loss = 0.71, batch loss = 0.48 (52.0 examples/sec; 0.154 sec/batch; 13h:15m:00s remains)
INFO - root - 2017-12-01 03:35:25.211126: step 22650, loss = 0.49, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 13h:37m:18s remains)
INFO - root - 2017-12-01 03:35:26.779486: step 22660, loss = 0.55, batch loss = 0.32 (51.7 examples/sec; 0.155 sec/batch; 13h:19m:17s remains)
INFO - root - 2017-12-01 03:35:28.341239: step 22670, loss = 0.48, batch loss = 0.25 (52.8 examples/sec; 0.152 sec/batch; 13h:02m:52s remains)
INFO - root - 2017-12-01 03:35:29.929345: step 22680, loss = 0.46, batch loss = 0.22 (49.6 examples/sec; 0.161 sec/batch; 13h:52m:59s remains)
INFO - root - 2017-12-01 03:35:31.499507: step 22690, loss = 0.48, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 13h:30m:48s remains)
INFO - root - 2017-12-01 03:35:33.065987: step 22700, loss = 0.77, batch loss = 0.54 (48.1 examples/sec; 0.166 sec/batch; 14h:18m:57s remains)
INFO - root - 2017-12-01 03:35:34.700887: step 22710, loss = 0.55, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 13h:34m:29s remains)
INFO - root - 2017-12-01 03:35:36.276285: step 22720, loss = 0.52, batch loss = 0.29 (51.1 examples/sec; 0.157 sec/batch; 13h:28m:49s remains)
INFO - root - 2017-12-01 03:35:37.834307: step 22730, loss = 0.51, batch loss = 0.28 (50.2 examples/sec; 0.159 sec/batch; 13h:42m:12s remains)
INFO - root - 2017-12-01 03:35:39.398896: step 22740, loss = 0.50, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 13h:22m:00s remains)
INFO - root - 2017-12-01 03:35:40.975333: step 22750, loss = 0.59, batch loss = 0.35 (52.9 examples/sec; 0.151 sec/batch; 13h:00m:32s remains)
INFO - root - 2017-12-01 03:35:42.557850: step 22760, loss = 0.50, batch loss = 0.27 (48.3 examples/sec; 0.166 sec/batch; 14h:15m:34s remains)
INFO - root - 2017-12-01 03:35:44.115421: step 22770, loss = 0.48, batch loss = 0.25 (53.5 examples/sec; 0.149 sec/batch; 12h:51m:15s remains)
INFO - root - 2017-12-01 03:35:45.683515: step 22780, loss = 0.52, batch loss = 0.29 (50.6 examples/sec; 0.158 sec/batch; 13h:35m:45s remains)
INFO - root - 2017-12-01 03:35:47.260281: step 22790, loss = 0.47, batch loss = 0.24 (50.5 examples/sec; 0.159 sec/batch; 13h:38m:31s remains)
INFO - root - 2017-12-01 03:35:48.823190: step 22800, loss = 0.44, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 13h:29m:42s remains)
INFO - root - 2017-12-01 03:35:50.427471: step 22810, loss = 0.65, batch loss = 0.42 (51.9 examples/sec; 0.154 sec/batch; 13h:15m:30s remains)
INFO - root - 2017-12-01 03:35:51.989461: step 22820, loss = 0.63, batch loss = 0.39 (52.8 examples/sec; 0.151 sec/batch; 13h:01m:25s remains)
INFO - root - 2017-12-01 03:35:53.575220: step 22830, loss = 0.44, batch loss = 0.21 (49.8 examples/sec; 0.161 sec/batch; 13h:49m:28s remains)
INFO - root - 2017-12-01 03:35:55.154834: step 22840, loss = 0.52, batch loss = 0.29 (49.5 examples/sec; 0.162 sec/batch; 13h:54m:37s remains)
INFO - root - 2017-12-01 03:35:56.713165: step 22850, loss = 0.49, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 13h:36m:20s remains)
INFO - root - 2017-12-01 03:35:58.332569: step 22860, loss = 0.48, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 13h:24m:31s remains)
INFO - root - 2017-12-01 03:35:59.884425: step 22870, loss = 0.48, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 13h:25m:43s remains)
INFO - root - 2017-12-01 03:36:01.426253: step 22880, loss = 0.49, batch loss = 0.26 (50.2 examples/sec; 0.159 sec/batch; 13h:42m:46s remains)
INFO - root - 2017-12-01 03:36:02.983808: step 22890, loss = 0.57, batch loss = 0.34 (50.7 examples/sec; 0.158 sec/batch; 13h:34m:48s remains)
INFO - root - 2017-12-01 03:36:04.552470: step 22900, loss = 0.54, batch loss = 0.31 (50.3 examples/sec; 0.159 sec/batch; 13h:40m:11s remains)
INFO - root - 2017-12-01 03:36:06.207530: step 22910, loss = 0.48, batch loss = 0.24 (50.2 examples/sec; 0.159 sec/batch; 13h:41m:31s remains)
INFO - root - 2017-12-01 03:36:07.767175: step 22920, loss = 0.64, batch loss = 0.40 (52.0 examples/sec; 0.154 sec/batch; 13h:13m:05s remains)
INFO - root - 2017-12-01 03:36:09.310625: step 22930, loss = 0.41, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 13h:21m:54s remains)
INFO - root - 2017-12-01 03:36:10.951414: step 22940, loss = 0.46, batch loss = 0.22 (48.2 examples/sec; 0.166 sec/batch; 14h:15m:58s remains)
INFO - root - 2017-12-01 03:36:12.532222: step 22950, loss = 0.53, batch loss = 0.30 (50.3 examples/sec; 0.159 sec/batch; 13h:40m:00s remains)
INFO - root - 2017-12-01 03:36:14.098816: step 22960, loss = 0.47, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 13h:20m:32s remains)
INFO - root - 2017-12-01 03:36:15.672483: step 22970, loss = 0.59, batch loss = 0.36 (50.6 examples/sec; 0.158 sec/batch; 13h:36m:03s remains)
INFO - root - 2017-12-01 03:36:17.231294: step 22980, loss = 0.49, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 13h:23m:53s remains)
INFO - root - 2017-12-01 03:36:18.809326: step 22990, loss = 0.54, batch loss = 0.31 (47.0 examples/sec; 0.170 sec/batch; 14h:38m:46s remains)
INFO - root - 2017-12-01 03:36:20.381627: step 23000, loss = 0.50, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 13h:10m:43s remains)
INFO - root - 2017-12-01 03:36:22.038380: step 23010, loss = 0.44, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 13h:30m:51s remains)
INFO - root - 2017-12-01 03:36:23.591776: step 23020, loss = 0.65, batch loss = 0.42 (51.8 examples/sec; 0.154 sec/batch; 13h:16m:22s remains)
INFO - root - 2017-12-01 03:36:25.178010: step 23030, loss = 0.49, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 13h:22m:50s remains)
INFO - root - 2017-12-01 03:36:26.742652: step 23040, loss = 0.42, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 13h:19m:44s remains)
INFO - root - 2017-12-01 03:36:28.294180: step 23050, loss = 0.62, batch loss = 0.38 (51.0 examples/sec; 0.157 sec/batch; 13h:28m:49s remains)
INFO - root - 2017-12-01 03:36:29.843938: step 23060, loss = 0.57, batch loss = 0.34 (52.4 examples/sec; 0.153 sec/batch; 13h:06m:44s remains)
INFO - root - 2017-12-01 03:36:31.417003: step 23070, loss = 0.47, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 13h:20m:25s remains)
INFO - root - 2017-12-01 03:36:32.984405: step 23080, loss = 0.42, batch loss = 0.19 (53.1 examples/sec; 0.151 sec/batch; 12h:56m:25s remains)
INFO - root - 2017-12-01 03:36:34.558941: step 23090, loss = 0.60, batch loss = 0.37 (51.7 examples/sec; 0.155 sec/batch; 13h:18m:42s remains)
INFO - root - 2017-12-01 03:36:36.131355: step 23100, loss = 0.41, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 13h:18m:49s remains)
INFO - root - 2017-12-01 03:36:37.778191: step 23110, loss = 0.52, batch loss = 0.29 (48.3 examples/sec; 0.166 sec/batch; 14h:13m:24s remains)
INFO - root - 2017-12-01 03:36:39.349357: step 23120, loss = 0.46, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 13h:13m:20s remains)
INFO - root - 2017-12-01 03:36:40.924557: step 23130, loss = 0.42, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 13h:20m:35s remains)
INFO - root - 2017-12-01 03:36:42.508274: step 23140, loss = 0.50, batch loss = 0.27 (50.5 examples/sec; 0.159 sec/batch; 13h:37m:19s remains)
INFO - root - 2017-12-01 03:36:44.080357: step 23150, loss = 0.51, batch loss = 0.28 (50.3 examples/sec; 0.159 sec/batch; 13h:39m:20s remains)
INFO - root - 2017-12-01 03:36:45.638394: step 23160, loss = 0.53, batch loss = 0.30 (49.2 examples/sec; 0.162 sec/batch; 13h:57m:47s remains)
INFO - root - 2017-12-01 03:36:47.199038: step 23170, loss = 0.44, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 13h:24m:12s remains)
INFO - root - 2017-12-01 03:36:48.743099: step 23180, loss = 0.48, batch loss = 0.25 (52.8 examples/sec; 0.151 sec/batch; 13h:00m:53s remains)
INFO - root - 2017-12-01 03:36:50.344060: step 23190, loss = 0.46, batch loss = 0.23 (51.8 examples/sec; 0.155 sec/batch; 13h:16m:52s remains)
INFO - root - 2017-12-01 03:36:51.906064: step 23200, loss = 0.48, batch loss = 0.25 (48.9 examples/sec; 0.163 sec/batch; 14h:02m:46s remains)
INFO - root - 2017-12-01 03:36:53.552739: step 23210, loss = 0.49, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 13h:09m:23s remains)
INFO - root - 2017-12-01 03:36:55.129560: step 23220, loss = 0.64, batch loss = 0.41 (49.0 examples/sec; 0.163 sec/batch; 14h:01m:26s remains)
INFO - root - 2017-12-01 03:36:56.693872: step 23230, loss = 0.44, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 13h:22m:34s remains)
INFO - root - 2017-12-01 03:36:58.284123: step 23240, loss = 0.58, batch loss = 0.34 (49.0 examples/sec; 0.163 sec/batch; 14h:01m:16s remains)
INFO - root - 2017-12-01 03:36:59.895758: step 23250, loss = 0.50, batch loss = 0.26 (50.0 examples/sec; 0.160 sec/batch; 13h:43m:54s remains)
INFO - root - 2017-12-01 03:37:01.478586: step 23260, loss = 0.55, batch loss = 0.32 (49.1 examples/sec; 0.163 sec/batch; 13h:59m:14s remains)
INFO - root - 2017-12-01 03:37:03.033362: step 23270, loss = 0.53, batch loss = 0.30 (52.7 examples/sec; 0.152 sec/batch; 13h:02m:14s remains)
INFO - root - 2017-12-01 03:37:04.605301: step 23280, loss = 0.49, batch loss = 0.26 (50.2 examples/sec; 0.159 sec/batch; 13h:40m:31s remains)
INFO - root - 2017-12-01 03:37:06.173621: step 23290, loss = 0.48, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 13h:33m:23s remains)
INFO - root - 2017-12-01 03:37:07.750143: step 23300, loss = 0.50, batch loss = 0.27 (48.4 examples/sec; 0.165 sec/batch; 14h:12m:12s remains)
INFO - root - 2017-12-01 03:37:09.393361: step 23310, loss = 0.43, batch loss = 0.20 (52.8 examples/sec; 0.151 sec/batch; 13h:00m:11s remains)
INFO - root - 2017-12-01 03:37:10.964520: step 23320, loss = 0.50, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 13h:33m:13s remains)
INFO - root - 2017-12-01 03:37:12.525103: step 23330, loss = 0.49, batch loss = 0.26 (52.1 examples/sec; 0.153 sec/batch; 13h:10m:48s remains)
INFO - root - 2017-12-01 03:37:14.098921: step 23340, loss = 0.47, batch loss = 0.24 (47.6 examples/sec; 0.168 sec/batch; 14h:26m:07s remains)
INFO - root - 2017-12-01 03:37:15.652765: step 23350, loss = 0.47, batch loss = 0.24 (52.9 examples/sec; 0.151 sec/batch; 12h:59m:09s remains)
INFO - root - 2017-12-01 03:37:17.207269: step 23360, loss = 0.56, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 13h:32m:58s remains)
INFO - root - 2017-12-01 03:37:18.760644: step 23370, loss = 0.48, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 13h:28m:34s remains)
INFO - root - 2017-12-01 03:37:20.307397: step 23380, loss = 0.54, batch loss = 0.31 (52.1 examples/sec; 0.153 sec/batch; 13h:10m:29s remains)
INFO - root - 2017-12-01 03:37:21.853521: step 23390, loss = 0.64, batch loss = 0.40 (52.7 examples/sec; 0.152 sec/batch; 13h:01m:54s remains)
INFO - root - 2017-12-01 03:37:23.415791: step 23400, loss = 0.62, batch loss = 0.39 (51.7 examples/sec; 0.155 sec/batch; 13h:17m:08s remains)
INFO - root - 2017-12-01 03:37:25.043763: step 23410, loss = 0.44, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 13h:18m:09s remains)
INFO - root - 2017-12-01 03:37:26.599363: step 23420, loss = 0.41, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 13h:35m:03s remains)
INFO - root - 2017-12-01 03:37:28.167442: step 23430, loss = 0.51, batch loss = 0.28 (49.6 examples/sec; 0.161 sec/batch; 13h:50m:07s remains)
INFO - root - 2017-12-01 03:37:29.731093: step 23440, loss = 0.50, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 13h:10m:08s remains)
INFO - root - 2017-12-01 03:37:31.278950: step 23450, loss = 0.51, batch loss = 0.28 (50.5 examples/sec; 0.159 sec/batch; 13h:36m:42s remains)
INFO - root - 2017-12-01 03:37:32.848921: step 23460, loss = 0.55, batch loss = 0.32 (50.8 examples/sec; 0.158 sec/batch; 13h:31m:15s remains)
INFO - root - 2017-12-01 03:37:34.419570: step 23470, loss = 0.54, batch loss = 0.31 (50.5 examples/sec; 0.158 sec/batch; 13h:36m:03s remains)
INFO - root - 2017-12-01 03:37:35.968296: step 23480, loss = 0.46, batch loss = 0.23 (49.2 examples/sec; 0.163 sec/batch; 13h:57m:21s remains)
INFO - root - 2017-12-01 03:37:37.538292: step 23490, loss = 0.45, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 13h:22m:04s remains)
INFO - root - 2017-12-01 03:37:39.119355: step 23500, loss = 0.60, batch loss = 0.37 (51.4 examples/sec; 0.156 sec/batch; 13h:20m:58s remains)
INFO - root - 2017-12-01 03:37:40.783078: step 23510, loss = 0.46, batch loss = 0.23 (52.8 examples/sec; 0.152 sec/batch; 13h:00m:33s remains)
INFO - root - 2017-12-01 03:37:42.345062: step 23520, loss = 0.56, batch loss = 0.33 (53.1 examples/sec; 0.151 sec/batch; 12h:55m:07s remains)
INFO - root - 2017-12-01 03:37:43.917524: step 23530, loss = 0.43, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 13h:17m:30s remains)
INFO - root - 2017-12-01 03:37:45.464380: step 23540, loss = 0.61, batch loss = 0.38 (51.9 examples/sec; 0.154 sec/batch; 13h:13m:47s remains)
INFO - root - 2017-12-01 03:37:47.021828: step 23550, loss = 0.48, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 13h:25m:15s remains)
INFO - root - 2017-12-01 03:37:48.587284: step 23560, loss = 0.52, batch loss = 0.29 (52.4 examples/sec; 0.153 sec/batch; 13h:05m:41s remains)
INFO - root - 2017-12-01 03:37:50.151307: step 23570, loss = 0.48, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 13h:14m:13s remains)
INFO - root - 2017-12-01 03:37:51.719987: step 23580, loss = 0.52, batch loss = 0.29 (51.1 examples/sec; 0.156 sec/batch; 13h:25m:19s remains)
INFO - root - 2017-12-01 03:37:53.289205: step 23590, loss = 0.48, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 13h:38m:03s remains)
INFO - root - 2017-12-01 03:37:54.855519: step 23600, loss = 0.74, batch loss = 0.51 (48.7 examples/sec; 0.164 sec/batch; 14h:05m:52s remains)
INFO - root - 2017-12-01 03:37:56.476422: step 23610, loss = 0.45, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 13h:37m:00s remains)
INFO - root - 2017-12-01 03:37:58.047859: step 23620, loss = 0.67, batch loss = 0.44 (53.3 examples/sec; 0.150 sec/batch; 12h:53m:14s remains)
INFO - root - 2017-12-01 03:37:59.610568: step 23630, loss = 0.56, batch loss = 0.33 (53.2 examples/sec; 0.150 sec/batch; 12h:53m:59s remains)
INFO - root - 2017-12-01 03:38:01.166532: step 23640, loss = 0.53, batch loss = 0.30 (52.6 examples/sec; 0.152 sec/batch; 13h:03m:18s remains)
INFO - root - 2017-12-01 03:38:02.744965: step 23650, loss = 0.51, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 13h:19m:20s remains)
INFO - root - 2017-12-01 03:38:04.309076: step 23660, loss = 0.47, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 13h:33m:46s remains)
INFO - root - 2017-12-01 03:38:05.872759: step 23670, loss = 0.51, batch loss = 0.28 (49.6 examples/sec; 0.161 sec/batch; 13h:50m:41s remains)
INFO - root - 2017-12-01 03:38:07.427521: step 23680, loss = 0.45, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 13h:04m:04s remains)
INFO - root - 2017-12-01 03:38:09.004263: step 23690, loss = 0.54, batch loss = 0.31 (52.2 examples/sec; 0.153 sec/batch; 13h:09m:06s remains)
INFO - root - 2017-12-01 03:38:10.564636: step 23700, loss = 0.47, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 13h:24m:12s remains)
INFO - root - 2017-12-01 03:38:12.204862: step 23710, loss = 0.53, batch loss = 0.30 (51.8 examples/sec; 0.155 sec/batch; 13h:15m:28s remains)
INFO - root - 2017-12-01 03:38:13.795676: step 23720, loss = 0.51, batch loss = 0.28 (51.8 examples/sec; 0.154 sec/batch; 13h:14m:49s remains)
INFO - root - 2017-12-01 03:38:15.342528: step 23730, loss = 0.56, batch loss = 0.32 (50.5 examples/sec; 0.158 sec/batch; 13h:34m:52s remains)
INFO - root - 2017-12-01 03:38:16.902303: step 23740, loss = 0.53, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 13h:28m:40s remains)
INFO - root - 2017-12-01 03:38:18.470907: step 23750, loss = 0.52, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 13h:38m:42s remains)
INFO - root - 2017-12-01 03:38:20.039740: step 23760, loss = 0.40, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 13h:12m:16s remains)
INFO - root - 2017-12-01 03:38:21.599444: step 23770, loss = 0.45, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 13h:06m:52s remains)
INFO - root - 2017-12-01 03:38:23.150569: step 23780, loss = 0.61, batch loss = 0.38 (51.5 examples/sec; 0.155 sec/batch; 13h:18m:45s remains)
INFO - root - 2017-12-01 03:38:24.705760: step 23790, loss = 0.50, batch loss = 0.27 (52.1 examples/sec; 0.154 sec/batch; 13h:09m:50s remains)
INFO - root - 2017-12-01 03:38:26.273806: step 23800, loss = 0.44, batch loss = 0.21 (49.6 examples/sec; 0.161 sec/batch; 13h:49m:08s remains)
INFO - root - 2017-12-01 03:38:27.918249: step 23810, loss = 0.45, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 13h:28m:52s remains)
INFO - root - 2017-12-01 03:38:29.478306: step 23820, loss = 0.56, batch loss = 0.33 (50.2 examples/sec; 0.159 sec/batch; 13h:39m:49s remains)
INFO - root - 2017-12-01 03:38:31.041634: step 23830, loss = 0.49, batch loss = 0.26 (50.1 examples/sec; 0.160 sec/batch; 13h:42m:07s remains)
INFO - root - 2017-12-01 03:38:32.595338: step 23840, loss = 0.57, batch loss = 0.34 (51.9 examples/sec; 0.154 sec/batch; 13h:13m:11s remains)
INFO - root - 2017-12-01 03:38:34.161037: step 23850, loss = 0.51, batch loss = 0.28 (52.4 examples/sec; 0.153 sec/batch; 13h:05m:03s remains)
INFO - root - 2017-12-01 03:38:35.729368: step 23860, loss = 0.51, batch loss = 0.28 (52.0 examples/sec; 0.154 sec/batch; 13h:11m:35s remains)
INFO - root - 2017-12-01 03:38:37.280765: step 23870, loss = 0.57, batch loss = 0.34 (50.4 examples/sec; 0.159 sec/batch; 13h:36m:14s remains)
INFO - root - 2017-12-01 03:38:38.830257: step 23880, loss = 0.53, batch loss = 0.30 (50.5 examples/sec; 0.159 sec/batch; 13h:35m:16s remains)
INFO - root - 2017-12-01 03:38:40.385125: step 23890, loss = 0.38, batch loss = 0.15 (50.9 examples/sec; 0.157 sec/batch; 13h:28m:14s remains)
INFO - root - 2017-12-01 03:38:41.951193: step 23900, loss = 0.52, batch loss = 0.29 (53.1 examples/sec; 0.151 sec/batch; 12h:54m:57s remains)
INFO - root - 2017-12-01 03:38:43.599033: step 23910, loss = 0.48, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 13h:17m:14s remains)
INFO - root - 2017-12-01 03:38:45.157995: step 23920, loss = 0.52, batch loss = 0.29 (48.9 examples/sec; 0.163 sec/batch; 14h:00m:38s remains)
INFO - root - 2017-12-01 03:38:46.744500: step 23930, loss = 0.54, batch loss = 0.31 (51.8 examples/sec; 0.154 sec/batch; 13h:14m:04s remains)
INFO - root - 2017-12-01 03:38:48.293184: step 23940, loss = 0.50, batch loss = 0.27 (51.9 examples/sec; 0.154 sec/batch; 13h:13m:06s remains)
INFO - root - 2017-12-01 03:38:49.861257: step 23950, loss = 0.46, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 13h:34m:28s remains)
INFO - root - 2017-12-01 03:38:51.432875: step 23960, loss = 0.48, batch loss = 0.25 (50.5 examples/sec; 0.158 sec/batch; 13h:33m:52s remains)
INFO - root - 2017-12-01 03:38:52.989001: step 23970, loss = 0.58, batch loss = 0.35 (52.5 examples/sec; 0.152 sec/batch; 13h:03m:50s remains)
INFO - root - 2017-12-01 03:38:54.575774: step 23980, loss = 0.46, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 13h:12m:48s remains)
INFO - root - 2017-12-01 03:38:56.158865: step 23990, loss = 0.48, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 13h:33m:24s remains)
INFO - root - 2017-12-01 03:38:57.717559: step 24000, loss = 0.62, batch loss = 0.39 (48.8 examples/sec; 0.164 sec/batch; 14h:02m:46s remains)
INFO - root - 2017-12-01 03:38:59.334355: step 24010, loss = 0.51, batch loss = 0.28 (50.0 examples/sec; 0.160 sec/batch; 13h:42m:19s remains)
INFO - root - 2017-12-01 03:39:00.895990: step 24020, loss = 0.45, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 13h:27m:30s remains)
INFO - root - 2017-12-01 03:39:02.460971: step 24030, loss = 0.46, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 13h:13m:15s remains)
INFO - root - 2017-12-01 03:39:04.038685: step 24040, loss = 0.51, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 13h:28m:38s remains)
INFO - root - 2017-12-01 03:39:05.592139: step 24050, loss = 0.53, batch loss = 0.30 (52.7 examples/sec; 0.152 sec/batch; 12h:59m:41s remains)
INFO - root - 2017-12-01 03:39:07.160641: step 24060, loss = 0.63, batch loss = 0.40 (49.3 examples/sec; 0.162 sec/batch; 13h:53m:42s remains)
INFO - root - 2017-12-01 03:39:08.731549: step 24070, loss = 0.49, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 13h:34m:22s remains)
INFO - root - 2017-12-01 03:39:10.300871: step 24080, loss = 0.59, batch loss = 0.36 (50.8 examples/sec; 0.158 sec/batch; 13h:29m:40s remains)
INFO - root - 2017-12-01 03:39:11.854935: step 24090, loss = 0.48, batch loss = 0.25 (52.7 examples/sec; 0.152 sec/batch; 13h:00m:37s remains)
INFO - root - 2017-12-01 03:39:13.433754: step 24100, loss = 0.51, batch loss = 0.28 (49.7 examples/sec; 0.161 sec/batch; 13h:47m:14s remains)
INFO - root - 2017-12-01 03:39:15.066577: step 24110, loss = 0.46, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 13h:22m:24s remains)
INFO - root - 2017-12-01 03:39:16.625162: step 24120, loss = 0.46, batch loss = 0.23 (52.8 examples/sec; 0.152 sec/batch; 12h:58m:56s remains)
INFO - root - 2017-12-01 03:39:18.196311: step 24130, loss = 0.41, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 13h:11m:34s remains)
INFO - root - 2017-12-01 03:39:19.763271: step 24140, loss = 0.52, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 13h:27m:49s remains)
INFO - root - 2017-12-01 03:39:21.323435: step 24150, loss = 0.55, batch loss = 0.32 (50.3 examples/sec; 0.159 sec/batch; 13h:37m:19s remains)
INFO - root - 2017-12-01 03:39:22.888103: step 24160, loss = 0.53, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 13h:20m:27s remains)
INFO - root - 2017-12-01 03:39:24.448784: step 24170, loss = 0.43, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 13h:12m:24s remains)
INFO - root - 2017-12-01 03:39:26.031910: step 24180, loss = 0.48, batch loss = 0.26 (51.1 examples/sec; 0.157 sec/batch; 13h:24m:17s remains)
INFO - root - 2017-12-01 03:39:27.589573: step 24190, loss = 0.56, batch loss = 0.33 (51.1 examples/sec; 0.157 sec/batch; 13h:24m:14s remains)
INFO - root - 2017-12-01 03:39:29.152611: step 24200, loss = 0.63, batch loss = 0.40 (52.9 examples/sec; 0.151 sec/batch; 12h:56m:34s remains)
INFO - root - 2017-12-01 03:39:30.793806: step 24210, loss = 0.55, batch loss = 0.32 (51.9 examples/sec; 0.154 sec/batch; 13h:12m:30s remains)
INFO - root - 2017-12-01 03:39:32.363963: step 24220, loss = 0.46, batch loss = 0.23 (48.1 examples/sec; 0.166 sec/batch; 14h:13m:41s remains)
INFO - root - 2017-12-01 03:39:33.924933: step 24230, loss = 0.57, batch loss = 0.34 (49.9 examples/sec; 0.160 sec/batch; 13h:43m:37s remains)
INFO - root - 2017-12-01 03:39:35.481022: step 24240, loss = 0.43, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 13h:09m:52s remains)
INFO - root - 2017-12-01 03:39:37.076538: step 24250, loss = 0.48, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 13h:12m:52s remains)
INFO - root - 2017-12-01 03:39:38.651141: step 24260, loss = 0.48, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 13h:18m:10s remains)
INFO - root - 2017-12-01 03:39:40.222758: step 24270, loss = 0.41, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 13h:28m:50s remains)
INFO - root - 2017-12-01 03:39:41.784000: step 24280, loss = 0.50, batch loss = 0.27 (52.1 examples/sec; 0.153 sec/batch; 13h:08m:22s remains)
INFO - root - 2017-12-01 03:39:43.351588: step 24290, loss = 0.49, batch loss = 0.26 (50.3 examples/sec; 0.159 sec/batch; 13h:37m:36s remains)
INFO - root - 2017-12-01 03:39:44.905185: step 24300, loss = 0.58, batch loss = 0.35 (51.6 examples/sec; 0.155 sec/batch; 13h:16m:42s remains)
INFO - root - 2017-12-01 03:39:46.507492: step 24310, loss = 0.54, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 13h:26m:25s remains)
INFO - root - 2017-12-01 03:39:48.061436: step 24320, loss = 0.53, batch loss = 0.30 (52.3 examples/sec; 0.153 sec/batch; 13h:05m:53s remains)
INFO - root - 2017-12-01 03:39:49.649421: step 24330, loss = 0.44, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 13h:31m:12s remains)
INFO - root - 2017-12-01 03:39:51.197453: step 24340, loss = 0.45, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 13h:16m:43s remains)
INFO - root - 2017-12-01 03:39:52.780365: step 24350, loss = 0.64, batch loss = 0.41 (51.3 examples/sec; 0.156 sec/batch; 13h:21m:01s remains)
INFO - root - 2017-12-01 03:39:54.347877: step 24360, loss = 0.47, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 13h:06m:10s remains)
INFO - root - 2017-12-01 03:39:55.931099: step 24370, loss = 0.46, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 13h:13m:05s remains)
INFO - root - 2017-12-01 03:39:57.523244: step 24380, loss = 0.58, batch loss = 0.35 (51.3 examples/sec; 0.156 sec/batch; 13h:20m:35s remains)
INFO - root - 2017-12-01 03:39:59.078831: step 24390, loss = 0.45, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 13h:22m:07s remains)
INFO - root - 2017-12-01 03:40:00.653033: step 24400, loss = 0.54, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 13h:29m:59s remains)
INFO - root - 2017-12-01 03:40:02.264470: step 24410, loss = 0.53, batch loss = 0.31 (51.7 examples/sec; 0.155 sec/batch; 13h:15m:17s remains)
INFO - root - 2017-12-01 03:40:03.834625: step 24420, loss = 0.53, batch loss = 0.30 (49.7 examples/sec; 0.161 sec/batch; 13h:46m:02s remains)
INFO - root - 2017-12-01 03:40:05.386186: step 24430, loss = 0.42, batch loss = 0.20 (52.1 examples/sec; 0.153 sec/batch; 13h:07m:59s remains)
INFO - root - 2017-12-01 03:40:06.970127: step 24440, loss = 0.43, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 13h:23m:03s remains)
INFO - root - 2017-12-01 03:40:08.541411: step 24450, loss = 0.51, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 13h:11m:40s remains)
INFO - root - 2017-12-01 03:40:10.117167: step 24460, loss = 0.57, batch loss = 0.34 (50.4 examples/sec; 0.159 sec/batch; 13h:34m:28s remains)
INFO - root - 2017-12-01 03:40:11.665916: step 24470, loss = 0.45, batch loss = 0.22 (51.4 examples/sec; 0.155 sec/batch; 13h:18m:15s remains)
INFO - root - 2017-12-01 03:40:13.205780: step 24480, loss = 0.48, batch loss = 0.25 (52.4 examples/sec; 0.153 sec/batch; 13h:03m:56s remains)
INFO - root - 2017-12-01 03:40:14.764397: step 24490, loss = 0.42, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 13h:01m:56s remains)
INFO - root - 2017-12-01 03:40:16.311094: step 24500, loss = 0.48, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 13h:01m:46s remains)
INFO - root - 2017-12-01 03:40:17.941647: step 24510, loss = 0.44, batch loss = 0.21 (48.7 examples/sec; 0.164 sec/batch; 14h:02m:56s remains)
INFO - root - 2017-12-01 03:40:19.499025: step 24520, loss = 0.45, batch loss = 0.22 (52.8 examples/sec; 0.152 sec/batch; 12h:58m:04s remains)
INFO - root - 2017-12-01 03:40:21.064953: step 24530, loss = 0.43, batch loss = 0.21 (53.0 examples/sec; 0.151 sec/batch; 12h:54m:30s remains)
INFO - root - 2017-12-01 03:40:22.650511: step 24540, loss = 0.43, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 13h:20m:04s remains)
INFO - root - 2017-12-01 03:40:24.220376: step 24550, loss = 0.55, batch loss = 0.33 (50.7 examples/sec; 0.158 sec/batch; 13h:29m:49s remains)
INFO - root - 2017-12-01 03:40:25.763997: step 24560, loss = 0.60, batch loss = 0.37 (52.5 examples/sec; 0.152 sec/batch; 13h:02m:17s remains)
INFO - root - 2017-12-01 03:40:27.327967: step 24570, loss = 0.66, batch loss = 0.43 (52.4 examples/sec; 0.153 sec/batch; 13h:03m:04s remains)
INFO - root - 2017-12-01 03:40:28.903716: step 24580, loss = 0.56, batch loss = 0.33 (51.1 examples/sec; 0.156 sec/batch; 13h:23m:02s remains)
INFO - root - 2017-12-01 03:40:30.467893: step 24590, loss = 0.47, batch loss = 0.24 (51.8 examples/sec; 0.155 sec/batch; 13h:13m:10s remains)
INFO - root - 2017-12-01 03:40:32.032296: step 24600, loss = 0.41, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 13h:24m:16s remains)
INFO - root - 2017-12-01 03:40:33.648015: step 24610, loss = 0.56, batch loss = 0.34 (51.3 examples/sec; 0.156 sec/batch; 13h:19m:38s remains)
INFO - root - 2017-12-01 03:40:35.207421: step 24620, loss = 0.72, batch loss = 0.49 (51.1 examples/sec; 0.156 sec/batch; 13h:22m:50s remains)
INFO - root - 2017-12-01 03:40:36.773847: step 24630, loss = 0.45, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 13h:30m:47s remains)
INFO - root - 2017-12-01 03:40:38.342256: step 24640, loss = 0.51, batch loss = 0.28 (49.0 examples/sec; 0.163 sec/batch; 13h:57m:17s remains)
INFO - root - 2017-12-01 03:40:39.934949: step 24650, loss = 0.46, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 13h:28m:54s remains)
INFO - root - 2017-12-01 03:40:41.543828: step 24660, loss = 0.45, batch loss = 0.22 (49.4 examples/sec; 0.162 sec/batch; 13h:50m:55s remains)
INFO - root - 2017-12-01 03:40:43.098370: step 24670, loss = 0.45, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 13h:20m:30s remains)
INFO - root - 2017-12-01 03:40:44.647690: step 24680, loss = 0.56, batch loss = 0.33 (52.0 examples/sec; 0.154 sec/batch; 13h:09m:57s remains)
INFO - root - 2017-12-01 03:40:46.224955: step 24690, loss = 0.50, batch loss = 0.27 (52.1 examples/sec; 0.154 sec/batch; 13h:08m:09s remains)
INFO - root - 2017-12-01 03:40:47.786667: step 24700, loss = 0.49, batch loss = 0.27 (52.1 examples/sec; 0.154 sec/batch; 13h:08m:12s remains)
INFO - root - 2017-12-01 03:40:49.459678: step 24710, loss = 0.45, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 13h:02m:03s remains)
INFO - root - 2017-12-01 03:40:51.009259: step 24720, loss = 0.50, batch loss = 0.27 (52.1 examples/sec; 0.154 sec/batch; 13h:07m:56s remains)
INFO - root - 2017-12-01 03:40:52.566943: step 24730, loss = 0.47, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 13h:11m:00s remains)
INFO - root - 2017-12-01 03:40:54.128317: step 24740, loss = 0.51, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 13h:30m:09s remains)
INFO - root - 2017-12-01 03:40:55.689878: step 24750, loss = 0.47, batch loss = 0.25 (50.3 examples/sec; 0.159 sec/batch; 13h:35m:22s remains)
INFO - root - 2017-12-01 03:40:57.255576: step 24760, loss = 0.60, batch loss = 0.37 (53.0 examples/sec; 0.151 sec/batch; 12h:53m:38s remains)
INFO - root - 2017-12-01 03:40:58.825645: step 24770, loss = 0.44, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 13h:28m:34s remains)
INFO - root - 2017-12-01 03:41:00.373329: step 24780, loss = 0.50, batch loss = 0.27 (52.4 examples/sec; 0.153 sec/batch; 13h:02m:18s remains)
INFO - root - 2017-12-01 03:41:01.934107: step 24790, loss = 0.61, batch loss = 0.38 (51.0 examples/sec; 0.157 sec/batch; 13h:24m:06s remains)
INFO - root - 2017-12-01 03:41:03.494964: step 24800, loss = 0.43, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 13h:08m:19s remains)
INFO - root - 2017-12-01 03:41:05.153609: step 24810, loss = 0.51, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 13h:11m:12s remains)
INFO - root - 2017-12-01 03:41:06.705188: step 24820, loss = 0.53, batch loss = 0.30 (51.1 examples/sec; 0.157 sec/batch; 13h:23m:12s remains)
INFO - root - 2017-12-01 03:41:08.272868: step 24830, loss = 0.62, batch loss = 0.39 (51.6 examples/sec; 0.155 sec/batch; 13h:15m:39s remains)
INFO - root - 2017-12-01 03:41:09.842991: step 24840, loss = 0.53, batch loss = 0.31 (51.4 examples/sec; 0.156 sec/batch; 13h:17m:24s remains)
INFO - root - 2017-12-01 03:41:11.428110: step 24850, loss = 0.48, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 13h:23m:16s remains)
INFO - root - 2017-12-01 03:41:12.998473: step 24860, loss = 0.45, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 13h:23m:47s remains)
INFO - root - 2017-12-01 03:41:14.563980: step 24870, loss = 0.49, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 13h:21m:40s remains)
INFO - root - 2017-12-01 03:41:16.134310: step 24880, loss = 0.52, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 13h:15m:09s remains)
INFO - root - 2017-12-01 03:41:17.689262: step 24890, loss = 0.43, batch loss = 0.20 (52.7 examples/sec; 0.152 sec/batch; 12h:57m:39s remains)
INFO - root - 2017-12-01 03:41:19.258985: step 24900, loss = 0.47, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 13h:16m:10s remains)
INFO - root - 2017-12-01 03:41:20.873761: step 24910, loss = 0.44, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 13h:21m:17s remains)
INFO - root - 2017-12-01 03:41:22.436486: step 24920, loss = 0.53, batch loss = 0.31 (51.4 examples/sec; 0.156 sec/batch; 13h:17m:28s remains)
INFO - root - 2017-12-01 03:41:24.029072: step 24930, loss = 0.57, batch loss = 0.35 (51.9 examples/sec; 0.154 sec/batch; 13h:10m:50s remains)
INFO - root - 2017-12-01 03:41:25.601637: step 24940, loss = 0.44, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 13h:36m:00s remains)
INFO - root - 2017-12-01 03:41:27.171005: step 24950, loss = 0.49, batch loss = 0.27 (53.0 examples/sec; 0.151 sec/batch; 12h:53m:26s remains)
INFO - root - 2017-12-01 03:41:28.744462: step 24960, loss = 0.63, batch loss = 0.41 (52.4 examples/sec; 0.153 sec/batch; 13h:02m:21s remains)
INFO - root - 2017-12-01 03:41:30.307915: step 24970, loss = 0.50, batch loss = 0.28 (51.1 examples/sec; 0.157 sec/batch; 13h:22m:37s remains)
INFO - root - 2017-12-01 03:41:31.877466: step 24980, loss = 0.48, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 13h:28m:32s remains)
INFO - root - 2017-12-01 03:41:33.434017: step 24990, loss = 0.49, batch loss = 0.26 (52.6 examples/sec; 0.152 sec/batch; 12h:59m:53s remains)
INFO - root - 2017-12-01 03:41:35.003668: step 25000, loss = 0.53, batch loss = 0.31 (51.7 examples/sec; 0.155 sec/batch; 13h:12m:49s remains)
INFO - root - 2017-12-01 03:41:36.672056: step 25010, loss = 0.58, batch loss = 0.35 (50.5 examples/sec; 0.158 sec/batch; 13h:31m:52s remains)
INFO - root - 2017-12-01 03:41:38.253103: step 25020, loss = 0.43, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 13h:23m:44s remains)
INFO - root - 2017-12-01 03:41:39.811135: step 25030, loss = 0.60, batch loss = 0.37 (51.8 examples/sec; 0.154 sec/batch; 13h:11m:26s remains)
INFO - root - 2017-12-01 03:41:41.369476: step 25040, loss = 0.47, batch loss = 0.24 (50.1 examples/sec; 0.160 sec/batch; 13h:38m:40s remains)
INFO - root - 2017-12-01 03:41:42.948726: step 25050, loss = 0.57, batch loss = 0.34 (48.8 examples/sec; 0.164 sec/batch; 14h:00m:03s remains)
INFO - root - 2017-12-01 03:41:44.494779: step 25060, loss = 0.51, batch loss = 0.28 (51.1 examples/sec; 0.157 sec/batch; 13h:22m:16s remains)
INFO - root - 2017-12-01 03:41:46.074851: step 25070, loss = 0.54, batch loss = 0.31 (51.9 examples/sec; 0.154 sec/batch; 13h:09m:07s remains)
INFO - root - 2017-12-01 03:41:47.641451: step 25080, loss = 0.46, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 13h:16m:06s remains)
INFO - root - 2017-12-01 03:41:49.216831: step 25090, loss = 0.41, batch loss = 0.18 (49.7 examples/sec; 0.161 sec/batch; 13h:44m:05s remains)
INFO - root - 2017-12-01 03:41:50.797559: step 25100, loss = 0.54, batch loss = 0.31 (51.3 examples/sec; 0.156 sec/batch; 13h:19m:07s remains)
INFO - root - 2017-12-01 03:41:52.417574: step 25110, loss = 0.46, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 13h:22m:46s remains)
INFO - root - 2017-12-01 03:41:53.981373: step 25120, loss = 0.62, batch loss = 0.39 (49.7 examples/sec; 0.161 sec/batch; 13h:44m:52s remains)
INFO - root - 2017-12-01 03:41:55.534255: step 25130, loss = 0.44, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 13h:00m:54s remains)
INFO - root - 2017-12-01 03:41:57.122745: step 25140, loss = 0.63, batch loss = 0.40 (52.9 examples/sec; 0.151 sec/batch; 12h:54m:15s remains)
INFO - root - 2017-12-01 03:41:58.694919: step 25150, loss = 0.44, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 13h:23m:53s remains)
INFO - root - 2017-12-01 03:42:00.251041: step 25160, loss = 0.48, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 13h:16m:46s remains)
INFO - root - 2017-12-01 03:42:01.819161: step 25170, loss = 0.48, batch loss = 0.26 (51.8 examples/sec; 0.155 sec/batch; 13h:11m:47s remains)
INFO - root - 2017-12-01 03:42:03.372183: step 25180, loss = 0.48, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 13h:16m:34s remains)
INFO - root - 2017-12-01 03:42:04.947211: step 25190, loss = 0.51, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 13h:29m:06s remains)
INFO - root - 2017-12-01 03:42:06.531821: step 25200, loss = 0.57, batch loss = 0.34 (49.5 examples/sec; 0.162 sec/batch; 13h:47m:51s remains)
INFO - root - 2017-12-01 03:42:08.203124: step 25210, loss = 0.42, batch loss = 0.19 (51.1 examples/sec; 0.156 sec/batch; 13h:21m:11s remains)
INFO - root - 2017-12-01 03:42:09.801188: step 25220, loss = 0.45, batch loss = 0.23 (49.2 examples/sec; 0.163 sec/batch; 13h:52m:55s remains)
INFO - root - 2017-12-01 03:42:11.427076: step 25230, loss = 0.45, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 13h:10m:07s remains)
INFO - root - 2017-12-01 03:42:13.004533: step 25240, loss = 0.48, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 13h:13m:28s remains)
INFO - root - 2017-12-01 03:42:14.661279: step 25250, loss = 0.54, batch loss = 0.31 (48.9 examples/sec; 0.164 sec/batch; 13h:57m:19s remains)
INFO - root - 2017-12-01 03:42:16.231519: step 25260, loss = 0.45, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 13h:27m:25s remains)
INFO - root - 2017-12-01 03:42:17.788050: step 25270, loss = 0.43, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 13h:06m:45s remains)
INFO - root - 2017-12-01 03:42:19.355215: step 25280, loss = 0.43, batch loss = 0.21 (52.9 examples/sec; 0.151 sec/batch; 12h:54m:04s remains)
INFO - root - 2017-12-01 03:42:20.933354: step 25290, loss = 0.50, batch loss = 0.27 (52.3 examples/sec; 0.153 sec/batch; 13h:03m:27s remains)
INFO - root - 2017-12-01 03:42:22.500230: step 25300, loss = 0.44, batch loss = 0.21 (49.6 examples/sec; 0.161 sec/batch; 13h:45m:43s remains)
INFO - root - 2017-12-01 03:42:24.112321: step 25310, loss = 0.52, batch loss = 0.29 (52.3 examples/sec; 0.153 sec/batch; 13h:03m:45s remains)
INFO - root - 2017-12-01 03:42:25.693468: step 25320, loss = 0.50, batch loss = 0.27 (53.4 examples/sec; 0.150 sec/batch; 12h:46m:35s remains)
INFO - root - 2017-12-01 03:42:27.305756: step 25330, loss = 0.46, batch loss = 0.24 (47.9 examples/sec; 0.167 sec/batch; 14h:15m:45s remains)
INFO - root - 2017-12-01 03:42:28.862541: step 25340, loss = 0.40, batch loss = 0.17 (52.8 examples/sec; 0.152 sec/batch; 12h:55m:54s remains)
INFO - root - 2017-12-01 03:42:30.438500: step 25350, loss = 0.48, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 13h:22m:36s remains)
INFO - root - 2017-12-01 03:42:32.029366: step 25360, loss = 0.52, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 13h:34m:49s remains)
INFO - root - 2017-12-01 03:42:33.598234: step 25370, loss = 0.43, batch loss = 0.20 (49.7 examples/sec; 0.161 sec/batch; 13h:43m:40s remains)
INFO - root - 2017-12-01 03:42:35.175880: step 25380, loss = 0.43, batch loss = 0.20 (49.6 examples/sec; 0.161 sec/batch; 13h:45m:33s remains)
INFO - root - 2017-12-01 03:42:36.766291: step 25390, loss = 0.60, batch loss = 0.38 (50.1 examples/sec; 0.160 sec/batch; 13h:37m:09s remains)
INFO - root - 2017-12-01 03:42:38.339909: step 25400, loss = 0.49, batch loss = 0.26 (50.5 examples/sec; 0.159 sec/batch; 13h:31m:36s remains)
INFO - root - 2017-12-01 03:42:39.976729: step 25410, loss = 0.43, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 13h:35m:27s remains)
INFO - root - 2017-12-01 03:42:41.567047: step 25420, loss = 0.57, batch loss = 0.34 (51.3 examples/sec; 0.156 sec/batch; 13h:17m:24s remains)
INFO - root - 2017-12-01 03:42:43.121280: step 25430, loss = 0.54, batch loss = 0.31 (52.8 examples/sec; 0.151 sec/batch; 12h:55m:08s remains)
INFO - root - 2017-12-01 03:42:44.682702: step 25440, loss = 0.50, batch loss = 0.27 (50.8 examples/sec; 0.158 sec/batch; 13h:26m:37s remains)
INFO - root - 2017-12-01 03:42:46.258342: step 25450, loss = 0.52, batch loss = 0.29 (52.4 examples/sec; 0.153 sec/batch; 13h:01m:56s remains)
INFO - root - 2017-12-01 03:42:47.853728: step 25460, loss = 0.48, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 13h:24m:04s remains)
INFO - root - 2017-12-01 03:42:49.399849: step 25470, loss = 0.44, batch loss = 0.21 (50.0 examples/sec; 0.160 sec/batch; 13h:39m:24s remains)
INFO - root - 2017-12-01 03:42:50.962166: step 25480, loss = 0.51, batch loss = 0.28 (53.0 examples/sec; 0.151 sec/batch; 12h:53m:04s remains)
INFO - root - 2017-12-01 03:42:52.533407: step 25490, loss = 0.48, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 13h:17m:15s remains)
INFO - root - 2017-12-01 03:42:54.093254: step 25500, loss = 0.47, batch loss = 0.24 (52.1 examples/sec; 0.153 sec/batch; 13h:05m:03s remains)
INFO - root - 2017-12-01 03:42:55.735222: step 25510, loss = 0.53, batch loss = 0.30 (50.8 examples/sec; 0.157 sec/batch; 13h:25m:07s remains)
INFO - root - 2017-12-01 03:42:57.327987: step 25520, loss = 0.55, batch loss = 0.32 (51.0 examples/sec; 0.157 sec/batch; 13h:22m:18s remains)
INFO - root - 2017-12-01 03:42:58.914220: step 25530, loss = 0.47, batch loss = 0.25 (49.7 examples/sec; 0.161 sec/batch; 13h:43m:32s remains)
INFO - root - 2017-12-01 03:43:00.468343: step 25540, loss = 0.63, batch loss = 0.40 (52.2 examples/sec; 0.153 sec/batch; 13h:04m:11s remains)
INFO - root - 2017-12-01 03:43:02.043517: step 25550, loss = 0.54, batch loss = 0.31 (51.8 examples/sec; 0.154 sec/batch; 13h:09m:54s remains)
INFO - root - 2017-12-01 03:43:03.611623: step 25560, loss = 0.45, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 13h:12m:01s remains)
INFO - root - 2017-12-01 03:43:05.182666: step 25570, loss = 0.53, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 13h:27m:08s remains)
INFO - root - 2017-12-01 03:43:06.786501: step 25580, loss = 0.57, batch loss = 0.34 (49.6 examples/sec; 0.161 sec/batch; 13h:45m:41s remains)
INFO - root - 2017-12-01 03:43:08.339946: step 25590, loss = 0.46, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 13h:13m:53s remains)
INFO - root - 2017-12-01 03:43:09.928690: step 25600, loss = 0.53, batch loss = 0.30 (49.5 examples/sec; 0.162 sec/batch; 13h:46m:17s remains)
INFO - root - 2017-12-01 03:43:11.549415: step 25610, loss = 0.44, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 13h:08m:32s remains)
INFO - root - 2017-12-01 03:43:13.102392: step 25620, loss = 0.47, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 13h:13m:16s remains)
INFO - root - 2017-12-01 03:43:14.660158: step 25630, loss = 0.46, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 13h:15m:10s remains)
INFO - root - 2017-12-01 03:43:16.219410: step 25640, loss = 0.66, batch loss = 0.43 (50.8 examples/sec; 0.157 sec/batch; 13h:25m:15s remains)
INFO - root - 2017-12-01 03:43:17.804580: step 25650, loss = 0.48, batch loss = 0.26 (49.3 examples/sec; 0.162 sec/batch; 13h:49m:32s remains)
INFO - root - 2017-12-01 03:43:19.364528: step 25660, loss = 0.49, batch loss = 0.26 (52.4 examples/sec; 0.153 sec/batch; 13h:00m:39s remains)
INFO - root - 2017-12-01 03:43:20.925965: step 25670, loss = 0.58, batch loss = 0.35 (49.4 examples/sec; 0.162 sec/batch; 13h:48m:40s remains)
INFO - root - 2017-12-01 03:43:22.508718: step 25680, loss = 0.57, batch loss = 0.34 (49.5 examples/sec; 0.162 sec/batch; 13h:47m:15s remains)
INFO - root - 2017-12-01 03:43:24.072019: step 25690, loss = 0.50, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 13h:29m:46s remains)
INFO - root - 2017-12-01 03:43:25.617119: step 25700, loss = 0.49, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 13h:14m:30s remains)
INFO - root - 2017-12-01 03:43:27.244502: step 25710, loss = 0.41, batch loss = 0.18 (51.1 examples/sec; 0.156 sec/batch; 13h:19m:49s remains)
INFO - root - 2017-12-01 03:43:28.801280: step 25720, loss = 0.47, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 13h:19m:45s remains)
INFO - root - 2017-12-01 03:43:30.380572: step 25730, loss = 0.64, batch loss = 0.41 (48.7 examples/sec; 0.164 sec/batch; 13h:59m:37s remains)
INFO - root - 2017-12-01 03:43:31.956552: step 25740, loss = 0.48, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 13h:22m:12s remains)
INFO - root - 2017-12-01 03:43:33.491647: step 25750, loss = 0.44, batch loss = 0.21 (52.7 examples/sec; 0.152 sec/batch; 12h:55m:53s remains)
INFO - root - 2017-12-01 03:43:35.082900: step 25760, loss = 0.49, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 13h:18m:12s remains)
INFO - root - 2017-12-01 03:43:36.639149: step 25770, loss = 0.47, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 13h:19m:09s remains)
INFO - root - 2017-12-01 03:43:38.214831: step 25780, loss = 0.48, batch loss = 0.25 (53.0 examples/sec; 0.151 sec/batch; 12h:51m:52s remains)
INFO - root - 2017-12-01 03:43:39.800490: step 25790, loss = 0.43, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 13h:32m:15s remains)
INFO - root - 2017-12-01 03:43:41.374215: step 25800, loss = 0.57, batch loss = 0.34 (51.4 examples/sec; 0.156 sec/batch; 13h:15m:31s remains)
INFO - root - 2017-12-01 03:43:43.002057: step 25810, loss = 0.41, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 13h:06m:19s remains)
INFO - root - 2017-12-01 03:43:44.565777: step 25820, loss = 0.65, batch loss = 0.42 (51.2 examples/sec; 0.156 sec/batch; 13h:18m:11s remains)
INFO - root - 2017-12-01 03:43:46.136020: step 25830, loss = 0.48, batch loss = 0.26 (51.1 examples/sec; 0.157 sec/batch; 13h:20m:14s remains)
INFO - root - 2017-12-01 03:43:47.684108: step 25840, loss = 0.59, batch loss = 0.37 (51.2 examples/sec; 0.156 sec/batch; 13h:19m:05s remains)
INFO - root - 2017-12-01 03:43:49.250267: step 25850, loss = 0.45, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 13h:33m:22s remains)
INFO - root - 2017-12-01 03:43:50.818319: step 25860, loss = 0.44, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 12h:59m:21s remains)
INFO - root - 2017-12-01 03:43:52.378592: step 25870, loss = 0.56, batch loss = 0.34 (52.2 examples/sec; 0.153 sec/batch; 13h:03m:40s remains)
INFO - root - 2017-12-01 03:43:53.959084: step 25880, loss = 0.46, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 13h:32m:13s remains)
INFO - root - 2017-12-01 03:43:55.559822: step 25890, loss = 0.55, batch loss = 0.32 (51.7 examples/sec; 0.155 sec/batch; 13h:10m:48s remains)
INFO - root - 2017-12-01 03:43:57.133018: step 25900, loss = 0.47, batch loss = 0.25 (50.3 examples/sec; 0.159 sec/batch; 13h:33m:19s remains)
INFO - root - 2017-12-01 03:43:58.761140: step 25910, loss = 0.46, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 13h:12m:52s remains)
INFO - root - 2017-12-01 03:44:00.350066: step 25920, loss = 0.53, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 13h:20m:51s remains)
INFO - root - 2017-12-01 03:44:01.937629: step 25930, loss = 0.48, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 13h:06m:32s remains)
INFO - root - 2017-12-01 03:44:03.497980: step 25940, loss = 0.52, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 13h:18m:35s remains)
INFO - root - 2017-12-01 03:44:05.065432: step 25950, loss = 0.50, batch loss = 0.27 (53.0 examples/sec; 0.151 sec/batch; 12h:51m:16s remains)
INFO - root - 2017-12-01 03:44:06.630836: step 25960, loss = 0.41, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 13h:32m:15s remains)
INFO - root - 2017-12-01 03:44:08.190914: step 25970, loss = 0.45, batch loss = 0.22 (52.7 examples/sec; 0.152 sec/batch; 12h:54m:59s remains)
INFO - root - 2017-12-01 03:44:09.751131: step 25980, loss = 0.50, batch loss = 0.27 (49.1 examples/sec; 0.163 sec/batch; 13h:52m:37s remains)
INFO - root - 2017-12-01 03:44:11.336325: step 25990, loss = 0.45, batch loss = 0.22 (49.4 examples/sec; 0.162 sec/batch; 13h:47m:13s remains)
INFO - root - 2017-12-01 03:44:12.911381: step 26000, loss = 0.66, batch loss = 0.43 (52.1 examples/sec; 0.154 sec/batch; 13h:04m:24s remains)
INFO - root - 2017-12-01 03:44:14.543698: step 26010, loss = 0.48, batch loss = 0.26 (47.6 examples/sec; 0.168 sec/batch; 14h:18m:07s remains)
INFO - root - 2017-12-01 03:44:16.106126: step 26020, loss = 0.61, batch loss = 0.38 (51.5 examples/sec; 0.155 sec/batch; 13h:13m:52s remains)
INFO - root - 2017-12-01 03:44:17.703810: step 26030, loss = 0.62, batch loss = 0.39 (51.4 examples/sec; 0.156 sec/batch; 13h:15m:02s remains)
INFO - root - 2017-12-01 03:44:19.282723: step 26040, loss = 0.64, batch loss = 0.41 (51.8 examples/sec; 0.155 sec/batch; 13h:09m:16s remains)
INFO - root - 2017-12-01 03:44:20.843288: step 26050, loss = 0.47, batch loss = 0.24 (50.0 examples/sec; 0.160 sec/batch; 13h:37m:54s remains)
INFO - root - 2017-12-01 03:44:22.395061: step 26060, loss = 0.47, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 13h:01m:25s remains)
INFO - root - 2017-12-01 03:44:23.982771: step 26070, loss = 0.71, batch loss = 0.48 (52.1 examples/sec; 0.153 sec/batch; 13h:03m:29s remains)
INFO - root - 2017-12-01 03:44:25.559470: step 26080, loss = 0.57, batch loss = 0.35 (48.7 examples/sec; 0.164 sec/batch; 13h:58m:10s remains)
INFO - root - 2017-12-01 03:44:27.112479: step 26090, loss = 0.55, batch loss = 0.32 (51.4 examples/sec; 0.156 sec/batch; 13h:15m:17s remains)
INFO - root - 2017-12-01 03:44:28.682165: step 26100, loss = 0.46, batch loss = 0.24 (53.3 examples/sec; 0.150 sec/batch; 12h:46m:03s remains)
INFO - root - 2017-12-01 03:44:30.294689: step 26110, loss = 0.64, batch loss = 0.41 (52.2 examples/sec; 0.153 sec/batch; 13h:02m:25s remains)
INFO - root - 2017-12-01 03:44:31.896711: step 26120, loss = 0.46, batch loss = 0.23 (49.3 examples/sec; 0.162 sec/batch; 13h:48m:57s remains)
INFO - root - 2017-12-01 03:44:33.464698: step 26130, loss = 0.44, batch loss = 0.21 (48.7 examples/sec; 0.164 sec/batch; 13h:58m:53s remains)
INFO - root - 2017-12-01 03:44:35.062759: step 26140, loss = 0.46, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 13h:21m:27s remains)
INFO - root - 2017-12-01 03:44:36.620552: step 26150, loss = 0.57, batch loss = 0.34 (50.8 examples/sec; 0.158 sec/batch; 13h:24m:31s remains)
INFO - root - 2017-12-01 03:44:38.184774: step 26160, loss = 0.47, batch loss = 0.25 (49.2 examples/sec; 0.162 sec/batch; 13h:49m:33s remains)
INFO - root - 2017-12-01 03:44:39.750203: step 26170, loss = 0.53, batch loss = 0.30 (52.5 examples/sec; 0.152 sec/batch; 12h:57m:49s remains)
INFO - root - 2017-12-01 03:44:41.305597: step 26180, loss = 0.53, batch loss = 0.30 (51.8 examples/sec; 0.154 sec/batch; 13h:08m:26s remains)
INFO - root - 2017-12-01 03:44:42.868983: step 26190, loss = 0.64, batch loss = 0.41 (51.5 examples/sec; 0.155 sec/batch; 13h:13m:47s remains)
INFO - root - 2017-12-01 03:44:44.440768: step 26200, loss = 0.48, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 13h:23m:06s remains)
INFO - root - 2017-12-01 03:44:46.049985: step 26210, loss = 0.48, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 13h:09m:30s remains)
INFO - root - 2017-12-01 03:44:47.622461: step 26220, loss = 0.54, batch loss = 0.31 (51.9 examples/sec; 0.154 sec/batch; 13h:06m:22s remains)
INFO - root - 2017-12-01 03:44:49.205946: step 26230, loss = 0.45, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 13h:12m:58s remains)
INFO - root - 2017-12-01 03:44:50.757352: step 26240, loss = 0.44, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 13h:27m:30s remains)
INFO - root - 2017-12-01 03:44:52.333004: step 26250, loss = 0.47, batch loss = 0.24 (52.1 examples/sec; 0.154 sec/batch; 13h:04m:01s remains)
INFO - root - 2017-12-01 03:44:53.926741: step 26260, loss = 0.51, batch loss = 0.28 (51.1 examples/sec; 0.157 sec/batch; 13h:19m:13s remains)
INFO - root - 2017-12-01 03:44:55.472498: step 26270, loss = 0.49, batch loss = 0.27 (50.0 examples/sec; 0.160 sec/batch; 13h:36m:16s remains)
INFO - root - 2017-12-01 03:44:57.042191: step 26280, loss = 0.44, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 13h:22m:46s remains)
INFO - root - 2017-12-01 03:44:58.595509: step 26290, loss = 0.54, batch loss = 0.32 (52.3 examples/sec; 0.153 sec/batch; 13h:00m:45s remains)
INFO - root - 2017-12-01 03:45:00.157638: step 26300, loss = 0.46, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 13h:27m:53s remains)
INFO - root - 2017-12-01 03:45:01.759367: step 26310, loss = 0.64, batch loss = 0.41 (51.8 examples/sec; 0.155 sec/batch; 13h:08m:33s remains)
INFO - root - 2017-12-01 03:45:03.320719: step 26320, loss = 0.56, batch loss = 0.33 (50.4 examples/sec; 0.159 sec/batch; 13h:30m:29s remains)
INFO - root - 2017-12-01 03:45:04.886481: step 26330, loss = 0.59, batch loss = 0.36 (49.0 examples/sec; 0.163 sec/batch; 13h:52m:35s remains)
INFO - root - 2017-12-01 03:45:06.453011: step 26340, loss = 0.60, batch loss = 0.38 (53.0 examples/sec; 0.151 sec/batch; 12h:49m:50s remains)
INFO - root - 2017-12-01 03:45:08.014290: step 26350, loss = 0.52, batch loss = 0.29 (53.1 examples/sec; 0.151 sec/batch; 12h:49m:26s remains)
INFO - root - 2017-12-01 03:45:09.607391: step 26360, loss = 0.45, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 13h:24m:04s remains)
INFO - root - 2017-12-01 03:45:11.221385: step 26370, loss = 0.46, batch loss = 0.23 (40.0 examples/sec; 0.200 sec/batch; 17h:00m:16s remains)
INFO - root - 2017-12-01 03:45:12.819392: step 26380, loss = 0.41, batch loss = 0.19 (50.2 examples/sec; 0.159 sec/batch; 13h:32m:23s remains)
INFO - root - 2017-12-01 03:45:14.377968: step 26390, loss = 0.50, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 13h:31m:49s remains)
INFO - root - 2017-12-01 03:45:15.945153: step 26400, loss = 0.43, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 13h:28m:35s remains)
INFO - root - 2017-12-01 03:45:17.584789: step 26410, loss = 0.53, batch loss = 0.31 (50.6 examples/sec; 0.158 sec/batch; 13h:26m:44s remains)
INFO - root - 2017-12-01 03:45:19.143678: step 26420, loss = 0.42, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 13h:24m:10s remains)
INFO - root - 2017-12-01 03:45:20.700219: step 26430, loss = 0.48, batch loss = 0.26 (53.3 examples/sec; 0.150 sec/batch; 12h:46m:22s remains)
INFO - root - 2017-12-01 03:45:22.272427: step 26440, loss = 0.44, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 13h:24m:35s remains)
INFO - root - 2017-12-01 03:45:23.818564: step 26450, loss = 0.45, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 13h:18m:25s remains)
INFO - root - 2017-12-01 03:45:25.420715: step 26460, loss = 0.47, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 13h:13m:46s remains)
INFO - root - 2017-12-01 03:45:26.985755: step 26470, loss = 0.48, batch loss = 0.25 (49.4 examples/sec; 0.162 sec/batch; 13h:45m:49s remains)
INFO - root - 2017-12-01 03:45:28.550333: step 26480, loss = 0.50, batch loss = 0.28 (52.7 examples/sec; 0.152 sec/batch; 12h:54m:40s remains)
INFO - root - 2017-12-01 03:45:30.139356: step 26490, loss = 0.49, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 13h:26m:00s remains)
INFO - root - 2017-12-01 03:45:31.701407: step 26500, loss = 0.42, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 13h:21m:26s remains)
INFO - root - 2017-12-01 03:45:33.360307: step 26510, loss = 0.52, batch loss = 0.30 (52.0 examples/sec; 0.154 sec/batch; 13h:04m:56s remains)
INFO - root - 2017-12-01 03:45:34.919494: step 26520, loss = 0.41, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 13h:18m:56s remains)
INFO - root - 2017-12-01 03:45:36.475873: step 26530, loss = 0.54, batch loss = 0.31 (49.9 examples/sec; 0.160 sec/batch; 13h:37m:40s remains)
INFO - root - 2017-12-01 03:45:38.042981: step 26540, loss = 0.41, batch loss = 0.18 (52.1 examples/sec; 0.154 sec/batch; 13h:03m:31s remains)
INFO - root - 2017-12-01 03:45:39.611606: step 26550, loss = 0.71, batch loss = 0.49 (52.0 examples/sec; 0.154 sec/batch; 13h:03m:51s remains)
INFO - root - 2017-12-01 03:45:41.211128: step 26560, loss = 0.48, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 13h:26m:28s remains)
INFO - root - 2017-12-01 03:45:42.772079: step 26570, loss = 0.50, batch loss = 0.28 (49.6 examples/sec; 0.161 sec/batch; 13h:42m:14s remains)
INFO - root - 2017-12-01 03:45:44.317523: step 26580, loss = 0.41, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 13h:17m:10s remains)
INFO - root - 2017-12-01 03:45:45.862274: step 26590, loss = 0.55, batch loss = 0.32 (52.2 examples/sec; 0.153 sec/batch; 13h:01m:05s remains)
INFO - root - 2017-12-01 03:45:47.423868: step 26600, loss = 0.43, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 12h:57m:14s remains)
INFO - root - 2017-12-01 03:45:49.050403: step 26610, loss = 0.46, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 13h:37m:33s remains)
INFO - root - 2017-12-01 03:45:50.610669: step 26620, loss = 0.47, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 13h:05m:59s remains)
INFO - root - 2017-12-01 03:45:52.167843: step 26630, loss = 0.47, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 13h:05m:03s remains)
INFO - root - 2017-12-01 03:45:53.728495: step 26640, loss = 0.50, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 13h:01m:07s remains)
INFO - root - 2017-12-01 03:45:55.314145: step 26650, loss = 0.48, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 13h:25m:36s remains)
INFO - root - 2017-12-01 03:45:56.902262: step 26660, loss = 0.43, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 13h:23m:46s remains)
INFO - root - 2017-12-01 03:45:58.463905: step 26670, loss = 0.49, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 13h:19m:16s remains)
INFO - root - 2017-12-01 03:46:00.040536: step 26680, loss = 0.53, batch loss = 0.30 (52.4 examples/sec; 0.153 sec/batch; 12h:57m:57s remains)
INFO - root - 2017-12-01 03:46:01.600134: step 26690, loss = 0.52, batch loss = 0.30 (51.1 examples/sec; 0.157 sec/batch; 13h:18m:32s remains)
INFO - root - 2017-12-01 03:46:03.166255: step 26700, loss = 0.43, batch loss = 0.21 (48.1 examples/sec; 0.166 sec/batch; 14h:07m:15s remains)
INFO - root - 2017-12-01 03:46:04.820530: step 26710, loss = 0.54, batch loss = 0.31 (51.8 examples/sec; 0.154 sec/batch; 13h:06m:22s remains)
INFO - root - 2017-12-01 03:46:06.377157: step 26720, loss = 0.59, batch loss = 0.36 (50.0 examples/sec; 0.160 sec/batch; 13h:34m:59s remains)
INFO - root - 2017-12-01 03:46:07.947369: step 26730, loss = 0.46, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 13h:06m:57s remains)
INFO - root - 2017-12-01 03:46:09.513694: step 26740, loss = 0.55, batch loss = 0.33 (52.8 examples/sec; 0.152 sec/batch; 12h:52m:15s remains)
INFO - root - 2017-12-01 03:46:11.127466: step 26750, loss = 0.50, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 13h:26m:09s remains)
INFO - root - 2017-12-01 03:46:12.725022: step 26760, loss = 0.47, batch loss = 0.25 (50.8 examples/sec; 0.158 sec/batch; 13h:23m:04s remains)
INFO - root - 2017-12-01 03:46:14.317065: step 26770, loss = 0.45, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 13h:10m:07s remains)
INFO - root - 2017-12-01 03:46:15.884896: step 26780, loss = 0.43, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 13h:32m:07s remains)
INFO - root - 2017-12-01 03:46:17.444485: step 26790, loss = 0.47, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 13h:14m:34s remains)
INFO - root - 2017-12-01 03:46:19.022179: step 26800, loss = 0.48, batch loss = 0.26 (49.4 examples/sec; 0.162 sec/batch; 13h:44m:29s remains)
INFO - root - 2017-12-01 03:46:20.704976: step 26810, loss = 0.46, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 13h:23m:38s remains)
INFO - root - 2017-12-01 03:46:22.283914: step 26820, loss = 0.47, batch loss = 0.24 (52.9 examples/sec; 0.151 sec/batch; 12h:49m:43s remains)
INFO - root - 2017-12-01 03:46:23.898509: step 26830, loss = 0.50, batch loss = 0.28 (47.6 examples/sec; 0.168 sec/batch; 14h:15m:24s remains)
INFO - root - 2017-12-01 03:46:25.449154: step 26840, loss = 0.42, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 12h:55m:57s remains)
INFO - root - 2017-12-01 03:46:27.011360: step 26850, loss = 0.53, batch loss = 0.30 (52.6 examples/sec; 0.152 sec/batch; 12h:54m:52s remains)
INFO - root - 2017-12-01 03:46:28.593816: step 26860, loss = 0.45, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 13h:04m:13s remains)
INFO - root - 2017-12-01 03:46:30.190594: step 26870, loss = 0.69, batch loss = 0.46 (51.5 examples/sec; 0.155 sec/batch; 13h:11m:57s remains)
INFO - root - 2017-12-01 03:46:31.739346: step 26880, loss = 0.56, batch loss = 0.34 (52.2 examples/sec; 0.153 sec/batch; 13h:00m:03s remains)
INFO - root - 2017-12-01 03:46:33.325226: step 26890, loss = 0.62, batch loss = 0.40 (51.4 examples/sec; 0.156 sec/batch; 13h:12m:43s remains)
INFO - root - 2017-12-01 03:46:34.888856: step 26900, loss = 0.57, batch loss = 0.34 (51.9 examples/sec; 0.154 sec/batch; 13h:04m:31s remains)
INFO - root - 2017-12-01 03:46:36.509233: step 26910, loss = 0.42, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 13h:34m:41s remains)
INFO - root - 2017-12-01 03:46:38.079794: step 26920, loss = 0.44, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 13h:03m:05s remains)
INFO - root - 2017-12-01 03:46:39.653491: step 26930, loss = 0.43, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 13h:10m:39s remains)
INFO - root - 2017-12-01 03:46:41.211065: step 26940, loss = 0.42, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 12h:59m:11s remains)
INFO - root - 2017-12-01 03:46:42.776010: step 26950, loss = 0.45, batch loss = 0.22 (49.6 examples/sec; 0.161 sec/batch; 13h:41m:52s remains)
INFO - root - 2017-12-01 03:46:44.330957: step 26960, loss = 0.62, batch loss = 0.39 (49.3 examples/sec; 0.162 sec/batch; 13h:46m:59s remains)
INFO - root - 2017-12-01 03:46:45.883919: step 26970, loss = 0.42, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 13h:05m:55s remains)
INFO - root - 2017-12-01 03:46:47.436921: step 26980, loss = 0.45, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 13h:02m:49s remains)
INFO - root - 2017-12-01 03:46:49.008908: step 26990, loss = 0.50, batch loss = 0.28 (50.3 examples/sec; 0.159 sec/batch; 13h:29m:38s remains)
INFO - root - 2017-12-01 03:46:50.569308: step 27000, loss = 0.57, batch loss = 0.35 (51.1 examples/sec; 0.156 sec/batch; 13h:16m:50s remains)
INFO - root - 2017-12-01 03:46:52.179218: step 27010, loss = 0.57, batch loss = 0.35 (52.8 examples/sec; 0.152 sec/batch; 12h:52m:09s remains)
INFO - root - 2017-12-01 03:46:53.778681: step 27020, loss = 0.54, batch loss = 0.32 (51.4 examples/sec; 0.156 sec/batch; 13h:12m:41s remains)
INFO - root - 2017-12-01 03:46:55.348145: step 27030, loss = 0.53, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 13h:16m:10s remains)
INFO - root - 2017-12-01 03:46:56.920968: step 27040, loss = 0.47, batch loss = 0.25 (49.7 examples/sec; 0.161 sec/batch; 13h:39m:57s remains)
INFO - root - 2017-12-01 03:46:58.468787: step 27050, loss = 0.51, batch loss = 0.29 (51.7 examples/sec; 0.155 sec/batch; 13h:07m:11s remains)
INFO - root - 2017-12-01 03:47:00.054591: step 27060, loss = 0.45, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 13h:01m:57s remains)
INFO - root - 2017-12-01 03:47:01.608786: step 27070, loss = 0.44, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 13h:23m:25s remains)
INFO - root - 2017-12-01 03:47:03.202000: step 27080, loss = 0.42, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 13h:24m:27s remains)
INFO - root - 2017-12-01 03:47:04.769113: step 27090, loss = 0.49, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 13h:00m:03s remains)
INFO - root - 2017-12-01 03:47:06.353457: step 27100, loss = 0.48, batch loss = 0.26 (49.5 examples/sec; 0.162 sec/batch; 13h:42m:07s remains)
INFO - root - 2017-12-01 03:47:07.975915: step 27110, loss = 0.44, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 13h:05m:48s remains)
INFO - root - 2017-12-01 03:47:09.547725: step 27120, loss = 0.61, batch loss = 0.39 (50.8 examples/sec; 0.157 sec/batch; 13h:21m:11s remains)
INFO - root - 2017-12-01 03:47:11.125402: step 27130, loss = 0.48, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 13h:14m:45s remains)
INFO - root - 2017-12-01 03:47:12.677871: step 27140, loss = 0.45, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 13h:16m:50s remains)
INFO - root - 2017-12-01 03:47:14.244522: step 27150, loss = 0.63, batch loss = 0.41 (51.2 examples/sec; 0.156 sec/batch; 13h:14m:52s remains)
INFO - root - 2017-12-01 03:47:15.800778: step 27160, loss = 0.51, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 13h:09m:16s remains)
INFO - root - 2017-12-01 03:47:17.389227: step 27170, loss = 0.47, batch loss = 0.25 (47.3 examples/sec; 0.169 sec/batch; 14h:21m:16s remains)
INFO - root - 2017-12-01 03:47:18.980091: step 27180, loss = 0.46, batch loss = 0.24 (49.7 examples/sec; 0.161 sec/batch; 13h:39m:25s remains)
INFO - root - 2017-12-01 03:47:20.550165: step 27190, loss = 0.51, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 13h:22m:32s remains)
INFO - root - 2017-12-01 03:47:22.146751: step 27200, loss = 0.51, batch loss = 0.29 (50.8 examples/sec; 0.157 sec/batch; 13h:21m:15s remains)
INFO - root - 2017-12-01 03:47:23.785079: step 27210, loss = 0.50, batch loss = 0.28 (51.8 examples/sec; 0.154 sec/batch; 13h:05m:11s remains)
INFO - root - 2017-12-01 03:47:25.338452: step 27220, loss = 0.44, batch loss = 0.21 (53.2 examples/sec; 0.150 sec/batch; 12h:45m:18s remains)
INFO - root - 2017-12-01 03:47:26.932786: step 27230, loss = 0.45, batch loss = 0.23 (50.4 examples/sec; 0.159 sec/batch; 13h:27m:34s remains)
INFO - root - 2017-12-01 03:47:28.507647: step 27240, loss = 0.55, batch loss = 0.32 (50.2 examples/sec; 0.159 sec/batch; 13h:31m:24s remains)
INFO - root - 2017-12-01 03:47:30.057325: step 27250, loss = 0.55, batch loss = 0.33 (48.6 examples/sec; 0.165 sec/batch; 13h:57m:54s remains)
INFO - root - 2017-12-01 03:47:31.632995: step 27260, loss = 0.58, batch loss = 0.36 (52.3 examples/sec; 0.153 sec/batch; 12h:58m:22s remains)
INFO - root - 2017-12-01 03:47:33.203630: step 27270, loss = 0.50, batch loss = 0.28 (53.0 examples/sec; 0.151 sec/batch; 12h:48m:28s remains)
INFO - root - 2017-12-01 03:47:34.774783: step 27280, loss = 0.46, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 13h:16m:33s remains)
INFO - root - 2017-12-01 03:47:36.337531: step 27290, loss = 0.43, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 13h:05m:18s remains)
INFO - root - 2017-12-01 03:47:37.896171: step 27300, loss = 0.47, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 13h:11m:57s remains)
INFO - root - 2017-12-01 03:47:39.589259: step 27310, loss = 0.75, batch loss = 0.52 (49.4 examples/sec; 0.162 sec/batch; 13h:43m:15s remains)
INFO - root - 2017-12-01 03:47:41.162240: step 27320, loss = 0.54, batch loss = 0.32 (51.4 examples/sec; 0.156 sec/batch; 13h:12m:09s remains)
INFO - root - 2017-12-01 03:47:42.730582: step 27330, loss = 0.46, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 13h:03m:08s remains)
INFO - root - 2017-12-01 03:47:44.291683: step 27340, loss = 0.53, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 13h:19m:21s remains)
INFO - root - 2017-12-01 03:47:45.828081: step 27350, loss = 0.66, batch loss = 0.44 (50.3 examples/sec; 0.159 sec/batch; 13h:28m:52s remains)
INFO - root - 2017-12-01 03:47:47.383900: step 27360, loss = 0.65, batch loss = 0.43 (52.5 examples/sec; 0.152 sec/batch; 12h:55m:28s remains)
INFO - root - 2017-12-01 03:47:48.946100: step 27370, loss = 0.46, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 13h:01m:58s remains)
INFO - root - 2017-12-01 03:47:50.524074: step 27380, loss = 0.42, batch loss = 0.20 (52.1 examples/sec; 0.153 sec/batch; 13h:00m:10s remains)
INFO - root - 2017-12-01 03:47:52.090866: step 27390, loss = 0.50, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 13h:02m:05s remains)
INFO - root - 2017-12-01 03:47:53.643585: step 27400, loss = 0.44, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 13h:26m:42s remains)
INFO - root - 2017-12-01 03:47:55.253935: step 27410, loss = 0.53, batch loss = 0.31 (51.1 examples/sec; 0.157 sec/batch; 13h:16m:03s remains)
INFO - root - 2017-12-01 03:47:56.821459: step 27420, loss = 0.50, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 13h:09m:31s remains)
INFO - root - 2017-12-01 03:47:58.384811: step 27430, loss = 0.47, batch loss = 0.25 (51.8 examples/sec; 0.155 sec/batch; 13h:05m:46s remains)
INFO - root - 2017-12-01 03:47:59.948648: step 27440, loss = 0.41, batch loss = 0.19 (50.1 examples/sec; 0.160 sec/batch; 13h:31m:48s remains)
INFO - root - 2017-12-01 03:48:01.502619: step 27450, loss = 0.43, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 13h:21m:13s remains)
INFO - root - 2017-12-01 03:48:03.071753: step 27460, loss = 0.53, batch loss = 0.31 (52.0 examples/sec; 0.154 sec/batch; 13h:02m:14s remains)
INFO - root - 2017-12-01 03:48:04.647636: step 27470, loss = 0.43, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 13h:11m:02s remains)
INFO - root - 2017-12-01 03:48:06.218552: step 27480, loss = 0.44, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 13h:20m:23s remains)
INFO - root - 2017-12-01 03:48:07.789453: step 27490, loss = 0.49, batch loss = 0.27 (49.5 examples/sec; 0.162 sec/batch; 13h:41m:50s remains)
INFO - root - 2017-12-01 03:48:09.387952: step 27500, loss = 0.48, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 13h:09m:44s remains)
INFO - root - 2017-12-01 03:48:11.052182: step 27510, loss = 0.56, batch loss = 0.34 (49.1 examples/sec; 0.163 sec/batch; 13h:48m:02s remains)
INFO - root - 2017-12-01 03:48:12.626250: step 27520, loss = 0.45, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 12h:53m:03s remains)
INFO - root - 2017-12-01 03:48:14.188298: step 27530, loss = 0.49, batch loss = 0.27 (50.8 examples/sec; 0.157 sec/batch; 13h:19m:56s remains)
INFO - root - 2017-12-01 03:48:15.749494: step 27540, loss = 0.62, batch loss = 0.40 (50.7 examples/sec; 0.158 sec/batch; 13h:22m:22s remains)
INFO - root - 2017-12-01 03:48:17.312831: step 27550, loss = 0.45, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 13h:17m:55s remains)
INFO - root - 2017-12-01 03:48:18.896632: step 27560, loss = 0.46, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 13h:16m:35s remains)
INFO - root - 2017-12-01 03:48:20.482608: step 27570, loss = 0.47, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 13h:26m:44s remains)
INFO - root - 2017-12-01 03:48:22.040720: step 27580, loss = 0.56, batch loss = 0.34 (47.7 examples/sec; 0.168 sec/batch; 14h:11m:58s remains)
INFO - root - 2017-12-01 03:48:23.592002: step 27590, loss = 0.40, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 12h:58m:02s remains)
INFO - root - 2017-12-01 03:48:25.158470: step 27600, loss = 0.45, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 12h:53m:09s remains)
INFO - root - 2017-12-01 03:48:26.834818: step 27610, loss = 0.53, batch loss = 0.31 (51.9 examples/sec; 0.154 sec/batch; 13h:03m:44s remains)
INFO - root - 2017-12-01 03:48:28.410101: step 27620, loss = 0.47, batch loss = 0.25 (53.4 examples/sec; 0.150 sec/batch; 12h:41m:01s remains)
INFO - root - 2017-12-01 03:48:29.977578: step 27630, loss = 0.56, batch loss = 0.34 (51.4 examples/sec; 0.156 sec/batch; 13h:11m:20s remains)
INFO - root - 2017-12-01 03:48:31.546028: step 27640, loss = 0.45, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 13h:12m:54s remains)
INFO - root - 2017-12-01 03:48:33.102307: step 27650, loss = 0.52, batch loss = 0.30 (50.6 examples/sec; 0.158 sec/batch; 13h:23m:36s remains)
INFO - root - 2017-12-01 03:48:34.662202: step 27660, loss = 0.53, batch loss = 0.31 (52.1 examples/sec; 0.154 sec/batch; 13h:00m:44s remains)
INFO - root - 2017-12-01 03:48:36.239539: step 27670, loss = 0.58, batch loss = 0.35 (49.7 examples/sec; 0.161 sec/batch; 13h:37m:59s remains)
INFO - root - 2017-12-01 03:48:37.800561: step 27680, loss = 0.48, batch loss = 0.26 (50.2 examples/sec; 0.159 sec/batch; 13h:29m:04s remains)
INFO - root - 2017-12-01 03:48:39.360235: step 27690, loss = 0.51, batch loss = 0.28 (51.8 examples/sec; 0.154 sec/batch; 13h:04m:07s remains)
INFO - root - 2017-12-01 03:48:40.939860: step 27700, loss = 0.61, batch loss = 0.38 (49.4 examples/sec; 0.162 sec/batch; 13h:43m:06s remains)
INFO - root - 2017-12-01 03:48:42.621765: step 27710, loss = 0.46, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 13h:24m:03s remains)
INFO - root - 2017-12-01 03:48:44.172995: step 27720, loss = 0.62, batch loss = 0.39 (51.8 examples/sec; 0.154 sec/batch; 13h:04m:15s remains)
INFO - root - 2017-12-01 03:48:45.742768: step 27730, loss = 0.53, batch loss = 0.31 (52.9 examples/sec; 0.151 sec/batch; 12h:48m:28s remains)
INFO - root - 2017-12-01 03:48:47.332820: step 27740, loss = 0.49, batch loss = 0.27 (51.9 examples/sec; 0.154 sec/batch; 13h:02m:29s remains)
INFO - root - 2017-12-01 03:48:48.884175: step 27750, loss = 0.49, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 13h:22m:56s remains)
INFO - root - 2017-12-01 03:48:50.452515: step 27760, loss = 0.44, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 13h:24m:29s remains)
INFO - root - 2017-12-01 03:48:52.012865: step 27770, loss = 0.44, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 13h:03m:42s remains)
INFO - root - 2017-12-01 03:48:53.583566: step 27780, loss = 0.42, batch loss = 0.20 (47.9 examples/sec; 0.167 sec/batch; 14h:08m:25s remains)
INFO - root - 2017-12-01 03:48:55.138553: step 27790, loss = 0.46, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 13h:02m:40s remains)
INFO - root - 2017-12-01 03:48:56.712685: step 27800, loss = 0.66, batch loss = 0.44 (50.3 examples/sec; 0.159 sec/batch; 13h:27m:33s remains)
INFO - root - 2017-12-01 03:48:58.329605: step 27810, loss = 0.46, batch loss = 0.24 (52.1 examples/sec; 0.153 sec/batch; 12h:59m:02s remains)
INFO - root - 2017-12-01 03:48:59.882076: step 27820, loss = 0.41, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 13h:22m:03s remains)
INFO - root - 2017-12-01 03:49:01.451548: step 27830, loss = 0.45, batch loss = 0.23 (49.2 examples/sec; 0.163 sec/batch; 13h:45m:46s remains)
INFO - root - 2017-12-01 03:49:03.013338: step 27840, loss = 0.47, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 13h:16m:36s remains)
INFO - root - 2017-12-01 03:49:04.582406: step 27850, loss = 0.48, batch loss = 0.26 (48.4 examples/sec; 0.165 sec/batch; 13h:59m:35s remains)
INFO - root - 2017-12-01 03:49:06.152318: step 27860, loss = 0.46, batch loss = 0.24 (50.8 examples/sec; 0.157 sec/batch; 13h:19m:34s remains)
INFO - root - 2017-12-01 03:49:07.733187: step 27870, loss = 0.53, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 13h:18m:28s remains)
INFO - root - 2017-12-01 03:49:09.282834: step 27880, loss = 0.47, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 13h:17m:30s remains)
INFO - root - 2017-12-01 03:49:10.837597: step 27890, loss = 0.48, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 13h:11m:23s remains)
INFO - root - 2017-12-01 03:49:12.413236: step 27900, loss = 0.46, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 12h:51m:52s remains)
INFO - root - 2017-12-01 03:49:14.064049: step 27910, loss = 0.62, batch loss = 0.40 (49.1 examples/sec; 0.163 sec/batch; 13h:47m:28s remains)
INFO - root - 2017-12-01 03:49:15.614345: step 27920, loss = 0.46, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 12h:55m:59s remains)
INFO - root - 2017-12-01 03:49:17.177108: step 27930, loss = 0.45, batch loss = 0.22 (48.8 examples/sec; 0.164 sec/batch; 13h:51m:44s remains)
INFO - root - 2017-12-01 03:49:18.743473: step 27940, loss = 0.52, batch loss = 0.29 (52.4 examples/sec; 0.153 sec/batch; 12h:54m:45s remains)
INFO - root - 2017-12-01 03:49:20.291238: step 27950, loss = 0.40, batch loss = 0.18 (52.5 examples/sec; 0.153 sec/batch; 12h:54m:11s remains)
INFO - root - 2017-12-01 03:49:21.869881: step 27960, loss = 0.46, batch loss = 0.24 (49.7 examples/sec; 0.161 sec/batch; 13h:37m:41s remains)
INFO - root - 2017-12-01 03:49:23.435249: step 27970, loss = 0.60, batch loss = 0.38 (49.0 examples/sec; 0.163 sec/batch; 13h:48m:39s remains)
INFO - root - 2017-12-01 03:49:24.996606: step 27980, loss = 0.42, batch loss = 0.20 (53.1 examples/sec; 0.151 sec/batch; 12h:45m:00s remains)
INFO - root - 2017-12-01 03:49:26.586329: step 27990, loss = 0.52, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 13h:18m:08s remains)
INFO - root - 2017-12-01 03:49:28.154082: step 28000, loss = 0.73, batch loss = 0.50 (50.9 examples/sec; 0.157 sec/batch; 13h:18m:08s remains)
INFO - root - 2017-12-01 03:49:29.787482: step 28010, loss = 0.49, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 13h:22m:34s remains)
INFO - root - 2017-12-01 03:49:31.382074: step 28020, loss = 0.39, batch loss = 0.17 (50.1 examples/sec; 0.160 sec/batch; 13h:31m:05s remains)
INFO - root - 2017-12-01 03:49:32.953574: step 28030, loss = 0.49, batch loss = 0.27 (48.0 examples/sec; 0.167 sec/batch; 14h:05m:53s remains)
INFO - root - 2017-12-01 03:49:34.525257: step 28040, loss = 0.50, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 13h:02m:35s remains)
INFO - root - 2017-12-01 03:49:36.093225: step 28050, loss = 0.49, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 12h:57m:07s remains)
INFO - root - 2017-12-01 03:49:37.644408: step 28060, loss = 0.41, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 13h:18m:55s remains)
INFO - root - 2017-12-01 03:49:39.205931: step 28070, loss = 0.40, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 13h:28m:46s remains)
INFO - root - 2017-12-01 03:49:40.844860: step 28080, loss = 0.55, batch loss = 0.33 (40.6 examples/sec; 0.197 sec/batch; 16h:40m:15s remains)
INFO - root - 2017-12-01 03:49:42.422695: step 28090, loss = 0.45, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 13h:28m:39s remains)
INFO - root - 2017-12-01 03:49:43.984079: step 28100, loss = 0.46, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 13h:05m:02s remains)
INFO - root - 2017-12-01 03:49:45.618146: step 28110, loss = 0.54, batch loss = 0.31 (51.5 examples/sec; 0.155 sec/batch; 13h:08m:40s remains)
INFO - root - 2017-12-01 03:49:47.199049: step 28120, loss = 0.45, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 13h:22m:05s remains)
INFO - root - 2017-12-01 03:49:48.750821: step 28130, loss = 0.51, batch loss = 0.28 (52.7 examples/sec; 0.152 sec/batch; 12h:50m:38s remains)
INFO - root - 2017-12-01 03:49:50.305692: step 28140, loss = 0.53, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 13h:12m:47s remains)
INFO - root - 2017-12-01 03:49:51.904834: step 28150, loss = 0.48, batch loss = 0.26 (50.2 examples/sec; 0.159 sec/batch; 13h:28m:37s remains)
INFO - root - 2017-12-01 03:49:53.484442: step 28160, loss = 0.49, batch loss = 0.27 (50.8 examples/sec; 0.158 sec/batch; 13h:19m:17s remains)
INFO - root - 2017-12-01 03:49:55.051294: step 28170, loss = 0.49, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 13h:02m:44s remains)
INFO - root - 2017-12-01 03:49:56.610848: step 28180, loss = 0.41, batch loss = 0.19 (53.8 examples/sec; 0.149 sec/batch; 12h:34m:30s remains)
INFO - root - 2017-12-01 03:49:58.182090: step 28190, loss = 0.48, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 13h:07m:30s remains)
INFO - root - 2017-12-01 03:49:59.755837: step 28200, loss = 0.56, batch loss = 0.34 (50.9 examples/sec; 0.157 sec/batch; 13h:17m:23s remains)
INFO - root - 2017-12-01 03:50:01.377288: step 28210, loss = 0.51, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 13h:19m:44s remains)
INFO - root - 2017-12-01 03:50:02.950094: step 28220, loss = 0.54, batch loss = 0.32 (51.1 examples/sec; 0.156 sec/batch; 13h:13m:33s remains)
INFO - root - 2017-12-01 03:50:04.512603: step 28230, loss = 0.54, batch loss = 0.32 (48.8 examples/sec; 0.164 sec/batch; 13h:51m:43s remains)
INFO - root - 2017-12-01 03:50:06.064540: step 28240, loss = 0.54, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 13h:17m:19s remains)
INFO - root - 2017-12-01 03:50:07.625287: step 28250, loss = 0.54, batch loss = 0.32 (51.8 examples/sec; 0.154 sec/batch; 13h:03m:08s remains)
INFO - root - 2017-12-01 03:50:09.173800: step 28260, loss = 0.47, batch loss = 0.24 (53.0 examples/sec; 0.151 sec/batch; 12h:44m:53s remains)
INFO - root - 2017-12-01 03:50:10.983331: step 28270, loss = 0.53, batch loss = 0.30 (51.9 examples/sec; 0.154 sec/batch; 13h:00m:56s remains)
INFO - root - 2017-12-01 03:50:12.528099: step 28280, loss = 0.44, batch loss = 0.22 (53.2 examples/sec; 0.150 sec/batch; 12h:42m:24s remains)
INFO - root - 2017-12-01 03:50:14.081694: step 28290, loss = 0.51, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 13h:06m:50s remains)
INFO - root - 2017-12-01 03:50:15.645252: step 28300, loss = 0.46, batch loss = 0.24 (52.8 examples/sec; 0.152 sec/batch; 12h:48m:18s remains)
INFO - root - 2017-12-01 03:50:17.292547: step 28310, loss = 0.52, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 13h:19m:32s remains)
INFO - root - 2017-12-01 03:50:18.858420: step 28320, loss = 0.45, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 13h:11m:43s remains)
INFO - root - 2017-12-01 03:50:20.454543: step 28330, loss = 0.49, batch loss = 0.27 (52.1 examples/sec; 0.154 sec/batch; 12h:58m:48s remains)
INFO - root - 2017-12-01 03:50:22.026959: step 28340, loss = 0.46, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 13h:09m:53s remains)
INFO - root - 2017-12-01 03:50:23.587178: step 28350, loss = 0.45, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 13h:18m:45s remains)
INFO - root - 2017-12-01 03:50:25.148349: step 28360, loss = 0.45, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 13h:07m:30s remains)
INFO - root - 2017-12-01 03:50:26.701542: step 28370, loss = 0.44, batch loss = 0.21 (53.9 examples/sec; 0.148 sec/batch; 12h:31m:53s remains)
INFO - root - 2017-12-01 03:50:28.261139: step 28380, loss = 0.48, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 13h:01m:50s remains)
INFO - root - 2017-12-01 03:50:29.821097: step 28390, loss = 0.47, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 13h:02m:36s remains)
INFO - root - 2017-12-01 03:50:31.393186: step 28400, loss = 0.41, batch loss = 0.19 (50.2 examples/sec; 0.159 sec/batch; 13h:27m:17s remains)
INFO - root - 2017-12-01 03:50:33.047454: step 28410, loss = 0.45, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 12h:58m:53s remains)
INFO - root - 2017-12-01 03:50:34.667560: step 28420, loss = 0.46, batch loss = 0.24 (46.5 examples/sec; 0.172 sec/batch; 14h:32m:22s remains)
INFO - root - 2017-12-01 03:50:36.253207: step 28430, loss = 0.51, batch loss = 0.29 (52.4 examples/sec; 0.153 sec/batch; 12h:53m:41s remains)
INFO - root - 2017-12-01 03:50:37.847738: step 28440, loss = 0.56, batch loss = 0.34 (44.1 examples/sec; 0.182 sec/batch; 15h:19m:53s remains)
INFO - root - 2017-12-01 03:50:39.384121: step 28450, loss = 0.50, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 13h:03m:56s remains)
INFO - root - 2017-12-01 03:50:40.949918: step 28460, loss = 0.42, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 13h:01m:45s remains)
INFO - root - 2017-12-01 03:50:42.533811: step 28470, loss = 0.49, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 13h:25m:29s remains)
INFO - root - 2017-12-01 03:50:44.105131: step 28480, loss = 0.56, batch loss = 0.34 (50.7 examples/sec; 0.158 sec/batch; 13h:18m:48s remains)
INFO - root - 2017-12-01 03:50:45.673573: step 28490, loss = 0.62, batch loss = 0.40 (51.9 examples/sec; 0.154 sec/batch; 13h:00m:52s remains)
INFO - root - 2017-12-01 03:50:47.231180: step 28500, loss = 0.59, batch loss = 0.37 (51.2 examples/sec; 0.156 sec/batch; 13h:11m:32s remains)
INFO - root - 2017-12-01 03:50:49.051875: step 28510, loss = 0.48, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 13h:21m:13s remains)
INFO - root - 2017-12-01 03:50:50.606739: step 28520, loss = 0.42, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 12h:52m:57s remains)
INFO - root - 2017-12-01 03:50:52.347635: step 28530, loss = 0.61, batch loss = 0.39 (37.1 examples/sec; 0.216 sec/batch; 18h:12m:41s remains)
INFO - root - 2017-12-01 03:50:53.908658: step 28540, loss = 0.50, batch loss = 0.28 (51.8 examples/sec; 0.154 sec/batch; 13h:02m:34s remains)
INFO - root - 2017-12-01 03:50:55.545219: step 28550, loss = 0.43, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 13h:06m:45s remains)
INFO - root - 2017-12-01 03:50:57.185810: step 28560, loss = 0.50, batch loss = 0.28 (36.9 examples/sec; 0.217 sec/batch; 18h:19m:00s remains)
INFO - root - 2017-12-01 03:50:58.746318: step 28570, loss = 0.46, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 13h:25m:23s remains)
INFO - root - 2017-12-01 03:51:00.365934: step 28580, loss = 0.42, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 13h:12m:26s remains)
INFO - root - 2017-12-01 03:51:01.927824: step 28590, loss = 0.53, batch loss = 0.31 (51.5 examples/sec; 0.155 sec/batch; 13h:06m:26s remains)
INFO - root - 2017-12-01 03:51:03.505064: step 28600, loss = 0.44, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 13h:05m:13s remains)
INFO - root - 2017-12-01 03:51:05.201694: step 28610, loss = 0.47, batch loss = 0.25 (49.6 examples/sec; 0.161 sec/batch; 13h:36m:50s remains)
INFO - root - 2017-12-01 03:51:06.811009: step 28620, loss = 0.38, batch loss = 0.15 (52.3 examples/sec; 0.153 sec/batch; 12h:54m:11s remains)
INFO - root - 2017-12-01 03:51:08.425988: step 28630, loss = 0.42, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 13h:30m:19s remains)
INFO - root - 2017-12-01 03:51:10.001104: step 28640, loss = 0.51, batch loss = 0.29 (48.8 examples/sec; 0.164 sec/batch; 13h:49m:43s remains)
INFO - root - 2017-12-01 03:51:11.608373: step 28650, loss = 0.46, batch loss = 0.24 (52.5 examples/sec; 0.152 sec/batch; 12h:51m:53s remains)
INFO - root - 2017-12-01 03:51:13.182538: step 28660, loss = 0.51, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 13h:15m:23s remains)
INFO - root - 2017-12-01 03:51:14.774740: step 28670, loss = 0.50, batch loss = 0.28 (52.0 examples/sec; 0.154 sec/batch; 12h:59m:16s remains)
INFO - root - 2017-12-01 03:51:16.337810: step 28680, loss = 0.44, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 13h:18m:46s remains)
INFO - root - 2017-12-01 03:51:17.909599: step 28690, loss = 0.46, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 13h:23m:52s remains)
INFO - root - 2017-12-01 03:51:19.473838: step 28700, loss = 0.45, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 13h:14m:52s remains)
INFO - root - 2017-12-01 03:51:21.173965: step 28710, loss = 0.45, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 13h:31m:57s remains)
INFO - root - 2017-12-01 03:51:22.757978: step 28720, loss = 0.66, batch loss = 0.44 (50.4 examples/sec; 0.159 sec/batch; 13h:22m:59s remains)
INFO - root - 2017-12-01 03:51:24.479913: step 28730, loss = 0.50, batch loss = 0.27 (47.9 examples/sec; 0.167 sec/batch; 14h:06m:25s remains)
INFO - root - 2017-12-01 03:51:26.073871: step 28740, loss = 0.45, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 13h:06m:20s remains)
INFO - root - 2017-12-01 03:51:27.647763: step 28750, loss = 0.67, batch loss = 0.45 (49.2 examples/sec; 0.163 sec/batch; 13h:43m:15s remains)
INFO - root - 2017-12-01 03:51:29.219664: step 28760, loss = 0.52, batch loss = 0.30 (52.8 examples/sec; 0.151 sec/batch; 12h:46m:26s remains)
INFO - root - 2017-12-01 03:51:30.839353: step 28770, loss = 0.61, batch loss = 0.39 (50.7 examples/sec; 0.158 sec/batch; 13h:19m:26s remains)
INFO - root - 2017-12-01 03:51:32.457877: step 28780, loss = 0.58, batch loss = 0.36 (51.5 examples/sec; 0.155 sec/batch; 13h:05m:47s remains)
INFO - root - 2017-12-01 03:51:34.026065: step 28790, loss = 0.65, batch loss = 0.42 (50.3 examples/sec; 0.159 sec/batch; 13h:25m:11s remains)
INFO - root - 2017-12-01 03:51:35.618177: step 28800, loss = 0.53, batch loss = 0.31 (51.4 examples/sec; 0.156 sec/batch; 13h:07m:30s remains)
INFO - root - 2017-12-01 03:51:37.226113: step 28810, loss = 0.39, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 13h:08m:27s remains)
INFO - root - 2017-12-01 03:51:38.794863: step 28820, loss = 0.50, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 13h:13m:48s remains)
INFO - root - 2017-12-01 03:51:40.365073: step 28830, loss = 0.57, batch loss = 0.35 (51.7 examples/sec; 0.155 sec/batch; 13h:02m:53s remains)
INFO - root - 2017-12-01 03:51:41.903098: step 28840, loss = 0.54, batch loss = 0.32 (51.4 examples/sec; 0.156 sec/batch; 13h:07m:46s remains)
INFO - root - 2017-12-01 03:51:43.458830: step 28850, loss = 0.56, batch loss = 0.34 (50.1 examples/sec; 0.160 sec/batch; 13h:27m:58s remains)
INFO - root - 2017-12-01 03:51:45.016571: step 28860, loss = 0.61, batch loss = 0.39 (51.9 examples/sec; 0.154 sec/batch; 13h:00m:46s remains)
INFO - root - 2017-12-01 03:51:46.571360: step 28870, loss = 0.43, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 12h:58m:17s remains)
INFO - root - 2017-12-01 03:51:48.133329: step 28880, loss = 0.65, batch loss = 0.43 (52.3 examples/sec; 0.153 sec/batch; 12h:54m:46s remains)
INFO - root - 2017-12-01 03:51:49.726673: step 28890, loss = 0.42, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 13h:09m:00s remains)
INFO - root - 2017-12-01 03:51:51.294537: step 28900, loss = 0.59, batch loss = 0.37 (48.9 examples/sec; 0.163 sec/batch; 13h:47m:00s remains)
INFO - root - 2017-12-01 03:51:52.912939: step 28910, loss = 0.57, batch loss = 0.35 (51.4 examples/sec; 0.156 sec/batch; 13h:07m:47s remains)
INFO - root - 2017-12-01 03:51:54.470347: step 28920, loss = 0.54, batch loss = 0.32 (51.8 examples/sec; 0.154 sec/batch; 13h:01m:27s remains)
INFO - root - 2017-12-01 03:51:56.020842: step 28930, loss = 0.53, batch loss = 0.31 (51.9 examples/sec; 0.154 sec/batch; 13h:00m:34s remains)
INFO - root - 2017-12-01 03:51:57.595877: step 28940, loss = 0.52, batch loss = 0.30 (48.9 examples/sec; 0.163 sec/batch; 13h:46m:55s remains)
INFO - root - 2017-12-01 03:51:59.153750: step 28950, loss = 0.42, batch loss = 0.20 (53.3 examples/sec; 0.150 sec/batch; 12h:38m:40s remains)
INFO - root - 2017-12-01 03:52:00.707026: step 28960, loss = 0.57, batch loss = 0.35 (50.8 examples/sec; 0.157 sec/batch; 13h:16m:37s remains)
INFO - root - 2017-12-01 03:52:02.398571: step 28970, loss = 0.46, batch loss = 0.24 (52.5 examples/sec; 0.152 sec/batch; 12h:50m:38s remains)
INFO - root - 2017-12-01 03:52:03.968426: step 28980, loss = 0.41, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 12h:57m:45s remains)
INFO - root - 2017-12-01 03:52:05.554526: step 28990, loss = 0.43, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 12h:52m:14s remains)
INFO - root - 2017-12-01 03:52:07.109012: step 29000, loss = 0.59, batch loss = 0.37 (51.6 examples/sec; 0.155 sec/batch; 13h:04m:14s remains)
INFO - root - 2017-12-01 03:52:08.762905: step 29010, loss = 0.46, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 13h:11m:36s remains)
INFO - root - 2017-12-01 03:52:10.312571: step 29020, loss = 0.45, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 13h:04m:29s remains)
INFO - root - 2017-12-01 03:52:11.868715: step 29030, loss = 0.48, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 13h:15m:16s remains)
INFO - root - 2017-12-01 03:52:13.434000: step 29040, loss = 0.48, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 12h:59m:09s remains)
INFO - root - 2017-12-01 03:52:14.984652: step 29050, loss = 0.56, batch loss = 0.34 (53.1 examples/sec; 0.151 sec/batch; 12h:41m:52s remains)
INFO - root - 2017-12-01 03:52:16.550762: step 29060, loss = 0.46, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 13h:09m:07s remains)
INFO - root - 2017-12-01 03:52:18.119998: step 29070, loss = 0.44, batch loss = 0.22 (49.6 examples/sec; 0.161 sec/batch; 13h:36m:13s remains)
INFO - root - 2017-12-01 03:52:19.676434: step 29080, loss = 0.51, batch loss = 0.29 (52.8 examples/sec; 0.152 sec/batch; 12h:46m:39s remains)
INFO - root - 2017-12-01 03:52:21.243290: step 29090, loss = 0.46, batch loss = 0.24 (52.7 examples/sec; 0.152 sec/batch; 12h:47m:20s remains)
INFO - root - 2017-12-01 03:52:22.812266: step 29100, loss = 0.40, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 12h:58m:59s remains)
INFO - root - 2017-12-01 03:52:24.451048: step 29110, loss = 0.66, batch loss = 0.44 (51.6 examples/sec; 0.155 sec/batch; 13h:04m:35s remains)
INFO - root - 2017-12-01 03:52:26.018076: step 29120, loss = 0.44, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 12h:49m:40s remains)
INFO - root - 2017-12-01 03:52:27.615589: step 29130, loss = 0.41, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 13h:02m:48s remains)
INFO - root - 2017-12-01 03:52:29.211712: step 29140, loss = 0.60, batch loss = 0.38 (51.4 examples/sec; 0.156 sec/batch; 13h:07m:06s remains)
INFO - root - 2017-12-01 03:52:30.785447: step 29150, loss = 0.52, batch loss = 0.30 (50.8 examples/sec; 0.158 sec/batch; 13h:16m:35s remains)
INFO - root - 2017-12-01 03:52:32.337269: step 29160, loss = 0.49, batch loss = 0.27 (52.4 examples/sec; 0.153 sec/batch; 12h:52m:16s remains)
INFO - root - 2017-12-01 03:52:33.936460: step 29170, loss = 0.59, batch loss = 0.37 (50.3 examples/sec; 0.159 sec/batch; 13h:23m:44s remains)
INFO - root - 2017-12-01 03:52:35.502788: step 29180, loss = 0.47, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 12h:59m:36s remains)
INFO - root - 2017-12-01 03:52:37.081513: step 29190, loss = 0.41, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 13h:08m:55s remains)
INFO - root - 2017-12-01 03:52:38.639739: step 29200, loss = 0.42, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 12h:58m:28s remains)
INFO - root - 2017-12-01 03:52:40.250207: step 29210, loss = 0.48, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 13h:05m:20s remains)
INFO - root - 2017-12-01 03:52:41.822577: step 29220, loss = 0.49, batch loss = 0.27 (51.7 examples/sec; 0.155 sec/batch; 13h:01m:55s remains)
INFO - root - 2017-12-01 03:52:43.392481: step 29230, loss = 0.45, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 12h:57m:08s remains)
INFO - root - 2017-12-01 03:52:44.957954: step 29240, loss = 0.43, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 13h:13m:20s remains)
INFO - root - 2017-12-01 03:52:46.517238: step 29250, loss = 0.60, batch loss = 0.38 (51.4 examples/sec; 0.156 sec/batch; 13h:06m:54s remains)
INFO - root - 2017-12-01 03:52:48.074709: step 29260, loss = 0.42, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 12h:49m:18s remains)
INFO - root - 2017-12-01 03:52:49.621627: step 29270, loss = 0.57, batch loss = 0.35 (51.2 examples/sec; 0.156 sec/batch; 13h:08m:56s remains)
INFO - root - 2017-12-01 03:52:51.180494: step 29280, loss = 0.48, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 12h:58m:53s remains)
INFO - root - 2017-12-01 03:52:52.750426: step 29290, loss = 0.42, batch loss = 0.20 (51.8 examples/sec; 0.155 sec/batch; 13h:00m:55s remains)
INFO - root - 2017-12-01 03:52:54.320343: step 29300, loss = 0.51, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 13h:23m:22s remains)
INFO - root - 2017-12-01 03:52:55.966309: step 29310, loss = 0.60, batch loss = 0.38 (52.2 examples/sec; 0.153 sec/batch; 12h:54m:31s remains)
INFO - root - 2017-12-01 03:52:57.551042: step 29320, loss = 0.40, batch loss = 0.18 (49.3 examples/sec; 0.162 sec/batch; 13h:39m:55s remains)
INFO - root - 2017-12-01 03:52:59.089390: step 29330, loss = 0.51, batch loss = 0.29 (51.0 examples/sec; 0.157 sec/batch; 13h:12m:51s remains)
INFO - root - 2017-12-01 03:53:00.658416: step 29340, loss = 0.48, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 12h:58m:18s remains)
INFO - root - 2017-12-01 03:53:02.227882: step 29350, loss = 0.43, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 13h:07m:04s remains)
INFO - root - 2017-12-01 03:53:03.811338: step 29360, loss = 0.45, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 13h:01m:10s remains)
INFO - root - 2017-12-01 03:53:05.364981: step 29370, loss = 0.52, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 13h:09m:33s remains)
INFO - root - 2017-12-01 03:53:06.925415: step 29380, loss = 0.43, batch loss = 0.21 (50.0 examples/sec; 0.160 sec/batch; 13h:27m:43s remains)
INFO - root - 2017-12-01 03:53:08.472942: step 29390, loss = 0.47, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 12h:50m:18s remains)
INFO - root - 2017-12-01 03:53:10.037773: step 29400, loss = 0.53, batch loss = 0.31 (51.4 examples/sec; 0.155 sec/batch; 13h:05m:31s remains)
INFO - root - 2017-12-01 03:53:11.642506: step 29410, loss = 0.46, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 13h:11m:53s remains)
INFO - root - 2017-12-01 03:53:13.228492: step 29420, loss = 0.47, batch loss = 0.25 (46.6 examples/sec; 0.172 sec/batch; 14h:28m:02s remains)
INFO - root - 2017-12-01 03:53:14.774497: step 29430, loss = 0.57, batch loss = 0.35 (52.1 examples/sec; 0.154 sec/batch; 12h:56m:16s remains)
INFO - root - 2017-12-01 03:53:16.337341: step 29440, loss = 0.46, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 13h:05m:26s remains)
INFO - root - 2017-12-01 03:53:17.897867: step 29450, loss = 0.43, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 12h:51m:08s remains)
INFO - root - 2017-12-01 03:53:19.484390: step 29460, loss = 0.42, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 13h:10m:55s remains)
INFO - root - 2017-12-01 03:53:21.042864: step 29470, loss = 0.48, batch loss = 0.26 (49.6 examples/sec; 0.161 sec/batch; 13h:34m:48s remains)
INFO - root - 2017-12-01 03:53:22.609788: step 29480, loss = 0.43, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 13h:06m:09s remains)
INFO - root - 2017-12-01 03:53:24.166785: step 29490, loss = 0.46, batch loss = 0.24 (52.7 examples/sec; 0.152 sec/batch; 12h:46m:19s remains)
INFO - root - 2017-12-01 03:53:25.724025: step 29500, loss = 0.53, batch loss = 0.31 (49.4 examples/sec; 0.162 sec/batch; 13h:38m:21s remains)
INFO - root - 2017-12-01 03:53:27.427821: step 29510, loss = 0.52, batch loss = 0.30 (52.1 examples/sec; 0.154 sec/batch; 12h:55m:16s remains)
INFO - root - 2017-12-01 03:53:28.994030: step 29520, loss = 0.51, batch loss = 0.29 (51.0 examples/sec; 0.157 sec/batch; 13h:12m:14s remains)
INFO - root - 2017-12-01 03:53:30.551074: step 29530, loss = 0.67, batch loss = 0.45 (50.2 examples/sec; 0.159 sec/batch; 13h:25m:19s remains)
INFO - root - 2017-12-01 03:53:32.114814: step 29540, loss = 0.42, batch loss = 0.20 (47.9 examples/sec; 0.167 sec/batch; 14h:03m:16s remains)
INFO - root - 2017-12-01 03:53:33.694757: step 29550, loss = 0.47, batch loss = 0.25 (50.8 examples/sec; 0.157 sec/batch; 13h:14m:30s remains)
INFO - root - 2017-12-01 03:53:35.267302: step 29560, loss = 0.48, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 13h:14m:13s remains)
INFO - root - 2017-12-01 03:53:36.822191: step 29570, loss = 0.46, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 13h:14m:09s remains)
INFO - root - 2017-12-01 03:53:38.388693: step 29580, loss = 0.50, batch loss = 0.28 (50.1 examples/sec; 0.160 sec/batch; 13h:26m:19s remains)
INFO - root - 2017-12-01 03:53:39.953107: step 29590, loss = 0.57, batch loss = 0.35 (48.4 examples/sec; 0.165 sec/batch; 13h:54m:17s remains)
INFO - root - 2017-12-01 03:53:41.515091: step 29600, loss = 0.58, batch loss = 0.36 (51.0 examples/sec; 0.157 sec/batch; 13h:11m:51s remains)
INFO - root - 2017-12-01 03:53:43.128470: step 29610, loss = 0.64, batch loss = 0.42 (50.0 examples/sec; 0.160 sec/batch; 13h:27m:43s remains)
INFO - root - 2017-12-01 03:53:44.683994: step 29620, loss = 0.47, batch loss = 0.25 (47.8 examples/sec; 0.167 sec/batch; 14h:05m:12s remains)
INFO - root - 2017-12-01 03:53:46.265356: step 29630, loss = 0.47, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 12h:59m:03s remains)
INFO - root - 2017-12-01 03:53:47.825438: step 29640, loss = 0.50, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 13h:17m:42s remains)
INFO - root - 2017-12-01 03:53:49.384871: step 29650, loss = 0.53, batch loss = 0.31 (50.8 examples/sec; 0.158 sec/batch; 13h:15m:17s remains)
INFO - root - 2017-12-01 03:53:50.936767: step 29660, loss = 0.51, batch loss = 0.29 (52.1 examples/sec; 0.154 sec/batch; 12h:55m:36s remains)
INFO - root - 2017-12-01 03:53:52.500610: step 29670, loss = 0.46, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 13h:04m:46s remains)
INFO - root - 2017-12-01 03:53:54.066737: step 29680, loss = 0.41, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 13h:06m:58s remains)
INFO - root - 2017-12-01 03:53:55.619889: step 29690, loss = 0.51, batch loss = 0.29 (52.0 examples/sec; 0.154 sec/batch; 12h:55m:50s remains)
INFO - root - 2017-12-01 03:53:57.182884: step 29700, loss = 0.46, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 13h:12m:05s remains)
INFO - root - 2017-12-01 03:53:58.815917: step 29710, loss = 0.53, batch loss = 0.31 (49.6 examples/sec; 0.161 sec/batch; 13h:33m:55s remains)
INFO - root - 2017-12-01 03:54:00.394731: step 29720, loss = 0.57, batch loss = 0.35 (52.1 examples/sec; 0.154 sec/batch; 12h:55m:35s remains)
INFO - root - 2017-12-01 03:54:01.957052: step 29730, loss = 0.41, batch loss = 0.19 (50.2 examples/sec; 0.159 sec/batch; 13h:24m:00s remains)
INFO - root - 2017-12-01 03:54:03.527255: step 29740, loss = 0.51, batch loss = 0.29 (53.3 examples/sec; 0.150 sec/batch; 12h:37m:30s remains)
INFO - root - 2017-12-01 03:54:05.100198: step 29750, loss = 0.55, batch loss = 0.34 (52.9 examples/sec; 0.151 sec/batch; 12h:43m:28s remains)
INFO - root - 2017-12-01 03:54:06.696570: step 29760, loss = 0.50, batch loss = 0.29 (51.0 examples/sec; 0.157 sec/batch; 13h:10m:53s remains)
INFO - root - 2017-12-01 03:54:08.281387: step 29770, loss = 0.44, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 13h:25m:26s remains)
INFO - root - 2017-12-01 03:54:09.885690: step 29780, loss = 0.51, batch loss = 0.29 (50.1 examples/sec; 0.160 sec/batch; 13h:25m:30s remains)
INFO - root - 2017-12-01 03:54:11.489501: step 29790, loss = 0.74, batch loss = 0.52 (50.3 examples/sec; 0.159 sec/batch; 13h:23m:03s remains)
INFO - root - 2017-12-01 03:54:13.047409: step 29800, loss = 0.42, batch loss = 0.21 (52.7 examples/sec; 0.152 sec/batch; 12h:45m:36s remains)
INFO - root - 2017-12-01 03:54:14.745084: step 29810, loss = 0.41, batch loss = 0.19 (50.1 examples/sec; 0.160 sec/batch; 13h:26m:17s remains)
INFO - root - 2017-12-01 03:54:16.312963: step 29820, loss = 0.56, batch loss = 0.34 (52.2 examples/sec; 0.153 sec/batch; 12h:53m:39s remains)
INFO - root - 2017-12-01 03:54:17.903133: step 29830, loss = 0.50, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 13h:02m:53s remains)
INFO - root - 2017-12-01 03:54:19.535308: step 29840, loss = 0.66, batch loss = 0.44 (50.1 examples/sec; 0.160 sec/batch; 13h:25m:30s remains)
INFO - root - 2017-12-01 03:54:21.106000: step 29850, loss = 0.39, batch loss = 0.18 (53.4 examples/sec; 0.150 sec/batch; 12h:35m:45s remains)
INFO - root - 2017-12-01 03:54:22.672405: step 29860, loss = 0.48, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 13h:04m:49s remains)
INFO - root - 2017-12-01 03:54:24.244685: step 29870, loss = 0.56, batch loss = 0.34 (50.8 examples/sec; 0.158 sec/batch; 13h:14m:51s remains)
INFO - root - 2017-12-01 03:54:25.805664: step 29880, loss = 0.40, batch loss = 0.18 (50.1 examples/sec; 0.160 sec/batch; 13h:24m:42s remains)
INFO - root - 2017-12-01 03:54:27.378659: step 29890, loss = 0.54, batch loss = 0.32 (52.1 examples/sec; 0.154 sec/batch; 12h:54m:57s remains)
INFO - root - 2017-12-01 03:54:28.959603: step 29900, loss = 0.47, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 13h:05m:25s remains)
INFO - root - 2017-12-01 03:54:30.628944: step 29910, loss = 0.45, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 12h:57m:53s remains)
INFO - root - 2017-12-01 03:54:32.199905: step 29920, loss = 0.54, batch loss = 0.32 (51.6 examples/sec; 0.155 sec/batch; 13h:02m:14s remains)
INFO - root - 2017-12-01 03:54:33.767677: step 29930, loss = 0.43, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 13h:17m:59s remains)
INFO - root - 2017-12-01 03:54:35.330626: step 29940, loss = 0.50, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 13h:08m:01s remains)
INFO - root - 2017-12-01 03:54:36.914651: step 29950, loss = 0.55, batch loss = 0.33 (50.7 examples/sec; 0.158 sec/batch; 13h:15m:14s remains)
INFO - root - 2017-12-01 03:54:38.498454: step 29960, loss = 0.39, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 13h:17m:31s remains)
INFO - root - 2017-12-01 03:54:40.063434: step 29970, loss = 0.49, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 13h:10m:11s remains)
INFO - root - 2017-12-01 03:54:41.624038: step 29980, loss = 0.45, batch loss = 0.23 (49.8 examples/sec; 0.161 sec/batch; 13h:30m:13s remains)
INFO - root - 2017-12-01 03:54:43.206209: step 29990, loss = 0.64, batch loss = 0.42 (50.9 examples/sec; 0.157 sec/batch; 13h:12m:07s remains)
INFO - root - 2017-12-01 03:54:44.768048: step 30000, loss = 0.50, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 12h:57m:40s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-30000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-30000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-01 03:54:46.722750: step 30010, loss = 0.42, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 13h:14m:12s remains)
INFO - root - 2017-12-01 03:54:48.290413: step 30020, loss = 0.44, batch loss = 0.22 (52.4 examples/sec; 0.153 sec/batch; 12h:50m:15s remains)
INFO - root - 2017-12-01 03:54:49.840776: step 30030, loss = 0.40, batch loss = 0.18 (52.2 examples/sec; 0.153 sec/batch; 12h:52m:21s remains)
INFO - root - 2017-12-01 03:54:51.426140: step 30040, loss = 0.43, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 13h:06m:34s remains)
INFO - root - 2017-12-01 03:54:52.993743: step 30050, loss = 0.54, batch loss = 0.32 (51.5 examples/sec; 0.155 sec/batch; 13h:02m:34s remains)
INFO - root - 2017-12-01 03:54:54.553347: step 30060, loss = 0.53, batch loss = 0.31 (53.4 examples/sec; 0.150 sec/batch; 12h:34m:46s remains)
INFO - root - 2017-12-01 03:54:56.120085: step 30070, loss = 0.45, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 12h:56m:24s remains)
INFO - root - 2017-12-01 03:54:57.697777: step 30080, loss = 0.42, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 13h:13m:06s remains)
INFO - root - 2017-12-01 03:54:59.250522: step 30090, loss = 0.49, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 13h:09m:36s remains)
INFO - root - 2017-12-01 03:55:00.801050: step 30100, loss = 0.49, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 13h:02m:12s remains)
INFO - root - 2017-12-01 03:55:02.450151: step 30110, loss = 0.39, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 12h:58m:25s remains)
INFO - root - 2017-12-01 03:55:04.016311: step 30120, loss = 0.53, batch loss = 0.31 (50.2 examples/sec; 0.159 sec/batch; 13h:22m:20s remains)
INFO - root - 2017-12-01 03:55:05.573708: step 30130, loss = 0.53, batch loss = 0.31 (52.5 examples/sec; 0.152 sec/batch; 12h:48m:30s remains)
INFO - root - 2017-12-01 03:55:07.165673: step 30140, loss = 0.46, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 12h:46m:55s remains)
INFO - root - 2017-12-01 03:55:08.761059: step 30150, loss = 0.39, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 13h:02m:27s remains)
INFO - root - 2017-12-01 03:55:10.315290: step 30160, loss = 0.40, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 13h:13m:58s remains)
INFO - root - 2017-12-01 03:55:11.868301: step 30170, loss = 0.50, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 13h:02m:54s remains)
INFO - root - 2017-12-01 03:55:13.437402: step 30180, loss = 0.49, batch loss = 0.27 (51.2 examples/sec; 0.156 sec/batch; 13h:07m:51s remains)
INFO - root - 2017-12-01 03:55:15.005239: step 30190, loss = 0.48, batch loss = 0.26 (53.3 examples/sec; 0.150 sec/batch; 12h:36m:45s remains)
INFO - root - 2017-12-01 03:55:16.587206: step 30200, loss = 0.49, batch loss = 0.28 (51.8 examples/sec; 0.154 sec/batch; 12h:57m:24s remains)
INFO - root - 2017-12-01 03:55:18.208741: step 30210, loss = 0.63, batch loss = 0.41 (51.3 examples/sec; 0.156 sec/batch; 13h:04m:56s remains)
INFO - root - 2017-12-01 03:55:19.782078: step 30220, loss = 0.46, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 12h:50m:47s remains)
INFO - root - 2017-12-01 03:55:21.352612: step 30230, loss = 0.49, batch loss = 0.28 (51.1 examples/sec; 0.157 sec/batch; 13h:09m:27s remains)
INFO - root - 2017-12-01 03:55:22.898344: step 30240, loss = 0.55, batch loss = 0.33 (51.8 examples/sec; 0.154 sec/batch; 12h:57m:38s remains)
INFO - root - 2017-12-01 03:55:24.466731: step 30250, loss = 0.50, batch loss = 0.28 (52.3 examples/sec; 0.153 sec/batch; 12h:50m:36s remains)
INFO - root - 2017-12-01 03:55:26.042366: step 30260, loss = 0.49, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 13h:10m:27s remains)
INFO - root - 2017-12-01 03:55:27.601260: step 30270, loss = 0.45, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 12h:54m:46s remains)
INFO - root - 2017-12-01 03:55:29.175156: step 30280, loss = 0.45, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 13h:09m:21s remains)
INFO - root - 2017-12-01 03:55:30.727972: step 30290, loss = 0.45, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 12h:56m:28s remains)
INFO - root - 2017-12-01 03:55:32.295863: step 30300, loss = 0.80, batch loss = 0.58 (51.5 examples/sec; 0.155 sec/batch; 13h:02m:13s remains)
INFO - root - 2017-12-01 03:55:33.940409: step 30310, loss = 0.43, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 13h:07m:25s remains)
INFO - root - 2017-12-01 03:55:35.505216: step 30320, loss = 0.47, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 13h:09m:25s remains)
INFO - root - 2017-12-01 03:55:37.073448: step 30330, loss = 0.51, batch loss = 0.29 (50.0 examples/sec; 0.160 sec/batch; 13h:25m:15s remains)
INFO - root - 2017-12-01 03:55:38.665169: step 30340, loss = 0.48, batch loss = 0.27 (51.8 examples/sec; 0.154 sec/batch; 12h:57m:41s remains)
INFO - root - 2017-12-01 03:55:40.228124: step 30350, loss = 0.50, batch loss = 0.28 (50.0 examples/sec; 0.160 sec/batch; 13h:26m:10s remains)
INFO - root - 2017-12-01 03:55:41.779700: step 30360, loss = 0.46, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 13h:05m:52s remains)
INFO - root - 2017-12-01 03:55:43.337102: step 30370, loss = 0.46, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 12h:54m:19s remains)
INFO - root - 2017-12-01 03:55:44.896228: step 30380, loss = 0.51, batch loss = 0.29 (52.9 examples/sec; 0.151 sec/batch; 12h:41m:14s remains)
INFO - root - 2017-12-01 03:55:46.474912: step 30390, loss = 0.42, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 13h:15m:11s remains)
INFO - root - 2017-12-01 03:55:48.037265: step 30400, loss = 0.52, batch loss = 0.30 (50.8 examples/sec; 0.158 sec/batch; 13h:13m:25s remains)
INFO - root - 2017-12-01 03:55:49.686912: step 30410, loss = 0.52, batch loss = 0.30 (51.6 examples/sec; 0.155 sec/batch; 13h:00m:08s remains)
INFO - root - 2017-12-01 03:55:51.277680: step 30420, loss = 0.50, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 13h:06m:57s remains)
INFO - root - 2017-12-01 03:55:52.857155: step 30430, loss = 0.42, batch loss = 0.20 (48.1 examples/sec; 0.166 sec/batch; 13h:57m:06s remains)
INFO - root - 2017-12-01 03:55:54.440584: step 30440, loss = 0.49, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 12h:54m:44s remains)
INFO - root - 2017-12-01 03:55:56.047442: step 30450, loss = 0.46, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 13h:09m:27s remains)
INFO - root - 2017-12-01 03:55:57.609137: step 30460, loss = 0.49, batch loss = 0.27 (52.1 examples/sec; 0.154 sec/batch; 12h:53m:24s remains)
INFO - root - 2017-12-01 03:55:59.173699: step 30470, loss = 0.62, batch loss = 0.40 (50.6 examples/sec; 0.158 sec/batch; 13h:16m:08s remains)
INFO - root - 2017-12-01 03:56:00.785056: step 30480, loss = 0.41, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 13h:01m:28s remains)
INFO - root - 2017-12-01 03:56:02.336759: step 30490, loss = 0.47, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 13h:14m:08s remains)
INFO - root - 2017-12-01 03:56:03.912498: step 30500, loss = 0.49, batch loss = 0.28 (52.6 examples/sec; 0.152 sec/batch; 12h:45m:14s remains)
INFO - root - 2017-12-01 03:56:05.582030: step 30510, loss = 0.69, batch loss = 0.47 (50.0 examples/sec; 0.160 sec/batch; 13h:24m:48s remains)
INFO - root - 2017-12-01 03:56:07.148687: step 30520, loss = 0.51, batch loss = 0.29 (50.5 examples/sec; 0.159 sec/batch; 13h:17m:57s remains)
INFO - root - 2017-12-01 03:56:08.778207: step 30530, loss = 0.42, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 13h:19m:54s remains)
INFO - root - 2017-12-01 03:56:10.360923: step 30540, loss = 0.46, batch loss = 0.25 (50.8 examples/sec; 0.158 sec/batch; 13h:12m:39s remains)
INFO - root - 2017-12-01 03:56:11.943009: step 30550, loss = 0.43, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 12h:58m:55s remains)
INFO - root - 2017-12-01 03:56:13.510693: step 30560, loss = 0.50, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 13h:14m:10s remains)
INFO - root - 2017-12-01 03:56:15.095165: step 30570, loss = 0.44, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 13h:10m:57s remains)
INFO - root - 2017-12-01 03:56:16.663818: step 30580, loss = 0.54, batch loss = 0.33 (50.3 examples/sec; 0.159 sec/batch; 13h:19m:44s remains)
INFO - root - 2017-12-01 03:56:18.259180: step 30590, loss = 0.46, batch loss = 0.25 (50.8 examples/sec; 0.157 sec/batch; 13h:11m:57s remains)
INFO - root - 2017-12-01 03:56:19.825955: step 30600, loss = 0.61, batch loss = 0.40 (49.1 examples/sec; 0.163 sec/batch; 13h:39m:06s remains)
INFO - root - 2017-12-01 03:56:21.459787: step 30610, loss = 0.44, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 13h:02m:07s remains)
INFO - root - 2017-12-01 03:56:23.023539: step 30620, loss = 0.51, batch loss = 0.29 (51.8 examples/sec; 0.154 sec/batch; 12h:57m:08s remains)
INFO - root - 2017-12-01 03:56:24.600992: step 30630, loss = 0.47, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 13h:13m:44s remains)
INFO - root - 2017-12-01 03:56:26.174020: step 30640, loss = 0.42, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 13h:07m:32s remains)
INFO - root - 2017-12-01 03:56:27.725124: step 30650, loss = 0.48, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 12h:43m:03s remains)
INFO - root - 2017-12-01 03:56:29.312208: step 30660, loss = 0.51, batch loss = 0.29 (51.0 examples/sec; 0.157 sec/batch; 13h:09m:30s remains)
INFO - root - 2017-12-01 03:56:30.866516: step 30670, loss = 0.42, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 12h:50m:26s remains)
INFO - root - 2017-12-01 03:56:32.417539: step 30680, loss = 0.42, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 13h:21m:56s remains)
INFO - root - 2017-12-01 03:56:33.993908: step 30690, loss = 0.58, batch loss = 0.36 (51.7 examples/sec; 0.155 sec/batch; 12h:57m:37s remains)
INFO - root - 2017-12-01 03:56:35.571020: step 30700, loss = 0.45, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 12h:47m:32s remains)
INFO - root - 2017-12-01 03:56:37.203075: step 30710, loss = 0.50, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 13h:16m:31s remains)
INFO - root - 2017-12-01 03:56:38.764990: step 30720, loss = 0.49, batch loss = 0.27 (52.7 examples/sec; 0.152 sec/batch; 12h:42m:50s remains)
INFO - root - 2017-12-01 03:56:40.372235: step 30730, loss = 0.54, batch loss = 0.32 (51.9 examples/sec; 0.154 sec/batch; 12h:55m:44s remains)
INFO - root - 2017-12-01 03:56:41.931316: step 30740, loss = 0.45, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 13h:19m:01s remains)
INFO - root - 2017-12-01 03:56:43.496462: step 30750, loss = 0.45, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 12h:58m:26s remains)
INFO - root - 2017-12-01 03:56:45.054227: step 30760, loss = 0.46, batch loss = 0.25 (52.0 examples/sec; 0.154 sec/batch; 12h:53m:05s remains)
INFO - root - 2017-12-01 03:56:46.621975: step 30770, loss = 0.50, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 13h:06m:12s remains)
INFO - root - 2017-12-01 03:56:48.188204: step 30780, loss = 0.47, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 13h:05m:34s remains)
INFO - root - 2017-12-01 03:56:49.754631: step 30790, loss = 0.49, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 13h:07m:11s remains)
INFO - root - 2017-12-01 03:56:51.312988: step 30800, loss = 0.41, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 13h:09m:04s remains)
INFO - root - 2017-12-01 03:56:52.951056: step 30810, loss = 0.53, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 13h:10m:25s remains)
INFO - root - 2017-12-01 03:56:54.491680: step 30820, loss = 0.51, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 13h:05m:55s remains)
INFO - root - 2017-12-01 03:56:56.055706: step 30830, loss = 0.49, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 13h:02m:54s remains)
INFO - root - 2017-12-01 03:56:57.616019: step 30840, loss = 0.45, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 13h:00m:36s remains)
INFO - root - 2017-12-01 03:56:59.168275: step 30850, loss = 0.38, batch loss = 0.17 (52.8 examples/sec; 0.152 sec/batch; 12h:41m:55s remains)
INFO - root - 2017-12-01 03:57:00.720753: step 30860, loss = 0.55, batch loss = 0.33 (50.2 examples/sec; 0.159 sec/batch; 13h:21m:20s remains)
INFO - root - 2017-12-01 03:57:02.282608: step 30870, loss = 0.41, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 12h:58m:49s remains)
INFO - root - 2017-12-01 03:57:03.846589: step 30880, loss = 0.49, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 12h:59m:35s remains)
INFO - root - 2017-12-01 03:57:05.411851: step 30890, loss = 0.44, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 12h:57m:55s remains)
INFO - root - 2017-12-01 03:57:07.008820: step 30900, loss = 0.44, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 13h:21m:40s remains)
INFO - root - 2017-12-01 03:57:08.661388: step 30910, loss = 0.39, batch loss = 0.18 (53.0 examples/sec; 0.151 sec/batch; 12h:39m:25s remains)
INFO - root - 2017-12-01 03:57:10.238506: step 30920, loss = 0.61, batch loss = 0.39 (52.5 examples/sec; 0.152 sec/batch; 12h:45m:54s remains)
INFO - root - 2017-12-01 03:57:11.834790: step 30930, loss = 0.48, batch loss = 0.26 (49.6 examples/sec; 0.161 sec/batch; 13h:30m:27s remains)
INFO - root - 2017-12-01 03:57:13.421441: step 30940, loss = 0.41, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 13h:12m:20s remains)
INFO - root - 2017-12-01 03:57:15.009261: step 30950, loss = 0.46, batch loss = 0.24 (52.4 examples/sec; 0.153 sec/batch; 12h:47m:52s remains)
INFO - root - 2017-12-01 03:57:16.610427: step 30960, loss = 0.49, batch loss = 0.27 (47.4 examples/sec; 0.169 sec/batch; 14h:08m:17s remains)
INFO - root - 2017-12-01 03:57:18.173665: step 30970, loss = 0.44, batch loss = 0.23 (49.6 examples/sec; 0.161 sec/batch; 13h:30m:51s remains)
INFO - root - 2017-12-01 03:57:19.744405: step 30980, loss = 0.51, batch loss = 0.29 (50.2 examples/sec; 0.159 sec/batch; 13h:20m:54s remains)
INFO - root - 2017-12-01 03:57:21.333581: step 30990, loss = 0.45, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 13h:13m:22s remains)
INFO - root - 2017-12-01 03:57:22.904356: step 31000, loss = 0.49, batch loss = 0.28 (49.1 examples/sec; 0.163 sec/batch; 13h:38m:56s remains)
INFO - root - 2017-12-01 03:57:24.582171: step 31010, loss = 0.47, batch loss = 0.26 (50.0 examples/sec; 0.160 sec/batch; 13h:23m:14s remains)
INFO - root - 2017-12-01 03:57:26.137768: step 31020, loss = 0.56, batch loss = 0.34 (51.5 examples/sec; 0.155 sec/batch; 12h:59m:58s remains)
INFO - root - 2017-12-01 03:57:27.696232: step 31030, loss = 0.46, batch loss = 0.24 (52.4 examples/sec; 0.153 sec/batch; 12h:46m:42s remains)
INFO - root - 2017-12-01 03:57:29.270266: step 31040, loss = 0.43, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 13h:07m:50s remains)
INFO - root - 2017-12-01 03:57:30.889885: step 31050, loss = 0.46, batch loss = 0.25 (48.6 examples/sec; 0.165 sec/batch; 13h:46m:41s remains)
INFO - root - 2017-12-01 03:57:32.459545: step 31060, loss = 0.60, batch loss = 0.38 (49.8 examples/sec; 0.161 sec/batch; 13h:26m:21s remains)
INFO - root - 2017-12-01 03:57:34.026307: step 31070, loss = 0.42, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 13h:10m:24s remains)
INFO - root - 2017-12-01 03:57:35.579885: step 31080, loss = 0.41, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 13h:02m:13s remains)
INFO - root - 2017-12-01 03:57:37.134484: step 31090, loss = 0.46, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 13h:05m:45s remains)
INFO - root - 2017-12-01 03:57:38.717150: step 31100, loss = 0.47, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 12h:48m:39s remains)
INFO - root - 2017-12-01 03:57:40.354754: step 31110, loss = 0.48, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 13h:00m:21s remains)
INFO - root - 2017-12-01 03:57:41.938506: step 31120, loss = 0.52, batch loss = 0.30 (50.3 examples/sec; 0.159 sec/batch; 13h:19m:15s remains)
INFO - root - 2017-12-01 03:57:43.496195: step 31130, loss = 0.64, batch loss = 0.43 (49.5 examples/sec; 0.162 sec/batch; 13h:31m:48s remains)
INFO - root - 2017-12-01 03:57:45.062782: step 31140, loss = 0.41, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 12h:58m:16s remains)
INFO - root - 2017-12-01 03:57:46.659317: step 31150, loss = 0.47, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 13h:17m:58s remains)
INFO - root - 2017-12-01 03:57:48.211975: step 31160, loss = 0.42, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 12h:54m:50s remains)
INFO - root - 2017-12-01 03:57:49.776947: step 31170, loss = 0.46, batch loss = 0.24 (49.4 examples/sec; 0.162 sec/batch; 13h:32m:34s remains)
INFO - root - 2017-12-01 03:57:51.332322: step 31180, loss = 0.45, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 13h:00m:45s remains)
INFO - root - 2017-12-01 03:57:52.904937: step 31190, loss = 0.59, batch loss = 0.37 (50.6 examples/sec; 0.158 sec/batch; 13h:13m:54s remains)
INFO - root - 2017-12-01 03:57:54.532009: step 31200, loss = 0.58, batch loss = 0.36 (42.5 examples/sec; 0.188 sec/batch; 15h:44m:33s remains)
INFO - root - 2017-12-01 03:57:56.310380: step 31210, loss = 0.48, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 13h:12m:22s remains)
INFO - root - 2017-12-01 03:57:57.892270: step 31220, loss = 0.43, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 12h:56m:20s remains)
INFO - root - 2017-12-01 03:57:59.446049: step 31230, loss = 0.55, batch loss = 0.33 (50.5 examples/sec; 0.159 sec/batch; 13h:16m:07s remains)
INFO - root - 2017-12-01 03:58:01.001298: step 31240, loss = 0.44, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 12h:59m:13s remains)
INFO - root - 2017-12-01 03:58:02.556976: step 31250, loss = 0.46, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 13h:18m:16s remains)
INFO - root - 2017-12-01 03:58:04.125318: step 31260, loss = 0.53, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 12h:57m:46s remains)
INFO - root - 2017-12-01 03:58:05.691668: step 31270, loss = 0.52, batch loss = 0.30 (51.0 examples/sec; 0.157 sec/batch; 13h:07m:14s remains)
INFO - root - 2017-12-01 03:58:07.227790: step 31280, loss = 0.48, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 12h:52m:06s remains)
INFO - root - 2017-12-01 03:58:08.867136: step 31290, loss = 0.44, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 12h:57m:29s remains)
INFO - root - 2017-12-01 03:58:10.433671: step 31300, loss = 0.51, batch loss = 0.29 (51.8 examples/sec; 0.154 sec/batch; 12h:55m:17s remains)
INFO - root - 2017-12-01 03:58:12.068643: step 31310, loss = 0.39, batch loss = 0.17 (49.1 examples/sec; 0.163 sec/batch; 13h:38m:29s remains)
INFO - root - 2017-12-01 03:58:13.658425: step 31320, loss = 0.45, batch loss = 0.23 (50.2 examples/sec; 0.160 sec/batch; 13h:20m:38s remains)
INFO - root - 2017-12-01 03:58:15.221046: step 31330, loss = 0.44, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 13h:03m:16s remains)
INFO - root - 2017-12-01 03:58:16.792172: step 31340, loss = 0.41, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 12h:57m:10s remains)
INFO - root - 2017-12-01 03:58:18.361718: step 31350, loss = 0.47, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 12h:58m:23s remains)
INFO - root - 2017-12-01 03:58:19.974548: step 31360, loss = 0.45, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 12h:49m:12s remains)
INFO - root - 2017-12-01 03:58:21.561261: step 31370, loss = 0.43, batch loss = 0.21 (49.2 examples/sec; 0.163 sec/batch; 13h:36m:37s remains)
INFO - root - 2017-12-01 03:58:23.133301: step 31380, loss = 0.50, batch loss = 0.28 (48.2 examples/sec; 0.166 sec/batch; 13h:52m:50s remains)
INFO - root - 2017-12-01 03:58:24.704057: step 31390, loss = 0.49, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 12h:49m:43s remains)
INFO - root - 2017-12-01 03:58:26.276131: step 31400, loss = 0.51, batch loss = 0.29 (51.7 examples/sec; 0.155 sec/batch; 12h:56m:09s remains)
INFO - root - 2017-12-01 03:58:27.882327: step 31410, loss = 0.49, batch loss = 0.28 (53.0 examples/sec; 0.151 sec/batch; 12h:37m:00s remains)
INFO - root - 2017-12-01 03:58:29.460161: step 31420, loss = 0.43, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 13h:05m:25s remains)
INFO - root - 2017-12-01 03:58:31.203661: step 31430, loss = 0.51, batch loss = 0.30 (34.1 examples/sec; 0.235 sec/batch; 19h:38m:06s remains)
INFO - root - 2017-12-01 03:58:32.764784: step 31440, loss = 0.41, batch loss = 0.20 (49.7 examples/sec; 0.161 sec/batch; 13h:27m:52s remains)
INFO - root - 2017-12-01 03:58:34.359037: step 31450, loss = 0.45, batch loss = 0.24 (50.0 examples/sec; 0.160 sec/batch; 13h:23m:34s remains)
INFO - root - 2017-12-01 03:58:35.921403: step 31460, loss = 0.48, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 12h:57m:28s remains)
INFO - root - 2017-12-01 03:58:37.504539: step 31470, loss = 0.47, batch loss = 0.26 (49.9 examples/sec; 0.160 sec/batch; 13h:24m:38s remains)
INFO - root - 2017-12-01 03:58:39.060854: step 31480, loss = 0.45, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 13h:00m:18s remains)
INFO - root - 2017-12-01 03:58:40.626536: step 31490, loss = 0.43, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 13h:06m:44s remains)
INFO - root - 2017-12-01 03:58:42.189254: step 31500, loss = 0.60, batch loss = 0.38 (52.3 examples/sec; 0.153 sec/batch; 12h:48m:03s remains)
INFO - root - 2017-12-01 03:58:43.840101: step 31510, loss = 0.48, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 13h:11m:42s remains)
INFO - root - 2017-12-01 03:58:45.418865: step 31520, loss = 0.52, batch loss = 0.30 (50.6 examples/sec; 0.158 sec/batch; 13h:13m:25s remains)
INFO - root - 2017-12-01 03:58:46.967811: step 31530, loss = 0.51, batch loss = 0.29 (53.0 examples/sec; 0.151 sec/batch; 12h:37m:22s remains)
INFO - root - 2017-12-01 03:58:48.551428: step 31540, loss = 0.52, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 13h:04m:06s remains)
INFO - root - 2017-12-01 03:58:50.110258: step 31550, loss = 0.44, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 13h:12m:30s remains)
INFO - root - 2017-12-01 03:58:51.681290: step 31560, loss = 0.50, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 13h:03m:58s remains)
INFO - root - 2017-12-01 03:58:53.254635: step 31570, loss = 0.39, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 12h:53m:34s remains)
INFO - root - 2017-12-01 03:58:54.811917: step 31580, loss = 0.45, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 13h:02m:18s remains)
INFO - root - 2017-12-01 03:58:56.375054: step 31590, loss = 0.48, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 13h:12m:21s remains)
INFO - root - 2017-12-01 03:58:57.934892: step 31600, loss = 0.64, batch loss = 0.43 (48.7 examples/sec; 0.164 sec/batch; 13h:43m:03s remains)
INFO - root - 2017-12-01 03:58:59.549908: step 31610, loss = 0.55, batch loss = 0.34 (50.6 examples/sec; 0.158 sec/batch; 13h:12m:10s remains)
INFO - root - 2017-12-01 03:59:01.112737: step 31620, loss = 0.50, batch loss = 0.29 (50.8 examples/sec; 0.157 sec/batch; 13h:09m:02s remains)
INFO - root - 2017-12-01 03:59:02.679459: step 31630, loss = 0.44, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 13h:14m:32s remains)
INFO - root - 2017-12-01 03:59:04.238481: step 31640, loss = 0.45, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 13h:08m:33s remains)
INFO - root - 2017-12-01 03:59:05.790407: step 31650, loss = 0.60, batch loss = 0.39 (51.7 examples/sec; 0.155 sec/batch; 12h:56m:30s remains)
INFO - root - 2017-12-01 03:59:07.363760: step 31660, loss = 0.54, batch loss = 0.32 (51.7 examples/sec; 0.155 sec/batch; 12h:56m:24s remains)
INFO - root - 2017-12-01 03:59:08.954008: step 31670, loss = 0.52, batch loss = 0.30 (50.5 examples/sec; 0.158 sec/batch; 13h:13m:49s remains)
INFO - root - 2017-12-01 03:59:10.539765: step 31680, loss = 0.49, batch loss = 0.27 (48.7 examples/sec; 0.164 sec/batch; 13h:43m:11s remains)
INFO - root - 2017-12-01 03:59:12.250519: step 31690, loss = 0.40, batch loss = 0.19 (51.8 examples/sec; 0.155 sec/batch; 12h:54m:52s remains)
INFO - root - 2017-12-01 03:59:13.943968: step 31700, loss = 0.47, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 12h:58m:39s remains)
INFO - root - 2017-12-01 03:59:15.566630: step 31710, loss = 0.48, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 13h:13m:45s remains)
INFO - root - 2017-12-01 03:59:17.119780: step 31720, loss = 0.43, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 13h:11m:03s remains)
INFO - root - 2017-12-01 03:59:18.638799: step 31730, loss = 0.46, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 12h:55m:50s remains)
INFO - root - 2017-12-01 03:59:20.195456: step 31740, loss = 0.52, batch loss = 0.31 (49.7 examples/sec; 0.161 sec/batch; 13h:27m:10s remains)
INFO - root - 2017-12-01 03:59:21.746012: step 31750, loss = 0.45, batch loss = 0.23 (52.5 examples/sec; 0.152 sec/batch; 12h:43m:41s remains)
INFO - root - 2017-12-01 03:59:23.312970: step 31760, loss = 0.48, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 12h:59m:25s remains)
INFO - root - 2017-12-01 03:59:24.883067: step 31770, loss = 0.48, batch loss = 0.27 (50.1 examples/sec; 0.160 sec/batch; 13h:20m:37s remains)
INFO - root - 2017-12-01 03:59:26.444457: step 31780, loss = 0.42, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 13h:03m:15s remains)
INFO - root - 2017-12-01 03:59:28.142337: step 31790, loss = 0.40, batch loss = 0.19 (48.9 examples/sec; 0.163 sec/batch; 13h:39m:08s remains)
INFO - root - 2017-12-01 03:59:29.702602: step 31800, loss = 0.59, batch loss = 0.38 (50.8 examples/sec; 0.157 sec/batch; 13h:08m:45s remains)
INFO - root - 2017-12-01 03:59:31.352065: step 31810, loss = 0.47, batch loss = 0.26 (50.8 examples/sec; 0.158 sec/batch; 13h:09m:21s remains)
INFO - root - 2017-12-01 03:59:32.921882: step 31820, loss = 0.44, batch loss = 0.23 (50.1 examples/sec; 0.160 sec/batch; 13h:20m:06s remains)
INFO - root - 2017-12-01 03:59:34.496403: step 31830, loss = 0.51, batch loss = 0.30 (48.6 examples/sec; 0.165 sec/batch; 13h:45m:01s remains)
INFO - root - 2017-12-01 03:59:36.124403: step 31840, loss = 0.39, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 13h:08m:51s remains)
INFO - root - 2017-12-01 03:59:37.684761: step 31850, loss = 0.44, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 12h:59m:24s remains)
INFO - root - 2017-12-01 03:59:39.246344: step 31860, loss = 0.42, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 12h:50m:02s remains)
INFO - root - 2017-12-01 03:59:40.888909: step 31870, loss = 0.59, batch loss = 0.37 (50.3 examples/sec; 0.159 sec/batch; 13h:16m:13s remains)
INFO - root - 2017-12-01 03:59:42.450253: step 31880, loss = 0.57, batch loss = 0.36 (50.2 examples/sec; 0.159 sec/batch; 13h:18m:42s remains)
INFO - root - 2017-12-01 03:59:44.006442: step 31890, loss = 0.45, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 13h:22m:43s remains)
INFO - root - 2017-12-01 03:59:45.573874: step 31900, loss = 0.43, batch loss = 0.22 (52.4 examples/sec; 0.153 sec/batch; 12h:44m:22s remains)
INFO - root - 2017-12-01 03:59:47.198963: step 31910, loss = 0.55, batch loss = 0.34 (51.1 examples/sec; 0.157 sec/batch; 13h:04m:06s remains)
INFO - root - 2017-12-01 03:59:48.744053: step 31920, loss = 0.43, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 13h:00m:58s remains)
INFO - root - 2017-12-01 03:59:50.295822: step 31930, loss = 0.56, batch loss = 0.34 (51.1 examples/sec; 0.157 sec/batch; 13h:05m:00s remains)
INFO - root - 2017-12-01 03:59:51.845251: step 31940, loss = 0.51, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 13h:08m:00s remains)
INFO - root - 2017-12-01 03:59:53.417741: step 31950, loss = 0.43, batch loss = 0.21 (48.8 examples/sec; 0.164 sec/batch; 13h:40m:51s remains)
INFO - root - 2017-12-01 03:59:54.992546: step 31960, loss = 0.45, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 12h:41m:11s remains)
INFO - root - 2017-12-01 03:59:56.553046: step 31970, loss = 0.41, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 13h:09m:20s remains)
INFO - root - 2017-12-01 03:59:58.113435: step 31980, loss = 0.64, batch loss = 0.43 (51.6 examples/sec; 0.155 sec/batch; 12h:57m:13s remains)
INFO - root - 2017-12-01 03:59:59.689455: step 31990, loss = 0.44, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 12h:48m:03s remains)
INFO - root - 2017-12-01 04:00:01.250234: step 32000, loss = 0.40, batch loss = 0.18 (49.2 examples/sec; 0.163 sec/batch; 13h:34m:24s remains)
INFO - root - 2017-12-01 04:00:02.865127: step 32010, loss = 0.58, batch loss = 0.37 (51.7 examples/sec; 0.155 sec/batch; 12h:54m:49s remains)
INFO - root - 2017-12-01 04:00:04.439427: step 32020, loss = 0.48, batch loss = 0.27 (52.7 examples/sec; 0.152 sec/batch; 12h:40m:47s remains)
INFO - root - 2017-12-01 04:00:06.015040: step 32030, loss = 0.59, batch loss = 0.37 (51.6 examples/sec; 0.155 sec/batch; 12h:56m:53s remains)
INFO - root - 2017-12-01 04:00:07.598412: step 32040, loss = 0.42, batch loss = 0.21 (49.8 examples/sec; 0.161 sec/batch; 13h:25m:12s remains)
INFO - root - 2017-12-01 04:00:09.155402: step 32050, loss = 0.50, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 13h:02m:24s remains)
INFO - root - 2017-12-01 04:00:10.717240: step 32060, loss = 0.46, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 12h:46m:08s remains)
INFO - root - 2017-12-01 04:00:12.286583: step 32070, loss = 0.43, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 12h:55m:20s remains)
INFO - root - 2017-12-01 04:00:13.853321: step 32080, loss = 0.54, batch loss = 0.33 (51.5 examples/sec; 0.155 sec/batch; 12h:57m:25s remains)
INFO - root - 2017-12-01 04:00:15.419414: step 32090, loss = 0.53, batch loss = 0.32 (50.2 examples/sec; 0.159 sec/batch; 13h:17m:26s remains)
INFO - root - 2017-12-01 04:00:16.999235: step 32100, loss = 0.43, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 13h:08m:30s remains)
INFO - root - 2017-12-01 04:00:18.648234: step 32110, loss = 0.60, batch loss = 0.39 (49.7 examples/sec; 0.161 sec/batch; 13h:25m:46s remains)
INFO - root - 2017-12-01 04:00:20.288200: step 32120, loss = 0.46, batch loss = 0.25 (34.3 examples/sec; 0.233 sec/batch; 19h:28m:35s remains)
INFO - root - 2017-12-01 04:00:21.965455: step 32130, loss = 0.51, batch loss = 0.30 (51.7 examples/sec; 0.155 sec/batch; 12h:54m:23s remains)
INFO - root - 2017-12-01 04:00:23.563702: step 32140, loss = 0.57, batch loss = 0.36 (49.7 examples/sec; 0.161 sec/batch; 13h:26m:36s remains)
INFO - root - 2017-12-01 04:00:25.140181: step 32150, loss = 0.58, batch loss = 0.37 (49.7 examples/sec; 0.161 sec/batch; 13h:26m:21s remains)
INFO - root - 2017-12-01 04:00:26.728142: step 32160, loss = 0.46, batch loss = 0.25 (52.2 examples/sec; 0.153 sec/batch; 12h:46m:37s remains)
INFO - root - 2017-12-01 04:00:28.290807: step 32170, loss = 0.42, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 12h:58m:59s remains)
INFO - root - 2017-12-01 04:00:29.864959: step 32180, loss = 0.44, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 13h:12m:13s remains)
INFO - root - 2017-12-01 04:00:31.435882: step 32190, loss = 0.44, batch loss = 0.23 (49.3 examples/sec; 0.162 sec/batch; 13h:32m:17s remains)
INFO - root - 2017-12-01 04:00:33.026909: step 32200, loss = 0.40, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 12h:52m:10s remains)
INFO - root - 2017-12-01 04:00:34.699809: step 32210, loss = 0.52, batch loss = 0.31 (53.0 examples/sec; 0.151 sec/batch; 12h:35m:25s remains)
INFO - root - 2017-12-01 04:00:36.293689: step 32220, loss = 0.55, batch loss = 0.34 (50.9 examples/sec; 0.157 sec/batch; 13h:05m:52s remains)
INFO - root - 2017-12-01 04:00:37.848416: step 32230, loss = 0.52, batch loss = 0.30 (50.5 examples/sec; 0.158 sec/batch; 13h:12m:00s remains)
INFO - root - 2017-12-01 04:00:39.604009: step 32240, loss = 0.47, batch loss = 0.25 (31.6 examples/sec; 0.253 sec/batch; 21h:06m:03s remains)
INFO - root - 2017-12-01 04:00:41.200850: step 32250, loss = 0.52, batch loss = 0.31 (50.6 examples/sec; 0.158 sec/batch; 13h:10m:50s remains)
INFO - root - 2017-12-01 04:00:42.773989: step 32260, loss = 0.40, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 12h:54m:42s remains)
INFO - root - 2017-12-01 04:00:44.337281: step 32270, loss = 0.42, batch loss = 0.21 (48.0 examples/sec; 0.167 sec/batch; 13h:53m:21s remains)
INFO - root - 2017-12-01 04:00:45.966681: step 32280, loss = 0.42, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 12h:57m:35s remains)
INFO - root - 2017-12-01 04:00:47.518877: step 32290, loss = 0.41, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 13h:02m:52s remains)
INFO - root - 2017-12-01 04:00:49.115945: step 32300, loss = 0.49, batch loss = 0.27 (52.1 examples/sec; 0.154 sec/batch; 12h:48m:46s remains)
INFO - root - 2017-12-01 04:00:50.828599: step 32310, loss = 0.39, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 12h:45m:08s remains)
INFO - root - 2017-12-01 04:00:52.392389: step 32320, loss = 0.49, batch loss = 0.28 (52.0 examples/sec; 0.154 sec/batch; 12h:49m:00s remains)
INFO - root - 2017-12-01 04:00:53.937824: step 32330, loss = 0.47, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 12h:58m:34s remains)
INFO - root - 2017-12-01 04:00:55.500656: step 32340, loss = 0.47, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 12h:58m:47s remains)
INFO - root - 2017-12-01 04:00:57.066215: step 32350, loss = 0.48, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 13h:08m:59s remains)
INFO - root - 2017-12-01 04:00:58.637032: step 32360, loss = 0.59, batch loss = 0.37 (49.9 examples/sec; 0.160 sec/batch; 13h:21m:50s remains)
INFO - root - 2017-12-01 04:01:00.182306: step 32370, loss = 0.43, batch loss = 0.21 (53.6 examples/sec; 0.149 sec/batch; 12h:25m:54s remains)
INFO - root - 2017-12-01 04:01:01.757120: step 32380, loss = 0.47, batch loss = 0.26 (52.1 examples/sec; 0.153 sec/batch; 12h:47m:31s remains)
INFO - root - 2017-12-01 04:01:03.330781: step 32390, loss = 0.68, batch loss = 0.46 (50.2 examples/sec; 0.160 sec/batch; 13h:17m:49s remains)
INFO - root - 2017-12-01 04:01:04.889807: step 32400, loss = 0.53, batch loss = 0.31 (49.8 examples/sec; 0.161 sec/batch; 13h:23m:34s remains)
INFO - root - 2017-12-01 04:01:06.543973: step 32410, loss = 0.61, batch loss = 0.40 (51.3 examples/sec; 0.156 sec/batch; 13h:00m:19s remains)
INFO - root - 2017-12-01 04:01:08.097545: step 32420, loss = 0.53, batch loss = 0.31 (50.8 examples/sec; 0.157 sec/batch; 13h:07m:23s remains)
INFO - root - 2017-12-01 04:01:09.640466: step 32430, loss = 0.45, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 12h:49m:56s remains)
INFO - root - 2017-12-01 04:01:11.193805: step 32440, loss = 0.40, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 13h:03m:06s remains)
INFO - root - 2017-12-01 04:01:12.763782: step 32450, loss = 0.41, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 13h:00m:43s remains)
INFO - root - 2017-12-01 04:01:14.374459: step 32460, loss = 0.44, batch loss = 0.23 (51.1 examples/sec; 0.156 sec/batch; 13h:02m:08s remains)
INFO - root - 2017-12-01 04:01:15.937518: step 32470, loss = 0.43, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 12h:54m:03s remains)
INFO - root - 2017-12-01 04:01:17.499237: step 32480, loss = 0.51, batch loss = 0.30 (51.6 examples/sec; 0.155 sec/batch; 12h:54m:58s remains)
INFO - root - 2017-12-01 04:01:19.073247: step 32490, loss = 0.57, batch loss = 0.36 (51.1 examples/sec; 0.157 sec/batch; 13h:03m:33s remains)
INFO - root - 2017-12-01 04:01:20.639707: step 32500, loss = 0.43, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 13h:03m:00s remains)
INFO - root - 2017-12-01 04:01:22.241464: step 32510, loss = 0.53, batch loss = 0.31 (50.1 examples/sec; 0.160 sec/batch; 13h:17m:43s remains)
INFO - root - 2017-12-01 04:01:23.801661: step 32520, loss = 0.45, batch loss = 0.23 (53.0 examples/sec; 0.151 sec/batch; 12h:34m:47s remains)
INFO - root - 2017-12-01 04:01:25.360863: step 32530, loss = 0.47, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 12h:50m:57s remains)
INFO - root - 2017-12-01 04:01:26.957693: step 32540, loss = 0.60, batch loss = 0.39 (51.5 examples/sec; 0.155 sec/batch; 12h:56m:57s remains)
INFO - root - 2017-12-01 04:01:28.511669: step 32550, loss = 0.44, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 12h:46m:32s remains)
INFO - root - 2017-12-01 04:01:30.074868: step 32560, loss = 0.46, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 12h:59m:02s remains)
INFO - root - 2017-12-01 04:01:31.638111: step 32570, loss = 0.58, batch loss = 0.37 (52.2 examples/sec; 0.153 sec/batch; 12h:46m:12s remains)
INFO - root - 2017-12-01 04:01:33.243844: step 32580, loss = 0.49, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 13h:01m:19s remains)
INFO - root - 2017-12-01 04:01:34.798448: step 32590, loss = 0.48, batch loss = 0.27 (49.2 examples/sec; 0.163 sec/batch; 13h:33m:00s remains)
INFO - root - 2017-12-01 04:01:36.351586: step 32600, loss = 0.46, batch loss = 0.25 (52.2 examples/sec; 0.153 sec/batch; 12h:46m:17s remains)
INFO - root - 2017-12-01 04:01:37.957166: step 32610, loss = 0.41, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 12h:50m:54s remains)
INFO - root - 2017-12-01 04:01:39.530361: step 32620, loss = 0.60, batch loss = 0.38 (50.1 examples/sec; 0.160 sec/batch; 13h:18m:51s remains)
INFO - root - 2017-12-01 04:01:41.104435: step 32630, loss = 0.48, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 13h:05m:07s remains)
INFO - root - 2017-12-01 04:01:42.670178: step 32640, loss = 0.53, batch loss = 0.31 (52.1 examples/sec; 0.154 sec/batch; 12h:47m:35s remains)
INFO - root - 2017-12-01 04:01:44.346718: step 32650, loss = 0.52, batch loss = 0.30 (48.1 examples/sec; 0.166 sec/batch; 13h:50m:44s remains)
INFO - root - 2017-12-01 04:01:45.919464: step 32660, loss = 0.63, batch loss = 0.41 (53.6 examples/sec; 0.149 sec/batch; 12h:25m:33s remains)
INFO - root - 2017-12-01 04:01:47.491085: step 32670, loss = 0.43, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 13h:04m:36s remains)
INFO - root - 2017-12-01 04:01:49.068208: step 32680, loss = 0.48, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 12h:49m:08s remains)
INFO - root - 2017-12-01 04:01:50.697809: step 32690, loss = 0.43, batch loss = 0.22 (35.1 examples/sec; 0.228 sec/batch; 18h:58m:56s remains)
INFO - root - 2017-12-01 04:01:52.269673: step 32700, loss = 0.45, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 12h:50m:14s remains)
INFO - root - 2017-12-01 04:01:53.919916: step 32710, loss = 0.64, batch loss = 0.42 (52.5 examples/sec; 0.152 sec/batch; 12h:41m:11s remains)
INFO - root - 2017-12-01 04:01:55.511255: step 32720, loss = 0.42, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 13h:05m:34s remains)
INFO - root - 2017-12-01 04:01:57.064377: step 32730, loss = 0.50, batch loss = 0.29 (50.5 examples/sec; 0.159 sec/batch; 13h:12m:14s remains)
INFO - root - 2017-12-01 04:01:58.617396: step 32740, loss = 0.45, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 12h:49m:20s remains)
INFO - root - 2017-12-01 04:02:00.176740: step 32750, loss = 0.52, batch loss = 0.31 (51.5 examples/sec; 0.155 sec/batch; 12h:55m:55s remains)
INFO - root - 2017-12-01 04:02:01.732671: step 32760, loss = 0.46, batch loss = 0.24 (52.7 examples/sec; 0.152 sec/batch; 12h:37m:44s remains)
INFO - root - 2017-12-01 04:02:03.297354: step 32770, loss = 0.47, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 13h:04m:04s remains)
INFO - root - 2017-12-01 04:02:04.861456: step 32780, loss = 0.43, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 13h:12m:54s remains)
INFO - root - 2017-12-01 04:02:06.429581: step 32790, loss = 0.57, batch loss = 0.35 (48.0 examples/sec; 0.167 sec/batch; 13h:53m:20s remains)
INFO - root - 2017-12-01 04:02:07.997932: step 32800, loss = 0.43, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 12h:40m:19s remains)
INFO - root - 2017-12-01 04:02:09.611077: step 32810, loss = 0.54, batch loss = 0.32 (50.5 examples/sec; 0.158 sec/batch; 13h:11m:33s remains)
INFO - root - 2017-12-01 04:02:11.205290: step 32820, loss = 0.51, batch loss = 0.29 (48.6 examples/sec; 0.165 sec/batch; 13h:42m:10s remains)
INFO - root - 2017-12-01 04:02:12.783756: step 32830, loss = 0.51, batch loss = 0.30 (49.9 examples/sec; 0.160 sec/batch; 13h:20m:31s remains)
INFO - root - 2017-12-01 04:02:14.337549: step 32840, loss = 0.46, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 12h:43m:43s remains)
INFO - root - 2017-12-01 04:02:15.907347: step 32850, loss = 0.64, batch loss = 0.43 (51.8 examples/sec; 0.154 sec/batch; 12h:51m:08s remains)
INFO - root - 2017-12-01 04:02:17.458450: step 32860, loss = 0.41, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 13h:03m:43s remains)
INFO - root - 2017-12-01 04:02:19.020991: step 32870, loss = 0.44, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 12h:57m:12s remains)
INFO - root - 2017-12-01 04:02:20.610743: step 32880, loss = 0.48, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 12h:54m:02s remains)
INFO - root - 2017-12-01 04:02:22.164367: step 32890, loss = 0.45, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 12h:50m:10s remains)
INFO - root - 2017-12-01 04:02:23.723607: step 32900, loss = 0.43, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 12h:56m:54s remains)
INFO - root - 2017-12-01 04:02:25.342468: step 32910, loss = 0.44, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 12h:52m:02s remains)
INFO - root - 2017-12-01 04:02:26.898023: step 32920, loss = 0.54, batch loss = 0.33 (52.4 examples/sec; 0.153 sec/batch; 12h:41m:43s remains)
INFO - root - 2017-12-01 04:02:28.449235: step 32930, loss = 0.43, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 12h:47m:17s remains)
INFO - root - 2017-12-01 04:02:30.012393: step 32940, loss = 0.46, batch loss = 0.25 (49.5 examples/sec; 0.162 sec/batch; 13h:26m:34s remains)
INFO - root - 2017-12-01 04:02:31.573299: step 32950, loss = 0.45, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 13h:19m:43s remains)
INFO - root - 2017-12-01 04:02:33.114965: step 32960, loss = 0.44, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 12h:48m:23s remains)
INFO - root - 2017-12-01 04:02:34.661755: step 32970, loss = 0.43, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 12h:39m:41s remains)
INFO - root - 2017-12-01 04:02:36.234040: step 32980, loss = 0.48, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 12h:47m:56s remains)
INFO - root - 2017-12-01 04:02:37.816959: step 32990, loss = 0.41, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 13h:07m:33s remains)
INFO - root - 2017-12-01 04:02:39.384661: step 33000, loss = 0.58, batch loss = 0.37 (51.2 examples/sec; 0.156 sec/batch; 12h:59m:34s remains)
INFO - root - 2017-12-01 04:02:41.037511: step 33010, loss = 0.42, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 13h:19m:09s remains)
INFO - root - 2017-12-01 04:02:42.590621: step 33020, loss = 0.44, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 12h:53m:59s remains)
INFO - root - 2017-12-01 04:02:44.185634: step 33030, loss = 0.42, batch loss = 0.20 (41.1 examples/sec; 0.195 sec/batch; 16h:11m:41s remains)
INFO - root - 2017-12-01 04:02:45.757415: step 33040, loss = 0.44, batch loss = 0.23 (51.1 examples/sec; 0.156 sec/batch; 13h:00m:49s remains)
INFO - root - 2017-12-01 04:02:47.484147: step 33050, loss = 0.46, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 12h:59m:21s remains)
INFO - root - 2017-12-01 04:02:49.055434: step 33060, loss = 0.47, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 12h:59m:33s remains)
INFO - root - 2017-12-01 04:02:50.606525: step 33070, loss = 0.41, batch loss = 0.20 (49.5 examples/sec; 0.161 sec/batch; 13h:25m:50s remains)
INFO - root - 2017-12-01 04:02:52.151827: step 33080, loss = 0.55, batch loss = 0.33 (51.1 examples/sec; 0.157 sec/batch; 13h:01m:33s remains)
INFO - root - 2017-12-01 04:02:53.716345: step 33090, loss = 0.50, batch loss = 0.28 (52.3 examples/sec; 0.153 sec/batch; 12h:43m:48s remains)
INFO - root - 2017-12-01 04:02:55.299833: step 33100, loss = 0.43, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 12h:46m:04s remains)
INFO - root - 2017-12-01 04:02:56.917241: step 33110, loss = 0.45, batch loss = 0.24 (52.5 examples/sec; 0.152 sec/batch; 12h:39m:49s remains)
INFO - root - 2017-12-01 04:02:58.469517: step 33120, loss = 0.41, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 12h:41m:14s remains)
INFO - root - 2017-12-01 04:03:00.064703: step 33130, loss = 0.46, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 13h:04m:42s remains)
INFO - root - 2017-12-01 04:03:01.606569: step 33140, loss = 0.45, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 13h:02m:07s remains)
INFO - root - 2017-12-01 04:03:03.176998: step 33150, loss = 0.52, batch loss = 0.31 (50.1 examples/sec; 0.160 sec/batch; 13h:16m:56s remains)
INFO - root - 2017-12-01 04:03:04.822999: step 33160, loss = 0.41, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 12h:59m:57s remains)
INFO - root - 2017-12-01 04:03:06.428570: step 33170, loss = 0.60, batch loss = 0.39 (52.1 examples/sec; 0.153 sec/batch; 12h:45m:34s remains)
INFO - root - 2017-12-01 04:03:07.973599: step 33180, loss = 0.43, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 12h:42m:48s remains)
INFO - root - 2017-12-01 04:03:09.656999: step 33190, loss = 0.46, batch loss = 0.25 (49.3 examples/sec; 0.162 sec/batch; 13h:29m:17s remains)
INFO - root - 2017-12-01 04:03:11.286864: step 33200, loss = 0.47, batch loss = 0.26 (49.9 examples/sec; 0.160 sec/batch; 13h:20m:20s remains)
INFO - root - 2017-12-01 04:03:12.911130: step 33210, loss = 0.40, batch loss = 0.18 (51.8 examples/sec; 0.155 sec/batch; 12h:50m:42s remains)
INFO - root - 2017-12-01 04:03:14.532174: step 33220, loss = 0.42, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 12h:54m:33s remains)
INFO - root - 2017-12-01 04:03:16.192079: step 33230, loss = 0.40, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 12h:51m:51s remains)
INFO - root - 2017-12-01 04:03:17.775966: step 33240, loss = 0.48, batch loss = 0.26 (49.3 examples/sec; 0.162 sec/batch; 13h:29m:22s remains)
INFO - root - 2017-12-01 04:03:19.340269: step 33250, loss = 0.48, batch loss = 0.27 (49.2 examples/sec; 0.163 sec/batch; 13h:30m:54s remains)
INFO - root - 2017-12-01 04:03:20.910925: step 33260, loss = 0.46, batch loss = 0.25 (52.2 examples/sec; 0.153 sec/batch; 12h:43m:51s remains)
INFO - root - 2017-12-01 04:03:22.478171: step 33270, loss = 0.47, batch loss = 0.26 (47.6 examples/sec; 0.168 sec/batch; 13h:57m:29s remains)
INFO - root - 2017-12-01 04:03:24.036622: step 33280, loss = 0.45, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 12h:58m:40s remains)
INFO - root - 2017-12-01 04:03:25.602042: step 33290, loss = 0.49, batch loss = 0.27 (50.4 examples/sec; 0.159 sec/batch; 13h:11m:22s remains)
INFO - root - 2017-12-01 04:03:27.178098: step 33300, loss = 0.47, batch loss = 0.26 (50.0 examples/sec; 0.160 sec/batch; 13h:17m:42s remains)
INFO - root - 2017-12-01 04:03:28.838377: step 33310, loss = 0.44, batch loss = 0.23 (49.0 examples/sec; 0.163 sec/batch; 13h:33m:39s remains)
INFO - root - 2017-12-01 04:03:30.387087: step 33320, loss = 0.43, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 12h:47m:55s remains)
INFO - root - 2017-12-01 04:03:31.947663: step 33330, loss = 0.39, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 13h:04m:00s remains)
INFO - root - 2017-12-01 04:03:33.513761: step 33340, loss = 0.43, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 12h:42m:54s remains)
INFO - root - 2017-12-01 04:03:35.089515: step 33350, loss = 0.57, batch loss = 0.36 (51.3 examples/sec; 0.156 sec/batch; 12h:58m:02s remains)
INFO - root - 2017-12-01 04:03:36.645591: step 33360, loss = 0.48, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 13h:02m:17s remains)
INFO - root - 2017-12-01 04:03:38.207403: step 33370, loss = 0.44, batch loss = 0.23 (49.4 examples/sec; 0.162 sec/batch; 13h:26m:43s remains)
INFO - root - 2017-12-01 04:03:39.784187: step 33380, loss = 0.44, batch loss = 0.23 (52.1 examples/sec; 0.154 sec/batch; 12h:45m:19s remains)
INFO - root - 2017-12-01 04:03:41.343177: step 33390, loss = 0.43, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 12h:53m:59s remains)
INFO - root - 2017-12-01 04:03:42.906844: step 33400, loss = 0.47, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 12h:55m:11s remains)
INFO - root - 2017-12-01 04:03:44.507936: step 33410, loss = 0.45, batch loss = 0.23 (51.8 examples/sec; 0.155 sec/batch; 12h:50m:19s remains)
INFO - root - 2017-12-01 04:03:46.068472: step 33420, loss = 0.44, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 12h:44m:28s remains)
INFO - root - 2017-12-01 04:03:47.650614: step 33430, loss = 0.42, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 12h:56m:30s remains)
INFO - root - 2017-12-01 04:03:49.227349: step 33440, loss = 0.50, batch loss = 0.28 (49.7 examples/sec; 0.161 sec/batch; 13h:21m:48s remains)
INFO - root - 2017-12-01 04:03:50.795109: step 33450, loss = 0.38, batch loss = 0.16 (49.7 examples/sec; 0.161 sec/batch; 13h:21m:33s remains)
INFO - root - 2017-12-01 04:03:52.358095: step 33460, loss = 0.43, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 13h:01m:19s remains)
INFO - root - 2017-12-01 04:03:54.142686: step 33470, loss = 0.44, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 13h:07m:01s remains)
INFO - root - 2017-12-01 04:03:55.718340: step 33480, loss = 0.61, batch loss = 0.40 (50.6 examples/sec; 0.158 sec/batch; 13h:08m:36s remains)
INFO - root - 2017-12-01 04:03:57.258722: step 33490, loss = 0.45, batch loss = 0.24 (53.3 examples/sec; 0.150 sec/batch; 12h:27m:41s remains)
INFO - root - 2017-12-01 04:03:58.824973: step 33500, loss = 0.43, batch loss = 0.22 (52.7 examples/sec; 0.152 sec/batch; 12h:36m:06s remains)
INFO - root - 2017-12-01 04:04:00.455388: step 33510, loss = 0.52, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 12h:53m:14s remains)
INFO - root - 2017-12-01 04:04:02.006780: step 33520, loss = 0.47, batch loss = 0.25 (53.0 examples/sec; 0.151 sec/batch; 12h:31m:51s remains)
INFO - root - 2017-12-01 04:04:03.580478: step 33530, loss = 0.37, batch loss = 0.16 (47.0 examples/sec; 0.170 sec/batch; 14h:08m:31s remains)
INFO - root - 2017-12-01 04:04:05.156796: step 33540, loss = 0.45, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 13h:05m:39s remains)
INFO - root - 2017-12-01 04:04:06.725491: step 33550, loss = 0.46, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 12h:55m:16s remains)
INFO - root - 2017-12-01 04:04:08.300363: step 33560, loss = 0.41, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 13h:15m:18s remains)
INFO - root - 2017-12-01 04:04:09.868943: step 33570, loss = 0.53, batch loss = 0.32 (52.2 examples/sec; 0.153 sec/batch; 12h:43m:05s remains)
INFO - root - 2017-12-01 04:04:11.461541: step 33580, loss = 0.44, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 13h:00m:29s remains)
INFO - root - 2017-12-01 04:04:13.057910: step 33590, loss = 0.44, batch loss = 0.23 (49.4 examples/sec; 0.162 sec/batch; 13h:26m:58s remains)
INFO - root - 2017-12-01 04:04:14.712996: step 33600, loss = 0.51, batch loss = 0.30 (50.8 examples/sec; 0.157 sec/batch; 13h:04m:24s remains)
INFO - root - 2017-12-01 04:04:16.318121: step 33610, loss = 0.53, batch loss = 0.32 (52.9 examples/sec; 0.151 sec/batch; 12h:32m:57s remains)
INFO - root - 2017-12-01 04:04:17.885841: step 33620, loss = 0.47, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 13h:02m:08s remains)
INFO - root - 2017-12-01 04:04:19.445000: step 33630, loss = 0.42, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 12h:47m:05s remains)
INFO - root - 2017-12-01 04:04:20.994536: step 33640, loss = 0.46, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 12h:47m:44s remains)
INFO - root - 2017-12-01 04:04:22.561060: step 33650, loss = 0.47, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 13h:09m:06s remains)
INFO - root - 2017-12-01 04:04:24.247407: step 33660, loss = 0.45, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 13h:02m:43s remains)
INFO - root - 2017-12-01 04:04:25.896806: step 33670, loss = 0.46, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 12h:47m:16s remains)
INFO - root - 2017-12-01 04:04:27.471115: step 33680, loss = 0.42, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 13h:02m:43s remains)
INFO - root - 2017-12-01 04:04:29.037960: step 33690, loss = 0.46, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 13h:18m:34s remains)
INFO - root - 2017-12-01 04:04:30.602114: step 33700, loss = 0.41, batch loss = 0.20 (53.1 examples/sec; 0.151 sec/batch; 12h:30m:26s remains)
INFO - root - 2017-12-01 04:04:32.224392: step 33710, loss = 0.57, batch loss = 0.36 (47.9 examples/sec; 0.167 sec/batch; 13h:52m:11s remains)
INFO - root - 2017-12-01 04:04:33.781958: step 33720, loss = 0.51, batch loss = 0.30 (50.6 examples/sec; 0.158 sec/batch; 13h:07m:47s remains)
INFO - root - 2017-12-01 04:04:35.340679: step 33730, loss = 0.55, batch loss = 0.34 (52.3 examples/sec; 0.153 sec/batch; 12h:42m:14s remains)
INFO - root - 2017-12-01 04:04:36.899724: step 33740, loss = 0.51, batch loss = 0.30 (53.2 examples/sec; 0.150 sec/batch; 12h:28m:18s remains)
INFO - root - 2017-12-01 04:04:38.469640: step 33750, loss = 0.48, batch loss = 0.27 (50.1 examples/sec; 0.160 sec/batch; 13h:15m:22s remains)
INFO - root - 2017-12-01 04:04:40.021409: step 33760, loss = 0.51, batch loss = 0.29 (53.0 examples/sec; 0.151 sec/batch; 12h:30m:53s remains)
INFO - root - 2017-12-01 04:04:41.622863: step 33770, loss = 0.40, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 13h:18m:23s remains)
INFO - root - 2017-12-01 04:04:43.201027: step 33780, loss = 0.43, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 12h:38m:12s remains)
INFO - root - 2017-12-01 04:04:44.739891: step 33790, loss = 0.53, batch loss = 0.31 (51.8 examples/sec; 0.154 sec/batch; 12h:48m:08s remains)
INFO - root - 2017-12-01 04:04:46.307627: step 33800, loss = 0.40, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 12h:41m:32s remains)
INFO - root - 2017-12-01 04:04:47.925820: step 33810, loss = 0.43, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 13h:02m:56s remains)
INFO - root - 2017-12-01 04:04:49.479457: step 33820, loss = 0.38, batch loss = 0.17 (50.7 examples/sec; 0.158 sec/batch; 13h:05m:27s remains)
INFO - root - 2017-12-01 04:04:51.055808: step 33830, loss = 0.40, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 12h:41m:15s remains)
INFO - root - 2017-12-01 04:04:52.616218: step 33840, loss = 0.63, batch loss = 0.42 (51.1 examples/sec; 0.156 sec/batch; 12h:58m:35s remains)
INFO - root - 2017-12-01 04:04:54.185438: step 33850, loss = 0.51, batch loss = 0.30 (51.6 examples/sec; 0.155 sec/batch; 12h:51m:49s remains)
INFO - root - 2017-12-01 04:04:55.754625: step 33860, loss = 0.45, batch loss = 0.23 (51.8 examples/sec; 0.155 sec/batch; 12h:49m:25s remains)
INFO - root - 2017-12-01 04:04:57.320002: step 33870, loss = 0.52, batch loss = 0.31 (50.5 examples/sec; 0.159 sec/batch; 13h:09m:11s remains)
INFO - root - 2017-12-01 04:04:58.885591: step 33880, loss = 0.40, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 12h:51m:18s remains)
INFO - root - 2017-12-01 04:05:00.448909: step 33890, loss = 0.48, batch loss = 0.27 (52.1 examples/sec; 0.154 sec/batch; 12h:44m:19s remains)
INFO - root - 2017-12-01 04:05:02.003322: step 33900, loss = 0.63, batch loss = 0.41 (50.8 examples/sec; 0.157 sec/batch; 13h:03m:04s remains)
INFO - root - 2017-12-01 04:05:03.660789: step 33910, loss = 0.36, batch loss = 0.15 (51.8 examples/sec; 0.154 sec/batch; 12h:48m:43s remains)
INFO - root - 2017-12-01 04:05:05.361206: step 33920, loss = 0.45, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 12h:51m:03s remains)
INFO - root - 2017-12-01 04:05:06.909820: step 33930, loss = 0.39, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 12h:52m:24s remains)
INFO - root - 2017-12-01 04:05:08.466477: step 33940, loss = 0.40, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 12h:54m:48s remains)
INFO - root - 2017-12-01 04:05:10.026980: step 33950, loss = 0.42, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 12h:40m:27s remains)
INFO - root - 2017-12-01 04:05:11.596733: step 33960, loss = 0.49, batch loss = 0.28 (52.4 examples/sec; 0.153 sec/batch; 12h:39m:54s remains)
INFO - root - 2017-12-01 04:05:13.157289: step 33970, loss = 0.47, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 12h:59m:53s remains)
INFO - root - 2017-12-01 04:05:14.747198: step 33980, loss = 0.45, batch loss = 0.23 (46.8 examples/sec; 0.171 sec/batch; 14h:09m:48s remains)
INFO - root - 2017-12-01 04:05:16.308324: step 33990, loss = 0.39, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 12h:58m:00s remains)
INFO - root - 2017-12-01 04:05:17.871055: step 34000, loss = 0.62, batch loss = 0.40 (52.0 examples/sec; 0.154 sec/batch; 12h:44m:49s remains)
INFO - root - 2017-12-01 04:05:19.510165: step 34010, loss = 0.44, batch loss = 0.23 (50.4 examples/sec; 0.159 sec/batch; 13h:09m:52s remains)
INFO - root - 2017-12-01 04:05:21.190887: step 34020, loss = 0.43, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 12h:56m:58s remains)
INFO - root - 2017-12-01 04:05:22.748500: step 34030, loss = 0.44, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 12h:51m:33s remains)
INFO - root - 2017-12-01 04:05:24.336220: step 34040, loss = 0.43, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 13h:08m:21s remains)
INFO - root - 2017-12-01 04:05:25.949373: step 34050, loss = 0.46, batch loss = 0.25 (49.0 examples/sec; 0.163 sec/batch; 13h:31m:50s remains)
INFO - root - 2017-12-01 04:05:27.526571: step 34060, loss = 0.57, batch loss = 0.36 (48.3 examples/sec; 0.166 sec/batch; 13h:44m:27s remains)
INFO - root - 2017-12-01 04:05:29.112631: step 34070, loss = 0.48, batch loss = 0.27 (53.4 examples/sec; 0.150 sec/batch; 12h:25m:23s remains)
INFO - root - 2017-12-01 04:05:30.818381: step 34080, loss = 0.53, batch loss = 0.32 (51.8 examples/sec; 0.155 sec/batch; 12h:48m:41s remains)
INFO - root - 2017-12-01 04:05:32.375083: step 34090, loss = 0.51, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 12h:54m:23s remains)
INFO - root - 2017-12-01 04:05:33.939892: step 34100, loss = 0.44, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 12h:58m:35s remains)
INFO - root - 2017-12-01 04:05:35.556469: step 34110, loss = 0.43, batch loss = 0.22 (52.8 examples/sec; 0.151 sec/batch; 12h:33m:13s remains)
INFO - root - 2017-12-01 04:05:37.100520: step 34120, loss = 0.43, batch loss = 0.22 (51.8 examples/sec; 0.155 sec/batch; 12h:48m:36s remains)
INFO - root - 2017-12-01 04:05:38.690930: step 34130, loss = 0.45, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 13h:00m:05s remains)
INFO - root - 2017-12-01 04:05:40.235288: step 34140, loss = 0.45, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 12h:40m:48s remains)
INFO - root - 2017-12-01 04:05:41.798787: step 34150, loss = 0.51, batch loss = 0.30 (48.8 examples/sec; 0.164 sec/batch; 13h:34m:27s remains)
INFO - root - 2017-12-01 04:05:43.363010: step 34160, loss = 0.48, batch loss = 0.27 (53.4 examples/sec; 0.150 sec/batch; 12h:25m:16s remains)
INFO - root - 2017-12-01 04:05:44.941012: step 34170, loss = 0.47, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 12h:44m:50s remains)
INFO - root - 2017-12-01 04:05:46.501123: step 34180, loss = 0.50, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 13h:04m:51s remains)
INFO - root - 2017-12-01 04:05:48.078594: step 34190, loss = 0.53, batch loss = 0.32 (45.0 examples/sec; 0.178 sec/batch; 14h:43m:52s remains)
INFO - root - 2017-12-01 04:05:49.631420: step 34200, loss = 0.42, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 12h:49m:36s remains)
INFO - root - 2017-12-01 04:05:51.229265: step 34210, loss = 0.41, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 13h:01m:23s remains)
INFO - root - 2017-12-01 04:05:52.799982: step 34220, loss = 0.46, batch loss = 0.25 (50.8 examples/sec; 0.158 sec/batch; 13h:03m:09s remains)
INFO - root - 2017-12-01 04:05:54.369979: step 34230, loss = 0.38, batch loss = 0.17 (49.3 examples/sec; 0.162 sec/batch; 13h:25m:59s remains)
INFO - root - 2017-12-01 04:05:55.958834: step 34240, loss = 0.47, batch loss = 0.26 (52.5 examples/sec; 0.152 sec/batch; 12h:37m:40s remains)
INFO - root - 2017-12-01 04:05:57.529730: step 34250, loss = 0.50, batch loss = 0.29 (51.1 examples/sec; 0.157 sec/batch; 12h:58m:57s remains)
INFO - root - 2017-12-01 04:05:59.083612: step 34260, loss = 0.41, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 13h:16m:02s remains)
INFO - root - 2017-12-01 04:06:00.646278: step 34270, loss = 0.50, batch loss = 0.29 (49.8 examples/sec; 0.161 sec/batch; 13h:17m:55s remains)
INFO - root - 2017-12-01 04:06:02.206825: step 34280, loss = 0.50, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 12h:50m:39s remains)
INFO - root - 2017-12-01 04:06:03.772254: step 34290, loss = 0.48, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 12h:41m:31s remains)
INFO - root - 2017-12-01 04:06:05.350600: step 34300, loss = 0.42, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 12h:59m:52s remains)
INFO - root - 2017-12-01 04:06:07.032236: step 34310, loss = 0.54, batch loss = 0.33 (52.2 examples/sec; 0.153 sec/batch; 12h:41m:20s remains)
INFO - root - 2017-12-01 04:06:08.596263: step 34320, loss = 0.40, batch loss = 0.19 (49.8 examples/sec; 0.161 sec/batch; 13h:18m:22s remains)
INFO - root - 2017-12-01 04:06:10.170753: step 34330, loss = 0.41, batch loss = 0.20 (49.6 examples/sec; 0.161 sec/batch; 13h:22m:06s remains)
INFO - root - 2017-12-01 04:06:11.731733: step 34340, loss = 0.43, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 12h:58m:50s remains)
INFO - root - 2017-12-01 04:06:13.309684: step 34350, loss = 0.52, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 13h:00m:11s remains)
INFO - root - 2017-12-01 04:06:14.878650: step 34360, loss = 0.41, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 12h:57m:57s remains)
INFO - root - 2017-12-01 04:06:16.471385: step 34370, loss = 0.40, batch loss = 0.19 (44.8 examples/sec; 0.179 sec/batch; 14h:47m:11s remains)
INFO - root - 2017-12-01 04:06:18.048364: step 34380, loss = 0.40, batch loss = 0.19 (50.3 examples/sec; 0.159 sec/batch; 13h:09m:48s remains)
INFO - root - 2017-12-01 04:06:19.618624: step 34390, loss = 0.56, batch loss = 0.35 (51.0 examples/sec; 0.157 sec/batch; 12h:58m:53s remains)
INFO - root - 2017-12-01 04:06:21.185266: step 34400, loss = 0.49, batch loss = 0.28 (50.3 examples/sec; 0.159 sec/batch; 13h:09m:47s remains)
INFO - root - 2017-12-01 04:06:22.909155: step 34410, loss = 0.51, batch loss = 0.30 (40.0 examples/sec; 0.200 sec/batch; 16h:32m:36s remains)
INFO - root - 2017-12-01 04:06:24.482053: step 34420, loss = 0.46, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 12h:49m:40s remains)
INFO - root - 2017-12-01 04:06:26.051095: step 34430, loss = 0.61, batch loss = 0.40 (50.9 examples/sec; 0.157 sec/batch; 13h:00m:43s remains)
INFO - root - 2017-12-01 04:06:27.624409: step 34440, loss = 0.47, batch loss = 0.26 (50.8 examples/sec; 0.158 sec/batch; 13h:02m:33s remains)
INFO - root - 2017-12-01 04:06:29.194943: step 34450, loss = 0.43, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 13h:00m:43s remains)
INFO - root - 2017-12-01 04:06:30.758303: step 34460, loss = 0.38, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 12h:52m:19s remains)
INFO - root - 2017-12-01 04:06:32.336601: step 34470, loss = 0.49, batch loss = 0.28 (49.5 examples/sec; 0.162 sec/batch; 13h:22m:15s remains)
INFO - root - 2017-12-01 04:06:33.911027: step 34480, loss = 0.42, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 13h:03m:17s remains)
INFO - root - 2017-12-01 04:06:35.478613: step 34490, loss = 0.52, batch loss = 0.31 (51.4 examples/sec; 0.156 sec/batch; 12h:53m:47s remains)
INFO - root - 2017-12-01 04:06:37.044618: step 34500, loss = 0.46, batch loss = 0.25 (52.2 examples/sec; 0.153 sec/batch; 12h:41m:44s remains)
INFO - root - 2017-12-01 04:06:38.723824: step 34510, loss = 0.55, batch loss = 0.34 (49.8 examples/sec; 0.161 sec/batch; 13h:17m:55s remains)
INFO - root - 2017-12-01 04:06:40.276446: step 34520, loss = 0.46, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 12h:46m:21s remains)
INFO - root - 2017-12-01 04:06:41.835378: step 34530, loss = 0.46, batch loss = 0.25 (49.8 examples/sec; 0.161 sec/batch; 13h:17m:40s remains)
INFO - root - 2017-12-01 04:06:43.397865: step 34540, loss = 0.49, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 12h:52m:09s remains)
INFO - root - 2017-12-01 04:06:44.991351: step 34550, loss = 0.39, batch loss = 0.18 (49.9 examples/sec; 0.160 sec/batch; 13h:15m:33s remains)
INFO - root - 2017-12-01 04:06:46.542083: step 34560, loss = 0.45, batch loss = 0.24 (51.8 examples/sec; 0.155 sec/batch; 12h:47m:29s remains)
INFO - root - 2017-12-01 04:06:48.103845: step 34570, loss = 0.45, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 13h:01m:03s remains)
INFO - root - 2017-12-01 04:06:49.648294: step 34580, loss = 0.49, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 12h:47m:41s remains)
INFO - root - 2017-12-01 04:06:51.239537: step 34590, loss = 0.41, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 12h:56m:03s remains)
INFO - root - 2017-12-01 04:06:52.809256: step 34600, loss = 0.50, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 12h:56m:24s remains)
INFO - root - 2017-12-01 04:06:54.451650: step 34610, loss = 0.49, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 12h:48m:02s remains)
INFO - root - 2017-12-01 04:06:56.023940: step 34620, loss = 0.43, batch loss = 0.22 (49.0 examples/sec; 0.163 sec/batch; 13h:31m:00s remains)
INFO - root - 2017-12-01 04:06:57.578567: step 34630, loss = 0.40, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 13h:08m:32s remains)
INFO - root - 2017-12-01 04:06:59.152711: step 34640, loss = 0.49, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 12h:45m:01s remains)
INFO - root - 2017-12-01 04:07:00.727494: step 34650, loss = 0.61, batch loss = 0.40 (51.6 examples/sec; 0.155 sec/batch; 12h:50m:15s remains)
INFO - root - 2017-12-01 04:07:02.294694: step 34660, loss = 0.53, batch loss = 0.32 (50.4 examples/sec; 0.159 sec/batch; 13h:07m:24s remains)
INFO - root - 2017-12-01 04:07:03.853323: step 34670, loss = 0.42, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 12h:54m:50s remains)
INFO - root - 2017-12-01 04:07:05.411861: step 34680, loss = 0.45, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 12h:44m:22s remains)
INFO - root - 2017-12-01 04:07:06.965825: step 34690, loss = 0.43, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 12h:53m:02s remains)
INFO - root - 2017-12-01 04:07:08.524293: step 34700, loss = 0.56, batch loss = 0.35 (52.0 examples/sec; 0.154 sec/batch; 12h:43m:27s remains)
INFO - root - 2017-12-01 04:07:10.157977: step 34710, loss = 0.44, batch loss = 0.23 (49.1 examples/sec; 0.163 sec/batch; 13h:28m:04s remains)
INFO - root - 2017-12-01 04:07:11.722327: step 34720, loss = 0.44, batch loss = 0.24 (49.4 examples/sec; 0.162 sec/batch; 13h:23m:12s remains)
INFO - root - 2017-12-01 04:07:13.294289: step 34730, loss = 0.43, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 12h:56m:10s remains)
INFO - root - 2017-12-01 04:07:14.858210: step 34740, loss = 0.42, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 13h:08m:00s remains)
INFO - root - 2017-12-01 04:07:16.403245: step 34750, loss = 0.41, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 12h:55m:18s remains)
INFO - root - 2017-12-01 04:07:17.963534: step 34760, loss = 0.42, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 12h:59m:11s remains)
INFO - root - 2017-12-01 04:07:19.524370: step 34770, loss = 0.60, batch loss = 0.39 (49.7 examples/sec; 0.161 sec/batch; 13h:18m:32s remains)
INFO - root - 2017-12-01 04:07:21.101532: step 34780, loss = 0.44, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 13h:02m:31s remains)
INFO - root - 2017-12-01 04:07:22.650841: step 34790, loss = 0.57, batch loss = 0.36 (51.5 examples/sec; 0.155 sec/batch; 12h:50m:32s remains)
INFO - root - 2017-12-01 04:07:24.210678: step 34800, loss = 0.40, batch loss = 0.19 (50.2 examples/sec; 0.160 sec/batch; 13h:11m:23s remains)
INFO - root - 2017-12-01 04:07:25.889100: step 34810, loss = 0.42, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 13h:01m:48s remains)
INFO - root - 2017-12-01 04:07:27.450927: step 34820, loss = 0.40, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 12h:55m:12s remains)
INFO - root - 2017-12-01 04:07:29.012729: step 34830, loss = 0.46, batch loss = 0.25 (50.1 examples/sec; 0.160 sec/batch; 13h:12m:13s remains)
INFO - root - 2017-12-01 04:07:30.600236: step 34840, loss = 0.44, batch loss = 0.24 (49.5 examples/sec; 0.162 sec/batch; 13h:21m:25s remains)
INFO - root - 2017-12-01 04:07:32.184939: step 34850, loss = 0.48, batch loss = 0.27 (52.1 examples/sec; 0.153 sec/batch; 12h:41m:17s remains)
INFO - root - 2017-12-01 04:07:33.745203: step 34860, loss = 0.45, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 12h:55m:16s remains)
INFO - root - 2017-12-01 04:07:35.318620: step 34870, loss = 0.57, batch loss = 0.36 (50.2 examples/sec; 0.159 sec/batch; 13h:11m:05s remains)
INFO - root - 2017-12-01 04:07:36.879268: step 34880, loss = 0.40, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 12h:47m:58s remains)
INFO - root - 2017-12-01 04:07:38.452662: step 34890, loss = 0.47, batch loss = 0.26 (53.0 examples/sec; 0.151 sec/batch; 12h:28m:22s remains)
INFO - root - 2017-12-01 04:07:40.052576: step 34900, loss = 0.45, batch loss = 0.24 (42.8 examples/sec; 0.187 sec/batch; 15h:27m:13s remains)
INFO - root - 2017-12-01 04:07:41.730895: step 34910, loss = 0.51, batch loss = 0.30 (49.1 examples/sec; 0.163 sec/batch; 13h:28m:24s remains)
INFO - root - 2017-12-01 04:07:43.292218: step 34920, loss = 0.53, batch loss = 0.32 (50.6 examples/sec; 0.158 sec/batch; 13h:04m:31s remains)
INFO - root - 2017-12-01 04:07:44.856522: step 34930, loss = 0.39, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 13h:04m:04s remains)
INFO - root - 2017-12-01 04:07:46.405764: step 34940, loss = 0.48, batch loss = 0.27 (48.9 examples/sec; 0.164 sec/batch; 13h:31m:52s remains)
INFO - root - 2017-12-01 04:07:47.983025: step 34950, loss = 0.42, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 12h:58m:20s remains)
INFO - root - 2017-12-01 04:07:49.562938: step 34960, loss = 0.47, batch loss = 0.27 (50.5 examples/sec; 0.158 sec/batch; 13h:05m:09s remains)
INFO - root - 2017-12-01 04:07:51.115445: step 34970, loss = 0.44, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 12h:59m:52s remains)
INFO - root - 2017-12-01 04:07:52.678372: step 34980, loss = 0.36, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 12h:53m:41s remains)
INFO - root - 2017-12-01 04:07:54.239481: step 34990, loss = 0.43, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 12h:32m:51s remains)
INFO - root - 2017-12-01 04:07:55.818911: step 35000, loss = 0.46, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 12h:55m:24s remains)
INFO - root - 2017-12-01 04:07:57.452826: step 35010, loss = 0.72, batch loss = 0.51 (51.3 examples/sec; 0.156 sec/batch; 12h:53m:35s remains)
INFO - root - 2017-12-01 04:07:59.034811: step 35020, loss = 0.44, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 12h:48m:01s remains)
INFO - root - 2017-12-01 04:08:00.597820: step 35030, loss = 0.39, batch loss = 0.18 (52.7 examples/sec; 0.152 sec/batch; 12h:32m:26s remains)
INFO - root - 2017-12-01 04:08:02.170348: step 35040, loss = 0.41, batch loss = 0.20 (49.5 examples/sec; 0.162 sec/batch; 13h:21m:39s remains)
INFO - root - 2017-12-01 04:08:03.758292: step 35050, loss = 0.37, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 13h:02m:02s remains)
INFO - root - 2017-12-01 04:08:05.339239: step 35060, loss = 0.45, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 12h:44m:38s remains)
INFO - root - 2017-12-01 04:08:06.897978: step 35070, loss = 0.43, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 12h:53m:34s remains)
INFO - root - 2017-12-01 04:08:08.459046: step 35080, loss = 0.48, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 12h:57m:53s remains)
INFO - root - 2017-12-01 04:08:10.009896: step 35090, loss = 0.43, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 12h:37m:40s remains)
INFO - root - 2017-12-01 04:08:11.614997: step 35100, loss = 0.46, batch loss = 0.25 (48.5 examples/sec; 0.165 sec/batch; 13h:38m:15s remains)
INFO - root - 2017-12-01 04:08:13.240694: step 35110, loss = 0.55, batch loss = 0.34 (46.8 examples/sec; 0.171 sec/batch; 14h:07m:56s remains)
INFO - root - 2017-12-01 04:08:14.820688: step 35120, loss = 0.48, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 12h:58m:19s remains)
INFO - root - 2017-12-01 04:08:16.376425: step 35130, loss = 0.46, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 12h:47m:00s remains)
INFO - root - 2017-12-01 04:08:17.938771: step 35140, loss = 0.51, batch loss = 0.30 (51.8 examples/sec; 0.154 sec/batch; 12h:44m:45s remains)
INFO - root - 2017-12-01 04:08:19.516436: step 35150, loss = 0.51, batch loss = 0.30 (50.3 examples/sec; 0.159 sec/batch; 13h:07m:35s remains)
INFO - root - 2017-12-01 04:08:21.083660: step 35160, loss = 0.44, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 12h:54m:45s remains)
INFO - root - 2017-12-01 04:08:22.674681: step 35170, loss = 0.48, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 13h:08m:23s remains)
INFO - root - 2017-12-01 04:08:24.235786: step 35180, loss = 0.46, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 12h:46m:56s remains)
INFO - root - 2017-12-01 04:08:25.785781: step 35190, loss = 0.63, batch loss = 0.42 (51.1 examples/sec; 0.157 sec/batch; 12h:56m:27s remains)
INFO - root - 2017-12-01 04:08:27.374342: step 35200, loss = 0.38, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 12h:52m:20s remains)
INFO - root - 2017-12-01 04:08:29.027990: step 35210, loss = 0.61, batch loss = 0.40 (50.1 examples/sec; 0.160 sec/batch; 13h:11m:21s remains)
INFO - root - 2017-12-01 04:08:30.597519: step 35220, loss = 0.49, batch loss = 0.28 (53.4 examples/sec; 0.150 sec/batch; 12h:22m:33s remains)
INFO - root - 2017-12-01 04:08:32.161724: step 35230, loss = 0.68, batch loss = 0.47 (53.0 examples/sec; 0.151 sec/batch; 12h:27m:53s remains)
INFO - root - 2017-12-01 04:08:33.717243: step 35240, loss = 0.59, batch loss = 0.38 (51.5 examples/sec; 0.155 sec/batch; 12h:49m:47s remains)
INFO - root - 2017-12-01 04:08:35.261482: step 35250, loss = 0.40, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 12h:59m:38s remains)
INFO - root - 2017-12-01 04:08:36.816553: step 35260, loss = 0.44, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 13h:01m:30s remains)
INFO - root - 2017-12-01 04:08:38.395605: step 35270, loss = 0.49, batch loss = 0.29 (48.9 examples/sec; 0.164 sec/batch; 13h:30m:27s remains)
INFO - root - 2017-12-01 04:08:39.969731: step 35280, loss = 0.46, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 12h:56m:33s remains)
INFO - root - 2017-12-01 04:08:41.527589: step 35290, loss = 0.47, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 12h:42m:25s remains)
INFO - root - 2017-12-01 04:08:43.081744: step 35300, loss = 0.51, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 12h:58m:51s remains)
INFO - root - 2017-12-01 04:08:44.679061: step 35310, loss = 0.65, batch loss = 0.45 (52.2 examples/sec; 0.153 sec/batch; 12h:39m:18s remains)
INFO - root - 2017-12-01 04:08:46.243918: step 35320, loss = 0.41, batch loss = 0.21 (53.0 examples/sec; 0.151 sec/batch; 12h:27m:07s remains)
INFO - root - 2017-12-01 04:08:47.800193: step 35330, loss = 0.41, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 12h:44m:25s remains)
INFO - root - 2017-12-01 04:08:49.349471: step 35340, loss = 0.39, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 12h:35m:01s remains)
INFO - root - 2017-12-01 04:08:50.911064: step 35350, loss = 0.50, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 12h:57m:48s remains)
INFO - root - 2017-12-01 04:08:52.468285: step 35360, loss = 0.40, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 12h:55m:20s remains)
INFO - root - 2017-12-01 04:08:54.024629: step 35370, loss = 0.46, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 12h:45m:34s remains)
INFO - root - 2017-12-01 04:08:55.594452: step 35380, loss = 0.48, batch loss = 0.27 (52.3 examples/sec; 0.153 sec/batch; 12h:37m:09s remains)
INFO - root - 2017-12-01 04:08:57.143547: step 35390, loss = 0.42, batch loss = 0.21 (49.8 examples/sec; 0.161 sec/batch; 13h:16m:09s remains)
INFO - root - 2017-12-01 04:08:58.694044: step 35400, loss = 0.41, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 12h:38m:47s remains)
INFO - root - 2017-12-01 04:09:00.327861: step 35410, loss = 0.47, batch loss = 0.26 (48.4 examples/sec; 0.165 sec/batch; 13h:38m:42s remains)
INFO - root - 2017-12-01 04:09:01.893314: step 35420, loss = 0.63, batch loss = 0.42 (52.7 examples/sec; 0.152 sec/batch; 12h:31m:27s remains)
INFO - root - 2017-12-01 04:09:03.453204: step 35430, loss = 0.59, batch loss = 0.39 (52.4 examples/sec; 0.153 sec/batch; 12h:35m:27s remains)
INFO - root - 2017-12-01 04:09:05.025259: step 35440, loss = 0.54, batch loss = 0.34 (49.7 examples/sec; 0.161 sec/batch; 13h:17m:39s remains)
INFO - root - 2017-12-01 04:09:06.589443: step 35450, loss = 0.43, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 12h:44m:38s remains)
INFO - root - 2017-12-01 04:09:08.149699: step 35460, loss = 0.50, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 13h:01m:52s remains)
INFO - root - 2017-12-01 04:09:09.702744: step 35470, loss = 0.40, batch loss = 0.19 (52.7 examples/sec; 0.152 sec/batch; 12h:31m:30s remains)
INFO - root - 2017-12-01 04:09:11.291275: step 35480, loss = 0.43, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 12h:41m:47s remains)
INFO - root - 2017-12-01 04:09:12.868318: step 35490, loss = 0.43, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 13h:09m:25s remains)
INFO - root - 2017-12-01 04:09:14.430953: step 35500, loss = 0.73, batch loss = 0.52 (50.9 examples/sec; 0.157 sec/batch; 12h:58m:24s remains)
INFO - root - 2017-12-01 04:09:16.059839: step 35510, loss = 0.46, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 12h:48m:20s remains)
INFO - root - 2017-12-01 04:09:17.621923: step 35520, loss = 0.52, batch loss = 0.31 (50.3 examples/sec; 0.159 sec/batch; 13h:07m:32s remains)
INFO - root - 2017-12-01 04:09:19.201664: step 35530, loss = 0.53, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 13h:00m:46s remains)
INFO - root - 2017-12-01 04:09:20.808886: step 35540, loss = 0.41, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 12h:39m:03s remains)
INFO - root - 2017-12-01 04:09:22.382828: step 35550, loss = 0.53, batch loss = 0.33 (51.2 examples/sec; 0.156 sec/batch; 12h:52m:54s remains)
INFO - root - 2017-12-01 04:09:23.938845: step 35560, loss = 0.52, batch loss = 0.31 (51.8 examples/sec; 0.155 sec/batch; 12h:44m:53s remains)
INFO - root - 2017-12-01 04:09:25.492340: step 35570, loss = 0.41, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 13h:02m:15s remains)
INFO - root - 2017-12-01 04:09:27.074568: step 35580, loss = 0.44, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 12h:57m:42s remains)
INFO - root - 2017-12-01 04:09:28.631899: step 35590, loss = 0.40, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 12h:57m:58s remains)
INFO - root - 2017-12-01 04:09:30.201079: step 35600, loss = 0.42, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 13h:01m:00s remains)
INFO - root - 2017-12-01 04:09:31.841702: step 35610, loss = 0.41, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 13h:08m:26s remains)
INFO - root - 2017-12-01 04:09:33.409665: step 35620, loss = 0.49, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 12h:57m:26s remains)
INFO - root - 2017-12-01 04:09:34.970166: step 35630, loss = 0.50, batch loss = 0.30 (50.2 examples/sec; 0.160 sec/batch; 13h:09m:14s remains)
INFO - root - 2017-12-01 04:09:36.531363: step 35640, loss = 0.49, batch loss = 0.28 (50.2 examples/sec; 0.159 sec/batch; 13h:09m:05s remains)
INFO - root - 2017-12-01 04:09:38.094238: step 35650, loss = 0.52, batch loss = 0.31 (52.2 examples/sec; 0.153 sec/batch; 12h:37m:33s remains)
INFO - root - 2017-12-01 04:09:39.678097: step 35660, loss = 0.51, batch loss = 0.30 (51.6 examples/sec; 0.155 sec/batch; 12h:46m:39s remains)
INFO - root - 2017-12-01 04:09:41.248759: step 35670, loss = 0.46, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 13h:05m:20s remains)
INFO - root - 2017-12-01 04:09:42.812327: step 35680, loss = 0.45, batch loss = 0.24 (50.5 examples/sec; 0.159 sec/batch; 13h:04m:25s remains)
INFO - root - 2017-12-01 04:09:44.392648: step 35690, loss = 0.44, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 12h:47m:26s remains)
INFO - root - 2017-12-01 04:09:45.951059: step 35700, loss = 0.46, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 12h:47m:53s remains)
INFO - root - 2017-12-01 04:09:47.557474: step 35710, loss = 0.43, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 12h:55m:57s remains)
INFO - root - 2017-12-01 04:09:49.132993: step 35720, loss = 0.41, batch loss = 0.20 (52.9 examples/sec; 0.151 sec/batch; 12h:28m:20s remains)
INFO - root - 2017-12-01 04:09:50.734577: step 35730, loss = 0.38, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 12h:44m:41s remains)
INFO - root - 2017-12-01 04:09:52.295417: step 35740, loss = 0.41, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 13h:09m:54s remains)
INFO - root - 2017-12-01 04:09:53.874729: step 35750, loss = 0.46, batch loss = 0.25 (50.0 examples/sec; 0.160 sec/batch; 13h:11m:44s remains)
INFO - root - 2017-12-01 04:09:55.450645: step 35760, loss = 0.44, batch loss = 0.23 (51.1 examples/sec; 0.156 sec/batch; 12h:53m:47s remains)
INFO - root - 2017-12-01 04:09:57.005075: step 35770, loss = 0.42, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 12h:43m:37s remains)
INFO - root - 2017-12-01 04:09:58.563035: step 35780, loss = 0.43, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 13h:10m:11s remains)
INFO - root - 2017-12-01 04:10:00.130895: step 35790, loss = 0.44, batch loss = 0.23 (50.1 examples/sec; 0.160 sec/batch; 13h:09m:48s remains)
INFO - root - 2017-12-01 04:10:01.692599: step 35800, loss = 0.51, batch loss = 0.30 (51.0 examples/sec; 0.157 sec/batch; 12h:55m:00s remains)
INFO - root - 2017-12-01 04:10:03.317096: step 35810, loss = 0.51, batch loss = 0.30 (48.9 examples/sec; 0.164 sec/batch; 13h:29m:16s remains)
INFO - root - 2017-12-01 04:10:04.899381: step 35820, loss = 0.40, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 13h:08m:25s remains)
INFO - root - 2017-12-01 04:10:06.464824: step 35830, loss = 0.45, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 12h:45m:32s remains)
INFO - root - 2017-12-01 04:10:08.040574: step 35840, loss = 0.43, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 13h:02m:35s remains)
INFO - root - 2017-12-01 04:10:09.601538: step 35850, loss = 0.45, batch loss = 0.24 (50.5 examples/sec; 0.159 sec/batch; 13h:03m:42s remains)
INFO - root - 2017-12-01 04:10:11.156926: step 35860, loss = 0.52, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 12h:56m:51s remains)
INFO - root - 2017-12-01 04:10:12.719177: step 35870, loss = 0.47, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 13h:01m:39s remains)
INFO - root - 2017-12-01 04:10:14.279489: step 35880, loss = 0.54, batch loss = 0.34 (52.2 examples/sec; 0.153 sec/batch; 12h:38m:05s remains)
INFO - root - 2017-12-01 04:10:15.859459: step 35890, loss = 0.47, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 12h:45m:33s remains)
INFO - root - 2017-12-01 04:10:17.412677: step 35900, loss = 0.42, batch loss = 0.21 (52.6 examples/sec; 0.152 sec/batch; 12h:31m:10s remains)
INFO - root - 2017-12-01 04:10:19.028905: step 35910, loss = 0.55, batch loss = 0.34 (51.6 examples/sec; 0.155 sec/batch; 12h:47m:02s remains)
INFO - root - 2017-12-01 04:10:20.611355: step 35920, loss = 0.57, batch loss = 0.36 (50.5 examples/sec; 0.158 sec/batch; 13h:03m:25s remains)
INFO - root - 2017-12-01 04:10:22.209648: step 35930, loss = 0.44, batch loss = 0.23 (50.4 examples/sec; 0.159 sec/batch; 13h:04m:08s remains)
INFO - root - 2017-12-01 04:10:23.778126: step 35940, loss = 0.42, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 12h:56m:57s remains)
INFO - root - 2017-12-01 04:10:25.316047: step 35950, loss = 0.46, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 13h:02m:11s remains)
INFO - root - 2017-12-01 04:10:26.897954: step 35960, loss = 0.41, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 13h:03m:54s remains)
INFO - root - 2017-12-01 04:10:28.475802: step 35970, loss = 0.41, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 13h:02m:36s remains)
INFO - root - 2017-12-01 04:10:30.073914: step 35980, loss = 0.39, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 13h:00m:17s remains)
INFO - root - 2017-12-01 04:10:31.631470: step 35990, loss = 0.46, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 12h:51m:24s remains)
INFO - root - 2017-12-01 04:10:33.192357: step 36000, loss = 0.47, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 12h:48m:10s remains)
INFO - root - 2017-12-01 04:10:34.826410: step 36010, loss = 0.43, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 13h:07m:23s remains)
INFO - root - 2017-12-01 04:10:36.365804: step 36020, loss = 0.56, batch loss = 0.36 (51.8 examples/sec; 0.154 sec/batch; 12h:42m:48s remains)
INFO - root - 2017-12-01 04:10:37.914167: step 36030, loss = 0.47, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 12h:45m:03s remains)
INFO - root - 2017-12-01 04:10:39.501174: step 36040, loss = 0.46, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 12h:42m:27s remains)
INFO - root - 2017-12-01 04:10:41.067853: step 36050, loss = 0.45, batch loss = 0.24 (51.8 examples/sec; 0.155 sec/batch; 12h:43m:21s remains)
INFO - root - 2017-12-01 04:10:42.621048: step 36060, loss = 0.46, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 12h:59m:44s remains)
INFO - root - 2017-12-01 04:10:44.183563: step 36070, loss = 0.55, batch loss = 0.35 (52.0 examples/sec; 0.154 sec/batch; 12h:40m:33s remains)
INFO - root - 2017-12-01 04:10:45.763399: step 36080, loss = 0.44, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 12h:49m:06s remains)
INFO - root - 2017-12-01 04:10:47.311950: step 36090, loss = 0.52, batch loss = 0.32 (51.5 examples/sec; 0.155 sec/batch; 12h:47m:00s remains)
INFO - root - 2017-12-01 04:10:48.891623: step 36100, loss = 0.45, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 12h:53m:56s remains)
INFO - root - 2017-12-01 04:10:50.535708: step 36110, loss = 0.47, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 12h:53m:26s remains)
INFO - root - 2017-12-01 04:10:52.104861: step 36120, loss = 0.46, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 12h:55m:48s remains)
INFO - root - 2017-12-01 04:10:53.672324: step 36130, loss = 0.42, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 12h:58m:50s remains)
INFO - root - 2017-12-01 04:10:55.231794: step 36140, loss = 0.43, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 13h:00m:36s remains)
INFO - root - 2017-12-01 04:10:56.800181: step 36150, loss = 0.42, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 12h:40m:20s remains)
INFO - root - 2017-12-01 04:10:58.359665: step 36160, loss = 0.44, batch loss = 0.24 (51.8 examples/sec; 0.155 sec/batch; 12h:43m:11s remains)
INFO - root - 2017-12-01 04:10:59.911903: step 36170, loss = 0.53, batch loss = 0.32 (51.4 examples/sec; 0.156 sec/batch; 12h:48m:23s remains)
INFO - root - 2017-12-01 04:11:01.490716: step 36180, loss = 0.36, batch loss = 0.15 (50.8 examples/sec; 0.158 sec/batch; 12h:57m:53s remains)
INFO - root - 2017-12-01 04:11:03.049447: step 36190, loss = 0.45, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 12h:42m:03s remains)
INFO - root - 2017-12-01 04:11:04.598971: step 36200, loss = 0.53, batch loss = 0.32 (52.5 examples/sec; 0.152 sec/batch; 12h:32m:51s remains)
INFO - root - 2017-12-01 04:11:06.220176: step 36210, loss = 0.56, batch loss = 0.35 (50.7 examples/sec; 0.158 sec/batch; 12h:59m:47s remains)
INFO - root - 2017-12-01 04:11:07.773244: step 36220, loss = 0.42, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 13h:07m:07s remains)
INFO - root - 2017-12-01 04:11:09.323812: step 36230, loss = 0.48, batch loss = 0.27 (51.2 examples/sec; 0.156 sec/batch; 12h:51m:26s remains)
INFO - root - 2017-12-01 04:11:10.891067: step 36240, loss = 0.44, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 12h:49m:45s remains)
INFO - root - 2017-12-01 04:11:12.466577: step 36250, loss = 0.45, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 12h:47m:56s remains)
INFO - root - 2017-12-01 04:11:14.053804: step 36260, loss = 0.46, batch loss = 0.26 (50.1 examples/sec; 0.160 sec/batch; 13h:07m:59s remains)
INFO - root - 2017-12-01 04:11:15.600467: step 36270, loss = 0.44, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 12h:47m:46s remains)
INFO - root - 2017-12-01 04:11:17.164146: step 36280, loss = 0.46, batch loss = 0.25 (48.6 examples/sec; 0.164 sec/batch; 13h:31m:51s remains)
INFO - root - 2017-12-01 04:11:18.735004: step 36290, loss = 0.44, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 12h:42m:33s remains)
INFO - root - 2017-12-01 04:11:20.301638: step 36300, loss = 0.61, batch loss = 0.41 (51.2 examples/sec; 0.156 sec/batch; 12h:51m:36s remains)
INFO - root - 2017-12-01 04:11:21.926127: step 36310, loss = 0.51, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 12h:51m:23s remains)
INFO - root - 2017-12-01 04:11:23.477165: step 36320, loss = 0.42, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 12h:41m:03s remains)
INFO - root - 2017-12-01 04:11:25.059320: step 36330, loss = 0.40, batch loss = 0.19 (49.3 examples/sec; 0.162 sec/batch; 13h:20m:27s remains)
INFO - root - 2017-12-01 04:11:26.623789: step 36340, loss = 0.44, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 12h:58m:59s remains)
INFO - root - 2017-12-01 04:11:28.204460: step 36350, loss = 0.52, batch loss = 0.31 (49.6 examples/sec; 0.161 sec/batch; 13h:16m:17s remains)
INFO - root - 2017-12-01 04:11:29.800522: step 36360, loss = 0.49, batch loss = 0.28 (50.8 examples/sec; 0.157 sec/batch; 12h:57m:06s remains)
INFO - root - 2017-12-01 04:11:31.354810: step 36370, loss = 0.49, batch loss = 0.28 (52.7 examples/sec; 0.152 sec/batch; 12h:29m:04s remains)
INFO - root - 2017-12-01 04:11:32.935306: step 36380, loss = 0.40, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 12h:57m:41s remains)
INFO - root - 2017-12-01 04:11:34.492141: step 36390, loss = 0.59, batch loss = 0.38 (49.8 examples/sec; 0.161 sec/batch; 13h:13m:12s remains)
INFO - root - 2017-12-01 04:11:36.059894: step 36400, loss = 0.45, batch loss = 0.24 (52.8 examples/sec; 0.151 sec/batch; 12h:27m:23s remains)
INFO - root - 2017-12-01 04:11:37.688434: step 36410, loss = 0.44, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 12h:54m:33s remains)
INFO - root - 2017-12-01 04:11:39.281007: step 36420, loss = 0.44, batch loss = 0.24 (50.5 examples/sec; 0.159 sec/batch; 13h:02m:24s remains)
INFO - root - 2017-12-01 04:11:40.855088: step 36430, loss = 0.51, batch loss = 0.30 (52.4 examples/sec; 0.153 sec/batch; 12h:33m:33s remains)
INFO - root - 2017-12-01 04:11:42.423391: step 36440, loss = 0.45, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 12h:40m:32s remains)
INFO - root - 2017-12-01 04:11:43.986475: step 36450, loss = 0.44, batch loss = 0.23 (50.1 examples/sec; 0.160 sec/batch; 13h:08m:06s remains)
INFO - root - 2017-12-01 04:11:45.540593: step 36460, loss = 0.41, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 13h:08m:00s remains)
INFO - root - 2017-12-01 04:11:47.123314: step 36470, loss = 0.44, batch loss = 0.23 (51.8 examples/sec; 0.155 sec/batch; 12h:42m:35s remains)
INFO - root - 2017-12-01 04:11:48.701680: step 36480, loss = 0.59, batch loss = 0.38 (50.9 examples/sec; 0.157 sec/batch; 12h:55m:45s remains)
INFO - root - 2017-12-01 04:11:50.271975: step 36490, loss = 0.43, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 12h:51m:03s remains)
INFO - root - 2017-12-01 04:11:51.818065: step 36500, loss = 0.46, batch loss = 0.25 (50.2 examples/sec; 0.159 sec/batch; 13h:05m:48s remains)
INFO - root - 2017-12-01 04:11:53.488964: step 36510, loss = 0.44, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 13h:11m:13s remains)
INFO - root - 2017-12-01 04:11:55.046061: step 36520, loss = 0.47, batch loss = 0.26 (50.0 examples/sec; 0.160 sec/batch; 13h:08m:54s remains)
INFO - root - 2017-12-01 04:11:56.598505: step 36530, loss = 0.41, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 12h:30m:10s remains)
INFO - root - 2017-12-01 04:11:58.169781: step 36540, loss = 0.45, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 12h:40m:45s remains)
INFO - root - 2017-12-01 04:11:59.738546: step 36550, loss = 0.64, batch loss = 0.44 (51.9 examples/sec; 0.154 sec/batch; 12h:40m:13s remains)
INFO - root - 2017-12-01 04:12:01.312251: step 36560, loss = 0.47, batch loss = 0.26 (50.8 examples/sec; 0.157 sec/batch; 12h:56m:34s remains)
INFO - root - 2017-12-01 04:12:02.852415: step 36570, loss = 0.47, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 12h:48m:38s remains)
INFO - root - 2017-12-01 04:12:04.438080: step 36580, loss = 0.55, batch loss = 0.35 (48.6 examples/sec; 0.165 sec/batch; 13h:32m:21s remains)
INFO - root - 2017-12-01 04:12:06.002068: step 36590, loss = 0.44, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 12h:52m:41s remains)
INFO - root - 2017-12-01 04:12:07.566521: step 36600, loss = 0.40, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 12h:49m:31s remains)
INFO - root - 2017-12-01 04:12:09.204656: step 36610, loss = 0.44, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 12h:34m:10s remains)
INFO - root - 2017-12-01 04:12:10.785992: step 36620, loss = 0.43, batch loss = 0.23 (49.8 examples/sec; 0.161 sec/batch; 13h:11m:39s remains)
INFO - root - 2017-12-01 04:12:12.352471: step 36630, loss = 0.50, batch loss = 0.30 (50.5 examples/sec; 0.158 sec/batch; 13h:01m:04s remains)
INFO - root - 2017-12-01 04:12:13.982620: step 36640, loss = 0.49, batch loss = 0.28 (50.0 examples/sec; 0.160 sec/batch; 13h:08m:22s remains)
INFO - root - 2017-12-01 04:12:15.539256: step 36650, loss = 0.47, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 12h:45m:58s remains)
INFO - root - 2017-12-01 04:12:17.099754: step 36660, loss = 0.48, batch loss = 0.27 (51.8 examples/sec; 0.154 sec/batch; 12h:40m:50s remains)
INFO - root - 2017-12-01 04:12:18.677508: step 36670, loss = 0.40, batch loss = 0.20 (46.9 examples/sec; 0.171 sec/batch; 14h:01m:00s remains)
INFO - root - 2017-12-01 04:12:20.255797: step 36680, loss = 0.43, batch loss = 0.23 (49.1 examples/sec; 0.163 sec/batch; 13h:22m:41s remains)
INFO - root - 2017-12-01 04:12:21.855884: step 36690, loss = 0.37, batch loss = 0.16 (51.0 examples/sec; 0.157 sec/batch; 12h:52m:38s remains)
INFO - root - 2017-12-01 04:12:23.422026: step 36700, loss = 0.54, batch loss = 0.34 (47.5 examples/sec; 0.169 sec/batch; 13h:51m:06s remains)
INFO - root - 2017-12-01 04:12:25.046544: step 36710, loss = 0.56, batch loss = 0.35 (51.5 examples/sec; 0.155 sec/batch; 12h:45m:21s remains)
INFO - root - 2017-12-01 04:12:26.603892: step 36720, loss = 0.47, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 12h:49m:31s remains)
INFO - root - 2017-12-01 04:12:28.168673: step 36730, loss = 0.62, batch loss = 0.41 (50.2 examples/sec; 0.159 sec/batch; 13h:05m:37s remains)
INFO - root - 2017-12-01 04:12:29.742032: step 36740, loss = 0.43, batch loss = 0.22 (49.4 examples/sec; 0.162 sec/batch; 13h:18m:01s remains)
INFO - root - 2017-12-01 04:12:31.322837: step 36750, loss = 0.44, batch loss = 0.24 (50.0 examples/sec; 0.160 sec/batch; 13h:08m:10s remains)
INFO - root - 2017-12-01 04:12:32.886317: step 36760, loss = 0.47, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 12h:59m:52s remains)
INFO - root - 2017-12-01 04:12:34.446586: step 36770, loss = 0.58, batch loss = 0.38 (50.9 examples/sec; 0.157 sec/batch; 12h:54m:06s remains)
INFO - root - 2017-12-01 04:12:36.027598: step 36780, loss = 0.51, batch loss = 0.30 (50.0 examples/sec; 0.160 sec/batch; 13h:08m:16s remains)
INFO - root - 2017-12-01 04:12:37.567313: step 36790, loss = 0.39, batch loss = 0.18 (52.8 examples/sec; 0.152 sec/batch; 12h:27m:01s remains)
INFO - root - 2017-12-01 04:12:39.166405: step 36800, loss = 0.40, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 13h:07m:23s remains)
INFO - root - 2017-12-01 04:12:40.774896: step 36810, loss = 0.48, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 12h:52m:54s remains)
INFO - root - 2017-12-01 04:12:42.340679: step 36820, loss = 0.46, batch loss = 0.25 (52.1 examples/sec; 0.154 sec/batch; 12h:37m:01s remains)
INFO - root - 2017-12-01 04:12:43.927765: step 36830, loss = 0.50, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 12h:49m:40s remains)
INFO - root - 2017-12-01 04:12:45.501124: step 36840, loss = 0.42, batch loss = 0.21 (50.0 examples/sec; 0.160 sec/batch; 13h:09m:00s remains)
INFO - root - 2017-12-01 04:12:47.073427: step 36850, loss = 0.40, batch loss = 0.20 (50.5 examples/sec; 0.159 sec/batch; 13h:01m:17s remains)
INFO - root - 2017-12-01 04:12:48.637826: step 36860, loss = 0.44, batch loss = 0.24 (48.6 examples/sec; 0.165 sec/batch; 13h:30m:51s remains)
INFO - root - 2017-12-01 04:12:50.225966: step 36870, loss = 0.47, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 13h:02m:52s remains)
INFO - root - 2017-12-01 04:12:51.776383: step 36880, loss = 0.60, batch loss = 0.39 (51.4 examples/sec; 0.156 sec/batch; 12h:47m:32s remains)
INFO - root - 2017-12-01 04:12:53.337961: step 36890, loss = 0.43, batch loss = 0.23 (48.1 examples/sec; 0.166 sec/batch; 13h:39m:23s remains)
INFO - root - 2017-12-01 04:12:54.895175: step 36900, loss = 0.44, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 12h:27m:37s remains)
INFO - root - 2017-12-01 04:12:56.547233: step 36910, loss = 0.46, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 13h:01m:50s remains)
INFO - root - 2017-12-01 04:12:58.117116: step 36920, loss = 0.43, batch loss = 0.22 (48.6 examples/sec; 0.165 sec/batch; 13h:31m:16s remains)
INFO - root - 2017-12-01 04:12:59.695928: step 36930, loss = 0.45, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 12h:48m:57s remains)
INFO - root - 2017-12-01 04:13:01.255887: step 36940, loss = 0.57, batch loss = 0.36 (51.6 examples/sec; 0.155 sec/batch; 12h:43m:51s remains)
INFO - root - 2017-12-01 04:13:02.815159: step 36950, loss = 0.63, batch loss = 0.42 (50.0 examples/sec; 0.160 sec/batch; 13h:07m:54s remains)
INFO - root - 2017-12-01 04:13:04.384492: step 36960, loss = 0.44, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 12h:56m:48s remains)
INFO - root - 2017-12-01 04:13:05.941396: step 36970, loss = 0.44, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 12h:58m:07s remains)
INFO - root - 2017-12-01 04:13:07.498154: step 36980, loss = 0.48, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 12h:59m:22s remains)
INFO - root - 2017-12-01 04:13:09.055609: step 36990, loss = 0.40, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 12h:40m:18s remains)
INFO - root - 2017-12-01 04:13:10.617474: step 37000, loss = 0.38, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 12h:37m:17s remains)
INFO - root - 2017-12-01 04:13:12.242999: step 37010, loss = 0.44, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 12h:48m:30s remains)
INFO - root - 2017-12-01 04:13:13.800341: step 37020, loss = 0.49, batch loss = 0.28 (53.1 examples/sec; 0.151 sec/batch; 12h:22m:26s remains)
INFO - root - 2017-12-01 04:13:15.362627: step 37030, loss = 0.56, batch loss = 0.36 (51.9 examples/sec; 0.154 sec/batch; 12h:38m:23s remains)
INFO - root - 2017-12-01 04:13:16.932090: step 37040, loss = 0.50, batch loss = 0.29 (52.4 examples/sec; 0.153 sec/batch; 12h:32m:06s remains)
INFO - root - 2017-12-01 04:13:18.498049: step 37050, loss = 0.56, batch loss = 0.35 (49.6 examples/sec; 0.161 sec/batch; 13h:13m:31s remains)
INFO - root - 2017-12-01 04:13:20.057030: step 37060, loss = 0.55, batch loss = 0.34 (51.6 examples/sec; 0.155 sec/batch; 12h:43m:57s remains)
INFO - root - 2017-12-01 04:13:21.619916: step 37070, loss = 0.51, batch loss = 0.30 (53.0 examples/sec; 0.151 sec/batch; 12h:22m:53s remains)
INFO - root - 2017-12-01 04:13:23.207298: step 37080, loss = 0.46, batch loss = 0.26 (49.8 examples/sec; 0.161 sec/batch; 13h:11m:12s remains)
INFO - root - 2017-12-01 04:13:24.760732: step 37090, loss = 0.49, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 12h:52m:50s remains)
INFO - root - 2017-12-01 04:13:26.325653: step 37100, loss = 0.50, batch loss = 0.29 (50.1 examples/sec; 0.160 sec/batch; 13h:06m:42s remains)
INFO - root - 2017-12-01 04:13:27.937573: step 37110, loss = 0.46, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 12h:46m:38s remains)
INFO - root - 2017-12-01 04:13:29.497731: step 37120, loss = 0.38, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 12h:41m:34s remains)
INFO - root - 2017-12-01 04:13:31.045483: step 37130, loss = 0.40, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 12h:59m:54s remains)
INFO - root - 2017-12-01 04:13:32.637102: step 37140, loss = 0.57, batch loss = 0.36 (51.9 examples/sec; 0.154 sec/batch; 12h:39m:04s remains)
INFO - root - 2017-12-01 04:13:34.195170: step 37150, loss = 0.53, batch loss = 0.32 (52.7 examples/sec; 0.152 sec/batch; 12h:26m:50s remains)
INFO - root - 2017-12-01 04:13:35.756518: step 37160, loss = 0.55, batch loss = 0.35 (51.8 examples/sec; 0.154 sec/batch; 12h:39m:55s remains)
INFO - root - 2017-12-01 04:13:37.332226: step 37170, loss = 0.43, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 12h:47m:22s remains)
INFO - root - 2017-12-01 04:13:38.889613: step 37180, loss = 0.44, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 12h:42m:27s remains)
INFO - root - 2017-12-01 04:13:40.459075: step 37190, loss = 0.41, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 12h:48m:37s remains)
INFO - root - 2017-12-01 04:13:42.037120: step 37200, loss = 0.46, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 12h:45m:57s remains)
INFO - root - 2017-12-01 04:13:43.669408: step 37210, loss = 0.36, batch loss = 0.16 (48.6 examples/sec; 0.164 sec/batch; 13h:29m:33s remains)
INFO - root - 2017-12-01 04:13:45.230305: step 37220, loss = 0.42, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 12h:50m:42s remains)
INFO - root - 2017-12-01 04:13:46.789082: step 37230, loss = 0.45, batch loss = 0.25 (52.1 examples/sec; 0.153 sec/batch; 12h:35m:06s remains)
INFO - root - 2017-12-01 04:13:48.343319: step 37240, loss = 0.39, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 12h:42m:45s remains)
INFO - root - 2017-12-01 04:13:49.910441: step 37250, loss = 0.40, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 12h:35m:25s remains)
INFO - root - 2017-12-01 04:13:51.457260: step 37260, loss = 0.47, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 12h:52m:11s remains)
INFO - root - 2017-12-01 04:13:53.028396: step 37270, loss = 0.45, batch loss = 0.24 (50.8 examples/sec; 0.157 sec/batch; 12h:54m:44s remains)
INFO - root - 2017-12-01 04:13:54.582445: step 37280, loss = 0.50, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 12h:48m:22s remains)
INFO - root - 2017-12-01 04:13:56.168937: step 37290, loss = 0.43, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 13h:08m:01s remains)
INFO - root - 2017-12-01 04:13:57.750883: step 37300, loss = 0.46, batch loss = 0.26 (48.1 examples/sec; 0.166 sec/batch; 13h:37m:54s remains)
INFO - root - 2017-12-01 04:13:59.382358: step 37310, loss = 0.54, batch loss = 0.33 (51.7 examples/sec; 0.155 sec/batch; 12h:41m:19s remains)
INFO - root - 2017-12-01 04:14:00.950247: step 37320, loss = 0.49, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 12h:48m:31s remains)
INFO - root - 2017-12-01 04:14:02.510908: step 37330, loss = 0.48, batch loss = 0.27 (50.5 examples/sec; 0.158 sec/batch; 12h:59m:14s remains)
INFO - root - 2017-12-01 04:14:04.074681: step 37340, loss = 0.45, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 12h:48m:21s remains)
INFO - root - 2017-12-01 04:14:05.649148: step 37350, loss = 0.42, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 12h:35m:26s remains)
INFO - root - 2017-12-01 04:14:07.215049: step 37360, loss = 0.51, batch loss = 0.31 (52.0 examples/sec; 0.154 sec/batch; 12h:37m:04s remains)
INFO - root - 2017-12-01 04:14:08.783050: step 37370, loss = 0.51, batch loss = 0.30 (50.8 examples/sec; 0.158 sec/batch; 12h:55m:05s remains)
INFO - root - 2017-12-01 04:14:10.340940: step 37380, loss = 0.41, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 13h:03m:49s remains)
INFO - root - 2017-12-01 04:14:11.890436: step 37390, loss = 0.49, batch loss = 0.29 (52.0 examples/sec; 0.154 sec/batch; 12h:36m:42s remains)
INFO - root - 2017-12-01 04:14:13.462471: step 37400, loss = 0.40, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 12h:48m:02s remains)
INFO - root - 2017-12-01 04:14:15.110365: step 37410, loss = 0.41, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 13h:08m:53s remains)
INFO - root - 2017-12-01 04:14:16.661900: step 37420, loss = 0.42, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 12h:36m:00s remains)
INFO - root - 2017-12-01 04:14:18.216060: step 37430, loss = 0.52, batch loss = 0.32 (51.7 examples/sec; 0.155 sec/batch; 12h:41m:00s remains)
INFO - root - 2017-12-01 04:14:19.839622: step 37440, loss = 0.50, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 12h:44m:20s remains)
INFO - root - 2017-12-01 04:14:21.395054: step 37450, loss = 0.43, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 12h:41m:18s remains)
INFO - root - 2017-12-01 04:14:22.961397: step 37460, loss = 0.55, batch loss = 0.35 (51.0 examples/sec; 0.157 sec/batch; 12h:51m:22s remains)
INFO - root - 2017-12-01 04:14:24.556733: step 37470, loss = 0.39, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 12h:45m:42s remains)
INFO - root - 2017-12-01 04:14:26.159911: step 37480, loss = 0.41, batch loss = 0.20 (49.0 examples/sec; 0.163 sec/batch; 13h:22m:11s remains)
INFO - root - 2017-12-01 04:14:27.743595: step 37490, loss = 0.57, batch loss = 0.37 (52.4 examples/sec; 0.153 sec/batch; 12h:30m:27s remains)
INFO - root - 2017-12-01 04:14:29.342626: step 37500, loss = 0.43, batch loss = 0.23 (50.0 examples/sec; 0.160 sec/batch; 13h:07m:07s remains)
INFO - root - 2017-12-01 04:14:30.959019: step 37510, loss = 0.61, batch loss = 0.40 (50.6 examples/sec; 0.158 sec/batch; 12h:57m:14s remains)
INFO - root - 2017-12-01 04:14:32.558095: step 37520, loss = 0.43, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 12h:55m:13s remains)
INFO - root - 2017-12-01 04:14:34.117034: step 37530, loss = 0.40, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 13h:08m:08s remains)
INFO - root - 2017-12-01 04:14:35.675802: step 37540, loss = 0.44, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 13h:07m:29s remains)
INFO - root - 2017-12-01 04:14:37.234381: step 37550, loss = 0.38, batch loss = 0.18 (52.2 examples/sec; 0.153 sec/batch; 12h:33m:44s remains)
INFO - root - 2017-12-01 04:14:38.843223: step 37560, loss = 0.44, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 12h:49m:24s remains)
INFO - root - 2017-12-01 04:14:40.410339: step 37570, loss = 0.43, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 12h:50m:48s remains)
INFO - root - 2017-12-01 04:14:41.962791: step 37580, loss = 0.39, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 12h:38m:24s remains)
INFO - root - 2017-12-01 04:14:43.543362: step 37590, loss = 0.59, batch loss = 0.39 (51.0 examples/sec; 0.157 sec/batch; 12h:51m:41s remains)
INFO - root - 2017-12-01 04:14:45.094994: step 37600, loss = 0.44, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 12h:46m:03s remains)
INFO - root - 2017-12-01 04:14:46.697079: step 37610, loss = 0.46, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 12h:45m:01s remains)
INFO - root - 2017-12-01 04:14:48.257796: step 37620, loss = 0.56, batch loss = 0.36 (52.2 examples/sec; 0.153 sec/batch; 12h:32m:39s remains)
INFO - root - 2017-12-01 04:14:49.836050: step 37630, loss = 0.42, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 12h:29m:19s remains)
INFO - root - 2017-12-01 04:14:51.395832: step 37640, loss = 0.40, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 12h:49m:59s remains)
INFO - root - 2017-12-01 04:14:52.945846: step 37650, loss = 0.37, batch loss = 0.17 (52.1 examples/sec; 0.154 sec/batch; 12h:34m:57s remains)
INFO - root - 2017-12-01 04:14:54.498790: step 37660, loss = 0.49, batch loss = 0.28 (50.1 examples/sec; 0.160 sec/batch; 13h:05m:02s remains)
INFO - root - 2017-12-01 04:14:56.075900: step 37670, loss = 0.42, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 13h:05m:56s remains)
INFO - root - 2017-12-01 04:14:57.638308: step 37680, loss = 0.44, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 12h:57m:47s remains)
INFO - root - 2017-12-01 04:14:59.225373: step 37690, loss = 0.50, batch loss = 0.30 (51.3 examples/sec; 0.156 sec/batch; 12h:46m:49s remains)
INFO - root - 2017-12-01 04:15:00.771860: step 37700, loss = 0.42, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 12h:33m:02s remains)
INFO - root - 2017-12-01 04:15:02.378724: step 37710, loss = 0.47, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 12h:41m:52s remains)
INFO - root - 2017-12-01 04:15:03.968651: step 37720, loss = 0.43, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 12h:41m:00s remains)
INFO - root - 2017-12-01 04:15:05.549654: step 37730, loss = 0.49, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 12h:39m:31s remains)
INFO - root - 2017-12-01 04:15:07.111833: step 37740, loss = 0.44, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 13h:07m:10s remains)
INFO - root - 2017-12-01 04:15:08.687004: step 37750, loss = 0.43, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 12h:29m:33s remains)
INFO - root - 2017-12-01 04:15:10.286046: step 37760, loss = 0.42, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 12h:41m:35s remains)
INFO - root - 2017-12-01 04:15:11.865132: step 37770, loss = 0.43, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 12h:56m:53s remains)
INFO - root - 2017-12-01 04:15:13.433059: step 37780, loss = 0.57, batch loss = 0.36 (49.3 examples/sec; 0.162 sec/batch; 13h:16m:21s remains)
INFO - root - 2017-12-01 04:15:15.023238: step 37790, loss = 0.41, batch loss = 0.20 (52.5 examples/sec; 0.152 sec/batch; 12h:27m:55s remains)
INFO - root - 2017-12-01 04:15:16.601742: step 37800, loss = 0.52, batch loss = 0.31 (51.9 examples/sec; 0.154 sec/batch; 12h:36m:58s remains)
INFO - root - 2017-12-01 04:15:18.230081: step 37810, loss = 0.53, batch loss = 0.32 (52.6 examples/sec; 0.152 sec/batch; 12h:27m:31s remains)
INFO - root - 2017-12-01 04:15:19.810708: step 37820, loss = 0.43, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 12h:52m:43s remains)
INFO - root - 2017-12-01 04:15:21.405658: step 37830, loss = 0.50, batch loss = 0.30 (50.0 examples/sec; 0.160 sec/batch; 13h:05m:31s remains)
INFO - root - 2017-12-01 04:15:22.979291: step 37840, loss = 0.50, batch loss = 0.30 (52.9 examples/sec; 0.151 sec/batch; 12h:22m:33s remains)
INFO - root - 2017-12-01 04:15:24.553132: step 37850, loss = 0.45, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 12h:41m:16s remains)
INFO - root - 2017-12-01 04:15:26.153579: step 37860, loss = 0.56, batch loss = 0.36 (48.5 examples/sec; 0.165 sec/batch; 13h:29m:57s remains)
INFO - root - 2017-12-01 04:15:27.715630: step 37870, loss = 0.34, batch loss = 0.14 (52.4 examples/sec; 0.153 sec/batch; 12h:28m:59s remains)
INFO - root - 2017-12-01 04:15:29.305890: step 37880, loss = 0.48, batch loss = 0.27 (50.5 examples/sec; 0.158 sec/batch; 12h:57m:39s remains)
INFO - root - 2017-12-01 04:15:30.857615: step 37890, loss = 0.38, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 12h:39m:31s remains)
INFO - root - 2017-12-01 04:15:32.394062: step 37900, loss = 0.54, batch loss = 0.33 (51.9 examples/sec; 0.154 sec/batch; 12h:36m:11s remains)
INFO - root - 2017-12-01 04:15:34.008446: step 37910, loss = 0.44, batch loss = 0.24 (53.1 examples/sec; 0.151 sec/batch; 12h:19m:15s remains)
INFO - root - 2017-12-01 04:15:35.566822: step 37920, loss = 0.50, batch loss = 0.29 (52.0 examples/sec; 0.154 sec/batch; 12h:35m:27s remains)
INFO - root - 2017-12-01 04:15:37.127102: step 37930, loss = 0.40, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 12h:34m:58s remains)
INFO - root - 2017-12-01 04:15:38.695603: step 37940, loss = 0.38, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 12h:48m:49s remains)
INFO - root - 2017-12-01 04:15:40.255162: step 37950, loss = 0.48, batch loss = 0.27 (50.2 examples/sec; 0.159 sec/batch; 13h:01m:33s remains)
INFO - root - 2017-12-01 04:15:41.819671: step 37960, loss = 0.57, batch loss = 0.36 (51.5 examples/sec; 0.155 sec/batch; 12h:42m:12s remains)
INFO - root - 2017-12-01 04:15:43.403165: step 37970, loss = 0.42, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 12h:38m:06s remains)
INFO - root - 2017-12-01 04:15:44.991356: step 37980, loss = 0.49, batch loss = 0.28 (50.8 examples/sec; 0.157 sec/batch; 12h:52m:44s remains)
INFO - root - 2017-12-01 04:15:46.538168: step 37990, loss = 0.44, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 12h:54m:48s remains)
INFO - root - 2017-12-01 04:15:48.096622: step 38000, loss = 0.44, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 13h:07m:30s remains)
INFO - root - 2017-12-01 04:15:49.749766: step 38010, loss = 0.46, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 12h:54m:24s remains)
INFO - root - 2017-12-01 04:15:51.307201: step 38020, loss = 0.40, batch loss = 0.19 (49.2 examples/sec; 0.163 sec/batch; 13h:17m:38s remains)
INFO - root - 2017-12-01 04:15:52.863861: step 38030, loss = 0.43, batch loss = 0.23 (49.6 examples/sec; 0.161 sec/batch; 13h:10m:54s remains)
INFO - root - 2017-12-01 04:15:54.452752: step 38040, loss = 0.40, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 12h:59m:43s remains)
INFO - root - 2017-12-01 04:15:56.024446: step 38050, loss = 0.39, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 12h:43m:17s remains)
INFO - root - 2017-12-01 04:15:57.591663: step 38060, loss = 0.52, batch loss = 0.32 (50.6 examples/sec; 0.158 sec/batch; 12h:56m:23s remains)
INFO - root - 2017-12-01 04:15:59.200576: step 38070, loss = 0.45, batch loss = 0.25 (52.9 examples/sec; 0.151 sec/batch; 12h:21m:47s remains)
INFO - root - 2017-12-01 04:16:00.814718: step 38080, loss = 0.74, batch loss = 0.54 (50.4 examples/sec; 0.159 sec/batch; 12h:58m:56s remains)
INFO - root - 2017-12-01 04:16:02.370627: step 38090, loss = 0.49, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 12h:42m:06s remains)
INFO - root - 2017-12-01 04:16:03.945287: step 38100, loss = 0.40, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 12h:36m:41s remains)
INFO - root - 2017-12-01 04:16:05.562544: step 38110, loss = 0.48, batch loss = 0.27 (49.7 examples/sec; 0.161 sec/batch; 13h:09m:32s remains)
INFO - root - 2017-12-01 04:16:07.112137: step 38120, loss = 0.42, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 12h:26m:40s remains)
INFO - root - 2017-12-01 04:16:08.665917: step 38130, loss = 0.39, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 12h:44m:49s remains)
INFO - root - 2017-12-01 04:16:10.240024: step 38140, loss = 0.49, batch loss = 0.28 (52.0 examples/sec; 0.154 sec/batch; 12h:34m:46s remains)
INFO - root - 2017-12-01 04:16:11.808100: step 38150, loss = 0.49, batch loss = 0.29 (52.5 examples/sec; 0.152 sec/batch; 12h:27m:23s remains)
INFO - root - 2017-12-01 04:16:13.384239: step 38160, loss = 0.45, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 12h:50m:59s remains)
INFO - root - 2017-12-01 04:16:14.932139: step 38170, loss = 0.37, batch loss = 0.17 (52.9 examples/sec; 0.151 sec/batch; 12h:21m:56s remains)
INFO - root - 2017-12-01 04:16:16.485233: step 38180, loss = 0.48, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 12h:40m:26s remains)
INFO - root - 2017-12-01 04:16:18.062513: step 38190, loss = 0.49, batch loss = 0.28 (47.5 examples/sec; 0.169 sec/batch; 13h:46m:35s remains)
INFO - root - 2017-12-01 04:16:19.643084: step 38200, loss = 0.39, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 12h:38m:31s remains)
INFO - root - 2017-12-01 04:16:21.247130: step 38210, loss = 0.44, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 12h:26m:26s remains)
INFO - root - 2017-12-01 04:16:22.806223: step 38220, loss = 0.47, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 12h:54m:24s remains)
INFO - root - 2017-12-01 04:16:24.367054: step 38230, loss = 0.53, batch loss = 0.33 (53.4 examples/sec; 0.150 sec/batch; 12h:14m:05s remains)
INFO - root - 2017-12-01 04:16:25.938353: step 38240, loss = 0.42, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 12h:50m:04s remains)
INFO - root - 2017-12-01 04:16:27.499416: step 38250, loss = 0.49, batch loss = 0.29 (50.2 examples/sec; 0.159 sec/batch; 13h:01m:50s remains)
INFO - root - 2017-12-01 04:16:29.057509: step 38260, loss = 0.55, batch loss = 0.35 (50.2 examples/sec; 0.160 sec/batch; 13h:02m:11s remains)
INFO - root - 2017-12-01 04:16:30.616851: step 38270, loss = 0.38, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 12h:45m:18s remains)
INFO - root - 2017-12-01 04:16:32.185238: step 38280, loss = 0.50, batch loss = 0.30 (52.5 examples/sec; 0.152 sec/batch; 12h:26m:38s remains)
INFO - root - 2017-12-01 04:16:33.772350: step 38290, loss = 0.43, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 12h:51m:14s remains)
INFO - root - 2017-12-01 04:16:35.354357: step 38300, loss = 0.44, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 12h:48m:53s remains)
INFO - root - 2017-12-01 04:16:36.974294: step 38310, loss = 0.46, batch loss = 0.26 (51.1 examples/sec; 0.156 sec/batch; 12h:47m:18s remains)
INFO - root - 2017-12-01 04:16:38.544508: step 38320, loss = 0.40, batch loss = 0.19 (50.2 examples/sec; 0.160 sec/batch; 13h:02m:05s remains)
INFO - root - 2017-12-01 04:16:40.087033: step 38330, loss = 0.44, batch loss = 0.24 (50.8 examples/sec; 0.158 sec/batch; 12h:52m:27s remains)
INFO - root - 2017-12-01 04:16:41.664248: step 38340, loss = 0.43, batch loss = 0.23 (52.8 examples/sec; 0.152 sec/batch; 12h:22m:53s remains)
INFO - root - 2017-12-01 04:16:43.217270: step 38350, loss = 0.47, batch loss = 0.27 (52.6 examples/sec; 0.152 sec/batch; 12h:25m:52s remains)
INFO - root - 2017-12-01 04:16:44.802219: step 38360, loss = 0.39, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 12h:52m:00s remains)
INFO - root - 2017-12-01 04:16:46.364512: step 38370, loss = 0.37, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 13h:00m:25s remains)
INFO - root - 2017-12-01 04:16:47.906878: step 38380, loss = 0.45, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 12h:38m:18s remains)
INFO - root - 2017-12-01 04:16:49.471964: step 38390, loss = 0.48, batch loss = 0.28 (52.4 examples/sec; 0.153 sec/batch; 12h:28m:05s remains)
INFO - root - 2017-12-01 04:16:51.047269: step 38400, loss = 0.38, batch loss = 0.18 (48.6 examples/sec; 0.165 sec/batch; 13h:26m:28s remains)
INFO - root - 2017-12-01 04:16:52.667035: step 38410, loss = 0.42, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 13h:00m:27s remains)
INFO - root - 2017-12-01 04:16:54.228523: step 38420, loss = 0.50, batch loss = 0.30 (52.2 examples/sec; 0.153 sec/batch; 12h:30m:46s remains)
INFO - root - 2017-12-01 04:16:55.804649: step 38430, loss = 0.44, batch loss = 0.24 (50.8 examples/sec; 0.157 sec/batch; 12h:51m:23s remains)
INFO - root - 2017-12-01 04:16:57.374545: step 38440, loss = 0.43, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 12h:42m:11s remains)
INFO - root - 2017-12-01 04:16:58.940170: step 38450, loss = 0.58, batch loss = 0.37 (50.6 examples/sec; 0.158 sec/batch; 12h:54m:09s remains)
INFO - root - 2017-12-01 04:17:00.507625: step 38460, loss = 0.45, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 12h:49m:33s remains)
INFO - root - 2017-12-01 04:17:02.054524: step 38470, loss = 0.50, batch loss = 0.29 (52.8 examples/sec; 0.151 sec/batch; 12h:22m:22s remains)
INFO - root - 2017-12-01 04:17:03.631384: step 38480, loss = 0.43, batch loss = 0.23 (49.8 examples/sec; 0.161 sec/batch; 13h:07m:51s remains)
INFO - root - 2017-12-01 04:17:05.198777: step 38490, loss = 0.50, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 12h:53m:45s remains)
INFO - root - 2017-12-01 04:17:06.746215: step 38500, loss = 0.49, batch loss = 0.29 (50.6 examples/sec; 0.158 sec/batch; 12h:55m:01s remains)
INFO - root - 2017-12-01 04:17:08.419076: step 38510, loss = 0.52, batch loss = 0.31 (47.9 examples/sec; 0.167 sec/batch; 13h:38m:02s remains)
INFO - root - 2017-12-01 04:17:09.970313: step 38520, loss = 0.40, batch loss = 0.20 (52.5 examples/sec; 0.152 sec/batch; 12h:25m:55s remains)
INFO - root - 2017-12-01 04:17:11.525182: step 38530, loss = 0.58, batch loss = 0.38 (51.0 examples/sec; 0.157 sec/batch; 12h:48m:44s remains)
INFO - root - 2017-12-01 04:17:13.088137: step 38540, loss = 0.53, batch loss = 0.33 (49.0 examples/sec; 0.163 sec/batch; 13h:20m:21s remains)
INFO - root - 2017-12-01 04:17:14.681163: step 38550, loss = 0.42, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 12h:43m:59s remains)
INFO - root - 2017-12-01 04:17:16.245587: step 38560, loss = 0.51, batch loss = 0.31 (49.5 examples/sec; 0.162 sec/batch; 13h:11m:19s remains)
INFO - root - 2017-12-01 04:17:17.797059: step 38570, loss = 0.44, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 12h:28m:21s remains)
INFO - root - 2017-12-01 04:17:19.354063: step 38580, loss = 0.49, batch loss = 0.29 (53.4 examples/sec; 0.150 sec/batch; 12h:14m:31s remains)
INFO - root - 2017-12-01 04:17:20.920602: step 38590, loss = 0.39, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 12h:45m:24s remains)
INFO - root - 2017-12-01 04:17:22.492818: step 38600, loss = 0.47, batch loss = 0.26 (50.8 examples/sec; 0.157 sec/batch; 12h:50m:39s remains)
INFO - root - 2017-12-01 04:17:24.125483: step 38610, loss = 0.42, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 13h:03m:47s remains)
INFO - root - 2017-12-01 04:17:25.688115: step 38620, loss = 0.41, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 12h:42m:38s remains)
INFO - root - 2017-12-01 04:17:27.246620: step 38630, loss = 0.41, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 12h:35m:55s remains)
INFO - root - 2017-12-01 04:17:28.809788: step 38640, loss = 0.45, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 12h:52m:48s remains)
INFO - root - 2017-12-01 04:17:30.369727: step 38650, loss = 0.39, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 12h:46m:54s remains)
INFO - root - 2017-12-01 04:17:31.928046: step 38660, loss = 0.57, batch loss = 0.36 (51.3 examples/sec; 0.156 sec/batch; 12h:43m:36s remains)
INFO - root - 2017-12-01 04:17:33.484406: step 38670, loss = 0.55, batch loss = 0.34 (50.2 examples/sec; 0.159 sec/batch; 12h:59m:55s remains)
INFO - root - 2017-12-01 04:17:35.049644: step 38680, loss = 0.45, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 12h:28m:47s remains)
INFO - root - 2017-12-01 04:17:36.627419: step 38690, loss = 0.42, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 12h:25m:31s remains)
INFO - root - 2017-12-01 04:17:38.197986: step 38700, loss = 0.53, batch loss = 0.32 (50.5 examples/sec; 0.158 sec/batch; 12h:56m:06s remains)
INFO - root - 2017-12-01 04:17:39.826828: step 38710, loss = 0.47, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 12h:54m:17s remains)
INFO - root - 2017-12-01 04:17:41.383786: step 38720, loss = 0.48, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 12h:53m:20s remains)
INFO - root - 2017-12-01 04:17:42.942047: step 38730, loss = 0.53, batch loss = 0.32 (51.1 examples/sec; 0.157 sec/batch; 12h:46m:39s remains)
INFO - root - 2017-12-01 04:17:44.505471: step 38740, loss = 0.41, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 12h:38m:14s remains)
INFO - root - 2017-12-01 04:17:46.071933: step 38750, loss = 0.46, batch loss = 0.26 (48.7 examples/sec; 0.164 sec/batch; 13h:24m:22s remains)
INFO - root - 2017-12-01 04:17:47.653547: step 38760, loss = 0.41, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 12h:36m:16s remains)
INFO - root - 2017-12-01 04:17:49.250987: step 38770, loss = 0.51, batch loss = 0.30 (48.2 examples/sec; 0.166 sec/batch; 13h:32m:34s remains)
INFO - root - 2017-12-01 04:17:50.813994: step 38780, loss = 0.43, batch loss = 0.23 (51.8 examples/sec; 0.155 sec/batch; 12h:36m:36s remains)
INFO - root - 2017-12-01 04:17:52.390248: step 38790, loss = 0.40, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 12h:30m:28s remains)
INFO - root - 2017-12-01 04:17:53.952363: step 38800, loss = 0.43, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 12h:47m:21s remains)
INFO - root - 2017-12-01 04:17:55.584085: step 38810, loss = 0.40, batch loss = 0.19 (48.8 examples/sec; 0.164 sec/batch; 13h:22m:32s remains)
INFO - root - 2017-12-01 04:17:57.148441: step 38820, loss = 0.67, batch loss = 0.47 (53.0 examples/sec; 0.151 sec/batch; 12h:18m:16s remains)
INFO - root - 2017-12-01 04:17:58.728122: step 38830, loss = 0.43, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 12h:52m:25s remains)
INFO - root - 2017-12-01 04:18:00.271967: step 38840, loss = 0.47, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 12h:58m:45s remains)
INFO - root - 2017-12-01 04:18:01.820525: step 38850, loss = 0.42, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 12h:47m:30s remains)
INFO - root - 2017-12-01 04:18:03.379926: step 38860, loss = 0.50, batch loss = 0.30 (51.7 examples/sec; 0.155 sec/batch; 12h:37m:41s remains)
INFO - root - 2017-12-01 04:18:04.955597: step 38870, loss = 0.43, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 12h:43m:23s remains)
INFO - root - 2017-12-01 04:18:06.536141: step 38880, loss = 0.58, batch loss = 0.38 (50.5 examples/sec; 0.158 sec/batch; 12h:55m:34s remains)
INFO - root - 2017-12-01 04:18:08.098073: step 38890, loss = 0.54, batch loss = 0.34 (52.1 examples/sec; 0.154 sec/batch; 12h:31m:32s remains)
INFO - root - 2017-12-01 04:18:09.667999: step 38900, loss = 0.42, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 12h:51m:56s remains)
INFO - root - 2017-12-01 04:18:11.364092: step 38910, loss = 0.50, batch loss = 0.30 (50.5 examples/sec; 0.159 sec/batch; 12h:55m:41s remains)
INFO - root - 2017-12-01 04:18:12.917328: step 38920, loss = 0.54, batch loss = 0.33 (51.7 examples/sec; 0.155 sec/batch; 12h:36m:35s remains)
INFO - root - 2017-12-01 04:18:14.490423: step 38930, loss = 0.40, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 12h:59m:41s remains)
INFO - root - 2017-12-01 04:18:16.074349: step 38940, loss = 0.40, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 12h:52m:51s remains)
INFO - root - 2017-12-01 04:18:17.658574: step 38950, loss = 0.50, batch loss = 0.30 (50.8 examples/sec; 0.157 sec/batch; 12h:49m:48s remains)
INFO - root - 2017-12-01 04:18:19.218873: step 38960, loss = 0.41, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 12h:31m:08s remains)
INFO - root - 2017-12-01 04:18:20.787786: step 38970, loss = 0.43, batch loss = 0.23 (52.1 examples/sec; 0.153 sec/batch; 12h:30m:47s remains)
INFO - root - 2017-12-01 04:18:22.351262: step 38980, loss = 0.43, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 12h:26m:49s remains)
INFO - root - 2017-12-01 04:18:23.924566: step 38990, loss = 0.45, batch loss = 0.25 (50.5 examples/sec; 0.158 sec/batch; 12h:54m:50s remains)
INFO - root - 2017-12-01 04:18:25.499182: step 39000, loss = 0.52, batch loss = 0.32 (50.3 examples/sec; 0.159 sec/batch; 12h:58m:24s remains)
INFO - root - 2017-12-01 04:18:27.135165: step 39010, loss = 0.54, batch loss = 0.34 (50.7 examples/sec; 0.158 sec/batch; 12h:52m:04s remains)
INFO - root - 2017-12-01 04:18:28.694325: step 39020, loss = 0.69, batch loss = 0.49 (49.5 examples/sec; 0.162 sec/batch; 13h:10m:14s remains)
INFO - root - 2017-12-01 04:18:30.269098: step 39030, loss = 0.47, batch loss = 0.27 (49.5 examples/sec; 0.162 sec/batch; 13h:10m:04s remains)
INFO - root - 2017-12-01 04:18:31.824144: step 39040, loss = 0.55, batch loss = 0.35 (48.7 examples/sec; 0.164 sec/batch; 13h:22m:56s remains)
INFO - root - 2017-12-01 04:18:33.390770: step 39050, loss = 0.40, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 12h:46m:58s remains)
INFO - root - 2017-12-01 04:18:34.957274: step 39060, loss = 0.46, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 12h:47m:23s remains)
INFO - root - 2017-12-01 04:18:36.552257: step 39070, loss = 0.45, batch loss = 0.25 (48.0 examples/sec; 0.167 sec/batch; 13h:34m:48s remains)
INFO - root - 2017-12-01 04:18:38.130447: step 39080, loss = 0.40, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 12h:50m:51s remains)
INFO - root - 2017-12-01 04:18:39.691808: step 39090, loss = 0.50, batch loss = 0.29 (49.4 examples/sec; 0.162 sec/batch; 13h:11m:13s remains)
INFO - root - 2017-12-01 04:18:41.259216: step 39100, loss = 0.43, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 12h:38m:37s remains)
INFO - root - 2017-12-01 04:18:42.866912: step 39110, loss = 0.41, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 12h:26m:27s remains)
INFO - root - 2017-12-01 04:18:44.438048: step 39120, loss = 0.56, batch loss = 0.35 (52.7 examples/sec; 0.152 sec/batch; 12h:21m:41s remains)
INFO - root - 2017-12-01 04:18:46.016106: step 39130, loss = 0.49, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 12h:44m:26s remains)
INFO - root - 2017-12-01 04:18:47.572880: step 39140, loss = 0.39, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 12h:41m:19s remains)
INFO - root - 2017-12-01 04:18:49.124606: step 39150, loss = 0.44, batch loss = 0.23 (50.1 examples/sec; 0.160 sec/batch; 13h:00m:23s remains)
INFO - root - 2017-12-01 04:18:50.689672: step 39160, loss = 0.42, batch loss = 0.22 (52.9 examples/sec; 0.151 sec/batch; 12h:19m:50s remains)
INFO - root - 2017-12-01 04:18:52.260326: step 39170, loss = 0.43, batch loss = 0.23 (52.1 examples/sec; 0.153 sec/batch; 12h:30m:10s remains)
INFO - root - 2017-12-01 04:18:53.830813: step 39180, loss = 0.53, batch loss = 0.33 (51.4 examples/sec; 0.156 sec/batch; 12h:40m:29s remains)
INFO - root - 2017-12-01 04:18:55.376454: step 39190, loss = 0.44, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 12h:45m:51s remains)
INFO - root - 2017-12-01 04:18:56.942546: step 39200, loss = 0.41, batch loss = 0.21 (49.7 examples/sec; 0.161 sec/batch; 13h:07m:22s remains)
INFO - root - 2017-12-01 04:18:58.605608: step 39210, loss = 0.55, batch loss = 0.35 (50.8 examples/sec; 0.158 sec/batch; 12h:50m:07s remains)
INFO - root - 2017-12-01 04:19:00.161618: step 39220, loss = 0.45, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 12h:35m:04s remains)
INFO - root - 2017-12-01 04:19:01.733391: step 39230, loss = 0.46, batch loss = 0.26 (53.1 examples/sec; 0.151 sec/batch; 12h:15m:58s remains)
INFO - root - 2017-12-01 04:19:03.325787: step 39240, loss = 0.42, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 12h:35m:02s remains)
INFO - root - 2017-12-01 04:19:04.918425: step 39250, loss = 0.51, batch loss = 0.31 (49.6 examples/sec; 0.161 sec/batch; 13h:09m:01s remains)
INFO - root - 2017-12-01 04:19:06.473785: step 39260, loss = 0.43, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 12h:48m:09s remains)
INFO - root - 2017-12-01 04:19:08.034764: step 39270, loss = 0.43, batch loss = 0.23 (52.5 examples/sec; 0.152 sec/batch; 12h:24m:25s remains)
INFO - root - 2017-12-01 04:19:09.620638: step 39280, loss = 0.46, batch loss = 0.26 (48.4 examples/sec; 0.165 sec/batch; 13h:27m:22s remains)
INFO - root - 2017-12-01 04:19:11.186918: step 39290, loss = 0.44, batch loss = 0.24 (49.6 examples/sec; 0.161 sec/batch; 13h:07m:44s remains)
INFO - root - 2017-12-01 04:19:12.734535: step 39300, loss = 0.40, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 12h:29m:23s remains)
INFO - root - 2017-12-01 04:19:14.409220: step 39310, loss = 0.47, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 12h:56m:45s remains)
INFO - root - 2017-12-01 04:19:15.960924: step 39320, loss = 0.43, batch loss = 0.23 (51.8 examples/sec; 0.155 sec/batch; 12h:34m:58s remains)
INFO - root - 2017-12-01 04:19:17.530897: step 39330, loss = 0.53, batch loss = 0.33 (50.7 examples/sec; 0.158 sec/batch; 12h:50m:36s remains)
INFO - root - 2017-12-01 04:19:19.078248: step 39340, loss = 0.42, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 12h:46m:57s remains)
INFO - root - 2017-12-01 04:19:20.660806: step 39350, loss = 0.47, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 12h:32m:07s remains)
INFO - root - 2017-12-01 04:19:22.222546: step 39360, loss = 0.41, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 12h:48m:24s remains)
INFO - root - 2017-12-01 04:19:23.781699: step 39370, loss = 0.59, batch loss = 0.39 (50.7 examples/sec; 0.158 sec/batch; 12h:51m:19s remains)
INFO - root - 2017-12-01 04:19:25.345474: step 39380, loss = 0.46, batch loss = 0.26 (52.5 examples/sec; 0.152 sec/batch; 12h:24m:13s remains)
INFO - root - 2017-12-01 04:19:26.937066: step 39390, loss = 0.42, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 12h:34m:23s remains)
INFO - root - 2017-12-01 04:19:28.502800: step 39400, loss = 0.52, batch loss = 0.32 (51.6 examples/sec; 0.155 sec/batch; 12h:37m:38s remains)
INFO - root - 2017-12-01 04:19:30.122550: step 39410, loss = 0.49, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 12h:48m:14s remains)
INFO - root - 2017-12-01 04:19:31.699313: step 39420, loss = 0.39, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 12h:34m:13s remains)
INFO - root - 2017-12-01 04:19:33.267745: step 39430, loss = 0.39, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 12h:44m:57s remains)
INFO - root - 2017-12-01 04:19:34.844746: step 39440, loss = 0.41, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 12h:53m:09s remains)
INFO - root - 2017-12-01 04:19:36.389697: step 39450, loss = 0.48, batch loss = 0.28 (52.3 examples/sec; 0.153 sec/batch; 12h:27m:38s remains)
INFO - root - 2017-12-01 04:19:37.968210: step 39460, loss = 0.42, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 12h:53m:03s remains)
INFO - root - 2017-12-01 04:19:39.536670: step 39470, loss = 0.42, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 12h:43m:23s remains)
INFO - root - 2017-12-01 04:19:41.104960: step 39480, loss = 0.36, batch loss = 0.16 (49.8 examples/sec; 0.161 sec/batch; 13h:04m:43s remains)
INFO - root - 2017-12-01 04:19:42.668154: step 39490, loss = 0.42, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 12h:38m:58s remains)
INFO - root - 2017-12-01 04:19:44.220490: step 39500, loss = 0.55, batch loss = 0.35 (51.2 examples/sec; 0.156 sec/batch; 12h:42m:52s remains)
INFO - root - 2017-12-01 04:19:45.840800: step 39510, loss = 0.48, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 12h:51m:16s remains)
INFO - root - 2017-12-01 04:19:47.389512: step 39520, loss = 0.42, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 12h:44m:38s remains)
INFO - root - 2017-12-01 04:19:48.959109: step 39530, loss = 0.43, batch loss = 0.23 (48.3 examples/sec; 0.166 sec/batch; 13h:28m:50s remains)
INFO - root - 2017-12-01 04:19:50.520399: step 39540, loss = 0.44, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 12h:33m:14s remains)
INFO - root - 2017-12-01 04:19:52.103097: step 39550, loss = 0.49, batch loss = 0.29 (51.7 examples/sec; 0.155 sec/batch; 12h:35m:24s remains)
INFO - root - 2017-12-01 04:19:53.662634: step 39560, loss = 0.37, batch loss = 0.17 (49.2 examples/sec; 0.163 sec/batch; 13h:14m:02s remains)
INFO - root - 2017-12-01 04:19:55.231034: step 39570, loss = 0.46, batch loss = 0.26 (48.7 examples/sec; 0.164 sec/batch; 13h:22m:33s remains)
INFO - root - 2017-12-01 04:19:56.784525: step 39580, loss = 0.68, batch loss = 0.48 (52.3 examples/sec; 0.153 sec/batch; 12h:26m:29s remains)
INFO - root - 2017-12-01 04:19:58.352498: step 39590, loss = 0.42, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 12h:24m:08s remains)
INFO - root - 2017-12-01 04:19:59.925119: step 39600, loss = 0.61, batch loss = 0.41 (52.2 examples/sec; 0.153 sec/batch; 12h:28m:44s remains)
INFO - root - 2017-12-01 04:20:01.522278: step 39610, loss = 0.49, batch loss = 0.29 (51.4 examples/sec; 0.156 sec/batch; 12h:39m:46s remains)
INFO - root - 2017-12-01 04:20:03.057844: step 39620, loss = 0.53, batch loss = 0.33 (52.3 examples/sec; 0.153 sec/batch; 12h:26m:17s remains)
INFO - root - 2017-12-01 04:20:04.620713: step 39630, loss = 0.38, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 12h:32m:41s remains)
INFO - root - 2017-12-01 04:20:06.176211: step 39640, loss = 0.39, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 12h:35m:22s remains)
INFO - root - 2017-12-01 04:20:07.752707: step 39650, loss = 0.37, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 12h:42m:33s remains)
INFO - root - 2017-12-01 04:20:09.325336: step 39660, loss = 0.50, batch loss = 0.30 (50.5 examples/sec; 0.158 sec/batch; 12h:52m:59s remains)
INFO - root - 2017-12-01 04:20:10.879185: step 39670, loss = 0.47, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 12h:36m:17s remains)
INFO - root - 2017-12-01 04:20:12.447091: step 39680, loss = 0.62, batch loss = 0.42 (52.3 examples/sec; 0.153 sec/batch; 12h:26m:21s remains)
INFO - root - 2017-12-01 04:20:14.027318: step 39690, loss = 0.39, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 13h:02m:25s remains)
INFO - root - 2017-12-01 04:20:15.613308: step 39700, loss = 0.45, batch loss = 0.25 (50.2 examples/sec; 0.159 sec/batch; 12h:58m:21s remains)
INFO - root - 2017-12-01 04:20:17.218428: step 39710, loss = 0.71, batch loss = 0.51 (52.5 examples/sec; 0.152 sec/batch; 12h:23m:36s remains)
INFO - root - 2017-12-01 04:20:18.777941: step 39720, loss = 0.66, batch loss = 0.46 (50.7 examples/sec; 0.158 sec/batch; 12h:49m:24s remains)
INFO - root - 2017-12-01 04:20:20.343043: step 39730, loss = 0.51, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 12h:44m:49s remains)
INFO - root - 2017-12-01 04:20:21.909804: step 39740, loss = 0.37, batch loss = 0.17 (50.2 examples/sec; 0.159 sec/batch; 12h:57m:19s remains)
INFO - root - 2017-12-01 04:20:23.472496: step 39750, loss = 0.45, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 12h:36m:03s remains)
INFO - root - 2017-12-01 04:20:25.040951: step 39760, loss = 0.49, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 12h:32m:11s remains)
INFO - root - 2017-12-01 04:20:26.620484: step 39770, loss = 0.42, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 12h:47m:29s remains)
INFO - root - 2017-12-01 04:20:28.185112: step 39780, loss = 0.46, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 12h:39m:27s remains)
INFO - root - 2017-12-01 04:20:29.752361: step 39790, loss = 0.41, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 12h:41m:42s remains)
INFO - root - 2017-12-01 04:20:31.302270: step 39800, loss = 0.46, batch loss = 0.26 (52.3 examples/sec; 0.153 sec/batch; 12h:26m:14s remains)
INFO - root - 2017-12-01 04:20:32.941955: step 39810, loss = 0.64, batch loss = 0.44 (50.8 examples/sec; 0.157 sec/batch; 12h:48m:15s remains)
INFO - root - 2017-12-01 04:20:34.521706: step 39820, loss = 0.36, batch loss = 0.16 (48.3 examples/sec; 0.166 sec/batch; 13h:28m:19s remains)
INFO - root - 2017-12-01 04:20:36.083012: step 39830, loss = 0.39, batch loss = 0.19 (53.1 examples/sec; 0.151 sec/batch; 12h:15m:11s remains)
INFO - root - 2017-12-01 04:20:37.647923: step 39840, loss = 0.51, batch loss = 0.31 (52.7 examples/sec; 0.152 sec/batch; 12h:20m:09s remains)
INFO - root - 2017-12-01 04:20:39.239119: step 39850, loss = 0.38, batch loss = 0.18 (48.9 examples/sec; 0.164 sec/batch; 13h:18m:06s remains)
INFO - root - 2017-12-01 04:20:40.805504: step 39860, loss = 0.42, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 12h:59m:28s remains)
INFO - root - 2017-12-01 04:20:42.373808: step 39870, loss = 0.44, batch loss = 0.24 (53.3 examples/sec; 0.150 sec/batch; 12h:12m:10s remains)
INFO - root - 2017-12-01 04:20:43.959115: step 39880, loss = 0.43, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 12h:40m:27s remains)
INFO - root - 2017-12-01 04:20:45.548175: step 39890, loss = 0.39, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 12h:34m:23s remains)
INFO - root - 2017-12-01 04:20:47.103467: step 39900, loss = 0.42, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 12h:26m:46s remains)
INFO - root - 2017-12-01 04:20:48.725555: step 39910, loss = 0.48, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 12h:44m:15s remains)
INFO - root - 2017-12-01 04:20:50.300093: step 39920, loss = 0.47, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 12h:55m:38s remains)
INFO - root - 2017-12-01 04:20:51.859175: step 39930, loss = 0.40, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 12h:37m:45s remains)
INFO - root - 2017-12-01 04:20:53.416999: step 39940, loss = 0.62, batch loss = 0.42 (51.2 examples/sec; 0.156 sec/batch; 12h:42m:26s remains)
INFO - root - 2017-12-01 04:20:54.980320: step 39950, loss = 0.45, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 12h:36m:07s remains)
INFO - root - 2017-12-01 04:20:56.571793: step 39960, loss = 0.47, batch loss = 0.27 (49.8 examples/sec; 0.161 sec/batch; 13h:02m:44s remains)
INFO - root - 2017-12-01 04:20:58.123513: step 39970, loss = 0.46, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 12h:36m:53s remains)
INFO - root - 2017-12-01 04:20:59.680597: step 39980, loss = 0.44, batch loss = 0.24 (52.8 examples/sec; 0.152 sec/batch; 12h:19m:11s remains)
INFO - root - 2017-12-01 04:21:01.248277: step 39990, loss = 0.47, batch loss = 0.27 (52.5 examples/sec; 0.152 sec/batch; 12h:23m:27s remains)
INFO - root - 2017-12-01 04:21:02.817005: step 40000, loss = 0.47, batch loss = 0.28 (52.1 examples/sec; 0.153 sec/batch; 12h:27m:54s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-40000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-40000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-01 04:21:04.871597: step 40010, loss = 0.42, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 12h:50m:09s remains)
INFO - root - 2017-12-01 04:21:06.433317: step 40020, loss = 0.44, batch loss = 0.24 (49.0 examples/sec; 0.163 sec/batch; 13h:16m:17s remains)
INFO - root - 2017-12-01 04:21:08.018916: step 40030, loss = 0.47, batch loss = 0.27 (49.7 examples/sec; 0.161 sec/batch; 13h:04m:02s remains)
INFO - root - 2017-12-01 04:21:09.612650: step 40040, loss = 0.55, batch loss = 0.35 (50.8 examples/sec; 0.158 sec/batch; 12h:48m:16s remains)
INFO - root - 2017-12-01 04:21:11.190444: step 40050, loss = 0.44, batch loss = 0.24 (47.6 examples/sec; 0.168 sec/batch; 13h:38m:46s remains)
INFO - root - 2017-12-01 04:21:12.746004: step 40060, loss = 0.44, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 12h:55m:55s remains)
INFO - root - 2017-12-01 04:21:14.310325: step 40070, loss = 0.48, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 12h:45m:10s remains)
INFO - root - 2017-12-01 04:21:15.927944: step 40080, loss = 0.51, batch loss = 0.31 (50.4 examples/sec; 0.159 sec/batch; 12h:53m:18s remains)
INFO - root - 2017-12-01 04:21:17.485746: step 40090, loss = 0.39, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 12h:50m:45s remains)
INFO - root - 2017-12-01 04:21:19.047424: step 40100, loss = 0.49, batch loss = 0.29 (52.5 examples/sec; 0.152 sec/batch; 12h:22m:02s remains)
INFO - root - 2017-12-01 04:21:20.756474: step 40110, loss = 0.40, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 12h:21m:52s remains)
INFO - root - 2017-12-01 04:21:22.323261: step 40120, loss = 0.42, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 12h:35m:30s remains)
INFO - root - 2017-12-01 04:21:23.902228: step 40130, loss = 0.38, batch loss = 0.19 (50.2 examples/sec; 0.160 sec/batch; 12h:57m:19s remains)
INFO - root - 2017-12-01 04:21:25.471063: step 40140, loss = 0.50, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 12h:37m:27s remains)
INFO - root - 2017-12-01 04:21:27.042194: step 40150, loss = 0.44, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 12h:50m:51s remains)
INFO - root - 2017-12-01 04:21:28.592598: step 40160, loss = 0.39, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 12h:25m:14s remains)
INFO - root - 2017-12-01 04:21:30.164427: step 40170, loss = 0.42, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 12h:21m:15s remains)
INFO - root - 2017-12-01 04:21:31.741106: step 40180, loss = 0.40, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 12h:35m:06s remains)
INFO - root - 2017-12-01 04:21:33.306291: step 40190, loss = 0.45, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 12h:36m:57s remains)
INFO - root - 2017-12-01 04:21:34.873062: step 40200, loss = 0.36, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 12h:33m:37s remains)
INFO - root - 2017-12-01 04:21:36.478932: step 40210, loss = 0.46, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 12h:19m:22s remains)
INFO - root - 2017-12-01 04:21:38.017183: step 40220, loss = 0.44, batch loss = 0.24 (52.9 examples/sec; 0.151 sec/batch; 12h:17m:12s remains)
INFO - root - 2017-12-01 04:21:39.580603: step 40230, loss = 0.44, batch loss = 0.24 (50.2 examples/sec; 0.159 sec/batch; 12h:55m:56s remains)
INFO - root - 2017-12-01 04:21:41.133470: step 40240, loss = 0.43, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 12h:44m:50s remains)
INFO - root - 2017-12-01 04:21:42.682188: step 40250, loss = 0.38, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 12h:42m:23s remains)
INFO - root - 2017-12-01 04:21:44.248455: step 40260, loss = 0.48, batch loss = 0.28 (50.8 examples/sec; 0.158 sec/batch; 12h:47m:46s remains)
INFO - root - 2017-12-01 04:21:45.835619: step 40270, loss = 0.42, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 12h:29m:55s remains)
INFO - root - 2017-12-01 04:21:47.397816: step 40280, loss = 0.44, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 12h:43m:08s remains)
INFO - root - 2017-12-01 04:21:48.956135: step 40290, loss = 0.56, batch loss = 0.36 (48.8 examples/sec; 0.164 sec/batch; 13h:18m:03s remains)
INFO - root - 2017-12-01 04:21:50.528767: step 40300, loss = 0.51, batch loss = 0.31 (53.1 examples/sec; 0.151 sec/batch; 12h:13m:23s remains)
INFO - root - 2017-12-01 04:21:52.183039: step 40310, loss = 0.47, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 12h:45m:49s remains)
INFO - root - 2017-12-01 04:21:53.736020: step 40320, loss = 0.45, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 12h:42m:10s remains)
INFO - root - 2017-12-01 04:21:55.302821: step 40330, loss = 0.53, batch loss = 0.33 (49.0 examples/sec; 0.163 sec/batch; 13h:14m:13s remains)
INFO - root - 2017-12-01 04:21:56.897021: step 40340, loss = 0.37, batch loss = 0.17 (50.8 examples/sec; 0.157 sec/batch; 12h:46m:43s remains)
INFO - root - 2017-12-01 04:21:58.461343: step 40350, loss = 0.40, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 12h:54m:20s remains)
INFO - root - 2017-12-01 04:22:00.048523: step 40360, loss = 0.45, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 12h:30m:01s remains)
INFO - root - 2017-12-01 04:22:01.606239: step 40370, loss = 0.41, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 12h:31m:41s remains)
INFO - root - 2017-12-01 04:22:03.170063: step 40380, loss = 0.49, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 12h:35m:02s remains)
INFO - root - 2017-12-01 04:22:04.736015: step 40390, loss = 0.41, batch loss = 0.21 (51.1 examples/sec; 0.156 sec/batch; 12h:41m:41s remains)
INFO - root - 2017-12-01 04:22:06.279952: step 40400, loss = 0.50, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 12h:44m:38s remains)
INFO - root - 2017-12-01 04:22:07.886868: step 40410, loss = 0.40, batch loss = 0.20 (53.6 examples/sec; 0.149 sec/batch; 12h:06m:52s remains)
INFO - root - 2017-12-01 04:22:09.477558: step 40420, loss = 0.47, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 12h:28m:24s remains)
INFO - root - 2017-12-01 04:22:11.051469: step 40430, loss = 0.48, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 12h:45m:38s remains)
INFO - root - 2017-12-01 04:22:12.624331: step 40440, loss = 0.39, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 12h:26m:42s remains)
INFO - root - 2017-12-01 04:22:14.216503: step 40450, loss = 0.49, batch loss = 0.29 (51.8 examples/sec; 0.154 sec/batch; 12h:31m:56s remains)
INFO - root - 2017-12-01 04:22:15.778005: step 40460, loss = 0.51, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 12h:40m:57s remains)
INFO - root - 2017-12-01 04:22:17.333397: step 40470, loss = 0.41, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 12h:56m:57s remains)
INFO - root - 2017-12-01 04:22:18.898133: step 40480, loss = 0.40, batch loss = 0.20 (50.5 examples/sec; 0.159 sec/batch; 12h:51m:46s remains)
INFO - root - 2017-12-01 04:22:20.476256: step 40490, loss = 0.53, batch loss = 0.33 (51.2 examples/sec; 0.156 sec/batch; 12h:39m:47s remains)
INFO - root - 2017-12-01 04:22:22.042944: step 40500, loss = 0.40, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 12h:43m:26s remains)
INFO - root - 2017-12-01 04:22:23.691713: step 40510, loss = 0.38, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 12h:48m:05s remains)
INFO - root - 2017-12-01 04:22:25.292259: step 40520, loss = 0.45, batch loss = 0.25 (50.1 examples/sec; 0.160 sec/batch; 12h:57m:34s remains)
INFO - root - 2017-12-01 04:22:26.845037: step 40530, loss = 0.52, batch loss = 0.32 (50.1 examples/sec; 0.160 sec/batch; 12h:56m:30s remains)
INFO - root - 2017-12-01 04:22:28.403087: step 40540, loss = 0.46, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 12h:52m:46s remains)
INFO - root - 2017-12-01 04:22:29.956147: step 40550, loss = 0.41, batch loss = 0.21 (52.7 examples/sec; 0.152 sec/batch; 12h:19m:05s remains)
INFO - root - 2017-12-01 04:22:31.547431: step 40560, loss = 0.42, batch loss = 0.22 (52.7 examples/sec; 0.152 sec/batch; 12h:18m:00s remains)
INFO - root - 2017-12-01 04:22:33.106968: step 40570, loss = 0.39, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 12h:38m:00s remains)
INFO - root - 2017-12-01 04:22:34.667392: step 40580, loss = 0.45, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 12h:43m:44s remains)
INFO - root - 2017-12-01 04:22:36.248268: step 40590, loss = 0.45, batch loss = 0.25 (49.9 examples/sec; 0.160 sec/batch; 13h:00m:09s remains)
INFO - root - 2017-12-01 04:22:37.826154: step 40600, loss = 0.44, batch loss = 0.24 (53.3 examples/sec; 0.150 sec/batch; 12h:10m:37s remains)
INFO - root - 2017-12-01 04:22:39.433528: step 40610, loss = 0.49, batch loss = 0.29 (51.0 examples/sec; 0.157 sec/batch; 12h:43m:37s remains)
INFO - root - 2017-12-01 04:22:40.995590: step 40620, loss = 0.40, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 12h:40m:22s remains)
INFO - root - 2017-12-01 04:22:42.552708: step 40630, loss = 0.45, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 12h:36m:29s remains)
INFO - root - 2017-12-01 04:22:44.125453: step 40640, loss = 0.47, batch loss = 0.27 (52.4 examples/sec; 0.153 sec/batch; 12h:22m:07s remains)
INFO - root - 2017-12-01 04:22:45.705557: step 40650, loss = 0.38, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 12h:53m:15s remains)
INFO - root - 2017-12-01 04:22:47.266654: step 40660, loss = 0.46, batch loss = 0.26 (49.6 examples/sec; 0.161 sec/batch; 13h:04m:36s remains)
INFO - root - 2017-12-01 04:22:48.812254: step 40670, loss = 0.63, batch loss = 0.43 (50.2 examples/sec; 0.159 sec/batch; 12h:55m:02s remains)
INFO - root - 2017-12-01 04:22:50.386905: step 40680, loss = 0.56, batch loss = 0.36 (53.8 examples/sec; 0.149 sec/batch; 12h:03m:42s remains)
INFO - root - 2017-12-01 04:22:51.976966: step 40690, loss = 0.43, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 12h:20m:03s remains)
INFO - root - 2017-12-01 04:22:53.542842: step 40700, loss = 0.54, batch loss = 0.34 (50.7 examples/sec; 0.158 sec/batch; 12h:47m:44s remains)
INFO - root - 2017-12-01 04:22:55.192784: step 40710, loss = 0.54, batch loss = 0.34 (50.8 examples/sec; 0.158 sec/batch; 12h:46m:02s remains)
INFO - root - 2017-12-01 04:22:56.761331: step 40720, loss = 0.39, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 12h:47m:54s remains)
INFO - root - 2017-12-01 04:22:58.323422: step 40730, loss = 0.43, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 12h:43m:43s remains)
INFO - root - 2017-12-01 04:22:59.887395: step 40740, loss = 0.43, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 12h:25m:00s remains)
INFO - root - 2017-12-01 04:23:01.455019: step 40750, loss = 0.43, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 12h:35m:31s remains)
INFO - root - 2017-12-01 04:23:03.014185: step 40760, loss = 0.58, batch loss = 0.39 (52.2 examples/sec; 0.153 sec/batch; 12h:25m:50s remains)
INFO - root - 2017-12-01 04:23:04.565339: step 40770, loss = 0.41, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 12h:53m:54s remains)
INFO - root - 2017-12-01 04:23:06.122565: step 40780, loss = 0.60, batch loss = 0.41 (50.4 examples/sec; 0.159 sec/batch; 12h:51m:01s remains)
INFO - root - 2017-12-01 04:23:07.687464: step 40790, loss = 0.40, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 12h:22m:20s remains)
INFO - root - 2017-12-01 04:23:09.251198: step 40800, loss = 0.67, batch loss = 0.48 (53.5 examples/sec; 0.149 sec/batch; 12h:06m:30s remains)
INFO - root - 2017-12-01 04:23:10.901039: step 40810, loss = 0.48, batch loss = 0.28 (50.8 examples/sec; 0.157 sec/batch; 12h:45m:35s remains)
INFO - root - 2017-12-01 04:23:12.449125: step 40820, loss = 0.43, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 12h:22m:26s remains)
INFO - root - 2017-12-01 04:23:14.010305: step 40830, loss = 0.45, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 12h:38m:59s remains)
INFO - root - 2017-12-01 04:23:15.574655: step 40840, loss = 0.54, batch loss = 0.34 (52.0 examples/sec; 0.154 sec/batch; 12h:27m:22s remains)
INFO - root - 2017-12-01 04:23:17.135156: step 40850, loss = 0.40, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 12h:49m:51s remains)
INFO - root - 2017-12-01 04:23:18.696196: step 40860, loss = 0.45, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 12h:39m:44s remains)
INFO - root - 2017-12-01 04:23:20.262026: step 40870, loss = 0.47, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 12h:42m:56s remains)
INFO - root - 2017-12-01 04:23:21.832613: step 40880, loss = 0.47, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 12h:29m:28s remains)
INFO - root - 2017-12-01 04:23:23.401230: step 40890, loss = 0.42, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 12h:26m:04s remains)
INFO - root - 2017-12-01 04:23:24.991915: step 40900, loss = 0.42, batch loss = 0.22 (48.3 examples/sec; 0.166 sec/batch; 13h:24m:40s remains)
INFO - root - 2017-12-01 04:23:26.633773: step 40910, loss = 0.45, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 12h:20m:24s remains)
INFO - root - 2017-12-01 04:23:28.192400: step 40920, loss = 0.51, batch loss = 0.31 (51.7 examples/sec; 0.155 sec/batch; 12h:31m:40s remains)
INFO - root - 2017-12-01 04:23:29.761238: step 40930, loss = 0.42, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 12h:44m:30s remains)
INFO - root - 2017-12-01 04:23:31.317870: step 40940, loss = 0.47, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 12h:40m:35s remains)
INFO - root - 2017-12-01 04:23:32.886374: step 40950, loss = 0.42, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 12h:24m:46s remains)
INFO - root - 2017-12-01 04:23:34.439354: step 40960, loss = 0.46, batch loss = 0.26 (52.4 examples/sec; 0.153 sec/batch; 12h:22m:14s remains)
INFO - root - 2017-12-01 04:23:36.029288: step 40970, loss = 0.44, batch loss = 0.24 (49.4 examples/sec; 0.162 sec/batch; 13h:07m:34s remains)
INFO - root - 2017-12-01 04:23:37.578058: step 40980, loss = 0.42, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 12h:21m:44s remains)
INFO - root - 2017-12-01 04:23:39.145548: step 40990, loss = 0.47, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 12h:36m:00s remains)
INFO - root - 2017-12-01 04:23:40.719376: step 41000, loss = 0.39, batch loss = 0.19 (49.2 examples/sec; 0.162 sec/batch; 13h:09m:13s remains)
INFO - root - 2017-12-01 04:23:42.390225: step 41010, loss = 0.41, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 12h:42m:36s remains)
INFO - root - 2017-12-01 04:23:43.984057: step 41020, loss = 0.41, batch loss = 0.21 (49.8 examples/sec; 0.161 sec/batch; 13h:01m:04s remains)
INFO - root - 2017-12-01 04:23:45.575557: step 41030, loss = 0.55, batch loss = 0.35 (50.4 examples/sec; 0.159 sec/batch; 12h:50m:52s remains)
INFO - root - 2017-12-01 04:23:47.121300: step 41040, loss = 0.50, batch loss = 0.30 (49.7 examples/sec; 0.161 sec/batch; 13h:01m:40s remains)
INFO - root - 2017-12-01 04:23:48.692299: step 41050, loss = 0.43, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 12h:43m:40s remains)
INFO - root - 2017-12-01 04:23:50.285470: step 41060, loss = 0.49, batch loss = 0.30 (51.6 examples/sec; 0.155 sec/batch; 12h:33m:30s remains)
INFO - root - 2017-12-01 04:23:51.838473: step 41070, loss = 0.42, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 12h:27m:53s remains)
INFO - root - 2017-12-01 04:23:53.394563: step 41080, loss = 0.75, batch loss = 0.55 (50.1 examples/sec; 0.160 sec/batch; 12h:56m:06s remains)
INFO - root - 2017-12-01 04:23:54.957000: step 41090, loss = 0.42, batch loss = 0.22 (49.1 examples/sec; 0.163 sec/batch; 13h:11m:24s remains)
INFO - root - 2017-12-01 04:23:56.535163: step 41100, loss = 0.36, batch loss = 0.16 (50.8 examples/sec; 0.157 sec/batch; 12h:44m:38s remains)
INFO - root - 2017-12-01 04:23:58.163215: step 41110, loss = 0.38, batch loss = 0.18 (49.8 examples/sec; 0.161 sec/batch; 13h:00m:17s remains)
INFO - root - 2017-12-01 04:23:59.744186: step 41120, loss = 0.44, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 12h:45m:50s remains)
INFO - root - 2017-12-01 04:24:01.313437: step 41130, loss = 0.54, batch loss = 0.34 (51.9 examples/sec; 0.154 sec/batch; 12h:28m:32s remains)
INFO - root - 2017-12-01 04:24:02.879558: step 41140, loss = 0.37, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 12h:51m:52s remains)
INFO - root - 2017-12-01 04:24:04.451217: step 41150, loss = 0.48, batch loss = 0.28 (50.5 examples/sec; 0.159 sec/batch; 12h:49m:41s remains)
INFO - root - 2017-12-01 04:24:06.024835: step 41160, loss = 0.44, batch loss = 0.25 (52.7 examples/sec; 0.152 sec/batch; 12h:17m:42s remains)
INFO - root - 2017-12-01 04:24:07.589983: step 41170, loss = 0.49, batch loss = 0.29 (52.2 examples/sec; 0.153 sec/batch; 12h:23m:41s remains)
INFO - root - 2017-12-01 04:24:09.160114: step 41180, loss = 0.39, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 12h:52m:26s remains)
INFO - root - 2017-12-01 04:24:10.754073: step 41190, loss = 0.45, batch loss = 0.26 (47.5 examples/sec; 0.169 sec/batch; 13h:38m:31s remains)
INFO - root - 2017-12-01 04:24:12.308572: step 41200, loss = 0.45, batch loss = 0.25 (53.3 examples/sec; 0.150 sec/batch; 12h:08m:07s remains)
INFO - root - 2017-12-01 04:24:13.936473: step 41210, loss = 0.44, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 12h:38m:28s remains)
INFO - root - 2017-12-01 04:24:15.493933: step 41220, loss = 0.44, batch loss = 0.24 (49.3 examples/sec; 0.162 sec/batch; 13h:07m:28s remains)
INFO - root - 2017-12-01 04:24:17.052983: step 41230, loss = 0.39, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 12h:31m:42s remains)
INFO - root - 2017-12-01 04:24:18.590075: step 41240, loss = 0.39, batch loss = 0.19 (53.2 examples/sec; 0.150 sec/batch; 12h:10m:16s remains)
INFO - root - 2017-12-01 04:24:20.154588: step 41250, loss = 0.42, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 12h:23m:22s remains)
INFO - root - 2017-12-01 04:24:21.735722: step 41260, loss = 0.39, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 12h:26m:21s remains)
INFO - root - 2017-12-01 04:24:23.289725: step 41270, loss = 0.37, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 12h:35m:48s remains)
INFO - root - 2017-12-01 04:24:24.852989: step 41280, loss = 0.43, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 12h:40m:13s remains)
INFO - root - 2017-12-01 04:24:26.427659: step 41290, loss = 0.51, batch loss = 0.31 (53.7 examples/sec; 0.149 sec/batch; 12h:03m:18s remains)
INFO - root - 2017-12-01 04:24:28.004115: step 41300, loss = 0.67, batch loss = 0.47 (50.8 examples/sec; 0.157 sec/batch; 12h:43m:35s remains)
INFO - root - 2017-12-01 04:24:29.676428: step 41310, loss = 0.49, batch loss = 0.30 (50.8 examples/sec; 0.157 sec/batch; 12h:44m:05s remains)
INFO - root - 2017-12-01 04:24:31.225998: step 41320, loss = 0.37, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 12h:24m:20s remains)
INFO - root - 2017-12-01 04:24:32.785926: step 41330, loss = 0.47, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 12h:40m:07s remains)
INFO - root - 2017-12-01 04:24:34.348269: step 41340, loss = 0.52, batch loss = 0.32 (50.5 examples/sec; 0.159 sec/batch; 12h:49m:26s remains)
INFO - root - 2017-12-01 04:24:35.903735: step 41350, loss = 0.38, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 12h:36m:41s remains)
INFO - root - 2017-12-01 04:24:37.470431: step 41360, loss = 0.44, batch loss = 0.25 (52.7 examples/sec; 0.152 sec/batch; 12h:16m:01s remains)
INFO - root - 2017-12-01 04:24:39.043077: step 41370, loss = 0.45, batch loss = 0.26 (49.7 examples/sec; 0.161 sec/batch; 13h:01m:27s remains)
INFO - root - 2017-12-01 04:24:40.628517: step 41380, loss = 0.58, batch loss = 0.38 (51.0 examples/sec; 0.157 sec/batch; 12h:41m:39s remains)
INFO - root - 2017-12-01 04:24:42.206387: step 41390, loss = 0.49, batch loss = 0.29 (48.3 examples/sec; 0.166 sec/batch; 13h:24m:03s remains)
INFO - root - 2017-12-01 04:24:43.777384: step 41400, loss = 0.42, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 12h:35m:45s remains)
INFO - root - 2017-12-01 04:24:45.402315: step 41410, loss = 0.42, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 12h:25m:39s remains)
INFO - root - 2017-12-01 04:24:46.941697: step 41420, loss = 0.40, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 12h:33m:18s remains)
INFO - root - 2017-12-01 04:24:48.515686: step 41430, loss = 0.50, batch loss = 0.31 (51.3 examples/sec; 0.156 sec/batch; 12h:36m:23s remains)
INFO - root - 2017-12-01 04:24:50.080860: step 41440, loss = 0.48, batch loss = 0.28 (50.2 examples/sec; 0.159 sec/batch; 12h:52m:21s remains)
INFO - root - 2017-12-01 04:24:51.650707: step 41450, loss = 0.46, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 12h:48m:05s remains)
INFO - root - 2017-12-01 04:24:53.210283: step 41460, loss = 0.37, batch loss = 0.17 (51.1 examples/sec; 0.156 sec/batch; 12h:39m:01s remains)
INFO - root - 2017-12-01 04:24:54.759509: step 41470, loss = 0.40, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 12h:31m:56s remains)
INFO - root - 2017-12-01 04:24:56.327788: step 41480, loss = 0.64, batch loss = 0.45 (51.8 examples/sec; 0.154 sec/batch; 12h:29m:16s remains)
INFO - root - 2017-12-01 04:24:57.886380: step 41490, loss = 0.45, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 12h:15m:43s remains)
INFO - root - 2017-12-01 04:24:59.441887: step 41500, loss = 0.38, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 12h:30m:43s remains)
INFO - root - 2017-12-01 04:25:01.043907: step 41510, loss = 0.48, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 12h:46m:45s remains)
INFO - root - 2017-12-01 04:25:02.610616: step 41520, loss = 0.42, batch loss = 0.23 (49.5 examples/sec; 0.162 sec/batch; 13h:03m:54s remains)
INFO - root - 2017-12-01 04:25:04.227141: step 41530, loss = 0.38, batch loss = 0.18 (52.4 examples/sec; 0.153 sec/batch; 12h:20m:42s remains)
INFO - root - 2017-12-01 04:25:05.766557: step 41540, loss = 0.42, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 12h:27m:42s remains)
INFO - root - 2017-12-01 04:25:07.338481: step 41550, loss = 0.53, batch loss = 0.34 (47.6 examples/sec; 0.168 sec/batch; 13h:35m:37s remains)
INFO - root - 2017-12-01 04:25:08.896986: step 41560, loss = 0.53, batch loss = 0.33 (51.1 examples/sec; 0.157 sec/batch; 12h:39m:33s remains)
INFO - root - 2017-12-01 04:25:10.471145: step 41570, loss = 0.53, batch loss = 0.33 (51.6 examples/sec; 0.155 sec/batch; 12h:32m:11s remains)
INFO - root - 2017-12-01 04:25:12.065844: step 41580, loss = 0.51, batch loss = 0.31 (51.1 examples/sec; 0.156 sec/batch; 12h:38m:42s remains)
INFO - root - 2017-12-01 04:25:13.631176: step 41590, loss = 0.61, batch loss = 0.41 (50.0 examples/sec; 0.160 sec/batch; 12h:55m:58s remains)
INFO - root - 2017-12-01 04:25:15.197454: step 41600, loss = 0.60, batch loss = 0.41 (52.3 examples/sec; 0.153 sec/batch; 12h:21m:16s remains)
INFO - root - 2017-12-01 04:25:16.833594: step 41610, loss = 0.50, batch loss = 0.30 (49.8 examples/sec; 0.161 sec/batch; 12h:58m:48s remains)
INFO - root - 2017-12-01 04:25:18.397142: step 41620, loss = 0.40, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 12h:30m:51s remains)
INFO - root - 2017-12-01 04:25:19.958426: step 41630, loss = 0.44, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 12h:44m:15s remains)
INFO - root - 2017-12-01 04:25:21.542823: step 41640, loss = 0.36, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 12h:32m:17s remains)
INFO - root - 2017-12-01 04:25:23.101960: step 41650, loss = 0.41, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 12h:31m:54s remains)
INFO - root - 2017-12-01 04:25:24.643556: step 41660, loss = 0.52, batch loss = 0.33 (51.0 examples/sec; 0.157 sec/batch; 12h:40m:01s remains)
INFO - root - 2017-12-01 04:25:26.191436: step 41670, loss = 0.40, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 12h:33m:45s remains)
INFO - root - 2017-12-01 04:25:27.738453: step 41680, loss = 0.56, batch loss = 0.36 (52.2 examples/sec; 0.153 sec/batch; 12h:23m:23s remains)
INFO - root - 2017-12-01 04:25:29.313543: step 41690, loss = 0.44, batch loss = 0.25 (52.9 examples/sec; 0.151 sec/batch; 12h:13m:34s remains)
INFO - root - 2017-12-01 04:25:30.870403: step 41700, loss = 0.60, batch loss = 0.40 (51.9 examples/sec; 0.154 sec/batch; 12h:27m:25s remains)
INFO - root - 2017-12-01 04:25:32.485587: step 41710, loss = 0.45, batch loss = 0.25 (49.0 examples/sec; 0.163 sec/batch; 13h:11m:04s remains)
INFO - root - 2017-12-01 04:25:34.041146: step 41720, loss = 0.40, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 12h:17m:36s remains)
INFO - root - 2017-12-01 04:25:35.616539: step 41730, loss = 0.43, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 12h:27m:48s remains)
INFO - root - 2017-12-01 04:25:37.189793: step 41740, loss = 0.37, batch loss = 0.18 (52.1 examples/sec; 0.154 sec/batch; 12h:23m:54s remains)
INFO - root - 2017-12-01 04:25:38.750734: step 41750, loss = 0.48, batch loss = 0.29 (51.1 examples/sec; 0.157 sec/batch; 12h:38m:51s remains)
INFO - root - 2017-12-01 04:25:40.312896: step 41760, loss = 0.46, batch loss = 0.27 (49.6 examples/sec; 0.161 sec/batch; 13h:00m:57s remains)
INFO - root - 2017-12-01 04:25:41.881763: step 41770, loss = 0.47, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 12h:42m:08s remains)
INFO - root - 2017-12-01 04:25:43.455742: step 41780, loss = 0.39, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 12h:47m:47s remains)
INFO - root - 2017-12-01 04:25:45.029190: step 41790, loss = 0.37, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 12h:38m:42s remains)
INFO - root - 2017-12-01 04:25:46.578162: step 41800, loss = 0.38, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 12h:38m:46s remains)
INFO - root - 2017-12-01 04:25:48.185433: step 41810, loss = 0.43, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 12h:19m:23s remains)
INFO - root - 2017-12-01 04:25:49.768825: step 41820, loss = 0.42, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 12h:25m:26s remains)
INFO - root - 2017-12-01 04:25:51.334301: step 41830, loss = 0.42, batch loss = 0.23 (50.4 examples/sec; 0.159 sec/batch; 12h:49m:07s remains)
INFO - root - 2017-12-01 04:25:52.875795: step 41840, loss = 0.39, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 12h:29m:14s remains)
INFO - root - 2017-12-01 04:25:54.443324: step 41850, loss = 0.49, batch loss = 0.29 (51.8 examples/sec; 0.154 sec/batch; 12h:27m:58s remains)
INFO - root - 2017-12-01 04:25:55.997506: step 41860, loss = 0.53, batch loss = 0.33 (52.6 examples/sec; 0.152 sec/batch; 12h:17m:00s remains)
INFO - root - 2017-12-01 04:25:57.556417: step 41870, loss = 0.36, batch loss = 0.17 (53.0 examples/sec; 0.151 sec/batch; 12h:10m:41s remains)
INFO - root - 2017-12-01 04:25:59.132944: step 41880, loss = 0.45, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 12h:46m:29s remains)
INFO - root - 2017-12-01 04:26:00.689809: step 41890, loss = 0.44, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 12h:35m:15s remains)
INFO - root - 2017-12-01 04:26:02.247922: step 41900, loss = 0.45, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 12h:37m:00s remains)
INFO - root - 2017-12-01 04:26:03.885280: step 41910, loss = 0.43, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 12h:38m:27s remains)
INFO - root - 2017-12-01 04:26:05.456916: step 41920, loss = 0.64, batch loss = 0.44 (50.6 examples/sec; 0.158 sec/batch; 12h:45m:56s remains)
INFO - root - 2017-12-01 04:26:07.007407: step 41930, loss = 0.46, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 12h:27m:39s remains)
INFO - root - 2017-12-01 04:26:08.568867: step 41940, loss = 0.34, batch loss = 0.15 (51.9 examples/sec; 0.154 sec/batch; 12h:25m:45s remains)
INFO - root - 2017-12-01 04:26:10.141923: step 41950, loss = 0.38, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 12h:24m:20s remains)
INFO - root - 2017-12-01 04:26:11.708924: step 41960, loss = 0.47, batch loss = 0.28 (52.1 examples/sec; 0.154 sec/batch; 12h:23m:31s remains)
INFO - root - 2017-12-01 04:26:13.261402: step 41970, loss = 0.42, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 12h:46m:03s remains)
INFO - root - 2017-12-01 04:26:14.821808: step 41980, loss = 0.38, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 12h:54m:04s remains)
INFO - root - 2017-12-01 04:26:16.374228: step 41990, loss = 0.53, batch loss = 0.34 (51.2 examples/sec; 0.156 sec/batch; 12h:37m:06s remains)
INFO - root - 2017-12-01 04:26:17.937052: step 42000, loss = 0.45, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 12h:29m:48s remains)
INFO - root - 2017-12-01 04:26:19.562246: step 42010, loss = 0.47, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 12h:31m:14s remains)
INFO - root - 2017-12-01 04:26:21.118210: step 42020, loss = 0.52, batch loss = 0.33 (53.3 examples/sec; 0.150 sec/batch; 12h:06m:03s remains)
INFO - root - 2017-12-01 04:26:22.667714: step 42030, loss = 0.64, batch loss = 0.44 (51.1 examples/sec; 0.157 sec/batch; 12h:38m:33s remains)
INFO - root - 2017-12-01 04:26:24.253415: step 42040, loss = 0.43, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 12h:56m:29s remains)
INFO - root - 2017-12-01 04:26:25.823003: step 42050, loss = 0.48, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 12h:40m:17s remains)
INFO - root - 2017-12-01 04:26:27.384964: step 42060, loss = 0.44, batch loss = 0.25 (49.8 examples/sec; 0.161 sec/batch; 12h:56m:57s remains)
INFO - root - 2017-12-01 04:26:28.935053: step 42070, loss = 0.48, batch loss = 0.29 (52.2 examples/sec; 0.153 sec/batch; 12h:21m:32s remains)
INFO - root - 2017-12-01 04:26:30.503845: step 42080, loss = 0.43, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 12h:38m:47s remains)
INFO - root - 2017-12-01 04:26:32.092653: step 42090, loss = 0.47, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 12h:44m:01s remains)
INFO - root - 2017-12-01 04:26:33.645158: step 42100, loss = 0.42, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 12h:42m:41s remains)
INFO - root - 2017-12-01 04:26:35.261090: step 42110, loss = 0.49, batch loss = 0.30 (53.2 examples/sec; 0.150 sec/batch; 12h:07m:08s remains)
INFO - root - 2017-12-01 04:26:36.818955: step 42120, loss = 0.40, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 12h:34m:35s remains)
INFO - root - 2017-12-01 04:26:38.375970: step 42130, loss = 0.48, batch loss = 0.29 (51.0 examples/sec; 0.157 sec/batch; 12h:38m:53s remains)
INFO - root - 2017-12-01 04:26:39.942797: step 42140, loss = 0.40, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 12h:37m:36s remains)
INFO - root - 2017-12-01 04:26:41.507521: step 42150, loss = 0.41, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 12h:36m:42s remains)
INFO - root - 2017-12-01 04:26:43.066458: step 42160, loss = 0.42, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 12h:15m:54s remains)
INFO - root - 2017-12-01 04:26:44.643839: step 42170, loss = 0.57, batch loss = 0.37 (51.6 examples/sec; 0.155 sec/batch; 12h:30m:13s remains)
INFO - root - 2017-12-01 04:26:46.219564: step 42180, loss = 0.48, batch loss = 0.29 (52.1 examples/sec; 0.153 sec/batch; 12h:22m:30s remains)
INFO - root - 2017-12-01 04:26:47.776855: step 42190, loss = 0.44, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 12h:47m:23s remains)
INFO - root - 2017-12-01 04:26:49.333575: step 42200, loss = 0.42, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 12h:35m:19s remains)
INFO - root - 2017-12-01 04:26:50.938199: step 42210, loss = 0.43, batch loss = 0.23 (53.2 examples/sec; 0.150 sec/batch; 12h:06m:51s remains)
INFO - root - 2017-12-01 04:26:52.511676: step 42220, loss = 0.42, batch loss = 0.22 (49.0 examples/sec; 0.163 sec/batch; 13h:10m:20s remains)
INFO - root - 2017-12-01 04:26:54.074642: step 42230, loss = 0.47, batch loss = 0.28 (49.7 examples/sec; 0.161 sec/batch; 12h:58m:14s remains)
INFO - root - 2017-12-01 04:26:55.626291: step 42240, loss = 0.40, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 12h:52m:33s remains)
INFO - root - 2017-12-01 04:26:57.180023: step 42250, loss = 0.42, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 12h:43m:00s remains)
INFO - root - 2017-12-01 04:26:58.737042: step 42260, loss = 0.43, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 12h:20m:49s remains)
INFO - root - 2017-12-01 04:27:00.312073: step 42270, loss = 0.55, batch loss = 0.35 (50.0 examples/sec; 0.160 sec/batch; 12h:53m:45s remains)
INFO - root - 2017-12-01 04:27:01.887484: step 42280, loss = 0.46, batch loss = 0.26 (50.8 examples/sec; 0.157 sec/batch; 12h:41m:31s remains)
INFO - root - 2017-12-01 04:27:03.433626: step 42290, loss = 0.50, batch loss = 0.30 (50.4 examples/sec; 0.159 sec/batch; 12h:47m:18s remains)
INFO - root - 2017-12-01 04:27:05.007603: step 42300, loss = 0.48, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 12h:48m:57s remains)
INFO - root - 2017-12-01 04:27:06.645689: step 42310, loss = 0.36, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 12h:39m:59s remains)
INFO - root - 2017-12-01 04:27:08.212345: step 42320, loss = 0.36, batch loss = 0.16 (47.4 examples/sec; 0.169 sec/batch; 13h:35m:30s remains)
INFO - root - 2017-12-01 04:27:09.791968: step 42330, loss = 0.46, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 12h:39m:55s remains)
INFO - root - 2017-12-01 04:27:11.372973: step 42340, loss = 0.41, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 12h:30m:04s remains)
INFO - root - 2017-12-01 04:27:12.945827: step 42350, loss = 0.51, batch loss = 0.32 (50.6 examples/sec; 0.158 sec/batch; 12h:45m:02s remains)
INFO - root - 2017-12-01 04:27:14.519948: step 42360, loss = 0.41, batch loss = 0.22 (49.8 examples/sec; 0.161 sec/batch; 12h:56m:34s remains)
INFO - root - 2017-12-01 04:27:16.107030: step 42370, loss = 0.42, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 12h:55m:03s remains)
INFO - root - 2017-12-01 04:27:17.668147: step 42380, loss = 0.39, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 12h:34m:25s remains)
INFO - root - 2017-12-01 04:27:19.227525: step 42390, loss = 0.62, batch loss = 0.43 (49.2 examples/sec; 0.163 sec/batch; 13h:06m:56s remains)
INFO - root - 2017-12-01 04:27:20.784423: step 42400, loss = 0.43, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 12h:25m:15s remains)
INFO - root - 2017-12-01 04:27:22.426417: step 42410, loss = 0.38, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 12h:26m:34s remains)
INFO - root - 2017-12-01 04:27:23.985452: step 42420, loss = 0.42, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 12h:54m:07s remains)
INFO - root - 2017-12-01 04:27:25.560550: step 42430, loss = 0.46, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 12h:37m:02s remains)
INFO - root - 2017-12-01 04:27:27.109217: step 42440, loss = 0.41, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 12h:30m:58s remains)
INFO - root - 2017-12-01 04:27:28.668314: step 42450, loss = 0.49, batch loss = 0.30 (52.2 examples/sec; 0.153 sec/batch; 12h:21m:13s remains)
INFO - root - 2017-12-01 04:27:30.234157: step 42460, loss = 0.41, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 12h:21m:03s remains)
INFO - root - 2017-12-01 04:27:31.785285: step 42470, loss = 0.49, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 12h:24m:32s remains)
INFO - root - 2017-12-01 04:27:33.336071: step 42480, loss = 0.55, batch loss = 0.36 (50.7 examples/sec; 0.158 sec/batch; 12h:43m:02s remains)
INFO - root - 2017-12-01 04:27:34.900014: step 42490, loss = 0.37, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 12h:28m:36s remains)
INFO - root - 2017-12-01 04:27:36.483890: step 42500, loss = 0.44, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 12h:33m:40s remains)
INFO - root - 2017-12-01 04:27:38.092586: step 42510, loss = 0.57, batch loss = 0.37 (51.3 examples/sec; 0.156 sec/batch; 12h:34m:13s remains)
INFO - root - 2017-12-01 04:27:39.652752: step 42520, loss = 0.67, batch loss = 0.48 (49.9 examples/sec; 0.160 sec/batch; 12h:55m:19s remains)
INFO - root - 2017-12-01 04:27:41.224892: step 42530, loss = 0.53, batch loss = 0.34 (48.8 examples/sec; 0.164 sec/batch; 13h:12m:49s remains)
INFO - root - 2017-12-01 04:27:42.804322: step 42540, loss = 0.42, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 12h:45m:11s remains)
INFO - root - 2017-12-01 04:27:44.361947: step 42550, loss = 0.55, batch loss = 0.36 (51.8 examples/sec; 0.155 sec/batch; 12h:26m:56s remains)
INFO - root - 2017-12-01 04:27:45.917455: step 42560, loss = 0.56, batch loss = 0.36 (50.2 examples/sec; 0.159 sec/batch; 12h:50m:25s remains)
INFO - root - 2017-12-01 04:27:47.486107: step 42570, loss = 0.38, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 12h:40m:01s remains)
INFO - root - 2017-12-01 04:27:49.034276: step 42580, loss = 0.41, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 12h:32m:15s remains)
INFO - root - 2017-12-01 04:27:50.612498: step 42590, loss = 0.43, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 12h:20m:18s remains)
INFO - root - 2017-12-01 04:27:52.158372: step 42600, loss = 0.41, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 12h:35m:15s remains)
INFO - root - 2017-12-01 04:27:53.810704: step 42610, loss = 0.41, batch loss = 0.22 (49.9 examples/sec; 0.160 sec/batch; 12h:53m:59s remains)
INFO - root - 2017-12-01 04:27:55.362911: step 42620, loss = 0.46, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 12h:36m:39s remains)
INFO - root - 2017-12-01 04:27:56.930795: step 42630, loss = 0.37, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 12h:37m:05s remains)
INFO - root - 2017-12-01 04:27:58.494730: step 42640, loss = 0.48, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 12h:39m:35s remains)
INFO - root - 2017-12-01 04:28:00.050206: step 42650, loss = 0.49, batch loss = 0.30 (49.5 examples/sec; 0.162 sec/batch; 13h:00m:44s remains)
INFO - root - 2017-12-01 04:28:01.604013: step 42660, loss = 0.38, batch loss = 0.18 (52.5 examples/sec; 0.152 sec/batch; 12h:16m:38s remains)
INFO - root - 2017-12-01 04:28:03.195986: step 42670, loss = 0.48, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 12h:24m:23s remains)
INFO - root - 2017-12-01 04:28:04.756607: step 42680, loss = 0.42, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 12h:43m:24s remains)
INFO - root - 2017-12-01 04:28:06.319638: step 42690, loss = 0.48, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 12h:42m:27s remains)
INFO - root - 2017-12-01 04:28:07.890909: step 42700, loss = 0.38, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 12h:42m:02s remains)
INFO - root - 2017-12-01 04:28:09.492810: step 42710, loss = 0.43, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 12h:20m:51s remains)
INFO - root - 2017-12-01 04:28:11.071974: step 42720, loss = 0.49, batch loss = 0.30 (49.9 examples/sec; 0.160 sec/batch; 12h:53m:43s remains)
INFO - root - 2017-12-01 04:28:12.642364: step 42730, loss = 0.41, batch loss = 0.22 (49.6 examples/sec; 0.161 sec/batch; 12h:59m:42s remains)
INFO - root - 2017-12-01 04:28:14.218438: step 42740, loss = 0.42, batch loss = 0.23 (50.4 examples/sec; 0.159 sec/batch; 12h:45m:48s remains)
INFO - root - 2017-12-01 04:28:15.787141: step 42750, loss = 0.56, batch loss = 0.37 (51.3 examples/sec; 0.156 sec/batch; 12h:33m:39s remains)
INFO - root - 2017-12-01 04:28:17.349261: step 42760, loss = 0.52, batch loss = 0.33 (50.7 examples/sec; 0.158 sec/batch; 12h:42m:24s remains)
INFO - root - 2017-12-01 04:28:18.917275: step 42770, loss = 0.60, batch loss = 0.41 (49.2 examples/sec; 0.162 sec/batch; 13h:04m:23s remains)
INFO - root - 2017-12-01 04:28:20.478898: step 42780, loss = 0.38, batch loss = 0.18 (52.5 examples/sec; 0.152 sec/batch; 12h:15m:27s remains)
INFO - root - 2017-12-01 04:28:22.038764: step 42790, loss = 0.40, batch loss = 0.20 (52.1 examples/sec; 0.153 sec/batch; 12h:21m:10s remains)
INFO - root - 2017-12-01 04:28:23.618128: step 42800, loss = 0.47, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 12h:42m:05s remains)
INFO - root - 2017-12-01 04:28:25.239071: step 42810, loss = 0.65, batch loss = 0.46 (51.2 examples/sec; 0.156 sec/batch; 12h:34m:33s remains)
INFO - root - 2017-12-01 04:28:26.818696: step 42820, loss = 0.47, batch loss = 0.28 (52.3 examples/sec; 0.153 sec/batch; 12h:18m:52s remains)
INFO - root - 2017-12-01 04:28:28.383695: step 42830, loss = 0.58, batch loss = 0.39 (50.6 examples/sec; 0.158 sec/batch; 12h:43m:52s remains)
INFO - root - 2017-12-01 04:28:29.953281: step 42840, loss = 0.42, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 12h:48m:27s remains)
INFO - root - 2017-12-01 04:28:31.521120: step 42850, loss = 0.38, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 12h:38m:19s remains)
INFO - root - 2017-12-01 04:28:33.088239: step 42860, loss = 0.44, batch loss = 0.25 (52.1 examples/sec; 0.153 sec/batch; 12h:20m:47s remains)
INFO - root - 2017-12-01 04:28:34.667006: step 42870, loss = 0.46, batch loss = 0.27 (49.9 examples/sec; 0.160 sec/batch; 12h:53m:15s remains)
INFO - root - 2017-12-01 04:28:36.228443: step 42880, loss = 0.47, batch loss = 0.28 (50.4 examples/sec; 0.159 sec/batch; 12h:46m:06s remains)
INFO - root - 2017-12-01 04:28:37.779386: step 42890, loss = 0.43, batch loss = 0.24 (52.9 examples/sec; 0.151 sec/batch; 12h:10m:09s remains)
INFO - root - 2017-12-01 04:28:39.356024: step 42900, loss = 0.42, batch loss = 0.22 (49.4 examples/sec; 0.162 sec/batch; 13h:02m:18s remains)
INFO - root - 2017-12-01 04:28:41.003839: step 42910, loss = 0.51, batch loss = 0.32 (51.4 examples/sec; 0.156 sec/batch; 12h:31m:04s remains)
INFO - root - 2017-12-01 04:28:42.567761: step 42920, loss = 0.51, batch loss = 0.31 (50.1 examples/sec; 0.160 sec/batch; 12h:50m:06s remains)
INFO - root - 2017-12-01 04:28:44.142761: step 42930, loss = 0.54, batch loss = 0.34 (51.0 examples/sec; 0.157 sec/batch; 12h:36m:40s remains)
INFO - root - 2017-12-01 04:28:45.723478: step 42940, loss = 0.39, batch loss = 0.20 (47.9 examples/sec; 0.167 sec/batch; 13h:25m:11s remains)
INFO - root - 2017-12-01 04:28:47.307133: step 42950, loss = 0.47, batch loss = 0.28 (48.5 examples/sec; 0.165 sec/batch; 13h:16m:31s remains)
INFO - root - 2017-12-01 04:28:48.859427: step 42960, loss = 0.48, batch loss = 0.29 (51.1 examples/sec; 0.156 sec/batch; 12h:34m:50s remains)
INFO - root - 2017-12-01 04:28:50.420859: step 42970, loss = 0.55, batch loss = 0.35 (52.7 examples/sec; 0.152 sec/batch; 12h:12m:43s remains)
INFO - root - 2017-12-01 04:28:51.976407: step 42980, loss = 0.40, batch loss = 0.20 (53.2 examples/sec; 0.150 sec/batch; 12h:05m:11s remains)
INFO - root - 2017-12-01 04:28:53.536793: step 42990, loss = 0.46, batch loss = 0.26 (51.1 examples/sec; 0.157 sec/batch; 12h:35m:08s remains)
INFO - root - 2017-12-01 04:28:55.097244: step 43000, loss = 0.43, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 12h:41m:49s remains)
INFO - root - 2017-12-01 04:28:56.733887: step 43010, loss = 0.45, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 12h:36m:14s remains)
INFO - root - 2017-12-01 04:28:58.298482: step 43020, loss = 0.40, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 12h:35m:59s remains)
INFO - root - 2017-12-01 04:28:59.875394: step 43030, loss = 0.45, batch loss = 0.25 (48.6 examples/sec; 0.165 sec/batch; 13h:14m:00s remains)
INFO - root - 2017-12-01 04:29:01.430428: step 43040, loss = 0.55, batch loss = 0.36 (51.2 examples/sec; 0.156 sec/batch; 12h:34m:17s remains)
INFO - root - 2017-12-01 04:29:03.003314: step 43050, loss = 0.41, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 12h:38m:33s remains)
INFO - root - 2017-12-01 04:29:04.614007: step 43060, loss = 0.46, batch loss = 0.27 (50.4 examples/sec; 0.159 sec/batch; 12h:46m:07s remains)
INFO - root - 2017-12-01 04:29:06.168870: step 43070, loss = 0.57, batch loss = 0.37 (51.0 examples/sec; 0.157 sec/batch; 12h:37m:00s remains)
INFO - root - 2017-12-01 04:29:07.726446: step 43080, loss = 0.42, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 12h:21m:59s remains)
INFO - root - 2017-12-01 04:29:09.313322: step 43090, loss = 0.51, batch loss = 0.31 (49.7 examples/sec; 0.161 sec/batch; 12h:56m:08s remains)
INFO - root - 2017-12-01 04:29:10.881476: step 43100, loss = 0.45, batch loss = 0.26 (50.0 examples/sec; 0.160 sec/batch; 12h:51m:50s remains)
INFO - root - 2017-12-01 04:29:12.493550: step 43110, loss = 0.44, batch loss = 0.25 (53.0 examples/sec; 0.151 sec/batch; 12h:07m:52s remains)
INFO - root - 2017-12-01 04:29:14.069246: step 43120, loss = 0.48, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 12h:41m:19s remains)
INFO - root - 2017-12-01 04:29:15.614139: step 43130, loss = 0.40, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 12h:24m:13s remains)
INFO - root - 2017-12-01 04:29:17.170893: step 43140, loss = 0.38, batch loss = 0.19 (49.8 examples/sec; 0.161 sec/batch; 12h:54m:36s remains)
INFO - root - 2017-12-01 04:29:18.778398: step 43150, loss = 0.52, batch loss = 0.32 (50.0 examples/sec; 0.160 sec/batch; 12h:51m:11s remains)
INFO - root - 2017-12-01 04:29:20.338027: step 43160, loss = 0.50, batch loss = 0.31 (49.4 examples/sec; 0.162 sec/batch; 13h:00m:25s remains)
INFO - root - 2017-12-01 04:29:21.936975: step 43170, loss = 0.47, batch loss = 0.28 (49.7 examples/sec; 0.161 sec/batch; 12h:56m:46s remains)
INFO - root - 2017-12-01 04:29:23.506227: step 43180, loss = 0.45, batch loss = 0.26 (49.8 examples/sec; 0.161 sec/batch; 12h:54m:23s remains)
INFO - root - 2017-12-01 04:29:25.066131: step 43190, loss = 0.54, batch loss = 0.35 (51.2 examples/sec; 0.156 sec/batch; 12h:33m:01s remains)
INFO - root - 2017-12-01 04:29:26.612650: step 43200, loss = 0.53, batch loss = 0.34 (50.7 examples/sec; 0.158 sec/batch; 12h:41m:29s remains)
INFO - root - 2017-12-01 04:29:28.236389: step 43210, loss = 0.44, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 12h:40m:40s remains)
INFO - root - 2017-12-01 04:29:29.822182: step 43220, loss = 0.40, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 12h:40m:44s remains)
INFO - root - 2017-12-01 04:29:31.386321: step 43230, loss = 0.49, batch loss = 0.29 (52.3 examples/sec; 0.153 sec/batch; 12h:17m:05s remains)
INFO - root - 2017-12-01 04:29:32.951469: step 43240, loss = 0.43, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 12h:15m:20s remains)
INFO - root - 2017-12-01 04:29:34.512173: step 43250, loss = 0.39, batch loss = 0.19 (51.8 examples/sec; 0.155 sec/batch; 12h:25m:10s remains)
INFO - root - 2017-12-01 04:29:36.073624: step 43260, loss = 0.51, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 12h:32m:33s remains)
INFO - root - 2017-12-01 04:29:37.640821: step 43270, loss = 0.40, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 12h:29m:01s remains)
INFO - root - 2017-12-01 04:29:39.216839: step 43280, loss = 0.47, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 12h:29m:17s remains)
INFO - root - 2017-12-01 04:29:40.784064: step 43290, loss = 0.46, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 12h:43m:30s remains)
INFO - root - 2017-12-01 04:29:42.336821: step 43300, loss = 0.42, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 12h:39m:15s remains)
INFO - root - 2017-12-01 04:29:43.973881: step 43310, loss = 0.43, batch loss = 0.23 (49.4 examples/sec; 0.162 sec/batch; 13h:01m:00s remains)
INFO - root - 2017-12-01 04:29:45.552561: step 43320, loss = 0.47, batch loss = 0.27 (51.2 examples/sec; 0.156 sec/batch; 12h:33m:13s remains)
INFO - root - 2017-12-01 04:29:47.108440: step 43330, loss = 0.42, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 12h:19m:56s remains)
INFO - root - 2017-12-01 04:29:48.662208: step 43340, loss = 0.41, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 12h:22m:36s remains)
INFO - root - 2017-12-01 04:29:50.235661: step 43350, loss = 0.44, batch loss = 0.24 (48.2 examples/sec; 0.166 sec/batch; 13h:19m:58s remains)
INFO - root - 2017-12-01 04:29:51.813250: step 43360, loss = 0.64, batch loss = 0.45 (52.5 examples/sec; 0.152 sec/batch; 12h:14m:06s remains)
INFO - root - 2017-12-01 04:29:53.374533: step 43370, loss = 0.41, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 12h:35m:03s remains)
INFO - root - 2017-12-01 04:29:54.940300: step 43380, loss = 0.55, batch loss = 0.36 (50.1 examples/sec; 0.160 sec/batch; 12h:48m:42s remains)
INFO - root - 2017-12-01 04:29:56.505405: step 43390, loss = 0.50, batch loss = 0.31 (52.0 examples/sec; 0.154 sec/batch; 12h:20m:56s remains)
INFO - root - 2017-12-01 04:29:58.073412: step 43400, loss = 0.39, batch loss = 0.20 (49.7 examples/sec; 0.161 sec/batch; 12h:55m:39s remains)
INFO - root - 2017-12-01 04:29:59.677945: step 43410, loss = 0.46, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 12h:34m:04s remains)
INFO - root - 2017-12-01 04:30:01.249280: step 43420, loss = 0.53, batch loss = 0.33 (49.1 examples/sec; 0.163 sec/batch; 13h:04m:13s remains)
INFO - root - 2017-12-01 04:30:02.825254: step 43430, loss = 0.37, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 12h:26m:31s remains)
INFO - root - 2017-12-01 04:30:04.403672: step 43440, loss = 0.44, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 12h:46m:33s remains)
INFO - root - 2017-12-01 04:30:05.981565: step 43450, loss = 0.49, batch loss = 0.29 (51.0 examples/sec; 0.157 sec/batch; 12h:35m:57s remains)
INFO - root - 2017-12-01 04:30:07.543565: step 43460, loss = 0.47, batch loss = 0.28 (50.0 examples/sec; 0.160 sec/batch; 12h:50m:47s remains)
INFO - root - 2017-12-01 04:30:09.111506: step 43470, loss = 0.41, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 12h:25m:30s remains)
INFO - root - 2017-12-01 04:30:10.682888: step 43480, loss = 0.36, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 12h:23m:49s remains)
INFO - root - 2017-12-01 04:30:12.263132: step 43490, loss = 0.43, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 12h:41m:52s remains)
INFO - root - 2017-12-01 04:30:13.798931: step 43500, loss = 0.38, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 12h:34m:45s remains)
INFO - root - 2017-12-01 04:30:15.446929: step 43510, loss = 0.52, batch loss = 0.33 (50.4 examples/sec; 0.159 sec/batch; 12h:45m:01s remains)
INFO - root - 2017-12-01 04:30:17.012308: step 43520, loss = 0.42, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 12h:35m:09s remains)
INFO - root - 2017-12-01 04:30:18.578268: step 43530, loss = 0.47, batch loss = 0.28 (49.5 examples/sec; 0.162 sec/batch; 12h:58m:58s remains)
INFO - root - 2017-12-01 04:30:20.138746: step 43540, loss = 0.41, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 12h:39m:29s remains)
INFO - root - 2017-12-01 04:30:21.703194: step 43550, loss = 0.41, batch loss = 0.21 (53.1 examples/sec; 0.151 sec/batch; 12h:04m:57s remains)
INFO - root - 2017-12-01 04:30:23.257714: step 43560, loss = 0.39, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 12h:33m:45s remains)
INFO - root - 2017-12-01 04:30:24.817684: step 43570, loss = 0.38, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 12h:34m:11s remains)
INFO - root - 2017-12-01 04:30:26.381188: step 43580, loss = 0.49, batch loss = 0.29 (49.4 examples/sec; 0.162 sec/batch; 12h:59m:22s remains)
INFO - root - 2017-12-01 04:30:27.941386: step 43590, loss = 0.47, batch loss = 0.28 (50.8 examples/sec; 0.158 sec/batch; 12h:38m:33s remains)
INFO - root - 2017-12-01 04:30:29.500175: step 43600, loss = 0.37, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 12h:37m:00s remains)
INFO - root - 2017-12-01 04:30:31.171021: step 43610, loss = 0.47, batch loss = 0.28 (50.4 examples/sec; 0.159 sec/batch; 12h:43m:46s remains)
INFO - root - 2017-12-01 04:30:32.721758: step 43620, loss = 0.42, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 12h:25m:55s remains)
INFO - root - 2017-12-01 04:30:34.280403: step 43630, loss = 0.50, batch loss = 0.31 (51.7 examples/sec; 0.155 sec/batch; 12h:25m:41s remains)
INFO - root - 2017-12-01 04:30:35.855811: step 43640, loss = 0.42, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 12h:24m:50s remains)
INFO - root - 2017-12-01 04:30:37.409981: step 43650, loss = 0.57, batch loss = 0.38 (50.6 examples/sec; 0.158 sec/batch; 12h:41m:27s remains)
INFO - root - 2017-12-01 04:30:38.962087: step 43660, loss = 0.39, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 12h:38m:24s remains)
INFO - root - 2017-12-01 04:30:40.559161: step 43670, loss = 0.34, batch loss = 0.15 (52.1 examples/sec; 0.154 sec/batch; 12h:19m:20s remains)
INFO - root - 2017-12-01 04:30:42.112026: step 43680, loss = 0.44, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 12h:24m:58s remains)
INFO - root - 2017-12-01 04:30:43.664800: step 43690, loss = 0.41, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 12h:21m:23s remains)
INFO - root - 2017-12-01 04:30:45.244340: step 43700, loss = 0.46, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 12h:27m:03s remains)
INFO - root - 2017-12-01 04:30:46.891580: step 43710, loss = 0.58, batch loss = 0.39 (51.8 examples/sec; 0.154 sec/batch; 12h:23m:10s remains)
INFO - root - 2017-12-01 04:30:48.456623: step 43720, loss = 0.47, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 12h:20m:02s remains)
INFO - root - 2017-12-01 04:30:50.031469: step 43730, loss = 0.48, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 12h:36m:50s remains)
INFO - root - 2017-12-01 04:30:51.601884: step 43740, loss = 0.44, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 12h:39m:17s remains)
INFO - root - 2017-12-01 04:30:53.175358: step 43750, loss = 0.45, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 12h:30m:56s remains)
INFO - root - 2017-12-01 04:30:54.730060: step 43760, loss = 0.40, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 12h:17m:56s remains)
INFO - root - 2017-12-01 04:30:56.299027: step 43770, loss = 0.41, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 12h:18m:42s remains)
INFO - root - 2017-12-01 04:30:57.849349: step 43780, loss = 0.44, batch loss = 0.25 (51.1 examples/sec; 0.156 sec/batch; 12h:32m:38s remains)
INFO - root - 2017-12-01 04:30:59.411053: step 43790, loss = 0.39, batch loss = 0.20 (49.4 examples/sec; 0.162 sec/batch; 12h:58m:45s remains)
INFO - root - 2017-12-01 04:31:00.990140: step 43800, loss = 0.42, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 12h:27m:50s remains)
INFO - root - 2017-12-01 04:31:02.602374: step 43810, loss = 0.48, batch loss = 0.28 (50.4 examples/sec; 0.159 sec/batch; 12h:43m:14s remains)
INFO - root - 2017-12-01 04:31:04.155072: step 43820, loss = 0.43, batch loss = 0.24 (49.4 examples/sec; 0.162 sec/batch; 12h:58m:40s remains)
INFO - root - 2017-12-01 04:31:05.726488: step 43830, loss = 0.39, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 12h:44m:28s remains)
INFO - root - 2017-12-01 04:31:07.291114: step 43840, loss = 0.53, batch loss = 0.34 (51.0 examples/sec; 0.157 sec/batch; 12h:34m:32s remains)
INFO - root - 2017-12-01 04:31:08.885700: step 43850, loss = 0.41, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 12h:13m:57s remains)
INFO - root - 2017-12-01 04:31:10.452499: step 43860, loss = 0.45, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 12h:25m:32s remains)
INFO - root - 2017-12-01 04:31:12.006813: step 43870, loss = 0.48, batch loss = 0.29 (53.3 examples/sec; 0.150 sec/batch; 12h:02m:40s remains)
INFO - root - 2017-12-01 04:31:13.558947: step 43880, loss = 0.48, batch loss = 0.29 (52.3 examples/sec; 0.153 sec/batch; 12h:16m:17s remains)
INFO - root - 2017-12-01 04:31:15.141492: step 43890, loss = 0.43, batch loss = 0.24 (47.6 examples/sec; 0.168 sec/batch; 13h:28m:08s remains)
INFO - root - 2017-12-01 04:31:16.692786: step 43900, loss = 0.71, batch loss = 0.51 (51.3 examples/sec; 0.156 sec/batch; 12h:29m:23s remains)
INFO - root - 2017-12-01 04:31:18.294679: step 43910, loss = 0.58, batch loss = 0.39 (52.7 examples/sec; 0.152 sec/batch; 12h:09m:32s remains)
INFO - root - 2017-12-01 04:31:19.857759: step 43920, loss = 0.41, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 12h:24m:50s remains)
INFO - root - 2017-12-01 04:31:21.443847: step 43930, loss = 0.44, batch loss = 0.25 (48.6 examples/sec; 0.165 sec/batch; 13h:11m:24s remains)
INFO - root - 2017-12-01 04:31:23.005035: step 43940, loss = 0.47, batch loss = 0.27 (49.5 examples/sec; 0.162 sec/batch; 12h:57m:08s remains)
INFO - root - 2017-12-01 04:31:24.546971: step 43950, loss = 0.43, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 12h:19m:30s remains)
INFO - root - 2017-12-01 04:31:26.104598: step 43960, loss = 0.50, batch loss = 0.30 (52.8 examples/sec; 0.151 sec/batch; 12h:08m:04s remains)
INFO - root - 2017-12-01 04:31:27.703164: step 43970, loss = 0.38, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 12h:25m:24s remains)
INFO - root - 2017-12-01 04:31:29.258447: step 43980, loss = 0.48, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 12h:31m:57s remains)
INFO - root - 2017-12-01 04:31:30.802697: step 43990, loss = 0.62, batch loss = 0.42 (51.4 examples/sec; 0.156 sec/batch; 12h:29m:00s remains)
INFO - root - 2017-12-01 04:31:32.353003: step 44000, loss = 0.36, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 12h:27m:43s remains)
INFO - root - 2017-12-01 04:31:34.040569: step 44010, loss = 0.37, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 12h:41m:43s remains)
INFO - root - 2017-12-01 04:31:35.606392: step 44020, loss = 0.44, batch loss = 0.25 (50.1 examples/sec; 0.160 sec/batch; 12h:47m:22s remains)
INFO - root - 2017-12-01 04:31:37.151477: step 44030, loss = 0.40, batch loss = 0.20 (53.4 examples/sec; 0.150 sec/batch; 12h:00m:53s remains)
INFO - root - 2017-12-01 04:31:38.708149: step 44040, loss = 0.40, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 12h:21m:30s remains)
INFO - root - 2017-12-01 04:31:40.289899: step 44050, loss = 0.48, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 12h:35m:57s remains)
INFO - root - 2017-12-01 04:31:41.856362: step 44060, loss = 0.48, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 12h:35m:16s remains)
INFO - root - 2017-12-01 04:31:43.406061: step 44070, loss = 0.45, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 12h:24m:23s remains)
INFO - root - 2017-12-01 04:31:44.978064: step 44080, loss = 0.67, batch loss = 0.48 (51.8 examples/sec; 0.154 sec/batch; 12h:22m:00s remains)
INFO - root - 2017-12-01 04:31:46.557762: step 44090, loss = 0.37, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 12h:26m:13s remains)
INFO - root - 2017-12-01 04:31:48.119905: step 44100, loss = 0.37, batch loss = 0.17 (50.0 examples/sec; 0.160 sec/batch; 12h:48m:46s remains)
INFO - root - 2017-12-01 04:31:49.794119: step 44110, loss = 0.50, batch loss = 0.31 (48.6 examples/sec; 0.164 sec/batch; 13h:10m:23s remains)
INFO - root - 2017-12-01 04:31:51.380760: step 44120, loss = 0.44, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 12h:39m:49s remains)
INFO - root - 2017-12-01 04:31:52.930002: step 44130, loss = 0.38, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 12h:16m:39s remains)
INFO - root - 2017-12-01 04:31:54.491514: step 44140, loss = 0.44, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 12h:38m:40s remains)
INFO - root - 2017-12-01 04:31:56.084629: step 44150, loss = 0.45, batch loss = 0.26 (49.5 examples/sec; 0.162 sec/batch; 12h:56m:27s remains)
INFO - root - 2017-12-01 04:31:57.645248: step 44160, loss = 0.49, batch loss = 0.30 (51.1 examples/sec; 0.157 sec/batch; 12h:32m:29s remains)
INFO - root - 2017-12-01 04:31:59.210999: step 44170, loss = 0.51, batch loss = 0.31 (49.2 examples/sec; 0.162 sec/batch; 13h:00m:47s remains)
INFO - root - 2017-12-01 04:32:00.771169: step 44180, loss = 0.42, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 12h:39m:36s remains)
INFO - root - 2017-12-01 04:32:02.352396: step 44190, loss = 0.60, batch loss = 0.40 (51.2 examples/sec; 0.156 sec/batch; 12h:30m:23s remains)
INFO - root - 2017-12-01 04:32:03.904801: step 44200, loss = 0.41, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 12h:23m:05s remains)
INFO - root - 2017-12-01 04:32:05.511112: step 44210, loss = 0.36, batch loss = 0.16 (52.3 examples/sec; 0.153 sec/batch; 12h:14m:49s remains)
INFO - root - 2017-12-01 04:32:07.061783: step 44220, loss = 0.42, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 12h:39m:03s remains)
INFO - root - 2017-12-01 04:32:08.639185: step 44230, loss = 0.61, batch loss = 0.41 (51.5 examples/sec; 0.155 sec/batch; 12h:26m:20s remains)
INFO - root - 2017-12-01 04:32:10.215299: step 44240, loss = 0.59, batch loss = 0.40 (51.8 examples/sec; 0.154 sec/batch; 12h:21m:34s remains)
INFO - root - 2017-12-01 04:32:11.774228: step 44250, loss = 0.45, batch loss = 0.25 (49.6 examples/sec; 0.161 sec/batch; 12h:54m:59s remains)
INFO - root - 2017-12-01 04:32:13.342297: step 44260, loss = 0.52, batch loss = 0.33 (51.5 examples/sec; 0.155 sec/batch; 12h:25m:36s remains)
INFO - root - 2017-12-01 04:32:14.900771: step 44270, loss = 0.48, batch loss = 0.28 (50.8 examples/sec; 0.158 sec/batch; 12h:36m:52s remains)
INFO - root - 2017-12-01 04:32:16.475834: step 44280, loss = 0.46, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 12h:27m:46s remains)
INFO - root - 2017-12-01 04:32:18.035501: step 44290, loss = 0.43, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 12h:23m:47s remains)
INFO - root - 2017-12-01 04:32:19.617148: step 44300, loss = 0.55, batch loss = 0.36 (51.4 examples/sec; 0.156 sec/batch; 12h:27m:23s remains)
INFO - root - 2017-12-01 04:32:21.260087: step 44310, loss = 0.38, batch loss = 0.19 (51.1 examples/sec; 0.156 sec/batch; 12h:31m:28s remains)
INFO - root - 2017-12-01 04:32:22.810113: step 44320, loss = 0.40, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 12h:34m:31s remains)
INFO - root - 2017-12-01 04:32:24.372047: step 44330, loss = 0.44, batch loss = 0.25 (48.8 examples/sec; 0.164 sec/batch; 13h:07m:58s remains)
INFO - root - 2017-12-01 04:32:25.937050: step 44340, loss = 0.42, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 12h:15m:38s remains)
INFO - root - 2017-12-01 04:32:27.507530: step 44350, loss = 0.40, batch loss = 0.21 (52.8 examples/sec; 0.151 sec/batch; 12h:07m:29s remains)
INFO - root - 2017-12-01 04:32:29.082300: step 44360, loss = 0.69, batch loss = 0.50 (50.9 examples/sec; 0.157 sec/batch; 12h:34m:24s remains)
INFO - root - 2017-12-01 04:32:30.682583: step 44370, loss = 0.47, batch loss = 0.28 (49.4 examples/sec; 0.162 sec/batch; 12h:57m:40s remains)
INFO - root - 2017-12-01 04:32:32.244985: step 44380, loss = 0.42, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 12h:20m:30s remains)
INFO - root - 2017-12-01 04:32:33.810640: step 44390, loss = 0.45, batch loss = 0.26 (52.5 examples/sec; 0.152 sec/batch; 12h:11m:00s remains)
INFO - root - 2017-12-01 04:32:35.378855: step 44400, loss = 0.49, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 12h:26m:55s remains)
INFO - root - 2017-12-01 04:32:37.020883: step 44410, loss = 0.50, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 12h:34m:45s remains)
INFO - root - 2017-12-01 04:32:38.581586: step 44420, loss = 0.44, batch loss = 0.25 (52.4 examples/sec; 0.153 sec/batch; 12h:13m:01s remains)
INFO - root - 2017-12-01 04:32:40.152495: step 44430, loss = 0.65, batch loss = 0.45 (49.3 examples/sec; 0.162 sec/batch; 12h:59m:38s remains)
INFO - root - 2017-12-01 04:32:41.722019: step 44440, loss = 0.47, batch loss = 0.28 (49.3 examples/sec; 0.162 sec/batch; 12h:58m:33s remains)
INFO - root - 2017-12-01 04:32:43.280496: step 44450, loss = 0.43, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 12h:39m:06s remains)
INFO - root - 2017-12-01 04:32:44.863842: step 44460, loss = 0.44, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 12h:20m:24s remains)
INFO - root - 2017-12-01 04:32:46.421886: step 44470, loss = 0.52, batch loss = 0.33 (47.2 examples/sec; 0.169 sec/batch; 13h:32m:59s remains)
INFO - root - 2017-12-01 04:32:48.001800: step 44480, loss = 0.38, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 12h:49m:10s remains)
INFO - root - 2017-12-01 04:32:49.570196: step 44490, loss = 0.58, batch loss = 0.38 (49.7 examples/sec; 0.161 sec/batch; 12h:51m:58s remains)
INFO - root - 2017-12-01 04:32:51.133265: step 44500, loss = 0.57, batch loss = 0.38 (51.4 examples/sec; 0.156 sec/batch; 12h:26m:50s remains)
INFO - root - 2017-12-01 04:32:52.759409: step 44510, loss = 0.43, batch loss = 0.24 (49.4 examples/sec; 0.162 sec/batch; 12h:56m:38s remains)
INFO - root - 2017-12-01 04:32:54.325008: step 44520, loss = 0.46, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 12h:39m:19s remains)
INFO - root - 2017-12-01 04:32:55.919694: step 44530, loss = 0.53, batch loss = 0.34 (51.6 examples/sec; 0.155 sec/batch; 12h:24m:32s remains)
INFO - root - 2017-12-01 04:32:57.481938: step 44540, loss = 0.42, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 12h:32m:05s remains)
INFO - root - 2017-12-01 04:32:59.039936: step 44550, loss = 0.47, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 12h:30m:18s remains)
INFO - root - 2017-12-01 04:33:00.615599: step 44560, loss = 0.38, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 12h:34m:52s remains)
INFO - root - 2017-12-01 04:33:02.182566: step 44570, loss = 0.43, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 12h:34m:31s remains)
INFO - root - 2017-12-01 04:33:03.727394: step 44580, loss = 0.48, batch loss = 0.29 (53.0 examples/sec; 0.151 sec/batch; 12h:04m:38s remains)
INFO - root - 2017-12-01 04:33:05.302033: step 44590, loss = 0.42, batch loss = 0.23 (50.0 examples/sec; 0.160 sec/batch; 12h:47m:13s remains)
INFO - root - 2017-12-01 04:33:06.877929: step 44600, loss = 0.35, batch loss = 0.16 (48.7 examples/sec; 0.164 sec/batch; 13h:07m:47s remains)
INFO - root - 2017-12-01 04:33:08.499584: step 44610, loss = 0.39, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 12h:22m:32s remains)
INFO - root - 2017-12-01 04:33:10.089794: step 44620, loss = 0.45, batch loss = 0.26 (49.4 examples/sec; 0.162 sec/batch; 12h:57m:27s remains)
INFO - root - 2017-12-01 04:33:11.666697: step 44630, loss = 0.45, batch loss = 0.26 (52.6 examples/sec; 0.152 sec/batch; 12h:09m:13s remains)
INFO - root - 2017-12-01 04:33:13.225879: step 44640, loss = 0.39, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 12h:27m:51s remains)
INFO - root - 2017-12-01 04:33:14.829106: step 44650, loss = 0.49, batch loss = 0.30 (51.0 examples/sec; 0.157 sec/batch; 12h:32m:57s remains)
INFO - root - 2017-12-01 04:33:16.379486: step 44660, loss = 0.37, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 12h:41m:51s remains)
INFO - root - 2017-12-01 04:33:17.931297: step 44670, loss = 0.44, batch loss = 0.25 (52.0 examples/sec; 0.154 sec/batch; 12h:17m:31s remains)
INFO - root - 2017-12-01 04:33:19.498348: step 44680, loss = 0.46, batch loss = 0.27 (49.0 examples/sec; 0.163 sec/batch; 13h:03m:54s remains)
INFO - root - 2017-12-01 04:33:21.085808: step 44690, loss = 0.60, batch loss = 0.41 (49.1 examples/sec; 0.163 sec/batch; 13h:01m:15s remains)
INFO - root - 2017-12-01 04:33:22.641658: step 44700, loss = 0.48, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 12h:30m:07s remains)
INFO - root - 2017-12-01 04:33:24.251051: step 44710, loss = 0.40, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 12h:11m:47s remains)
INFO - root - 2017-12-01 04:33:25.822499: step 44720, loss = 0.52, batch loss = 0.33 (49.7 examples/sec; 0.161 sec/batch; 12h:52m:01s remains)
INFO - root - 2017-12-01 04:33:27.392557: step 44730, loss = 0.38, batch loss = 0.18 (49.7 examples/sec; 0.161 sec/batch; 12h:52m:36s remains)
INFO - root - 2017-12-01 04:33:28.955213: step 44740, loss = 0.47, batch loss = 0.28 (50.8 examples/sec; 0.158 sec/batch; 12h:35m:22s remains)
INFO - root - 2017-12-01 04:33:30.518286: step 44750, loss = 0.37, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 12h:33m:57s remains)
INFO - root - 2017-12-01 04:33:32.086694: step 44760, loss = 0.39, batch loss = 0.20 (49.1 examples/sec; 0.163 sec/batch; 13h:01m:42s remains)
INFO - root - 2017-12-01 04:33:33.648663: step 44770, loss = 0.40, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 12h:43m:46s remains)
INFO - root - 2017-12-01 04:33:35.223167: step 44780, loss = 0.46, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 12h:30m:52s remains)
INFO - root - 2017-12-01 04:33:36.774456: step 44790, loss = 0.45, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 12h:24m:32s remains)
INFO - root - 2017-12-01 04:33:38.313929: step 44800, loss = 0.41, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 12h:29m:26s remains)
INFO - root - 2017-12-01 04:33:39.938793: step 44810, loss = 0.46, batch loss = 0.27 (49.8 examples/sec; 0.161 sec/batch; 12h:50m:36s remains)
INFO - root - 2017-12-01 04:33:41.508170: step 44820, loss = 0.43, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 12h:17m:56s remains)
INFO - root - 2017-12-01 04:33:43.068263: step 44830, loss = 0.34, batch loss = 0.15 (51.1 examples/sec; 0.156 sec/batch; 12h:30m:17s remains)
INFO - root - 2017-12-01 04:33:44.635698: step 44840, loss = 0.43, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 12h:25m:41s remains)
INFO - root - 2017-12-01 04:33:46.197292: step 44850, loss = 0.49, batch loss = 0.30 (52.7 examples/sec; 0.152 sec/batch; 12h:08m:22s remains)
INFO - root - 2017-12-01 04:33:47.766458: step 44860, loss = 0.44, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 12h:22m:34s remains)
INFO - root - 2017-12-01 04:33:49.341850: step 44870, loss = 0.49, batch loss = 0.30 (52.6 examples/sec; 0.152 sec/batch; 12h:08m:44s remains)
INFO - root - 2017-12-01 04:33:50.901725: step 44880, loss = 0.45, batch loss = 0.25 (50.2 examples/sec; 0.159 sec/batch; 12h:44m:17s remains)
INFO - root - 2017-12-01 04:33:52.460291: step 44890, loss = 0.38, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 12h:09m:57s remains)
INFO - root - 2017-12-01 04:33:54.040094: step 44900, loss = 0.64, batch loss = 0.45 (51.0 examples/sec; 0.157 sec/batch; 12h:32m:08s remains)
INFO - root - 2017-12-01 04:33:55.680311: step 44910, loss = 0.47, batch loss = 0.28 (49.6 examples/sec; 0.161 sec/batch; 12h:53m:44s remains)
INFO - root - 2017-12-01 04:33:57.244024: step 44920, loss = 0.55, batch loss = 0.36 (51.7 examples/sec; 0.155 sec/batch; 12h:21m:35s remains)
INFO - root - 2017-12-01 04:33:58.827394: step 44930, loss = 0.45, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 12h:38m:31s remains)
INFO - root - 2017-12-01 04:34:00.380976: step 44940, loss = 0.45, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 12h:32m:51s remains)
INFO - root - 2017-12-01 04:34:01.952978: step 44950, loss = 0.40, batch loss = 0.21 (49.9 examples/sec; 0.160 sec/batch; 12h:48m:19s remains)
INFO - root - 2017-12-01 04:34:03.521464: step 44960, loss = 0.45, batch loss = 0.26 (53.0 examples/sec; 0.151 sec/batch; 12h:03m:00s remains)
INFO - root - 2017-12-01 04:34:05.082964: step 44970, loss = 0.57, batch loss = 0.38 (52.4 examples/sec; 0.153 sec/batch; 12h:11m:52s remains)
INFO - root - 2017-12-01 04:34:06.638743: step 44980, loss = 0.45, batch loss = 0.26 (52.5 examples/sec; 0.152 sec/batch; 12h:10m:24s remains)
INFO - root - 2017-12-01 04:34:08.224957: step 44990, loss = 0.40, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 12h:34m:13s remains)
INFO - root - 2017-12-01 04:34:09.800633: step 45000, loss = 0.46, batch loss = 0.27 (49.1 examples/sec; 0.163 sec/batch; 13h:01m:22s remains)
INFO - root - 2017-12-01 04:34:11.459217: step 45010, loss = 0.39, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 12h:24m:27s remains)
INFO - root - 2017-12-01 04:34:13.028410: step 45020, loss = 0.65, batch loss = 0.46 (49.2 examples/sec; 0.163 sec/batch; 12h:59m:25s remains)
INFO - root - 2017-12-01 04:34:14.602696: step 45030, loss = 0.49, batch loss = 0.30 (52.2 examples/sec; 0.153 sec/batch; 12h:14m:13s remains)
INFO - root - 2017-12-01 04:34:16.162243: step 45040, loss = 0.56, batch loss = 0.37 (51.7 examples/sec; 0.155 sec/batch; 12h:21m:14s remains)
INFO - root - 2017-12-01 04:34:17.733066: step 45050, loss = 0.38, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 12h:20m:44s remains)
INFO - root - 2017-12-01 04:34:19.282463: step 45060, loss = 0.47, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 12h:27m:17s remains)
INFO - root - 2017-12-01 04:34:20.857320: step 45070, loss = 0.37, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 12h:25m:23s remains)
INFO - root - 2017-12-01 04:34:22.404801: step 45080, loss = 0.40, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 12h:36m:08s remains)
INFO - root - 2017-12-01 04:34:23.997291: step 45090, loss = 0.50, batch loss = 0.31 (51.5 examples/sec; 0.155 sec/batch; 12h:23m:28s remains)
INFO - root - 2017-12-01 04:34:25.552282: step 45100, loss = 0.38, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 12h:27m:54s remains)
INFO - root - 2017-12-01 04:34:27.189415: step 45110, loss = 0.36, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 12h:23m:34s remains)
INFO - root - 2017-12-01 04:34:28.736466: step 45120, loss = 0.57, batch loss = 0.38 (52.1 examples/sec; 0.153 sec/batch; 12h:14m:47s remains)
INFO - root - 2017-12-01 04:34:30.302299: step 45130, loss = 0.42, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 12h:36m:34s remains)
INFO - root - 2017-12-01 04:34:31.891399: step 45140, loss = 0.54, batch loss = 0.35 (48.9 examples/sec; 0.163 sec/batch; 13h:02m:55s remains)
INFO - root - 2017-12-01 04:34:33.477096: step 45150, loss = 0.33, batch loss = 0.14 (50.9 examples/sec; 0.157 sec/batch; 12h:32m:51s remains)
INFO - root - 2017-12-01 04:34:35.059971: step 45160, loss = 0.36, batch loss = 0.17 (51.1 examples/sec; 0.156 sec/batch; 12h:29m:02s remains)
INFO - root - 2017-12-01 04:34:36.619879: step 45170, loss = 0.46, batch loss = 0.27 (49.9 examples/sec; 0.160 sec/batch; 12h:47m:49s remains)
INFO - root - 2017-12-01 04:34:38.172452: step 45180, loss = 0.42, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 12h:23m:46s remains)
INFO - root - 2017-12-01 04:34:39.748191: step 45190, loss = 0.36, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 12h:25m:23s remains)
INFO - root - 2017-12-01 04:34:41.325893: step 45200, loss = 0.47, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 12h:27m:44s remains)
INFO - root - 2017-12-01 04:34:42.989688: step 45210, loss = 0.47, batch loss = 0.28 (52.5 examples/sec; 0.152 sec/batch; 12h:09m:00s remains)
INFO - root - 2017-12-01 04:34:44.556687: step 45220, loss = 0.43, batch loss = 0.24 (49.2 examples/sec; 0.163 sec/batch; 12h:58m:20s remains)
INFO - root - 2017-12-01 04:34:46.132588: step 45230, loss = 0.40, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 12h:39m:41s remains)
INFO - root - 2017-12-01 04:34:47.691016: step 45240, loss = 0.44, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 12h:18m:43s remains)
INFO - root - 2017-12-01 04:34:49.260421: step 45250, loss = 0.39, batch loss = 0.20 (52.5 examples/sec; 0.152 sec/batch; 12h:09m:20s remains)
INFO - root - 2017-12-01 04:34:50.867925: step 45260, loss = 0.42, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 12h:35m:06s remains)
INFO - root - 2017-12-01 04:34:52.435813: step 45270, loss = 0.39, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 12h:20m:42s remains)
INFO - root - 2017-12-01 04:34:53.992832: step 45280, loss = 0.45, batch loss = 0.26 (52.1 examples/sec; 0.154 sec/batch; 12h:14m:54s remains)
INFO - root - 2017-12-01 04:34:55.576194: step 45290, loss = 0.43, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 12h:31m:22s remains)
INFO - root - 2017-12-01 04:34:57.153627: step 45300, loss = 0.46, batch loss = 0.27 (49.9 examples/sec; 0.160 sec/batch; 12h:47m:25s remains)
INFO - root - 2017-12-01 04:34:58.767368: step 45310, loss = 0.39, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 12h:19m:24s remains)
INFO - root - 2017-12-01 04:35:00.337775: step 45320, loss = 0.40, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 12h:17m:59s remains)
INFO - root - 2017-12-01 04:35:01.916303: step 45330, loss = 0.46, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 12h:30m:12s remains)
INFO - root - 2017-12-01 04:35:03.479557: step 45340, loss = 0.46, batch loss = 0.27 (50.8 examples/sec; 0.157 sec/batch; 12h:33m:21s remains)
INFO - root - 2017-12-01 04:35:05.045938: step 45350, loss = 0.41, batch loss = 0.22 (48.8 examples/sec; 0.164 sec/batch; 13h:03m:50s remains)
INFO - root - 2017-12-01 04:35:06.619206: step 45360, loss = 0.41, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 12h:21m:12s remains)
INFO - root - 2017-12-01 04:35:08.179375: step 45370, loss = 0.38, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 12h:10m:45s remains)
INFO - root - 2017-12-01 04:35:09.761350: step 45380, loss = 0.53, batch loss = 0.34 (51.6 examples/sec; 0.155 sec/batch; 12h:21m:16s remains)
INFO - root - 2017-12-01 04:35:11.324839: step 45390, loss = 0.63, batch loss = 0.44 (50.7 examples/sec; 0.158 sec/batch; 12h:35m:38s remains)
INFO - root - 2017-12-01 04:35:12.891243: step 45400, loss = 0.39, batch loss = 0.20 (52.9 examples/sec; 0.151 sec/batch; 12h:03m:40s remains)
INFO - root - 2017-12-01 04:35:14.494333: step 45410, loss = 0.39, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 12h:18m:26s remains)
INFO - root - 2017-12-01 04:35:16.063779: step 45420, loss = 0.44, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 12h:30m:55s remains)
INFO - root - 2017-12-01 04:35:17.635550: step 45430, loss = 0.39, batch loss = 0.20 (53.6 examples/sec; 0.149 sec/batch; 11h:54m:12s remains)
INFO - root - 2017-12-01 04:35:19.196078: step 45440, loss = 0.38, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 12h:09m:20s remains)
INFO - root - 2017-12-01 04:35:20.774941: step 45450, loss = 0.42, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 12h:26m:02s remains)
INFO - root - 2017-12-01 04:35:22.320329: step 45460, loss = 0.49, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 12h:35m:04s remains)
INFO - root - 2017-12-01 04:35:23.918568: step 45470, loss = 0.46, batch loss = 0.27 (49.3 examples/sec; 0.162 sec/batch; 12h:56m:37s remains)
INFO - root - 2017-12-01 04:35:25.476554: step 45480, loss = 0.41, batch loss = 0.22 (52.9 examples/sec; 0.151 sec/batch; 12h:03m:00s remains)
INFO - root - 2017-12-01 04:35:27.036720: step 45490, loss = 0.34, batch loss = 0.15 (52.1 examples/sec; 0.153 sec/batch; 12h:13m:49s remains)
INFO - root - 2017-12-01 04:35:28.600582: step 45500, loss = 0.41, batch loss = 0.22 (51.1 examples/sec; 0.156 sec/batch; 12h:28m:16s remains)
INFO - root - 2017-12-01 04:35:30.226448: step 45510, loss = 0.41, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 12h:24m:18s remains)
INFO - root - 2017-12-01 04:35:31.816059: step 45520, loss = 0.47, batch loss = 0.28 (51.8 examples/sec; 0.155 sec/batch; 12h:19m:14s remains)
INFO - root - 2017-12-01 04:35:33.396565: step 45530, loss = 0.50, batch loss = 0.31 (49.8 examples/sec; 0.161 sec/batch; 12h:47m:46s remains)
INFO - root - 2017-12-01 04:35:34.955185: step 45540, loss = 0.44, batch loss = 0.25 (50.8 examples/sec; 0.158 sec/batch; 12h:33m:31s remains)
INFO - root - 2017-12-01 04:35:36.534407: step 45550, loss = 0.43, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 12h:25m:14s remains)
INFO - root - 2017-12-01 04:35:38.093343: step 45560, loss = 0.42, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 12h:20m:49s remains)
INFO - root - 2017-12-01 04:35:39.649440: step 45570, loss = 0.35, batch loss = 0.16 (50.1 examples/sec; 0.160 sec/batch; 12h:43m:25s remains)
INFO - root - 2017-12-01 04:35:41.203957: step 45580, loss = 0.45, batch loss = 0.26 (51.1 examples/sec; 0.157 sec/batch; 12h:28m:52s remains)
INFO - root - 2017-12-01 04:35:42.748761: step 45590, loss = 0.52, batch loss = 0.33 (50.1 examples/sec; 0.160 sec/batch; 12h:43m:51s remains)
INFO - root - 2017-12-01 04:35:44.336654: step 45600, loss = 0.43, batch loss = 0.24 (48.9 examples/sec; 0.164 sec/batch; 13h:02m:55s remains)
INFO - root - 2017-12-01 04:35:45.945494: step 45610, loss = 0.43, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 12h:32m:09s remains)
INFO - root - 2017-12-01 04:35:47.500518: step 45620, loss = 0.46, batch loss = 0.27 (50.2 examples/sec; 0.159 sec/batch; 12h:42m:05s remains)
INFO - root - 2017-12-01 04:35:49.057820: step 45630, loss = 0.39, batch loss = 0.20 (49.6 examples/sec; 0.161 sec/batch; 12h:51m:40s remains)
INFO - root - 2017-12-01 04:35:50.626441: step 45640, loss = 0.46, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 12h:22m:29s remains)
INFO - root - 2017-12-01 04:35:52.199721: step 45650, loss = 0.39, batch loss = 0.20 (52.5 examples/sec; 0.152 sec/batch; 12h:07m:50s remains)
INFO - root - 2017-12-01 04:35:53.767302: step 45660, loss = 0.46, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 12h:31m:26s remains)
INFO - root - 2017-12-01 04:35:55.319575: step 45670, loss = 0.41, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 12h:24m:42s remains)
INFO - root - 2017-12-01 04:35:56.865243: step 45680, loss = 0.36, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 12h:21m:23s remains)
INFO - root - 2017-12-01 04:35:58.403501: step 45690, loss = 0.38, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 12h:21m:30s remains)
INFO - root - 2017-12-01 04:35:59.953886: step 45700, loss = 0.36, batch loss = 0.17 (52.1 examples/sec; 0.153 sec/batch; 12h:13m:16s remains)
INFO - root - 2017-12-01 04:36:01.602835: step 45710, loss = 0.40, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 12h:24m:50s remains)
INFO - root - 2017-12-01 04:36:03.176297: step 45720, loss = 0.53, batch loss = 0.34 (51.1 examples/sec; 0.157 sec/batch; 12h:28m:58s remains)
INFO - root - 2017-12-01 04:36:04.755072: step 45730, loss = 0.50, batch loss = 0.31 (50.8 examples/sec; 0.158 sec/batch; 12h:33m:12s remains)
INFO - root - 2017-12-01 04:36:06.309332: step 45740, loss = 0.46, batch loss = 0.27 (51.9 examples/sec; 0.154 sec/batch; 12h:16m:41s remains)
INFO - root - 2017-12-01 04:36:07.889765: step 45750, loss = 0.56, batch loss = 0.37 (50.6 examples/sec; 0.158 sec/batch; 12h:36m:09s remains)
INFO - root - 2017-12-01 04:36:09.444371: step 45760, loss = 0.47, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 12h:34m:33s remains)
INFO - root - 2017-12-01 04:36:11.012088: step 45770, loss = 0.51, batch loss = 0.32 (49.5 examples/sec; 0.162 sec/batch; 12h:52m:26s remains)
INFO - root - 2017-12-01 04:36:12.573238: step 45780, loss = 0.37, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 12h:20m:08s remains)
INFO - root - 2017-12-01 04:36:14.137052: step 45790, loss = 0.39, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 12h:13m:51s remains)
INFO - root - 2017-12-01 04:36:15.695501: step 45800, loss = 0.44, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 12h:25m:07s remains)
INFO - root - 2017-12-01 04:36:17.345377: step 45810, loss = 0.39, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 12h:40m:21s remains)
INFO - root - 2017-12-01 04:36:18.912279: step 45820, loss = 0.47, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 12h:35m:04s remains)
INFO - root - 2017-12-01 04:36:20.483604: step 45830, loss = 0.40, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 12h:29m:58s remains)
INFO - root - 2017-12-01 04:36:22.047852: step 45840, loss = 0.40, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 12h:34m:09s remains)
INFO - root - 2017-12-01 04:36:23.599154: step 45850, loss = 0.52, batch loss = 0.33 (51.9 examples/sec; 0.154 sec/batch; 12h:16m:22s remains)
INFO - root - 2017-12-01 04:36:25.170393: step 45860, loss = 0.64, batch loss = 0.45 (49.5 examples/sec; 0.162 sec/batch; 12h:52m:24s remains)
INFO - root - 2017-12-01 04:36:26.726232: step 45870, loss = 0.38, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 12h:19m:56s remains)
INFO - root - 2017-12-01 04:36:28.298726: step 45880, loss = 0.45, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 12h:21m:35s remains)
INFO - root - 2017-12-01 04:36:29.863886: step 45890, loss = 0.47, batch loss = 0.28 (49.3 examples/sec; 0.162 sec/batch; 12h:54m:47s remains)
INFO - root - 2017-12-01 04:36:31.430804: step 45900, loss = 0.47, batch loss = 0.28 (49.5 examples/sec; 0.162 sec/batch; 12h:51m:47s remains)
INFO - root - 2017-12-01 04:36:33.073416: step 45910, loss = 0.37, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 12h:40m:27s remains)
INFO - root - 2017-12-01 04:36:34.643855: step 45920, loss = 0.51, batch loss = 0.32 (50.6 examples/sec; 0.158 sec/batch; 12h:35m:34s remains)
INFO - root - 2017-12-01 04:36:36.216030: step 45930, loss = 0.39, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 12h:18m:53s remains)
INFO - root - 2017-12-01 04:36:37.772678: step 45940, loss = 0.49, batch loss = 0.30 (52.0 examples/sec; 0.154 sec/batch; 12h:15m:07s remains)
INFO - root - 2017-12-01 04:36:39.312939: step 45950, loss = 0.50, batch loss = 0.31 (52.6 examples/sec; 0.152 sec/batch; 12h:06m:12s remains)
INFO - root - 2017-12-01 04:36:40.888302: step 45960, loss = 0.46, batch loss = 0.27 (50.5 examples/sec; 0.158 sec/batch; 12h:35m:50s remains)
INFO - root - 2017-12-01 04:36:42.436231: step 45970, loss = 0.59, batch loss = 0.40 (51.6 examples/sec; 0.155 sec/batch; 12h:19m:47s remains)
INFO - root - 2017-12-01 04:36:43.997185: step 45980, loss = 0.40, batch loss = 0.21 (53.3 examples/sec; 0.150 sec/batch; 11h:56m:26s remains)
INFO - root - 2017-12-01 04:36:45.565649: step 45990, loss = 0.41, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 12h:15m:54s remains)
INFO - root - 2017-12-01 04:36:47.150314: step 46000, loss = 0.37, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 12h:32m:01s remains)
INFO - root - 2017-12-01 04:36:48.780291: step 46010, loss = 0.42, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 12h:35m:32s remains)
INFO - root - 2017-12-01 04:36:50.332757: step 46020, loss = 0.38, batch loss = 0.19 (52.8 examples/sec; 0.152 sec/batch; 12h:03m:22s remains)
INFO - root - 2017-12-01 04:36:51.910839: step 46030, loss = 0.40, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 12h:33m:51s remains)
INFO - root - 2017-12-01 04:36:53.467039: step 46040, loss = 0.51, batch loss = 0.32 (52.9 examples/sec; 0.151 sec/batch; 12h:01m:45s remains)
INFO - root - 2017-12-01 04:36:55.030268: step 46050, loss = 0.44, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 12h:29m:42s remains)
INFO - root - 2017-12-01 04:36:56.623197: step 46060, loss = 0.42, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 12h:18m:26s remains)
INFO - root - 2017-12-01 04:36:58.185324: step 46070, loss = 0.53, batch loss = 0.34 (50.8 examples/sec; 0.157 sec/batch; 12h:31m:29s remains)
INFO - root - 2017-12-01 04:36:59.753827: step 46080, loss = 0.59, batch loss = 0.41 (49.7 examples/sec; 0.161 sec/batch; 12h:48m:26s remains)
INFO - root - 2017-12-01 04:37:01.300489: step 46090, loss = 0.40, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 12h:29m:06s remains)
INFO - root - 2017-12-01 04:37:02.877129: step 46100, loss = 0.51, batch loss = 0.32 (52.3 examples/sec; 0.153 sec/batch; 12h:10m:43s remains)
INFO - root - 2017-12-01 04:37:04.512663: step 46110, loss = 0.39, batch loss = 0.20 (53.6 examples/sec; 0.149 sec/batch; 11h:52m:11s remains)
INFO - root - 2017-12-01 04:37:06.078541: step 46120, loss = 0.41, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 12h:15m:53s remains)
INFO - root - 2017-12-01 04:37:07.628094: step 46130, loss = 0.39, batch loss = 0.20 (53.3 examples/sec; 0.150 sec/batch; 11h:56m:43s remains)
INFO - root - 2017-12-01 04:37:09.180807: step 46140, loss = 0.41, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 12h:22m:55s remains)
INFO - root - 2017-12-01 04:37:10.772067: step 46150, loss = 0.45, batch loss = 0.26 (46.6 examples/sec; 0.172 sec/batch; 13h:39m:05s remains)
INFO - root - 2017-12-01 04:37:12.331973: step 46160, loss = 0.47, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 12h:33m:45s remains)
INFO - root - 2017-12-01 04:37:13.884550: step 46170, loss = 0.47, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 12h:18m:44s remains)
INFO - root - 2017-12-01 04:37:15.457466: step 46180, loss = 0.50, batch loss = 0.31 (52.8 examples/sec; 0.152 sec/batch; 12h:03m:14s remains)
INFO - root - 2017-12-01 04:37:17.049606: step 46190, loss = 0.50, batch loss = 0.31 (50.7 examples/sec; 0.158 sec/batch; 12h:32m:43s remains)
INFO - root - 2017-12-01 04:37:18.612351: step 46200, loss = 0.39, batch loss = 0.20 (50.5 examples/sec; 0.159 sec/batch; 12h:36m:29s remains)
INFO - root - 2017-12-01 04:37:20.269353: step 46210, loss = 0.44, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 12h:28m:46s remains)
INFO - root - 2017-12-01 04:37:21.825695: step 46220, loss = 0.40, batch loss = 0.22 (49.6 examples/sec; 0.161 sec/batch; 12h:49m:32s remains)
INFO - root - 2017-12-01 04:37:23.402106: step 46230, loss = 0.43, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 12h:34m:37s remains)
INFO - root - 2017-12-01 04:37:24.951049: step 46240, loss = 0.47, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 12h:23m:07s remains)
INFO - root - 2017-12-01 04:37:26.526673: step 46250, loss = 0.44, batch loss = 0.25 (53.0 examples/sec; 0.151 sec/batch; 12h:00m:28s remains)
INFO - root - 2017-12-01 04:37:28.095590: step 46260, loss = 0.47, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 12h:28m:30s remains)
INFO - root - 2017-12-01 04:37:29.660345: step 46270, loss = 0.48, batch loss = 0.29 (49.8 examples/sec; 0.161 sec/batch; 12h:46m:59s remains)
INFO - root - 2017-12-01 04:37:31.265486: step 46280, loss = 0.49, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 12h:21m:38s remains)
INFO - root - 2017-12-01 04:37:32.826668: step 46290, loss = 0.37, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 12h:09m:14s remains)
INFO - root - 2017-12-01 04:37:34.388275: step 46300, loss = 0.54, batch loss = 0.35 (51.0 examples/sec; 0.157 sec/batch; 12h:28m:33s remains)
INFO - root - 2017-12-01 04:37:36.000726: step 46310, loss = 0.42, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 12h:04m:17s remains)
INFO - root - 2017-12-01 04:37:37.560359: step 46320, loss = 0.38, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 12h:21m:23s remains)
INFO - root - 2017-12-01 04:37:39.130654: step 46330, loss = 0.44, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 12h:33m:20s remains)
INFO - root - 2017-12-01 04:37:40.687409: step 46340, loss = 0.42, batch loss = 0.23 (49.8 examples/sec; 0.161 sec/batch; 12h:46m:53s remains)
INFO - root - 2017-12-01 04:37:42.250058: step 46350, loss = 0.41, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 12h:16m:39s remains)
INFO - root - 2017-12-01 04:37:43.826822: step 46360, loss = 0.44, batch loss = 0.25 (52.2 examples/sec; 0.153 sec/batch; 12h:11m:02s remains)
INFO - root - 2017-12-01 04:37:45.401682: step 46370, loss = 0.39, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 12h:12m:32s remains)
INFO - root - 2017-12-01 04:37:46.956847: step 46380, loss = 0.38, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 12h:19m:17s remains)
INFO - root - 2017-12-01 04:37:48.528104: step 46390, loss = 0.37, batch loss = 0.18 (50.0 examples/sec; 0.160 sec/batch; 12h:42m:41s remains)
INFO - root - 2017-12-01 04:37:50.080459: step 46400, loss = 0.58, batch loss = 0.39 (51.6 examples/sec; 0.155 sec/batch; 12h:19m:36s remains)
INFO - root - 2017-12-01 04:37:51.755250: step 46410, loss = 0.61, batch loss = 0.42 (49.7 examples/sec; 0.161 sec/batch; 12h:47m:28s remains)
INFO - root - 2017-12-01 04:37:53.310833: step 46420, loss = 0.50, batch loss = 0.31 (50.7 examples/sec; 0.158 sec/batch; 12h:31m:57s remains)
INFO - root - 2017-12-01 04:37:54.881138: step 46430, loss = 0.48, batch loss = 0.29 (51.1 examples/sec; 0.157 sec/batch; 12h:27m:02s remains)
INFO - root - 2017-12-01 04:37:56.453941: step 46440, loss = 0.39, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 12h:04m:48s remains)
INFO - root - 2017-12-01 04:37:58.053451: step 46450, loss = 0.45, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 12h:16m:04s remains)
INFO - root - 2017-12-01 04:37:59.623133: step 46460, loss = 0.52, batch loss = 0.33 (50.7 examples/sec; 0.158 sec/batch; 12h:31m:41s remains)
INFO - root - 2017-12-01 04:38:01.170429: step 46470, loss = 0.47, batch loss = 0.28 (53.4 examples/sec; 0.150 sec/batch; 11h:54m:45s remains)
INFO - root - 2017-12-01 04:38:02.720818: step 46480, loss = 0.43, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 12h:20m:19s remains)
INFO - root - 2017-12-01 04:38:04.288727: step 46490, loss = 0.40, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 12h:29m:33s remains)
INFO - root - 2017-12-01 04:38:05.854347: step 46500, loss = 0.47, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 12h:29m:06s remains)
INFO - root - 2017-12-01 04:38:07.482437: step 46510, loss = 0.44, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 12h:16m:02s remains)
INFO - root - 2017-12-01 04:38:09.065880: step 46520, loss = 0.35, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 12h:19m:27s remains)
INFO - root - 2017-12-01 04:38:10.619066: step 46530, loss = 0.40, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 12h:28m:45s remains)
INFO - root - 2017-12-01 04:38:12.181838: step 46540, loss = 0.39, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 12h:28m:23s remains)
INFO - root - 2017-12-01 04:38:13.741306: step 46550, loss = 0.48, batch loss = 0.29 (52.3 examples/sec; 0.153 sec/batch; 12h:09m:00s remains)
INFO - root - 2017-12-01 04:38:15.321593: step 46560, loss = 0.41, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 12h:13m:21s remains)
INFO - root - 2017-12-01 04:38:16.878036: step 46570, loss = 0.45, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 12h:31m:23s remains)
INFO - root - 2017-12-01 04:38:18.416653: step 46580, loss = 0.42, batch loss = 0.23 (51.8 examples/sec; 0.155 sec/batch; 12h:16m:39s remains)
INFO - root - 2017-12-01 04:38:19.980057: step 46590, loss = 0.53, batch loss = 0.34 (50.4 examples/sec; 0.159 sec/batch; 12h:36m:52s remains)
INFO - root - 2017-12-01 04:38:21.542084: step 46600, loss = 0.49, batch loss = 0.30 (51.6 examples/sec; 0.155 sec/batch; 12h:19m:27s remains)
INFO - root - 2017-12-01 04:38:23.188558: step 46610, loss = 0.41, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 12h:28m:37s remains)
INFO - root - 2017-12-01 04:38:24.749721: step 46620, loss = 0.39, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 12h:43m:50s remains)
INFO - root - 2017-12-01 04:38:26.324172: step 46630, loss = 0.45, batch loss = 0.26 (50.1 examples/sec; 0.160 sec/batch; 12h:41m:05s remains)
INFO - root - 2017-12-01 04:38:27.897611: step 46640, loss = 0.49, batch loss = 0.30 (52.1 examples/sec; 0.153 sec/batch; 12h:11m:03s remains)
INFO - root - 2017-12-01 04:38:29.465637: step 46650, loss = 0.43, batch loss = 0.25 (51.8 examples/sec; 0.155 sec/batch; 12h:16m:09s remains)
INFO - root - 2017-12-01 04:38:31.025983: step 46660, loss = 0.51, batch loss = 0.32 (51.6 examples/sec; 0.155 sec/batch; 12h:18m:22s remains)
INFO - root - 2017-12-01 04:38:32.592233: step 46670, loss = 0.39, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 12h:20m:51s remains)
INFO - root - 2017-12-01 04:38:34.199643: step 46680, loss = 0.48, batch loss = 0.29 (51.1 examples/sec; 0.157 sec/batch; 12h:26m:19s remains)
INFO - root - 2017-12-01 04:38:35.772463: step 46690, loss = 0.34, batch loss = 0.15 (50.5 examples/sec; 0.158 sec/batch; 12h:34m:04s remains)
INFO - root - 2017-12-01 04:38:37.336351: step 46700, loss = 0.49, batch loss = 0.30 (47.5 examples/sec; 0.168 sec/batch; 13h:21m:41s remains)
INFO - root - 2017-12-01 04:38:38.982235: step 46710, loss = 0.45, batch loss = 0.26 (49.7 examples/sec; 0.161 sec/batch; 12h:46m:42s remains)
INFO - root - 2017-12-01 04:38:40.581620: step 46720, loss = 0.49, batch loss = 0.30 (48.3 examples/sec; 0.166 sec/batch; 13h:09m:32s remains)
INFO - root - 2017-12-01 04:38:42.171094: step 46730, loss = 0.35, batch loss = 0.17 (52.1 examples/sec; 0.154 sec/batch; 12h:11m:09s remains)
INFO - root - 2017-12-01 04:38:43.733419: step 46740, loss = 0.44, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 12h:29m:10s remains)
INFO - root - 2017-12-01 04:38:45.297385: step 46750, loss = 0.51, batch loss = 0.33 (52.2 examples/sec; 0.153 sec/batch; 12h:09m:46s remains)
INFO - root - 2017-12-01 04:38:46.861405: step 46760, loss = 0.41, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 12h:11m:17s remains)
INFO - root - 2017-12-01 04:38:48.434591: step 46770, loss = 0.38, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 12h:26m:45s remains)
INFO - root - 2017-12-01 04:38:49.998150: step 46780, loss = 0.50, batch loss = 0.32 (51.2 examples/sec; 0.156 sec/batch; 12h:24m:41s remains)
INFO - root - 2017-12-01 04:38:51.567055: step 46790, loss = 0.38, batch loss = 0.19 (51.8 examples/sec; 0.155 sec/batch; 12h:15m:45s remains)
INFO - root - 2017-12-01 04:38:53.119106: step 46800, loss = 0.41, batch loss = 0.22 (49.4 examples/sec; 0.162 sec/batch; 12h:50m:54s remains)
INFO - root - 2017-12-01 04:38:54.739814: step 46810, loss = 0.45, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 12h:32m:58s remains)
INFO - root - 2017-12-01 04:38:56.318330: step 46820, loss = 0.44, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 12h:18m:38s remains)
INFO - root - 2017-12-01 04:38:57.872680: step 46830, loss = 0.42, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 12h:37m:03s remains)
INFO - root - 2017-12-01 04:38:59.434478: step 46840, loss = 0.33, batch loss = 0.14 (51.3 examples/sec; 0.156 sec/batch; 12h:22m:32s remains)
INFO - root - 2017-12-01 04:39:01.008928: step 46850, loss = 0.42, batch loss = 0.23 (51.1 examples/sec; 0.156 sec/batch; 12h:24m:57s remains)
INFO - root - 2017-12-01 04:39:02.605140: step 46860, loss = 0.42, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 12h:36m:39s remains)
INFO - root - 2017-12-01 04:39:04.184754: step 46870, loss = 0.43, batch loss = 0.24 (49.7 examples/sec; 0.161 sec/batch; 12h:45m:36s remains)
INFO - root - 2017-12-01 04:39:05.748047: step 46880, loss = 0.58, batch loss = 0.39 (51.8 examples/sec; 0.155 sec/batch; 12h:15m:29s remains)
INFO - root - 2017-12-01 04:39:07.340480: step 46890, loss = 0.39, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 12h:17m:30s remains)
INFO - root - 2017-12-01 04:39:08.909792: step 46900, loss = 0.51, batch loss = 0.32 (50.3 examples/sec; 0.159 sec/batch; 12h:36m:32s remains)
INFO - root - 2017-12-01 04:39:10.525382: step 46910, loss = 0.47, batch loss = 0.28 (52.2 examples/sec; 0.153 sec/batch; 12h:08m:48s remains)
INFO - root - 2017-12-01 04:39:12.087403: step 46920, loss = 0.38, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 12h:12m:57s remains)
INFO - root - 2017-12-01 04:39:13.646942: step 46930, loss = 0.46, batch loss = 0.27 (50.8 examples/sec; 0.158 sec/batch; 12h:29m:45s remains)
INFO - root - 2017-12-01 04:39:15.216707: step 46940, loss = 0.42, batch loss = 0.23 (50.0 examples/sec; 0.160 sec/batch; 12h:41m:22s remains)
INFO - root - 2017-12-01 04:39:16.766077: step 46950, loss = 0.43, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 12h:36m:49s remains)
INFO - root - 2017-12-01 04:39:18.317756: step 46960, loss = 0.42, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 12h:03m:34s remains)
INFO - root - 2017-12-01 04:39:19.923470: step 46970, loss = 0.36, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 12h:13m:05s remains)
INFO - root - 2017-12-01 04:39:21.481887: step 46980, loss = 0.44, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 12h:27m:20s remains)
INFO - root - 2017-12-01 04:39:23.050894: step 46990, loss = 0.47, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 12h:34m:11s remains)
INFO - root - 2017-12-01 04:39:24.606607: step 47000, loss = 0.43, batch loss = 0.25 (53.2 examples/sec; 0.150 sec/batch; 11h:55m:38s remains)
INFO - root - 2017-12-01 04:39:26.227275: step 47010, loss = 0.58, batch loss = 0.39 (52.0 examples/sec; 0.154 sec/batch; 12h:12m:14s remains)
INFO - root - 2017-12-01 04:39:27.788214: step 47020, loss = 0.41, batch loss = 0.22 (49.4 examples/sec; 0.162 sec/batch; 12h:50m:24s remains)
INFO - root - 2017-12-01 04:39:29.342328: step 47030, loss = 0.39, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 12h:07m:24s remains)
INFO - root - 2017-12-01 04:39:30.908026: step 47040, loss = 0.57, batch loss = 0.39 (51.9 examples/sec; 0.154 sec/batch; 12h:13m:45s remains)
INFO - root - 2017-12-01 04:39:32.473661: step 47050, loss = 0.53, batch loss = 0.34 (51.5 examples/sec; 0.155 sec/batch; 12h:19m:06s remains)
INFO - root - 2017-12-01 04:39:34.059128: step 47060, loss = 0.52, batch loss = 0.33 (49.8 examples/sec; 0.161 sec/batch; 12h:44m:58s remains)
INFO - root - 2017-12-01 04:39:35.606023: step 47070, loss = 0.37, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 12h:14m:00s remains)
INFO - root - 2017-12-01 04:39:37.167751: step 47080, loss = 0.40, batch loss = 0.22 (52.4 examples/sec; 0.153 sec/batch; 12h:06m:20s remains)
INFO - root - 2017-12-01 04:39:38.725976: step 47090, loss = 0.51, batch loss = 0.32 (51.3 examples/sec; 0.156 sec/batch; 12h:21m:51s remains)
INFO - root - 2017-12-01 04:39:40.318089: step 47100, loss = 0.40, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 12h:16m:01s remains)
INFO - root - 2017-12-01 04:39:41.979975: step 47110, loss = 0.39, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 12h:20m:15s remains)
INFO - root - 2017-12-01 04:39:43.534547: step 47120, loss = 0.50, batch loss = 0.32 (52.9 examples/sec; 0.151 sec/batch; 11h:58m:56s remains)
INFO - root - 2017-12-01 04:39:45.114973: step 47130, loss = 0.48, batch loss = 0.29 (51.1 examples/sec; 0.156 sec/batch; 12h:24m:18s remains)
INFO - root - 2017-12-01 04:39:46.680170: step 47140, loss = 0.41, batch loss = 0.23 (48.2 examples/sec; 0.166 sec/batch; 13h:08m:51s remains)
INFO - root - 2017-12-01 04:39:48.265903: step 47150, loss = 0.43, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 12h:41m:42s remains)
INFO - root - 2017-12-01 04:39:49.812551: step 47160, loss = 0.40, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 12h:14m:09s remains)
INFO - root - 2017-12-01 04:39:51.378164: step 47170, loss = 0.48, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 12h:16m:53s remains)
INFO - root - 2017-12-01 04:39:52.938511: step 47180, loss = 0.45, batch loss = 0.26 (49.5 examples/sec; 0.162 sec/batch; 12h:48m:07s remains)
INFO - root - 2017-12-01 04:39:54.502024: step 47190, loss = 0.41, batch loss = 0.22 (49.2 examples/sec; 0.163 sec/batch; 12h:53m:35s remains)
INFO - root - 2017-12-01 04:39:56.130155: step 47200, loss = 0.41, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 12h:28m:18s remains)
INFO - root - 2017-12-01 04:39:57.742518: step 47210, loss = 0.46, batch loss = 0.27 (52.6 examples/sec; 0.152 sec/batch; 12h:02m:36s remains)
INFO - root - 2017-12-01 04:39:59.313064: step 47220, loss = 0.38, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 12h:04m:36s remains)
INFO - root - 2017-12-01 04:40:00.880681: step 47230, loss = 0.43, batch loss = 0.24 (52.7 examples/sec; 0.152 sec/batch; 12h:01m:07s remains)
INFO - root - 2017-12-01 04:40:02.463855: step 47240, loss = 0.52, batch loss = 0.33 (49.1 examples/sec; 0.163 sec/batch; 12h:54m:34s remains)
INFO - root - 2017-12-01 04:40:04.025032: step 47250, loss = 0.38, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 12h:27m:00s remains)
INFO - root - 2017-12-01 04:40:05.586513: step 47260, loss = 0.43, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 12h:03m:00s remains)
INFO - root - 2017-12-01 04:40:07.159949: step 47270, loss = 0.45, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 12h:09m:06s remains)
INFO - root - 2017-12-01 04:40:08.711875: step 47280, loss = 0.39, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 12h:15m:44s remains)
INFO - root - 2017-12-01 04:40:10.271836: step 47290, loss = 0.42, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 12h:27m:48s remains)
INFO - root - 2017-12-01 04:40:11.839538: step 47300, loss = 0.34, batch loss = 0.16 (48.9 examples/sec; 0.164 sec/batch; 12h:58m:24s remains)
INFO - root - 2017-12-01 04:40:13.489289: step 47310, loss = 0.41, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 12h:30m:18s remains)
INFO - root - 2017-12-01 04:40:15.062455: step 47320, loss = 0.39, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 12h:17m:13s remains)
INFO - root - 2017-12-01 04:40:16.618505: step 47330, loss = 0.41, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 12h:11m:07s remains)
INFO - root - 2017-12-01 04:40:18.179752: step 47340, loss = 0.53, batch loss = 0.35 (53.6 examples/sec; 0.149 sec/batch; 11h:49m:33s remains)
INFO - root - 2017-12-01 04:40:19.761751: step 47350, loss = 0.41, batch loss = 0.23 (51.1 examples/sec; 0.156 sec/batch; 12h:23m:21s remains)
INFO - root - 2017-12-01 04:40:21.340666: step 47360, loss = 0.36, batch loss = 0.18 (50.1 examples/sec; 0.160 sec/batch; 12h:38m:55s remains)
INFO - root - 2017-12-01 04:40:22.896323: step 47370, loss = 0.47, batch loss = 0.29 (47.8 examples/sec; 0.167 sec/batch; 13h:14m:48s remains)
INFO - root - 2017-12-01 04:40:24.471771: step 47380, loss = 0.50, batch loss = 0.32 (51.2 examples/sec; 0.156 sec/batch; 12h:22m:26s remains)
INFO - root - 2017-12-01 04:40:26.041925: step 47390, loss = 0.43, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 12h:16m:47s remains)
INFO - root - 2017-12-01 04:40:27.606717: step 47400, loss = 0.39, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 12h:36m:17s remains)
INFO - root - 2017-12-01 04:40:29.236135: step 47410, loss = 0.50, batch loss = 0.31 (52.6 examples/sec; 0.152 sec/batch; 12h:02m:30s remains)
INFO - root - 2017-12-01 04:40:30.817956: step 47420, loss = 0.43, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 12h:12m:30s remains)
INFO - root - 2017-12-01 04:40:32.375559: step 47430, loss = 0.35, batch loss = 0.16 (51.1 examples/sec; 0.157 sec/batch; 12h:24m:03s remains)
INFO - root - 2017-12-01 04:40:33.943072: step 47440, loss = 0.36, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 12h:35m:20s remains)
INFO - root - 2017-12-01 04:40:35.520112: step 47450, loss = 0.42, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 12h:22m:03s remains)
INFO - root - 2017-12-01 04:40:37.084084: step 47460, loss = 0.41, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 12h:08m:18s remains)
INFO - root - 2017-12-01 04:40:38.650221: step 47470, loss = 0.44, batch loss = 0.26 (50.8 examples/sec; 0.157 sec/batch; 12h:27m:42s remains)
INFO - root - 2017-12-01 04:40:40.206238: step 47480, loss = 0.39, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 12h:21m:41s remains)
INFO - root - 2017-12-01 04:40:41.757579: step 47490, loss = 0.44, batch loss = 0.25 (50.3 examples/sec; 0.159 sec/batch; 12h:35m:13s remains)
INFO - root - 2017-12-01 04:40:43.326966: step 47500, loss = 0.38, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 12h:13m:00s remains)
INFO - root - 2017-12-01 04:40:44.940657: step 47510, loss = 0.45, batch loss = 0.26 (49.5 examples/sec; 0.161 sec/batch; 12h:46m:58s remains)
INFO - root - 2017-12-01 04:40:46.494480: step 47520, loss = 0.44, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 12h:14m:53s remains)
INFO - root - 2017-12-01 04:40:48.062435: step 47530, loss = 0.38, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 12h:29m:17s remains)
INFO - root - 2017-12-01 04:40:49.642719: step 47540, loss = 0.37, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 12h:34m:41s remains)
INFO - root - 2017-12-01 04:40:51.192479: step 47550, loss = 0.44, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 12h:26m:33s remains)
INFO - root - 2017-12-01 04:40:52.758908: step 47560, loss = 0.67, batch loss = 0.48 (50.4 examples/sec; 0.159 sec/batch; 12h:33m:53s remains)
INFO - root - 2017-12-01 04:40:54.345318: step 47570, loss = 0.51, batch loss = 0.33 (47.0 examples/sec; 0.170 sec/batch; 13h:27m:27s remains)
INFO - root - 2017-12-01 04:40:55.925519: step 47580, loss = 0.40, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 12h:29m:41s remains)
INFO - root - 2017-12-01 04:40:57.493680: step 47590, loss = 0.45, batch loss = 0.26 (50.0 examples/sec; 0.160 sec/batch; 12h:39m:37s remains)
INFO - root - 2017-12-01 04:40:59.071620: step 47600, loss = 0.45, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 12h:26m:46s remains)
INFO - root - 2017-12-01 04:41:00.724010: step 47610, loss = 0.44, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 12h:24m:14s remains)
INFO - root - 2017-12-01 04:41:02.312175: step 47620, loss = 0.43, batch loss = 0.25 (50.0 examples/sec; 0.160 sec/batch; 12h:39m:07s remains)
INFO - root - 2017-12-01 04:41:03.887941: step 47630, loss = 0.37, batch loss = 0.19 (52.7 examples/sec; 0.152 sec/batch; 12h:00m:46s remains)
INFO - root - 2017-12-01 04:41:05.486905: step 47640, loss = 0.37, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 12h:20m:16s remains)
INFO - root - 2017-12-01 04:41:07.048653: step 47650, loss = 0.35, batch loss = 0.16 (50.2 examples/sec; 0.159 sec/batch; 12h:36m:37s remains)
INFO - root - 2017-12-01 04:41:08.612555: step 47660, loss = 0.40, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 12h:39m:44s remains)
INFO - root - 2017-12-01 04:41:10.174756: step 47670, loss = 0.45, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 12h:16m:31s remains)
INFO - root - 2017-12-01 04:41:11.753939: step 47680, loss = 0.41, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 12h:31m:32s remains)
INFO - root - 2017-12-01 04:41:13.317523: step 47690, loss = 0.43, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 12h:16m:42s remains)
INFO - root - 2017-12-01 04:41:14.874084: step 47700, loss = 0.36, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 12h:19m:25s remains)
INFO - root - 2017-12-01 04:41:16.532197: step 47710, loss = 0.41, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 12h:31m:03s remains)
INFO - root - 2017-12-01 04:41:18.089813: step 47720, loss = 0.39, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 12h:29m:20s remains)
INFO - root - 2017-12-01 04:41:19.639659: step 47730, loss = 0.44, batch loss = 0.25 (50.5 examples/sec; 0.159 sec/batch; 12h:32m:25s remains)
INFO - root - 2017-12-01 04:41:21.192324: step 47740, loss = 0.37, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 12h:07m:34s remains)
INFO - root - 2017-12-01 04:41:22.751906: step 47750, loss = 0.42, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 12h:24m:48s remains)
INFO - root - 2017-12-01 04:41:24.325705: step 47760, loss = 0.54, batch loss = 0.35 (50.1 examples/sec; 0.160 sec/batch; 12h:38m:01s remains)
INFO - root - 2017-12-01 04:41:25.885699: step 47770, loss = 0.50, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 12h:16m:18s remains)
INFO - root - 2017-12-01 04:41:27.435055: step 47780, loss = 0.56, batch loss = 0.37 (51.3 examples/sec; 0.156 sec/batch; 12h:20m:02s remains)
INFO - root - 2017-12-01 04:41:28.994175: step 47790, loss = 0.40, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 12h:35m:57s remains)
INFO - root - 2017-12-01 04:41:30.547769: step 47800, loss = 0.41, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 12h:22m:52s remains)
INFO - root - 2017-12-01 04:41:32.177645: step 47810, loss = 0.47, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 12h:19m:33s remains)
INFO - root - 2017-12-01 04:41:33.739992: step 47820, loss = 0.42, batch loss = 0.23 (49.7 examples/sec; 0.161 sec/batch; 12h:43m:23s remains)
INFO - root - 2017-12-01 04:41:35.299325: step 47830, loss = 0.53, batch loss = 0.34 (50.4 examples/sec; 0.159 sec/batch; 12h:32m:41s remains)
INFO - root - 2017-12-01 04:41:36.873407: step 47840, loss = 0.42, batch loss = 0.24 (52.4 examples/sec; 0.153 sec/batch; 12h:03m:50s remains)
INFO - root - 2017-12-01 04:41:38.437916: step 47850, loss = 0.45, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 12h:09m:12s remains)
INFO - root - 2017-12-01 04:41:40.008294: step 47860, loss = 0.46, batch loss = 0.28 (51.1 examples/sec; 0.156 sec/batch; 12h:22m:09s remains)
INFO - root - 2017-12-01 04:41:41.573533: step 47870, loss = 0.36, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 12h:33m:39s remains)
INFO - root - 2017-12-01 04:41:43.128451: step 47880, loss = 0.42, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 12h:03m:52s remains)
INFO - root - 2017-12-01 04:41:44.706342: step 47890, loss = 0.46, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 12h:21m:22s remains)
INFO - root - 2017-12-01 04:41:46.263733: step 47900, loss = 0.42, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 12h:09m:47s remains)
INFO - root - 2017-12-01 04:41:47.877894: step 47910, loss = 0.40, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 12h:19m:32s remains)
INFO - root - 2017-12-01 04:41:49.437290: step 47920, loss = 0.34, batch loss = 0.16 (52.9 examples/sec; 0.151 sec/batch; 11h:56m:46s remains)
INFO - root - 2017-12-01 04:41:50.994758: step 47930, loss = 0.41, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 12h:03m:08s remains)
INFO - root - 2017-12-01 04:41:52.536006: step 47940, loss = 0.41, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 12h:25m:52s remains)
INFO - root - 2017-12-01 04:41:54.087579: step 47950, loss = 0.40, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 12h:24m:08s remains)
INFO - root - 2017-12-01 04:41:55.655779: step 47960, loss = 0.48, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 12h:28m:53s remains)
INFO - root - 2017-12-01 04:41:57.208329: step 47970, loss = 0.49, batch loss = 0.30 (49.9 examples/sec; 0.160 sec/batch; 12h:40m:32s remains)
INFO - root - 2017-12-01 04:41:58.763440: step 47980, loss = 0.51, batch loss = 0.32 (50.9 examples/sec; 0.157 sec/batch; 12h:24m:55s remains)
INFO - root - 2017-12-01 04:42:00.343579: step 47990, loss = 0.58, batch loss = 0.39 (51.3 examples/sec; 0.156 sec/batch; 12h:18m:59s remains)
INFO - root - 2017-12-01 04:42:01.935295: step 48000, loss = 0.42, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 12h:35m:13s remains)
INFO - root - 2017-12-01 04:42:03.556821: step 48010, loss = 0.39, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 12h:34m:18s remains)
INFO - root - 2017-12-01 04:42:05.128645: step 48020, loss = 0.40, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 12h:13m:43s remains)
INFO - root - 2017-12-01 04:42:06.693913: step 48030, loss = 0.44, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 12h:28m:11s remains)
INFO - root - 2017-12-01 04:42:08.263269: step 48040, loss = 0.35, batch loss = 0.17 (49.7 examples/sec; 0.161 sec/batch; 12h:42m:42s remains)
INFO - root - 2017-12-01 04:42:09.815764: step 48050, loss = 0.40, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 12h:13m:52s remains)
INFO - root - 2017-12-01 04:42:11.394416: step 48060, loss = 0.36, batch loss = 0.18 (52.5 examples/sec; 0.152 sec/batch; 12h:02m:21s remains)
INFO - root - 2017-12-01 04:42:12.958009: step 48070, loss = 0.36, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 12h:29m:38s remains)
INFO - root - 2017-12-01 04:42:14.519861: step 48080, loss = 0.49, batch loss = 0.30 (52.7 examples/sec; 0.152 sec/batch; 12h:00m:15s remains)
INFO - root - 2017-12-01 04:42:16.084967: step 48090, loss = 0.49, batch loss = 0.30 (50.0 examples/sec; 0.160 sec/batch; 12h:38m:06s remains)
INFO - root - 2017-12-01 04:42:17.655817: step 48100, loss = 0.38, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 12h:31m:38s remains)
INFO - root - 2017-12-01 04:42:19.307272: step 48110, loss = 0.38, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 12h:24m:45s remains)
INFO - root - 2017-12-01 04:42:20.881442: step 48120, loss = 0.40, batch loss = 0.21 (53.6 examples/sec; 0.149 sec/batch; 11h:47m:05s remains)
INFO - root - 2017-12-01 04:42:22.456008: step 48130, loss = 0.45, batch loss = 0.27 (52.4 examples/sec; 0.153 sec/batch; 12h:03m:05s remains)
INFO - root - 2017-12-01 04:42:24.005730: step 48140, loss = 0.44, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 12h:10m:00s remains)
INFO - root - 2017-12-01 04:42:25.577864: step 48150, loss = 0.46, batch loss = 0.27 (50.8 examples/sec; 0.157 sec/batch; 12h:26m:10s remains)
INFO - root - 2017-12-01 04:42:27.152016: step 48160, loss = 0.44, batch loss = 0.25 (52.8 examples/sec; 0.152 sec/batch; 11h:58m:21s remains)
INFO - root - 2017-12-01 04:42:28.706284: step 48170, loss = 0.50, batch loss = 0.32 (52.7 examples/sec; 0.152 sec/batch; 11h:58m:58s remains)
INFO - root - 2017-12-01 04:42:30.288821: step 48180, loss = 0.50, batch loss = 0.32 (50.9 examples/sec; 0.157 sec/batch; 12h:24m:53s remains)
INFO - root - 2017-12-01 04:42:31.877792: step 48190, loss = 0.42, batch loss = 0.24 (49.5 examples/sec; 0.162 sec/batch; 12h:45m:33s remains)
INFO - root - 2017-12-01 04:42:33.435825: step 48200, loss = 0.53, batch loss = 0.34 (52.3 examples/sec; 0.153 sec/batch; 12h:04m:20s remains)
INFO - root - 2017-12-01 04:42:35.072558: step 48210, loss = 0.43, batch loss = 0.24 (50.0 examples/sec; 0.160 sec/batch; 12h:38m:29s remains)
INFO - root - 2017-12-01 04:42:36.667493: step 48220, loss = 0.42, batch loss = 0.23 (44.3 examples/sec; 0.181 sec/batch; 14h:16m:09s remains)
INFO - root - 2017-12-01 04:42:38.233911: step 48230, loss = 0.56, batch loss = 0.38 (50.9 examples/sec; 0.157 sec/batch; 12h:24m:32s remains)
INFO - root - 2017-12-01 04:42:39.776154: step 48240, loss = 0.45, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 11h:58m:45s remains)
INFO - root - 2017-12-01 04:42:41.351024: step 48250, loss = 0.54, batch loss = 0.36 (51.8 examples/sec; 0.155 sec/batch; 12h:12m:17s remains)
INFO - root - 2017-12-01 04:42:42.943691: step 48260, loss = 0.43, batch loss = 0.24 (47.5 examples/sec; 0.168 sec/batch; 13h:17m:37s remains)
INFO - root - 2017-12-01 04:42:44.496898: step 48270, loss = 0.44, batch loss = 0.25 (52.9 examples/sec; 0.151 sec/batch; 11h:56m:02s remains)
INFO - root - 2017-12-01 04:42:46.057878: step 48280, loss = 0.64, batch loss = 0.45 (52.0 examples/sec; 0.154 sec/batch; 12h:08m:32s remains)
INFO - root - 2017-12-01 04:42:47.621024: step 48290, loss = 0.41, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 12h:04m:42s remains)
INFO - root - 2017-12-01 04:42:49.188635: step 48300, loss = 0.42, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 12h:16m:23s remains)
INFO - root - 2017-12-01 04:42:50.792223: step 48310, loss = 0.55, batch loss = 0.36 (51.8 examples/sec; 0.154 sec/batch; 12h:11m:07s remains)
INFO - root - 2017-12-01 04:42:52.349470: step 48320, loss = 0.41, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 12h:06m:21s remains)
INFO - root - 2017-12-01 04:42:53.906387: step 48330, loss = 0.43, batch loss = 0.25 (52.8 examples/sec; 0.151 sec/batch; 11h:57m:23s remains)
INFO - root - 2017-12-01 04:42:55.463325: step 48340, loss = 0.43, batch loss = 0.24 (51.8 examples/sec; 0.155 sec/batch; 12h:11m:48s remains)
INFO - root - 2017-12-01 04:42:57.017501: step 48350, loss = 0.69, batch loss = 0.50 (51.1 examples/sec; 0.157 sec/batch; 12h:21m:11s remains)
INFO - root - 2017-12-01 04:42:58.582450: step 48360, loss = 0.43, batch loss = 0.24 (49.2 examples/sec; 0.163 sec/batch; 12h:50m:06s remains)
INFO - root - 2017-12-01 04:43:00.141400: step 48370, loss = 0.50, batch loss = 0.31 (50.0 examples/sec; 0.160 sec/batch; 12h:37m:31s remains)
INFO - root - 2017-12-01 04:43:01.712285: step 48380, loss = 0.42, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 12h:14m:18s remains)
INFO - root - 2017-12-01 04:43:03.258201: step 48390, loss = 0.38, batch loss = 0.20 (53.5 examples/sec; 0.150 sec/batch; 11h:48m:27s remains)
INFO - root - 2017-12-01 04:43:04.817807: step 48400, loss = 0.48, batch loss = 0.30 (50.8 examples/sec; 0.157 sec/batch; 12h:25m:38s remains)
INFO - root - 2017-12-01 04:43:06.445735: step 48410, loss = 0.39, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 12h:30m:55s remains)
INFO - root - 2017-12-01 04:43:08.013005: step 48420, loss = 0.46, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 12h:09m:33s remains)
INFO - root - 2017-12-01 04:43:09.583532: step 48430, loss = 0.45, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 12h:16m:45s remains)
INFO - root - 2017-12-01 04:43:11.160656: step 48440, loss = 0.37, batch loss = 0.18 (49.9 examples/sec; 0.160 sec/batch; 12h:38m:23s remains)
INFO - root - 2017-12-01 04:43:12.732260: step 48450, loss = 0.42, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 12h:23m:40s remains)
INFO - root - 2017-12-01 04:43:14.311036: step 48460, loss = 0.46, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 12h:28m:48s remains)
INFO - root - 2017-12-01 04:43:15.872953: step 48470, loss = 0.48, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 12h:26m:21s remains)
INFO - root - 2017-12-01 04:43:17.434590: step 48480, loss = 0.51, batch loss = 0.33 (51.5 examples/sec; 0.155 sec/batch; 12h:15m:33s remains)
INFO - root - 2017-12-01 04:43:18.992156: step 48490, loss = 0.52, batch loss = 0.34 (52.8 examples/sec; 0.152 sec/batch; 11h:57m:47s remains)
INFO - root - 2017-12-01 04:43:20.564299: step 48500, loss = 0.41, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 12h:00m:33s remains)
INFO - root - 2017-12-01 04:43:22.229508: step 48510, loss = 0.38, batch loss = 0.19 (46.5 examples/sec; 0.172 sec/batch; 13h:35m:00s remains)
INFO - root - 2017-12-01 04:43:23.787493: step 48520, loss = 0.45, batch loss = 0.27 (51.9 examples/sec; 0.154 sec/batch; 12h:10m:14s remains)
INFO - root - 2017-12-01 04:43:25.362269: step 48530, loss = 0.50, batch loss = 0.31 (51.1 examples/sec; 0.157 sec/batch; 12h:21m:23s remains)
INFO - root - 2017-12-01 04:43:26.943668: step 48540, loss = 0.46, batch loss = 0.27 (50.0 examples/sec; 0.160 sec/batch; 12h:37m:22s remains)
INFO - root - 2017-12-01 04:43:28.511713: step 48550, loss = 0.47, batch loss = 0.29 (52.0 examples/sec; 0.154 sec/batch; 12h:07m:23s remains)
INFO - root - 2017-12-01 04:43:30.082490: step 48560, loss = 0.41, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 12h:16m:24s remains)
INFO - root - 2017-12-01 04:43:31.657590: step 48570, loss = 0.39, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 12h:25m:50s remains)
INFO - root - 2017-12-01 04:43:33.220035: step 48580, loss = 0.50, batch loss = 0.31 (50.3 examples/sec; 0.159 sec/batch; 12h:31m:57s remains)
INFO - root - 2017-12-01 04:43:34.795063: step 48590, loss = 0.46, batch loss = 0.27 (52.1 examples/sec; 0.154 sec/batch; 12h:06m:27s remains)
INFO - root - 2017-12-01 04:43:36.376968: step 48600, loss = 0.54, batch loss = 0.35 (51.0 examples/sec; 0.157 sec/batch; 12h:21m:42s remains)
INFO - root - 2017-12-01 04:43:38.006555: step 48610, loss = 0.61, batch loss = 0.42 (51.1 examples/sec; 0.157 sec/batch; 12h:21m:00s remains)
INFO - root - 2017-12-01 04:43:39.563251: step 48620, loss = 0.43, batch loss = 0.25 (50.5 examples/sec; 0.158 sec/batch; 12h:29m:19s remains)
INFO - root - 2017-12-01 04:43:41.116067: step 48630, loss = 0.56, batch loss = 0.37 (52.7 examples/sec; 0.152 sec/batch; 11h:57m:33s remains)
INFO - root - 2017-12-01 04:43:42.708588: step 48640, loss = 0.38, batch loss = 0.19 (48.2 examples/sec; 0.166 sec/batch; 13h:05m:59s remains)
INFO - root - 2017-12-01 04:43:44.294591: step 48650, loss = 0.55, batch loss = 0.37 (49.6 examples/sec; 0.161 sec/batch; 12h:42m:24s remains)
INFO - root - 2017-12-01 04:43:45.858067: step 48660, loss = 0.43, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 12h:21m:01s remains)
INFO - root - 2017-12-01 04:43:47.434527: step 48670, loss = 0.37, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 12h:26m:22s remains)
INFO - root - 2017-12-01 04:43:49.013443: step 48680, loss = 0.51, batch loss = 0.32 (52.2 examples/sec; 0.153 sec/batch; 12h:04m:50s remains)
INFO - root - 2017-12-01 04:43:50.589872: step 48690, loss = 0.39, batch loss = 0.21 (47.5 examples/sec; 0.169 sec/batch; 13h:17m:22s remains)
INFO - root - 2017-12-01 04:43:52.140208: step 48700, loss = 0.42, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 12h:17m:41s remains)
INFO - root - 2017-12-01 04:43:53.750625: step 48710, loss = 0.38, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 12h:08m:50s remains)
INFO - root - 2017-12-01 04:43:55.329541: step 48720, loss = 0.43, batch loss = 0.24 (50.0 examples/sec; 0.160 sec/batch; 12h:36m:53s remains)
INFO - root - 2017-12-01 04:43:56.892942: step 48730, loss = 0.39, batch loss = 0.21 (52.7 examples/sec; 0.152 sec/batch; 11h:57m:16s remains)
INFO - root - 2017-12-01 04:43:58.464642: step 48740, loss = 0.38, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 11h:58m:52s remains)
INFO - root - 2017-12-01 04:44:00.030999: step 48750, loss = 0.34, batch loss = 0.15 (50.2 examples/sec; 0.159 sec/batch; 12h:32m:57s remains)
INFO - root - 2017-12-01 04:44:01.607407: step 48760, loss = 0.49, batch loss = 0.31 (51.1 examples/sec; 0.157 sec/batch; 12h:20m:29s remains)
INFO - root - 2017-12-01 04:44:03.167909: step 48770, loss = 0.45, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 12h:25m:57s remains)
INFO - root - 2017-12-01 04:44:04.732323: step 48780, loss = 0.48, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 12h:23m:13s remains)
INFO - root - 2017-12-01 04:44:06.303024: step 48790, loss = 0.39, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 12h:28m:59s remains)
INFO - root - 2017-12-01 04:44:07.861625: step 48800, loss = 0.49, batch loss = 0.31 (50.3 examples/sec; 0.159 sec/batch; 12h:31m:21s remains)
INFO - root - 2017-12-01 04:44:09.472906: step 48810, loss = 0.46, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 12h:22m:37s remains)
INFO - root - 2017-12-01 04:44:11.054778: step 48820, loss = 0.44, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 12h:25m:42s remains)
INFO - root - 2017-12-01 04:44:12.612391: step 48830, loss = 0.38, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 12h:07m:28s remains)
INFO - root - 2017-12-01 04:44:14.175096: step 48840, loss = 0.36, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 12h:32m:36s remains)
INFO - root - 2017-12-01 04:44:15.743891: step 48850, loss = 0.42, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 12h:01m:59s remains)
INFO - root - 2017-12-01 04:44:17.293237: step 48860, loss = 0.40, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 12h:01m:56s remains)
INFO - root - 2017-12-01 04:44:18.859991: step 48870, loss = 0.44, batch loss = 0.26 (52.5 examples/sec; 0.152 sec/batch; 12h:00m:43s remains)
INFO - root - 2017-12-01 04:44:20.436013: step 48880, loss = 0.48, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 12h:13m:47s remains)
INFO - root - 2017-12-01 04:44:22.004043: step 48890, loss = 0.43, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 12h:18m:53s remains)
INFO - root - 2017-12-01 04:44:23.544158: step 48900, loss = 0.39, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 12h:12m:58s remains)
INFO - root - 2017-12-01 04:44:25.189611: step 48910, loss = 0.37, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 12h:37m:04s remains)
INFO - root - 2017-12-01 04:44:26.759052: step 48920, loss = 0.46, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 12h:19m:59s remains)
INFO - root - 2017-12-01 04:44:28.308883: step 48930, loss = 0.53, batch loss = 0.34 (51.1 examples/sec; 0.157 sec/batch; 12h:20m:13s remains)
INFO - root - 2017-12-01 04:44:29.865947: step 48940, loss = 0.38, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 12h:21m:46s remains)
INFO - root - 2017-12-01 04:44:31.482227: step 48950, loss = 0.38, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 12h:36m:15s remains)
INFO - root - 2017-12-01 04:44:33.044011: step 48960, loss = 0.43, batch loss = 0.24 (49.8 examples/sec; 0.161 sec/batch; 12h:39m:01s remains)
INFO - root - 2017-12-01 04:44:34.593472: step 48970, loss = 0.38, batch loss = 0.19 (50.2 examples/sec; 0.159 sec/batch; 12h:32m:23s remains)
INFO - root - 2017-12-01 04:44:36.170265: step 48980, loss = 0.44, batch loss = 0.26 (48.8 examples/sec; 0.164 sec/batch; 12h:55m:12s remains)
INFO - root - 2017-12-01 04:44:37.735156: step 48990, loss = 0.40, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 12h:29m:52s remains)
INFO - root - 2017-12-01 04:44:39.296323: step 49000, loss = 0.40, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 12h:18m:55s remains)
INFO - root - 2017-12-01 04:44:40.921882: step 49010, loss = 0.43, batch loss = 0.24 (46.6 examples/sec; 0.172 sec/batch; 13h:31m:04s remains)
INFO - root - 2017-12-01 04:44:42.519969: step 49020, loss = 0.45, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 12h:21m:38s remains)
INFO - root - 2017-12-01 04:44:44.053492: step 49030, loss = 0.42, batch loss = 0.24 (52.7 examples/sec; 0.152 sec/batch; 11h:57m:51s remains)
INFO - root - 2017-12-01 04:44:45.605376: step 49040, loss = 0.48, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 12h:22m:07s remains)
INFO - root - 2017-12-01 04:44:47.161976: step 49050, loss = 0.43, batch loss = 0.24 (50.2 examples/sec; 0.159 sec/batch; 12h:32m:29s remains)
INFO - root - 2017-12-01 04:44:48.727186: step 49060, loss = 0.59, batch loss = 0.40 (49.7 examples/sec; 0.161 sec/batch; 12h:40m:20s remains)
INFO - root - 2017-12-01 04:44:50.318391: step 49070, loss = 0.43, batch loss = 0.25 (52.1 examples/sec; 0.154 sec/batch; 12h:05m:59s remains)
INFO - root - 2017-12-01 04:44:51.905506: step 49080, loss = 0.40, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 12h:33m:24s remains)
INFO - root - 2017-12-01 04:44:53.460114: step 49090, loss = 0.56, batch loss = 0.37 (49.8 examples/sec; 0.161 sec/batch; 12h:38m:28s remains)
INFO - root - 2017-12-01 04:44:55.027753: step 49100, loss = 0.37, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 12h:22m:31s remains)
INFO - root - 2017-12-01 04:44:56.700679: step 49110, loss = 0.52, batch loss = 0.33 (48.1 examples/sec; 0.166 sec/batch; 13h:05m:37s remains)
INFO - root - 2017-12-01 04:44:58.266336: step 49120, loss = 0.45, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 12h:10m:41s remains)
INFO - root - 2017-12-01 04:44:59.825616: step 49130, loss = 0.51, batch loss = 0.32 (52.5 examples/sec; 0.152 sec/batch; 12h:00m:10s remains)
INFO - root - 2017-12-01 04:45:01.392450: step 49140, loss = 0.68, batch loss = 0.49 (50.3 examples/sec; 0.159 sec/batch; 12h:30m:41s remains)
INFO - root - 2017-12-01 04:45:02.948200: step 49150, loss = 0.41, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 12h:16m:45s remains)
INFO - root - 2017-12-01 04:45:04.507246: step 49160, loss = 0.36, batch loss = 0.17 (50.2 examples/sec; 0.159 sec/batch; 12h:32m:25s remains)
INFO - root - 2017-12-01 04:45:06.073770: step 49170, loss = 0.42, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 11h:58m:28s remains)
INFO - root - 2017-12-01 04:45:07.629862: step 49180, loss = 0.35, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 12h:25m:52s remains)
INFO - root - 2017-12-01 04:45:09.198184: step 49190, loss = 0.46, batch loss = 0.27 (51.9 examples/sec; 0.154 sec/batch; 12h:08m:05s remains)
INFO - root - 2017-12-01 04:45:10.787200: step 49200, loss = 0.41, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 12h:15m:18s remains)
INFO - root - 2017-12-01 04:45:12.487834: step 49210, loss = 0.44, batch loss = 0.25 (50.2 examples/sec; 0.159 sec/batch; 12h:31m:44s remains)
INFO - root - 2017-12-01 04:45:14.045527: step 49220, loss = 0.38, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 12h:02m:49s remains)
INFO - root - 2017-12-01 04:45:15.626620: step 49230, loss = 0.48, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 12h:31m:29s remains)
INFO - root - 2017-12-01 04:45:17.197478: step 49240, loss = 0.39, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 12h:20m:11s remains)
INFO - root - 2017-12-01 04:45:18.760214: step 49250, loss = 0.35, batch loss = 0.17 (49.9 examples/sec; 0.160 sec/batch; 12h:36m:24s remains)
INFO - root - 2017-12-01 04:45:20.336744: step 49260, loss = 0.43, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 12h:22m:20s remains)
INFO - root - 2017-12-01 04:45:21.890973: step 49270, loss = 0.36, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 12h:07m:31s remains)
INFO - root - 2017-12-01 04:45:23.465688: step 49280, loss = 0.45, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 12h:03m:10s remains)
INFO - root - 2017-12-01 04:45:25.032227: step 49290, loss = 0.48, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 12h:21m:19s remains)
INFO - root - 2017-12-01 04:45:26.615328: step 49300, loss = 0.43, batch loss = 0.25 (49.1 examples/sec; 0.163 sec/batch; 12h:49m:38s remains)
INFO - root - 2017-12-01 04:45:28.244699: step 49310, loss = 0.43, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 12h:30m:24s remains)
INFO - root - 2017-12-01 04:45:29.804563: step 49320, loss = 0.39, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 12h:20m:32s remains)
INFO - root - 2017-12-01 04:45:31.378295: step 49330, loss = 0.53, batch loss = 0.35 (51.7 examples/sec; 0.155 sec/batch; 12h:09m:47s remains)
INFO - root - 2017-12-01 04:45:32.946472: step 49340, loss = 0.39, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 12h:04m:36s remains)
INFO - root - 2017-12-01 04:45:34.497962: step 49350, loss = 0.49, batch loss = 0.31 (52.6 examples/sec; 0.152 sec/batch; 11h:57m:14s remains)
INFO - root - 2017-12-01 04:45:36.067829: step 49360, loss = 0.43, batch loss = 0.25 (50.0 examples/sec; 0.160 sec/batch; 12h:34m:53s remains)
INFO - root - 2017-12-01 04:45:37.641345: step 49370, loss = 0.44, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 12h:10m:48s remains)
INFO - root - 2017-12-01 04:45:39.208236: step 49380, loss = 0.41, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 12h:19m:33s remains)
INFO - root - 2017-12-01 04:45:40.779324: step 49390, loss = 0.50, batch loss = 0.32 (50.6 examples/sec; 0.158 sec/batch; 12h:25m:37s remains)
INFO - root - 2017-12-01 04:45:42.348912: step 49400, loss = 0.45, batch loss = 0.27 (48.4 examples/sec; 0.165 sec/batch; 13h:00m:30s remains)
INFO - root - 2017-12-01 04:45:43.978909: step 49410, loss = 0.46, batch loss = 0.28 (52.6 examples/sec; 0.152 sec/batch; 11h:57m:46s remains)
INFO - root - 2017-12-01 04:45:45.532529: step 49420, loss = 0.42, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 12h:07m:44s remains)
INFO - root - 2017-12-01 04:45:47.099466: step 49430, loss = 0.35, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 12h:11m:05s remains)
INFO - root - 2017-12-01 04:45:48.668850: step 49440, loss = 0.40, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 12h:11m:53s remains)
INFO - root - 2017-12-01 04:45:50.229501: step 49450, loss = 0.49, batch loss = 0.31 (50.8 examples/sec; 0.157 sec/batch; 12h:22m:50s remains)
INFO - root - 2017-12-01 04:45:51.802809: step 49460, loss = 0.47, batch loss = 0.29 (48.0 examples/sec; 0.167 sec/batch; 13h:06m:22s remains)
INFO - root - 2017-12-01 04:45:53.405736: step 49470, loss = 0.44, batch loss = 0.26 (50.3 examples/sec; 0.159 sec/batch; 12h:29m:48s remains)
INFO - root - 2017-12-01 04:45:54.957301: step 49480, loss = 0.39, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 12h:28m:48s remains)
INFO - root - 2017-12-01 04:45:56.530182: step 49490, loss = 0.35, batch loss = 0.17 (51.8 examples/sec; 0.154 sec/batch; 12h:08m:29s remains)
INFO - root - 2017-12-01 04:45:58.084897: step 49500, loss = 0.44, batch loss = 0.26 (52.8 examples/sec; 0.152 sec/batch; 11h:54m:36s remains)
INFO - root - 2017-12-01 04:45:59.722291: step 49510, loss = 0.54, batch loss = 0.36 (50.5 examples/sec; 0.158 sec/batch; 12h:27m:16s remains)
INFO - root - 2017-12-01 04:46:01.277386: step 49520, loss = 0.46, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 12h:15m:33s remains)
INFO - root - 2017-12-01 04:46:02.853482: step 49530, loss = 0.37, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 11h:56m:51s remains)
INFO - root - 2017-12-01 04:46:04.408626: step 49540, loss = 0.40, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 12h:10m:40s remains)
INFO - root - 2017-12-01 04:46:05.973149: step 49550, loss = 0.44, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 12h:03m:20s remains)
INFO - root - 2017-12-01 04:46:07.550408: step 49560, loss = 0.44, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 12h:28m:40s remains)
INFO - root - 2017-12-01 04:46:09.106271: step 49570, loss = 0.77, batch loss = 0.58 (50.3 examples/sec; 0.159 sec/batch; 12h:30m:04s remains)
INFO - root - 2017-12-01 04:46:10.672422: step 49580, loss = 0.43, batch loss = 0.25 (53.4 examples/sec; 0.150 sec/batch; 11h:46m:10s remains)
INFO - root - 2017-12-01 04:46:12.234134: step 49590, loss = 0.44, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 12h:10m:36s remains)
INFO - root - 2017-12-01 04:46:13.790898: step 49600, loss = 0.40, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 12h:10m:43s remains)
INFO - root - 2017-12-01 04:46:15.441074: step 49610, loss = 0.48, batch loss = 0.30 (49.2 examples/sec; 0.163 sec/batch; 12h:46m:16s remains)
INFO - root - 2017-12-01 04:46:16.990963: step 49620, loss = 0.41, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 12h:12m:54s remains)
INFO - root - 2017-12-01 04:46:18.547604: step 49630, loss = 0.52, batch loss = 0.34 (51.9 examples/sec; 0.154 sec/batch; 12h:06m:29s remains)
INFO - root - 2017-12-01 04:46:20.099541: step 49640, loss = 0.39, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 12h:19m:28s remains)
INFO - root - 2017-12-01 04:46:21.657059: step 49650, loss = 0.37, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 12h:22m:53s remains)
INFO - root - 2017-12-01 04:46:23.223614: step 49660, loss = 0.36, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 12h:18m:05s remains)
INFO - root - 2017-12-01 04:46:24.794543: step 49670, loss = 0.56, batch loss = 0.38 (51.6 examples/sec; 0.155 sec/batch; 12h:10m:43s remains)
INFO - root - 2017-12-01 04:46:26.360614: step 49680, loss = 0.47, batch loss = 0.29 (52.3 examples/sec; 0.153 sec/batch; 12h:01m:40s remains)
INFO - root - 2017-12-01 04:46:27.920538: step 49690, loss = 0.60, batch loss = 0.42 (51.6 examples/sec; 0.155 sec/batch; 12h:10m:50s remains)
INFO - root - 2017-12-01 04:46:29.471695: step 49700, loss = 0.59, batch loss = 0.40 (51.2 examples/sec; 0.156 sec/batch; 12h:16m:40s remains)
INFO - root - 2017-12-01 04:46:31.109131: step 49710, loss = 0.53, batch loss = 0.35 (51.8 examples/sec; 0.154 sec/batch; 12h:07m:44s remains)
INFO - root - 2017-12-01 04:46:32.669892: step 49720, loss = 0.34, batch loss = 0.16 (50.3 examples/sec; 0.159 sec/batch; 12h:29m:47s remains)
INFO - root - 2017-12-01 04:46:34.227379: step 49730, loss = 0.41, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 12h:18m:52s remains)
INFO - root - 2017-12-01 04:46:35.792803: step 49740, loss = 0.49, batch loss = 0.31 (49.8 examples/sec; 0.160 sec/batch; 12h:36m:22s remains)
INFO - root - 2017-12-01 04:46:37.352490: step 49750, loss = 0.41, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 12h:17m:39s remains)
INFO - root - 2017-12-01 04:46:38.934151: step 49760, loss = 0.58, batch loss = 0.39 (52.0 examples/sec; 0.154 sec/batch; 12h:04m:43s remains)
INFO - root - 2017-12-01 04:46:40.521059: step 49770, loss = 0.55, batch loss = 0.36 (48.5 examples/sec; 0.165 sec/batch; 12h:57m:39s remains)
INFO - root - 2017-12-01 04:46:42.096828: step 49780, loss = 0.38, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 12h:21m:50s remains)
INFO - root - 2017-12-01 04:46:43.684254: step 49790, loss = 0.46, batch loss = 0.28 (50.8 examples/sec; 0.158 sec/batch; 12h:22m:37s remains)
INFO - root - 2017-12-01 04:46:45.244777: step 49800, loss = 0.41, batch loss = 0.23 (50.8 examples/sec; 0.157 sec/batch; 12h:21m:55s remains)
INFO - root - 2017-12-01 04:46:46.846829: step 49810, loss = 0.38, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 12h:19m:54s remains)
INFO - root - 2017-12-01 04:46:48.414172: step 49820, loss = 0.41, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 11h:59m:41s remains)
INFO - root - 2017-12-01 04:46:50.000394: step 49830, loss = 0.48, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 12h:21m:06s remains)
INFO - root - 2017-12-01 04:46:51.568171: step 49840, loss = 0.47, batch loss = 0.29 (49.3 examples/sec; 0.162 sec/batch; 12h:45m:03s remains)
INFO - root - 2017-12-01 04:46:53.140996: step 49850, loss = 0.43, batch loss = 0.25 (47.8 examples/sec; 0.167 sec/batch; 13h:08m:00s remains)
INFO - root - 2017-12-01 04:46:54.720209: step 49860, loss = 0.43, batch loss = 0.24 (53.3 examples/sec; 0.150 sec/batch; 11h:46m:52s remains)
INFO - root - 2017-12-01 04:46:56.296386: step 49870, loss = 0.53, batch loss = 0.35 (51.7 examples/sec; 0.155 sec/batch; 12h:08m:39s remains)
INFO - root - 2017-12-01 04:46:57.857721: step 49880, loss = 0.38, batch loss = 0.19 (51.1 examples/sec; 0.156 sec/batch; 12h:16m:54s remains)
INFO - root - 2017-12-01 04:46:59.422803: step 49890, loss = 0.39, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 12h:28m:02s remains)
INFO - root - 2017-12-01 04:47:00.985211: step 49900, loss = 0.38, batch loss = 0.20 (49.8 examples/sec; 0.161 sec/batch; 12h:36m:22s remains)
INFO - root - 2017-12-01 04:47:02.600895: step 49910, loss = 0.43, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 12h:12m:23s remains)
INFO - root - 2017-12-01 04:47:04.160705: step 49920, loss = 0.40, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 12h:24m:31s remains)
INFO - root - 2017-12-01 04:47:05.718940: step 49930, loss = 0.41, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 12h:14m:37s remains)
INFO - root - 2017-12-01 04:47:07.288724: step 49940, loss = 0.34, batch loss = 0.16 (51.7 examples/sec; 0.155 sec/batch; 12h:08m:28s remains)
INFO - root - 2017-12-01 04:47:08.862838: step 49950, loss = 0.42, batch loss = 0.24 (49.5 examples/sec; 0.162 sec/batch; 12h:40m:33s remains)
INFO - root - 2017-12-01 04:47:10.440772: step 49960, loss = 0.49, batch loss = 0.31 (50.8 examples/sec; 0.158 sec/batch; 12h:22m:16s remains)
INFO - root - 2017-12-01 04:47:11.984011: step 49970, loss = 0.46, batch loss = 0.27 (51.8 examples/sec; 0.154 sec/batch; 12h:06m:57s remains)
INFO - root - 2017-12-01 04:47:13.553915: step 49980, loss = 0.46, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 12h:18m:20s remains)
INFO - root - 2017-12-01 04:47:15.120508: step 49990, loss = 0.46, batch loss = 0.27 (51.1 examples/sec; 0.156 sec/batch; 12h:16m:40s remains)
INFO - root - 2017-12-01 04:47:16.678390: step 50000, loss = 0.38, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 11h:59m:33s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-50000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-50000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-01 04:47:18.593612: step 50010, loss = 0.44, batch loss = 0.25 (50.3 examples/sec; 0.159 sec/batch; 12h:28m:40s remains)
INFO - root - 2017-12-01 04:47:20.158796: step 50020, loss = 0.46, batch loss = 0.28 (49.3 examples/sec; 0.162 sec/batch; 12h:43m:38s remains)
INFO - root - 2017-12-01 04:47:21.739850: step 50030, loss = 0.57, batch loss = 0.39 (52.0 examples/sec; 0.154 sec/batch; 12h:04m:06s remains)
INFO - root - 2017-12-01 04:47:23.301432: step 50040, loss = 0.42, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 12h:16m:28s remains)
INFO - root - 2017-12-01 04:47:24.901700: step 50050, loss = 0.41, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 12h:20m:49s remains)
INFO - root - 2017-12-01 04:47:26.472293: step 50060, loss = 0.38, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 11h:58m:34s remains)
INFO - root - 2017-12-01 04:47:28.035399: step 50070, loss = 0.40, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 12h:05m:49s remains)
INFO - root - 2017-12-01 04:47:29.604632: step 50080, loss = 0.34, batch loss = 0.16 (52.1 examples/sec; 0.153 sec/batch; 12h:02m:05s remains)
INFO - root - 2017-12-01 04:47:31.168266: step 50090, loss = 0.46, batch loss = 0.28 (49.6 examples/sec; 0.161 sec/batch; 12h:38m:28s remains)
INFO - root - 2017-12-01 04:47:32.724528: step 50100, loss = 0.40, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 12h:04m:11s remains)
INFO - root - 2017-12-01 04:47:34.375554: step 50110, loss = 0.37, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 12h:08m:15s remains)
INFO - root - 2017-12-01 04:47:35.919598: step 50120, loss = 0.54, batch loss = 0.36 (51.1 examples/sec; 0.157 sec/batch; 12h:16m:42s remains)
INFO - root - 2017-12-01 04:47:37.474305: step 50130, loss = 0.41, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 12h:24m:10s remains)
INFO - root - 2017-12-01 04:47:39.034839: step 50140, loss = 0.43, batch loss = 0.24 (51.8 examples/sec; 0.155 sec/batch; 12h:07m:07s remains)
INFO - root - 2017-12-01 04:47:40.600170: step 50150, loss = 0.37, batch loss = 0.19 (53.6 examples/sec; 0.149 sec/batch; 11h:41m:54s remains)
INFO - root - 2017-12-01 04:47:42.181227: step 50160, loss = 0.49, batch loss = 0.31 (52.0 examples/sec; 0.154 sec/batch; 12h:03m:16s remains)
INFO - root - 2017-12-01 04:47:43.745221: step 50170, loss = 0.46, batch loss = 0.27 (51.2 examples/sec; 0.156 sec/batch; 12h:14m:44s remains)
INFO - root - 2017-12-01 04:47:45.302254: step 50180, loss = 0.41, batch loss = 0.23 (49.4 examples/sec; 0.162 sec/batch; 12h:42m:10s remains)
INFO - root - 2017-12-01 04:47:46.863272: step 50190, loss = 0.37, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 12h:10m:12s remains)
INFO - root - 2017-12-01 04:47:48.447968: step 50200, loss = 0.39, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 12h:13m:28s remains)
INFO - root - 2017-12-01 04:47:50.071891: step 50210, loss = 0.37, batch loss = 0.18 (49.2 examples/sec; 0.163 sec/batch; 12h:45m:01s remains)
INFO - root - 2017-12-01 04:47:51.651468: step 50220, loss = 0.46, batch loss = 0.28 (48.4 examples/sec; 0.165 sec/batch; 12h:56m:59s remains)
INFO - root - 2017-12-01 04:47:53.214327: step 50230, loss = 0.49, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 12h:19m:15s remains)
INFO - root - 2017-12-01 04:47:54.781503: step 50240, loss = 0.38, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 12h:19m:56s remains)
INFO - root - 2017-12-01 04:47:56.360857: step 50250, loss = 0.44, batch loss = 0.25 (49.8 examples/sec; 0.161 sec/batch; 12h:35m:29s remains)
INFO - root - 2017-12-01 04:47:57.917383: step 50260, loss = 0.41, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 12h:05m:14s remains)
INFO - root - 2017-12-01 04:47:59.481755: step 50270, loss = 0.40, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 12h:22m:26s remains)
INFO - root - 2017-12-01 04:48:01.061862: step 50280, loss = 0.48, batch loss = 0.30 (50.3 examples/sec; 0.159 sec/batch; 12h:27m:45s remains)
INFO - root - 2017-12-01 04:48:02.623889: step 50290, loss = 0.39, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 12h:16m:32s remains)
INFO - root - 2017-12-01 04:48:04.181260: step 50300, loss = 0.40, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 12h:09m:21s remains)
INFO - root - 2017-12-01 04:48:05.831182: step 50310, loss = 0.37, batch loss = 0.18 (47.9 examples/sec; 0.167 sec/batch; 13h:05m:20s remains)
INFO - root - 2017-12-01 04:48:07.401389: step 50320, loss = 0.43, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 12h:07m:40s remains)
INFO - root - 2017-12-01 04:48:08.959028: step 50330, loss = 0.35, batch loss = 0.17 (51.8 examples/sec; 0.154 sec/batch; 12h:05m:41s remains)
INFO - root - 2017-12-01 04:48:10.585270: step 50340, loss = 0.50, batch loss = 0.32 (49.9 examples/sec; 0.160 sec/batch; 12h:33m:48s remains)
INFO - root - 2017-12-01 04:48:12.155466: step 50350, loss = 0.46, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 12h:22m:36s remains)
INFO - root - 2017-12-01 04:48:13.743904: step 50360, loss = 0.39, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 12h:00m:26s remains)
INFO - root - 2017-12-01 04:48:15.321477: step 50370, loss = 0.56, batch loss = 0.37 (47.9 examples/sec; 0.167 sec/batch; 13h:05m:48s remains)
INFO - root - 2017-12-01 04:48:16.930178: step 50380, loss = 0.40, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 12h:26m:52s remains)
INFO - root - 2017-12-01 04:48:18.523418: step 50390, loss = 0.42, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 12h:10m:35s remains)
INFO - root - 2017-12-01 04:48:20.112548: step 50400, loss = 0.37, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 12h:12m:10s remains)
INFO - root - 2017-12-01 04:48:21.750406: step 50410, loss = 0.36, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 12h:02m:41s remains)
INFO - root - 2017-12-01 04:48:23.323140: step 50420, loss = 0.43, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 12h:22m:32s remains)
INFO - root - 2017-12-01 04:48:24.883799: step 50430, loss = 0.47, batch loss = 0.28 (50.4 examples/sec; 0.159 sec/batch; 12h:26m:03s remains)
INFO - root - 2017-12-01 04:48:26.447202: step 50440, loss = 0.53, batch loss = 0.34 (51.2 examples/sec; 0.156 sec/batch; 12h:15m:06s remains)
INFO - root - 2017-12-01 04:48:27.998497: step 50450, loss = 0.42, batch loss = 0.24 (52.4 examples/sec; 0.153 sec/batch; 11h:57m:04s remains)
INFO - root - 2017-12-01 04:48:29.567604: step 50460, loss = 0.51, batch loss = 0.32 (50.9 examples/sec; 0.157 sec/batch; 12h:18m:25s remains)
INFO - root - 2017-12-01 04:48:31.125833: step 50470, loss = 0.47, batch loss = 0.29 (48.5 examples/sec; 0.165 sec/batch; 12h:55m:49s remains)
INFO - root - 2017-12-01 04:48:32.696256: step 50480, loss = 0.36, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 12h:10m:15s remains)
INFO - root - 2017-12-01 04:48:34.251631: step 50490, loss = 0.38, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 12h:32m:34s remains)
INFO - root - 2017-12-01 04:48:35.817358: step 50500, loss = 0.47, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 12h:09m:08s remains)
INFO - root - 2017-12-01 04:48:37.469902: step 50510, loss = 0.39, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 12h:13m:37s remains)
INFO - root - 2017-12-01 04:48:39.033601: step 50520, loss = 0.40, batch loss = 0.21 (49.4 examples/sec; 0.162 sec/batch; 12h:40m:53s remains)
INFO - root - 2017-12-01 04:48:40.601260: step 50530, loss = 0.42, batch loss = 0.24 (52.8 examples/sec; 0.151 sec/batch; 11h:51m:38s remains)
INFO - root - 2017-12-01 04:48:42.168737: step 50540, loss = 0.47, batch loss = 0.29 (52.4 examples/sec; 0.153 sec/batch; 11h:58m:04s remains)
INFO - root - 2017-12-01 04:48:43.750357: step 50550, loss = 0.36, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 12h:19m:15s remains)
INFO - root - 2017-12-01 04:48:45.312574: step 50560, loss = 0.37, batch loss = 0.19 (52.1 examples/sec; 0.153 sec/batch; 12h:00m:58s remains)
INFO - root - 2017-12-01 04:48:46.882389: step 50570, loss = 0.37, batch loss = 0.19 (52.7 examples/sec; 0.152 sec/batch; 11h:53m:17s remains)
INFO - root - 2017-12-01 04:48:48.443238: step 50580, loss = 0.53, batch loss = 0.34 (50.8 examples/sec; 0.157 sec/batch; 12h:19m:56s remains)
INFO - root - 2017-12-01 04:48:50.023287: step 50590, loss = 0.40, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 12h:27m:54s remains)
INFO - root - 2017-12-01 04:48:51.585800: step 50600, loss = 0.44, batch loss = 0.26 (50.1 examples/sec; 0.160 sec/batch; 12h:30m:35s remains)
INFO - root - 2017-12-01 04:48:53.260467: step 50610, loss = 0.42, batch loss = 0.24 (49.3 examples/sec; 0.162 sec/batch; 12h:42m:57s remains)
INFO - root - 2017-12-01 04:48:54.825311: step 50620, loss = 0.45, batch loss = 0.26 (50.3 examples/sec; 0.159 sec/batch; 12h:27m:14s remains)
INFO - root - 2017-12-01 04:48:56.394876: step 50630, loss = 0.41, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 12h:16m:05s remains)
INFO - root - 2017-12-01 04:48:57.982871: step 50640, loss = 0.44, batch loss = 0.26 (53.0 examples/sec; 0.151 sec/batch; 11h:48m:29s remains)
INFO - root - 2017-12-01 04:48:59.538025: step 50650, loss = 0.38, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 12h:17m:52s remains)
INFO - root - 2017-12-01 04:49:01.111333: step 50660, loss = 0.34, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 12h:14m:03s remains)
INFO - root - 2017-12-01 04:49:02.659584: step 50670, loss = 0.46, batch loss = 0.28 (52.2 examples/sec; 0.153 sec/batch; 12h:00m:01s remains)
INFO - root - 2017-12-01 04:49:04.237569: step 50680, loss = 0.38, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 12h:13m:47s remains)
INFO - root - 2017-12-01 04:49:05.811010: step 50690, loss = 0.47, batch loss = 0.29 (50.8 examples/sec; 0.157 sec/batch; 12h:19m:38s remains)
INFO - root - 2017-12-01 04:49:07.366449: step 50700, loss = 0.35, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 12h:03m:49s remains)
INFO - root - 2017-12-01 04:49:08.961633: step 50710, loss = 0.41, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 11h:53m:48s remains)
INFO - root - 2017-12-01 04:49:10.533316: step 50720, loss = 0.37, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 12h:21m:53s remains)
INFO - root - 2017-12-01 04:49:12.093326: step 50730, loss = 0.39, batch loss = 0.21 (51.8 examples/sec; 0.155 sec/batch; 12h:05m:51s remains)
INFO - root - 2017-12-01 04:49:13.666421: step 50740, loss = 0.48, batch loss = 0.30 (51.0 examples/sec; 0.157 sec/batch; 12h:17m:20s remains)
INFO - root - 2017-12-01 04:49:15.224134: step 50750, loss = 0.37, batch loss = 0.19 (48.4 examples/sec; 0.165 sec/batch; 12h:55m:29s remains)
INFO - root - 2017-12-01 04:49:16.809309: step 50760, loss = 0.37, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 12h:02m:33s remains)
INFO - root - 2017-12-01 04:49:18.372095: step 50770, loss = 0.38, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 11h:57m:28s remains)
INFO - root - 2017-12-01 04:49:19.944006: step 50780, loss = 0.34, batch loss = 0.16 (52.1 examples/sec; 0.154 sec/batch; 12h:01m:00s remains)
INFO - root - 2017-12-01 04:49:21.493525: step 50790, loss = 0.46, batch loss = 0.28 (52.6 examples/sec; 0.152 sec/batch; 11h:54m:15s remains)
INFO - root - 2017-12-01 04:49:23.029148: step 50800, loss = 0.71, batch loss = 0.52 (51.0 examples/sec; 0.157 sec/batch; 12h:16m:03s remains)
INFO - root - 2017-12-01 04:49:24.654417: step 50810, loss = 0.39, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 12h:20m:18s remains)
INFO - root - 2017-12-01 04:49:26.229989: step 50820, loss = 0.40, batch loss = 0.21 (49.7 examples/sec; 0.161 sec/batch; 12h:35m:36s remains)
INFO - root - 2017-12-01 04:49:27.786155: step 50830, loss = 0.41, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 12h:23m:44s remains)
INFO - root - 2017-12-01 04:49:29.345265: step 50840, loss = 0.41, batch loss = 0.23 (50.8 examples/sec; 0.157 sec/batch; 12h:18m:54s remains)
INFO - root - 2017-12-01 04:49:30.891139: step 50850, loss = 0.51, batch loss = 0.33 (53.0 examples/sec; 0.151 sec/batch; 11h:48m:31s remains)
INFO - root - 2017-12-01 04:49:32.437849: step 50860, loss = 0.49, batch loss = 0.31 (52.1 examples/sec; 0.154 sec/batch; 12h:00m:52s remains)
INFO - root - 2017-12-01 04:49:33.994164: step 50870, loss = 0.37, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 11h:58m:46s remains)
INFO - root - 2017-12-01 04:49:35.593808: step 50880, loss = 0.42, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 12h:23m:05s remains)
INFO - root - 2017-12-01 04:49:37.153823: step 50890, loss = 0.44, batch loss = 0.26 (49.3 examples/sec; 0.162 sec/batch; 12h:41m:54s remains)
INFO - root - 2017-12-01 04:49:38.707817: step 50900, loss = 0.43, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 11h:54m:42s remains)
INFO - root - 2017-12-01 04:49:40.328856: step 50910, loss = 0.37, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 12h:15m:38s remains)
INFO - root - 2017-12-01 04:49:41.895341: step 50920, loss = 0.40, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 12h:30m:34s remains)
INFO - root - 2017-12-01 04:49:43.464640: step 50930, loss = 0.45, batch loss = 0.27 (51.7 examples/sec; 0.155 sec/batch; 12h:05m:56s remains)
INFO - root - 2017-12-01 04:49:45.019348: step 50940, loss = 0.38, batch loss = 0.20 (52.7 examples/sec; 0.152 sec/batch; 11h:51m:48s remains)
INFO - root - 2017-12-01 04:49:46.568920: step 50950, loss = 0.65, batch loss = 0.47 (51.0 examples/sec; 0.157 sec/batch; 12h:16m:00s remains)
INFO - root - 2017-12-01 04:49:48.124484: step 50960, loss = 0.44, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 11h:52m:50s remains)
INFO - root - 2017-12-01 04:49:49.692069: step 50970, loss = 0.39, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 12h:21m:10s remains)
INFO - root - 2017-12-01 04:49:51.254889: step 50980, loss = 0.39, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 12h:08m:38s remains)
INFO - root - 2017-12-01 04:49:52.811944: step 50990, loss = 0.56, batch loss = 0.38 (52.4 examples/sec; 0.153 sec/batch; 11h:55m:44s remains)
INFO - root - 2017-12-01 04:49:54.387536: step 51000, loss = 0.37, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 12h:06m:23s remains)
INFO - root - 2017-12-01 04:49:56.029747: step 51010, loss = 0.49, batch loss = 0.31 (49.4 examples/sec; 0.162 sec/batch; 12h:40m:08s remains)
INFO - root - 2017-12-01 04:49:57.595916: step 51020, loss = 0.44, batch loss = 0.26 (51.1 examples/sec; 0.157 sec/batch; 12h:14m:28s remains)
INFO - root - 2017-12-01 04:49:59.146759: step 51030, loss = 0.44, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 12h:20m:59s remains)
INFO - root - 2017-12-01 04:50:00.722084: step 51040, loss = 0.39, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 12h:16m:51s remains)
INFO - root - 2017-12-01 04:50:02.289417: step 51050, loss = 0.59, batch loss = 0.41 (51.4 examples/sec; 0.156 sec/batch; 12h:10m:03s remains)
INFO - root - 2017-12-01 04:50:03.836442: step 51060, loss = 0.46, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 12h:01m:08s remains)
INFO - root - 2017-12-01 04:50:05.401039: step 51070, loss = 0.45, batch loss = 0.27 (49.1 examples/sec; 0.163 sec/batch; 12h:44m:54s remains)
INFO - root - 2017-12-01 04:50:06.960072: step 51080, loss = 0.42, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 12h:06m:54s remains)
INFO - root - 2017-12-01 04:50:08.525756: step 51090, loss = 0.39, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 11h:57m:15s remains)
INFO - root - 2017-12-01 04:50:10.095853: step 51100, loss = 0.36, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 12h:23m:03s remains)
INFO - root - 2017-12-01 04:50:11.749165: step 51110, loss = 0.42, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 12h:24m:46s remains)
INFO - root - 2017-12-01 04:50:13.319725: step 51120, loss = 0.55, batch loss = 0.37 (51.5 examples/sec; 0.155 sec/batch; 12h:08m:19s remains)
INFO - root - 2017-12-01 04:50:14.882358: step 51130, loss = 0.39, batch loss = 0.21 (49.7 examples/sec; 0.161 sec/batch; 12h:35m:03s remains)
INFO - root - 2017-12-01 04:50:16.441320: step 51140, loss = 0.43, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 11h:54m:02s remains)
INFO - root - 2017-12-01 04:50:18.018765: step 51150, loss = 0.43, batch loss = 0.25 (50.8 examples/sec; 0.158 sec/batch; 12h:18m:32s remains)
INFO - root - 2017-12-01 04:50:19.584160: step 51160, loss = 0.47, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 12h:19m:48s remains)
INFO - root - 2017-12-01 04:50:21.169871: step 51170, loss = 0.39, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 12h:29m:16s remains)
INFO - root - 2017-12-01 04:50:22.732818: step 51180, loss = 0.38, batch loss = 0.19 (48.9 examples/sec; 0.163 sec/batch; 12h:46m:17s remains)
INFO - root - 2017-12-01 04:50:24.300576: step 51190, loss = 0.45, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 12h:21m:05s remains)
INFO - root - 2017-12-01 04:50:25.863720: step 51200, loss = 0.39, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 12h:19m:16s remains)
INFO - root - 2017-12-01 04:50:27.468589: step 51210, loss = 0.38, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 12h:12m:23s remains)
INFO - root - 2017-12-01 04:50:29.023049: step 51220, loss = 0.35, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 12h:11m:47s remains)
INFO - root - 2017-12-01 04:50:30.582295: step 51230, loss = 0.52, batch loss = 0.34 (52.6 examples/sec; 0.152 sec/batch; 11h:53m:21s remains)
INFO - root - 2017-12-01 04:50:32.146636: step 51240, loss = 0.34, batch loss = 0.16 (52.7 examples/sec; 0.152 sec/batch; 11h:51m:27s remains)
INFO - root - 2017-12-01 04:50:33.727676: step 51250, loss = 0.40, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 12h:26m:03s remains)
INFO - root - 2017-12-01 04:50:35.289624: step 51260, loss = 0.39, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 12h:10m:33s remains)
INFO - root - 2017-12-01 04:50:36.857616: step 51270, loss = 0.38, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 11h:56m:09s remains)
INFO - root - 2017-12-01 04:50:38.404402: step 51280, loss = 0.39, batch loss = 0.21 (52.6 examples/sec; 0.152 sec/batch; 11h:52m:23s remains)
INFO - root - 2017-12-01 04:50:39.989028: step 51290, loss = 0.50, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 12h:05m:58s remains)
INFO - root - 2017-12-01 04:50:41.556135: step 51300, loss = 0.39, batch loss = 0.21 (49.7 examples/sec; 0.161 sec/batch; 12h:33m:39s remains)
INFO - root - 2017-12-01 04:50:43.198020: step 51310, loss = 0.46, batch loss = 0.28 (51.8 examples/sec; 0.154 sec/batch; 12h:03m:58s remains)
INFO - root - 2017-12-01 04:50:44.755115: step 51320, loss = 0.40, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 12h:21m:48s remains)
INFO - root - 2017-12-01 04:50:46.302054: step 51330, loss = 0.41, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 12h:07m:45s remains)
INFO - root - 2017-12-01 04:50:47.862009: step 51340, loss = 0.43, batch loss = 0.25 (49.1 examples/sec; 0.163 sec/batch; 12h:43m:40s remains)
INFO - root - 2017-12-01 04:50:49.426866: step 51350, loss = 0.41, batch loss = 0.23 (53.1 examples/sec; 0.151 sec/batch; 11h:45m:44s remains)
INFO - root - 2017-12-01 04:50:50.991993: step 51360, loss = 0.55, batch loss = 0.36 (51.1 examples/sec; 0.156 sec/batch; 12h:13m:09s remains)
INFO - root - 2017-12-01 04:50:52.600655: step 51370, loss = 0.48, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 12h:18m:37s remains)
INFO - root - 2017-12-01 04:50:54.148129: step 51380, loss = 0.43, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 12h:19m:48s remains)
INFO - root - 2017-12-01 04:50:55.712220: step 51390, loss = 0.47, batch loss = 0.29 (51.1 examples/sec; 0.157 sec/batch; 12h:13m:21s remains)
INFO - root - 2017-12-01 04:50:57.264159: step 51400, loss = 0.80, batch loss = 0.62 (52.9 examples/sec; 0.151 sec/batch; 11h:48m:01s remains)
INFO - root - 2017-12-01 04:50:58.893494: step 51410, loss = 0.47, batch loss = 0.29 (49.4 examples/sec; 0.162 sec/batch; 12h:38m:13s remains)
INFO - root - 2017-12-01 04:51:00.458738: step 51420, loss = 0.43, batch loss = 0.25 (52.7 examples/sec; 0.152 sec/batch; 11h:51m:28s remains)
INFO - root - 2017-12-01 04:51:02.007381: step 51430, loss = 0.60, batch loss = 0.42 (52.7 examples/sec; 0.152 sec/batch; 11h:51m:36s remains)
INFO - root - 2017-12-01 04:51:03.593136: step 51440, loss = 0.47, batch loss = 0.29 (50.6 examples/sec; 0.158 sec/batch; 12h:20m:08s remains)
INFO - root - 2017-12-01 04:51:05.146557: step 51450, loss = 0.44, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 11h:59m:59s remains)
INFO - root - 2017-12-01 04:51:06.708358: step 51460, loss = 0.41, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 12h:28m:50s remains)
INFO - root - 2017-12-01 04:51:08.264638: step 51470, loss = 0.45, batch loss = 0.27 (48.9 examples/sec; 0.164 sec/batch; 12h:46m:27s remains)
INFO - root - 2017-12-01 04:51:09.845956: step 51480, loss = 0.37, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 12h:06m:41s remains)
INFO - root - 2017-12-01 04:51:11.430004: step 51490, loss = 0.42, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 12h:13m:19s remains)
INFO - root - 2017-12-01 04:51:12.990095: step 51500, loss = 0.69, batch loss = 0.51 (50.4 examples/sec; 0.159 sec/batch; 12h:23m:05s remains)
INFO - root - 2017-12-01 04:51:14.629759: step 51510, loss = 0.39, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 12h:07m:55s remains)
INFO - root - 2017-12-01 04:51:16.197367: step 51520, loss = 0.33, batch loss = 0.15 (51.9 examples/sec; 0.154 sec/batch; 12h:02m:20s remains)
INFO - root - 2017-12-01 04:51:17.752531: step 51530, loss = 0.39, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 12h:07m:49s remains)
INFO - root - 2017-12-01 04:51:19.299419: step 51540, loss = 0.34, batch loss = 0.16 (51.1 examples/sec; 0.157 sec/batch; 12h:13m:39s remains)
INFO - root - 2017-12-01 04:51:20.880336: step 51550, loss = 0.48, batch loss = 0.30 (52.2 examples/sec; 0.153 sec/batch; 11h:57m:35s remains)
INFO - root - 2017-12-01 04:51:22.440794: step 51560, loss = 0.43, batch loss = 0.25 (50.2 examples/sec; 0.159 sec/batch; 12h:25m:33s remains)
INFO - root - 2017-12-01 04:51:24.003960: step 51570, loss = 0.40, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 12h:03m:02s remains)
INFO - root - 2017-12-01 04:51:25.581546: step 51580, loss = 0.47, batch loss = 0.29 (51.4 examples/sec; 0.156 sec/batch; 12h:08m:24s remains)
INFO - root - 2017-12-01 04:51:27.157161: step 51590, loss = 0.47, batch loss = 0.29 (51.1 examples/sec; 0.157 sec/batch; 12h:13m:00s remains)
INFO - root - 2017-12-01 04:51:28.712056: step 51600, loss = 0.36, batch loss = 0.18 (52.6 examples/sec; 0.152 sec/batch; 11h:51m:56s remains)
INFO - root - 2017-12-01 04:51:30.326930: step 51610, loss = 0.45, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 12h:19m:25s remains)
INFO - root - 2017-12-01 04:51:31.892530: step 51620, loss = 0.38, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 12h:20m:00s remains)
INFO - root - 2017-12-01 04:51:33.465890: step 51630, loss = 0.40, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 11h:55m:36s remains)
INFO - root - 2017-12-01 04:51:35.019792: step 51640, loss = 0.36, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 12h:00m:05s remains)
INFO - root - 2017-12-01 04:51:36.585472: step 51650, loss = 0.40, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 12h:18m:07s remains)
INFO - root - 2017-12-01 04:51:38.146503: step 51660, loss = 0.47, batch loss = 0.28 (49.8 examples/sec; 0.161 sec/batch; 12h:31m:53s remains)
INFO - root - 2017-12-01 04:51:39.703356: step 51670, loss = 0.40, batch loss = 0.22 (49.5 examples/sec; 0.162 sec/batch; 12h:36m:42s remains)
INFO - root - 2017-12-01 04:51:41.274675: step 51680, loss = 0.44, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 12h:14m:52s remains)
INFO - root - 2017-12-01 04:51:42.841052: step 51690, loss = 0.54, batch loss = 0.36 (51.4 examples/sec; 0.156 sec/batch; 12h:08m:11s remains)
INFO - root - 2017-12-01 04:51:44.392248: step 51700, loss = 0.51, batch loss = 0.33 (50.8 examples/sec; 0.158 sec/batch; 12h:17m:31s remains)
INFO - root - 2017-12-01 04:51:45.996493: step 51710, loss = 0.58, batch loss = 0.40 (51.9 examples/sec; 0.154 sec/batch; 12h:00m:59s remains)
INFO - root - 2017-12-01 04:51:47.551071: step 51720, loss = 0.43, batch loss = 0.25 (51.1 examples/sec; 0.156 sec/batch; 12h:12m:17s remains)
INFO - root - 2017-12-01 04:51:49.141921: step 51730, loss = 0.58, batch loss = 0.40 (51.4 examples/sec; 0.156 sec/batch; 12h:07m:43s remains)
INFO - root - 2017-12-01 04:51:50.700760: step 51740, loss = 0.36, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 12h:22m:20s remains)
INFO - root - 2017-12-01 04:51:52.271769: step 51750, loss = 0.36, batch loss = 0.18 (49.8 examples/sec; 0.161 sec/batch; 12h:32m:00s remains)
INFO - root - 2017-12-01 04:51:53.828113: step 51760, loss = 0.50, batch loss = 0.32 (51.8 examples/sec; 0.155 sec/batch; 12h:03m:13s remains)
INFO - root - 2017-12-01 04:51:55.406998: step 51770, loss = 0.57, batch loss = 0.39 (51.2 examples/sec; 0.156 sec/batch; 12h:11m:39s remains)
INFO - root - 2017-12-01 04:51:56.970804: step 51780, loss = 0.51, batch loss = 0.33 (51.0 examples/sec; 0.157 sec/batch; 12h:13m:22s remains)
INFO - root - 2017-12-01 04:51:58.523900: step 51790, loss = 0.48, batch loss = 0.29 (50.6 examples/sec; 0.158 sec/batch; 12h:19m:26s remains)
INFO - root - 2017-12-01 04:52:00.096638: step 51800, loss = 0.42, batch loss = 0.24 (49.0 examples/sec; 0.163 sec/batch; 12h:43m:59s remains)
INFO - root - 2017-12-01 04:52:01.704140: step 51810, loss = 0.35, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 12h:08m:10s remains)
INFO - root - 2017-12-01 04:52:03.261698: step 51820, loss = 0.41, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 12h:08m:40s remains)
INFO - root - 2017-12-01 04:52:04.826714: step 51830, loss = 0.36, batch loss = 0.18 (49.4 examples/sec; 0.162 sec/batch; 12h:38m:08s remains)
INFO - root - 2017-12-01 04:52:06.406405: step 51840, loss = 0.54, batch loss = 0.36 (50.7 examples/sec; 0.158 sec/batch; 12h:18m:46s remains)
INFO - root - 2017-12-01 04:52:07.959186: step 51850, loss = 0.41, batch loss = 0.23 (52.5 examples/sec; 0.152 sec/batch; 11h:53m:09s remains)
INFO - root - 2017-12-01 04:52:09.534145: step 51860, loss = 0.41, batch loss = 0.23 (51.8 examples/sec; 0.155 sec/batch; 12h:02m:59s remains)
INFO - root - 2017-12-01 04:52:11.110664: step 51870, loss = 0.37, batch loss = 0.19 (48.3 examples/sec; 0.166 sec/batch; 12h:55m:25s remains)
INFO - root - 2017-12-01 04:52:12.683018: step 51880, loss = 0.36, batch loss = 0.18 (48.9 examples/sec; 0.164 sec/batch; 12h:45m:11s remains)
INFO - root - 2017-12-01 04:52:14.257487: step 51890, loss = 0.42, batch loss = 0.24 (52.8 examples/sec; 0.151 sec/batch; 11h:48m:07s remains)
INFO - root - 2017-12-01 04:52:15.856204: step 51900, loss = 0.45, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 12h:23m:16s remains)
INFO - root - 2017-12-01 04:52:17.467476: step 51910, loss = 0.42, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 11h:58m:47s remains)
INFO - root - 2017-12-01 04:52:19.064414: step 51920, loss = 0.58, batch loss = 0.40 (51.2 examples/sec; 0.156 sec/batch; 12h:10m:33s remains)
INFO - root - 2017-12-01 04:52:20.615420: step 51930, loss = 0.42, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 12h:19m:23s remains)
INFO - root - 2017-12-01 04:52:22.178105: step 51940, loss = 0.49, batch loss = 0.31 (49.8 examples/sec; 0.161 sec/batch; 12h:31m:08s remains)
INFO - root - 2017-12-01 04:52:23.733589: step 51950, loss = 0.51, batch loss = 0.33 (49.5 examples/sec; 0.162 sec/batch; 12h:35m:15s remains)
INFO - root - 2017-12-01 04:52:25.301781: step 51960, loss = 0.49, batch loss = 0.31 (50.6 examples/sec; 0.158 sec/batch; 12h:19m:21s remains)
INFO - root - 2017-12-01 04:52:26.894574: step 51970, loss = 0.65, batch loss = 0.47 (52.6 examples/sec; 0.152 sec/batch; 11h:51m:36s remains)
INFO - root - 2017-12-01 04:52:28.451120: step 51980, loss = 0.40, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 12h:17m:56s remains)
INFO - root - 2017-12-01 04:52:30.017729: step 51990, loss = 0.47, batch loss = 0.29 (50.4 examples/sec; 0.159 sec/batch; 12h:21m:34s remains)
INFO - root - 2017-12-01 04:52:31.581042: step 52000, loss = 0.57, batch loss = 0.39 (50.0 examples/sec; 0.160 sec/batch; 12h:28m:29s remains)
INFO - root - 2017-12-01 04:52:33.197277: step 52010, loss = 0.39, batch loss = 0.21 (50.0 examples/sec; 0.160 sec/batch; 12h:28m:30s remains)
INFO - root - 2017-12-01 04:52:34.761721: step 52020, loss = 0.45, batch loss = 0.27 (49.8 examples/sec; 0.161 sec/batch; 12h:31m:10s remains)
INFO - root - 2017-12-01 04:52:36.320676: step 52030, loss = 0.41, batch loss = 0.23 (49.8 examples/sec; 0.161 sec/batch; 12h:30m:21s remains)
INFO - root - 2017-12-01 04:52:37.902440: step 52040, loss = 0.40, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 12h:15m:28s remains)
INFO - root - 2017-12-01 04:52:39.472746: step 52050, loss = 0.40, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 12h:16m:41s remains)
INFO - root - 2017-12-01 04:52:41.030307: step 52060, loss = 0.55, batch loss = 0.37 (50.9 examples/sec; 0.157 sec/batch; 12h:14m:48s remains)
INFO - root - 2017-12-01 04:52:42.589585: step 52070, loss = 0.60, batch loss = 0.42 (50.0 examples/sec; 0.160 sec/batch; 12h:28m:26s remains)
INFO - root - 2017-12-01 04:52:44.146733: step 52080, loss = 0.38, batch loss = 0.20 (53.2 examples/sec; 0.150 sec/batch; 11h:42m:12s remains)
INFO - root - 2017-12-01 04:52:45.720121: step 52090, loss = 0.51, batch loss = 0.33 (49.5 examples/sec; 0.161 sec/batch; 12h:34m:38s remains)
INFO - root - 2017-12-01 04:52:47.271248: step 52100, loss = 0.37, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 12h:14m:56s remains)
INFO - root - 2017-12-01 04:52:48.878168: step 52110, loss = 0.44, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 12h:14m:41s remains)
INFO - root - 2017-12-01 04:52:50.430216: step 52120, loss = 0.41, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 11h:53m:49s remains)
INFO - root - 2017-12-01 04:52:52.001870: step 52130, loss = 0.42, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 12h:03m:31s remains)
INFO - root - 2017-12-01 04:52:53.584410: step 52140, loss = 0.40, batch loss = 0.22 (48.9 examples/sec; 0.164 sec/batch; 12h:44m:54s remains)
INFO - root - 2017-12-01 04:52:55.139798: step 52150, loss = 0.56, batch loss = 0.38 (50.4 examples/sec; 0.159 sec/batch; 12h:21m:18s remains)
INFO - root - 2017-12-01 04:52:56.711212: step 52160, loss = 0.48, batch loss = 0.30 (50.0 examples/sec; 0.160 sec/batch; 12h:27m:45s remains)
INFO - root - 2017-12-01 04:52:58.291667: step 52170, loss = 0.39, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 12h:17m:42s remains)
INFO - root - 2017-12-01 04:52:59.857387: step 52180, loss = 0.45, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 12h:18m:35s remains)
INFO - root - 2017-12-01 04:53:01.429017: step 52190, loss = 0.45, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 12h:12m:41s remains)
INFO - root - 2017-12-01 04:53:02.987568: step 52200, loss = 0.35, batch loss = 0.17 (52.5 examples/sec; 0.152 sec/batch; 11h:51m:41s remains)
INFO - root - 2017-12-01 04:53:04.588927: step 52210, loss = 0.38, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 12h:05m:26s remains)
INFO - root - 2017-12-01 04:53:06.161918: step 52220, loss = 0.38, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 12h:27m:00s remains)
INFO - root - 2017-12-01 04:53:07.730805: step 52230, loss = 0.40, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 12h:16m:23s remains)
INFO - root - 2017-12-01 04:53:09.284808: step 52240, loss = 0.44, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 12h:03m:36s remains)
INFO - root - 2017-12-01 04:53:10.875431: step 52250, loss = 0.39, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 12h:00m:52s remains)
INFO - root - 2017-12-01 04:53:12.437316: step 52260, loss = 0.53, batch loss = 0.35 (51.8 examples/sec; 0.154 sec/batch; 12h:00m:48s remains)
INFO - root - 2017-12-01 04:53:13.985928: step 52270, loss = 0.40, batch loss = 0.22 (48.9 examples/sec; 0.163 sec/batch; 12h:43m:32s remains)
INFO - root - 2017-12-01 04:53:15.537938: step 52280, loss = 0.45, batch loss = 0.27 (50.2 examples/sec; 0.159 sec/batch; 12h:23m:33s remains)
INFO - root - 2017-12-01 04:53:17.104579: step 52290, loss = 0.41, batch loss = 0.23 (51.1 examples/sec; 0.156 sec/batch; 12h:10m:47s remains)
INFO - root - 2017-12-01 04:53:18.662319: step 52300, loss = 0.41, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 11h:54m:39s remains)
INFO - root - 2017-12-01 04:53:20.295202: step 52310, loss = 0.39, batch loss = 0.21 (49.9 examples/sec; 0.160 sec/batch; 12h:28m:15s remains)
INFO - root - 2017-12-01 04:53:21.853292: step 52320, loss = 0.49, batch loss = 0.32 (51.3 examples/sec; 0.156 sec/batch; 12h:08m:13s remains)
INFO - root - 2017-12-01 04:53:23.430161: step 52330, loss = 0.61, batch loss = 0.43 (49.7 examples/sec; 0.161 sec/batch; 12h:31m:26s remains)
INFO - root - 2017-12-01 04:53:25.011057: step 52340, loss = 0.42, batch loss = 0.24 (49.8 examples/sec; 0.161 sec/batch; 12h:29m:56s remains)
INFO - root - 2017-12-01 04:53:26.583606: step 52350, loss = 0.37, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 12h:16m:03s remains)
INFO - root - 2017-12-01 04:53:28.130603: step 52360, loss = 0.41, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 12h:05m:49s remains)
INFO - root - 2017-12-01 04:53:29.700543: step 52370, loss = 0.42, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 12h:16m:57s remains)
INFO - root - 2017-12-01 04:53:31.256043: step 52380, loss = 0.34, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 12h:07m:49s remains)
INFO - root - 2017-12-01 04:53:32.823785: step 52390, loss = 0.43, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 12h:09m:48s remains)
INFO - root - 2017-12-01 04:53:34.388879: step 52400, loss = 0.45, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 12h:07m:15s remains)
INFO - root - 2017-12-01 04:53:36.033544: step 52410, loss = 0.47, batch loss = 0.29 (51.8 examples/sec; 0.154 sec/batch; 12h:00m:46s remains)
INFO - root - 2017-12-01 04:53:37.593645: step 52420, loss = 0.44, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 12h:17m:46s remains)
INFO - root - 2017-12-01 04:53:39.149112: step 52430, loss = 0.40, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 12h:09m:25s remains)
INFO - root - 2017-12-01 04:53:40.709988: step 52440, loss = 0.43, batch loss = 0.25 (48.8 examples/sec; 0.164 sec/batch; 12h:45m:33s remains)
INFO - root - 2017-12-01 04:53:42.282040: step 52450, loss = 0.39, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 12h:25m:15s remains)
INFO - root - 2017-12-01 04:53:43.891655: step 52460, loss = 0.35, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 12h:10m:34s remains)
INFO - root - 2017-12-01 04:53:45.450160: step 52470, loss = 0.36, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 12h:08m:54s remains)
INFO - root - 2017-12-01 04:53:47.007949: step 52480, loss = 0.44, batch loss = 0.26 (50.5 examples/sec; 0.159 sec/batch; 12h:20m:02s remains)
INFO - root - 2017-12-01 04:53:48.569993: step 52490, loss = 0.37, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 11h:55m:21s remains)
INFO - root - 2017-12-01 04:53:50.138876: step 52500, loss = 0.45, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 12h:05m:13s remains)
INFO - root - 2017-12-01 04:53:51.785672: step 52510, loss = 0.49, batch loss = 0.31 (50.4 examples/sec; 0.159 sec/batch; 12h:21m:20s remains)
INFO - root - 2017-12-01 04:53:53.361788: step 52520, loss = 0.38, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 12h:20m:31s remains)
INFO - root - 2017-12-01 04:53:54.924805: step 52530, loss = 0.42, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 12h:17m:58s remains)
INFO - root - 2017-12-01 04:53:56.491296: step 52540, loss = 0.38, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 12h:16m:56s remains)
INFO - root - 2017-12-01 04:53:58.041082: step 52550, loss = 0.35, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 12h:11m:19s remains)
INFO - root - 2017-12-01 04:53:59.584465: step 52560, loss = 0.56, batch loss = 0.38 (51.8 examples/sec; 0.154 sec/batch; 12h:00m:43s remains)
INFO - root - 2017-12-01 04:54:01.146571: step 52570, loss = 0.42, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 12h:00m:22s remains)
INFO - root - 2017-12-01 04:54:02.722941: step 52580, loss = 0.40, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 11h:56m:34s remains)
INFO - root - 2017-12-01 04:54:04.276559: step 52590, loss = 0.41, batch loss = 0.23 (51.8 examples/sec; 0.155 sec/batch; 12h:00m:52s remains)
INFO - root - 2017-12-01 04:54:05.845615: step 52600, loss = 0.36, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 12h:12m:43s remains)
INFO - root - 2017-12-01 04:54:07.470519: step 52610, loss = 0.42, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 12h:16m:15s remains)
INFO - root - 2017-12-01 04:54:09.015496: step 52620, loss = 0.36, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 12h:03m:28s remains)
INFO - root - 2017-12-01 04:54:10.614137: step 52630, loss = 0.47, batch loss = 0.30 (50.4 examples/sec; 0.159 sec/batch; 12h:20m:43s remains)
INFO - root - 2017-12-01 04:54:12.198671: step 52640, loss = 0.37, batch loss = 0.19 (50.1 examples/sec; 0.160 sec/batch; 12h:24m:28s remains)
INFO - root - 2017-12-01 04:54:13.796881: step 52650, loss = 0.39, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 11h:59m:17s remains)
INFO - root - 2017-12-01 04:54:15.353231: step 52660, loss = 0.39, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 12h:18m:57s remains)
INFO - root - 2017-12-01 04:54:16.912733: step 52670, loss = 0.39, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 12h:17m:56s remains)
INFO - root - 2017-12-01 04:54:18.476988: step 52680, loss = 0.52, batch loss = 0.34 (50.0 examples/sec; 0.160 sec/batch; 12h:25m:51s remains)
INFO - root - 2017-12-01 04:54:20.045477: step 52690, loss = 0.42, batch loss = 0.24 (52.7 examples/sec; 0.152 sec/batch; 11h:48m:14s remains)
INFO - root - 2017-12-01 04:54:21.656215: step 52700, loss = 0.41, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 11h:54m:41s remains)
INFO - root - 2017-12-01 04:54:23.272382: step 52710, loss = 0.48, batch loss = 0.30 (51.1 examples/sec; 0.157 sec/batch; 12h:10m:15s remains)
INFO - root - 2017-12-01 04:54:24.826927: step 52720, loss = 0.36, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 11h:59m:37s remains)
INFO - root - 2017-12-01 04:54:26.389988: step 52730, loss = 0.45, batch loss = 0.27 (52.7 examples/sec; 0.152 sec/batch; 11h:47m:57s remains)
INFO - root - 2017-12-01 04:54:27.953455: step 52740, loss = 0.42, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 12h:28m:13s remains)
INFO - root - 2017-12-01 04:54:29.516249: step 52750, loss = 0.38, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 12h:05m:24s remains)
INFO - root - 2017-12-01 04:54:31.066362: step 52760, loss = 0.41, batch loss = 0.23 (53.2 examples/sec; 0.150 sec/batch; 11h:41m:19s remains)
INFO - root - 2017-12-01 04:54:32.621642: step 52770, loss = 0.42, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 11h:59m:21s remains)
INFO - root - 2017-12-01 04:54:34.186765: step 52780, loss = 0.43, batch loss = 0.25 (52.0 examples/sec; 0.154 sec/batch; 11h:56m:35s remains)
INFO - root - 2017-12-01 04:54:35.745223: step 52790, loss = 0.46, batch loss = 0.28 (48.9 examples/sec; 0.164 sec/batch; 12h:43m:25s remains)
INFO - root - 2017-12-01 04:54:37.302424: step 52800, loss = 0.50, batch loss = 0.32 (50.3 examples/sec; 0.159 sec/batch; 12h:21m:53s remains)
INFO - root - 2017-12-01 04:54:38.922246: step 52810, loss = 0.40, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 12h:21m:38s remains)
INFO - root - 2017-12-01 04:54:40.468458: step 52820, loss = 0.49, batch loss = 0.31 (50.2 examples/sec; 0.159 sec/batch; 12h:22m:55s remains)
INFO - root - 2017-12-01 04:54:42.053668: step 52830, loss = 0.48, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 12h:08m:20s remains)
INFO - root - 2017-12-01 04:54:43.618352: step 52840, loss = 0.38, batch loss = 0.20 (49.4 examples/sec; 0.162 sec/batch; 12h:35m:15s remains)
INFO - root - 2017-12-01 04:54:45.179042: step 52850, loss = 0.33, batch loss = 0.15 (51.1 examples/sec; 0.156 sec/batch; 12h:08m:59s remains)
INFO - root - 2017-12-01 04:54:46.760764: step 52860, loss = 0.55, batch loss = 0.37 (52.1 examples/sec; 0.153 sec/batch; 11h:55m:16s remains)
INFO - root - 2017-12-01 04:54:48.318190: step 52870, loss = 0.46, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 12h:11m:57s remains)
INFO - root - 2017-12-01 04:54:49.892207: step 52880, loss = 0.48, batch loss = 0.31 (51.3 examples/sec; 0.156 sec/batch; 12h:06m:41s remains)
INFO - root - 2017-12-01 04:54:51.451172: step 52890, loss = 0.49, batch loss = 0.32 (51.0 examples/sec; 0.157 sec/batch; 12h:10m:45s remains)
INFO - root - 2017-12-01 04:54:53.025074: step 52900, loss = 0.45, batch loss = 0.27 (53.0 examples/sec; 0.151 sec/batch; 11h:43m:49s remains)
INFO - root - 2017-12-01 04:54:54.645693: step 52910, loss = 0.35, batch loss = 0.18 (51.1 examples/sec; 0.156 sec/batch; 12h:08m:57s remains)
INFO - root - 2017-12-01 04:54:56.200012: step 52920, loss = 0.44, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 11h:59m:45s remains)
INFO - root - 2017-12-01 04:54:57.760134: step 52930, loss = 0.33, batch loss = 0.15 (52.0 examples/sec; 0.154 sec/batch; 11h:57m:01s remains)
INFO - root - 2017-12-01 04:54:59.349590: step 52940, loss = 0.43, batch loss = 0.25 (49.8 examples/sec; 0.161 sec/batch; 12h:29m:13s remains)
INFO - root - 2017-12-01 04:55:00.909776: step 52950, loss = 0.42, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 12h:20m:07s remains)
INFO - root - 2017-12-01 04:55:02.472476: step 52960, loss = 0.41, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 12h:12m:18s remains)
INFO - root - 2017-12-01 04:55:04.020600: step 52970, loss = 0.39, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 12h:02m:09s remains)
INFO - root - 2017-12-01 04:55:05.576253: step 52980, loss = 0.45, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 12h:17m:13s remains)
INFO - root - 2017-12-01 04:55:07.134563: step 52990, loss = 0.40, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 11h:58m:36s remains)
INFO - root - 2017-12-01 04:55:08.699143: step 53000, loss = 0.43, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 11h:53m:00s remains)
INFO - root - 2017-12-01 04:55:10.315850: step 53010, loss = 0.48, batch loss = 0.30 (49.4 examples/sec; 0.162 sec/batch; 12h:34m:13s remains)
INFO - root - 2017-12-01 04:55:11.886036: step 53020, loss = 0.49, batch loss = 0.31 (52.0 examples/sec; 0.154 sec/batch; 11h:56m:13s remains)
INFO - root - 2017-12-01 04:55:13.452150: step 53030, loss = 0.38, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 11h:52m:07s remains)
INFO - root - 2017-12-01 04:55:15.015320: step 53040, loss = 0.36, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 12h:21m:26s remains)
INFO - root - 2017-12-01 04:55:16.573281: step 53050, loss = 0.52, batch loss = 0.34 (49.4 examples/sec; 0.162 sec/batch; 12h:34m:21s remains)
INFO - root - 2017-12-01 04:55:18.141587: step 53060, loss = 0.38, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 11h:55m:37s remains)
INFO - root - 2017-12-01 04:55:19.722332: step 53070, loss = 0.41, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 11h:47m:35s remains)
INFO - root - 2017-12-01 04:55:21.293940: step 53080, loss = 0.55, batch loss = 0.37 (49.9 examples/sec; 0.160 sec/batch; 12h:26m:06s remains)
INFO - root - 2017-12-01 04:55:22.855478: step 53090, loss = 0.38, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 12h:07m:04s remains)
INFO - root - 2017-12-01 04:55:24.414437: step 53100, loss = 0.51, batch loss = 0.33 (51.7 examples/sec; 0.155 sec/batch; 12h:00m:28s remains)
INFO - root - 2017-12-01 04:55:26.054213: step 53110, loss = 0.45, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 11h:58m:03s remains)
INFO - root - 2017-12-01 04:55:27.640316: step 53120, loss = 0.49, batch loss = 0.31 (49.3 examples/sec; 0.162 sec/batch; 12h:36m:17s remains)
INFO - root - 2017-12-01 04:55:29.197275: step 53130, loss = 0.39, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 12h:13m:36s remains)
INFO - root - 2017-12-01 04:55:30.749884: step 53140, loss = 0.44, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 11h:58m:16s remains)
INFO - root - 2017-12-01 04:55:32.325564: step 53150, loss = 0.41, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 12h:01m:07s remains)
INFO - root - 2017-12-01 04:55:33.889014: step 53160, loss = 0.70, batch loss = 0.52 (50.5 examples/sec; 0.158 sec/batch; 12h:16m:56s remains)
INFO - root - 2017-12-01 04:55:35.444205: step 53170, loss = 0.38, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 12h:11m:50s remains)
INFO - root - 2017-12-01 04:55:37.000188: step 53180, loss = 0.49, batch loss = 0.31 (49.1 examples/sec; 0.163 sec/batch; 12h:37m:47s remains)
INFO - root - 2017-12-01 04:55:38.572214: step 53190, loss = 0.44, batch loss = 0.26 (51.8 examples/sec; 0.155 sec/batch; 11h:59m:14s remains)
INFO - root - 2017-12-01 04:55:40.154355: step 53200, loss = 0.39, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 12h:03m:59s remains)
INFO - root - 2017-12-01 04:55:41.778381: step 53210, loss = 0.38, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 12h:00m:38s remains)
INFO - root - 2017-12-01 04:55:43.341774: step 53220, loss = 0.42, batch loss = 0.24 (53.1 examples/sec; 0.151 sec/batch; 11h:41m:29s remains)
INFO - root - 2017-12-01 04:55:44.890460: step 53230, loss = 0.42, batch loss = 0.24 (50.0 examples/sec; 0.160 sec/batch; 12h:24m:39s remains)
INFO - root - 2017-12-01 04:55:46.462015: step 53240, loss = 0.47, batch loss = 0.29 (49.6 examples/sec; 0.161 sec/batch; 12h:30m:41s remains)
INFO - root - 2017-12-01 04:55:48.015765: step 53250, loss = 0.38, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 11h:58m:54s remains)
INFO - root - 2017-12-01 04:55:49.567804: step 53260, loss = 0.41, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 12h:20m:02s remains)
INFO - root - 2017-12-01 04:55:51.142788: step 53270, loss = 0.46, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 12h:17m:29s remains)
INFO - root - 2017-12-01 04:55:52.697410: step 53280, loss = 0.45, batch loss = 0.28 (52.3 examples/sec; 0.153 sec/batch; 11h:51m:11s remains)
INFO - root - 2017-12-01 04:55:54.281817: step 53290, loss = 0.37, batch loss = 0.19 (52.1 examples/sec; 0.154 sec/batch; 11h:55m:00s remains)
INFO - root - 2017-12-01 04:55:55.853903: step 53300, loss = 0.43, batch loss = 0.25 (48.8 examples/sec; 0.164 sec/batch; 12h:42m:23s remains)
INFO - root - 2017-12-01 04:55:57.523260: step 53310, loss = 0.46, batch loss = 0.29 (48.9 examples/sec; 0.164 sec/batch; 12h:41m:34s remains)
INFO - root - 2017-12-01 04:55:59.083146: step 53320, loss = 0.50, batch loss = 0.32 (53.0 examples/sec; 0.151 sec/batch; 11h:42m:07s remains)
INFO - root - 2017-12-01 04:56:00.640858: step 53330, loss = 0.36, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 12h:07m:30s remains)
INFO - root - 2017-12-01 04:56:02.220506: step 53340, loss = 0.41, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 12h:11m:51s remains)
INFO - root - 2017-12-01 04:56:03.791375: step 53350, loss = 0.39, batch loss = 0.22 (50.5 examples/sec; 0.159 sec/batch; 12h:17m:43s remains)
INFO - root - 2017-12-01 04:56:05.348983: step 53360, loss = 0.43, batch loss = 0.26 (50.3 examples/sec; 0.159 sec/batch; 12h:19m:16s remains)
INFO - root - 2017-12-01 04:56:06.911155: step 53370, loss = 0.49, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 12h:06m:42s remains)
INFO - root - 2017-12-01 04:56:08.474812: step 53380, loss = 0.44, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 12h:05m:35s remains)
INFO - root - 2017-12-01 04:56:10.049598: step 53390, loss = 0.42, batch loss = 0.24 (50.8 examples/sec; 0.158 sec/batch; 12h:13m:13s remains)
INFO - root - 2017-12-01 04:56:11.609259: step 53400, loss = 0.43, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 11h:59m:27s remains)
INFO - root - 2017-12-01 04:56:13.249896: step 53410, loss = 0.38, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 12h:09m:50s remains)
INFO - root - 2017-12-01 04:56:14.844775: step 53420, loss = 0.35, batch loss = 0.17 (49.7 examples/sec; 0.161 sec/batch; 12h:29m:04s remains)
INFO - root - 2017-12-01 04:56:16.399438: step 53430, loss = 0.41, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 12h:14m:12s remains)
INFO - root - 2017-12-01 04:56:17.948518: step 53440, loss = 0.46, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 12h:09m:31s remains)
INFO - root - 2017-12-01 04:56:19.513036: step 53450, loss = 0.38, batch loss = 0.20 (49.6 examples/sec; 0.161 sec/batch; 12h:30m:08s remains)
INFO - root - 2017-12-01 04:56:21.097245: step 53460, loss = 0.45, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 12h:10m:30s remains)
INFO - root - 2017-12-01 04:56:22.645217: step 53470, loss = 0.42, batch loss = 0.24 (53.0 examples/sec; 0.151 sec/batch; 11h:41m:24s remains)
INFO - root - 2017-12-01 04:56:24.188060: step 53480, loss = 0.47, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 12h:19m:46s remains)
INFO - root - 2017-12-01 04:56:25.749058: step 53490, loss = 0.41, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 12h:18m:13s remains)
INFO - root - 2017-12-01 04:56:27.319590: step 53500, loss = 0.34, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 12h:03m:14s remains)
INFO - root - 2017-12-01 04:56:28.931329: step 53510, loss = 0.40, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 11h:52m:08s remains)
INFO - root - 2017-12-01 04:56:30.492372: step 53520, loss = 0.50, batch loss = 0.32 (51.5 examples/sec; 0.155 sec/batch; 12h:02m:50s remains)
INFO - root - 2017-12-01 04:56:32.043087: step 53530, loss = 0.44, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 12h:02m:02s remains)
INFO - root - 2017-12-01 04:56:33.603963: step 53540, loss = 0.46, batch loss = 0.28 (50.1 examples/sec; 0.160 sec/batch; 12h:21m:40s remains)
INFO - root - 2017-12-01 04:56:35.175053: step 53550, loss = 0.32, batch loss = 0.15 (50.2 examples/sec; 0.160 sec/batch; 12h:21m:35s remains)
INFO - root - 2017-12-01 04:56:36.754426: step 53560, loss = 0.40, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 11h:52m:07s remains)
INFO - root - 2017-12-01 04:56:38.324029: step 53570, loss = 0.36, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 12h:12m:26s remains)
INFO - root - 2017-12-01 04:56:39.890631: step 53580, loss = 0.37, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 12h:03m:09s remains)
INFO - root - 2017-12-01 04:56:41.479388: step 53590, loss = 0.37, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 11h:52m:48s remains)
INFO - root - 2017-12-01 04:56:43.051031: step 53600, loss = 0.48, batch loss = 0.30 (52.0 examples/sec; 0.154 sec/batch; 11h:55m:19s remains)
INFO - root - 2017-12-01 04:56:44.682548: step 53610, loss = 0.35, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 11h:59m:25s remains)
INFO - root - 2017-12-01 04:56:46.280488: step 53620, loss = 0.38, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 12h:09m:24s remains)
INFO - root - 2017-12-01 04:56:47.832978: step 53630, loss = 0.47, batch loss = 0.30 (50.4 examples/sec; 0.159 sec/batch; 12h:17m:47s remains)
INFO - root - 2017-12-01 04:56:49.399570: step 53640, loss = 0.41, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 12h:24m:46s remains)
INFO - root - 2017-12-01 04:56:50.974251: step 53650, loss = 0.42, batch loss = 0.25 (50.8 examples/sec; 0.157 sec/batch; 12h:11m:56s remains)
INFO - root - 2017-12-01 04:56:52.542320: step 53660, loss = 0.39, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 12h:15m:57s remains)
INFO - root - 2017-12-01 04:56:54.097397: step 53670, loss = 0.33, batch loss = 0.15 (51.6 examples/sec; 0.155 sec/batch; 12h:00m:10s remains)
INFO - root - 2017-12-01 04:56:55.656927: step 53680, loss = 0.43, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 12h:03m:43s remains)
INFO - root - 2017-12-01 04:56:57.221886: step 53690, loss = 0.38, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 12h:18m:07s remains)
INFO - root - 2017-12-01 04:56:58.768827: step 53700, loss = 0.34, batch loss = 0.16 (50.1 examples/sec; 0.160 sec/batch; 12h:21m:20s remains)
INFO - root - 2017-12-01 04:57:00.424247: step 53710, loss = 0.46, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 12h:06m:37s remains)
INFO - root - 2017-12-01 04:57:01.987919: step 53720, loss = 0.37, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 11h:48m:55s remains)
INFO - root - 2017-12-01 04:57:03.559792: step 53730, loss = 0.43, batch loss = 0.25 (48.6 examples/sec; 0.165 sec/batch; 12h:44m:52s remains)
INFO - root - 2017-12-01 04:57:05.157496: step 53740, loss = 0.32, batch loss = 0.15 (52.6 examples/sec; 0.152 sec/batch; 11h:46m:12s remains)
INFO - root - 2017-12-01 04:57:06.720312: step 53750, loss = 0.36, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 12h:04m:15s remains)
INFO - root - 2017-12-01 04:57:08.278072: step 53760, loss = 0.37, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 11h:57m:38s remains)
INFO - root - 2017-12-01 04:57:09.832565: step 53770, loss = 0.36, batch loss = 0.18 (53.2 examples/sec; 0.150 sec/batch; 11h:38m:59s remains)
INFO - root - 2017-12-01 04:57:11.398062: step 53780, loss = 0.41, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 11h:56m:31s remains)
INFO - root - 2017-12-01 04:57:12.957191: step 53790, loss = 0.48, batch loss = 0.31 (49.0 examples/sec; 0.163 sec/batch; 12h:37m:57s remains)
INFO - root - 2017-12-01 04:57:14.520436: step 53800, loss = 0.43, batch loss = 0.25 (49.9 examples/sec; 0.160 sec/batch; 12h:25m:16s remains)
INFO - root - 2017-12-01 04:57:16.168511: step 53810, loss = 0.61, batch loss = 0.43 (51.8 examples/sec; 0.155 sec/batch; 11h:57m:58s remains)
INFO - root - 2017-12-01 04:57:17.708862: step 53820, loss = 0.44, batch loss = 0.27 (52.1 examples/sec; 0.154 sec/batch; 11h:53m:07s remains)
INFO - root - 2017-12-01 04:57:19.273214: step 53830, loss = 0.36, batch loss = 0.18 (50.0 examples/sec; 0.160 sec/batch; 12h:23m:42s remains)
INFO - root - 2017-12-01 04:57:20.838379: step 53840, loss = 0.41, batch loss = 0.24 (49.7 examples/sec; 0.161 sec/batch; 12h:27m:11s remains)
INFO - root - 2017-12-01 04:57:22.388978: step 53850, loss = 0.37, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 12h:09m:20s remains)
INFO - root - 2017-12-01 04:57:23.959286: step 53860, loss = 0.39, batch loss = 0.21 (52.8 examples/sec; 0.151 sec/batch; 11h:42m:58s remains)
INFO - root - 2017-12-01 04:57:25.512199: step 53870, loss = 0.39, batch loss = 0.21 (53.4 examples/sec; 0.150 sec/batch; 11h:35m:35s remains)
INFO - root - 2017-12-01 04:57:27.099400: step 53880, loss = 0.53, batch loss = 0.35 (51.0 examples/sec; 0.157 sec/batch; 12h:07m:58s remains)
INFO - root - 2017-12-01 04:57:28.670493: step 53890, loss = 0.39, batch loss = 0.21 (48.7 examples/sec; 0.164 sec/batch; 12h:42m:50s remains)
INFO - root - 2017-12-01 04:57:30.222450: step 53900, loss = 0.48, batch loss = 0.30 (51.9 examples/sec; 0.154 sec/batch; 11h:55m:05s remains)
INFO - root - 2017-12-01 04:57:31.901007: step 53910, loss = 0.39, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 12h:16m:59s remains)
INFO - root - 2017-12-01 04:57:33.456994: step 53920, loss = 0.42, batch loss = 0.24 (49.7 examples/sec; 0.161 sec/batch; 12h:27m:21s remains)
INFO - root - 2017-12-01 04:57:35.035053: step 53930, loss = 0.40, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 12h:15m:15s remains)
INFO - root - 2017-12-01 04:57:36.624521: step 53940, loss = 0.39, batch loss = 0.22 (49.5 examples/sec; 0.161 sec/batch; 12h:29m:46s remains)
INFO - root - 2017-12-01 04:57:38.177107: step 53950, loss = 0.38, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 12h:02m:36s remains)
INFO - root - 2017-12-01 04:57:39.748208: step 53960, loss = 0.40, batch loss = 0.22 (49.7 examples/sec; 0.161 sec/batch; 12h:27m:10s remains)
INFO - root - 2017-12-01 04:57:41.316092: step 53970, loss = 0.43, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 11h:47m:20s remains)
INFO - root - 2017-12-01 04:57:42.869518: step 53980, loss = 0.34, batch loss = 0.16 (51.7 examples/sec; 0.155 sec/batch; 11h:57m:41s remains)
INFO - root - 2017-12-01 04:57:44.477667: step 53990, loss = 0.47, batch loss = 0.29 (50.4 examples/sec; 0.159 sec/batch; 12h:17m:00s remains)
INFO - root - 2017-12-01 04:57:46.059582: step 54000, loss = 0.39, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 11h:54m:40s remains)
INFO - root - 2017-12-01 04:57:47.676893: step 54010, loss = 0.55, batch loss = 0.38 (51.0 examples/sec; 0.157 sec/batch; 12h:07m:24s remains)
INFO - root - 2017-12-01 04:57:49.230060: step 54020, loss = 0.43, batch loss = 0.25 (53.0 examples/sec; 0.151 sec/batch; 11h:40m:15s remains)
INFO - root - 2017-12-01 04:57:50.779385: step 54030, loss = 0.39, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 11h:55m:03s remains)
INFO - root - 2017-12-01 04:57:52.349249: step 54040, loss = 0.36, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 12h:04m:43s remains)
INFO - root - 2017-12-01 04:57:53.923790: step 54050, loss = 0.43, batch loss = 0.25 (52.1 examples/sec; 0.154 sec/batch; 11h:52m:44s remains)
INFO - root - 2017-12-01 04:57:55.482959: step 54060, loss = 0.42, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 12h:08m:40s remains)
INFO - root - 2017-12-01 04:57:57.041398: step 54070, loss = 0.46, batch loss = 0.29 (51.0 examples/sec; 0.157 sec/batch; 12h:07m:26s remains)
INFO - root - 2017-12-01 04:57:58.612590: step 54080, loss = 0.42, batch loss = 0.24 (48.7 examples/sec; 0.164 sec/batch; 12h:41m:50s remains)
INFO - root - 2017-12-01 04:58:00.184203: step 54090, loss = 0.40, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 12h:07m:08s remains)
INFO - root - 2017-12-01 04:58:01.744796: step 54100, loss = 0.46, batch loss = 0.28 (52.1 examples/sec; 0.154 sec/batch; 11h:52m:53s remains)
INFO - root - 2017-12-01 04:58:03.348925: step 54110, loss = 0.40, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 12h:22m:01s remains)
INFO - root - 2017-12-01 04:58:04.907005: step 54120, loss = 0.49, batch loss = 0.32 (51.2 examples/sec; 0.156 sec/batch; 12h:04m:55s remains)
INFO - root - 2017-12-01 04:58:06.470913: step 54130, loss = 0.45, batch loss = 0.28 (52.1 examples/sec; 0.153 sec/batch; 11h:51m:56s remains)
INFO - root - 2017-12-01 04:58:08.038604: step 54140, loss = 0.40, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 12h:13m:43s remains)
INFO - root - 2017-12-01 04:58:09.612559: step 54150, loss = 0.37, batch loss = 0.20 (50.2 examples/sec; 0.160 sec/batch; 12h:20m:02s remains)
INFO - root - 2017-12-01 04:58:11.192530: step 54160, loss = 0.41, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 12h:09m:49s remains)
INFO - root - 2017-12-01 04:58:12.768879: step 54170, loss = 0.39, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 11h:55m:00s remains)
INFO - root - 2017-12-01 04:58:14.338753: step 54180, loss = 0.38, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 12h:03m:11s remains)
INFO - root - 2017-12-01 04:58:15.921961: step 54190, loss = 0.39, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 12h:10m:16s remains)
INFO - root - 2017-12-01 04:58:17.461707: step 54200, loss = 0.46, batch loss = 0.28 (51.8 examples/sec; 0.154 sec/batch; 11h:55m:46s remains)
INFO - root - 2017-12-01 04:58:19.081231: step 54210, loss = 0.36, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 11h:55m:26s remains)
INFO - root - 2017-12-01 04:58:20.636843: step 54220, loss = 0.36, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 11h:50m:10s remains)
INFO - root - 2017-12-01 04:58:22.190181: step 54230, loss = 0.38, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 12h:03m:10s remains)
INFO - root - 2017-12-01 04:58:23.740205: step 54240, loss = 0.38, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 12h:19m:08s remains)
INFO - root - 2017-12-01 04:58:25.302254: step 54250, loss = 0.40, batch loss = 0.23 (48.8 examples/sec; 0.164 sec/batch; 12h:40m:25s remains)
INFO - root - 2017-12-01 04:58:26.891633: step 54260, loss = 0.45, batch loss = 0.27 (50.4 examples/sec; 0.159 sec/batch; 12h:16m:34s remains)
INFO - root - 2017-12-01 04:58:28.461551: step 54270, loss = 0.41, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 12h:17m:37s remains)
INFO - root - 2017-12-01 04:58:30.019315: step 54280, loss = 0.36, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 12h:15m:31s remains)
INFO - root - 2017-12-01 04:58:31.583068: step 54290, loss = 0.46, batch loss = 0.29 (52.8 examples/sec; 0.152 sec/batch; 11h:42m:41s remains)
INFO - root - 2017-12-01 04:58:33.142868: step 54300, loss = 0.45, batch loss = 0.27 (51.8 examples/sec; 0.154 sec/batch; 11h:55m:46s remains)
INFO - root - 2017-12-01 04:58:34.761534: step 54310, loss = 0.37, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 11h:57m:23s remains)
INFO - root - 2017-12-01 04:58:36.319491: step 54320, loss = 0.48, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 12h:07m:09s remains)
INFO - root - 2017-12-01 04:58:37.892432: step 54330, loss = 0.40, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 12h:03m:46s remains)
INFO - root - 2017-12-01 04:58:39.447916: step 54340, loss = 0.40, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 11h:47m:08s remains)
INFO - root - 2017-12-01 04:58:41.024442: step 54350, loss = 0.47, batch loss = 0.29 (50.0 examples/sec; 0.160 sec/batch; 12h:22m:16s remains)
INFO - root - 2017-12-01 04:58:42.583241: step 54360, loss = 0.33, batch loss = 0.16 (51.7 examples/sec; 0.155 sec/batch; 11h:57m:36s remains)
INFO - root - 2017-12-01 04:58:44.142153: step 54370, loss = 0.40, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 12h:14m:28s remains)
INFO - root - 2017-12-01 04:58:45.715915: step 54380, loss = 0.40, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 11h:58m:46s remains)
INFO - root - 2017-12-01 04:58:47.288900: step 54390, loss = 0.47, batch loss = 0.29 (51.8 examples/sec; 0.154 sec/batch; 11h:55m:39s remains)
INFO - root - 2017-12-01 04:58:48.865616: step 54400, loss = 0.38, batch loss = 0.20 (52.9 examples/sec; 0.151 sec/batch; 11h:40m:51s remains)
INFO - root - 2017-12-01 04:58:50.504479: step 54410, loss = 0.47, batch loss = 0.29 (52.0 examples/sec; 0.154 sec/batch; 11h:52m:45s remains)
INFO - root - 2017-12-01 04:58:52.064391: step 54420, loss = 0.49, batch loss = 0.31 (50.7 examples/sec; 0.158 sec/batch; 12h:11m:14s remains)
INFO - root - 2017-12-01 04:58:53.629094: step 54430, loss = 0.39, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 11h:58m:30s remains)
INFO - root - 2017-12-01 04:58:55.194094: step 54440, loss = 0.36, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 12h:13m:29s remains)
INFO - root - 2017-12-01 04:58:56.754492: step 54450, loss = 0.31, batch loss = 0.14 (50.7 examples/sec; 0.158 sec/batch; 12h:10m:37s remains)
INFO - root - 2017-12-01 04:58:58.315144: step 54460, loss = 0.40, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 11h:45m:04s remains)
INFO - root - 2017-12-01 04:58:59.882687: step 54470, loss = 0.39, batch loss = 0.21 (51.1 examples/sec; 0.156 sec/batch; 12h:05m:11s remains)
INFO - root - 2017-12-01 04:59:01.465332: step 54480, loss = 0.41, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 12h:03m:36s remains)
INFO - root - 2017-12-01 04:59:03.035654: step 54490, loss = 0.37, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 11h:59m:57s remains)
INFO - root - 2017-12-01 04:59:04.584427: step 54500, loss = 0.41, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 11h:44m:22s remains)
INFO - root - 2017-12-01 04:59:06.249609: step 54510, loss = 0.55, batch loss = 0.38 (51.3 examples/sec; 0.156 sec/batch; 12h:01m:57s remains)
INFO - root - 2017-12-01 04:59:07.802034: step 54520, loss = 0.41, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 12h:04m:19s remains)
INFO - root - 2017-12-01 04:59:09.372449: step 54530, loss = 0.35, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 12h:00m:44s remains)
INFO - root - 2017-12-01 04:59:10.942241: step 54540, loss = 0.55, batch loss = 0.37 (50.9 examples/sec; 0.157 sec/batch; 12h:08m:25s remains)
INFO - root - 2017-12-01 04:59:12.514780: step 54550, loss = 0.44, batch loss = 0.26 (49.0 examples/sec; 0.163 sec/batch; 12h:36m:25s remains)
INFO - root - 2017-12-01 04:59:14.092221: step 54560, loss = 0.38, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 12h:17m:45s remains)
INFO - root - 2017-12-01 04:59:15.653793: step 54570, loss = 0.42, batch loss = 0.24 (52.4 examples/sec; 0.153 sec/batch; 11h:47m:43s remains)
INFO - root - 2017-12-01 04:59:17.213893: step 54580, loss = 0.45, batch loss = 0.27 (51.9 examples/sec; 0.154 sec/batch; 11h:53m:40s remains)
INFO - root - 2017-12-01 04:59:18.791433: step 54590, loss = 0.35, batch loss = 0.18 (49.7 examples/sec; 0.161 sec/batch; 12h:25m:18s remains)
INFO - root - 2017-12-01 04:59:20.349908: step 54600, loss = 0.40, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 11h:56m:26s remains)
INFO - root - 2017-12-01 04:59:21.949755: step 54610, loss = 0.48, batch loss = 0.30 (51.1 examples/sec; 0.157 sec/batch; 12h:05m:32s remains)
INFO - root - 2017-12-01 04:59:23.715995: step 54620, loss = 0.46, batch loss = 0.28 (29.4 examples/sec; 0.272 sec/batch; 21h:00m:24s remains)
INFO - root - 2017-12-01 04:59:25.290250: step 54630, loss = 0.54, batch loss = 0.37 (50.1 examples/sec; 0.160 sec/batch; 12h:20m:03s remains)
INFO - root - 2017-12-01 04:59:26.859536: step 54640, loss = 0.44, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 11h:52m:30s remains)
INFO - root - 2017-12-01 04:59:28.448209: step 54650, loss = 0.39, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 11h:52m:17s remains)
INFO - root - 2017-12-01 04:59:30.004764: step 54660, loss = 0.41, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 12h:03m:21s remains)
INFO - root - 2017-12-01 04:59:31.569376: step 54670, loss = 0.37, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 12h:18m:43s remains)
INFO - root - 2017-12-01 04:59:33.138742: step 54680, loss = 0.33, batch loss = 0.16 (51.1 examples/sec; 0.157 sec/batch; 12h:04m:57s remains)
INFO - root - 2017-12-01 04:59:34.715065: step 54690, loss = 0.55, batch loss = 0.37 (50.9 examples/sec; 0.157 sec/batch; 12h:08m:14s remains)
INFO - root - 2017-12-01 04:59:36.278986: step 54700, loss = 0.49, batch loss = 0.32 (52.0 examples/sec; 0.154 sec/batch; 11h:52m:17s remains)
INFO - root - 2017-12-01 04:59:37.916623: step 54710, loss = 0.42, batch loss = 0.25 (49.3 examples/sec; 0.162 sec/batch; 12h:31m:08s remains)
INFO - root - 2017-12-01 04:59:39.488291: step 54720, loss = 0.46, batch loss = 0.29 (52.4 examples/sec; 0.153 sec/batch; 11h:47m:14s remains)
INFO - root - 2017-12-01 04:59:41.054203: step 54730, loss = 0.40, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 12h:11m:52s remains)
INFO - root - 2017-12-01 04:59:42.635904: step 54740, loss = 0.41, batch loss = 0.23 (49.6 examples/sec; 0.161 sec/batch; 12h:26m:21s remains)
INFO - root - 2017-12-01 04:59:44.222170: step 54750, loss = 0.36, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 12h:01m:39s remains)
INFO - root - 2017-12-01 04:59:45.788877: step 54760, loss = 0.39, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 11h:51m:16s remains)
INFO - root - 2017-12-01 04:59:47.344977: step 54770, loss = 0.38, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 12h:03m:05s remains)
INFO - root - 2017-12-01 04:59:48.912708: step 54780, loss = 0.36, batch loss = 0.18 (49.4 examples/sec; 0.162 sec/batch; 12h:29m:00s remains)
INFO - root - 2017-12-01 04:59:50.493592: step 54790, loss = 0.58, batch loss = 0.40 (52.1 examples/sec; 0.153 sec/batch; 11h:50m:17s remains)
INFO - root - 2017-12-01 04:59:52.086166: step 54800, loss = 0.56, batch loss = 0.39 (50.4 examples/sec; 0.159 sec/batch; 12h:14m:59s remains)
INFO - root - 2017-12-01 04:59:53.711836: step 54810, loss = 0.38, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 12h:05m:28s remains)
INFO - root - 2017-12-01 04:59:55.283197: step 54820, loss = 0.35, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 12h:07m:47s remains)
INFO - root - 2017-12-01 04:59:56.844555: step 54830, loss = 0.43, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 12h:01m:15s remains)
INFO - root - 2017-12-01 04:59:58.407309: step 54840, loss = 0.43, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 12h:11m:33s remains)
INFO - root - 2017-12-01 04:59:59.975568: step 54850, loss = 0.38, batch loss = 0.21 (49.6 examples/sec; 0.161 sec/batch; 12h:27m:01s remains)
INFO - root - 2017-12-01 05:00:01.539286: step 54860, loss = 0.45, batch loss = 0.27 (51.9 examples/sec; 0.154 sec/batch; 11h:53m:47s remains)
INFO - root - 2017-12-01 05:00:03.108707: step 54870, loss = 0.52, batch loss = 0.34 (50.9 examples/sec; 0.157 sec/batch; 12h:07m:45s remains)
INFO - root - 2017-12-01 05:00:04.679233: step 54880, loss = 0.46, batch loss = 0.29 (50.5 examples/sec; 0.158 sec/batch; 12h:13m:06s remains)
INFO - root - 2017-12-01 05:00:06.240645: step 54890, loss = 0.41, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 12h:22m:03s remains)
INFO - root - 2017-12-01 05:00:07.818218: step 54900, loss = 0.46, batch loss = 0.28 (50.0 examples/sec; 0.160 sec/batch; 12h:19m:32s remains)
INFO - root - 2017-12-01 05:00:09.427667: step 54910, loss = 0.41, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 11h:55m:33s remains)
INFO - root - 2017-12-01 05:00:10.993044: step 54920, loss = 0.38, batch loss = 0.20 (47.3 examples/sec; 0.169 sec/batch; 13h:02m:56s remains)
INFO - root - 2017-12-01 05:00:12.569213: step 54930, loss = 0.42, batch loss = 0.24 (48.6 examples/sec; 0.165 sec/batch; 12h:41m:54s remains)
INFO - root - 2017-12-01 05:00:14.151198: step 54940, loss = 0.45, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 12h:01m:46s remains)
INFO - root - 2017-12-01 05:00:15.721041: step 54950, loss = 0.45, batch loss = 0.27 (51.2 examples/sec; 0.156 sec/batch; 12h:02m:35s remains)
INFO - root - 2017-12-01 05:00:17.288415: step 54960, loss = 0.39, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 12h:13m:47s remains)
INFO - root - 2017-12-01 05:00:18.848128: step 54970, loss = 0.39, batch loss = 0.22 (49.8 examples/sec; 0.160 sec/batch; 12h:22m:21s remains)
INFO - root - 2017-12-01 05:00:20.447680: step 54980, loss = 0.39, batch loss = 0.21 (49.9 examples/sec; 0.160 sec/batch; 12h:21m:32s remains)
INFO - root - 2017-12-01 05:00:22.029495: step 54990, loss = 0.53, batch loss = 0.36 (51.0 examples/sec; 0.157 sec/batch; 12h:05m:15s remains)
INFO - root - 2017-12-01 05:00:23.591374: step 55000, loss = 0.49, batch loss = 0.31 (50.6 examples/sec; 0.158 sec/batch; 12h:10m:45s remains)
INFO - root - 2017-12-01 05:00:25.281595: step 55010, loss = 0.40, batch loss = 0.22 (49.6 examples/sec; 0.161 sec/batch; 12h:26m:39s remains)
INFO - root - 2017-12-01 05:00:26.841609: step 55020, loss = 0.39, batch loss = 0.22 (51.8 examples/sec; 0.155 sec/batch; 11h:54m:31s remains)
INFO - root - 2017-12-01 05:00:28.398083: step 55030, loss = 0.41, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 11h:57m:51s remains)
INFO - root - 2017-12-01 05:00:29.962601: step 55040, loss = 0.41, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 12h:01m:49s remains)
INFO - root - 2017-12-01 05:00:31.516150: step 55050, loss = 0.37, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 11h:47m:55s remains)
INFO - root - 2017-12-01 05:00:33.085250: step 55060, loss = 0.48, batch loss = 0.31 (51.5 examples/sec; 0.155 sec/batch; 11h:58m:29s remains)
INFO - root - 2017-12-01 05:00:34.645507: step 55070, loss = 0.41, batch loss = 0.24 (50.0 examples/sec; 0.160 sec/batch; 12h:20m:01s remains)
INFO - root - 2017-12-01 05:00:36.210150: step 55080, loss = 0.48, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 12h:08m:53s remains)
INFO - root - 2017-12-01 05:00:37.761995: step 55090, loss = 0.36, batch loss = 0.19 (53.5 examples/sec; 0.149 sec/batch; 11h:31m:08s remains)
INFO - root - 2017-12-01 05:00:39.317628: step 55100, loss = 0.36, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 12h:00m:32s remains)
INFO - root - 2017-12-01 05:00:40.955036: step 55110, loss = 0.40, batch loss = 0.23 (47.7 examples/sec; 0.168 sec/batch; 12h:55m:39s remains)
INFO - root - 2017-12-01 05:00:42.533968: step 55120, loss = 0.39, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 12h:05m:02s remains)
INFO - root - 2017-12-01 05:00:44.084221: step 55130, loss = 0.57, batch loss = 0.40 (51.6 examples/sec; 0.155 sec/batch; 11h:57m:21s remains)
INFO - root - 2017-12-01 05:00:45.644290: step 55140, loss = 0.51, batch loss = 0.33 (51.1 examples/sec; 0.156 sec/batch; 12h:03m:09s remains)
INFO - root - 2017-12-01 05:00:47.204088: step 55150, loss = 0.35, batch loss = 0.17 (50.0 examples/sec; 0.160 sec/batch; 12h:19m:49s remains)
INFO - root - 2017-12-01 05:00:48.748161: step 55160, loss = 0.46, batch loss = 0.28 (52.7 examples/sec; 0.152 sec/batch; 11h:42m:18s remains)
INFO - root - 2017-12-01 05:00:50.319077: step 55170, loss = 0.48, batch loss = 0.30 (52.3 examples/sec; 0.153 sec/batch; 11h:46m:53s remains)
INFO - root - 2017-12-01 05:00:51.876215: step 55180, loss = 0.37, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 11h:47m:52s remains)
INFO - root - 2017-12-01 05:00:53.438203: step 55190, loss = 0.44, batch loss = 0.26 (52.5 examples/sec; 0.152 sec/batch; 11h:44m:07s remains)
INFO - root - 2017-12-01 05:00:55.013899: step 55200, loss = 0.38, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 12h:01m:08s remains)
INFO - root - 2017-12-01 05:00:56.669029: step 55210, loss = 0.44, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 11h:50m:48s remains)
INFO - root - 2017-12-01 05:00:58.227407: step 55220, loss = 0.39, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 12h:11m:26s remains)
INFO - root - 2017-12-01 05:00:59.792621: step 55230, loss = 0.42, batch loss = 0.25 (49.4 examples/sec; 0.162 sec/batch; 12h:27m:45s remains)
INFO - root - 2017-12-01 05:01:01.376111: step 55240, loss = 0.39, batch loss = 0.22 (51.8 examples/sec; 0.155 sec/batch; 11h:54m:06s remains)
INFO - root - 2017-12-01 05:01:02.943926: step 55250, loss = 0.36, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 11h:59m:23s remains)
INFO - root - 2017-12-01 05:01:04.495739: step 55260, loss = 0.46, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 12h:12m:07s remains)
INFO - root - 2017-12-01 05:01:06.048943: step 55270, loss = 0.42, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 12h:14m:27s remains)
INFO - root - 2017-12-01 05:01:07.585944: step 55280, loss = 0.37, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 11h:56m:07s remains)
INFO - root - 2017-12-01 05:01:09.139778: step 55290, loss = 0.40, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 12h:19m:53s remains)
INFO - root - 2017-12-01 05:01:10.709876: step 55300, loss = 0.44, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 12h:10m:55s remains)
INFO - root - 2017-12-01 05:01:12.334231: step 55310, loss = 0.44, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 12h:08m:26s remains)
INFO - root - 2017-12-01 05:01:13.889919: step 55320, loss = 0.37, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 12h:02m:13s remains)
INFO - root - 2017-12-01 05:01:15.451065: step 55330, loss = 0.39, batch loss = 0.22 (49.6 examples/sec; 0.161 sec/batch; 12h:24m:49s remains)
INFO - root - 2017-12-01 05:01:17.013334: step 55340, loss = 0.41, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 12h:04m:16s remains)
INFO - root - 2017-12-01 05:01:18.593938: step 55350, loss = 0.33, batch loss = 0.15 (51.0 examples/sec; 0.157 sec/batch; 12h:04m:51s remains)
INFO - root - 2017-12-01 05:01:20.163375: step 55360, loss = 0.36, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 12h:12m:33s remains)
INFO - root - 2017-12-01 05:01:21.718925: step 55370, loss = 0.43, batch loss = 0.26 (52.1 examples/sec; 0.154 sec/batch; 11h:49m:52s remains)
INFO - root - 2017-12-01 05:01:23.274065: step 55380, loss = 0.59, batch loss = 0.42 (52.3 examples/sec; 0.153 sec/batch; 11h:46m:14s remains)
INFO - root - 2017-12-01 05:01:24.849491: step 55390, loss = 0.36, batch loss = 0.19 (52.9 examples/sec; 0.151 sec/batch; 11h:38m:23s remains)
INFO - root - 2017-12-01 05:01:26.447054: step 55400, loss = 0.36, batch loss = 0.19 (50.3 examples/sec; 0.159 sec/batch; 12h:14m:08s remains)
INFO - root - 2017-12-01 05:01:28.092397: step 55410, loss = 0.47, batch loss = 0.29 (48.8 examples/sec; 0.164 sec/batch; 12h:37m:17s remains)
INFO - root - 2017-12-01 05:01:29.643795: step 55420, loss = 0.38, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 11h:47m:17s remains)
INFO - root - 2017-12-01 05:01:31.211280: step 55430, loss = 0.51, batch loss = 0.34 (50.9 examples/sec; 0.157 sec/batch; 12h:05m:33s remains)
INFO - root - 2017-12-01 05:01:32.774887: step 55440, loss = 0.48, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 11h:56m:17s remains)
INFO - root - 2017-12-01 05:01:34.336245: step 55450, loss = 0.48, batch loss = 0.31 (52.7 examples/sec; 0.152 sec/batch; 11h:41m:01s remains)
INFO - root - 2017-12-01 05:01:35.889347: step 55460, loss = 0.50, batch loss = 0.32 (52.6 examples/sec; 0.152 sec/batch; 11h:42m:41s remains)
INFO - root - 2017-12-01 05:01:37.448018: step 55470, loss = 0.40, batch loss = 0.22 (51.8 examples/sec; 0.155 sec/batch; 11h:53m:21s remains)
INFO - root - 2017-12-01 05:01:39.017235: step 55480, loss = 0.44, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 12h:08m:22s remains)
INFO - root - 2017-12-01 05:01:40.562019: step 55490, loss = 0.40, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 12h:10m:32s remains)
INFO - root - 2017-12-01 05:01:42.103227: step 55500, loss = 0.36, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 12h:04m:38s remains)
INFO - root - 2017-12-01 05:01:43.746645: step 55510, loss = 0.49, batch loss = 0.32 (52.5 examples/sec; 0.152 sec/batch; 11h:42m:58s remains)
INFO - root - 2017-12-01 05:01:45.314033: step 55520, loss = 0.41, batch loss = 0.24 (50.1 examples/sec; 0.160 sec/batch; 12h:17m:00s remains)
INFO - root - 2017-12-01 05:01:46.865870: step 55530, loss = 0.38, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 11h:46m:12s remains)
INFO - root - 2017-12-01 05:01:48.400100: step 55540, loss = 0.34, batch loss = 0.17 (52.5 examples/sec; 0.152 sec/batch; 11h:43m:33s remains)
INFO - root - 2017-12-01 05:01:49.974025: step 55550, loss = 0.36, batch loss = 0.19 (49.7 examples/sec; 0.161 sec/batch; 12h:22m:19s remains)
INFO - root - 2017-12-01 05:01:51.539602: step 55560, loss = 0.62, batch loss = 0.44 (50.6 examples/sec; 0.158 sec/batch; 12h:09m:43s remains)
INFO - root - 2017-12-01 05:01:53.106520: step 55570, loss = 0.39, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 12h:03m:22s remains)
INFO - root - 2017-12-01 05:01:54.678037: step 55580, loss = 0.36, batch loss = 0.18 (49.4 examples/sec; 0.162 sec/batch; 12h:27m:11s remains)
INFO - root - 2017-12-01 05:01:56.235133: step 55590, loss = 0.57, batch loss = 0.39 (49.3 examples/sec; 0.162 sec/batch; 12h:28m:20s remains)
INFO - root - 2017-12-01 05:01:57.805539: step 55600, loss = 0.39, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 11h:55m:56s remains)
INFO - root - 2017-12-01 05:01:59.430178: step 55610, loss = 0.46, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 12h:05m:45s remains)
INFO - root - 2017-12-01 05:02:00.991437: step 55620, loss = 0.39, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 12h:13m:37s remains)
INFO - root - 2017-12-01 05:02:02.554028: step 55630, loss = 0.54, batch loss = 0.36 (48.9 examples/sec; 0.163 sec/batch; 12h:34m:17s remains)
INFO - root - 2017-12-01 05:02:04.122306: step 55640, loss = 0.45, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 12h:11m:09s remains)
INFO - root - 2017-12-01 05:02:05.689593: step 55650, loss = 0.42, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 12h:00m:22s remains)
INFO - root - 2017-12-01 05:02:07.257874: step 55660, loss = 0.40, batch loss = 0.22 (49.5 examples/sec; 0.161 sec/batch; 12h:24m:59s remains)
INFO - root - 2017-12-01 05:02:08.818971: step 55670, loss = 0.37, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 11h:50m:15s remains)
INFO - root - 2017-12-01 05:02:10.379784: step 55680, loss = 0.38, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 11h:45m:13s remains)
INFO - root - 2017-12-01 05:02:11.964528: step 55690, loss = 0.50, batch loss = 0.33 (51.0 examples/sec; 0.157 sec/batch; 12h:03m:04s remains)
INFO - root - 2017-12-01 05:02:13.534226: step 55700, loss = 0.38, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 12h:10m:51s remains)
INFO - root - 2017-12-01 05:02:15.139047: step 55710, loss = 0.43, batch loss = 0.25 (52.0 examples/sec; 0.154 sec/batch; 11h:49m:58s remains)
INFO - root - 2017-12-01 05:02:16.707880: step 55720, loss = 0.52, batch loss = 0.35 (51.7 examples/sec; 0.155 sec/batch; 11h:54m:00s remains)
INFO - root - 2017-12-01 05:02:18.270936: step 55730, loss = 0.42, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 11h:44m:57s remains)
INFO - root - 2017-12-01 05:02:19.847453: step 55740, loss = 0.42, batch loss = 0.25 (49.9 examples/sec; 0.160 sec/batch; 12h:19m:28s remains)
INFO - root - 2017-12-01 05:02:21.396160: step 55750, loss = 0.41, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 11h:53m:18s remains)
INFO - root - 2017-12-01 05:02:22.949855: step 55760, loss = 0.41, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 11h:50m:09s remains)
INFO - root - 2017-12-01 05:02:24.537014: step 55770, loss = 0.51, batch loss = 0.34 (51.3 examples/sec; 0.156 sec/batch; 11h:59m:12s remains)
INFO - root - 2017-12-01 05:02:26.102686: step 55780, loss = 0.39, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 12h:09m:25s remains)
INFO - root - 2017-12-01 05:02:27.682959: step 55790, loss = 0.46, batch loss = 0.29 (49.5 examples/sec; 0.162 sec/batch; 12h:24m:50s remains)
INFO - root - 2017-12-01 05:02:29.239657: step 55800, loss = 0.53, batch loss = 0.36 (50.7 examples/sec; 0.158 sec/batch; 12h:07m:29s remains)
INFO - root - 2017-12-01 05:02:30.857511: step 55810, loss = 0.39, batch loss = 0.21 (51.1 examples/sec; 0.156 sec/batch; 12h:01m:36s remains)
INFO - root - 2017-12-01 05:02:32.432162: step 55820, loss = 0.47, batch loss = 0.29 (50.8 examples/sec; 0.157 sec/batch; 12h:06m:09s remains)
INFO - root - 2017-12-01 05:02:33.983959: step 55830, loss = 0.39, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 11h:49m:48s remains)
INFO - root - 2017-12-01 05:02:35.540353: step 55840, loss = 0.43, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 11h:52m:12s remains)
INFO - root - 2017-12-01 05:02:37.099629: step 55850, loss = 0.35, batch loss = 0.17 (52.5 examples/sec; 0.152 sec/batch; 11h:42m:50s remains)
INFO - root - 2017-12-01 05:02:38.646644: step 55860, loss = 0.60, batch loss = 0.43 (51.8 examples/sec; 0.154 sec/batch; 11h:51m:46s remains)
INFO - root - 2017-12-01 05:02:40.211496: step 55870, loss = 0.45, batch loss = 0.28 (50.8 examples/sec; 0.157 sec/batch; 12h:05m:41s remains)
INFO - root - 2017-12-01 05:02:41.777957: step 55880, loss = 0.38, batch loss = 0.21 (49.7 examples/sec; 0.161 sec/batch; 12h:21m:44s remains)
INFO - root - 2017-12-01 05:02:43.343659: step 55890, loss = 0.43, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 12h:07m:44s remains)
INFO - root - 2017-12-01 05:02:44.906778: step 55900, loss = 0.49, batch loss = 0.32 (50.9 examples/sec; 0.157 sec/batch; 12h:05m:01s remains)
INFO - root - 2017-12-01 05:02:46.507118: step 55910, loss = 0.43, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 12h:06m:53s remains)
INFO - root - 2017-12-01 05:02:48.064508: step 55920, loss = 0.40, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 12h:00m:54s remains)
INFO - root - 2017-12-01 05:02:49.630459: step 55930, loss = 0.32, batch loss = 0.15 (48.3 examples/sec; 0.166 sec/batch; 12h:43m:35s remains)
INFO - root - 2017-12-01 05:02:51.215250: step 55940, loss = 0.40, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 11h:50m:16s remains)
INFO - root - 2017-12-01 05:02:52.777462: step 55950, loss = 0.38, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 12h:06m:05s remains)
INFO - root - 2017-12-01 05:02:54.339688: step 55960, loss = 0.41, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 11h:58m:24s remains)
INFO - root - 2017-12-01 05:02:55.907705: step 55970, loss = 0.51, batch loss = 0.33 (51.4 examples/sec; 0.156 sec/batch; 11h:57m:40s remains)
INFO - root - 2017-12-01 05:02:57.461326: step 55980, loss = 0.50, batch loss = 0.33 (51.2 examples/sec; 0.156 sec/batch; 12h:00m:18s remains)
INFO - root - 2017-12-01 05:02:59.033371: step 55990, loss = 0.36, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 12h:02m:21s remains)
INFO - root - 2017-12-01 05:03:00.600896: step 56000, loss = 0.38, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 12h:07m:23s remains)
INFO - root - 2017-12-01 05:03:02.239945: step 56010, loss = 0.42, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 11h:54m:05s remains)
INFO - root - 2017-12-01 05:03:03.815646: step 56020, loss = 0.38, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 12h:08m:30s remains)
INFO - root - 2017-12-01 05:03:05.383288: step 56030, loss = 0.44, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 12h:08m:23s remains)
INFO - root - 2017-12-01 05:03:06.950554: step 56040, loss = 0.46, batch loss = 0.28 (50.1 examples/sec; 0.160 sec/batch; 12h:16m:03s remains)
INFO - root - 2017-12-01 05:03:08.505021: step 56050, loss = 0.40, batch loss = 0.23 (52.8 examples/sec; 0.152 sec/batch; 11h:38m:32s remains)
INFO - root - 2017-12-01 05:03:10.087684: step 56060, loss = 0.36, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 11h:45m:37s remains)
INFO - root - 2017-12-01 05:03:11.646906: step 56070, loss = 0.46, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 11h:54m:27s remains)
INFO - root - 2017-12-01 05:03:13.212822: step 56080, loss = 0.37, batch loss = 0.20 (53.5 examples/sec; 0.150 sec/batch; 11h:29m:17s remains)
INFO - root - 2017-12-01 05:03:14.758736: step 56090, loss = 0.39, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 11h:54m:35s remains)
INFO - root - 2017-12-01 05:03:16.319181: step 56100, loss = 0.44, batch loss = 0.27 (51.2 examples/sec; 0.156 sec/batch; 11h:59m:31s remains)
INFO - root - 2017-12-01 05:03:17.996062: step 56110, loss = 0.53, batch loss = 0.36 (49.7 examples/sec; 0.161 sec/batch; 12h:21m:02s remains)
INFO - root - 2017-12-01 05:03:19.588041: step 56120, loss = 0.39, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 12h:05m:51s remains)
INFO - root - 2017-12-01 05:03:21.188095: step 56130, loss = 0.38, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 12h:14m:59s remains)
INFO - root - 2017-12-01 05:03:22.764832: step 56140, loss = 0.34, batch loss = 0.17 (47.6 examples/sec; 0.168 sec/batch; 12h:53m:58s remains)
INFO - root - 2017-12-01 05:03:24.341390: step 56150, loss = 0.42, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 12h:11m:45s remains)
INFO - root - 2017-12-01 05:03:25.913901: step 56160, loss = 0.47, batch loss = 0.30 (52.8 examples/sec; 0.151 sec/batch; 11h:37m:36s remains)
INFO - root - 2017-12-01 05:03:27.473858: step 56170, loss = 0.37, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 11h:56m:28s remains)
INFO - root - 2017-12-01 05:03:29.039975: step 56180, loss = 0.57, batch loss = 0.40 (50.1 examples/sec; 0.160 sec/batch; 12h:15m:58s remains)
INFO - root - 2017-12-01 05:03:30.624113: step 56190, loss = 0.46, batch loss = 0.29 (48.0 examples/sec; 0.167 sec/batch; 12h:48m:16s remains)
INFO - root - 2017-12-01 05:03:32.197635: step 56200, loss = 0.42, batch loss = 0.25 (51.8 examples/sec; 0.155 sec/batch; 11h:51m:31s remains)
INFO - root - 2017-12-01 05:03:33.818140: step 56210, loss = 0.39, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 11h:42m:47s remains)
INFO - root - 2017-12-01 05:03:35.400478: step 56220, loss = 0.43, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 11h:54m:37s remains)
INFO - root - 2017-12-01 05:03:36.968690: step 56230, loss = 0.46, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 11h:54m:41s remains)
INFO - root - 2017-12-01 05:03:38.527447: step 56240, loss = 0.35, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 11h:59m:52s remains)
INFO - root - 2017-12-01 05:03:40.088060: step 56250, loss = 0.39, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 11h:58m:08s remains)
INFO - root - 2017-12-01 05:03:41.672144: step 56260, loss = 0.39, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 11h:55m:17s remains)
INFO - root - 2017-12-01 05:03:43.222297: step 56270, loss = 0.34, batch loss = 0.17 (52.9 examples/sec; 0.151 sec/batch; 11h:36m:47s remains)
INFO - root - 2017-12-01 05:03:44.790664: step 56280, loss = 0.48, batch loss = 0.30 (51.1 examples/sec; 0.156 sec/batch; 12h:00m:07s remains)
INFO - root - 2017-12-01 05:03:46.356330: step 56290, loss = 0.42, batch loss = 0.25 (49.7 examples/sec; 0.161 sec/batch; 12h:20m:45s remains)
INFO - root - 2017-12-01 05:03:47.911228: step 56300, loss = 0.40, batch loss = 0.23 (50.0 examples/sec; 0.160 sec/batch; 12h:16m:39s remains)
INFO - root - 2017-12-01 05:03:49.564728: step 56310, loss = 0.35, batch loss = 0.18 (51.1 examples/sec; 0.156 sec/batch; 12h:00m:14s remains)
INFO - root - 2017-12-01 05:03:51.133276: step 56320, loss = 0.37, batch loss = 0.19 (48.6 examples/sec; 0.165 sec/batch; 12h:37m:28s remains)
INFO - root - 2017-12-01 05:03:52.701518: step 56330, loss = 0.56, batch loss = 0.39 (48.8 examples/sec; 0.164 sec/batch; 12h:34m:49s remains)
INFO - root - 2017-12-01 05:03:54.258108: step 56340, loss = 0.48, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 11h:53m:11s remains)
INFO - root - 2017-12-01 05:03:55.814078: step 56350, loss = 0.35, batch loss = 0.18 (52.5 examples/sec; 0.152 sec/batch; 11h:41m:34s remains)
INFO - root - 2017-12-01 05:03:57.406582: step 56360, loss = 0.41, batch loss = 0.23 (49.6 examples/sec; 0.161 sec/batch; 12h:21m:53s remains)
INFO - root - 2017-12-01 05:03:58.959493: step 56370, loss = 0.36, batch loss = 0.19 (50.5 examples/sec; 0.159 sec/batch; 12h:09m:42s remains)
INFO - root - 2017-12-01 05:04:00.535649: step 56380, loss = 0.33, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 11h:54m:59s remains)
INFO - root - 2017-12-01 05:04:02.087092: step 56390, loss = 0.43, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 11h:52m:51s remains)
INFO - root - 2017-12-01 05:04:03.664711: step 56400, loss = 0.41, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 11h:54m:27s remains)
INFO - root - 2017-12-01 05:04:05.266245: step 56410, loss = 0.37, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 11h:39m:48s remains)
INFO - root - 2017-12-01 05:04:06.824831: step 56420, loss = 0.39, batch loss = 0.22 (52.8 examples/sec; 0.152 sec/batch; 11h:37m:27s remains)
INFO - root - 2017-12-01 05:04:08.390324: step 56430, loss = 0.49, batch loss = 0.32 (51.8 examples/sec; 0.154 sec/batch; 11h:49m:55s remains)
INFO - root - 2017-12-01 05:04:09.960573: step 56440, loss = 0.38, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 11h:49m:42s remains)
INFO - root - 2017-12-01 05:04:11.507869: step 56450, loss = 0.54, batch loss = 0.36 (50.9 examples/sec; 0.157 sec/batch; 12h:02m:54s remains)
INFO - root - 2017-12-01 05:04:13.056765: step 56460, loss = 0.39, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 11h:48m:00s remains)
INFO - root - 2017-12-01 05:04:14.614324: step 56470, loss = 0.37, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 11h:52m:30s remains)
INFO - root - 2017-12-01 05:04:16.194558: step 56480, loss = 0.36, batch loss = 0.18 (49.5 examples/sec; 0.162 sec/batch; 12h:23m:20s remains)
INFO - root - 2017-12-01 05:04:17.750734: step 56490, loss = 0.37, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 11h:49m:52s remains)
INFO - root - 2017-12-01 05:04:19.318450: step 56500, loss = 0.41, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 12h:08m:03s remains)
INFO - root - 2017-12-01 05:04:20.965401: step 56510, loss = 0.50, batch loss = 0.32 (50.1 examples/sec; 0.160 sec/batch; 12h:13m:59s remains)
INFO - root - 2017-12-01 05:04:22.554240: step 56520, loss = 0.34, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 11h:56m:32s remains)
INFO - root - 2017-12-01 05:04:24.094992: step 56530, loss = 0.51, batch loss = 0.34 (51.5 examples/sec; 0.155 sec/batch; 11h:54m:55s remains)
INFO - root - 2017-12-01 05:04:25.667669: step 56540, loss = 0.45, batch loss = 0.28 (47.1 examples/sec; 0.170 sec/batch; 13h:01m:04s remains)
INFO - root - 2017-12-01 05:04:27.227745: step 56550, loss = 0.38, batch loss = 0.21 (53.0 examples/sec; 0.151 sec/batch; 11h:34m:34s remains)
INFO - root - 2017-12-01 05:04:28.811902: step 56560, loss = 0.52, batch loss = 0.35 (51.0 examples/sec; 0.157 sec/batch; 12h:00m:53s remains)
INFO - root - 2017-12-01 05:04:30.368148: step 56570, loss = 0.39, batch loss = 0.22 (49.8 examples/sec; 0.161 sec/batch; 12h:19m:02s remains)
INFO - root - 2017-12-01 05:04:31.939530: step 56580, loss = 0.38, batch loss = 0.21 (48.6 examples/sec; 0.165 sec/batch; 12h:37m:13s remains)
INFO - root - 2017-12-01 05:04:33.496926: step 56590, loss = 0.40, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 11h:52m:27s remains)
INFO - root - 2017-12-01 05:04:35.080504: step 56600, loss = 0.44, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 11h:47m:03s remains)
INFO - root - 2017-12-01 05:04:36.721294: step 56610, loss = 0.48, batch loss = 0.31 (52.9 examples/sec; 0.151 sec/batch; 11h:35m:12s remains)
INFO - root - 2017-12-01 05:04:38.329453: step 56620, loss = 0.36, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 12h:12m:59s remains)
INFO - root - 2017-12-01 05:04:39.886969: step 56630, loss = 0.38, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 11h:58m:46s remains)
INFO - root - 2017-12-01 05:04:41.437162: step 56640, loss = 0.45, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 11h:56m:45s remains)
INFO - root - 2017-12-01 05:04:43.006969: step 56650, loss = 0.43, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 12h:08m:12s remains)
INFO - root - 2017-12-01 05:04:44.562115: step 56660, loss = 0.41, batch loss = 0.24 (53.3 examples/sec; 0.150 sec/batch; 11h:30m:07s remains)
INFO - root - 2017-12-01 05:04:46.156941: step 56670, loss = 0.43, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 12h:10m:07s remains)
INFO - root - 2017-12-01 05:04:47.694499: step 56680, loss = 0.45, batch loss = 0.28 (51.8 examples/sec; 0.155 sec/batch; 11h:50m:31s remains)
INFO - root - 2017-12-01 05:04:49.252675: step 56690, loss = 0.37, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 12h:09m:55s remains)
INFO - root - 2017-12-01 05:04:50.800053: step 56700, loss = 0.38, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 11h:47m:52s remains)
INFO - root - 2017-12-01 05:04:52.459553: step 56710, loss = 0.50, batch loss = 0.33 (49.1 examples/sec; 0.163 sec/batch; 12h:29m:02s remains)
INFO - root - 2017-12-01 05:04:54.016719: step 56720, loss = 0.33, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 11h:47m:48s remains)
INFO - root - 2017-12-01 05:04:55.569909: step 56730, loss = 0.38, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 11h:40m:06s remains)
INFO - root - 2017-12-01 05:04:57.126387: step 56740, loss = 0.38, batch loss = 0.21 (52.8 examples/sec; 0.152 sec/batch; 11h:37m:00s remains)
INFO - root - 2017-12-01 05:04:58.685112: step 56750, loss = 0.40, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 11h:55m:04s remains)
INFO - root - 2017-12-01 05:05:00.261503: step 56760, loss = 0.36, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 12h:23m:24s remains)
INFO - root - 2017-12-01 05:05:01.818661: step 56770, loss = 0.37, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 12h:01m:52s remains)
INFO - root - 2017-12-01 05:05:03.381519: step 56780, loss = 0.41, batch loss = 0.24 (49.3 examples/sec; 0.162 sec/batch; 12h:25m:56s remains)
INFO - root - 2017-12-01 05:05:04.962935: step 56790, loss = 0.45, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 12h:01m:34s remains)
INFO - root - 2017-12-01 05:05:06.516074: step 56800, loss = 0.38, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 12h:02m:48s remains)
INFO - root - 2017-12-01 05:05:08.118354: step 56810, loss = 0.44, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 12h:00m:23s remains)
INFO - root - 2017-12-01 05:05:09.685614: step 56820, loss = 0.39, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 12h:04m:44s remains)
INFO - root - 2017-12-01 05:05:11.263565: step 56830, loss = 0.40, batch loss = 0.23 (50.1 examples/sec; 0.160 sec/batch; 12h:13m:37s remains)
INFO - root - 2017-12-01 05:05:12.812172: step 56840, loss = 0.52, batch loss = 0.34 (51.9 examples/sec; 0.154 sec/batch; 11h:48m:26s remains)
INFO - root - 2017-12-01 05:05:14.388367: step 56850, loss = 0.41, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 11h:53m:52s remains)
INFO - root - 2017-12-01 05:05:15.939493: step 56860, loss = 0.42, batch loss = 0.25 (49.9 examples/sec; 0.160 sec/batch; 12h:17m:02s remains)
INFO - root - 2017-12-01 05:05:17.499415: step 56870, loss = 0.40, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 11h:43m:54s remains)
INFO - root - 2017-12-01 05:05:19.089294: step 56880, loss = 0.48, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 11h:55m:26s remains)
INFO - root - 2017-12-01 05:05:20.675295: step 56890, loss = 0.37, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 12h:14m:22s remains)
INFO - root - 2017-12-01 05:05:22.247092: step 56900, loss = 0.38, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 11h:52m:31s remains)
INFO - root - 2017-12-01 05:05:23.887994: step 56910, loss = 0.39, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 12h:04m:33s remains)
INFO - root - 2017-12-01 05:05:25.443455: step 56920, loss = 0.43, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 11h:56m:51s remains)
INFO - root - 2017-12-01 05:05:27.013818: step 56930, loss = 0.47, batch loss = 0.30 (52.2 examples/sec; 0.153 sec/batch; 11h:44m:13s remains)
INFO - root - 2017-12-01 05:05:28.575175: step 56940, loss = 0.39, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 11h:51m:01s remains)
INFO - root - 2017-12-01 05:05:30.119271: step 56950, loss = 0.37, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 11h:44m:57s remains)
INFO - root - 2017-12-01 05:05:31.697625: step 56960, loss = 0.49, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 12h:03m:55s remains)
INFO - root - 2017-12-01 05:05:33.256605: step 56970, loss = 0.40, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 12h:05m:22s remains)
INFO - root - 2017-12-01 05:05:34.823505: step 56980, loss = 0.36, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 12h:07m:01s remains)
INFO - root - 2017-12-01 05:05:36.373528: step 56990, loss = 0.35, batch loss = 0.18 (52.5 examples/sec; 0.152 sec/batch; 11h:39m:46s remains)
INFO - root - 2017-12-01 05:05:37.944254: step 57000, loss = 0.41, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 11h:50m:51s remains)
INFO - root - 2017-12-01 05:05:39.594226: step 57010, loss = 0.47, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 11h:56m:51s remains)
INFO - root - 2017-12-01 05:05:41.163993: step 57020, loss = 0.39, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 11h:52m:18s remains)
INFO - root - 2017-12-01 05:05:42.774640: step 57030, loss = 0.52, batch loss = 0.35 (51.4 examples/sec; 0.156 sec/batch; 11h:55m:11s remains)
INFO - root - 2017-12-01 05:05:44.325478: step 57040, loss = 0.43, batch loss = 0.25 (51.8 examples/sec; 0.155 sec/batch; 11h:49m:40s remains)
INFO - root - 2017-12-01 05:05:45.880259: step 57050, loss = 0.42, batch loss = 0.25 (52.1 examples/sec; 0.154 sec/batch; 11h:44m:53s remains)
INFO - root - 2017-12-01 05:05:47.448995: step 57060, loss = 0.37, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 11h:41m:20s remains)
INFO - root - 2017-12-01 05:05:49.035043: step 57070, loss = 0.41, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 12h:06m:57s remains)
INFO - root - 2017-12-01 05:05:50.589380: step 57080, loss = 0.42, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 12h:06m:16s remains)
INFO - root - 2017-12-01 05:05:52.149822: step 57090, loss = 0.37, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 11h:52m:25s remains)
INFO - root - 2017-12-01 05:05:53.705446: step 57100, loss = 0.47, batch loss = 0.30 (53.0 examples/sec; 0.151 sec/batch; 11h:32m:11s remains)
INFO - root - 2017-12-01 05:05:55.321271: step 57110, loss = 0.35, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 11h:48m:02s remains)
INFO - root - 2017-12-01 05:05:56.869741: step 57120, loss = 0.39, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 11h:47m:38s remains)
INFO - root - 2017-12-01 05:05:58.452268: step 57130, loss = 0.48, batch loss = 0.31 (50.0 examples/sec; 0.160 sec/batch; 12h:14m:44s remains)
INFO - root - 2017-12-01 05:06:00.030737: step 57140, loss = 0.31, batch loss = 0.14 (51.6 examples/sec; 0.155 sec/batch; 11h:51m:47s remains)
INFO - root - 2017-12-01 05:06:01.601978: step 57150, loss = 0.50, batch loss = 0.33 (51.3 examples/sec; 0.156 sec/batch; 11h:55m:27s remains)
INFO - root - 2017-12-01 05:06:03.161530: step 57160, loss = 0.36, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 12h:04m:15s remains)
INFO - root - 2017-12-01 05:06:04.731711: step 57170, loss = 0.47, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 11h:54m:08s remains)
INFO - root - 2017-12-01 05:06:06.302490: step 57180, loss = 0.37, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 11h:53m:54s remains)
INFO - root - 2017-12-01 05:06:07.865890: step 57190, loss = 0.33, batch loss = 0.16 (52.3 examples/sec; 0.153 sec/batch; 11h:41m:51s remains)
INFO - root - 2017-12-01 05:06:09.427805: step 57200, loss = 0.36, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 11h:55m:41s remains)
INFO - root - 2017-12-01 05:06:11.091113: step 57210, loss = 0.37, batch loss = 0.20 (52.9 examples/sec; 0.151 sec/batch; 11h:33m:20s remains)
INFO - root - 2017-12-01 05:06:12.663648: step 57220, loss = 0.36, batch loss = 0.19 (50.1 examples/sec; 0.160 sec/batch; 12h:12m:53s remains)
INFO - root - 2017-12-01 05:06:14.213857: step 57230, loss = 0.39, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 12h:04m:10s remains)
INFO - root - 2017-12-01 05:06:15.770394: step 57240, loss = 0.40, batch loss = 0.23 (51.8 examples/sec; 0.155 sec/batch; 11h:48m:52s remains)
INFO - root - 2017-12-01 05:06:17.345270: step 57250, loss = 0.44, batch loss = 0.27 (47.9 examples/sec; 0.167 sec/batch; 12h:45m:28s remains)
INFO - root - 2017-12-01 05:06:18.900761: step 57260, loss = 0.41, batch loss = 0.24 (52.4 examples/sec; 0.153 sec/batch; 11h:40m:36s remains)
INFO - root - 2017-12-01 05:06:20.476872: step 57270, loss = 0.45, batch loss = 0.28 (51.1 examples/sec; 0.156 sec/batch; 11h:57m:39s remains)
INFO - root - 2017-12-01 05:06:22.045275: step 57280, loss = 0.37, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 11h:57m:23s remains)
INFO - root - 2017-12-01 05:06:23.596689: step 57290, loss = 0.45, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 11h:51m:45s remains)
INFO - root - 2017-12-01 05:06:25.166879: step 57300, loss = 0.39, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 11h:45m:19s remains)
INFO - root - 2017-12-01 05:06:26.776214: step 57310, loss = 0.36, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 11h:47m:15s remains)
INFO - root - 2017-12-01 05:06:28.365893: step 57320, loss = 0.46, batch loss = 0.29 (45.2 examples/sec; 0.177 sec/batch; 13h:31m:16s remains)
INFO - root - 2017-12-01 05:06:29.928642: step 57330, loss = 0.44, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 11h:55m:25s remains)
INFO - root - 2017-12-01 05:06:31.500187: step 57340, loss = 0.40, batch loss = 0.23 (53.3 examples/sec; 0.150 sec/batch; 11h:28m:09s remains)
INFO - root - 2017-12-01 05:06:33.080528: step 57350, loss = 0.39, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 12h:05m:07s remains)
INFO - root - 2017-12-01 05:06:34.633864: step 57360, loss = 0.50, batch loss = 0.33 (50.4 examples/sec; 0.159 sec/batch; 12h:07m:47s remains)
INFO - root - 2017-12-01 05:06:36.195177: step 57370, loss = 0.57, batch loss = 0.39 (51.7 examples/sec; 0.155 sec/batch; 11h:49m:26s remains)
INFO - root - 2017-12-01 05:06:37.753567: step 57380, loss = 0.39, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 11h:47m:52s remains)
INFO - root - 2017-12-01 05:06:39.314931: step 57390, loss = 0.44, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 11h:35m:39s remains)
INFO - root - 2017-12-01 05:06:40.899814: step 57400, loss = 0.44, batch loss = 0.26 (50.1 examples/sec; 0.160 sec/batch; 12h:11m:46s remains)
INFO - root - 2017-12-01 05:06:42.536616: step 57410, loss = 0.41, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 11h:58m:19s remains)
INFO - root - 2017-12-01 05:06:44.098723: step 57420, loss = 0.40, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 11h:57m:33s remains)
INFO - root - 2017-12-01 05:06:45.653890: step 57430, loss = 0.41, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 12h:09m:45s remains)
INFO - root - 2017-12-01 05:06:47.229641: step 57440, loss = 0.38, batch loss = 0.20 (48.0 examples/sec; 0.167 sec/batch; 12h:44m:01s remains)
INFO - root - 2017-12-01 05:06:48.782970: step 57450, loss = 0.45, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 11h:58m:05s remains)
INFO - root - 2017-12-01 05:06:50.335214: step 57460, loss = 0.41, batch loss = 0.24 (52.8 examples/sec; 0.151 sec/batch; 11h:34m:26s remains)
INFO - root - 2017-12-01 05:06:51.887088: step 57470, loss = 0.40, batch loss = 0.23 (53.1 examples/sec; 0.151 sec/batch; 11h:31m:00s remains)
INFO - root - 2017-12-01 05:06:53.455061: step 57480, loss = 0.42, batch loss = 0.25 (49.7 examples/sec; 0.161 sec/batch; 12h:17m:34s remains)
INFO - root - 2017-12-01 05:06:55.013957: step 57490, loss = 0.40, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 11h:49m:09s remains)
INFO - root - 2017-12-01 05:06:56.585062: step 57500, loss = 0.50, batch loss = 0.33 (51.3 examples/sec; 0.156 sec/batch; 11h:54m:19s remains)
INFO - root - 2017-12-01 05:06:58.190255: step 57510, loss = 0.40, batch loss = 0.23 (50.4 examples/sec; 0.159 sec/batch; 12h:08m:08s remains)
INFO - root - 2017-12-01 05:06:59.742057: step 57520, loss = 0.38, batch loss = 0.21 (49.5 examples/sec; 0.162 sec/batch; 12h:20m:48s remains)
INFO - root - 2017-12-01 05:07:01.316590: step 57530, loss = 0.46, batch loss = 0.28 (50.4 examples/sec; 0.159 sec/batch; 12h:07m:42s remains)
INFO - root - 2017-12-01 05:07:02.850369: step 57540, loss = 0.45, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 11h:58m:26s remains)
INFO - root - 2017-12-01 05:07:04.429452: step 57550, loss = 0.42, batch loss = 0.25 (52.2 examples/sec; 0.153 sec/batch; 11h:41m:38s remains)
INFO - root - 2017-12-01 05:07:06.041002: step 57560, loss = 0.33, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 12h:06m:48s remains)
INFO - root - 2017-12-01 05:07:07.593666: step 57570, loss = 0.34, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 11h:48m:40s remains)
INFO - root - 2017-12-01 05:07:09.135366: step 57580, loss = 0.41, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 11h:50m:59s remains)
INFO - root - 2017-12-01 05:07:10.711704: step 57590, loss = 0.35, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 12h:08m:22s remains)
INFO - root - 2017-12-01 05:07:12.304995: step 57600, loss = 0.46, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 11h:59m:37s remains)
INFO - root - 2017-12-01 05:07:13.962749: step 57610, loss = 0.42, batch loss = 0.25 (52.4 examples/sec; 0.153 sec/batch; 11h:39m:31s remains)
INFO - root - 2017-12-01 05:07:15.524148: step 57620, loss = 0.47, batch loss = 0.30 (52.0 examples/sec; 0.154 sec/batch; 11h:45m:18s remains)
INFO - root - 2017-12-01 05:07:17.090577: step 57630, loss = 0.37, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 11h:57m:50s remains)
INFO - root - 2017-12-01 05:07:18.627292: step 57640, loss = 0.40, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 11h:51m:15s remains)
INFO - root - 2017-12-01 05:07:20.180916: step 57650, loss = 0.38, batch loss = 0.21 (49.1 examples/sec; 0.163 sec/batch; 12h:26m:49s remains)
INFO - root - 2017-12-01 05:07:21.738083: step 57660, loss = 0.33, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 11h:53m:06s remains)
INFO - root - 2017-12-01 05:07:23.301452: step 57670, loss = 0.40, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 11h:35m:55s remains)
INFO - root - 2017-12-01 05:07:24.889238: step 57680, loss = 0.40, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 12h:09m:45s remains)
INFO - root - 2017-12-01 05:07:26.466944: step 57690, loss = 0.38, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 12h:10m:15s remains)
INFO - root - 2017-12-01 05:07:28.007395: step 57700, loss = 0.45, batch loss = 0.28 (53.0 examples/sec; 0.151 sec/batch; 11h:30m:54s remains)
INFO - root - 2017-12-01 05:07:29.629920: step 57710, loss = 0.50, batch loss = 0.33 (52.3 examples/sec; 0.153 sec/batch; 11h:40m:26s remains)
INFO - root - 2017-12-01 05:07:31.183919: step 57720, loss = 0.37, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 12h:04m:05s remains)
INFO - root - 2017-12-01 05:07:32.740561: step 57730, loss = 0.43, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 11h:54m:44s remains)
INFO - root - 2017-12-01 05:07:34.303313: step 57740, loss = 0.46, batch loss = 0.29 (51.4 examples/sec; 0.156 sec/batch; 11h:53m:24s remains)
INFO - root - 2017-12-01 05:07:35.857983: step 57750, loss = 0.54, batch loss = 0.36 (52.1 examples/sec; 0.154 sec/batch; 11h:43m:27s remains)
INFO - root - 2017-12-01 05:07:37.445938: step 57760, loss = 0.37, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 12h:07m:44s remains)
INFO - root - 2017-12-01 05:07:39.029581: step 57770, loss = 0.40, batch loss = 0.23 (47.9 examples/sec; 0.167 sec/batch; 12h:44m:22s remains)
INFO - root - 2017-12-01 05:07:40.711610: step 57780, loss = 0.43, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 11h:54m:13s remains)
INFO - root - 2017-12-01 05:07:42.302520: step 57790, loss = 0.34, batch loss = 0.17 (48.2 examples/sec; 0.166 sec/batch; 12h:39m:16s remains)
INFO - root - 2017-12-01 05:07:43.874316: step 57800, loss = 0.42, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 11h:56m:43s remains)
INFO - root - 2017-12-01 05:07:45.496548: step 57810, loss = 0.62, batch loss = 0.44 (50.2 examples/sec; 0.159 sec/batch; 12h:09m:58s remains)
INFO - root - 2017-12-01 05:07:47.061096: step 57820, loss = 0.40, batch loss = 0.23 (48.4 examples/sec; 0.165 sec/batch; 12h:36m:14s remains)
INFO - root - 2017-12-01 05:07:48.643679: step 57830, loss = 0.36, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 11h:43m:39s remains)
INFO - root - 2017-12-01 05:07:50.224916: step 57840, loss = 0.42, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 11h:48m:23s remains)
INFO - root - 2017-12-01 05:07:51.789523: step 57850, loss = 0.39, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 12h:11m:01s remains)
INFO - root - 2017-12-01 05:07:53.342387: step 57860, loss = 0.38, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 12h:09m:34s remains)
INFO - root - 2017-12-01 05:07:54.900851: step 57870, loss = 0.41, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 11h:44m:31s remains)
INFO - root - 2017-12-01 05:07:56.452683: step 57880, loss = 0.36, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 11h:47m:38s remains)
INFO - root - 2017-12-01 05:07:58.036379: step 57890, loss = 0.47, batch loss = 0.30 (50.6 examples/sec; 0.158 sec/batch; 12h:03m:37s remains)
INFO - root - 2017-12-01 05:07:59.593779: step 57900, loss = 0.45, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 11h:49m:04s remains)
INFO - root - 2017-12-01 05:08:01.217048: step 57910, loss = 0.42, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 12h:01m:53s remains)
INFO - root - 2017-12-01 05:08:02.772913: step 57920, loss = 0.34, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 11h:54m:57s remains)
INFO - root - 2017-12-01 05:08:04.319322: step 57930, loss = 0.60, batch loss = 0.43 (52.3 examples/sec; 0.153 sec/batch; 11h:39m:35s remains)
INFO - root - 2017-12-01 05:08:05.886523: step 57940, loss = 0.35, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 12h:06m:27s remains)
INFO - root - 2017-12-01 05:08:07.460040: step 57950, loss = 0.40, batch loss = 0.23 (48.9 examples/sec; 0.163 sec/batch; 12h:27m:57s remains)
INFO - root - 2017-12-01 05:08:09.016480: step 57960, loss = 0.39, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 11h:53m:37s remains)
INFO - root - 2017-12-01 05:08:10.603190: step 57970, loss = 0.49, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 12h:01m:36s remains)
INFO - root - 2017-12-01 05:08:12.170208: step 57980, loss = 0.41, batch loss = 0.24 (53.1 examples/sec; 0.151 sec/batch; 11h:28m:45s remains)
INFO - root - 2017-12-01 05:08:13.733048: step 57990, loss = 0.44, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 12h:02m:30s remains)
INFO - root - 2017-12-01 05:08:15.295584: step 58000, loss = 0.40, batch loss = 0.23 (52.5 examples/sec; 0.152 sec/batch; 11h:36m:56s remains)
INFO - root - 2017-12-01 05:08:16.917994: step 58010, loss = 0.44, batch loss = 0.27 (50.4 examples/sec; 0.159 sec/batch; 12h:05m:52s remains)
INFO - root - 2017-12-01 05:08:18.474677: step 58020, loss = 0.36, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 11h:56m:53s remains)
INFO - root - 2017-12-01 05:08:20.016756: step 58030, loss = 0.39, batch loss = 0.22 (53.2 examples/sec; 0.150 sec/batch; 11h:27m:47s remains)
INFO - root - 2017-12-01 05:08:21.567698: step 58040, loss = 0.34, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 11h:48m:13s remains)
INFO - root - 2017-12-01 05:08:23.147103: step 58050, loss = 0.46, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 11h:47m:41s remains)
INFO - root - 2017-12-01 05:08:24.737734: step 58060, loss = 0.35, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 11h:58m:58s remains)
INFO - root - 2017-12-01 05:08:26.312686: step 58070, loss = 0.42, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 11h:54m:20s remains)
INFO - root - 2017-12-01 05:08:27.869422: step 58080, loss = 0.42, batch loss = 0.25 (52.7 examples/sec; 0.152 sec/batch; 11h:33m:58s remains)
INFO - root - 2017-12-01 05:08:29.435981: step 58090, loss = 0.40, batch loss = 0.23 (52.1 examples/sec; 0.154 sec/batch; 11h:42m:05s remains)
INFO - root - 2017-12-01 05:08:31.005848: step 58100, loss = 0.35, batch loss = 0.18 (52.6 examples/sec; 0.152 sec/batch; 11h:36m:02s remains)
INFO - root - 2017-12-01 05:08:32.613258: step 58110, loss = 0.37, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 11h:43m:07s remains)
INFO - root - 2017-12-01 05:08:34.178352: step 58120, loss = 0.38, batch loss = 0.21 (49.7 examples/sec; 0.161 sec/batch; 12h:15m:39s remains)
INFO - root - 2017-12-01 05:08:35.733169: step 58130, loss = 0.45, batch loss = 0.28 (52.7 examples/sec; 0.152 sec/batch; 11h:34m:03s remains)
INFO - root - 2017-12-01 05:08:37.305929: step 58140, loss = 0.38, batch loss = 0.21 (52.1 examples/sec; 0.153 sec/batch; 11h:41m:53s remains)
INFO - root - 2017-12-01 05:08:38.878078: step 58150, loss = 0.33, batch loss = 0.16 (51.1 examples/sec; 0.157 sec/batch; 11h:56m:08s remains)
INFO - root - 2017-12-01 05:08:40.440324: step 58160, loss = 0.34, batch loss = 0.17 (49.1 examples/sec; 0.163 sec/batch; 12h:24m:41s remains)
INFO - root - 2017-12-01 05:08:41.997575: step 58170, loss = 0.46, batch loss = 0.29 (52.1 examples/sec; 0.153 sec/batch; 11h:41m:43s remains)
INFO - root - 2017-12-01 05:08:43.550800: step 58180, loss = 0.46, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 11h:50m:26s remains)
INFO - root - 2017-12-01 05:08:45.104750: step 58190, loss = 0.38, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 12h:01m:22s remains)
INFO - root - 2017-12-01 05:08:46.680333: step 58200, loss = 0.35, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 12h:04m:03s remains)
INFO - root - 2017-12-01 05:08:48.298709: step 58210, loss = 0.47, batch loss = 0.30 (50.3 examples/sec; 0.159 sec/batch; 12h:06m:50s remains)
INFO - root - 2017-12-01 05:08:49.859271: step 58220, loss = 0.43, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 11h:33m:20s remains)
INFO - root - 2017-12-01 05:08:51.392998: step 58230, loss = 0.37, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 11h:37m:41s remains)
INFO - root - 2017-12-01 05:08:52.953171: step 58240, loss = 0.37, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 11h:56m:13s remains)
INFO - root - 2017-12-01 05:08:54.515547: step 58250, loss = 0.41, batch loss = 0.24 (50.1 examples/sec; 0.160 sec/batch; 12h:10m:25s remains)
INFO - root - 2017-12-01 05:08:56.085140: step 58260, loss = 0.35, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 12h:02m:36s remains)
INFO - root - 2017-12-01 05:08:57.669209: step 58270, loss = 0.42, batch loss = 0.25 (52.4 examples/sec; 0.153 sec/batch; 11h:38m:16s remains)
INFO - root - 2017-12-01 05:08:59.229008: step 58280, loss = 0.44, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 11h:42m:57s remains)
INFO - root - 2017-12-01 05:09:00.809110: step 58290, loss = 0.39, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 12h:09m:10s remains)
INFO - root - 2017-12-01 05:09:02.379949: step 58300, loss = 0.43, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 11h:57m:11s remains)
INFO - root - 2017-12-01 05:09:04.041306: step 58310, loss = 0.35, batch loss = 0.18 (50.1 examples/sec; 0.160 sec/batch; 12h:09m:17s remains)
INFO - root - 2017-12-01 05:09:05.608239: step 58320, loss = 0.53, batch loss = 0.36 (52.0 examples/sec; 0.154 sec/batch; 11h:43m:06s remains)
INFO - root - 2017-12-01 05:09:07.186127: step 58330, loss = 0.42, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 12h:02m:51s remains)
INFO - root - 2017-12-01 05:09:08.761640: step 58340, loss = 0.42, batch loss = 0.25 (49.7 examples/sec; 0.161 sec/batch; 12h:15m:18s remains)
INFO - root - 2017-12-01 05:09:10.304114: step 58350, loss = 0.51, batch loss = 0.34 (50.3 examples/sec; 0.159 sec/batch; 12h:06m:34s remains)
INFO - root - 2017-12-01 05:09:11.867973: step 58360, loss = 0.40, batch loss = 0.23 (49.0 examples/sec; 0.163 sec/batch; 12h:25m:29s remains)
INFO - root - 2017-12-01 05:09:13.415446: step 58370, loss = 0.39, batch loss = 0.22 (52.1 examples/sec; 0.153 sec/batch; 11h:41m:12s remains)
INFO - root - 2017-12-01 05:09:14.985803: step 58380, loss = 0.53, batch loss = 0.36 (52.0 examples/sec; 0.154 sec/batch; 11h:42m:33s remains)
INFO - root - 2017-12-01 05:09:16.551433: step 58390, loss = 0.34, batch loss = 0.17 (49.7 examples/sec; 0.161 sec/batch; 12h:15m:35s remains)
INFO - root - 2017-12-01 05:09:18.116937: step 58400, loss = 0.37, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 11h:58m:18s remains)
INFO - root - 2017-12-01 05:09:19.772057: step 58410, loss = 0.42, batch loss = 0.25 (48.3 examples/sec; 0.166 sec/batch; 12h:37m:14s remains)
INFO - root - 2017-12-01 05:09:21.372844: step 58420, loss = 0.46, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 11h:49m:19s remains)
INFO - root - 2017-12-01 05:09:22.954707: step 58430, loss = 0.45, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 11h:47m:07s remains)
INFO - root - 2017-12-01 05:09:24.534267: step 58440, loss = 0.32, batch loss = 0.15 (51.8 examples/sec; 0.154 sec/batch; 11h:45m:32s remains)
INFO - root - 2017-12-01 05:09:26.119173: step 58450, loss = 0.39, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 12h:08m:57s remains)
INFO - root - 2017-12-01 05:09:27.697065: step 58460, loss = 0.50, batch loss = 0.33 (48.2 examples/sec; 0.166 sec/batch; 12h:37m:45s remains)
INFO - root - 2017-12-01 05:09:29.251956: step 58470, loss = 0.50, batch loss = 0.33 (51.2 examples/sec; 0.156 sec/batch; 11h:54m:18s remains)
INFO - root - 2017-12-01 05:09:30.832705: step 58480, loss = 0.40, batch loss = 0.23 (49.6 examples/sec; 0.161 sec/batch; 12h:16m:54s remains)
INFO - root - 2017-12-01 05:09:32.389572: step 58490, loss = 0.35, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 11h:42m:27s remains)
INFO - root - 2017-12-01 05:09:33.948160: step 58500, loss = 0.46, batch loss = 0.29 (50.1 examples/sec; 0.160 sec/batch; 12h:09m:14s remains)
INFO - root - 2017-12-01 05:09:35.577292: step 58510, loss = 0.40, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 11h:49m:07s remains)
INFO - root - 2017-12-01 05:09:37.140892: step 58520, loss = 0.38, batch loss = 0.21 (50.0 examples/sec; 0.160 sec/batch; 12h:09m:57s remains)
INFO - root - 2017-12-01 05:09:38.704916: step 58530, loss = 0.43, batch loss = 0.26 (45.8 examples/sec; 0.175 sec/batch; 13h:17m:23s remains)
INFO - root - 2017-12-01 05:09:40.272130: step 58540, loss = 0.35, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 11h:53m:20s remains)
INFO - root - 2017-12-01 05:09:41.857916: step 58550, loss = 0.43, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 11h:57m:23s remains)
INFO - root - 2017-12-01 05:09:43.467115: step 58560, loss = 0.51, batch loss = 0.34 (50.4 examples/sec; 0.159 sec/batch; 12h:04m:50s remains)
INFO - root - 2017-12-01 05:09:45.015747: step 58570, loss = 0.37, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 11h:50m:53s remains)
INFO - root - 2017-12-01 05:09:46.591105: step 58580, loss = 0.43, batch loss = 0.26 (51.1 examples/sec; 0.156 sec/batch; 11h:54m:02s remains)
INFO - root - 2017-12-01 05:09:48.153103: step 58590, loss = 0.37, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 11h:46m:28s remains)
INFO - root - 2017-12-01 05:09:49.727763: step 58600, loss = 0.62, batch loss = 0.45 (49.5 examples/sec; 0.161 sec/batch; 12h:17m:14s remains)
INFO - root - 2017-12-01 05:09:51.348650: step 58610, loss = 0.48, batch loss = 0.31 (52.4 examples/sec; 0.153 sec/batch; 11h:36m:29s remains)
INFO - root - 2017-12-01 05:09:52.922747: step 58620, loss = 0.45, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 12h:03m:03s remains)
INFO - root - 2017-12-01 05:09:54.480286: step 58630, loss = 0.52, batch loss = 0.35 (50.6 examples/sec; 0.158 sec/batch; 12h:01m:56s remains)
INFO - root - 2017-12-01 05:09:56.035944: step 58640, loss = 0.40, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 11h:46m:21s remains)
INFO - root - 2017-12-01 05:09:57.611676: step 58650, loss = 0.42, batch loss = 0.26 (48.9 examples/sec; 0.164 sec/batch; 12h:27m:10s remains)
INFO - root - 2017-12-01 05:09:59.171484: step 58660, loss = 0.34, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 12h:04m:31s remains)
INFO - root - 2017-12-01 05:10:00.756622: step 58670, loss = 0.53, batch loss = 0.36 (51.0 examples/sec; 0.157 sec/batch; 11h:55m:54s remains)
INFO - root - 2017-12-01 05:10:02.320364: step 58680, loss = 0.42, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 11h:55m:42s remains)
INFO - root - 2017-12-01 05:10:03.876710: step 58690, loss = 0.40, batch loss = 0.23 (49.6 examples/sec; 0.161 sec/batch; 12h:15m:49s remains)
INFO - root - 2017-12-01 05:10:05.435862: step 58700, loss = 0.37, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 11h:45m:27s remains)
INFO - root - 2017-12-01 05:10:07.092733: step 58710, loss = 0.49, batch loss = 0.32 (50.8 examples/sec; 0.158 sec/batch; 11h:58m:52s remains)
INFO - root - 2017-12-01 05:10:08.673800: step 58720, loss = 0.36, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 11h:56m:06s remains)
INFO - root - 2017-12-01 05:10:10.255739: step 58730, loss = 0.34, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 11h:54m:41s remains)
INFO - root - 2017-12-01 05:10:11.839283: step 58740, loss = 0.37, batch loss = 0.20 (46.2 examples/sec; 0.173 sec/batch; 13h:09m:49s remains)
INFO - root - 2017-12-01 05:10:13.429978: step 58750, loss = 0.36, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 12h:01m:09s remains)
INFO - root - 2017-12-01 05:10:14.999354: step 58760, loss = 0.42, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 11h:47m:16s remains)
INFO - root - 2017-12-01 05:10:16.555978: step 58770, loss = 0.39, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 11h:51m:38s remains)
INFO - root - 2017-12-01 05:10:18.126700: step 58780, loss = 0.38, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 11h:50m:31s remains)
INFO - root - 2017-12-01 05:10:19.676054: step 58790, loss = 0.58, batch loss = 0.41 (49.7 examples/sec; 0.161 sec/batch; 12h:14m:03s remains)
INFO - root - 2017-12-01 05:10:21.247288: step 58800, loss = 0.35, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 11h:56m:44s remains)
INFO - root - 2017-12-01 05:10:22.873893: step 58810, loss = 0.44, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 11h:48m:53s remains)
INFO - root - 2017-12-01 05:10:24.440922: step 58820, loss = 0.39, batch loss = 0.22 (49.8 examples/sec; 0.161 sec/batch; 12h:12m:34s remains)
INFO - root - 2017-12-01 05:10:26.003075: step 58830, loss = 0.39, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 11h:56m:46s remains)
INFO - root - 2017-12-01 05:10:27.569191: step 58840, loss = 0.35, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 11h:47m:02s remains)
INFO - root - 2017-12-01 05:10:29.125578: step 58850, loss = 0.38, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 11h:58m:15s remains)
INFO - root - 2017-12-01 05:10:30.695943: step 58860, loss = 0.37, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 11h:52m:26s remains)
INFO - root - 2017-12-01 05:10:32.254504: step 58870, loss = 0.41, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 11h:52m:59s remains)
INFO - root - 2017-12-01 05:10:33.813881: step 58880, loss = 0.36, batch loss = 0.19 (50.1 examples/sec; 0.160 sec/batch; 12h:08m:20s remains)
INFO - root - 2017-12-01 05:10:35.390700: step 58890, loss = 0.53, batch loss = 0.36 (52.2 examples/sec; 0.153 sec/batch; 11h:38m:32s remains)
INFO - root - 2017-12-01 05:10:36.959884: step 58900, loss = 0.39, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 11h:40m:59s remains)
INFO - root - 2017-12-01 05:10:38.567306: step 58910, loss = 0.42, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 11h:34m:49s remains)
INFO - root - 2017-12-01 05:10:40.166446: step 58920, loss = 0.33, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 11h:46m:38s remains)
INFO - root - 2017-12-01 05:10:41.738130: step 58930, loss = 0.36, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 11h:57m:30s remains)
INFO - root - 2017-12-01 05:10:43.300128: step 58940, loss = 0.39, batch loss = 0.22 (49.7 examples/sec; 0.161 sec/batch; 12h:13m:40s remains)
INFO - root - 2017-12-01 05:10:44.859703: step 58950, loss = 0.37, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 11h:45m:16s remains)
INFO - root - 2017-12-01 05:10:46.424758: step 58960, loss = 0.46, batch loss = 0.29 (49.5 examples/sec; 0.162 sec/batch; 12h:16m:32s remains)
INFO - root - 2017-12-01 05:10:48.001900: step 58970, loss = 0.52, batch loss = 0.35 (50.1 examples/sec; 0.160 sec/batch; 12h:08m:10s remains)
INFO - root - 2017-12-01 05:10:49.579779: step 58980, loss = 0.45, batch loss = 0.28 (50.3 examples/sec; 0.159 sec/batch; 12h:04m:33s remains)
INFO - root - 2017-12-01 05:10:51.133678: step 58990, loss = 0.61, batch loss = 0.44 (51.8 examples/sec; 0.155 sec/batch; 11h:44m:37s remains)
INFO - root - 2017-12-01 05:10:52.711806: step 59000, loss = 0.45, batch loss = 0.28 (52.8 examples/sec; 0.151 sec/batch; 11h:30m:04s remains)
INFO - root - 2017-12-01 05:10:54.320889: step 59010, loss = 0.35, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 11h:54m:09s remains)
INFO - root - 2017-12-01 05:10:55.886993: step 59020, loss = 0.39, batch loss = 0.22 (49.1 examples/sec; 0.163 sec/batch; 12h:22m:34s remains)
INFO - root - 2017-12-01 05:10:57.441421: step 59030, loss = 0.46, batch loss = 0.29 (52.5 examples/sec; 0.152 sec/batch; 11h:34m:50s remains)
INFO - root - 2017-12-01 05:10:59.004111: step 59040, loss = 0.38, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 11h:40m:49s remains)
INFO - root - 2017-12-01 05:11:00.581700: step 59050, loss = 0.32, batch loss = 0.15 (51.5 examples/sec; 0.155 sec/batch; 11h:48m:07s remains)
INFO - root - 2017-12-01 05:11:02.147402: step 59060, loss = 0.47, batch loss = 0.30 (51.8 examples/sec; 0.154 sec/batch; 11h:43m:32s remains)
INFO - root - 2017-12-01 05:11:03.702396: step 59070, loss = 0.39, batch loss = 0.22 (50.2 examples/sec; 0.160 sec/batch; 12h:06m:55s remains)
INFO - root - 2017-12-01 05:11:05.268326: step 59080, loss = 0.49, batch loss = 0.32 (50.5 examples/sec; 0.158 sec/batch; 12h:01m:14s remains)
INFO - root - 2017-12-01 05:11:06.868633: step 59090, loss = 0.39, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 11h:40m:27s remains)
INFO - root - 2017-12-01 05:11:08.418804: step 59100, loss = 0.38, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 11h:56m:13s remains)
INFO - root - 2017-12-01 05:11:10.041493: step 59110, loss = 0.55, batch loss = 0.38 (51.5 examples/sec; 0.155 sec/batch; 11h:47m:35s remains)
INFO - root - 2017-12-01 05:11:11.606888: step 59120, loss = 0.52, batch loss = 0.35 (50.3 examples/sec; 0.159 sec/batch; 12h:04m:44s remains)
INFO - root - 2017-12-01 05:11:13.188874: step 59130, loss = 0.40, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 12h:02m:50s remains)
INFO - root - 2017-12-01 05:11:14.748874: step 59140, loss = 0.47, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 11h:59m:08s remains)
INFO - root - 2017-12-01 05:11:16.302698: step 59150, loss = 0.37, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 11h:48m:11s remains)
INFO - root - 2017-12-01 05:11:17.876569: step 59160, loss = 0.58, batch loss = 0.41 (49.1 examples/sec; 0.163 sec/batch; 12h:21m:52s remains)
INFO - root - 2017-12-01 05:11:19.449138: step 59170, loss = 0.40, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 11h:54m:45s remains)
INFO - root - 2017-12-01 05:11:20.999485: step 59180, loss = 0.38, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 11h:52m:25s remains)
INFO - root - 2017-12-01 05:11:22.535906: step 59190, loss = 0.39, batch loss = 0.22 (52.4 examples/sec; 0.153 sec/batch; 11h:35m:29s remains)
INFO - root - 2017-12-01 05:11:24.106293: step 59200, loss = 0.39, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 11h:57m:09s remains)
INFO - root - 2017-12-01 05:11:25.760952: step 59210, loss = 0.41, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 12h:01m:05s remains)
INFO - root - 2017-12-01 05:11:27.319890: step 59220, loss = 0.36, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 11h:50m:08s remains)
INFO - root - 2017-12-01 05:11:28.882069: step 59230, loss = 0.37, batch loss = 0.20 (48.6 examples/sec; 0.164 sec/batch; 12h:29m:10s remains)
INFO - root - 2017-12-01 05:11:30.464087: step 59240, loss = 0.41, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 11h:42m:16s remains)
INFO - root - 2017-12-01 05:11:32.025351: step 59250, loss = 0.34, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 11h:37m:17s remains)
INFO - root - 2017-12-01 05:11:33.597011: step 59260, loss = 0.35, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 11h:50m:19s remains)
INFO - root - 2017-12-01 05:11:35.158757: step 59270, loss = 0.39, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 12h:01m:02s remains)
INFO - root - 2017-12-01 05:11:36.727663: step 59280, loss = 0.51, batch loss = 0.34 (50.3 examples/sec; 0.159 sec/batch; 12h:04m:13s remains)
INFO - root - 2017-12-01 05:11:38.303837: step 59290, loss = 0.45, batch loss = 0.28 (49.9 examples/sec; 0.160 sec/batch; 12h:10m:39s remains)
INFO - root - 2017-12-01 05:11:39.856424: step 59300, loss = 0.35, batch loss = 0.18 (52.2 examples/sec; 0.153 sec/batch; 11h:37m:41s remains)
INFO - root - 2017-12-01 05:11:41.528700: step 59310, loss = 0.42, batch loss = 0.25 (49.8 examples/sec; 0.161 sec/batch; 12h:11m:17s remains)
INFO - root - 2017-12-01 05:11:43.080251: step 59320, loss = 0.42, batch loss = 0.25 (52.1 examples/sec; 0.154 sec/batch; 11h:38m:53s remains)
INFO - root - 2017-12-01 05:11:44.646368: step 59330, loss = 0.41, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 11h:51m:45s remains)
INFO - root - 2017-12-01 05:11:46.214025: step 59340, loss = 0.38, batch loss = 0.21 (49.2 examples/sec; 0.163 sec/batch; 12h:19m:49s remains)
INFO - root - 2017-12-01 05:11:47.778217: step 59350, loss = 0.43, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 11h:41m:20s remains)
INFO - root - 2017-12-01 05:11:49.334083: step 59360, loss = 0.47, batch loss = 0.30 (52.4 examples/sec; 0.153 sec/batch; 11h:34m:31s remains)
INFO - root - 2017-12-01 05:11:50.899006: step 59370, loss = 0.38, batch loss = 0.21 (52.1 examples/sec; 0.153 sec/batch; 11h:38m:33s remains)
INFO - root - 2017-12-01 05:11:52.471355: step 59380, loss = 0.37, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 12h:08m:13s remains)
INFO - root - 2017-12-01 05:11:54.025585: step 59390, loss = 0.34, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 11h:46m:28s remains)
INFO - root - 2017-12-01 05:11:55.579335: step 59400, loss = 0.33, batch loss = 0.16 (52.5 examples/sec; 0.152 sec/batch; 11h:33m:25s remains)
INFO - root - 2017-12-01 05:11:57.250394: step 59410, loss = 0.42, batch loss = 0.25 (50.1 examples/sec; 0.160 sec/batch; 12h:06m:20s remains)
INFO - root - 2017-12-01 05:11:58.812608: step 59420, loss = 0.46, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 11h:49m:25s remains)
INFO - root - 2017-12-01 05:12:00.381556: step 59430, loss = 0.42, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 11h:48m:39s remains)
INFO - root - 2017-12-01 05:12:01.946209: step 59440, loss = 0.38, batch loss = 0.21 (50.5 examples/sec; 0.159 sec/batch; 12h:01m:35s remains)
INFO - root - 2017-12-01 05:12:03.515709: step 59450, loss = 0.39, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 12h:07m:51s remains)
INFO - root - 2017-12-01 05:12:05.078057: step 59460, loss = 0.41, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 11h:46m:15s remains)
INFO - root - 2017-12-01 05:12:06.626354: step 59470, loss = 0.35, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 11h:46m:36s remains)
INFO - root - 2017-12-01 05:12:08.207016: step 59480, loss = 0.40, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 11h:58m:59s remains)
INFO - root - 2017-12-01 05:12:09.763248: step 59490, loss = 0.35, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 11h:41m:00s remains)
INFO - root - 2017-12-01 05:12:11.318241: step 59500, loss = 0.46, batch loss = 0.29 (50.5 examples/sec; 0.158 sec/batch; 12h:00m:52s remains)
INFO - root - 2017-12-01 05:12:12.983749: step 59510, loss = 0.36, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 11h:37m:05s remains)
INFO - root - 2017-12-01 05:12:14.548406: step 59520, loss = 0.42, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 11h:52m:59s remains)
INFO - root - 2017-12-01 05:12:16.103326: step 59530, loss = 0.34, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 12h:01m:02s remains)
INFO - root - 2017-12-01 05:12:17.653873: step 59540, loss = 0.49, batch loss = 0.32 (51.4 examples/sec; 0.156 sec/batch; 11h:48m:43s remains)
INFO - root - 2017-12-01 05:12:19.232542: step 59550, loss = 0.38, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 11h:40m:45s remains)
INFO - root - 2017-12-01 05:12:20.812849: step 59560, loss = 0.37, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 11h:50m:34s remains)
INFO - root - 2017-12-01 05:12:22.374710: step 59570, loss = 0.38, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 11h:53m:14s remains)
INFO - root - 2017-12-01 05:12:23.943720: step 59580, loss = 0.40, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 12h:01m:34s remains)
INFO - root - 2017-12-01 05:12:25.501654: step 59590, loss = 0.42, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 11h:49m:45s remains)
INFO - root - 2017-12-01 05:12:27.086990: step 59600, loss = 0.40, batch loss = 0.23 (52.8 examples/sec; 0.152 sec/batch; 11h:29m:47s remains)
INFO - root - 2017-12-01 05:12:28.696608: step 59610, loss = 0.41, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 12h:03m:11s remains)
INFO - root - 2017-12-01 05:12:30.249297: step 59620, loss = 0.39, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 11h:44m:35s remains)
INFO - root - 2017-12-01 05:12:31.818059: step 59630, loss = 0.37, batch loss = 0.20 (52.7 examples/sec; 0.152 sec/batch; 11h:29m:54s remains)
INFO - root - 2017-12-01 05:12:33.397272: step 59640, loss = 0.54, batch loss = 0.37 (52.0 examples/sec; 0.154 sec/batch; 11h:39m:40s remains)
INFO - root - 2017-12-01 05:12:34.961722: step 59650, loss = 0.46, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 11h:45m:38s remains)
INFO - root - 2017-12-01 05:12:36.503140: step 59660, loss = 0.39, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 11h:43m:23s remains)
INFO - root - 2017-12-01 05:12:38.058621: step 59670, loss = 0.43, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 11h:48m:18s remains)
INFO - root - 2017-12-01 05:12:39.619127: step 59680, loss = 0.38, batch loss = 0.21 (51.1 examples/sec; 0.156 sec/batch; 11h:51m:16s remains)
INFO - root - 2017-12-01 05:12:41.181948: step 59690, loss = 0.35, batch loss = 0.19 (52.1 examples/sec; 0.153 sec/batch; 11h:37m:51s remains)
INFO - root - 2017-12-01 05:12:42.726085: step 59700, loss = 0.60, batch loss = 0.44 (53.6 examples/sec; 0.149 sec/batch; 11h:18m:58s remains)
INFO - root - 2017-12-01 05:12:44.338070: step 59710, loss = 0.46, batch loss = 0.29 (51.8 examples/sec; 0.154 sec/batch; 11h:42m:02s remains)
INFO - root - 2017-12-01 05:12:45.892570: step 59720, loss = 0.36, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 11h:47m:35s remains)
INFO - root - 2017-12-01 05:12:47.452984: step 59730, loss = 0.46, batch loss = 0.29 (52.8 examples/sec; 0.152 sec/batch; 11h:29m:21s remains)
INFO - root - 2017-12-01 05:12:49.024190: step 59740, loss = 0.55, batch loss = 0.38 (51.9 examples/sec; 0.154 sec/batch; 11h:40m:25s remains)
INFO - root - 2017-12-01 05:12:50.599158: step 59750, loss = 0.41, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 12h:08m:18s remains)
INFO - root - 2017-12-01 05:12:52.166678: step 59760, loss = 0.44, batch loss = 0.27 (52.3 examples/sec; 0.153 sec/batch; 11h:35m:06s remains)
INFO - root - 2017-12-01 05:12:53.723087: step 59770, loss = 0.39, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 11h:50m:36s remains)
INFO - root - 2017-12-01 05:12:55.290359: step 59780, loss = 0.40, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 11h:40m:18s remains)
INFO - root - 2017-12-01 05:12:56.864539: step 59790, loss = 0.33, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 11h:46m:06s remains)
INFO - root - 2017-12-01 05:12:58.426996: step 59800, loss = 0.38, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 11h:55m:18s remains)
INFO - root - 2017-12-01 05:13:00.039030: step 59810, loss = 0.44, batch loss = 0.27 (52.4 examples/sec; 0.153 sec/batch; 11h:34m:12s remains)
INFO - root - 2017-12-01 05:13:01.601579: step 59820, loss = 0.41, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 11h:58m:53s remains)
INFO - root - 2017-12-01 05:13:03.166108: step 59830, loss = 0.40, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 11h:54m:04s remains)
INFO - root - 2017-12-01 05:13:04.738369: step 59840, loss = 0.45, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 11h:50m:28s remains)
INFO - root - 2017-12-01 05:13:06.300923: step 59850, loss = 0.42, batch loss = 0.25 (49.4 examples/sec; 0.162 sec/batch; 12h:16m:19s remains)
INFO - root - 2017-12-01 05:13:07.875952: step 59860, loss = 0.40, batch loss = 0.24 (50.2 examples/sec; 0.159 sec/batch; 12h:03m:27s remains)
INFO - root - 2017-12-01 05:13:09.441448: step 59870, loss = 0.40, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 11h:53m:38s remains)
INFO - root - 2017-12-01 05:13:11.001717: step 59880, loss = 0.42, batch loss = 0.26 (49.5 examples/sec; 0.161 sec/batch; 12h:13m:45s remains)
INFO - root - 2017-12-01 05:13:12.569312: step 59890, loss = 0.60, batch loss = 0.43 (51.8 examples/sec; 0.155 sec/batch; 11h:42m:22s remains)
INFO - root - 2017-12-01 05:13:14.116107: step 59900, loss = 0.44, batch loss = 0.27 (52.1 examples/sec; 0.154 sec/batch; 11h:38m:04s remains)
INFO - root - 2017-12-01 05:13:15.715925: step 59910, loss = 0.51, batch loss = 0.34 (52.1 examples/sec; 0.153 sec/batch; 11h:36m:57s remains)
INFO - root - 2017-12-01 05:13:17.311906: step 59920, loss = 0.46, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 11h:56m:35s remains)
INFO - root - 2017-12-01 05:13:18.867992: step 59930, loss = 0.37, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 11h:46m:06s remains)
INFO - root - 2017-12-01 05:13:20.426910: step 59940, loss = 0.36, batch loss = 0.20 (52.9 examples/sec; 0.151 sec/batch; 11h:27m:03s remains)
INFO - root - 2017-12-01 05:13:22.004520: step 59950, loss = 0.55, batch loss = 0.38 (50.9 examples/sec; 0.157 sec/batch; 11h:53m:53s remains)
INFO - root - 2017-12-01 05:13:23.573671: step 59960, loss = 0.42, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 11h:54m:27s remains)
INFO - root - 2017-12-01 05:13:25.135713: step 59970, loss = 0.41, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 11h:54m:00s remains)
INFO - root - 2017-12-01 05:13:26.709060: step 59980, loss = 0.39, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 11h:43m:35s remains)
INFO - root - 2017-12-01 05:13:28.269490: step 59990, loss = 0.41, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 11h:39m:44s remains)
INFO - root - 2017-12-01 05:13:29.829469: step 60000, loss = 0.41, batch loss = 0.25 (50.8 examples/sec; 0.158 sec/batch; 11h:55m:31s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-60000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-60000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-01 05:13:31.842785: step 60010, loss = 0.36, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 11h:57m:22s remains)
INFO - root - 2017-12-01 05:13:33.400934: step 60020, loss = 0.40, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 11h:46m:03s remains)
INFO - root - 2017-12-01 05:13:34.960553: step 60030, loss = 0.44, batch loss = 0.28 (50.3 examples/sec; 0.159 sec/batch; 12h:01m:45s remains)
INFO - root - 2017-12-01 05:13:36.503537: step 60040, loss = 0.33, batch loss = 0.16 (51.7 examples/sec; 0.155 sec/batch; 11h:43m:04s remains)
INFO - root - 2017-12-01 05:13:38.066080: step 60050, loss = 0.48, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 11h:52m:38s remains)
INFO - root - 2017-12-01 05:13:39.626304: step 60060, loss = 0.35, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 11h:46m:47s remains)
INFO - root - 2017-12-01 05:13:41.197837: step 60070, loss = 0.44, batch loss = 0.27 (51.8 examples/sec; 0.154 sec/batch; 11h:41m:25s remains)
INFO - root - 2017-12-01 05:13:42.765161: step 60080, loss = 0.37, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 11h:55m:33s remains)
INFO - root - 2017-12-01 05:13:44.337960: step 60090, loss = 0.53, batch loss = 0.36 (50.9 examples/sec; 0.157 sec/batch; 11h:53m:55s remains)
INFO - root - 2017-12-01 05:13:45.890414: step 60100, loss = 0.49, batch loss = 0.32 (50.1 examples/sec; 0.160 sec/batch; 12h:05m:21s remains)
INFO - root - 2017-12-01 05:13:47.515653: step 60110, loss = 0.41, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 11h:43m:31s remains)
INFO - root - 2017-12-01 05:13:49.071036: step 60120, loss = 0.38, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 11h:34m:15s remains)
INFO - root - 2017-12-01 05:13:50.628566: step 60130, loss = 0.31, batch loss = 0.14 (49.7 examples/sec; 0.161 sec/batch; 12h:10m:23s remains)
INFO - root - 2017-12-01 05:13:52.190686: step 60140, loss = 0.39, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 11h:54m:10s remains)
INFO - root - 2017-12-01 05:13:53.744850: step 60150, loss = 0.37, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 11h:31m:24s remains)
INFO - root - 2017-12-01 05:13:55.335142: step 60160, loss = 0.38, batch loss = 0.21 (51.8 examples/sec; 0.155 sec/batch; 11h:41m:35s remains)
INFO - root - 2017-12-01 05:13:56.897122: step 60170, loss = 0.38, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 11h:56m:42s remains)
INFO - root - 2017-12-01 05:13:58.446627: step 60180, loss = 0.40, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 11h:52m:26s remains)
INFO - root - 2017-12-01 05:14:00.023213: step 60190, loss = 0.43, batch loss = 0.26 (49.4 examples/sec; 0.162 sec/batch; 12h:14m:48s remains)
INFO - root - 2017-12-01 05:14:01.591612: step 60200, loss = 0.38, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 11h:46m:25s remains)
INFO - root - 2017-12-01 05:14:03.217298: step 60210, loss = 0.35, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 12h:00m:38s remains)
INFO - root - 2017-12-01 05:14:04.759568: step 60220, loss = 0.49, batch loss = 0.32 (51.4 examples/sec; 0.156 sec/batch; 11h:46m:08s remains)
INFO - root - 2017-12-01 05:14:06.329487: step 60230, loss = 0.38, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 11h:42m:27s remains)
INFO - root - 2017-12-01 05:14:07.911301: step 60240, loss = 0.56, batch loss = 0.39 (51.6 examples/sec; 0.155 sec/batch; 11h:43m:04s remains)
INFO - root - 2017-12-01 05:14:09.466425: step 60250, loss = 0.44, batch loss = 0.27 (51.1 examples/sec; 0.156 sec/batch; 11h:49m:55s remains)
INFO - root - 2017-12-01 05:14:11.057247: step 60260, loss = 0.34, batch loss = 0.18 (48.1 examples/sec; 0.166 sec/batch; 12h:34m:57s remains)
INFO - root - 2017-12-01 05:14:12.628419: step 60270, loss = 0.37, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 11h:39m:04s remains)
INFO - root - 2017-12-01 05:14:14.199758: step 60280, loss = 0.34, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 11h:58m:56s remains)
INFO - root - 2017-12-01 05:14:15.761043: step 60290, loss = 0.43, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 12h:00m:29s remains)
INFO - root - 2017-12-01 05:14:17.328986: step 60300, loss = 0.42, batch loss = 0.25 (49.2 examples/sec; 0.163 sec/batch; 12h:17m:48s remains)
INFO - root - 2017-12-01 05:14:18.938802: step 60310, loss = 0.38, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 11h:38m:53s remains)
INFO - root - 2017-12-01 05:14:20.497118: step 60320, loss = 0.39, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 11h:59m:52s remains)
INFO - root - 2017-12-01 05:14:22.074790: step 60330, loss = 0.44, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 11h:42m:35s remains)
INFO - root - 2017-12-01 05:14:23.626650: step 60340, loss = 0.55, batch loss = 0.38 (51.0 examples/sec; 0.157 sec/batch; 11h:51m:31s remains)
INFO - root - 2017-12-01 05:14:25.175366: step 60350, loss = 0.34, batch loss = 0.17 (51.8 examples/sec; 0.154 sec/batch; 11h:39m:53s remains)
INFO - root - 2017-12-01 05:14:26.756608: step 60360, loss = 0.34, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 11h:47m:51s remains)
INFO - root - 2017-12-01 05:14:28.342189: step 60370, loss = 0.44, batch loss = 0.27 (50.8 examples/sec; 0.157 sec/batch; 11h:53m:41s remains)
INFO - root - 2017-12-01 05:14:29.896552: step 60380, loss = 0.44, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 11h:51m:42s remains)
INFO - root - 2017-12-01 05:14:31.476777: step 60390, loss = 0.45, batch loss = 0.29 (51.4 examples/sec; 0.155 sec/batch; 11h:45m:11s remains)
INFO - root - 2017-12-01 05:14:33.040038: step 60400, loss = 0.51, batch loss = 0.34 (53.4 examples/sec; 0.150 sec/batch; 11h:19m:56s remains)
INFO - root - 2017-12-01 05:14:34.658852: step 60410, loss = 0.49, batch loss = 0.32 (50.1 examples/sec; 0.160 sec/batch; 12h:04m:27s remains)
INFO - root - 2017-12-01 05:14:36.236961: step 60420, loss = 0.36, batch loss = 0.20 (52.7 examples/sec; 0.152 sec/batch; 11h:28m:29s remains)
INFO - root - 2017-12-01 05:14:37.816814: step 60430, loss = 0.58, batch loss = 0.42 (51.3 examples/sec; 0.156 sec/batch; 11h:47m:05s remains)
INFO - root - 2017-12-01 05:14:39.378986: step 60440, loss = 0.41, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 12h:01m:31s remains)
INFO - root - 2017-12-01 05:14:40.934295: step 60450, loss = 0.50, batch loss = 0.33 (50.0 examples/sec; 0.160 sec/batch; 12h:05m:51s remains)
INFO - root - 2017-12-01 05:14:42.507913: step 60460, loss = 0.38, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 11h:56m:00s remains)
INFO - root - 2017-12-01 05:14:44.064994: step 60470, loss = 0.44, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 11h:34m:21s remains)
INFO - root - 2017-12-01 05:14:45.629219: step 60480, loss = 0.38, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 11h:32m:59s remains)
INFO - root - 2017-12-01 05:14:47.219597: step 60490, loss = 0.41, batch loss = 0.25 (50.8 examples/sec; 0.158 sec/batch; 11h:54m:18s remains)
INFO - root - 2017-12-01 05:14:48.771734: step 60500, loss = 0.32, batch loss = 0.15 (51.0 examples/sec; 0.157 sec/batch; 11h:50m:57s remains)
INFO - root - 2017-12-01 05:14:50.383941: step 60510, loss = 0.50, batch loss = 0.33 (51.6 examples/sec; 0.155 sec/batch; 11h:43m:02s remains)
INFO - root - 2017-12-01 05:14:51.950649: step 60520, loss = 0.38, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 12h:01m:27s remains)
INFO - root - 2017-12-01 05:14:53.505163: step 60530, loss = 0.39, batch loss = 0.22 (49.7 examples/sec; 0.161 sec/batch; 12h:09m:51s remains)
INFO - root - 2017-12-01 05:14:55.063576: step 60540, loss = 0.39, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 11h:54m:04s remains)
INFO - root - 2017-12-01 05:14:56.657495: step 60550, loss = 0.49, batch loss = 0.33 (51.4 examples/sec; 0.156 sec/batch; 11h:45m:02s remains)
INFO - root - 2017-12-01 05:14:58.210397: step 60560, loss = 0.35, batch loss = 0.18 (52.6 examples/sec; 0.152 sec/batch; 11h:29m:33s remains)
INFO - root - 2017-12-01 05:14:59.771399: step 60570, loss = 0.41, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 11h:52m:56s remains)
INFO - root - 2017-12-01 05:15:01.333883: step 60580, loss = 0.45, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 11h:52m:50s remains)
INFO - root - 2017-12-01 05:15:02.903223: step 60590, loss = 0.44, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 11h:49m:26s remains)
INFO - root - 2017-12-01 05:15:04.477896: step 60600, loss = 0.46, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 11h:52m:07s remains)
INFO - root - 2017-12-01 05:15:06.109838: step 60610, loss = 0.37, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 11h:59m:23s remains)
INFO - root - 2017-12-01 05:15:07.695059: step 60620, loss = 0.57, batch loss = 0.40 (50.4 examples/sec; 0.159 sec/batch; 11h:59m:10s remains)
INFO - root - 2017-12-01 05:15:09.253497: step 60630, loss = 0.40, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 11h:42m:43s remains)
INFO - root - 2017-12-01 05:15:10.824869: step 60640, loss = 0.47, batch loss = 0.31 (51.7 examples/sec; 0.155 sec/batch; 11h:41m:37s remains)
INFO - root - 2017-12-01 05:15:12.385513: step 60650, loss = 0.40, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 11h:56m:48s remains)
INFO - root - 2017-12-01 05:15:13.949574: step 60660, loss = 0.44, batch loss = 0.28 (52.9 examples/sec; 0.151 sec/batch; 11h:24m:47s remains)
INFO - root - 2017-12-01 05:15:15.504539: step 60670, loss = 0.49, batch loss = 0.32 (52.2 examples/sec; 0.153 sec/batch; 11h:34m:54s remains)
INFO - root - 2017-12-01 05:15:17.076919: step 60680, loss = 0.43, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 11h:42m:50s remains)
INFO - root - 2017-12-01 05:15:18.644385: step 60690, loss = 0.45, batch loss = 0.28 (52.4 examples/sec; 0.153 sec/batch; 11h:31m:49s remains)
INFO - root - 2017-12-01 05:15:20.224948: step 60700, loss = 0.43, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 11h:51m:51s remains)
INFO - root - 2017-12-01 05:15:21.909688: step 60710, loss = 0.49, batch loss = 0.32 (50.6 examples/sec; 0.158 sec/batch; 11h:55m:51s remains)
INFO - root - 2017-12-01 05:15:23.468451: step 60720, loss = 0.33, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 11h:44m:14s remains)
INFO - root - 2017-12-01 05:15:25.050038: step 60730, loss = 0.38, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 11h:45m:42s remains)
INFO - root - 2017-12-01 05:15:26.611441: step 60740, loss = 0.42, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 11h:38m:34s remains)
INFO - root - 2017-12-01 05:15:28.211225: step 60750, loss = 0.37, batch loss = 0.20 (49.6 examples/sec; 0.161 sec/batch; 12h:11m:01s remains)
INFO - root - 2017-12-01 05:15:29.769388: step 60760, loss = 0.33, batch loss = 0.16 (53.2 examples/sec; 0.150 sec/batch; 11h:21m:09s remains)
INFO - root - 2017-12-01 05:15:31.328409: step 60770, loss = 0.39, batch loss = 0.22 (52.1 examples/sec; 0.153 sec/batch; 11h:34m:59s remains)
INFO - root - 2017-12-01 05:15:32.899495: step 60780, loss = 0.37, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 11h:52m:21s remains)
INFO - root - 2017-12-01 05:15:34.479192: step 60790, loss = 0.41, batch loss = 0.24 (49.3 examples/sec; 0.162 sec/batch; 12h:14m:35s remains)
INFO - root - 2017-12-01 05:15:36.052404: step 60800, loss = 0.40, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 11h:36m:08s remains)
INFO - root - 2017-12-01 05:15:37.688281: step 60810, loss = 0.49, batch loss = 0.32 (51.7 examples/sec; 0.155 sec/batch; 11h:40m:04s remains)
INFO - root - 2017-12-01 05:15:39.247472: step 60820, loss = 0.41, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 11h:40m:31s remains)
INFO - root - 2017-12-01 05:15:40.820226: step 60830, loss = 0.42, batch loss = 0.25 (50.8 examples/sec; 0.157 sec/batch; 11h:52m:23s remains)
INFO - root - 2017-12-01 05:15:42.376743: step 60840, loss = 0.45, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 11h:44m:19s remains)
INFO - root - 2017-12-01 05:15:43.938662: step 60850, loss = 0.53, batch loss = 0.36 (51.9 examples/sec; 0.154 sec/batch; 11h:38m:09s remains)
INFO - root - 2017-12-01 05:15:45.510225: step 60860, loss = 0.34, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 11h:47m:36s remains)
INFO - root - 2017-12-01 05:15:47.062845: step 60870, loss = 0.39, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 11h:36m:16s remains)
INFO - root - 2017-12-01 05:15:48.629450: step 60880, loss = 0.34, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 11h:44m:29s remains)
INFO - root - 2017-12-01 05:15:50.187174: step 60890, loss = 0.36, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 11h:33m:02s remains)
INFO - root - 2017-12-01 05:15:51.743147: step 60900, loss = 0.39, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 12h:05m:36s remains)
INFO - root - 2017-12-01 05:15:53.406587: step 60910, loss = 0.42, batch loss = 0.26 (52.3 examples/sec; 0.153 sec/batch; 11h:32m:50s remains)
INFO - root - 2017-12-01 05:15:54.975816: step 60920, loss = 0.50, batch loss = 0.33 (52.2 examples/sec; 0.153 sec/batch; 11h:33m:25s remains)
INFO - root - 2017-12-01 05:15:56.567323: step 60930, loss = 0.36, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 11h:44m:01s remains)
INFO - root - 2017-12-01 05:15:58.133308: step 60940, loss = 0.44, batch loss = 0.27 (50.2 examples/sec; 0.159 sec/batch; 12h:00m:48s remains)
INFO - root - 2017-12-01 05:15:59.686208: step 60950, loss = 0.39, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 11h:48m:54s remains)
INFO - root - 2017-12-01 05:16:01.256787: step 60960, loss = 0.44, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 11h:54m:00s remains)
INFO - root - 2017-12-01 05:16:02.827168: step 60970, loss = 0.35, batch loss = 0.18 (49.8 examples/sec; 0.161 sec/batch; 12h:07m:08s remains)
INFO - root - 2017-12-01 05:16:04.392469: step 60980, loss = 0.52, batch loss = 0.35 (50.1 examples/sec; 0.160 sec/batch; 12h:02m:10s remains)
INFO - root - 2017-12-01 05:16:05.947240: step 60990, loss = 0.37, batch loss = 0.20 (49.4 examples/sec; 0.162 sec/batch; 12h:13m:05s remains)
INFO - root - 2017-12-01 05:16:07.520416: step 61000, loss = 0.36, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 11h:30m:41s remains)
INFO - root - 2017-12-01 05:16:09.167010: step 61010, loss = 0.39, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 11h:36m:55s remains)
INFO - root - 2017-12-01 05:16:10.729962: step 61020, loss = 0.42, batch loss = 0.26 (52.4 examples/sec; 0.153 sec/batch; 11h:31m:12s remains)
INFO - root - 2017-12-01 05:16:12.305452: step 61030, loss = 0.46, batch loss = 0.30 (51.7 examples/sec; 0.155 sec/batch; 11h:40m:04s remains)
INFO - root - 2017-12-01 05:16:13.870620: step 61040, loss = 0.39, batch loss = 0.23 (49.4 examples/sec; 0.162 sec/batch; 12h:12m:28s remains)
INFO - root - 2017-12-01 05:16:15.427804: step 61050, loss = 0.41, batch loss = 0.25 (50.8 examples/sec; 0.157 sec/batch; 11h:52m:30s remains)
INFO - root - 2017-12-01 05:16:17.007438: step 61060, loss = 0.36, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 11h:49m:45s remains)
INFO - root - 2017-12-01 05:16:18.551897: step 61070, loss = 0.40, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 11h:42m:07s remains)
INFO - root - 2017-12-01 05:16:20.139398: step 61080, loss = 0.35, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 11h:40m:28s remains)
INFO - root - 2017-12-01 05:16:21.679784: step 61090, loss = 0.36, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 11h:31m:20s remains)
INFO - root - 2017-12-01 05:16:23.250007: step 61100, loss = 0.36, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 11h:48m:15s remains)
INFO - root - 2017-12-01 05:16:24.924740: step 61110, loss = 0.43, batch loss = 0.26 (52.1 examples/sec; 0.153 sec/batch; 11h:33m:58s remains)
INFO - root - 2017-12-01 05:16:26.489862: step 61120, loss = 0.38, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 12h:02m:34s remains)
INFO - root - 2017-12-01 05:16:28.049250: step 61130, loss = 0.34, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 11h:48m:10s remains)
INFO - root - 2017-12-01 05:16:29.607666: step 61140, loss = 0.41, batch loss = 0.25 (52.7 examples/sec; 0.152 sec/batch; 11h:26m:11s remains)
INFO - root - 2017-12-01 05:16:31.174537: step 61150, loss = 0.40, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 11h:53m:23s remains)
INFO - root - 2017-12-01 05:16:32.755514: step 61160, loss = 0.47, batch loss = 0.31 (51.5 examples/sec; 0.155 sec/batch; 11h:42m:40s remains)
INFO - root - 2017-12-01 05:16:34.313286: step 61170, loss = 0.54, batch loss = 0.37 (49.7 examples/sec; 0.161 sec/batch; 12h:08m:14s remains)
INFO - root - 2017-12-01 05:16:35.885436: step 61180, loss = 0.48, batch loss = 0.31 (50.8 examples/sec; 0.157 sec/batch; 11h:52m:04s remains)
INFO - root - 2017-12-01 05:16:37.439341: step 61190, loss = 0.38, batch loss = 0.21 (53.0 examples/sec; 0.151 sec/batch; 11h:22m:17s remains)
INFO - root - 2017-12-01 05:16:39.002815: step 61200, loss = 0.38, batch loss = 0.21 (53.3 examples/sec; 0.150 sec/batch; 11h:18m:52s remains)
INFO - root - 2017-12-01 05:16:40.632133: step 61210, loss = 0.45, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 11h:43m:20s remains)
INFO - root - 2017-12-01 05:16:42.200598: step 61220, loss = 0.37, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 11h:50m:34s remains)
INFO - root - 2017-12-01 05:16:43.793165: step 61230, loss = 0.38, batch loss = 0.21 (50.0 examples/sec; 0.160 sec/batch; 12h:03m:28s remains)
INFO - root - 2017-12-01 05:16:45.349445: step 61240, loss = 0.37, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 11h:43m:18s remains)
INFO - root - 2017-12-01 05:16:46.899597: step 61250, loss = 0.33, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 11h:57m:30s remains)
INFO - root - 2017-12-01 05:16:48.485290: step 61260, loss = 0.42, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 11h:43m:29s remains)
INFO - root - 2017-12-01 05:16:50.075338: step 61270, loss = 0.45, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 11h:45m:21s remains)
INFO - root - 2017-12-01 05:16:51.637743: step 61280, loss = 0.39, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 11h:52m:09s remains)
INFO - root - 2017-12-01 05:16:53.205623: step 61290, loss = 0.41, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 11h:41m:12s remains)
INFO - root - 2017-12-01 05:16:54.785785: step 61300, loss = 0.44, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 11h:42m:10s remains)
INFO - root - 2017-12-01 05:16:56.421909: step 61310, loss = 0.35, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 11h:37m:41s remains)
INFO - root - 2017-12-01 05:16:57.997281: step 61320, loss = 0.36, batch loss = 0.19 (52.1 examples/sec; 0.154 sec/batch; 11h:34m:34s remains)
INFO - root - 2017-12-01 05:16:59.580117: step 61330, loss = 0.44, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 11h:48m:15s remains)
INFO - root - 2017-12-01 05:17:01.134161: step 61340, loss = 0.37, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 11h:53m:18s remains)
INFO - root - 2017-12-01 05:17:02.707786: step 61350, loss = 0.38, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 11h:44m:19s remains)
INFO - root - 2017-12-01 05:17:04.271336: step 61360, loss = 0.35, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 11h:48m:22s remains)
INFO - root - 2017-12-01 05:17:05.842730: step 61370, loss = 0.40, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 11h:39m:33s remains)
INFO - root - 2017-12-01 05:17:07.402040: step 61380, loss = 0.43, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 11h:44m:34s remains)
INFO - root - 2017-12-01 05:17:08.961286: step 61390, loss = 0.41, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 11h:50m:22s remains)
INFO - root - 2017-12-01 05:17:10.521698: step 61400, loss = 0.39, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 11h:49m:21s remains)
INFO - root - 2017-12-01 05:17:12.155043: step 61410, loss = 0.37, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 11h:33m:50s remains)
INFO - root - 2017-12-01 05:17:13.729683: step 61420, loss = 0.50, batch loss = 0.34 (50.6 examples/sec; 0.158 sec/batch; 11h:54m:06s remains)
INFO - root - 2017-12-01 05:17:15.349749: step 61430, loss = 0.38, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 11h:49m:02s remains)
INFO - root - 2017-12-01 05:17:16.900681: step 61440, loss = 0.45, batch loss = 0.29 (52.2 examples/sec; 0.153 sec/batch; 11h:31m:50s remains)
INFO - root - 2017-12-01 05:17:18.467804: step 61450, loss = 0.44, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 11h:38m:35s remains)
INFO - root - 2017-12-01 05:17:20.016459: step 61460, loss = 0.40, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 11h:35m:00s remains)
INFO - root - 2017-12-01 05:17:21.577285: step 61470, loss = 0.36, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 11h:59m:56s remains)
INFO - root - 2017-12-01 05:17:23.153900: step 61480, loss = 0.58, batch loss = 0.42 (50.5 examples/sec; 0.158 sec/batch; 11h:55m:45s remains)
INFO - root - 2017-12-01 05:17:24.693576: step 61490, loss = 0.33, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 11h:41m:25s remains)
INFO - root - 2017-12-01 05:17:26.274859: step 61500, loss = 0.38, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 11h:33m:39s remains)
INFO - root - 2017-12-01 05:17:27.932681: step 61510, loss = 0.38, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 11h:47m:29s remains)
INFO - root - 2017-12-01 05:17:29.486444: step 61520, loss = 0.50, batch loss = 0.33 (52.3 examples/sec; 0.153 sec/batch; 11h:31m:15s remains)
INFO - root - 2017-12-01 05:17:31.020261: step 61530, loss = 0.54, batch loss = 0.37 (52.7 examples/sec; 0.152 sec/batch; 11h:25m:02s remains)
INFO - root - 2017-12-01 05:17:32.591770: step 61540, loss = 0.32, batch loss = 0.15 (51.9 examples/sec; 0.154 sec/batch; 11h:36m:38s remains)
INFO - root - 2017-12-01 05:17:34.148625: step 61550, loss = 0.55, batch loss = 0.39 (49.9 examples/sec; 0.160 sec/batch; 12h:03m:38s remains)
INFO - root - 2017-12-01 05:17:35.708380: step 61560, loss = 0.38, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 11h:39m:24s remains)
INFO - root - 2017-12-01 05:17:37.288392: step 61570, loss = 0.42, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 11h:44m:08s remains)
INFO - root - 2017-12-01 05:17:38.842637: step 61580, loss = 0.37, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 11h:40m:13s remains)
INFO - root - 2017-12-01 05:17:40.377778: step 61590, loss = 0.38, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 11h:36m:40s remains)
INFO - root - 2017-12-01 05:17:41.943341: step 61600, loss = 0.36, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 12h:02m:28s remains)
INFO - root - 2017-12-01 05:17:43.590648: step 61610, loss = 0.43, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 11h:40m:33s remains)
INFO - root - 2017-12-01 05:17:45.152941: step 61620, loss = 0.41, batch loss = 0.24 (50.2 examples/sec; 0.159 sec/batch; 11h:58m:48s remains)
INFO - root - 2017-12-01 05:17:46.705899: step 61630, loss = 0.43, batch loss = 0.26 (50.8 examples/sec; 0.158 sec/batch; 11h:51m:34s remains)
INFO - root - 2017-12-01 05:17:48.279761: step 61640, loss = 0.46, batch loss = 0.30 (50.3 examples/sec; 0.159 sec/batch; 11h:57m:17s remains)
INFO - root - 2017-12-01 05:17:49.841484: step 61650, loss = 0.36, batch loss = 0.19 (52.7 examples/sec; 0.152 sec/batch; 11h:25m:16s remains)
INFO - root - 2017-12-01 05:17:51.403411: step 61660, loss = 0.43, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 11h:47m:55s remains)
INFO - root - 2017-12-01 05:17:52.973769: step 61670, loss = 0.43, batch loss = 0.27 (50.1 examples/sec; 0.160 sec/batch; 12h:00m:20s remains)
INFO - root - 2017-12-01 05:17:54.542956: step 61680, loss = 0.41, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 12h:04m:10s remains)
INFO - root - 2017-12-01 05:17:56.112487: step 61690, loss = 0.50, batch loss = 0.33 (51.4 examples/sec; 0.156 sec/batch; 11h:42m:30s remains)
INFO - root - 2017-12-01 05:17:57.675885: step 61700, loss = 0.36, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 11h:30m:03s remains)
INFO - root - 2017-12-01 05:17:59.281835: step 61710, loss = 0.36, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 11h:53m:05s remains)
INFO - root - 2017-12-01 05:18:00.846470: step 61720, loss = 0.44, batch loss = 0.28 (50.1 examples/sec; 0.160 sec/batch; 12h:00m:56s remains)
INFO - root - 2017-12-01 05:18:02.411273: step 61730, loss = 0.40, batch loss = 0.24 (50.2 examples/sec; 0.159 sec/batch; 11h:59m:16s remains)
INFO - root - 2017-12-01 05:18:03.974816: step 61740, loss = 0.48, batch loss = 0.31 (52.1 examples/sec; 0.153 sec/batch; 11h:32m:34s remains)
INFO - root - 2017-12-01 05:18:05.553687: step 61750, loss = 0.36, batch loss = 0.20 (52.7 examples/sec; 0.152 sec/batch; 11h:24m:59s remains)
INFO - root - 2017-12-01 05:18:07.122863: step 61760, loss = 0.36, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 11h:43m:01s remains)
INFO - root - 2017-12-01 05:18:08.680705: step 61770, loss = 0.36, batch loss = 0.19 (48.9 examples/sec; 0.164 sec/batch; 12h:18m:13s remains)
INFO - root - 2017-12-01 05:18:10.265319: step 61780, loss = 0.45, batch loss = 0.28 (50.5 examples/sec; 0.159 sec/batch; 11h:55m:16s remains)
INFO - root - 2017-12-01 05:18:11.805262: step 61790, loss = 0.32, batch loss = 0.16 (53.2 examples/sec; 0.150 sec/batch; 11h:18m:48s remains)
INFO - root - 2017-12-01 05:18:13.369602: step 61800, loss = 0.39, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 11h:38m:23s remains)
INFO - root - 2017-12-01 05:18:15.023491: step 61810, loss = 0.38, batch loss = 0.22 (53.3 examples/sec; 0.150 sec/batch; 11h:17m:12s remains)
INFO - root - 2017-12-01 05:18:16.577676: step 61820, loss = 0.35, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 11h:33m:24s remains)
INFO - root - 2017-12-01 05:18:18.143861: step 61830, loss = 0.35, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 11h:36m:54s remains)
INFO - root - 2017-12-01 05:18:19.713119: step 61840, loss = 0.57, batch loss = 0.41 (51.1 examples/sec; 0.157 sec/batch; 11h:46m:15s remains)
INFO - root - 2017-12-01 05:18:21.277799: step 61850, loss = 0.34, batch loss = 0.17 (52.5 examples/sec; 0.152 sec/batch; 11h:26m:49s remains)
INFO - root - 2017-12-01 05:18:22.843045: step 61860, loss = 0.41, batch loss = 0.25 (51.8 examples/sec; 0.155 sec/batch; 11h:37m:05s remains)
INFO - root - 2017-12-01 05:18:24.407047: step 61870, loss = 0.38, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 11h:40m:20s remains)
INFO - root - 2017-12-01 05:18:25.970343: step 61880, loss = 0.45, batch loss = 0.28 (50.4 examples/sec; 0.159 sec/batch; 11h:56m:00s remains)
INFO - root - 2017-12-01 05:18:27.562876: step 61890, loss = 0.48, batch loss = 0.32 (51.1 examples/sec; 0.156 sec/batch; 11h:45m:33s remains)
INFO - root - 2017-12-01 05:18:29.155522: step 61900, loss = 0.34, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 11h:41m:01s remains)
INFO - root - 2017-12-01 05:18:30.784086: step 61910, loss = 0.35, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 11h:52m:06s remains)
INFO - root - 2017-12-01 05:18:32.388956: step 61920, loss = 0.36, batch loss = 0.20 (49.8 examples/sec; 0.161 sec/batch; 12h:04m:20s remains)
INFO - root - 2017-12-01 05:18:33.952611: step 61930, loss = 0.60, batch loss = 0.43 (50.4 examples/sec; 0.159 sec/batch; 11h:55m:14s remains)
INFO - root - 2017-12-01 05:18:35.520664: step 61940, loss = 0.38, batch loss = 0.21 (53.7 examples/sec; 0.149 sec/batch; 11h:11m:33s remains)
INFO - root - 2017-12-01 05:18:37.082140: step 61950, loss = 0.35, batch loss = 0.18 (52.5 examples/sec; 0.152 sec/batch; 11h:27m:25s remains)
INFO - root - 2017-12-01 05:18:38.642456: step 61960, loss = 0.43, batch loss = 0.26 (52.9 examples/sec; 0.151 sec/batch; 11h:22m:11s remains)
INFO - root - 2017-12-01 05:18:40.228687: step 61970, loss = 0.36, batch loss = 0.19 (51.1 examples/sec; 0.156 sec/batch; 11h:45m:18s remains)
INFO - root - 2017-12-01 05:18:41.819925: step 61980, loss = 0.38, batch loss = 0.21 (49.9 examples/sec; 0.160 sec/batch; 12h:03m:33s remains)
INFO - root - 2017-12-01 05:18:43.397166: step 61990, loss = 0.40, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 11h:41m:35s remains)
INFO - root - 2017-12-01 05:18:44.975248: step 62000, loss = 0.58, batch loss = 0.42 (51.7 examples/sec; 0.155 sec/batch; 11h:38m:13s remains)
INFO - root - 2017-12-01 05:18:46.617652: step 62010, loss = 0.43, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 11h:30m:15s remains)
INFO - root - 2017-12-01 05:18:48.183057: step 62020, loss = 0.40, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 11h:43m:11s remains)
INFO - root - 2017-12-01 05:18:49.744683: step 62030, loss = 0.46, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 11h:49m:06s remains)
INFO - root - 2017-12-01 05:18:51.302729: step 62040, loss = 0.38, batch loss = 0.21 (51.1 examples/sec; 0.156 sec/batch; 11h:45m:02s remains)
INFO - root - 2017-12-01 05:18:52.869069: step 62050, loss = 0.47, batch loss = 0.30 (50.1 examples/sec; 0.160 sec/batch; 11h:59m:09s remains)
INFO - root - 2017-12-01 05:18:54.431873: step 62060, loss = 0.46, batch loss = 0.30 (53.1 examples/sec; 0.151 sec/batch; 11h:19m:03s remains)
INFO - root - 2017-12-01 05:18:55.986659: step 62070, loss = 0.43, batch loss = 0.27 (53.7 examples/sec; 0.149 sec/batch; 11h:10m:56s remains)
INFO - root - 2017-12-01 05:18:57.545909: step 62080, loss = 0.42, batch loss = 0.25 (52.0 examples/sec; 0.154 sec/batch; 11h:33m:05s remains)
INFO - root - 2017-12-01 05:18:59.111051: step 62090, loss = 0.38, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 11h:37m:04s remains)
INFO - root - 2017-12-01 05:19:00.666239: step 62100, loss = 0.35, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 11h:49m:10s remains)
INFO - root - 2017-12-01 05:19:02.338889: step 62110, loss = 0.35, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 11h:33m:41s remains)
INFO - root - 2017-12-01 05:19:03.893316: step 62120, loss = 0.48, batch loss = 0.31 (50.7 examples/sec; 0.158 sec/batch; 11h:51m:10s remains)
INFO - root - 2017-12-01 05:19:05.459421: step 62130, loss = 0.38, batch loss = 0.21 (49.6 examples/sec; 0.161 sec/batch; 12h:06m:30s remains)
INFO - root - 2017-12-01 05:19:07.025974: step 62140, loss = 0.35, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 11h:51m:36s remains)
INFO - root - 2017-12-01 05:19:08.592122: step 62150, loss = 0.37, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 11h:53m:12s remains)
INFO - root - 2017-12-01 05:19:10.142629: step 62160, loss = 0.46, batch loss = 0.30 (50.0 examples/sec; 0.160 sec/batch; 12h:00m:34s remains)
INFO - root - 2017-12-01 05:19:11.727058: step 62170, loss = 0.37, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 11h:32m:26s remains)
INFO - root - 2017-12-01 05:19:13.298651: step 62180, loss = 0.42, batch loss = 0.25 (49.6 examples/sec; 0.161 sec/batch; 12h:07m:05s remains)
INFO - root - 2017-12-01 05:19:14.866270: step 62190, loss = 0.47, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 11h:50m:36s remains)
INFO - root - 2017-12-01 05:19:16.419320: step 62200, loss = 0.36, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 11h:34m:20s remains)
INFO - root - 2017-12-01 05:19:18.028644: step 62210, loss = 0.39, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 11h:35m:49s remains)
INFO - root - 2017-12-01 05:19:19.589741: step 62220, loss = 0.48, batch loss = 0.31 (52.6 examples/sec; 0.152 sec/batch; 11h:25m:42s remains)
INFO - root - 2017-12-01 05:19:21.166054: step 62230, loss = 0.48, batch loss = 0.32 (51.9 examples/sec; 0.154 sec/batch; 11h:34m:02s remains)
INFO - root - 2017-12-01 05:19:22.730348: step 62240, loss = 0.34, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 11h:49m:16s remains)
INFO - root - 2017-12-01 05:19:24.293911: step 62250, loss = 0.42, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 11h:51m:57s remains)
INFO - root - 2017-12-01 05:19:25.848505: step 62260, loss = 0.33, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 11h:41m:01s remains)
INFO - root - 2017-12-01 05:19:27.425933: step 62270, loss = 0.44, batch loss = 0.28 (49.7 examples/sec; 0.161 sec/batch; 12h:04m:17s remains)
INFO - root - 2017-12-01 05:19:28.984339: step 62280, loss = 0.43, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 11h:45m:55s remains)
INFO - root - 2017-12-01 05:19:30.553446: step 62290, loss = 0.35, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 11h:50m:23s remains)
INFO - root - 2017-12-01 05:19:32.123107: step 62300, loss = 0.36, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 12h:07m:52s remains)
INFO - root - 2017-12-01 05:19:33.774008: step 62310, loss = 0.44, batch loss = 0.28 (50.2 examples/sec; 0.159 sec/batch; 11h:57m:10s remains)
INFO - root - 2017-12-01 05:19:35.342623: step 62320, loss = 0.37, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 11h:42m:48s remains)
INFO - root - 2017-12-01 05:19:36.900545: step 62330, loss = 0.34, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 11h:51m:13s remains)
INFO - root - 2017-12-01 05:19:38.449188: step 62340, loss = 0.41, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 11h:35m:35s remains)
INFO - root - 2017-12-01 05:19:40.029278: step 62350, loss = 0.34, batch loss = 0.18 (49.3 examples/sec; 0.162 sec/batch; 12h:10m:19s remains)
INFO - root - 2017-12-01 05:19:41.615295: step 62360, loss = 0.36, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 11h:50m:51s remains)
INFO - root - 2017-12-01 05:19:43.170161: step 62370, loss = 0.45, batch loss = 0.29 (49.9 examples/sec; 0.160 sec/batch; 12h:01m:16s remains)
INFO - root - 2017-12-01 05:19:44.745383: step 62380, loss = 0.41, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 11h:50m:41s remains)
INFO - root - 2017-12-01 05:19:46.310081: step 62390, loss = 0.47, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 11h:45m:55s remains)
INFO - root - 2017-12-01 05:19:47.873185: step 62400, loss = 0.36, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 11h:34m:16s remains)
INFO - root - 2017-12-01 05:19:49.487779: step 62410, loss = 0.40, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 11h:43m:42s remains)
INFO - root - 2017-12-01 05:19:51.056476: step 62420, loss = 0.45, batch loss = 0.29 (51.8 examples/sec; 0.155 sec/batch; 11h:35m:44s remains)
INFO - root - 2017-12-01 05:19:52.641440: step 62430, loss = 0.44, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 11h:40m:39s remains)
INFO - root - 2017-12-01 05:19:54.222922: step 62440, loss = 0.38, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 11h:46m:12s remains)
INFO - root - 2017-12-01 05:19:55.780215: step 62450, loss = 0.34, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 11h:43m:21s remains)
INFO - root - 2017-12-01 05:19:57.357662: step 62460, loss = 0.40, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 11h:42m:29s remains)
INFO - root - 2017-12-01 05:19:58.910541: step 62470, loss = 0.37, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 11h:52m:56s remains)
INFO - root - 2017-12-01 05:20:00.470097: step 62480, loss = 0.50, batch loss = 0.33 (50.9 examples/sec; 0.157 sec/batch; 11h:46m:46s remains)
INFO - root - 2017-12-01 05:20:02.053104: step 62490, loss = 0.48, batch loss = 0.32 (49.8 examples/sec; 0.161 sec/batch; 12h:02m:35s remains)
INFO - root - 2017-12-01 05:20:03.631180: step 62500, loss = 0.44, batch loss = 0.27 (51.9 examples/sec; 0.154 sec/batch; 11h:33m:28s remains)
INFO - root - 2017-12-01 05:20:05.240297: step 62510, loss = 0.39, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 11h:51m:15s remains)
INFO - root - 2017-12-01 05:20:06.797506: step 62520, loss = 0.38, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 11h:48m:23s remains)
INFO - root - 2017-12-01 05:20:08.356063: step 62530, loss = 0.51, batch loss = 0.35 (52.0 examples/sec; 0.154 sec/batch; 11h:32m:52s remains)
INFO - root - 2017-12-01 05:20:09.921262: step 62540, loss = 0.39, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 12h:01m:33s remains)
INFO - root - 2017-12-01 05:20:11.505384: step 62550, loss = 0.39, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 11h:50m:28s remains)
INFO - root - 2017-12-01 05:20:13.080786: step 62560, loss = 0.41, batch loss = 0.25 (50.2 examples/sec; 0.159 sec/batch; 11h:57m:31s remains)
INFO - root - 2017-12-01 05:20:14.636630: step 62570, loss = 0.39, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 11h:38m:36s remains)
INFO - root - 2017-12-01 05:20:16.189431: step 62580, loss = 0.36, batch loss = 0.20 (53.0 examples/sec; 0.151 sec/batch; 11h:19m:18s remains)
INFO - root - 2017-12-01 05:20:17.750569: step 62590, loss = 0.37, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 11h:24m:51s remains)
INFO - root - 2017-12-01 05:20:19.311880: step 62600, loss = 0.40, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 11h:52m:02s remains)
INFO - root - 2017-12-01 05:20:20.920718: step 62610, loss = 0.35, batch loss = 0.18 (49.5 examples/sec; 0.162 sec/batch; 12h:06m:47s remains)
INFO - root - 2017-12-01 05:20:22.493750: step 62620, loss = 0.47, batch loss = 0.30 (52.3 examples/sec; 0.153 sec/batch; 11h:27m:23s remains)
INFO - root - 2017-12-01 05:20:24.058537: step 62630, loss = 0.51, batch loss = 0.34 (52.1 examples/sec; 0.153 sec/batch; 11h:30m:25s remains)
INFO - root - 2017-12-01 05:20:25.617601: step 62640, loss = 0.45, batch loss = 0.29 (51.8 examples/sec; 0.155 sec/batch; 11h:35m:15s remains)
INFO - root - 2017-12-01 05:20:27.179102: step 62650, loss = 0.39, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 11h:38m:03s remains)
INFO - root - 2017-12-01 05:20:28.720064: step 62660, loss = 0.37, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 11h:47m:32s remains)
INFO - root - 2017-12-01 05:20:30.291739: step 62670, loss = 0.36, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 11h:41m:35s remains)
INFO - root - 2017-12-01 05:20:31.880113: step 62680, loss = 0.41, batch loss = 0.25 (52.9 examples/sec; 0.151 sec/batch; 11h:19m:50s remains)
INFO - root - 2017-12-01 05:20:33.444719: step 62690, loss = 0.35, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 11h:55m:21s remains)
INFO - root - 2017-12-01 05:20:35.012366: step 62700, loss = 0.58, batch loss = 0.42 (50.4 examples/sec; 0.159 sec/batch; 11h:54m:06s remains)
INFO - root - 2017-12-01 05:20:36.658103: step 62710, loss = 0.34, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 11h:50m:38s remains)
INFO - root - 2017-12-01 05:20:38.229296: step 62720, loss = 0.44, batch loss = 0.28 (49.5 examples/sec; 0.162 sec/batch; 12h:07m:14s remains)
INFO - root - 2017-12-01 05:20:39.807110: step 62730, loss = 0.35, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 11h:35m:25s remains)
INFO - root - 2017-12-01 05:20:41.359661: step 62740, loss = 0.36, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 11h:24m:13s remains)
INFO - root - 2017-12-01 05:20:42.947539: step 62750, loss = 0.40, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 11h:50m:28s remains)
INFO - root - 2017-12-01 05:20:44.504648: step 62760, loss = 0.55, batch loss = 0.38 (51.6 examples/sec; 0.155 sec/batch; 11h:37m:32s remains)
INFO - root - 2017-12-01 05:20:46.073554: step 62770, loss = 0.33, batch loss = 0.17 (50.1 examples/sec; 0.160 sec/batch; 11h:57m:08s remains)
INFO - root - 2017-12-01 05:20:47.642566: step 62780, loss = 0.33, batch loss = 0.17 (52.7 examples/sec; 0.152 sec/batch; 11h:22m:49s remains)
INFO - root - 2017-12-01 05:20:49.202826: step 62790, loss = 0.42, batch loss = 0.25 (50.5 examples/sec; 0.159 sec/batch; 11h:52m:44s remains)
INFO - root - 2017-12-01 05:20:50.786713: step 62800, loss = 0.42, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 11h:48m:45s remains)
INFO - root - 2017-12-01 05:20:52.437021: step 62810, loss = 0.43, batch loss = 0.27 (52.5 examples/sec; 0.153 sec/batch; 11h:25m:29s remains)
INFO - root - 2017-12-01 05:20:53.998330: step 62820, loss = 0.38, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 11h:48m:52s remains)
INFO - root - 2017-12-01 05:20:55.555899: step 62830, loss = 0.47, batch loss = 0.31 (50.5 examples/sec; 0.158 sec/batch; 11h:52m:09s remains)
INFO - root - 2017-12-01 05:20:57.138605: step 62840, loss = 0.58, batch loss = 0.42 (51.2 examples/sec; 0.156 sec/batch; 11h:41m:54s remains)
INFO - root - 2017-12-01 05:20:58.726574: step 62850, loss = 0.37, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 11h:46m:11s remains)
INFO - root - 2017-12-01 05:21:00.296518: step 62860, loss = 0.43, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 11h:50m:57s remains)
INFO - root - 2017-12-01 05:21:01.854980: step 62870, loss = 0.41, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 11h:37m:17s remains)
INFO - root - 2017-12-01 05:21:03.421320: step 62880, loss = 0.42, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 11h:41m:43s remains)
INFO - root - 2017-12-01 05:21:04.971415: step 62890, loss = 0.40, batch loss = 0.24 (53.4 examples/sec; 0.150 sec/batch; 11h:13m:09s remains)
INFO - root - 2017-12-01 05:21:06.535385: step 62900, loss = 0.35, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 11h:35m:23s remains)
INFO - root - 2017-12-01 05:21:08.164355: step 62910, loss = 0.40, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 11h:35m:23s remains)
INFO - root - 2017-12-01 05:21:09.738321: step 62920, loss = 0.35, batch loss = 0.19 (49.6 examples/sec; 0.161 sec/batch; 12h:04m:12s remains)
INFO - root - 2017-12-01 05:21:11.321328: step 62930, loss = 0.48, batch loss = 0.32 (50.5 examples/sec; 0.158 sec/batch; 11h:51m:36s remains)
INFO - root - 2017-12-01 05:21:12.871452: step 62940, loss = 0.36, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 11h:45m:07s remains)
INFO - root - 2017-12-01 05:21:14.427796: step 62950, loss = 0.38, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 11h:45m:34s remains)
INFO - root - 2017-12-01 05:21:15.990337: step 62960, loss = 0.43, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 11h:49m:26s remains)
INFO - root - 2017-12-01 05:21:17.598560: step 62970, loss = 0.54, batch loss = 0.37 (52.9 examples/sec; 0.151 sec/batch; 11h:19m:42s remains)
INFO - root - 2017-12-01 05:21:19.178046: step 62980, loss = 0.49, batch loss = 0.33 (51.0 examples/sec; 0.157 sec/batch; 11h:45m:14s remains)
INFO - root - 2017-12-01 05:21:20.737647: step 62990, loss = 0.50, batch loss = 0.34 (51.9 examples/sec; 0.154 sec/batch; 11h:32m:09s remains)
INFO - root - 2017-12-01 05:21:22.309200: step 63000, loss = 0.35, batch loss = 0.19 (53.3 examples/sec; 0.150 sec/batch; 11h:13m:59s remains)
INFO - root - 2017-12-01 05:21:23.939103: step 63010, loss = 0.33, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 11h:52m:58s remains)
INFO - root - 2017-12-01 05:21:25.502828: step 63020, loss = 0.33, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 11h:54m:14s remains)
INFO - root - 2017-12-01 05:21:27.059946: step 63030, loss = 0.39, batch loss = 0.23 (52.1 examples/sec; 0.153 sec/batch; 11h:29m:03s remains)
INFO - root - 2017-12-01 05:21:28.607171: step 63040, loss = 0.32, batch loss = 0.16 (52.4 examples/sec; 0.153 sec/batch; 11h:25m:36s remains)
INFO - root - 2017-12-01 05:21:30.178514: step 63050, loss = 0.36, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 11h:54m:11s remains)
INFO - root - 2017-12-01 05:21:31.773693: step 63060, loss = 0.41, batch loss = 0.24 (47.9 examples/sec; 0.167 sec/batch; 12h:29m:20s remains)
INFO - root - 2017-12-01 05:21:33.338628: step 63070, loss = 0.38, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 11h:34m:48s remains)
INFO - root - 2017-12-01 05:21:34.918979: step 63080, loss = 0.37, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 11h:51m:04s remains)
INFO - root - 2017-12-01 05:21:36.475725: step 63090, loss = 0.44, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 11h:31m:20s remains)
INFO - root - 2017-12-01 05:21:38.043365: step 63100, loss = 0.41, batch loss = 0.25 (51.1 examples/sec; 0.156 sec/batch; 11h:42m:39s remains)
INFO - root - 2017-12-01 05:21:39.692775: step 63110, loss = 0.39, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 11h:42m:00s remains)
INFO - root - 2017-12-01 05:21:41.250544: step 63120, loss = 0.42, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 11h:46m:03s remains)
INFO - root - 2017-12-01 05:21:42.827689: step 63130, loss = 0.40, batch loss = 0.23 (52.5 examples/sec; 0.152 sec/batch; 11h:23m:35s remains)
INFO - root - 2017-12-01 05:21:44.395753: step 63140, loss = 0.38, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 11h:31m:14s remains)
INFO - root - 2017-12-01 05:21:45.957724: step 63150, loss = 0.37, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 11h:34m:33s remains)
INFO - root - 2017-12-01 05:21:47.536973: step 63160, loss = 0.35, batch loss = 0.19 (49.6 examples/sec; 0.161 sec/batch; 12h:03m:39s remains)
INFO - root - 2017-12-01 05:21:49.087101: step 63170, loss = 0.33, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 11h:43m:22s remains)
INFO - root - 2017-12-01 05:21:50.648860: step 63180, loss = 0.42, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 11h:47m:39s remains)
INFO - root - 2017-12-01 05:21:52.212773: step 63190, loss = 0.39, batch loss = 0.23 (53.9 examples/sec; 0.148 sec/batch; 11h:06m:28s remains)
INFO - root - 2017-12-01 05:21:53.773800: step 63200, loss = 0.38, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 11h:38m:46s remains)
INFO - root - 2017-12-01 05:21:55.381128: step 63210, loss = 0.43, batch loss = 0.27 (49.5 examples/sec; 0.162 sec/batch; 12h:04m:54s remains)
INFO - root - 2017-12-01 05:21:56.949343: step 63220, loss = 0.46, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 11h:48m:49s remains)
INFO - root - 2017-12-01 05:21:58.506152: step 63230, loss = 0.51, batch loss = 0.35 (51.2 examples/sec; 0.156 sec/batch; 11h:41m:01s remains)
INFO - root - 2017-12-01 05:22:00.085873: step 63240, loss = 0.51, batch loss = 0.35 (50.3 examples/sec; 0.159 sec/batch; 11h:53m:52s remains)
INFO - root - 2017-12-01 05:22:01.660043: step 63250, loss = 0.50, batch loss = 0.34 (50.5 examples/sec; 0.158 sec/batch; 11h:50m:26s remains)
INFO - root - 2017-12-01 05:22:03.218160: step 63260, loss = 0.35, batch loss = 0.19 (50.1 examples/sec; 0.160 sec/batch; 11h:56m:10s remains)
INFO - root - 2017-12-01 05:22:04.770046: step 63270, loss = 0.44, batch loss = 0.27 (49.7 examples/sec; 0.161 sec/batch; 12h:02m:34s remains)
INFO - root - 2017-12-01 05:22:06.323516: step 63280, loss = 0.36, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 11h:24m:31s remains)
INFO - root - 2017-12-01 05:22:07.916490: step 63290, loss = 0.37, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 11h:29m:14s remains)
INFO - root - 2017-12-01 05:22:09.477864: step 63300, loss = 0.39, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 11h:44m:53s remains)
INFO - root - 2017-12-01 05:22:11.108538: step 63310, loss = 0.36, batch loss = 0.20 (53.0 examples/sec; 0.151 sec/batch; 11h:17m:42s remains)
INFO - root - 2017-12-01 05:22:12.685961: step 63320, loss = 0.40, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 11h:34m:34s remains)
INFO - root - 2017-12-01 05:22:14.246199: step 63330, loss = 0.42, batch loss = 0.25 (48.6 examples/sec; 0.165 sec/batch; 12h:18m:32s remains)
INFO - root - 2017-12-01 05:22:15.821562: step 63340, loss = 0.37, batch loss = 0.20 (48.0 examples/sec; 0.167 sec/batch; 12h:27m:32s remains)
INFO - root - 2017-12-01 05:22:17.374130: step 63350, loss = 0.36, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 11h:36m:48s remains)
INFO - root - 2017-12-01 05:22:18.932331: step 63360, loss = 0.36, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 11h:26m:24s remains)
INFO - root - 2017-12-01 05:22:20.508822: step 63370, loss = 0.44, batch loss = 0.27 (50.1 examples/sec; 0.160 sec/batch; 11h:56m:09s remains)
INFO - root - 2017-12-01 05:22:22.066526: step 63380, loss = 0.36, batch loss = 0.19 (49.6 examples/sec; 0.161 sec/batch; 12h:03m:07s remains)
INFO - root - 2017-12-01 05:22:23.627001: step 63390, loss = 0.41, batch loss = 0.25 (49.7 examples/sec; 0.161 sec/batch; 12h:01m:29s remains)
INFO - root - 2017-12-01 05:22:25.189496: step 63400, loss = 0.41, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 11h:35m:15s remains)
INFO - root - 2017-12-01 05:22:26.866677: step 63410, loss = 0.45, batch loss = 0.29 (52.9 examples/sec; 0.151 sec/batch; 11h:17m:55s remains)
INFO - root - 2017-12-01 05:22:28.442795: step 63420, loss = 0.40, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 11h:38m:26s remains)
INFO - root - 2017-12-01 05:22:30.008364: step 63430, loss = 0.41, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 11h:37m:36s remains)
INFO - root - 2017-12-01 05:22:31.563348: step 63440, loss = 0.40, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 11h:49m:22s remains)
INFO - root - 2017-12-01 05:22:33.138341: step 63450, loss = 0.36, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 12h:05m:08s remains)
INFO - root - 2017-12-01 05:22:34.711352: step 63460, loss = 0.34, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 11h:45m:19s remains)
INFO - root - 2017-12-01 05:22:36.260320: step 63470, loss = 0.41, batch loss = 0.25 (53.1 examples/sec; 0.151 sec/batch; 11h:15m:26s remains)
INFO - root - 2017-12-01 05:22:37.820741: step 63480, loss = 0.34, batch loss = 0.17 (51.8 examples/sec; 0.154 sec/batch; 11h:32m:23s remains)
INFO - root - 2017-12-01 05:22:39.376059: step 63490, loss = 0.39, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 11h:43m:20s remains)
INFO - root - 2017-12-01 05:22:40.969820: step 63500, loss = 0.34, batch loss = 0.18 (49.7 examples/sec; 0.161 sec/batch; 12h:01m:22s remains)
INFO - root - 2017-12-01 05:22:42.583769: step 63510, loss = 0.38, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 11h:25m:23s remains)
INFO - root - 2017-12-01 05:22:44.147519: step 63520, loss = 0.52, batch loss = 0.36 (51.0 examples/sec; 0.157 sec/batch; 11h:42m:37s remains)
INFO - root - 2017-12-01 05:22:45.718521: step 63530, loss = 0.52, batch loss = 0.36 (51.4 examples/sec; 0.155 sec/batch; 11h:37m:04s remains)
INFO - root - 2017-12-01 05:22:47.274047: step 63540, loss = 0.32, batch loss = 0.16 (51.0 examples/sec; 0.157 sec/batch; 11h:42m:50s remains)
INFO - root - 2017-12-01 05:22:48.845281: step 63550, loss = 0.41, batch loss = 0.24 (50.2 examples/sec; 0.159 sec/batch; 11h:54m:06s remains)
INFO - root - 2017-12-01 05:22:50.417735: step 63560, loss = 0.43, batch loss = 0.27 (50.8 examples/sec; 0.157 sec/batch; 11h:45m:26s remains)
INFO - root - 2017-12-01 05:22:51.981845: step 63570, loss = 0.49, batch loss = 0.33 (50.3 examples/sec; 0.159 sec/batch; 11h:52m:10s remains)
INFO - root - 2017-12-01 05:22:53.550062: step 63580, loss = 0.42, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 11h:35m:00s remains)
INFO - root - 2017-12-01 05:22:55.102821: step 63590, loss = 0.38, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 11h:26m:16s remains)
INFO - root - 2017-12-01 05:22:56.666085: step 63600, loss = 0.37, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 11h:44m:34s remains)
INFO - root - 2017-12-01 05:22:58.347753: step 63610, loss = 0.39, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 11h:30m:18s remains)
INFO - root - 2017-12-01 05:22:59.915875: step 63620, loss = 0.35, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 11h:31m:39s remains)
INFO - root - 2017-12-01 05:23:01.493120: step 63630, loss = 0.34, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 11h:40m:51s remains)
INFO - root - 2017-12-01 05:23:03.062250: step 63640, loss = 0.60, batch loss = 0.44 (50.7 examples/sec; 0.158 sec/batch; 11h:46m:48s remains)
INFO - root - 2017-12-01 05:23:04.628378: step 63650, loss = 0.44, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 11h:38m:27s remains)
INFO - root - 2017-12-01 05:23:06.208203: step 63660, loss = 0.37, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 11h:31m:10s remains)
INFO - root - 2017-12-01 05:23:07.778518: step 63670, loss = 0.43, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 11h:37m:58s remains)
INFO - root - 2017-12-01 05:23:09.353990: step 63680, loss = 0.49, batch loss = 0.33 (48.8 examples/sec; 0.164 sec/batch; 12h:14m:10s remains)
INFO - root - 2017-12-01 05:23:10.929382: step 63690, loss = 0.35, batch loss = 0.18 (52.1 examples/sec; 0.154 sec/batch; 11h:28m:12s remains)
INFO - root - 2017-12-01 05:23:12.510677: step 63700, loss = 0.33, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 11h:29m:58s remains)
INFO - root - 2017-12-01 05:23:14.133048: step 63710, loss = 0.54, batch loss = 0.38 (48.8 examples/sec; 0.164 sec/batch; 12h:14m:36s remains)
INFO - root - 2017-12-01 05:23:15.691013: step 63720, loss = 0.39, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 11h:46m:34s remains)
INFO - root - 2017-12-01 05:23:17.234555: step 63730, loss = 0.39, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 11h:28m:18s remains)
INFO - root - 2017-12-01 05:23:18.801286: step 63740, loss = 0.41, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 11h:47m:17s remains)
INFO - root - 2017-12-01 05:23:20.375045: step 63750, loss = 0.40, batch loss = 0.24 (49.8 examples/sec; 0.161 sec/batch; 11h:59m:11s remains)
INFO - root - 2017-12-01 05:23:21.921694: step 63760, loss = 0.33, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 11h:51m:39s remains)
INFO - root - 2017-12-01 05:23:23.503298: step 63770, loss = 0.44, batch loss = 0.27 (49.2 examples/sec; 0.163 sec/batch; 12h:07m:49s remains)
INFO - root - 2017-12-01 05:23:25.064738: step 63780, loss = 0.42, batch loss = 0.26 (49.9 examples/sec; 0.160 sec/batch; 11h:58m:11s remains)
INFO - root - 2017-12-01 05:23:26.673537: step 63790, loss = 0.32, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 11h:35m:37s remains)
INFO - root - 2017-12-01 05:23:28.249836: step 63800, loss = 0.34, batch loss = 0.18 (50.1 examples/sec; 0.160 sec/batch; 11h:55m:31s remains)
INFO - root - 2017-12-01 05:23:29.858975: step 63810, loss = 0.38, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 11h:52m:17s remains)
INFO - root - 2017-12-01 05:23:31.414809: step 63820, loss = 0.41, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 11h:32m:54s remains)
INFO - root - 2017-12-01 05:23:32.978879: step 63830, loss = 0.36, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 11h:42m:03s remains)
INFO - root - 2017-12-01 05:23:34.520649: step 63840, loss = 0.39, batch loss = 0.23 (50.4 examples/sec; 0.159 sec/batch; 11h:51m:21s remains)
INFO - root - 2017-12-01 05:23:36.076314: step 63850, loss = 0.40, batch loss = 0.23 (48.7 examples/sec; 0.164 sec/batch; 12h:16m:10s remains)
INFO - root - 2017-12-01 05:23:37.637179: step 63860, loss = 0.46, batch loss = 0.30 (51.0 examples/sec; 0.157 sec/batch; 11h:41m:46s remains)
INFO - root - 2017-12-01 05:23:39.201548: step 63870, loss = 0.32, batch loss = 0.16 (51.8 examples/sec; 0.155 sec/batch; 11h:32m:02s remains)
INFO - root - 2017-12-01 05:23:40.762872: step 63880, loss = 0.43, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 11h:51m:59s remains)
INFO - root - 2017-12-01 05:23:42.320767: step 63890, loss = 0.37, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 11h:37m:20s remains)
INFO - root - 2017-12-01 05:23:43.888780: step 63900, loss = 0.36, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 11h:52m:40s remains)
INFO - root - 2017-12-01 05:23:45.503948: step 63910, loss = 0.43, batch loss = 0.27 (50.0 examples/sec; 0.160 sec/batch; 11h:55m:36s remains)
INFO - root - 2017-12-01 05:23:47.064764: step 63920, loss = 0.45, batch loss = 0.29 (50.2 examples/sec; 0.159 sec/batch; 11h:53m:05s remains)
INFO - root - 2017-12-01 05:23:48.627247: step 63930, loss = 0.38, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 11h:37m:14s remains)
INFO - root - 2017-12-01 05:23:50.187667: step 63940, loss = 0.36, batch loss = 0.19 (53.0 examples/sec; 0.151 sec/batch; 11h:15m:47s remains)
INFO - root - 2017-12-01 05:23:51.741189: step 63950, loss = 0.47, batch loss = 0.31 (52.4 examples/sec; 0.153 sec/batch; 11h:23m:51s remains)
INFO - root - 2017-12-01 05:23:53.341771: step 63960, loss = 0.46, batch loss = 0.30 (51.0 examples/sec; 0.157 sec/batch; 11h:41m:34s remains)
INFO - root - 2017-12-01 05:23:54.894021: step 63970, loss = 0.36, batch loss = 0.20 (52.8 examples/sec; 0.151 sec/batch; 11h:17m:50s remains)
INFO - root - 2017-12-01 05:23:56.452203: step 63980, loss = 0.40, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 11h:38m:45s remains)
INFO - root - 2017-12-01 05:23:58.022635: step 63990, loss = 0.40, batch loss = 0.23 (51.1 examples/sec; 0.156 sec/batch; 11h:39m:59s remains)
INFO - root - 2017-12-01 05:23:59.586302: step 64000, loss = 0.42, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 11h:34m:19s remains)
INFO - root - 2017-12-01 05:24:01.192228: step 64010, loss = 0.40, batch loss = 0.24 (49.8 examples/sec; 0.160 sec/batch; 11h:58m:10s remains)
INFO - root - 2017-12-01 05:24:02.762827: step 64020, loss = 0.55, batch loss = 0.39 (52.4 examples/sec; 0.153 sec/batch; 11h:23m:36s remains)
INFO - root - 2017-12-01 05:24:04.347336: step 64030, loss = 0.41, batch loss = 0.25 (47.9 examples/sec; 0.167 sec/batch; 12h:27m:27s remains)
INFO - root - 2017-12-01 05:24:05.931323: step 64040, loss = 0.39, batch loss = 0.23 (49.3 examples/sec; 0.162 sec/batch; 12h:06m:15s remains)
INFO - root - 2017-12-01 05:24:07.495819: step 64050, loss = 0.36, batch loss = 0.19 (52.1 examples/sec; 0.154 sec/batch; 11h:27m:26s remains)
INFO - root - 2017-12-01 05:24:09.054863: step 64060, loss = 0.55, batch loss = 0.39 (52.9 examples/sec; 0.151 sec/batch; 11h:16m:37s remains)
INFO - root - 2017-12-01 05:24:10.646546: step 64070, loss = 0.38, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 11h:49m:41s remains)
INFO - root - 2017-12-01 05:24:12.233637: step 64080, loss = 0.44, batch loss = 0.28 (45.4 examples/sec; 0.176 sec/batch; 13h:08m:21s remains)
INFO - root - 2017-12-01 05:24:13.798457: step 64090, loss = 0.45, batch loss = 0.28 (53.4 examples/sec; 0.150 sec/batch; 11h:10m:27s remains)
INFO - root - 2017-12-01 05:24:15.358349: step 64100, loss = 0.41, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 11h:35m:15s remains)
INFO - root - 2017-12-01 05:24:17.008187: step 64110, loss = 0.33, batch loss = 0.17 (49.0 examples/sec; 0.163 sec/batch; 12h:10m:32s remains)
INFO - root - 2017-12-01 05:24:18.596302: step 64120, loss = 0.39, batch loss = 0.23 (52.8 examples/sec; 0.152 sec/batch; 11h:18m:11s remains)
INFO - root - 2017-12-01 05:24:20.160369: step 64130, loss = 0.45, batch loss = 0.29 (50.4 examples/sec; 0.159 sec/batch; 11h:49m:29s remains)
INFO - root - 2017-12-01 05:24:21.714827: step 64140, loss = 0.35, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 11h:38m:39s remains)
INFO - root - 2017-12-01 05:24:23.273538: step 64150, loss = 0.37, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 11h:25m:00s remains)
INFO - root - 2017-12-01 05:24:24.846945: step 64160, loss = 0.32, batch loss = 0.16 (51.1 examples/sec; 0.156 sec/batch; 11h:39m:33s remains)
INFO - root - 2017-12-01 05:24:26.421613: step 64170, loss = 0.34, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 11h:32m:13s remains)
INFO - root - 2017-12-01 05:24:28.006365: step 64180, loss = 0.49, batch loss = 0.33 (51.8 examples/sec; 0.154 sec/batch; 11h:30m:06s remains)
INFO - root - 2017-12-01 05:24:29.569843: step 64190, loss = 0.45, batch loss = 0.29 (50.2 examples/sec; 0.159 sec/batch; 11h:51m:58s remains)
INFO - root - 2017-12-01 05:24:31.127898: step 64200, loss = 0.40, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 11h:38m:22s remains)
INFO - root - 2017-12-01 05:24:32.759812: step 64210, loss = 0.36, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 11h:38m:01s remains)
INFO - root - 2017-12-01 05:24:34.320966: step 64220, loss = 0.31, batch loss = 0.15 (50.8 examples/sec; 0.158 sec/batch; 11h:44m:35s remains)
INFO - root - 2017-12-01 05:24:35.898613: step 64230, loss = 0.41, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 11h:30m:29s remains)
INFO - root - 2017-12-01 05:24:37.483990: step 64240, loss = 0.38, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 11h:27m:31s remains)
INFO - root - 2017-12-01 05:24:39.053859: step 64250, loss = 0.37, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 11h:47m:33s remains)
INFO - root - 2017-12-01 05:24:40.606497: step 64260, loss = 0.36, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 11h:48m:13s remains)
INFO - root - 2017-12-01 05:24:42.172986: step 64270, loss = 0.47, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 11h:42m:12s remains)
INFO - root - 2017-12-01 05:24:43.767989: step 64280, loss = 0.39, batch loss = 0.23 (52.1 examples/sec; 0.153 sec/batch; 11h:26m:09s remains)
INFO - root - 2017-12-01 05:24:45.343607: step 64290, loss = 0.39, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 11h:45m:52s remains)
INFO - root - 2017-12-01 05:24:46.900427: step 64300, loss = 0.36, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 11h:38m:24s remains)
INFO - root - 2017-12-01 05:24:48.571836: step 64310, loss = 0.48, batch loss = 0.32 (51.2 examples/sec; 0.156 sec/batch; 11h:39m:02s remains)
INFO - root - 2017-12-01 05:24:50.145059: step 64320, loss = 0.44, batch loss = 0.28 (51.1 examples/sec; 0.157 sec/batch; 11h:39m:33s remains)
INFO - root - 2017-12-01 05:24:51.699031: step 64330, loss = 0.43, batch loss = 0.27 (51.8 examples/sec; 0.155 sec/batch; 11h:30m:41s remains)
INFO - root - 2017-12-01 05:24:53.279618: step 64340, loss = 0.36, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 11h:49m:42s remains)
INFO - root - 2017-12-01 05:24:54.864091: step 64350, loss = 0.36, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 11h:53m:25s remains)
INFO - root - 2017-12-01 05:24:56.447718: step 64360, loss = 0.36, batch loss = 0.20 (49.3 examples/sec; 0.162 sec/batch; 12h:05m:32s remains)
INFO - root - 2017-12-01 05:24:58.017931: step 64370, loss = 0.35, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 11h:40m:35s remains)
INFO - root - 2017-12-01 05:24:59.616366: step 64380, loss = 0.31, batch loss = 0.15 (50.1 examples/sec; 0.160 sec/batch; 11h:52m:51s remains)
INFO - root - 2017-12-01 05:25:01.179023: step 64390, loss = 0.38, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 11h:51m:41s remains)
INFO - root - 2017-12-01 05:25:02.731850: step 64400, loss = 0.46, batch loss = 0.29 (49.8 examples/sec; 0.160 sec/batch; 11h:57m:07s remains)
INFO - root - 2017-12-01 05:25:04.393135: step 64410, loss = 0.43, batch loss = 0.27 (49.2 examples/sec; 0.163 sec/batch; 12h:06m:13s remains)
INFO - root - 2017-12-01 05:25:05.955559: step 64420, loss = 0.55, batch loss = 0.39 (49.3 examples/sec; 0.162 sec/batch; 12h:05m:36s remains)
INFO - root - 2017-12-01 05:25:07.518576: step 64430, loss = 0.34, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 11h:28m:51s remains)
INFO - root - 2017-12-01 05:25:09.099718: step 64440, loss = 0.43, batch loss = 0.26 (52.1 examples/sec; 0.154 sec/batch; 11h:26m:00s remains)
INFO - root - 2017-12-01 05:25:10.674936: step 64450, loss = 0.35, batch loss = 0.19 (50.2 examples/sec; 0.159 sec/batch; 11h:51m:41s remains)
INFO - root - 2017-12-01 05:25:12.247206: step 64460, loss = 0.44, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 11h:41m:57s remains)
INFO - root - 2017-12-01 05:25:13.789421: step 64470, loss = 0.56, batch loss = 0.40 (53.4 examples/sec; 0.150 sec/batch; 11h:09m:48s remains)
INFO - root - 2017-12-01 05:25:15.377405: step 64480, loss = 0.39, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 11h:27m:36s remains)
INFO - root - 2017-12-01 05:25:16.943216: step 64490, loss = 0.34, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 11h:26m:50s remains)
INFO - root - 2017-12-01 05:25:18.502022: step 64500, loss = 0.42, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 11h:32m:28s remains)
INFO - root - 2017-12-01 05:25:20.166162: step 64510, loss = 0.45, batch loss = 0.29 (51.7 examples/sec; 0.155 sec/batch; 11h:31m:20s remains)
INFO - root - 2017-12-01 05:25:21.750780: step 64520, loss = 0.41, batch loss = 0.25 (49.5 examples/sec; 0.162 sec/batch; 12h:01m:51s remains)
INFO - root - 2017-12-01 05:25:23.302618: step 64530, loss = 0.37, batch loss = 0.21 (53.1 examples/sec; 0.151 sec/batch; 11h:13m:23s remains)
INFO - root - 2017-12-01 05:25:24.865094: step 64540, loss = 0.50, batch loss = 0.34 (53.4 examples/sec; 0.150 sec/batch; 11h:09m:00s remains)
INFO - root - 2017-12-01 05:25:26.444673: step 64550, loss = 0.42, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 11h:28m:04s remains)
INFO - root - 2017-12-01 05:25:27.995217: step 64560, loss = 0.46, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 11h:37m:48s remains)
INFO - root - 2017-12-01 05:25:29.559380: step 64570, loss = 0.45, batch loss = 0.29 (49.7 examples/sec; 0.161 sec/batch; 11h:58m:31s remains)
INFO - root - 2017-12-01 05:25:31.110844: step 64580, loss = 0.43, batch loss = 0.27 (49.4 examples/sec; 0.162 sec/batch; 12h:03m:33s remains)
INFO - root - 2017-12-01 05:25:32.669264: step 64590, loss = 0.39, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 11h:21m:39s remains)
INFO - root - 2017-12-01 05:25:34.241293: step 64600, loss = 0.48, batch loss = 0.32 (52.3 examples/sec; 0.153 sec/batch; 11h:22m:27s remains)
INFO - root - 2017-12-01 05:25:35.867087: step 64610, loss = 0.36, batch loss = 0.20 (49.8 examples/sec; 0.161 sec/batch; 11h:57m:30s remains)
INFO - root - 2017-12-01 05:25:37.441958: step 64620, loss = 0.35, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 11h:33m:29s remains)
INFO - root - 2017-12-01 05:25:39.017709: step 64630, loss = 0.37, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 11h:23m:11s remains)
INFO - root - 2017-12-01 05:25:40.581695: step 64640, loss = 0.46, batch loss = 0.30 (50.4 examples/sec; 0.159 sec/batch; 11h:47m:58s remains)
INFO - root - 2017-12-01 05:25:42.145510: step 64650, loss = 0.43, batch loss = 0.27 (50.0 examples/sec; 0.160 sec/batch; 11h:53m:35s remains)
INFO - root - 2017-12-01 05:25:43.710952: step 64660, loss = 0.36, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 11h:30m:58s remains)
INFO - root - 2017-12-01 05:25:45.298532: step 64670, loss = 0.35, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 11h:26m:37s remains)
INFO - root - 2017-12-01 05:25:46.858258: step 64680, loss = 0.34, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 11h:32m:49s remains)
INFO - root - 2017-12-01 05:25:48.429747: step 64690, loss = 0.36, batch loss = 0.20 (47.3 examples/sec; 0.169 sec/batch; 12h:34m:49s remains)
INFO - root - 2017-12-01 05:25:49.994958: step 64700, loss = 0.49, batch loss = 0.33 (52.9 examples/sec; 0.151 sec/batch; 11h:15m:28s remains)
INFO - root - 2017-12-01 05:25:51.635798: step 64710, loss = 0.41, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 11h:38m:58s remains)
INFO - root - 2017-12-01 05:25:53.189844: step 64720, loss = 0.43, batch loss = 0.27 (52.3 examples/sec; 0.153 sec/batch; 11h:22m:20s remains)
INFO - root - 2017-12-01 05:25:54.739526: step 64730, loss = 0.44, batch loss = 0.28 (52.8 examples/sec; 0.152 sec/batch; 11h:16m:48s remains)
INFO - root - 2017-12-01 05:25:56.326472: step 64740, loss = 0.32, batch loss = 0.16 (50.6 examples/sec; 0.158 sec/batch; 11h:45m:02s remains)
INFO - root - 2017-12-01 05:25:57.901923: step 64750, loss = 0.59, batch loss = 0.43 (51.7 examples/sec; 0.155 sec/batch; 11h:30m:43s remains)
INFO - root - 2017-12-01 05:25:59.454808: step 64760, loss = 0.30, batch loss = 0.14 (50.8 examples/sec; 0.158 sec/batch; 11h:43m:00s remains)
INFO - root - 2017-12-01 05:26:01.028846: step 64770, loss = 0.39, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 11h:34m:17s remains)
INFO - root - 2017-12-01 05:26:02.601965: step 64780, loss = 0.38, batch loss = 0.22 (52.1 examples/sec; 0.153 sec/batch; 11h:24m:50s remains)
INFO - root - 2017-12-01 05:26:04.165626: step 64790, loss = 0.37, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 11h:39m:20s remains)
INFO - root - 2017-12-01 05:26:05.723852: step 64800, loss = 0.38, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 11h:48m:56s remains)
INFO - root - 2017-12-01 05:26:07.343558: step 64810, loss = 0.34, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 11h:32m:17s remains)
INFO - root - 2017-12-01 05:26:08.902479: step 64820, loss = 0.37, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 11h:28m:03s remains)
INFO - root - 2017-12-01 05:26:10.455333: step 64830, loss = 0.40, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 11h:27m:43s remains)
INFO - root - 2017-12-01 05:26:12.019045: step 64840, loss = 0.37, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 11h:39m:15s remains)
INFO - root - 2017-12-01 05:26:13.587729: step 64850, loss = 0.43, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 11h:31m:51s remains)
INFO - root - 2017-12-01 05:26:15.140902: step 64860, loss = 0.49, batch loss = 0.33 (51.7 examples/sec; 0.155 sec/batch; 11h:30m:32s remains)
INFO - root - 2017-12-01 05:26:16.726270: step 64870, loss = 0.38, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 11h:44m:00s remains)
INFO - root - 2017-12-01 05:26:18.292652: step 64880, loss = 0.40, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 11h:28m:54s remains)
INFO - root - 2017-12-01 05:26:19.851084: step 64890, loss = 0.38, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 11h:35m:38s remains)
INFO - root - 2017-12-01 05:26:21.404861: step 64900, loss = 0.47, batch loss = 0.31 (51.8 examples/sec; 0.154 sec/batch; 11h:28m:10s remains)
INFO - root - 2017-12-01 05:26:23.023278: step 64910, loss = 0.37, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 11h:27m:00s remains)
INFO - root - 2017-12-01 05:26:24.598183: step 64920, loss = 0.38, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 11h:45m:36s remains)
INFO - root - 2017-12-01 05:26:26.174938: step 64930, loss = 0.41, batch loss = 0.25 (49.4 examples/sec; 0.162 sec/batch; 12h:02m:06s remains)
INFO - root - 2017-12-01 05:26:27.747225: step 64940, loss = 0.32, batch loss = 0.16 (50.6 examples/sec; 0.158 sec/batch; 11h:45m:04s remains)
INFO - root - 2017-12-01 05:26:29.331759: step 64950, loss = 0.33, batch loss = 0.17 (50.1 examples/sec; 0.160 sec/batch; 11h:52m:39s remains)
INFO - root - 2017-12-01 05:26:30.884835: step 64960, loss = 0.36, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 11h:45m:26s remains)
INFO - root - 2017-12-01 05:26:32.439400: step 64970, loss = 0.36, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 11h:29m:55s remains)
INFO - root - 2017-12-01 05:26:34.002633: step 64980, loss = 0.34, batch loss = 0.18 (49.3 examples/sec; 0.162 sec/batch; 12h:03m:18s remains)
INFO - root - 2017-12-01 05:26:35.581806: step 64990, loss = 0.45, batch loss = 0.28 (52.0 examples/sec; 0.154 sec/batch; 11h:25m:50s remains)
INFO - root - 2017-12-01 05:26:37.138724: step 65000, loss = 0.39, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 11h:16m:43s remains)
INFO - root - 2017-12-01 05:26:38.751548: step 65010, loss = 0.36, batch loss = 0.20 (53.3 examples/sec; 0.150 sec/batch; 11h:09m:02s remains)
INFO - root - 2017-12-01 05:26:40.327109: step 65020, loss = 0.40, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 11h:17m:54s remains)
INFO - root - 2017-12-01 05:26:41.902588: step 65030, loss = 0.37, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 11h:26m:41s remains)
INFO - root - 2017-12-01 05:26:43.490809: step 65040, loss = 0.38, batch loss = 0.22 (49.8 examples/sec; 0.161 sec/batch; 11h:55m:42s remains)
INFO - root - 2017-12-01 05:26:45.064002: step 65050, loss = 0.35, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 11h:37m:46s remains)
INFO - root - 2017-12-01 05:26:46.630173: step 65060, loss = 0.37, batch loss = 0.21 (52.8 examples/sec; 0.152 sec/batch; 11h:15m:27s remains)
INFO - root - 2017-12-01 05:26:48.193762: step 65070, loss = 0.35, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 11h:22m:59s remains)
INFO - root - 2017-12-01 05:26:49.767203: step 65080, loss = 0.35, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 11h:33m:23s remains)
INFO - root - 2017-12-01 05:26:51.327601: step 65090, loss = 0.37, batch loss = 0.21 (49.5 examples/sec; 0.162 sec/batch; 11h:59m:47s remains)
INFO - root - 2017-12-01 05:26:52.893984: step 65100, loss = 0.38, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 11h:44m:25s remains)
INFO - root - 2017-12-01 05:26:54.540966: step 65110, loss = 0.43, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 11h:38m:42s remains)
INFO - root - 2017-12-01 05:26:56.075398: step 65120, loss = 0.40, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 11h:33m:30s remains)
INFO - root - 2017-12-01 05:26:57.634817: step 65130, loss = 0.43, batch loss = 0.27 (49.2 examples/sec; 0.163 sec/batch; 12h:04m:10s remains)
INFO - root - 2017-12-01 05:26:59.231523: step 65140, loss = 0.39, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 11h:30m:08s remains)
INFO - root - 2017-12-01 05:27:00.803363: step 65150, loss = 0.39, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 11h:44m:32s remains)
INFO - root - 2017-12-01 05:27:02.375442: step 65160, loss = 0.37, batch loss = 0.21 (49.1 examples/sec; 0.163 sec/batch; 12h:05m:28s remains)
INFO - root - 2017-12-01 05:27:03.937211: step 65170, loss = 0.42, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 11h:30m:39s remains)
INFO - root - 2017-12-01 05:27:05.503871: step 65180, loss = 0.40, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 11h:47m:51s remains)
INFO - root - 2017-12-01 05:27:07.066613: step 65190, loss = 0.38, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 11h:42m:54s remains)
INFO - root - 2017-12-01 05:27:08.629137: step 65200, loss = 0.33, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 11h:34m:02s remains)
INFO - root - 2017-12-01 05:27:10.284166: step 65210, loss = 0.49, batch loss = 0.33 (51.5 examples/sec; 0.155 sec/batch; 11h:32m:15s remains)
INFO - root - 2017-12-01 05:27:11.840650: step 65220, loss = 0.34, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 11h:33m:47s remains)
INFO - root - 2017-12-01 05:27:13.428779: step 65230, loss = 0.39, batch loss = 0.23 (48.6 examples/sec; 0.165 sec/batch; 12h:13m:47s remains)
INFO - root - 2017-12-01 05:27:15.113938: step 65240, loss = 0.44, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 11h:34m:52s remains)
INFO - root - 2017-12-01 05:27:16.685068: step 65250, loss = 0.38, batch loss = 0.22 (52.4 examples/sec; 0.153 sec/batch; 11h:20m:04s remains)
INFO - root - 2017-12-01 05:27:18.265968: step 65260, loss = 0.38, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 11h:33m:47s remains)
INFO - root - 2017-12-01 05:27:19.828356: step 65270, loss = 0.41, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 11h:27m:48s remains)
INFO - root - 2017-12-01 05:27:21.394388: step 65280, loss = 0.43, batch loss = 0.27 (50.0 examples/sec; 0.160 sec/batch; 11h:52m:37s remains)
INFO - root - 2017-12-01 05:27:22.955336: step 65290, loss = 0.36, batch loss = 0.20 (49.7 examples/sec; 0.161 sec/batch; 11h:57m:17s remains)
INFO - root - 2017-12-01 05:27:24.509935: step 65300, loss = 0.39, batch loss = 0.23 (53.0 examples/sec; 0.151 sec/batch; 11h:12m:33s remains)
INFO - root - 2017-12-01 05:27:26.169509: step 65310, loss = 0.33, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 11h:37m:04s remains)
INFO - root - 2017-12-01 05:27:27.714652: step 65320, loss = 0.43, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 11h:22m:28s remains)
INFO - root - 2017-12-01 05:27:29.271158: step 65330, loss = 0.35, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 11h:42m:57s remains)
INFO - root - 2017-12-01 05:27:30.848811: step 65340, loss = 0.38, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 11h:17m:16s remains)
INFO - root - 2017-12-01 05:27:32.416742: step 65350, loss = 0.42, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 11h:33m:20s remains)
INFO - root - 2017-12-01 05:27:33.992255: step 65360, loss = 0.49, batch loss = 0.33 (49.9 examples/sec; 0.160 sec/batch; 11h:53m:59s remains)
INFO - root - 2017-12-01 05:27:35.563055: step 65370, loss = 0.56, batch loss = 0.40 (52.1 examples/sec; 0.154 sec/batch; 11h:23m:46s remains)
INFO - root - 2017-12-01 05:27:37.123413: step 65380, loss = 0.43, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 11h:39m:37s remains)
INFO - root - 2017-12-01 05:27:38.692928: step 65390, loss = 0.39, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 11h:35m:29s remains)
INFO - root - 2017-12-01 05:27:40.249879: step 65400, loss = 0.36, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 11h:44m:06s remains)
INFO - root - 2017-12-01 05:27:41.859581: step 65410, loss = 0.31, batch loss = 0.15 (52.6 examples/sec; 0.152 sec/batch; 11h:17m:10s remains)
INFO - root - 2017-12-01 05:27:43.449091: step 65420, loss = 0.40, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 11h:33m:28s remains)
INFO - root - 2017-12-01 05:27:45.033369: step 65430, loss = 0.41, batch loss = 0.25 (49.9 examples/sec; 0.160 sec/batch; 11h:54m:06s remains)
INFO - root - 2017-12-01 05:27:46.594594: step 65440, loss = 0.34, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 11h:34m:52s remains)
INFO - root - 2017-12-01 05:27:48.169501: step 65450, loss = 0.38, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 11h:35m:03s remains)
INFO - root - 2017-12-01 05:27:49.743005: step 65460, loss = 0.34, batch loss = 0.18 (49.6 examples/sec; 0.161 sec/batch; 11h:58m:05s remains)
INFO - root - 2017-12-01 05:27:51.298814: step 65470, loss = 0.50, batch loss = 0.34 (51.1 examples/sec; 0.157 sec/batch; 11h:37m:09s remains)
INFO - root - 2017-12-01 05:27:52.867460: step 65480, loss = 0.39, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 11h:30m:14s remains)
INFO - root - 2017-12-01 05:27:54.451280: step 65490, loss = 0.50, batch loss = 0.34 (48.0 examples/sec; 0.167 sec/batch; 12h:21m:37s remains)
INFO - root - 2017-12-01 05:27:56.030051: step 65500, loss = 0.42, batch loss = 0.26 (49.4 examples/sec; 0.162 sec/batch; 12h:01m:20s remains)
INFO - root - 2017-12-01 05:27:57.699697: step 65510, loss = 0.37, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 11h:28m:04s remains)
INFO - root - 2017-12-01 05:27:59.266664: step 65520, loss = 0.39, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 11h:27m:21s remains)
INFO - root - 2017-12-01 05:28:00.812344: step 65530, loss = 0.37, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 11h:34m:25s remains)
INFO - root - 2017-12-01 05:28:02.356526: step 65540, loss = 0.35, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 11h:33m:49s remains)
INFO - root - 2017-12-01 05:28:03.923801: step 65550, loss = 0.36, batch loss = 0.20 (52.8 examples/sec; 0.152 sec/batch; 11h:14m:33s remains)
INFO - root - 2017-12-01 05:28:05.468163: step 65560, loss = 0.51, batch loss = 0.35 (52.6 examples/sec; 0.152 sec/batch; 11h:16m:11s remains)
INFO - root - 2017-12-01 05:28:07.052786: step 65570, loss = 0.36, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 11h:39m:18s remains)
INFO - root - 2017-12-01 05:28:08.610370: step 65580, loss = 0.41, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 11h:27m:13s remains)
INFO - root - 2017-12-01 05:28:10.185231: step 65590, loss = 0.37, batch loss = 0.21 (49.8 examples/sec; 0.161 sec/batch; 11h:54m:25s remains)
INFO - root - 2017-12-01 05:28:11.740924: step 65600, loss = 0.35, batch loss = 0.19 (49.4 examples/sec; 0.162 sec/batch; 11h:59m:51s remains)
INFO - root - 2017-12-01 05:28:13.391192: step 65610, loss = 0.40, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 11h:32m:15s remains)
INFO - root - 2017-12-01 05:28:14.955629: step 65620, loss = 0.52, batch loss = 0.36 (51.2 examples/sec; 0.156 sec/batch; 11h:35m:25s remains)
INFO - root - 2017-12-01 05:28:16.494794: step 65630, loss = 0.38, batch loss = 0.22 (52.4 examples/sec; 0.153 sec/batch; 11h:18m:36s remains)
INFO - root - 2017-12-01 05:28:18.082422: step 65640, loss = 0.38, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 11h:22m:53s remains)
INFO - root - 2017-12-01 05:28:19.641817: step 65650, loss = 0.40, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 11h:33m:06s remains)
INFO - root - 2017-12-01 05:28:21.199834: step 65660, loss = 0.45, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 11h:41m:35s remains)
INFO - root - 2017-12-01 05:28:22.761866: step 65670, loss = 0.53, batch loss = 0.37 (50.6 examples/sec; 0.158 sec/batch; 11h:43m:33s remains)
INFO - root - 2017-12-01 05:28:24.338803: step 65680, loss = 0.40, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 11h:39m:19s remains)
INFO - root - 2017-12-01 05:28:25.927292: step 65690, loss = 0.42, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 11h:42m:12s remains)
INFO - root - 2017-12-01 05:28:27.485185: step 65700, loss = 0.40, batch loss = 0.24 (50.2 examples/sec; 0.159 sec/batch; 11h:48m:11s remains)
INFO - root - 2017-12-01 05:28:29.124278: step 65710, loss = 0.38, batch loss = 0.22 (52.9 examples/sec; 0.151 sec/batch; 11h:12m:58s remains)
INFO - root - 2017-12-01 05:28:30.702406: step 65720, loss = 0.54, batch loss = 0.38 (52.2 examples/sec; 0.153 sec/batch; 11h:21m:00s remains)
INFO - root - 2017-12-01 05:28:32.291851: step 65730, loss = 0.40, batch loss = 0.24 (49.1 examples/sec; 0.163 sec/batch; 12h:04m:20s remains)
INFO - root - 2017-12-01 05:28:33.876918: step 65740, loss = 0.46, batch loss = 0.30 (52.5 examples/sec; 0.152 sec/batch; 11h:17m:13s remains)
INFO - root - 2017-12-01 05:28:35.445271: step 65750, loss = 0.36, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 11h:39m:11s remains)
INFO - root - 2017-12-01 05:28:37.005057: step 65760, loss = 0.58, batch loss = 0.42 (50.8 examples/sec; 0.157 sec/batch; 11h:39m:25s remains)
INFO - root - 2017-12-01 05:28:38.569446: step 65770, loss = 0.39, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 11h:15m:44s remains)
INFO - root - 2017-12-01 05:28:40.143911: step 65780, loss = 0.40, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 11h:32m:40s remains)
INFO - root - 2017-12-01 05:28:41.698003: step 65790, loss = 0.40, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 11h:43m:48s remains)
INFO - root - 2017-12-01 05:28:43.264494: step 65800, loss = 0.45, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 11h:29m:15s remains)
INFO - root - 2017-12-01 05:28:44.896179: step 65810, loss = 0.39, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 11h:23m:23s remains)
INFO - root - 2017-12-01 05:28:46.474164: step 65820, loss = 0.39, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 11h:28m:03s remains)
INFO - root - 2017-12-01 05:28:48.035993: step 65830, loss = 0.43, batch loss = 0.27 (50.1 examples/sec; 0.160 sec/batch; 11h:49m:46s remains)
INFO - root - 2017-12-01 05:28:49.611911: step 65840, loss = 0.33, batch loss = 0.17 (49.2 examples/sec; 0.162 sec/batch; 12h:02m:00s remains)
INFO - root - 2017-12-01 05:28:51.159789: step 65850, loss = 0.35, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 11h:25m:10s remains)
INFO - root - 2017-12-01 05:28:52.726456: step 65860, loss = 0.41, batch loss = 0.25 (52.8 examples/sec; 0.151 sec/batch; 11h:13m:15s remains)
INFO - root - 2017-12-01 05:28:54.303640: step 65870, loss = 0.42, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 11h:37m:15s remains)
INFO - root - 2017-12-01 05:28:55.867260: step 65880, loss = 0.44, batch loss = 0.28 (49.9 examples/sec; 0.160 sec/batch; 11h:51m:46s remains)
INFO - root - 2017-12-01 05:28:57.421009: step 65890, loss = 0.39, batch loss = 0.23 (49.1 examples/sec; 0.163 sec/batch; 12h:04m:23s remains)
INFO - root - 2017-12-01 05:28:58.982084: step 65900, loss = 0.39, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 11h:33m:36s remains)
INFO - root - 2017-12-01 05:29:00.599071: step 65910, loss = 0.38, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 11h:41m:04s remains)
INFO - root - 2017-12-01 05:29:02.166713: step 65920, loss = 0.57, batch loss = 0.41 (50.9 examples/sec; 0.157 sec/batch; 11h:38m:57s remains)
INFO - root - 2017-12-01 05:29:03.737039: step 65930, loss = 0.39, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 11h:52m:30s remains)
INFO - root - 2017-12-01 05:29:05.295268: step 65940, loss = 0.38, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 11h:30m:26s remains)
INFO - root - 2017-12-01 05:29:06.858673: step 65950, loss = 0.41, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 11h:29m:01s remains)
INFO - root - 2017-12-01 05:29:08.440636: step 65960, loss = 0.47, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 11h:34m:37s remains)
INFO - root - 2017-12-01 05:29:10.008434: step 65970, loss = 0.35, batch loss = 0.19 (50.1 examples/sec; 0.160 sec/batch; 11h:49m:36s remains)
INFO - root - 2017-12-01 05:29:11.558955: step 65980, loss = 0.49, batch loss = 0.33 (51.0 examples/sec; 0.157 sec/batch; 11h:36m:13s remains)
INFO - root - 2017-12-01 05:29:13.109618: step 65990, loss = 0.34, batch loss = 0.18 (52.5 examples/sec; 0.153 sec/batch; 11h:17m:25s remains)
INFO - root - 2017-12-01 05:29:14.672867: step 66000, loss = 0.42, batch loss = 0.26 (50.5 examples/sec; 0.159 sec/batch; 11h:44m:11s remains)
INFO - root - 2017-12-01 05:29:16.287818: step 66010, loss = 0.44, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 11h:32m:50s remains)
INFO - root - 2017-12-01 05:29:17.845786: step 66020, loss = 0.42, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 11h:26m:35s remains)
INFO - root - 2017-12-01 05:29:19.409897: step 66030, loss = 0.42, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 11h:28m:53s remains)
INFO - root - 2017-12-01 05:29:20.974329: step 66040, loss = 0.39, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 11h:41m:07s remains)
INFO - root - 2017-12-01 05:29:22.547634: step 66050, loss = 0.39, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 11h:38m:27s remains)
INFO - root - 2017-12-01 05:29:24.118358: step 66060, loss = 0.31, batch loss = 0.15 (50.7 examples/sec; 0.158 sec/batch; 11h:40m:17s remains)
INFO - root - 2017-12-01 05:29:25.683253: step 66070, loss = 0.44, batch loss = 0.28 (52.5 examples/sec; 0.152 sec/batch; 11h:17m:03s remains)
INFO - root - 2017-12-01 05:29:27.249818: step 66080, loss = 0.43, batch loss = 0.28 (52.0 examples/sec; 0.154 sec/batch; 11h:23m:29s remains)
INFO - root - 2017-12-01 05:29:28.796481: step 66090, loss = 0.40, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 11h:28m:16s remains)
INFO - root - 2017-12-01 05:29:30.380546: step 66100, loss = 0.36, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 11h:40m:18s remains)
INFO - root - 2017-12-01 05:29:32.005795: step 66110, loss = 0.41, batch loss = 0.25 (52.6 examples/sec; 0.152 sec/batch; 11h:15m:25s remains)
INFO - root - 2017-12-01 05:29:33.591968: step 66120, loss = 0.32, batch loss = 0.16 (50.5 examples/sec; 0.159 sec/batch; 11h:43m:49s remains)
INFO - root - 2017-12-01 05:29:35.152110: step 66130, loss = 0.39, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 11h:39m:26s remains)
INFO - root - 2017-12-01 05:29:36.711803: step 66140, loss = 0.37, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 11h:37m:40s remains)
INFO - root - 2017-12-01 05:29:38.273908: step 66150, loss = 0.40, batch loss = 0.24 (52.5 examples/sec; 0.152 sec/batch; 11h:16m:06s remains)
INFO - root - 2017-12-01 05:29:39.845390: step 66160, loss = 0.38, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 11h:33m:23s remains)
INFO - root - 2017-12-01 05:29:41.403359: step 66170, loss = 0.41, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 11h:35m:51s remains)
INFO - root - 2017-12-01 05:29:42.982311: step 66180, loss = 0.38, batch loss = 0.23 (48.5 examples/sec; 0.165 sec/batch; 12h:11m:33s remains)
INFO - root - 2017-12-01 05:29:44.561462: step 66190, loss = 0.40, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 11h:26m:54s remains)
INFO - root - 2017-12-01 05:29:46.120299: step 66200, loss = 0.40, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 11h:18m:51s remains)
INFO - root - 2017-12-01 05:29:47.728704: step 66210, loss = 0.43, batch loss = 0.27 (49.1 examples/sec; 0.163 sec/batch; 12h:02m:37s remains)
INFO - root - 2017-12-01 05:29:49.299803: step 66220, loss = 0.36, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 11h:30m:25s remains)
INFO - root - 2017-12-01 05:29:50.876928: step 66230, loss = 0.41, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 11h:35m:31s remains)
INFO - root - 2017-12-01 05:29:52.437124: step 66240, loss = 0.56, batch loss = 0.40 (50.9 examples/sec; 0.157 sec/batch; 11h:37m:22s remains)
INFO - root - 2017-12-01 05:29:53.988541: step 66250, loss = 0.41, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 11h:29m:27s remains)
INFO - root - 2017-12-01 05:29:55.550082: step 66260, loss = 0.46, batch loss = 0.30 (50.5 examples/sec; 0.158 sec/batch; 11h:43m:07s remains)
INFO - root - 2017-12-01 05:29:57.114407: step 66270, loss = 0.43, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 11h:34m:40s remains)
INFO - root - 2017-12-01 05:29:58.674774: step 66280, loss = 0.46, batch loss = 0.30 (51.9 examples/sec; 0.154 sec/batch; 11h:24m:21s remains)
INFO - root - 2017-12-01 05:30:00.248539: step 66290, loss = 0.35, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 11h:36m:57s remains)
INFO - root - 2017-12-01 05:30:01.806474: step 66300, loss = 0.34, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 11h:41m:37s remains)
INFO - root - 2017-12-01 05:30:03.463211: step 66310, loss = 0.46, batch loss = 0.30 (51.7 examples/sec; 0.155 sec/batch; 11h:26m:34s remains)
INFO - root - 2017-12-01 05:30:05.016744: step 66320, loss = 0.34, batch loss = 0.18 (52.8 examples/sec; 0.152 sec/batch; 11h:12m:43s remains)
INFO - root - 2017-12-01 05:30:06.592244: step 66330, loss = 0.41, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 11h:32m:30s remains)
INFO - root - 2017-12-01 05:30:08.171543: step 66340, loss = 0.31, batch loss = 0.15 (51.7 examples/sec; 0.155 sec/batch; 11h:25m:58s remains)
INFO - root - 2017-12-01 05:30:09.729904: step 66350, loss = 0.33, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 11h:20m:17s remains)
INFO - root - 2017-12-01 05:30:11.278453: step 66360, loss = 0.41, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 11h:24m:34s remains)
INFO - root - 2017-12-01 05:30:12.852408: step 66370, loss = 0.40, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 11h:19m:34s remains)
INFO - root - 2017-12-01 05:30:14.418978: step 66380, loss = 0.45, batch loss = 0.30 (49.4 examples/sec; 0.162 sec/batch; 11h:58m:18s remains)
INFO - root - 2017-12-01 05:30:15.997286: step 66390, loss = 0.35, batch loss = 0.19 (49.0 examples/sec; 0.163 sec/batch; 12h:04m:10s remains)
INFO - root - 2017-12-01 05:30:17.560695: step 66400, loss = 0.37, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 11h:35m:58s remains)
INFO - root - 2017-12-01 05:30:19.176007: step 66410, loss = 0.34, batch loss = 0.18 (50.1 examples/sec; 0.160 sec/batch; 11h:47m:28s remains)
INFO - root - 2017-12-01 05:30:20.758212: step 66420, loss = 0.45, batch loss = 0.29 (49.9 examples/sec; 0.160 sec/batch; 11h:51m:14s remains)
INFO - root - 2017-12-01 05:30:22.323958: step 66430, loss = 0.34, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 11h:17m:44s remains)
INFO - root - 2017-12-01 05:30:23.883389: step 66440, loss = 0.34, batch loss = 0.18 (49.9 examples/sec; 0.160 sec/batch; 11h:51m:03s remains)
INFO - root - 2017-12-01 05:30:25.447783: step 66450, loss = 0.35, batch loss = 0.19 (49.7 examples/sec; 0.161 sec/batch; 11h:53m:53s remains)
INFO - root - 2017-12-01 05:30:27.007799: step 66460, loss = 0.44, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 11h:30m:32s remains)
INFO - root - 2017-12-01 05:30:28.569372: step 66470, loss = 0.49, batch loss = 0.33 (52.8 examples/sec; 0.151 sec/batch; 11h:11m:41s remains)
INFO - root - 2017-12-01 05:30:30.143861: step 66480, loss = 0.41, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 11h:43m:50s remains)
INFO - root - 2017-12-01 05:30:31.712424: step 66490, loss = 0.39, batch loss = 0.24 (50.0 examples/sec; 0.160 sec/batch; 11h:48m:59s remains)
INFO - root - 2017-12-01 05:30:33.276838: step 66500, loss = 0.42, batch loss = 0.26 (50.1 examples/sec; 0.160 sec/batch; 11h:47m:57s remains)
INFO - root - 2017-12-01 05:30:34.888605: step 66510, loss = 0.35, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 11h:13m:38s remains)
INFO - root - 2017-12-01 05:30:36.475088: step 66520, loss = 0.38, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 11h:37m:49s remains)
INFO - root - 2017-12-01 05:30:38.015243: step 66530, loss = 0.47, batch loss = 0.31 (51.5 examples/sec; 0.155 sec/batch; 11h:29m:01s remains)
INFO - root - 2017-12-01 05:30:39.589162: step 66540, loss = 0.47, batch loss = 0.31 (49.3 examples/sec; 0.162 sec/batch; 11h:59m:58s remains)
INFO - root - 2017-12-01 05:30:41.156969: step 66550, loss = 0.38, batch loss = 0.22 (53.1 examples/sec; 0.151 sec/batch; 11h:07m:13s remains)
INFO - root - 2017-12-01 05:30:42.733951: step 66560, loss = 0.38, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 11h:25m:59s remains)
INFO - root - 2017-12-01 05:30:44.282065: step 66570, loss = 0.51, batch loss = 0.35 (51.5 examples/sec; 0.155 sec/batch; 11h:29m:06s remains)
INFO - root - 2017-12-01 05:30:45.827565: step 66580, loss = 0.32, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 11h:40m:01s remains)
INFO - root - 2017-12-01 05:30:47.402344: step 66590, loss = 0.28, batch loss = 0.12 (51.2 examples/sec; 0.156 sec/batch; 11h:32m:47s remains)
INFO - root - 2017-12-01 05:30:48.958076: step 66600, loss = 0.34, batch loss = 0.18 (53.1 examples/sec; 0.151 sec/batch; 11h:07m:25s remains)
INFO - root - 2017-12-01 05:30:50.608081: step 66610, loss = 0.37, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 11h:40m:17s remains)
INFO - root - 2017-12-01 05:30:52.166445: step 66620, loss = 0.33, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 11h:24m:24s remains)
INFO - root - 2017-12-01 05:30:53.740467: step 66630, loss = 0.45, batch loss = 0.29 (52.5 examples/sec; 0.152 sec/batch; 11h:15m:02s remains)
INFO - root - 2017-12-01 05:30:55.326811: step 66640, loss = 0.39, batch loss = 0.23 (51.1 examples/sec; 0.156 sec/batch; 11h:33m:22s remains)
INFO - root - 2017-12-01 05:30:56.891192: step 66650, loss = 0.36, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 11h:45m:29s remains)
INFO - root - 2017-12-01 05:30:58.469354: step 66660, loss = 0.40, batch loss = 0.24 (48.4 examples/sec; 0.165 sec/batch; 12h:11m:36s remains)
INFO - root - 2017-12-01 05:31:00.069103: step 66670, loss = 0.46, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 11h:32m:09s remains)
INFO - root - 2017-12-01 05:31:01.618175: step 66680, loss = 0.37, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 11h:35m:02s remains)
INFO - root - 2017-12-01 05:31:03.190989: step 66690, loss = 0.42, batch loss = 0.26 (49.3 examples/sec; 0.162 sec/batch; 11h:59m:00s remains)
INFO - root - 2017-12-01 05:31:04.737072: step 66700, loss = 0.36, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 11h:48m:03s remains)
INFO - root - 2017-12-01 05:31:06.398001: step 66710, loss = 0.40, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 11h:27m:22s remains)
INFO - root - 2017-12-01 05:31:07.954988: step 66720, loss = 0.33, batch loss = 0.17 (49.9 examples/sec; 0.160 sec/batch; 11h:50m:43s remains)
INFO - root - 2017-12-01 05:31:09.522082: step 66730, loss = 0.38, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 11h:33m:20s remains)
INFO - root - 2017-12-01 05:31:11.094546: step 66740, loss = 0.46, batch loss = 0.30 (50.8 examples/sec; 0.158 sec/batch; 11h:38m:05s remains)
INFO - root - 2017-12-01 05:31:12.652329: step 66750, loss = 0.51, batch loss = 0.35 (51.6 examples/sec; 0.155 sec/batch; 11h:26m:44s remains)
INFO - root - 2017-12-01 05:31:14.212923: step 66760, loss = 0.42, batch loss = 0.26 (50.8 examples/sec; 0.157 sec/batch; 11h:37m:04s remains)
INFO - root - 2017-12-01 05:31:15.765721: step 66770, loss = 0.37, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 11h:17m:27s remains)
INFO - root - 2017-12-01 05:31:17.315559: step 66780, loss = 0.42, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 11h:32m:32s remains)
INFO - root - 2017-12-01 05:31:18.871516: step 66790, loss = 0.34, batch loss = 0.18 (52.1 examples/sec; 0.154 sec/batch; 11h:20m:20s remains)
INFO - root - 2017-12-01 05:31:20.466648: step 66800, loss = 0.37, batch loss = 0.21 (51.8 examples/sec; 0.155 sec/batch; 11h:24m:11s remains)
INFO - root - 2017-12-01 05:31:22.067318: step 66810, loss = 0.42, batch loss = 0.26 (52.5 examples/sec; 0.152 sec/batch; 11h:14m:40s remains)
INFO - root - 2017-12-01 05:31:23.633769: step 66820, loss = 0.35, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 11h:42m:43s remains)
INFO - root - 2017-12-01 05:31:25.188448: step 66830, loss = 0.37, batch loss = 0.21 (53.0 examples/sec; 0.151 sec/batch; 11h:08m:04s remains)
INFO - root - 2017-12-01 05:31:26.747306: step 66840, loss = 0.42, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 11h:18m:40s remains)
INFO - root - 2017-12-01 05:31:28.313034: step 66850, loss = 0.33, batch loss = 0.17 (48.9 examples/sec; 0.164 sec/batch; 12h:04m:46s remains)
INFO - root - 2017-12-01 05:31:29.874772: step 66860, loss = 0.37, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 11h:33m:51s remains)
INFO - root - 2017-12-01 05:31:31.442157: step 66870, loss = 0.34, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 11h:24m:52s remains)
INFO - root - 2017-12-01 05:31:32.997528: step 66880, loss = 0.58, batch loss = 0.42 (53.2 examples/sec; 0.150 sec/batch; 11h:05m:14s remains)
INFO - root - 2017-12-01 05:31:34.550381: step 66890, loss = 0.34, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 11h:24m:54s remains)
INFO - root - 2017-12-01 05:31:36.103806: step 66900, loss = 0.34, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 11h:16m:57s remains)
INFO - root - 2017-12-01 05:31:37.735632: step 66910, loss = 0.39, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 11h:12m:35s remains)
INFO - root - 2017-12-01 05:31:39.292887: step 66920, loss = 0.64, batch loss = 0.48 (52.0 examples/sec; 0.154 sec/batch; 11h:20m:30s remains)
INFO - root - 2017-12-01 05:31:40.865426: step 66930, loss = 0.46, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 11h:27m:12s remains)
INFO - root - 2017-12-01 05:31:42.409111: step 66940, loss = 0.40, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 11h:40m:25s remains)
INFO - root - 2017-12-01 05:31:43.971764: step 66950, loss = 0.36, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 11h:32m:01s remains)
INFO - root - 2017-12-01 05:31:45.538590: step 66960, loss = 0.37, batch loss = 0.21 (49.8 examples/sec; 0.161 sec/batch; 11h:51m:17s remains)
INFO - root - 2017-12-01 05:31:47.110435: step 66970, loss = 0.39, batch loss = 0.24 (50.1 examples/sec; 0.160 sec/batch; 11h:46m:00s remains)
INFO - root - 2017-12-01 05:31:48.665691: step 66980, loss = 0.38, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 11h:26m:31s remains)
INFO - root - 2017-12-01 05:31:50.248620: step 66990, loss = 0.38, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 11h:31m:58s remains)
INFO - root - 2017-12-01 05:31:51.804577: step 67000, loss = 0.42, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 11h:38m:05s remains)
INFO - root - 2017-12-01 05:31:53.458111: step 67010, loss = 0.36, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 11h:36m:02s remains)
INFO - root - 2017-12-01 05:31:55.014134: step 67020, loss = 0.37, batch loss = 0.21 (50.0 examples/sec; 0.160 sec/batch; 11h:48m:02s remains)
INFO - root - 2017-12-01 05:31:56.571826: step 67030, loss = 0.52, batch loss = 0.36 (51.6 examples/sec; 0.155 sec/batch; 11h:25m:56s remains)
INFO - root - 2017-12-01 05:31:58.141298: step 67040, loss = 0.39, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 11h:13m:30s remains)
INFO - root - 2017-12-01 05:31:59.687474: step 67050, loss = 0.31, batch loss = 0.15 (51.9 examples/sec; 0.154 sec/batch; 11h:21m:40s remains)
INFO - root - 2017-12-01 05:32:01.237143: step 67060, loss = 0.40, batch loss = 0.24 (52.9 examples/sec; 0.151 sec/batch; 11h:08m:28s remains)
INFO - root - 2017-12-01 05:32:02.821693: step 67070, loss = 0.51, batch loss = 0.36 (51.0 examples/sec; 0.157 sec/batch; 11h:33m:55s remains)
INFO - root - 2017-12-01 05:32:04.377472: step 67080, loss = 0.32, batch loss = 0.16 (50.2 examples/sec; 0.159 sec/batch; 11h:44m:36s remains)
INFO - root - 2017-12-01 05:32:05.935903: step 67090, loss = 0.42, batch loss = 0.26 (49.3 examples/sec; 0.162 sec/batch; 11h:57m:38s remains)
INFO - root - 2017-12-01 05:32:07.508923: step 67100, loss = 0.44, batch loss = 0.28 (48.6 examples/sec; 0.165 sec/batch; 12h:08m:23s remains)
INFO - root - 2017-12-01 05:32:09.120250: step 67110, loss = 0.37, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 11h:43m:00s remains)
INFO - root - 2017-12-01 05:32:10.667403: step 67120, loss = 0.36, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 11h:23m:56s remains)
INFO - root - 2017-12-01 05:32:12.235733: step 67130, loss = 0.38, batch loss = 0.22 (52.8 examples/sec; 0.152 sec/batch; 11h:10m:14s remains)
INFO - root - 2017-12-01 05:32:13.804487: step 67140, loss = 0.42, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 11h:21m:57s remains)
INFO - root - 2017-12-01 05:32:15.416008: step 67150, loss = 0.30, batch loss = 0.15 (51.5 examples/sec; 0.155 sec/batch; 11h:26m:31s remains)
INFO - root - 2017-12-01 05:32:16.973500: step 67160, loss = 0.37, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 11h:30m:52s remains)
INFO - root - 2017-12-01 05:32:18.527300: step 67170, loss = 0.34, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 11h:37m:00s remains)
INFO - root - 2017-12-01 05:32:20.094005: step 67180, loss = 0.56, batch loss = 0.40 (52.5 examples/sec; 0.153 sec/batch; 11h:14m:25s remains)
INFO - root - 2017-12-01 05:32:21.661130: step 67190, loss = 0.39, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 11h:28m:36s remains)
INFO - root - 2017-12-01 05:32:23.231728: step 67200, loss = 0.36, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 11h:41m:59s remains)
INFO - root - 2017-12-01 05:32:24.872521: step 67210, loss = 0.44, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 11h:26m:48s remains)
INFO - root - 2017-12-01 05:32:26.439612: step 67220, loss = 0.32, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 11h:31m:26s remains)
INFO - root - 2017-12-01 05:32:28.013614: step 67230, loss = 0.41, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 11h:37m:28s remains)
INFO - root - 2017-12-01 05:32:29.578859: step 67240, loss = 0.40, batch loss = 0.24 (49.0 examples/sec; 0.163 sec/batch; 12h:01m:46s remains)
INFO - root - 2017-12-01 05:32:31.147916: step 67250, loss = 0.39, batch loss = 0.23 (52.5 examples/sec; 0.152 sec/batch; 11h:14m:05s remains)
INFO - root - 2017-12-01 05:32:32.706011: step 67260, loss = 0.34, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 11h:16m:34s remains)
INFO - root - 2017-12-01 05:32:34.255945: step 67270, loss = 0.36, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 11h:24m:27s remains)
INFO - root - 2017-12-01 05:32:35.821672: step 67280, loss = 0.64, batch loss = 0.48 (52.6 examples/sec; 0.152 sec/batch; 11h:11m:50s remains)
INFO - root - 2017-12-01 05:32:37.384694: step 67290, loss = 0.49, batch loss = 0.33 (48.4 examples/sec; 0.165 sec/batch; 12h:09m:56s remains)
INFO - root - 2017-12-01 05:32:38.951946: step 67300, loss = 0.34, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 11h:33m:47s remains)
INFO - root - 2017-12-01 05:32:40.585001: step 67310, loss = 0.34, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 11h:38m:11s remains)
INFO - root - 2017-12-01 05:32:42.139862: step 67320, loss = 0.35, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 11h:26m:16s remains)
INFO - root - 2017-12-01 05:32:43.702467: step 67330, loss = 0.67, batch loss = 0.51 (51.9 examples/sec; 0.154 sec/batch; 11h:20m:45s remains)
INFO - root - 2017-12-01 05:32:45.286428: step 67340, loss = 0.37, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 11h:40m:56s remains)
INFO - root - 2017-12-01 05:32:46.849260: step 67350, loss = 0.38, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 11h:38m:32s remains)
INFO - root - 2017-12-01 05:32:48.420794: step 67360, loss = 0.39, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 11h:30m:36s remains)
INFO - root - 2017-12-01 05:32:49.978762: step 67370, loss = 0.41, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 11h:26m:09s remains)
INFO - root - 2017-12-01 05:32:51.542839: step 67380, loss = 0.34, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 11h:15m:27s remains)
INFO - root - 2017-12-01 05:32:53.105847: step 67390, loss = 0.42, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 11h:36m:38s remains)
INFO - root - 2017-12-01 05:32:54.677144: step 67400, loss = 0.32, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 11h:41m:29s remains)
INFO - root - 2017-12-01 05:32:56.280440: step 67410, loss = 0.40, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 11h:25m:12s remains)
INFO - root - 2017-12-01 05:32:57.852494: step 67420, loss = 0.47, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 11h:34m:54s remains)
INFO - root - 2017-12-01 05:32:59.409119: step 67430, loss = 0.49, batch loss = 0.33 (51.7 examples/sec; 0.155 sec/batch; 11h:23m:00s remains)
INFO - root - 2017-12-01 05:33:00.975348: step 67440, loss = 0.47, batch loss = 0.32 (50.3 examples/sec; 0.159 sec/batch; 11h:42m:52s remains)
INFO - root - 2017-12-01 05:33:02.567567: step 67450, loss = 0.45, batch loss = 0.29 (48.0 examples/sec; 0.167 sec/batch; 12h:16m:37s remains)
INFO - root - 2017-12-01 05:33:04.136480: step 67460, loss = 0.38, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 11h:15m:56s remains)
INFO - root - 2017-12-01 05:33:05.709659: step 67470, loss = 0.54, batch loss = 0.38 (50.1 examples/sec; 0.160 sec/batch; 11h:45m:40s remains)
INFO - root - 2017-12-01 05:33:07.271168: step 67480, loss = 0.33, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 11h:39m:55s remains)
INFO - root - 2017-12-01 05:33:08.822915: step 67490, loss = 0.33, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 11h:21m:02s remains)
INFO - root - 2017-12-01 05:33:10.383439: step 67500, loss = 0.37, batch loss = 0.22 (50.5 examples/sec; 0.159 sec/batch; 11h:40m:07s remains)
INFO - root - 2017-12-01 05:33:12.062680: step 67510, loss = 0.33, batch loss = 0.17 (48.7 examples/sec; 0.164 sec/batch; 12h:05m:50s remains)
INFO - root - 2017-12-01 05:33:13.627059: step 67520, loss = 0.36, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 11h:11m:54s remains)
INFO - root - 2017-12-01 05:33:15.203265: step 67530, loss = 0.36, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 11h:16m:25s remains)
INFO - root - 2017-12-01 05:33:16.758386: step 67540, loss = 0.33, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 11h:28m:05s remains)
INFO - root - 2017-12-01 05:33:18.326004: step 67550, loss = 0.44, batch loss = 0.29 (51.4 examples/sec; 0.156 sec/batch; 11h:27m:05s remains)
INFO - root - 2017-12-01 05:33:19.881429: step 67560, loss = 0.35, batch loss = 0.19 (51.8 examples/sec; 0.155 sec/batch; 11h:22m:28s remains)
INFO - root - 2017-12-01 05:33:21.464304: step 67570, loss = 0.34, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 11h:27m:12s remains)
INFO - root - 2017-12-01 05:33:23.000067: step 67580, loss = 0.40, batch loss = 0.24 (53.1 examples/sec; 0.151 sec/batch; 11h:05m:45s remains)
INFO - root - 2017-12-01 05:33:24.545386: step 67590, loss = 0.45, batch loss = 0.30 (50.5 examples/sec; 0.158 sec/batch; 11h:39m:16s remains)
INFO - root - 2017-12-01 05:33:26.118246: step 67600, loss = 0.36, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 11h:28m:12s remains)
INFO - root - 2017-12-01 05:33:27.725930: step 67610, loss = 0.38, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 11h:25m:38s remains)
INFO - root - 2017-12-01 05:33:29.289483: step 67620, loss = 0.38, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 11h:21m:26s remains)
INFO - root - 2017-12-01 05:33:30.850275: step 67630, loss = 0.55, batch loss = 0.39 (50.8 examples/sec; 0.157 sec/batch; 11h:34m:55s remains)
INFO - root - 2017-12-01 05:33:32.431338: step 67640, loss = 0.49, batch loss = 0.34 (51.5 examples/sec; 0.155 sec/batch; 11h:25m:07s remains)
INFO - root - 2017-12-01 05:33:34.002410: step 67650, loss = 0.33, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 11h:28m:14s remains)
INFO - root - 2017-12-01 05:33:35.554190: step 67660, loss = 0.34, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 11h:33m:17s remains)
INFO - root - 2017-12-01 05:33:37.119511: step 67670, loss = 0.41, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 11h:32m:25s remains)
INFO - root - 2017-12-01 05:33:38.702490: step 67680, loss = 0.39, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 11h:28m:08s remains)
INFO - root - 2017-12-01 05:33:40.268253: step 67690, loss = 0.30, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 11h:28m:19s remains)
INFO - root - 2017-12-01 05:33:41.828226: step 67700, loss = 0.30, batch loss = 0.15 (50.1 examples/sec; 0.160 sec/batch; 11h:44m:36s remains)
INFO - root - 2017-12-01 05:33:43.488702: step 67710, loss = 0.40, batch loss = 0.24 (48.0 examples/sec; 0.167 sec/batch; 12h:15m:31s remains)
INFO - root - 2017-12-01 05:33:45.054087: step 67720, loss = 0.42, batch loss = 0.26 (48.9 examples/sec; 0.164 sec/batch; 12h:01m:58s remains)
INFO - root - 2017-12-01 05:33:46.632556: step 67730, loss = 0.48, batch loss = 0.32 (52.2 examples/sec; 0.153 sec/batch; 11h:15m:50s remains)
INFO - root - 2017-12-01 05:33:48.205265: step 67740, loss = 0.36, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 11h:26m:58s remains)
INFO - root - 2017-12-01 05:33:49.760214: step 67750, loss = 0.35, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 11h:31m:50s remains)
INFO - root - 2017-12-01 05:33:51.335894: step 67760, loss = 0.47, batch loss = 0.31 (48.8 examples/sec; 0.164 sec/batch; 12h:03m:58s remains)
INFO - root - 2017-12-01 05:33:52.899163: step 67770, loss = 0.39, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 11h:16m:38s remains)
INFO - root - 2017-12-01 05:33:54.450098: step 67780, loss = 0.39, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 11h:23m:21s remains)
INFO - root - 2017-12-01 05:33:55.998810: step 67790, loss = 0.37, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 11h:35m:53s remains)
INFO - root - 2017-12-01 05:33:57.571325: step 67800, loss = 0.42, batch loss = 0.26 (49.7 examples/sec; 0.161 sec/batch; 11h:50m:38s remains)
INFO - root - 2017-12-01 05:33:59.169029: step 67810, loss = 0.35, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 11h:22m:07s remains)
INFO - root - 2017-12-01 05:34:00.742168: step 67820, loss = 0.51, batch loss = 0.35 (51.9 examples/sec; 0.154 sec/batch; 11h:19m:24s remains)
INFO - root - 2017-12-01 05:34:02.322250: step 67830, loss = 0.57, batch loss = 0.41 (48.6 examples/sec; 0.165 sec/batch; 12h:06m:28s remains)
INFO - root - 2017-12-01 05:34:03.906084: step 67840, loss = 0.43, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 11h:31m:06s remains)
INFO - root - 2017-12-01 05:34:05.470948: step 67850, loss = 0.47, batch loss = 0.32 (48.5 examples/sec; 0.165 sec/batch; 12h:08m:12s remains)
INFO - root - 2017-12-01 05:34:07.072358: step 67860, loss = 0.34, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 11h:30m:58s remains)
INFO - root - 2017-12-01 05:34:08.635945: step 67870, loss = 0.39, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 11h:34m:49s remains)
INFO - root - 2017-12-01 05:34:10.196462: step 67880, loss = 0.31, batch loss = 0.15 (51.4 examples/sec; 0.156 sec/batch; 11h:27m:04s remains)
INFO - root - 2017-12-01 05:34:11.757297: step 67890, loss = 0.37, batch loss = 0.21 (52.9 examples/sec; 0.151 sec/batch; 11h:06m:20s remains)
INFO - root - 2017-12-01 05:34:13.325873: step 67900, loss = 0.35, batch loss = 0.19 (52.8 examples/sec; 0.151 sec/batch; 11h:08m:03s remains)
INFO - root - 2017-12-01 05:34:14.933774: step 67910, loss = 0.36, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 11h:27m:22s remains)
INFO - root - 2017-12-01 05:34:16.490721: step 67920, loss = 0.42, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 11h:22m:06s remains)
INFO - root - 2017-12-01 05:34:18.062884: step 67930, loss = 0.39, batch loss = 0.24 (53.8 examples/sec; 0.149 sec/batch; 10h:56m:17s remains)
INFO - root - 2017-12-01 05:34:19.623208: step 67940, loss = 0.37, batch loss = 0.21 (51.8 examples/sec; 0.155 sec/batch; 11h:21m:35s remains)
INFO - root - 2017-12-01 05:34:21.195424: step 67950, loss = 0.32, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 11h:37m:04s remains)
INFO - root - 2017-12-01 05:34:22.763077: step 67960, loss = 0.42, batch loss = 0.26 (50.3 examples/sec; 0.159 sec/batch; 11h:40m:56s remains)
INFO - root - 2017-12-01 05:34:24.316064: step 67970, loss = 0.49, batch loss = 0.33 (52.0 examples/sec; 0.154 sec/batch; 11h:17m:50s remains)
INFO - root - 2017-12-01 05:34:25.900170: step 67980, loss = 0.37, batch loss = 0.21 (49.8 examples/sec; 0.161 sec/batch; 11h:48m:32s remains)
INFO - root - 2017-12-01 05:34:27.464277: step 67990, loss = 0.35, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 11h:37m:06s remains)
INFO - root - 2017-12-01 05:34:29.004688: step 68000, loss = 0.29, batch loss = 0.13 (51.5 examples/sec; 0.155 sec/batch; 11h:25m:09s remains)
INFO - root - 2017-12-01 05:34:30.609480: step 68010, loss = 0.43, batch loss = 0.27 (49.8 examples/sec; 0.161 sec/batch; 11h:48m:47s remains)
INFO - root - 2017-12-01 05:34:32.162443: step 68020, loss = 0.41, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 11h:23m:50s remains)
INFO - root - 2017-12-01 05:34:33.719256: step 68030, loss = 0.36, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 11h:09m:48s remains)
INFO - root - 2017-12-01 05:34:35.292787: step 68040, loss = 0.38, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 11h:40m:53s remains)
INFO - root - 2017-12-01 05:34:36.846696: step 68050, loss = 0.41, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 11h:32m:06s remains)
INFO - root - 2017-12-01 05:34:38.401722: step 68060, loss = 0.43, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 11h:32m:13s remains)
INFO - root - 2017-12-01 05:34:39.958655: step 68070, loss = 0.33, batch loss = 0.17 (47.3 examples/sec; 0.169 sec/batch; 12h:25m:05s remains)
INFO - root - 2017-12-01 05:34:41.525903: step 68080, loss = 0.34, batch loss = 0.18 (49.6 examples/sec; 0.161 sec/batch; 11h:50m:44s remains)
INFO - root - 2017-12-01 05:34:43.090653: step 68090, loss = 0.48, batch loss = 0.32 (51.4 examples/sec; 0.156 sec/batch; 11h:25m:55s remains)
INFO - root - 2017-12-01 05:34:44.647054: step 68100, loss = 0.34, batch loss = 0.19 (49.4 examples/sec; 0.162 sec/batch; 11h:53m:36s remains)
INFO - root - 2017-12-01 05:34:46.328308: step 68110, loss = 0.36, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 11h:20m:30s remains)
INFO - root - 2017-12-01 05:34:47.897041: step 68120, loss = 0.43, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 11h:35m:40s remains)
INFO - root - 2017-12-01 05:34:49.456638: step 68130, loss = 0.33, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 11h:37m:28s remains)
INFO - root - 2017-12-01 05:34:51.009838: step 68140, loss = 0.40, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 11h:29m:35s remains)
INFO - root - 2017-12-01 05:34:52.600176: step 68150, loss = 0.39, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 11h:46m:03s remains)
INFO - root - 2017-12-01 05:34:54.162074: step 68160, loss = 0.38, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 11h:28m:59s remains)
INFO - root - 2017-12-01 05:34:55.743737: step 68170, loss = 0.38, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 11h:44m:28s remains)
INFO - root - 2017-12-01 05:34:57.296920: step 68180, loss = 0.37, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 11h:23m:36s remains)
INFO - root - 2017-12-01 05:34:58.854693: step 68190, loss = 0.43, batch loss = 0.28 (52.9 examples/sec; 0.151 sec/batch; 11h:05m:43s remains)
INFO - root - 2017-12-01 05:35:00.424162: step 68200, loss = 0.36, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 11h:42m:24s remains)
INFO - root - 2017-12-01 05:35:02.063886: step 68210, loss = 0.34, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 11h:27m:29s remains)
INFO - root - 2017-12-01 05:35:03.639936: step 68220, loss = 0.49, batch loss = 0.34 (51.3 examples/sec; 0.156 sec/batch; 11h:26m:18s remains)
INFO - root - 2017-12-01 05:35:05.201879: step 68230, loss = 0.33, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 11h:22m:38s remains)
INFO - root - 2017-12-01 05:35:06.769424: step 68240, loss = 0.32, batch loss = 0.17 (50.1 examples/sec; 0.160 sec/batch; 11h:43m:59s remains)
INFO - root - 2017-12-01 05:35:08.326598: step 68250, loss = 0.37, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 11h:43m:25s remains)
INFO - root - 2017-12-01 05:35:09.885864: step 68260, loss = 0.33, batch loss = 0.17 (50.8 examples/sec; 0.158 sec/batch; 11h:33m:52s remains)
INFO - root - 2017-12-01 05:35:11.448913: step 68270, loss = 0.45, batch loss = 0.29 (49.9 examples/sec; 0.160 sec/batch; 11h:46m:22s remains)
INFO - root - 2017-12-01 05:35:13.028487: step 68280, loss = 0.36, batch loss = 0.21 (52.6 examples/sec; 0.152 sec/batch; 11h:09m:24s remains)
INFO - root - 2017-12-01 05:35:14.604674: step 68290, loss = 0.44, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 11h:27m:31s remains)
INFO - root - 2017-12-01 05:35:16.165663: step 68300, loss = 0.39, batch loss = 0.23 (51.8 examples/sec; 0.155 sec/batch; 11h:20m:35s remains)
INFO - root - 2017-12-01 05:35:17.812657: step 68310, loss = 0.47, batch loss = 0.31 (51.4 examples/sec; 0.156 sec/batch; 11h:24m:51s remains)
INFO - root - 2017-12-01 05:35:19.382338: step 68320, loss = 0.40, batch loss = 0.25 (48.9 examples/sec; 0.164 sec/batch; 12h:00m:10s remains)
INFO - root - 2017-12-01 05:35:20.960793: step 68330, loss = 0.38, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 11h:23m:17s remains)
INFO - root - 2017-12-01 05:35:22.506807: step 68340, loss = 0.35, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 11h:18m:37s remains)
INFO - root - 2017-12-01 05:35:24.074948: step 68350, loss = 0.37, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 11h:20m:02s remains)
INFO - root - 2017-12-01 05:35:25.642381: step 68360, loss = 0.35, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 11h:31m:23s remains)
INFO - root - 2017-12-01 05:35:27.203664: step 68370, loss = 0.46, batch loss = 0.30 (49.7 examples/sec; 0.161 sec/batch; 11h:48m:26s remains)
INFO - root - 2017-12-01 05:35:28.771476: step 68380, loss = 0.37, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 11h:25m:44s remains)
INFO - root - 2017-12-01 05:35:30.346229: step 68390, loss = 0.43, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 11h:19m:03s remains)
INFO - root - 2017-12-01 05:35:31.922549: step 68400, loss = 0.29, batch loss = 0.13 (50.9 examples/sec; 0.157 sec/batch; 11h:31m:56s remains)
INFO - root - 2017-12-01 05:35:33.560058: step 68410, loss = 0.52, batch loss = 0.36 (51.1 examples/sec; 0.157 sec/batch; 11h:29m:30s remains)
INFO - root - 2017-12-01 05:35:35.116544: step 68420, loss = 0.35, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 11h:23m:24s remains)
INFO - root - 2017-12-01 05:35:36.680206: step 68430, loss = 0.50, batch loss = 0.34 (50.4 examples/sec; 0.159 sec/batch; 11h:38m:55s remains)
INFO - root - 2017-12-01 05:35:38.245047: step 68440, loss = 0.41, batch loss = 0.26 (49.9 examples/sec; 0.160 sec/batch; 11h:45m:29s remains)
INFO - root - 2017-12-01 05:35:39.799055: step 68450, loss = 0.33, batch loss = 0.17 (49.5 examples/sec; 0.162 sec/batch; 11h:51m:22s remains)
INFO - root - 2017-12-01 05:35:41.395295: step 68460, loss = 0.30, batch loss = 0.14 (48.9 examples/sec; 0.164 sec/batch; 12h:00m:14s remains)
INFO - root - 2017-12-01 05:35:42.965638: step 68470, loss = 0.43, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 11h:30m:41s remains)
INFO - root - 2017-12-01 05:35:44.526605: step 68480, loss = 0.34, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 11h:31m:06s remains)
INFO - root - 2017-12-01 05:35:46.089492: step 68490, loss = 0.48, batch loss = 0.32 (48.9 examples/sec; 0.164 sec/batch; 11h:59m:56s remains)
INFO - root - 2017-12-01 05:35:47.639292: step 68500, loss = 0.30, batch loss = 0.15 (51.2 examples/sec; 0.156 sec/batch; 11h:27m:53s remains)
INFO - root - 2017-12-01 05:35:49.258602: step 68510, loss = 0.42, batch loss = 0.27 (52.3 examples/sec; 0.153 sec/batch; 11h:13m:06s remains)
INFO - root - 2017-12-01 05:35:50.835902: step 68520, loss = 0.42, batch loss = 0.26 (49.8 examples/sec; 0.161 sec/batch; 11h:46m:10s remains)
INFO - root - 2017-12-01 05:35:52.373546: step 68530, loss = 0.36, batch loss = 0.20 (52.9 examples/sec; 0.151 sec/batch; 11h:05m:14s remains)
INFO - root - 2017-12-01 05:35:53.944175: step 68540, loss = 0.35, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 11h:17m:41s remains)
INFO - root - 2017-12-01 05:35:55.531296: step 68550, loss = 0.36, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 11h:32m:44s remains)
INFO - root - 2017-12-01 05:35:57.128775: step 68560, loss = 0.46, batch loss = 0.31 (50.2 examples/sec; 0.159 sec/batch; 11h:41m:14s remains)
INFO - root - 2017-12-01 05:35:58.694848: step 68570, loss = 0.36, batch loss = 0.21 (53.3 examples/sec; 0.150 sec/batch; 11h:00m:07s remains)
INFO - root - 2017-12-01 05:36:00.256668: step 68580, loss = 0.32, batch loss = 0.16 (52.4 examples/sec; 0.153 sec/batch; 11h:11m:56s remains)
INFO - root - 2017-12-01 05:36:01.817269: step 68590, loss = 0.52, batch loss = 0.36 (51.4 examples/sec; 0.156 sec/batch; 11h:24m:01s remains)
INFO - root - 2017-12-01 05:36:03.391687: step 68600, loss = 0.42, batch loss = 0.26 (49.3 examples/sec; 0.162 sec/batch; 11h:53m:39s remains)
INFO - root - 2017-12-01 05:36:05.048332: step 68610, loss = 0.53, batch loss = 0.37 (52.3 examples/sec; 0.153 sec/batch; 11h:12m:29s remains)
INFO - root - 2017-12-01 05:36:06.648070: step 68620, loss = 0.40, batch loss = 0.25 (47.4 examples/sec; 0.169 sec/batch; 12h:22m:02s remains)
INFO - root - 2017-12-01 05:36:08.220191: step 68630, loss = 0.43, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 11h:22m:49s remains)
INFO - root - 2017-12-01 05:36:09.858415: step 68640, loss = 0.33, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 11h:24m:43s remains)
INFO - root - 2017-12-01 05:36:11.421345: step 68650, loss = 0.35, batch loss = 0.19 (52.9 examples/sec; 0.151 sec/batch; 11h:05m:19s remains)
INFO - root - 2017-12-01 05:36:13.014733: step 68660, loss = 0.37, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 11h:21m:15s remains)
INFO - root - 2017-12-01 05:36:14.578571: step 68670, loss = 0.37, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 11h:28m:52s remains)
INFO - root - 2017-12-01 05:36:16.133128: step 68680, loss = 0.45, batch loss = 0.30 (50.6 examples/sec; 0.158 sec/batch; 11h:35m:34s remains)
INFO - root - 2017-12-01 05:36:17.699585: step 68690, loss = 0.42, batch loss = 0.26 (49.0 examples/sec; 0.163 sec/batch; 11h:57m:42s remains)
INFO - root - 2017-12-01 05:36:19.283428: step 68700, loss = 0.47, batch loss = 0.31 (52.7 examples/sec; 0.152 sec/batch; 11h:07m:40s remains)
INFO - root - 2017-12-01 05:36:20.909716: step 68710, loss = 0.36, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 11h:26m:23s remains)
INFO - root - 2017-12-01 05:36:22.478149: step 68720, loss = 0.44, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 11h:22m:32s remains)
INFO - root - 2017-12-01 05:36:24.035333: step 68730, loss = 0.41, batch loss = 0.25 (50.0 examples/sec; 0.160 sec/batch; 11h:44m:04s remains)
INFO - root - 2017-12-01 05:36:25.621747: step 68740, loss = 0.47, batch loss = 0.31 (51.9 examples/sec; 0.154 sec/batch; 11h:17m:06s remains)
INFO - root - 2017-12-01 05:36:27.180729: step 68750, loss = 0.40, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 11h:27m:12s remains)
INFO - root - 2017-12-01 05:36:28.747402: step 68760, loss = 0.39, batch loss = 0.23 (49.1 examples/sec; 0.163 sec/batch; 11h:56m:09s remains)
INFO - root - 2017-12-01 05:36:30.305985: step 68770, loss = 0.36, batch loss = 0.20 (53.4 examples/sec; 0.150 sec/batch; 10h:58m:00s remains)
INFO - root - 2017-12-01 05:36:31.883207: step 68780, loss = 0.32, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 11h:20m:07s remains)
INFO - root - 2017-12-01 05:36:33.449706: step 68790, loss = 0.39, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 11h:28m:30s remains)
INFO - root - 2017-12-01 05:36:35.018634: step 68800, loss = 0.39, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 11h:26m:44s remains)
INFO - root - 2017-12-01 05:36:36.660863: step 68810, loss = 0.44, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 11h:19m:29s remains)
INFO - root - 2017-12-01 05:36:38.225880: step 68820, loss = 0.32, batch loss = 0.16 (50.6 examples/sec; 0.158 sec/batch; 11h:34m:56s remains)
INFO - root - 2017-12-01 05:36:39.786383: step 68830, loss = 0.33, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 11h:21m:38s remains)
INFO - root - 2017-12-01 05:36:41.351200: step 68840, loss = 0.34, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 11h:24m:36s remains)
INFO - root - 2017-12-01 05:36:42.932336: step 68850, loss = 0.37, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 11h:15m:38s remains)
INFO - root - 2017-12-01 05:36:44.501952: step 68860, loss = 0.38, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 11h:24m:50s remains)
INFO - root - 2017-12-01 05:36:46.057509: step 68870, loss = 0.31, batch loss = 0.15 (49.5 examples/sec; 0.161 sec/batch; 11h:49m:34s remains)
INFO - root - 2017-12-01 05:36:47.614509: step 68880, loss = 0.40, batch loss = 0.25 (50.8 examples/sec; 0.158 sec/batch; 11h:32m:28s remains)
INFO - root - 2017-12-01 05:36:49.190049: step 68890, loss = 0.36, batch loss = 0.21 (48.1 examples/sec; 0.166 sec/batch; 12h:10m:18s remains)
INFO - root - 2017-12-01 05:36:50.798594: step 68900, loss = 0.39, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 11h:34m:51s remains)
INFO - root - 2017-12-01 05:36:52.402780: step 68910, loss = 0.35, batch loss = 0.20 (53.8 examples/sec; 0.149 sec/batch; 10h:53m:45s remains)
INFO - root - 2017-12-01 05:36:53.987665: step 68920, loss = 0.52, batch loss = 0.37 (51.4 examples/sec; 0.156 sec/batch; 11h:24m:04s remains)
INFO - root - 2017-12-01 05:36:55.544634: step 68930, loss = 0.35, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 11h:31m:30s remains)
INFO - root - 2017-12-01 05:36:57.084058: step 68940, loss = 0.38, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 11h:27m:57s remains)
INFO - root - 2017-12-01 05:36:58.648654: step 68950, loss = 0.38, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 11h:20m:39s remains)
INFO - root - 2017-12-01 05:37:00.202830: step 68960, loss = 0.53, batch loss = 0.38 (48.3 examples/sec; 0.165 sec/batch; 12h:06m:47s remains)
INFO - root - 2017-12-01 05:37:01.782038: step 68970, loss = 0.46, batch loss = 0.30 (52.5 examples/sec; 0.152 sec/batch; 11h:09m:46s remains)
INFO - root - 2017-12-01 05:37:03.341231: step 68980, loss = 0.37, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 11h:12m:06s remains)
INFO - root - 2017-12-01 05:37:04.902502: step 68990, loss = 0.37, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 11h:27m:52s remains)
INFO - root - 2017-12-01 05:37:06.467426: step 69000, loss = 0.36, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 11h:16m:49s remains)
INFO - root - 2017-12-01 05:37:08.095642: step 69010, loss = 0.48, batch loss = 0.32 (51.4 examples/sec; 0.156 sec/batch; 11h:23m:13s remains)
INFO - root - 2017-12-01 05:37:09.655722: step 69020, loss = 0.42, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 11h:22m:05s remains)
INFO - root - 2017-12-01 05:37:11.245636: step 69030, loss = 0.42, batch loss = 0.26 (48.8 examples/sec; 0.164 sec/batch; 11h:59m:42s remains)
INFO - root - 2017-12-01 05:37:12.827299: step 69040, loss = 0.35, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 11h:32m:09s remains)
INFO - root - 2017-12-01 05:37:14.469265: step 69050, loss = 0.40, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 11h:17m:33s remains)
INFO - root - 2017-12-01 05:37:16.031708: step 69060, loss = 0.39, batch loss = 0.23 (52.9 examples/sec; 0.151 sec/batch; 11h:04m:37s remains)
INFO - root - 2017-12-01 05:37:17.589142: step 69070, loss = 0.34, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 11h:30m:45s remains)
INFO - root - 2017-12-01 05:37:19.158669: step 69080, loss = 0.47, batch loss = 0.32 (51.1 examples/sec; 0.157 sec/batch; 11h:27m:09s remains)
INFO - root - 2017-12-01 05:37:20.725525: step 69090, loss = 0.35, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 11h:33m:47s remains)
INFO - root - 2017-12-01 05:37:22.273799: step 69100, loss = 0.36, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 11h:40m:01s remains)
INFO - root - 2017-12-01 05:37:23.929830: step 69110, loss = 0.36, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 11h:44m:20s remains)
INFO - root - 2017-12-01 05:37:25.497066: step 69120, loss = 0.43, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 11h:38m:18s remains)
INFO - root - 2017-12-01 05:37:27.051654: step 69130, loss = 0.35, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 11h:41m:59s remains)
INFO - root - 2017-12-01 05:37:28.623032: step 69140, loss = 0.42, batch loss = 0.26 (51.8 examples/sec; 0.155 sec/batch; 11h:18m:12s remains)
INFO - root - 2017-12-01 05:37:30.195087: step 69150, loss = 0.46, batch loss = 0.30 (52.8 examples/sec; 0.151 sec/batch; 11h:04m:48s remains)
INFO - root - 2017-12-01 05:37:31.758508: step 69160, loss = 0.40, batch loss = 0.24 (50.8 examples/sec; 0.158 sec/batch; 11h:31m:45s remains)
INFO - root - 2017-12-01 05:37:33.328366: step 69170, loss = 0.61, batch loss = 0.45 (50.9 examples/sec; 0.157 sec/batch; 11h:30m:22s remains)
INFO - root - 2017-12-01 05:37:34.897519: step 69180, loss = 0.49, batch loss = 0.33 (50.9 examples/sec; 0.157 sec/batch; 11h:30m:18s remains)
INFO - root - 2017-12-01 05:37:36.455391: step 69190, loss = 0.45, batch loss = 0.30 (52.4 examples/sec; 0.153 sec/batch; 11h:09m:46s remains)
INFO - root - 2017-12-01 05:37:38.043732: step 69200, loss = 0.53, batch loss = 0.38 (50.9 examples/sec; 0.157 sec/batch; 11h:29m:29s remains)
INFO - root - 2017-12-01 05:37:39.638681: step 69210, loss = 0.43, batch loss = 0.28 (53.1 examples/sec; 0.151 sec/batch; 11h:00m:58s remains)
INFO - root - 2017-12-01 05:37:41.209218: step 69220, loss = 0.37, batch loss = 0.22 (52.4 examples/sec; 0.153 sec/batch; 11h:09m:25s remains)
INFO - root - 2017-12-01 05:37:42.810631: step 69230, loss = 0.53, batch loss = 0.37 (51.2 examples/sec; 0.156 sec/batch; 11h:25m:33s remains)
INFO - root - 2017-12-01 05:37:44.369276: step 69240, loss = 0.47, batch loss = 0.31 (50.0 examples/sec; 0.160 sec/batch; 11h:42m:43s remains)
INFO - root - 2017-12-01 05:37:45.925798: step 69250, loss = 0.38, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 11h:12m:09s remains)
INFO - root - 2017-12-01 05:37:47.505649: step 69260, loss = 0.40, batch loss = 0.24 (50.8 examples/sec; 0.157 sec/batch; 11h:30m:28s remains)
INFO - root - 2017-12-01 05:37:49.067443: step 69270, loss = 0.38, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 11h:12m:23s remains)
INFO - root - 2017-12-01 05:37:50.671684: step 69280, loss = 0.35, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 11h:28m:41s remains)
INFO - root - 2017-12-01 05:37:52.242363: step 69290, loss = 0.37, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 11h:23m:02s remains)
INFO - root - 2017-12-01 05:37:53.798617: step 69300, loss = 0.39, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 11h:19m:28s remains)
INFO - root - 2017-12-01 05:37:55.442496: step 69310, loss = 0.33, batch loss = 0.18 (51.1 examples/sec; 0.156 sec/batch; 11h:26m:14s remains)
INFO - root - 2017-12-01 05:37:57.033248: step 69320, loss = 0.47, batch loss = 0.31 (51.8 examples/sec; 0.154 sec/batch; 11h:17m:32s remains)
INFO - root - 2017-12-01 05:37:58.580685: step 69330, loss = 0.31, batch loss = 0.16 (52.2 examples/sec; 0.153 sec/batch; 11h:12m:00s remains)
INFO - root - 2017-12-01 05:38:00.144004: step 69340, loss = 0.43, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 11h:19m:40s remains)
INFO - root - 2017-12-01 05:38:01.713841: step 69350, loss = 0.35, batch loss = 0.19 (48.8 examples/sec; 0.164 sec/batch; 11h:59m:17s remains)
INFO - root - 2017-12-01 05:38:03.274758: step 69360, loss = 0.42, batch loss = 0.27 (53.5 examples/sec; 0.150 sec/batch; 10h:56m:17s remains)
INFO - root - 2017-12-01 05:38:04.845877: step 69370, loss = 0.42, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 11h:33m:28s remains)
INFO - root - 2017-12-01 05:38:06.409385: step 69380, loss = 0.31, batch loss = 0.16 (50.8 examples/sec; 0.157 sec/batch; 11h:30m:14s remains)
INFO - root - 2017-12-01 05:38:07.967029: step 69390, loss = 0.42, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 11h:36m:04s remains)
INFO - root - 2017-12-01 05:38:09.517590: step 69400, loss = 0.36, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 11h:21m:54s remains)
INFO - root - 2017-12-01 05:38:11.149480: step 69410, loss = 0.48, batch loss = 0.33 (52.2 examples/sec; 0.153 sec/batch; 11h:12m:13s remains)
INFO - root - 2017-12-01 05:38:12.702033: step 69420, loss = 0.41, batch loss = 0.26 (52.3 examples/sec; 0.153 sec/batch; 11h:10m:45s remains)
INFO - root - 2017-12-01 05:38:14.264253: step 69430, loss = 0.43, batch loss = 0.28 (50.0 examples/sec; 0.160 sec/batch; 11h:41m:07s remains)
INFO - root - 2017-12-01 05:38:15.812650: step 69440, loss = 0.37, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 11h:18m:54s remains)
INFO - root - 2017-12-01 05:38:17.352390: step 69450, loss = 0.31, batch loss = 0.16 (52.4 examples/sec; 0.153 sec/batch; 11h:09m:01s remains)
INFO - root - 2017-12-01 05:38:18.922267: step 69460, loss = 0.43, batch loss = 0.27 (50.1 examples/sec; 0.160 sec/batch; 11h:40m:07s remains)
INFO - root - 2017-12-01 05:38:20.510066: step 69470, loss = 0.33, batch loss = 0.17 (51.1 examples/sec; 0.156 sec/batch; 11h:25m:56s remains)
INFO - root - 2017-12-01 05:38:22.074085: step 69480, loss = 0.38, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 11h:20m:54s remains)
INFO - root - 2017-12-01 05:38:23.629925: step 69490, loss = 0.41, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 11h:32m:40s remains)
INFO - root - 2017-12-01 05:38:25.203750: step 69500, loss = 0.38, batch loss = 0.23 (47.6 examples/sec; 0.168 sec/batch; 12h:17m:23s remains)
INFO - root - 2017-12-01 05:38:26.823038: step 69510, loss = 0.33, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 11h:14m:08s remains)
INFO - root - 2017-12-01 05:38:28.378309: step 69520, loss = 0.51, batch loss = 0.36 (50.9 examples/sec; 0.157 sec/batch; 11h:29m:16s remains)
INFO - root - 2017-12-01 05:38:30.205348: step 69530, loss = 0.33, batch loss = 0.18 (20.2 examples/sec; 0.397 sec/batch; 28h:59m:49s remains)
INFO - root - 2017-12-01 05:38:31.765078: step 69540, loss = 0.61, batch loss = 0.46 (50.8 examples/sec; 0.157 sec/batch; 11h:29m:50s remains)
INFO - root - 2017-12-01 05:38:33.323251: step 69550, loss = 0.39, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 11h:23m:19s remains)
INFO - root - 2017-12-01 05:38:34.884224: step 69560, loss = 0.48, batch loss = 0.33 (51.9 examples/sec; 0.154 sec/batch; 11h:15m:28s remains)
INFO - root - 2017-12-01 05:38:36.444224: step 69570, loss = 0.36, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 11h:23m:38s remains)
INFO - root - 2017-12-01 05:38:37.994182: step 69580, loss = 0.39, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 11h:36m:39s remains)
INFO - root - 2017-12-01 05:38:39.565955: step 69590, loss = 0.36, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 11h:07m:04s remains)
INFO - root - 2017-12-01 05:38:41.132148: step 69600, loss = 0.40, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 11h:21m:50s remains)
INFO - root - 2017-12-01 05:38:42.836916: step 69610, loss = 0.48, batch loss = 0.32 (49.2 examples/sec; 0.163 sec/batch; 11h:52m:54s remains)
INFO - root - 2017-12-01 05:38:44.401165: step 69620, loss = 0.51, batch loss = 0.36 (52.2 examples/sec; 0.153 sec/batch; 11h:11m:42s remains)
INFO - root - 2017-12-01 05:38:45.987964: step 69630, loss = 0.39, batch loss = 0.24 (51.8 examples/sec; 0.155 sec/batch; 11h:17m:08s remains)
INFO - root - 2017-12-01 05:38:47.546284: step 69640, loss = 0.31, batch loss = 0.15 (52.5 examples/sec; 0.152 sec/batch; 11h:07m:57s remains)
INFO - root - 2017-12-01 05:38:49.116695: step 69650, loss = 0.42, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 11h:33m:59s remains)
INFO - root - 2017-12-01 05:38:50.686786: step 69660, loss = 0.48, batch loss = 0.32 (49.3 examples/sec; 0.162 sec/batch; 11h:50m:53s remains)
INFO - root - 2017-12-01 05:38:52.281813: step 69670, loss = 0.35, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 11h:14m:05s remains)
INFO - root - 2017-12-01 05:38:53.849460: step 69680, loss = 0.40, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 11h:28m:27s remains)
INFO - root - 2017-12-01 05:38:55.408291: step 69690, loss = 0.40, batch loss = 0.24 (50.8 examples/sec; 0.157 sec/batch; 11h:29m:47s remains)
INFO - root - 2017-12-01 05:38:56.979124: step 69700, loss = 0.38, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 11h:08m:23s remains)
INFO - root - 2017-12-01 05:38:58.607885: step 69710, loss = 0.57, batch loss = 0.42 (51.7 examples/sec; 0.155 sec/batch; 11h:17m:36s remains)
INFO - root - 2017-12-01 05:39:00.180240: step 69720, loss = 0.36, batch loss = 0.20 (48.6 examples/sec; 0.164 sec/batch; 12h:00m:24s remains)
INFO - root - 2017-12-01 05:39:01.734362: step 69730, loss = 0.31, batch loss = 0.15 (50.6 examples/sec; 0.158 sec/batch; 11h:32m:32s remains)
INFO - root - 2017-12-01 05:39:03.288050: step 69740, loss = 0.38, batch loss = 0.23 (53.9 examples/sec; 0.149 sec/batch; 10h:50m:30s remains)
INFO - root - 2017-12-01 05:39:04.844067: step 69750, loss = 0.50, batch loss = 0.35 (52.2 examples/sec; 0.153 sec/batch; 11h:10m:43s remains)
INFO - root - 2017-12-01 05:39:06.445773: step 69760, loss = 0.41, batch loss = 0.25 (50.5 examples/sec; 0.158 sec/batch; 11h:34m:00s remains)
INFO - root - 2017-12-01 05:39:08.011859: step 69770, loss = 0.40, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 11h:24m:01s remains)
INFO - root - 2017-12-01 05:39:09.575974: step 69780, loss = 0.34, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 11h:07m:22s remains)
INFO - root - 2017-12-01 05:39:11.171623: step 69790, loss = 0.41, batch loss = 0.25 (50.0 examples/sec; 0.160 sec/batch; 11h:40m:02s remains)
INFO - root - 2017-12-01 05:39:12.751285: step 69800, loss = 0.37, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 11h:31m:58s remains)
INFO - root - 2017-12-01 05:39:14.395117: step 69810, loss = 0.37, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 11h:20m:29s remains)
INFO - root - 2017-12-01 05:39:15.959646: step 69820, loss = 0.41, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 11h:23m:52s remains)
INFO - root - 2017-12-01 05:39:17.515908: step 69830, loss = 0.34, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 11h:32m:57s remains)
INFO - root - 2017-12-01 05:39:19.074228: step 69840, loss = 0.35, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 11h:09m:32s remains)
INFO - root - 2017-12-01 05:39:20.657102: step 69850, loss = 0.36, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 11h:40m:30s remains)
INFO - root - 2017-12-01 05:39:22.209026: step 69860, loss = 0.37, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 11h:06m:00s remains)
INFO - root - 2017-12-01 05:39:23.781070: step 69870, loss = 0.30, batch loss = 0.14 (50.9 examples/sec; 0.157 sec/batch; 11h:28m:05s remains)
INFO - root - 2017-12-01 05:39:25.348608: step 69880, loss = 0.41, batch loss = 0.25 (49.5 examples/sec; 0.161 sec/batch; 11h:46m:51s remains)
INFO - root - 2017-12-01 05:39:26.909933: step 69890, loss = 0.35, batch loss = 0.20 (53.3 examples/sec; 0.150 sec/batch; 10h:57m:11s remains)
INFO - root - 2017-12-01 05:39:28.478099: step 69900, loss = 0.31, batch loss = 0.16 (52.6 examples/sec; 0.152 sec/batch; 11h:05m:37s remains)
INFO - root - 2017-12-01 05:39:30.088876: step 69910, loss = 0.38, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 11h:20m:16s remains)
INFO - root - 2017-12-01 05:39:31.638169: step 69920, loss = 0.38, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 11h:21m:06s remains)
INFO - root - 2017-12-01 05:39:33.198520: step 69930, loss = 0.37, batch loss = 0.22 (52.1 examples/sec; 0.153 sec/batch; 11h:11m:32s remains)
INFO - root - 2017-12-01 05:39:34.771394: step 69940, loss = 0.37, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 11h:17m:29s remains)
INFO - root - 2017-12-01 05:39:36.314148: step 69950, loss = 0.42, batch loss = 0.26 (52.5 examples/sec; 0.152 sec/batch; 11h:06m:40s remains)
INFO - root - 2017-12-01 05:39:37.887970: step 69960, loss = 0.38, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 11h:29m:41s remains)
INFO - root - 2017-12-01 05:39:39.461330: step 69970, loss = 0.30, batch loss = 0.14 (50.3 examples/sec; 0.159 sec/batch; 11h:36m:17s remains)
INFO - root - 2017-12-01 05:39:41.029899: step 69980, loss = 0.35, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 11h:38m:17s remains)
INFO - root - 2017-12-01 05:39:42.612799: step 69990, loss = 0.39, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 11h:09m:49s remains)
INFO - root - 2017-12-01 05:39:44.192967: step 70000, loss = 0.39, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 11h:23m:07s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-70000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-70000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-01 05:39:46.108641: step 70010, loss = 0.51, batch loss = 0.35 (50.8 examples/sec; 0.157 sec/batch; 11h:28m:51s remains)
INFO - root - 2017-12-01 05:39:47.652304: step 70020, loss = 0.34, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 11h:23m:59s remains)
INFO - root - 2017-12-01 05:39:49.240766: step 70030, loss = 0.37, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 11h:22m:59s remains)
INFO - root - 2017-12-01 05:39:50.806948: step 70040, loss = 0.38, batch loss = 0.22 (48.9 examples/sec; 0.164 sec/batch; 11h:56m:09s remains)
INFO - root - 2017-12-01 05:39:52.360352: step 70050, loss = 0.40, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 11h:41m:56s remains)
INFO - root - 2017-12-01 05:39:53.927014: step 70060, loss = 0.39, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 11h:14m:26s remains)
INFO - root - 2017-12-01 05:39:55.490341: step 70070, loss = 0.37, batch loss = 0.22 (53.1 examples/sec; 0.151 sec/batch; 10h:59m:04s remains)
INFO - root - 2017-12-01 05:39:57.038535: step 70080, loss = 0.43, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 11h:13m:59s remains)
INFO - root - 2017-12-01 05:39:58.587740: step 70090, loss = 0.39, batch loss = 0.23 (52.9 examples/sec; 0.151 sec/batch; 11h:01m:17s remains)
INFO - root - 2017-12-01 05:40:00.173653: step 70100, loss = 0.55, batch loss = 0.40 (51.8 examples/sec; 0.154 sec/batch; 11h:14m:51s remains)
INFO - root - 2017-12-01 05:40:01.817136: step 70110, loss = 0.61, batch loss = 0.45 (51.2 examples/sec; 0.156 sec/batch; 11h:23m:12s remains)
INFO - root - 2017-12-01 05:40:03.378646: step 70120, loss = 0.41, batch loss = 0.26 (51.1 examples/sec; 0.156 sec/batch; 11h:24m:05s remains)
INFO - root - 2017-12-01 05:40:04.915722: step 70130, loss = 0.46, batch loss = 0.31 (50.8 examples/sec; 0.158 sec/batch; 11h:28m:49s remains)
INFO - root - 2017-12-01 05:40:06.467597: step 70140, loss = 0.43, batch loss = 0.27 (52.9 examples/sec; 0.151 sec/batch; 11h:00m:46s remains)
INFO - root - 2017-12-01 05:40:08.021096: step 70150, loss = 0.39, batch loss = 0.23 (49.3 examples/sec; 0.162 sec/batch; 11h:49m:51s remains)
INFO - root - 2017-12-01 05:40:09.590665: step 70160, loss = 0.33, batch loss = 0.18 (49.4 examples/sec; 0.162 sec/batch; 11h:47m:31s remains)
INFO - root - 2017-12-01 05:40:11.169465: step 70170, loss = 0.39, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 11h:16m:59s remains)
INFO - root - 2017-12-01 05:40:12.721584: step 70180, loss = 0.45, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 11h:18m:41s remains)
INFO - root - 2017-12-01 05:40:14.285663: step 70190, loss = 0.30, batch loss = 0.15 (49.7 examples/sec; 0.161 sec/batch; 11h:43m:06s remains)
INFO - root - 2017-12-01 05:40:15.850783: step 70200, loss = 0.39, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 11h:15m:19s remains)
INFO - root - 2017-12-01 05:40:17.473503: step 70210, loss = 0.34, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 11h:24m:13s remains)
INFO - root - 2017-12-01 05:40:19.031837: step 70220, loss = 0.30, batch loss = 0.15 (51.2 examples/sec; 0.156 sec/batch; 11h:22m:21s remains)
INFO - root - 2017-12-01 05:40:20.622645: step 70230, loss = 0.38, batch loss = 0.22 (48.5 examples/sec; 0.165 sec/batch; 12h:01m:00s remains)
INFO - root - 2017-12-01 05:40:22.208826: step 70240, loss = 0.33, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 11h:17m:47s remains)
INFO - root - 2017-12-01 05:40:23.795802: step 70250, loss = 0.37, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 11h:26m:47s remains)
INFO - root - 2017-12-01 05:40:25.378477: step 70260, loss = 0.38, batch loss = 0.22 (47.7 examples/sec; 0.168 sec/batch; 12h:12m:41s remains)
INFO - root - 2017-12-01 05:40:26.943517: step 70270, loss = 0.33, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 11h:22m:53s remains)
INFO - root - 2017-12-01 05:40:28.510852: step 70280, loss = 0.35, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 11h:26m:49s remains)
INFO - root - 2017-12-01 05:40:30.076916: step 70290, loss = 0.40, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 11h:15m:10s remains)
INFO - root - 2017-12-01 05:40:31.631676: step 70300, loss = 0.36, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 11h:11m:23s remains)
INFO - root - 2017-12-01 05:40:33.283511: step 70310, loss = 0.38, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 11h:36m:45s remains)
INFO - root - 2017-12-01 05:40:34.830851: step 70320, loss = 0.33, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 11h:14m:07s remains)
INFO - root - 2017-12-01 05:40:36.377014: step 70330, loss = 0.45, batch loss = 0.30 (50.8 examples/sec; 0.158 sec/batch; 11h:28m:25s remains)
INFO - root - 2017-12-01 05:40:37.929406: step 70340, loss = 0.54, batch loss = 0.39 (52.6 examples/sec; 0.152 sec/batch; 11h:04m:24s remains)
INFO - root - 2017-12-01 05:40:39.487535: step 70350, loss = 0.37, batch loss = 0.21 (52.8 examples/sec; 0.152 sec/batch; 11h:01m:58s remains)
INFO - root - 2017-12-01 05:40:41.065497: step 70360, loss = 0.35, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 11h:12m:07s remains)
INFO - root - 2017-12-01 05:40:42.634946: step 70370, loss = 0.42, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 11h:29m:00s remains)
INFO - root - 2017-12-01 05:40:44.195008: step 70380, loss = 0.39, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 11h:33m:42s remains)
INFO - root - 2017-12-01 05:40:45.755744: step 70390, loss = 0.34, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 11h:13m:33s remains)
INFO - root - 2017-12-01 05:40:47.318264: step 70400, loss = 0.40, batch loss = 0.25 (48.8 examples/sec; 0.164 sec/batch; 11h:56m:35s remains)
INFO - root - 2017-12-01 05:40:48.971705: step 70410, loss = 0.33, batch loss = 0.18 (49.4 examples/sec; 0.162 sec/batch; 11h:46m:43s remains)
INFO - root - 2017-12-01 05:40:50.536290: step 70420, loss = 0.53, batch loss = 0.38 (53.1 examples/sec; 0.151 sec/batch; 10h:57m:37s remains)
INFO - root - 2017-12-01 05:40:52.093836: step 70430, loss = 0.40, batch loss = 0.25 (52.6 examples/sec; 0.152 sec/batch; 11h:03m:50s remains)
INFO - root - 2017-12-01 05:40:53.656597: step 70440, loss = 0.35, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 11h:12m:44s remains)
INFO - root - 2017-12-01 05:40:55.227309: step 70450, loss = 0.36, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 11h:25m:04s remains)
INFO - root - 2017-12-01 05:40:56.774788: step 70460, loss = 0.35, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 11h:35m:40s remains)
INFO - root - 2017-12-01 05:40:58.336487: step 70470, loss = 0.41, batch loss = 0.25 (49.5 examples/sec; 0.162 sec/batch; 11h:45m:55s remains)
INFO - root - 2017-12-01 05:40:59.910887: step 70480, loss = 0.54, batch loss = 0.39 (52.9 examples/sec; 0.151 sec/batch; 10h:59m:52s remains)
INFO - root - 2017-12-01 05:41:01.482801: step 70490, loss = 0.33, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 11h:08m:25s remains)
INFO - root - 2017-12-01 05:41:03.056352: step 70500, loss = 0.36, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 11h:34m:22s remains)
INFO - root - 2017-12-01 05:41:04.692119: step 70510, loss = 0.37, batch loss = 0.21 (49.2 examples/sec; 0.163 sec/batch; 11h:49m:39s remains)
INFO - root - 2017-12-01 05:41:06.254959: step 70520, loss = 0.47, batch loss = 0.32 (52.5 examples/sec; 0.152 sec/batch; 11h:04m:48s remains)
INFO - root - 2017-12-01 05:41:07.844692: step 70530, loss = 0.33, batch loss = 0.18 (49.7 examples/sec; 0.161 sec/batch; 11h:42m:27s remains)
INFO - root - 2017-12-01 05:41:09.401266: step 70540, loss = 0.37, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 11h:15m:44s remains)
INFO - root - 2017-12-01 05:41:10.987234: step 70550, loss = 0.43, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 11h:33m:49s remains)
INFO - root - 2017-12-01 05:41:12.554831: step 70560, loss = 0.52, batch loss = 0.37 (51.4 examples/sec; 0.156 sec/batch; 11h:19m:22s remains)
INFO - root - 2017-12-01 05:41:14.106962: step 70570, loss = 0.33, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 11h:32m:38s remains)
INFO - root - 2017-12-01 05:41:15.656783: step 70580, loss = 0.37, batch loss = 0.21 (49.6 examples/sec; 0.161 sec/batch; 11h:44m:07s remains)
INFO - root - 2017-12-01 05:41:17.219708: step 70590, loss = 0.36, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 11h:22m:34s remains)
INFO - root - 2017-12-01 05:41:18.791173: step 70600, loss = 0.41, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 11h:28m:51s remains)
INFO - root - 2017-12-01 05:41:20.403045: step 70610, loss = 0.51, batch loss = 0.35 (53.5 examples/sec; 0.150 sec/batch; 10h:53m:09s remains)
INFO - root - 2017-12-01 05:41:21.962117: step 70620, loss = 0.36, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 11h:06m:27s remains)
INFO - root - 2017-12-01 05:41:23.533959: step 70630, loss = 0.43, batch loss = 0.28 (52.4 examples/sec; 0.153 sec/batch; 11h:06m:33s remains)
INFO - root - 2017-12-01 05:41:25.117744: step 70640, loss = 0.40, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 11h:19m:35s remains)
INFO - root - 2017-12-01 05:41:26.698023: step 70650, loss = 0.43, batch loss = 0.28 (48.6 examples/sec; 0.165 sec/batch; 11h:58m:57s remains)
INFO - root - 2017-12-01 05:41:28.260186: step 70660, loss = 0.31, batch loss = 0.16 (53.0 examples/sec; 0.151 sec/batch; 10h:59m:08s remains)
INFO - root - 2017-12-01 05:41:29.819104: step 70670, loss = 0.40, batch loss = 0.25 (52.7 examples/sec; 0.152 sec/batch; 11h:02m:41s remains)
INFO - root - 2017-12-01 05:41:31.393778: step 70680, loss = 0.33, batch loss = 0.17 (51.8 examples/sec; 0.154 sec/batch; 11h:13m:49s remains)
INFO - root - 2017-12-01 05:41:32.958574: step 70690, loss = 0.37, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 11h:27m:30s remains)
INFO - root - 2017-12-01 05:41:34.521776: step 70700, loss = 0.37, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 11h:36m:58s remains)
INFO - root - 2017-12-01 05:41:36.180711: step 70710, loss = 0.41, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 11h:15m:49s remains)
INFO - root - 2017-12-01 05:41:37.727879: step 70720, loss = 0.42, batch loss = 0.27 (50.8 examples/sec; 0.157 sec/batch; 11h:27m:09s remains)
INFO - root - 2017-12-01 05:41:39.285604: step 70730, loss = 0.36, batch loss = 0.21 (51.8 examples/sec; 0.155 sec/batch; 11h:14m:05s remains)
INFO - root - 2017-12-01 05:41:40.853103: step 70740, loss = 0.32, batch loss = 0.16 (52.5 examples/sec; 0.152 sec/batch; 11h:04m:57s remains)
INFO - root - 2017-12-01 05:41:42.419029: step 70750, loss = 0.31, batch loss = 0.15 (50.9 examples/sec; 0.157 sec/batch; 11h:25m:21s remains)
INFO - root - 2017-12-01 05:41:43.997168: step 70760, loss = 0.41, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 11h:18m:58s remains)
INFO - root - 2017-12-01 05:41:45.550146: step 70770, loss = 0.35, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 11h:27m:23s remains)
INFO - root - 2017-12-01 05:41:47.114746: step 70780, loss = 0.39, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 11h:21m:03s remains)
INFO - root - 2017-12-01 05:41:48.677060: step 70790, loss = 0.36, batch loss = 0.20 (52.9 examples/sec; 0.151 sec/batch; 10h:59m:43s remains)
INFO - root - 2017-12-01 05:41:50.240441: step 70800, loss = 0.51, batch loss = 0.35 (51.6 examples/sec; 0.155 sec/batch; 11h:16m:50s remains)
INFO - root - 2017-12-01 05:41:51.846692: step 70810, loss = 0.33, batch loss = 0.18 (51.1 examples/sec; 0.156 sec/batch; 11h:22m:24s remains)
INFO - root - 2017-12-01 05:41:53.403110: step 70820, loss = 0.36, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 11h:24m:40s remains)
INFO - root - 2017-12-01 05:41:54.969027: step 70830, loss = 0.34, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 11h:23m:48s remains)
INFO - root - 2017-12-01 05:41:56.530008: step 70840, loss = 0.41, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 11h:08m:54s remains)
INFO - root - 2017-12-01 05:41:58.076251: step 70850, loss = 0.34, batch loss = 0.19 (52.1 examples/sec; 0.154 sec/batch; 11h:10m:01s remains)
INFO - root - 2017-12-01 05:41:59.630538: step 70860, loss = 0.41, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 11h:13m:01s remains)
INFO - root - 2017-12-01 05:42:01.200366: step 70870, loss = 0.39, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 11h:34m:06s remains)
INFO - root - 2017-12-01 05:42:02.756460: step 70880, loss = 0.34, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 11h:12m:01s remains)
INFO - root - 2017-12-01 05:42:04.318988: step 70890, loss = 0.37, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 11h:36m:05s remains)
INFO - root - 2017-12-01 05:42:05.890479: step 70900, loss = 0.38, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 11h:12m:01s remains)
INFO - root - 2017-12-01 05:42:07.487740: step 70910, loss = 0.35, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 11h:11m:36s remains)
INFO - root - 2017-12-01 05:42:09.049946: step 70920, loss = 0.40, batch loss = 0.24 (52.4 examples/sec; 0.153 sec/batch; 11h:05m:51s remains)
INFO - root - 2017-12-01 05:42:10.611864: step 70930, loss = 0.36, batch loss = 0.21 (53.8 examples/sec; 0.149 sec/batch; 10h:48m:27s remains)
INFO - root - 2017-12-01 05:42:12.181767: step 70940, loss = 0.38, batch loss = 0.22 (53.0 examples/sec; 0.151 sec/batch; 10h:57m:52s remains)
INFO - root - 2017-12-01 05:42:13.761139: step 70950, loss = 0.37, batch loss = 0.22 (49.6 examples/sec; 0.161 sec/batch; 11h:42m:42s remains)
INFO - root - 2017-12-01 05:42:15.323531: step 70960, loss = 0.39, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 11h:02m:34s remains)
INFO - root - 2017-12-01 05:42:16.875956: step 70970, loss = 0.35, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 11h:07m:50s remains)
INFO - root - 2017-12-01 05:42:18.472857: step 70980, loss = 0.44, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 11h:11m:55s remains)
INFO - root - 2017-12-01 05:42:20.025623: step 70990, loss = 0.35, batch loss = 0.19 (51.1 examples/sec; 0.156 sec/batch; 11h:21m:56s remains)
INFO - root - 2017-12-01 05:42:21.589352: step 71000, loss = 0.34, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 11h:44m:16s remains)
INFO - root - 2017-12-01 05:42:23.237742: step 71010, loss = 0.39, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 11h:21m:32s remains)
INFO - root - 2017-12-01 05:42:24.797678: step 71020, loss = 0.47, batch loss = 0.32 (52.2 examples/sec; 0.153 sec/batch; 11h:08m:12s remains)
INFO - root - 2017-12-01 05:42:26.383210: step 71030, loss = 0.57, batch loss = 0.41 (48.8 examples/sec; 0.164 sec/batch; 11h:54m:18s remains)
INFO - root - 2017-12-01 05:42:27.993652: step 71040, loss = 0.38, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 11h:33m:03s remains)
INFO - root - 2017-12-01 05:42:29.579196: step 71050, loss = 0.40, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 11h:31m:42s remains)
INFO - root - 2017-12-01 05:42:31.126287: step 71060, loss = 0.38, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 11h:13m:53s remains)
INFO - root - 2017-12-01 05:42:32.693092: step 71070, loss = 0.50, batch loss = 0.34 (49.7 examples/sec; 0.161 sec/batch; 11h:41m:59s remains)
INFO - root - 2017-12-01 05:42:34.282278: step 71080, loss = 0.38, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 11h:19m:23s remains)
INFO - root - 2017-12-01 05:42:35.834795: step 71090, loss = 0.46, batch loss = 0.31 (51.1 examples/sec; 0.157 sec/batch; 11h:22m:08s remains)
INFO - root - 2017-12-01 05:42:37.422292: step 71100, loss = 0.40, batch loss = 0.25 (50.8 examples/sec; 0.158 sec/batch; 11h:26m:20s remains)
INFO - root - 2017-12-01 05:42:39.104742: step 71110, loss = 0.33, batch loss = 0.18 (49.6 examples/sec; 0.161 sec/batch; 11h:42m:27s remains)
INFO - root - 2017-12-01 05:42:40.700947: step 71120, loss = 0.33, batch loss = 0.18 (48.0 examples/sec; 0.167 sec/batch; 12h:06m:41s remains)
INFO - root - 2017-12-01 05:42:42.271012: step 71130, loss = 0.43, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 11h:10m:17s remains)
INFO - root - 2017-12-01 05:42:43.850195: step 71140, loss = 0.37, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 11h:23m:57s remains)
INFO - root - 2017-12-01 05:42:45.413311: step 71150, loss = 0.34, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 11h:18m:53s remains)
INFO - root - 2017-12-01 05:42:46.982029: step 71160, loss = 0.39, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 11h:17m:05s remains)
INFO - root - 2017-12-01 05:42:48.561675: step 71170, loss = 0.40, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 11h:24m:24s remains)
INFO - root - 2017-12-01 05:42:50.111023: step 71180, loss = 0.41, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 11h:00m:33s remains)
INFO - root - 2017-12-01 05:42:51.661929: step 71190, loss = 0.41, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 11h:17m:55s remains)
INFO - root - 2017-12-01 05:42:53.220941: step 71200, loss = 0.39, batch loss = 0.24 (50.8 examples/sec; 0.158 sec/batch; 11h:26m:22s remains)
INFO - root - 2017-12-01 05:42:54.855293: step 71210, loss = 0.54, batch loss = 0.39 (50.5 examples/sec; 0.158 sec/batch; 11h:29m:48s remains)
INFO - root - 2017-12-01 05:42:56.411170: step 71220, loss = 0.36, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 11h:26m:52s remains)
INFO - root - 2017-12-01 05:42:57.980170: step 71230, loss = 0.31, batch loss = 0.15 (51.7 examples/sec; 0.155 sec/batch; 11h:13m:30s remains)
INFO - root - 2017-12-01 05:42:59.549187: step 71240, loss = 0.38, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 11h:01m:27s remains)
INFO - root - 2017-12-01 05:43:01.113718: step 71250, loss = 0.38, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 11h:19m:08s remains)
INFO - root - 2017-12-01 05:43:02.678289: step 71260, loss = 0.43, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 11h:16m:20s remains)
INFO - root - 2017-12-01 05:43:04.240700: step 71270, loss = 0.36, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 11h:10m:43s remains)
INFO - root - 2017-12-01 05:43:05.803586: step 71280, loss = 0.44, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 11h:16m:08s remains)
INFO - root - 2017-12-01 05:43:07.375033: step 71290, loss = 0.35, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 11h:36m:09s remains)
INFO - root - 2017-12-01 05:43:08.947267: step 71300, loss = 0.48, batch loss = 0.33 (52.6 examples/sec; 0.152 sec/batch; 11h:01m:43s remains)
INFO - root - 2017-12-01 05:43:10.572062: step 71310, loss = 0.51, batch loss = 0.36 (48.3 examples/sec; 0.165 sec/batch; 12h:00m:26s remains)
INFO - root - 2017-12-01 05:43:12.151723: step 71320, loss = 0.36, batch loss = 0.21 (53.1 examples/sec; 0.151 sec/batch; 10h:55m:29s remains)
INFO - root - 2017-12-01 05:43:13.716359: step 71330, loss = 0.44, batch loss = 0.29 (50.5 examples/sec; 0.158 sec/batch; 11h:29m:08s remains)
INFO - root - 2017-12-01 05:43:15.295431: step 71340, loss = 0.28, batch loss = 0.12 (51.7 examples/sec; 0.155 sec/batch; 11h:13m:37s remains)
INFO - root - 2017-12-01 05:43:16.852824: step 71350, loss = 0.35, batch loss = 0.20 (49.7 examples/sec; 0.161 sec/batch; 11h:41m:18s remains)
INFO - root - 2017-12-01 05:43:18.418279: step 71360, loss = 0.39, batch loss = 0.24 (50.8 examples/sec; 0.158 sec/batch; 11h:25m:39s remains)
INFO - root - 2017-12-01 05:43:19.993530: step 71370, loss = 0.47, batch loss = 0.32 (51.2 examples/sec; 0.156 sec/batch; 11h:19m:41s remains)
INFO - root - 2017-12-01 05:43:21.556298: step 71380, loss = 0.44, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 11h:23m:55s remains)
INFO - root - 2017-12-01 05:43:23.107880: step 71390, loss = 0.43, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 11h:15m:06s remains)
INFO - root - 2017-12-01 05:43:24.678139: step 71400, loss = 0.40, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 11h:10m:50s remains)
INFO - root - 2017-12-01 05:43:26.277346: step 71410, loss = 0.39, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 11h:21m:59s remains)
INFO - root - 2017-12-01 05:43:27.870397: step 71420, loss = 0.41, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 11h:30m:54s remains)
INFO - root - 2017-12-01 05:43:29.417879: step 71430, loss = 0.39, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 11h:18m:08s remains)
INFO - root - 2017-12-01 05:43:30.973229: step 71440, loss = 0.36, batch loss = 0.21 (52.6 examples/sec; 0.152 sec/batch; 11h:01m:08s remains)
INFO - root - 2017-12-01 05:43:32.541054: step 71450, loss = 0.43, batch loss = 0.28 (51.8 examples/sec; 0.154 sec/batch; 11h:11m:19s remains)
INFO - root - 2017-12-01 05:43:34.114516: step 71460, loss = 0.32, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 11h:06m:46s remains)
INFO - root - 2017-12-01 05:43:35.687531: step 71470, loss = 0.51, batch loss = 0.35 (49.0 examples/sec; 0.163 sec/batch; 11h:49m:36s remains)
INFO - root - 2017-12-01 05:43:37.253442: step 71480, loss = 0.42, batch loss = 0.26 (50.2 examples/sec; 0.159 sec/batch; 11h:32m:48s remains)
INFO - root - 2017-12-01 05:43:38.813017: step 71490, loss = 0.34, batch loss = 0.18 (53.3 examples/sec; 0.150 sec/batch; 10h:53m:01s remains)
INFO - root - 2017-12-01 05:43:40.382882: step 71500, loss = 0.42, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 11h:25m:47s remains)
INFO - root - 2017-12-01 05:43:42.023036: step 71510, loss = 0.45, batch loss = 0.29 (51.8 examples/sec; 0.154 sec/batch; 11h:12m:01s remains)
INFO - root - 2017-12-01 05:43:43.591206: step 71520, loss = 0.36, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 11h:31m:13s remains)
INFO - root - 2017-12-01 05:43:45.146558: step 71530, loss = 0.38, batch loss = 0.23 (50.1 examples/sec; 0.160 sec/batch; 11h:33m:59s remains)
INFO - root - 2017-12-01 05:43:46.721976: step 71540, loss = 0.32, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 11h:30m:12s remains)
INFO - root - 2017-12-01 05:43:48.279490: step 71550, loss = 0.36, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 11h:33m:37s remains)
INFO - root - 2017-12-01 05:43:49.841927: step 71560, loss = 0.39, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 11h:08m:33s remains)
INFO - root - 2017-12-01 05:43:51.399672: step 71570, loss = 0.34, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 11h:01m:54s remains)
INFO - root - 2017-12-01 05:43:52.964677: step 71580, loss = 0.43, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 11h:15m:49s remains)
INFO - root - 2017-12-01 05:43:54.517786: step 71590, loss = 0.42, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 11h:13m:50s remains)
INFO - root - 2017-12-01 05:43:56.067925: step 71600, loss = 0.36, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 11h:28m:36s remains)
INFO - root - 2017-12-01 05:43:57.717470: step 71610, loss = 0.37, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 11h:22m:39s remains)
INFO - root - 2017-12-01 05:43:59.285020: step 71620, loss = 0.35, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 11h:05m:39s remains)
INFO - root - 2017-12-01 05:44:00.839968: step 71630, loss = 0.34, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 11h:23m:01s remains)
INFO - root - 2017-12-01 05:44:02.397904: step 71640, loss = 0.36, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 11h:11m:38s remains)
INFO - root - 2017-12-01 05:44:03.978717: step 71650, loss = 0.50, batch loss = 0.35 (52.8 examples/sec; 0.151 sec/batch; 10h:58m:12s remains)
INFO - root - 2017-12-01 05:44:05.545495: step 71660, loss = 0.38, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 11h:21m:10s remains)
INFO - root - 2017-12-01 05:44:07.110623: step 71670, loss = 0.35, batch loss = 0.20 (49.7 examples/sec; 0.161 sec/batch; 11h:39m:36s remains)
INFO - root - 2017-12-01 05:44:08.673841: step 71680, loss = 0.35, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 11h:36m:47s remains)
INFO - root - 2017-12-01 05:44:10.221722: step 71690, loss = 0.31, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 11h:19m:03s remains)
INFO - root - 2017-12-01 05:44:11.795214: step 71700, loss = 0.29, batch loss = 0.14 (52.2 examples/sec; 0.153 sec/batch; 11h:05m:56s remains)
INFO - root - 2017-12-01 05:44:13.425535: step 71710, loss = 0.36, batch loss = 0.21 (50.0 examples/sec; 0.160 sec/batch; 11h:35m:08s remains)
INFO - root - 2017-12-01 05:44:14.975677: step 71720, loss = 0.49, batch loss = 0.34 (52.7 examples/sec; 0.152 sec/batch; 10h:59m:52s remains)
INFO - root - 2017-12-01 05:44:16.524663: step 71730, loss = 0.37, batch loss = 0.22 (53.6 examples/sec; 0.149 sec/batch; 10h:48m:16s remains)
INFO - root - 2017-12-01 05:44:18.075968: step 71740, loss = 0.39, batch loss = 0.23 (53.4 examples/sec; 0.150 sec/batch; 10h:51m:32s remains)
INFO - root - 2017-12-01 05:44:19.629579: step 71750, loss = 0.34, batch loss = 0.19 (53.2 examples/sec; 0.150 sec/batch; 10h:53m:31s remains)
INFO - root - 2017-12-01 05:44:21.215822: step 71760, loss = 0.37, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 11h:22m:42s remains)
INFO - root - 2017-12-01 05:44:22.771906: step 71770, loss = 0.50, batch loss = 0.35 (51.3 examples/sec; 0.156 sec/batch; 11h:18m:10s remains)
INFO - root - 2017-12-01 05:44:24.337267: step 71780, loss = 0.44, batch loss = 0.29 (49.7 examples/sec; 0.161 sec/batch; 11h:39m:29s remains)
INFO - root - 2017-12-01 05:44:25.908607: step 71790, loss = 0.38, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 11h:08m:07s remains)
INFO - root - 2017-12-01 05:44:27.421228: step 71800, loss = 0.48, batch loss = 0.33 (50.2 examples/sec; 0.159 sec/batch; 11h:32m:31s remains)
INFO - root - 2017-12-01 05:44:29.036593: step 71810, loss = 0.37, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 11h:24m:02s remains)
INFO - root - 2017-12-01 05:44:30.598105: step 71820, loss = 0.35, batch loss = 0.19 (50.2 examples/sec; 0.159 sec/batch; 11h:32m:23s remains)
INFO - root - 2017-12-01 05:44:32.164245: step 71830, loss = 0.30, batch loss = 0.15 (50.7 examples/sec; 0.158 sec/batch; 11h:25m:34s remains)
INFO - root - 2017-12-01 05:44:33.718853: step 71840, loss = 0.37, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 11h:00m:35s remains)
INFO - root - 2017-12-01 05:44:35.299192: step 71850, loss = 0.35, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 11h:22m:34s remains)
INFO - root - 2017-12-01 05:44:36.859553: step 71860, loss = 0.36, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 11h:28m:15s remains)
INFO - root - 2017-12-01 05:44:38.423922: step 71870, loss = 0.48, batch loss = 0.33 (51.8 examples/sec; 0.154 sec/batch; 11h:10m:14s remains)
INFO - root - 2017-12-01 05:44:39.996974: step 71880, loss = 0.35, batch loss = 0.20 (48.7 examples/sec; 0.164 sec/batch; 11h:53m:29s remains)
INFO - root - 2017-12-01 05:44:41.580329: step 71890, loss = 0.38, batch loss = 0.23 (52.1 examples/sec; 0.153 sec/batch; 11h:06m:20s remains)
INFO - root - 2017-12-01 05:44:43.138232: step 71900, loss = 0.34, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 11h:24m:50s remains)
INFO - root - 2017-12-01 05:44:44.741694: step 71910, loss = 0.43, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 11h:14m:10s remains)
INFO - root - 2017-12-01 05:44:46.303777: step 71920, loss = 0.47, batch loss = 0.32 (52.2 examples/sec; 0.153 sec/batch; 11h:05m:40s remains)
INFO - root - 2017-12-01 05:44:47.848291: step 71930, loss = 0.37, batch loss = 0.22 (52.4 examples/sec; 0.153 sec/batch; 11h:03m:04s remains)
INFO - root - 2017-12-01 05:44:49.404590: step 71940, loss = 0.40, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 11h:11m:58s remains)
INFO - root - 2017-12-01 05:44:50.974773: step 71950, loss = 0.41, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 11h:12m:07s remains)
INFO - root - 2017-12-01 05:44:52.529859: step 71960, loss = 0.55, batch loss = 0.40 (49.4 examples/sec; 0.162 sec/batch; 11h:43m:07s remains)
INFO - root - 2017-12-01 05:44:54.106832: step 71970, loss = 0.44, batch loss = 0.29 (49.4 examples/sec; 0.162 sec/batch; 11h:43m:10s remains)
INFO - root - 2017-12-01 05:44:55.682507: step 71980, loss = 0.39, batch loss = 0.24 (48.4 examples/sec; 0.165 sec/batch; 11h:57m:54s remains)
INFO - root - 2017-12-01 05:44:57.253243: step 71990, loss = 0.34, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 11h:18m:11s remains)
INFO - root - 2017-12-01 05:44:58.816077: step 72000, loss = 0.32, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 11h:22m:00s remains)
INFO - root - 2017-12-01 05:45:00.490299: step 72010, loss = 0.34, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 11h:26m:53s remains)
INFO - root - 2017-12-01 05:45:02.041597: step 72020, loss = 0.36, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 11h:27m:52s remains)
INFO - root - 2017-12-01 05:45:03.596226: step 72030, loss = 0.34, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 11h:12m:33s remains)
INFO - root - 2017-12-01 05:45:05.170360: step 72040, loss = 0.36, batch loss = 0.21 (52.6 examples/sec; 0.152 sec/batch; 11h:00m:46s remains)
INFO - root - 2017-12-01 05:45:06.732178: step 72050, loss = 0.40, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 11h:04m:08s remains)
INFO - root - 2017-12-01 05:45:08.305114: step 72060, loss = 0.39, batch loss = 0.24 (49.2 examples/sec; 0.163 sec/batch; 11h:46m:30s remains)
INFO - root - 2017-12-01 05:45:09.872041: step 72070, loss = 0.40, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 11h:11m:42s remains)
INFO - root - 2017-12-01 05:45:11.425281: step 72080, loss = 0.39, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 11h:19m:14s remains)
INFO - root - 2017-12-01 05:45:12.970492: step 72090, loss = 0.38, batch loss = 0.23 (48.6 examples/sec; 0.165 sec/batch; 11h:54m:38s remains)
INFO - root - 2017-12-01 05:45:14.528490: step 72100, loss = 0.43, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 11h:11m:24s remains)
INFO - root - 2017-12-01 05:45:16.176638: step 72110, loss = 0.39, batch loss = 0.23 (48.0 examples/sec; 0.167 sec/batch; 12h:03m:29s remains)
INFO - root - 2017-12-01 05:45:17.752095: step 72120, loss = 0.34, batch loss = 0.19 (52.1 examples/sec; 0.153 sec/batch; 11h:05m:56s remains)
INFO - root - 2017-12-01 05:45:19.309605: step 72130, loss = 0.33, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 11h:24m:51s remains)
INFO - root - 2017-12-01 05:45:20.869091: step 72140, loss = 0.37, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 11h:28m:55s remains)
INFO - root - 2017-12-01 05:45:22.437784: step 72150, loss = 0.40, batch loss = 0.25 (49.9 examples/sec; 0.160 sec/batch; 11h:36m:18s remains)
INFO - root - 2017-12-01 05:45:24.000123: step 72160, loss = 0.33, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 11h:07m:03s remains)
INFO - root - 2017-12-01 05:45:25.578523: step 72170, loss = 0.30, batch loss = 0.15 (52.0 examples/sec; 0.154 sec/batch; 11h:07m:10s remains)
INFO - root - 2017-12-01 05:45:27.136232: step 72180, loss = 0.40, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 11h:16m:35s remains)
INFO - root - 2017-12-01 05:45:28.714632: step 72190, loss = 0.51, batch loss = 0.36 (50.6 examples/sec; 0.158 sec/batch; 11h:26m:28s remains)
INFO - root - 2017-12-01 05:45:30.281709: step 72200, loss = 0.36, batch loss = 0.21 (50.2 examples/sec; 0.160 sec/batch; 11h:32m:02s remains)
INFO - root - 2017-12-01 05:45:31.910773: step 72210, loss = 0.41, batch loss = 0.26 (51.1 examples/sec; 0.157 sec/batch; 11h:19m:36s remains)
INFO - root - 2017-12-01 05:45:33.486036: step 72220, loss = 0.40, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 11h:12m:55s remains)
INFO - root - 2017-12-01 05:45:35.038151: step 72230, loss = 0.35, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 11h:20m:58s remains)
INFO - root - 2017-12-01 05:45:36.617937: step 72240, loss = 0.42, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 11h:16m:40s remains)
INFO - root - 2017-12-01 05:45:38.172755: step 72250, loss = 0.33, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 11h:07m:08s remains)
INFO - root - 2017-12-01 05:45:39.736428: step 72260, loss = 0.45, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 11h:21m:58s remains)
INFO - root - 2017-12-01 05:45:41.302239: step 72270, loss = 0.39, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 11h:13m:06s remains)
INFO - root - 2017-12-01 05:45:42.856850: step 72280, loss = 0.36, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 11h:31m:30s remains)
INFO - root - 2017-12-01 05:45:44.424492: step 72290, loss = 0.43, batch loss = 0.28 (52.2 examples/sec; 0.153 sec/batch; 11h:04m:44s remains)
INFO - root - 2017-12-01 05:45:46.004648: step 72300, loss = 0.32, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 11h:09m:34s remains)
INFO - root - 2017-12-01 05:45:47.640604: step 72310, loss = 0.36, batch loss = 0.21 (48.2 examples/sec; 0.166 sec/batch; 11h:59m:56s remains)
INFO - root - 2017-12-01 05:45:49.236603: step 72320, loss = 0.32, batch loss = 0.17 (52.4 examples/sec; 0.153 sec/batch; 11h:02m:38s remains)
INFO - root - 2017-12-01 05:45:50.800424: step 72330, loss = 0.40, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 11h:28m:29s remains)
INFO - root - 2017-12-01 05:45:52.363227: step 72340, loss = 0.42, batch loss = 0.27 (51.9 examples/sec; 0.154 sec/batch; 11h:08m:47s remains)
INFO - root - 2017-12-01 05:45:53.927315: step 72350, loss = 0.38, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 11h:08m:27s remains)
INFO - root - 2017-12-01 05:45:55.485456: step 72360, loss = 0.37, batch loss = 0.22 (53.1 examples/sec; 0.151 sec/batch; 10h:53m:30s remains)
INFO - root - 2017-12-01 05:45:57.032101: step 72370, loss = 0.30, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 11h:15m:49s remains)
INFO - root - 2017-12-01 05:45:58.612683: step 72380, loss = 0.35, batch loss = 0.20 (50.2 examples/sec; 0.160 sec/batch; 11h:31m:29s remains)
INFO - root - 2017-12-01 05:46:00.171125: step 72390, loss = 0.34, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 11h:15m:26s remains)
INFO - root - 2017-12-01 05:46:01.725889: step 72400, loss = 0.50, batch loss = 0.35 (50.3 examples/sec; 0.159 sec/batch; 11h:29m:15s remains)
INFO - root - 2017-12-01 05:46:03.375137: step 72410, loss = 0.40, batch loss = 0.25 (50.0 examples/sec; 0.160 sec/batch; 11h:34m:04s remains)
INFO - root - 2017-12-01 05:46:04.923977: step 72420, loss = 0.35, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 11h:28m:12s remains)
INFO - root - 2017-12-01 05:46:06.490770: step 72430, loss = 0.38, batch loss = 0.23 (50.1 examples/sec; 0.160 sec/batch; 11h:32m:11s remains)
INFO - root - 2017-12-01 05:46:08.052567: step 72440, loss = 0.33, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 11h:08m:41s remains)
INFO - root - 2017-12-01 05:46:09.623455: step 72450, loss = 0.30, batch loss = 0.15 (48.8 examples/sec; 0.164 sec/batch; 11h:49m:50s remains)
INFO - root - 2017-12-01 05:46:11.187994: step 72460, loss = 0.41, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 11h:12m:42s remains)
INFO - root - 2017-12-01 05:46:12.741731: step 72470, loss = 0.37, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 11h:20m:58s remains)
INFO - root - 2017-12-01 05:46:14.314020: step 72480, loss = 0.36, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 11h:21m:32s remains)
INFO - root - 2017-12-01 05:46:15.875424: step 72490, loss = 0.40, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 11h:03m:12s remains)
INFO - root - 2017-12-01 05:46:17.425940: step 72500, loss = 0.43, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 11h:17m:24s remains)
INFO - root - 2017-12-01 05:46:19.072630: step 72510, loss = 0.36, batch loss = 0.21 (48.9 examples/sec; 0.164 sec/batch; 11h:48m:48s remains)
INFO - root - 2017-12-01 05:46:20.638171: step 72520, loss = 0.38, batch loss = 0.23 (53.2 examples/sec; 0.150 sec/batch; 10h:51m:57s remains)
INFO - root - 2017-12-01 05:46:22.205623: step 72530, loss = 0.49, batch loss = 0.33 (52.6 examples/sec; 0.152 sec/batch; 10h:59m:18s remains)
INFO - root - 2017-12-01 05:46:23.756671: step 72540, loss = 0.37, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 11h:24m:23s remains)
INFO - root - 2017-12-01 05:46:25.304418: step 72550, loss = 0.41, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 11h:15m:10s remains)
INFO - root - 2017-12-01 05:46:26.855320: step 72560, loss = 0.33, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 11h:25m:57s remains)
INFO - root - 2017-12-01 05:46:28.420713: step 72570, loss = 0.33, batch loss = 0.18 (48.7 examples/sec; 0.164 sec/batch; 11h:51m:29s remains)
INFO - root - 2017-12-01 05:46:29.970507: step 72580, loss = 0.29, batch loss = 0.14 (52.9 examples/sec; 0.151 sec/batch; 10h:55m:30s remains)
INFO - root - 2017-12-01 05:46:31.533474: step 72590, loss = 0.34, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 11h:11m:19s remains)
INFO - root - 2017-12-01 05:46:33.099098: step 72600, loss = 0.38, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 11h:03m:26s remains)
INFO - root - 2017-12-01 05:46:34.709132: step 72610, loss = 0.39, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 11h:19m:00s remains)
INFO - root - 2017-12-01 05:46:36.285184: step 72620, loss = 0.40, batch loss = 0.25 (45.3 examples/sec; 0.177 sec/batch; 12h:45m:02s remains)
INFO - root - 2017-12-01 05:46:37.885396: step 72630, loss = 0.31, batch loss = 0.15 (51.1 examples/sec; 0.157 sec/batch; 11h:17m:51s remains)
INFO - root - 2017-12-01 05:46:39.444915: step 72640, loss = 0.35, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 11h:24m:29s remains)
INFO - root - 2017-12-01 05:46:41.003848: step 72650, loss = 0.31, batch loss = 0.16 (51.1 examples/sec; 0.156 sec/batch; 11h:17m:22s remains)
INFO - root - 2017-12-01 05:46:42.564484: step 72660, loss = 0.37, batch loss = 0.22 (53.0 examples/sec; 0.151 sec/batch; 10h:53m:35s remains)
INFO - root - 2017-12-01 05:46:44.154341: step 72670, loss = 0.41, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 11h:19m:41s remains)
INFO - root - 2017-12-01 05:46:45.717112: step 72680, loss = 0.41, batch loss = 0.26 (51.4 examples/sec; 0.155 sec/batch; 11h:13m:21s remains)
INFO - root - 2017-12-01 05:46:47.260619: step 72690, loss = 0.37, batch loss = 0.22 (52.1 examples/sec; 0.153 sec/batch; 11h:04m:29s remains)
INFO - root - 2017-12-01 05:46:48.816567: step 72700, loss = 0.42, batch loss = 0.27 (49.3 examples/sec; 0.162 sec/batch; 11h:43m:14s remains)
INFO - root - 2017-12-01 05:46:50.432869: step 72710, loss = 0.36, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 11h:03m:13s remains)
INFO - root - 2017-12-01 05:46:51.998503: step 72720, loss = 0.38, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 11h:17m:40s remains)
INFO - root - 2017-12-01 05:46:53.563924: step 72730, loss = 0.41, batch loss = 0.26 (50.1 examples/sec; 0.160 sec/batch; 11h:30m:59s remains)
INFO - root - 2017-12-01 05:46:55.128916: step 72740, loss = 0.46, batch loss = 0.31 (51.1 examples/sec; 0.157 sec/batch; 11h:17m:58s remains)
INFO - root - 2017-12-01 05:46:56.711321: step 72750, loss = 0.34, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 11h:05m:48s remains)
INFO - root - 2017-12-01 05:46:58.274942: step 72760, loss = 0.36, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 11h:10m:40s remains)
INFO - root - 2017-12-01 05:46:59.856209: step 72770, loss = 0.37, batch loss = 0.22 (48.7 examples/sec; 0.164 sec/batch; 11h:50m:24s remains)
INFO - root - 2017-12-01 05:47:01.409032: step 72780, loss = 0.29, batch loss = 0.14 (51.1 examples/sec; 0.157 sec/batch; 11h:18m:19s remains)
INFO - root - 2017-12-01 05:47:02.976311: step 72790, loss = 0.49, batch loss = 0.34 (51.2 examples/sec; 0.156 sec/batch; 11h:15m:54s remains)
INFO - root - 2017-12-01 05:47:04.544881: step 72800, loss = 0.33, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 11h:16m:42s remains)
INFO - root - 2017-12-01 05:47:06.162480: step 72810, loss = 0.44, batch loss = 0.29 (52.0 examples/sec; 0.154 sec/batch; 11h:05m:28s remains)
INFO - root - 2017-12-01 05:47:07.731291: step 72820, loss = 0.42, batch loss = 0.27 (50.8 examples/sec; 0.157 sec/batch; 11h:21m:24s remains)
INFO - root - 2017-12-01 05:47:09.299072: step 72830, loss = 0.46, batch loss = 0.31 (52.0 examples/sec; 0.154 sec/batch; 11h:06m:03s remains)
INFO - root - 2017-12-01 05:47:10.861962: step 72840, loss = 0.40, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 11h:19m:55s remains)
INFO - root - 2017-12-01 05:47:12.408123: step 72850, loss = 0.33, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 11h:24m:12s remains)
INFO - root - 2017-12-01 05:47:13.964572: step 72860, loss = 0.41, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 11h:10m:45s remains)
INFO - root - 2017-12-01 05:47:15.529232: step 72870, loss = 0.34, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 11h:02m:01s remains)
INFO - root - 2017-12-01 05:47:17.079042: step 72880, loss = 0.36, batch loss = 0.21 (53.1 examples/sec; 0.151 sec/batch; 10h:51m:48s remains)
INFO - root - 2017-12-01 05:47:18.647755: step 72890, loss = 0.39, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 11h:02m:55s remains)
INFO - root - 2017-12-01 05:47:20.212900: step 72900, loss = 0.37, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 11h:31m:27s remains)
INFO - root - 2017-12-01 05:47:21.859325: step 72910, loss = 0.38, batch loss = 0.23 (53.0 examples/sec; 0.151 sec/batch; 10h:53m:11s remains)
INFO - root - 2017-12-01 05:47:23.431699: step 72920, loss = 0.35, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 11h:32m:45s remains)
INFO - root - 2017-12-01 05:47:25.000365: step 72930, loss = 0.36, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 11h:28m:43s remains)
INFO - root - 2017-12-01 05:47:26.551215: step 72940, loss = 0.36, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 11h:13m:09s remains)
INFO - root - 2017-12-01 05:47:28.114444: step 72950, loss = 0.38, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 11h:07m:34s remains)
INFO - root - 2017-12-01 05:47:29.690106: step 72960, loss = 0.38, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 11h:05m:57s remains)
INFO - root - 2017-12-01 05:47:31.251560: step 72970, loss = 0.41, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 11h:23m:34s remains)
INFO - root - 2017-12-01 05:47:32.809610: step 72980, loss = 0.39, batch loss = 0.24 (50.8 examples/sec; 0.157 sec/batch; 11h:20m:54s remains)
INFO - root - 2017-12-01 05:47:34.360308: step 72990, loss = 0.39, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 11h:18m:24s remains)
INFO - root - 2017-12-01 05:47:35.925206: step 73000, loss = 0.35, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 11h:20m:08s remains)
INFO - root - 2017-12-01 05:47:37.539273: step 73010, loss = 0.33, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 11h:17m:26s remains)
INFO - root - 2017-12-01 05:47:39.110751: step 73020, loss = 0.46, batch loss = 0.31 (50.4 examples/sec; 0.159 sec/batch; 11h:26m:17s remains)
INFO - root - 2017-12-01 05:47:40.678088: step 73030, loss = 0.36, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 11h:13m:51s remains)
INFO - root - 2017-12-01 05:47:42.228898: step 73040, loss = 0.34, batch loss = 0.19 (53.2 examples/sec; 0.150 sec/batch; 10h:49m:55s remains)
INFO - root - 2017-12-01 05:47:43.803213: step 73050, loss = 0.36, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 11h:04m:35s remains)
INFO - root - 2017-12-01 05:47:45.365464: step 73060, loss = 0.39, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 11h:10m:49s remains)
INFO - root - 2017-12-01 05:47:46.938109: step 73070, loss = 0.35, batch loss = 0.20 (49.8 examples/sec; 0.161 sec/batch; 11h:34m:38s remains)
INFO - root - 2017-12-01 05:47:48.494553: step 73080, loss = 0.36, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 11h:28m:19s remains)
INFO - root - 2017-12-01 05:47:50.064100: step 73090, loss = 0.40, batch loss = 0.25 (53.1 examples/sec; 0.151 sec/batch; 10h:51m:48s remains)
INFO - root - 2017-12-01 05:47:51.647428: step 73100, loss = 0.28, batch loss = 0.13 (50.7 examples/sec; 0.158 sec/batch; 11h:21m:54s remains)
INFO - root - 2017-12-01 05:47:53.244796: step 73110, loss = 0.44, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 11h:11m:09s remains)
INFO - root - 2017-12-01 05:47:54.833128: step 73120, loss = 0.42, batch loss = 0.27 (49.8 examples/sec; 0.161 sec/batch; 11h:33m:52s remains)
INFO - root - 2017-12-01 05:47:56.425498: step 73130, loss = 0.42, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 11h:10m:29s remains)
INFO - root - 2017-12-01 05:47:57.975891: step 73140, loss = 0.36, batch loss = 0.21 (49.7 examples/sec; 0.161 sec/batch; 11h:35m:35s remains)
INFO - root - 2017-12-01 05:47:59.545602: step 73150, loss = 0.34, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 11h:10m:29s remains)
INFO - root - 2017-12-01 05:48:01.088963: step 73160, loss = 0.35, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 10h:56m:56s remains)
INFO - root - 2017-12-01 05:48:02.657873: step 73170, loss = 0.37, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 11h:03m:55s remains)
INFO - root - 2017-12-01 05:48:04.257155: step 73180, loss = 0.41, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 11h:14m:34s remains)
INFO - root - 2017-12-01 05:48:05.832492: step 73190, loss = 0.38, batch loss = 0.23 (49.0 examples/sec; 0.163 sec/batch; 11h:44m:53s remains)
INFO - root - 2017-12-01 05:48:07.412755: step 73200, loss = 0.30, batch loss = 0.15 (50.9 examples/sec; 0.157 sec/batch; 11h:19m:03s remains)
INFO - root - 2017-12-01 05:48:09.042087: step 73210, loss = 0.35, batch loss = 0.20 (49.5 examples/sec; 0.162 sec/batch; 11h:38m:05s remains)
INFO - root - 2017-12-01 05:48:10.607208: step 73220, loss = 0.38, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 11h:11m:27s remains)
INFO - root - 2017-12-01 05:48:12.188308: step 73230, loss = 0.46, batch loss = 0.31 (51.3 examples/sec; 0.156 sec/batch; 11h:13m:44s remains)
INFO - root - 2017-12-01 05:48:13.754855: step 73240, loss = 0.39, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 11h:15m:33s remains)
INFO - root - 2017-12-01 05:48:15.311855: step 73250, loss = 0.40, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 11h:14m:04s remains)
INFO - root - 2017-12-01 05:48:16.890522: step 73260, loss = 0.38, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 11h:15m:21s remains)
INFO - root - 2017-12-01 05:48:18.485333: step 73270, loss = 0.36, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 11h:13m:29s remains)
INFO - root - 2017-12-01 05:48:20.087276: step 73280, loss = 0.51, batch loss = 0.36 (49.7 examples/sec; 0.161 sec/batch; 11h:36m:03s remains)
INFO - root - 2017-12-01 05:48:21.648562: step 73290, loss = 0.36, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 11h:22m:53s remains)
INFO - root - 2017-12-01 05:48:23.205131: step 73300, loss = 0.35, batch loss = 0.20 (53.2 examples/sec; 0.150 sec/batch; 10h:49m:58s remains)
INFO - root - 2017-12-01 05:48:24.876662: step 73310, loss = 0.34, batch loss = 0.19 (48.3 examples/sec; 0.166 sec/batch; 11h:56m:01s remains)
INFO - root - 2017-12-01 05:48:26.465115: step 73320, loss = 0.41, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 11h:19m:33s remains)
INFO - root - 2017-12-01 05:48:28.034076: step 73330, loss = 0.32, batch loss = 0.17 (50.0 examples/sec; 0.160 sec/batch; 11h:30m:56s remains)
INFO - root - 2017-12-01 05:48:29.587156: step 73340, loss = 0.34, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 11h:20m:13s remains)
INFO - root - 2017-12-01 05:48:31.147509: step 73350, loss = 0.38, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 11h:12m:25s remains)
INFO - root - 2017-12-01 05:48:32.704641: step 73360, loss = 0.35, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 11h:08m:23s remains)
INFO - root - 2017-12-01 05:48:34.302861: step 73370, loss = 0.45, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 11h:22m:01s remains)
INFO - root - 2017-12-01 05:48:35.876597: step 73380, loss = 0.39, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 11h:17m:38s remains)
INFO - root - 2017-12-01 05:48:37.419173: step 73390, loss = 0.34, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 11h:17m:31s remains)
INFO - root - 2017-12-01 05:48:38.983170: step 73400, loss = 0.39, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 11h:22m:04s remains)
INFO - root - 2017-12-01 05:48:40.620727: step 73410, loss = 0.33, batch loss = 0.18 (48.9 examples/sec; 0.164 sec/batch; 11h:46m:14s remains)
INFO - root - 2017-12-01 05:48:42.189739: step 73420, loss = 0.35, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 11h:18m:43s remains)
INFO - root - 2017-12-01 05:48:43.753865: step 73430, loss = 0.41, batch loss = 0.26 (49.3 examples/sec; 0.162 sec/batch; 11h:40m:30s remains)
INFO - root - 2017-12-01 05:48:45.329496: step 73440, loss = 0.44, batch loss = 0.29 (51.0 examples/sec; 0.157 sec/batch; 11h:17m:19s remains)
INFO - root - 2017-12-01 05:48:46.886422: step 73450, loss = 0.35, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 11h:03m:17s remains)
INFO - root - 2017-12-01 05:48:48.453148: step 73460, loss = 0.33, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 11h:18m:32s remains)
INFO - root - 2017-12-01 05:48:50.028467: step 73470, loss = 0.41, batch loss = 0.26 (48.8 examples/sec; 0.164 sec/batch; 11h:47m:21s remains)
INFO - root - 2017-12-01 05:48:51.585479: step 73480, loss = 0.34, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 11h:13m:30s remains)
INFO - root - 2017-12-01 05:48:53.158152: step 73490, loss = 0.34, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 11h:10m:11s remains)
INFO - root - 2017-12-01 05:48:54.735922: step 73500, loss = 0.38, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 11h:05m:55s remains)
INFO - root - 2017-12-01 05:48:56.378575: step 73510, loss = 0.37, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 11h:15m:42s remains)
INFO - root - 2017-12-01 05:48:57.939042: step 73520, loss = 0.35, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 11h:06m:41s remains)
INFO - root - 2017-12-01 05:48:59.502990: step 73530, loss = 0.37, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 11h:19m:18s remains)
INFO - root - 2017-12-01 05:49:01.072302: step 73540, loss = 0.36, batch loss = 0.21 (49.1 examples/sec; 0.163 sec/batch; 11h:43m:03s remains)
INFO - root - 2017-12-01 05:49:02.647827: step 73550, loss = 0.35, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 10h:56m:34s remains)
INFO - root - 2017-12-01 05:49:04.211214: step 73560, loss = 0.38, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 11h:00m:25s remains)
INFO - root - 2017-12-01 05:49:05.781016: step 73570, loss = 0.48, batch loss = 0.33 (51.5 examples/sec; 0.155 sec/batch; 11h:10m:55s remains)
INFO - root - 2017-12-01 05:49:07.340986: step 73580, loss = 0.30, batch loss = 0.15 (50.5 examples/sec; 0.158 sec/batch; 11h:23m:00s remains)
INFO - root - 2017-12-01 05:49:08.908953: step 73590, loss = 0.42, batch loss = 0.27 (49.1 examples/sec; 0.163 sec/batch; 11h:43m:35s remains)
INFO - root - 2017-12-01 05:49:10.495667: step 73600, loss = 0.33, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 11h:07m:32s remains)
INFO - root - 2017-12-01 05:49:12.148047: step 73610, loss = 0.34, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 11h:15m:50s remains)
INFO - root - 2017-12-01 05:49:13.703994: step 73620, loss = 0.41, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 11h:01m:37s remains)
INFO - root - 2017-12-01 05:49:15.268383: step 73630, loss = 0.40, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 10h:56m:49s remains)
INFO - root - 2017-12-01 05:49:16.842888: step 73640, loss = 0.36, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 11h:11m:06s remains)
INFO - root - 2017-12-01 05:49:18.407878: step 73650, loss = 0.46, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 11h:14m:20s remains)
INFO - root - 2017-12-01 05:49:19.963514: step 73660, loss = 0.38, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 10h:59m:03s remains)
INFO - root - 2017-12-01 05:49:21.544782: step 73670, loss = 0.31, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 11h:09m:38s remains)
INFO - root - 2017-12-01 05:49:23.116255: step 73680, loss = 0.30, batch loss = 0.15 (50.5 examples/sec; 0.158 sec/batch; 11h:22m:47s remains)
INFO - root - 2017-12-01 05:49:24.681419: step 73690, loss = 0.34, batch loss = 0.19 (50.5 examples/sec; 0.159 sec/batch; 11h:23m:53s remains)
INFO - root - 2017-12-01 05:49:26.245355: step 73700, loss = 0.34, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 11h:37m:41s remains)
INFO - root - 2017-12-01 05:49:27.858585: step 73710, loss = 0.31, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 11h:14m:02s remains)
INFO - root - 2017-12-01 05:49:29.418365: step 73720, loss = 0.42, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 11h:21m:25s remains)
INFO - root - 2017-12-01 05:49:30.979171: step 73730, loss = 0.37, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 11h:24m:13s remains)
INFO - root - 2017-12-01 05:49:32.536564: step 73740, loss = 0.49, batch loss = 0.34 (52.1 examples/sec; 0.153 sec/batch; 11h:01m:49s remains)
INFO - root - 2017-12-01 05:49:34.113380: step 73750, loss = 0.53, batch loss = 0.38 (51.6 examples/sec; 0.155 sec/batch; 11h:08m:02s remains)
INFO - root - 2017-12-01 05:49:35.671620: step 73760, loss = 0.32, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 11h:03m:03s remains)
INFO - root - 2017-12-01 05:49:37.238304: step 73770, loss = 0.41, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 11h:21m:16s remains)
INFO - root - 2017-12-01 05:49:38.808957: step 73780, loss = 0.46, batch loss = 0.31 (53.1 examples/sec; 0.151 sec/batch; 10h:49m:58s remains)
INFO - root - 2017-12-01 05:49:40.364903: step 73790, loss = 0.33, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 11h:26m:35s remains)
INFO - root - 2017-12-01 05:49:41.913968: step 73800, loss = 0.36, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 11h:03m:06s remains)
INFO - root - 2017-12-01 05:49:43.548995: step 73810, loss = 0.36, batch loss = 0.21 (49.3 examples/sec; 0.162 sec/batch; 11h:38m:56s remains)
INFO - root - 2017-12-01 05:49:45.123549: step 73820, loss = 0.35, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 11h:14m:33s remains)
INFO - root - 2017-12-01 05:49:46.687654: step 73830, loss = 0.33, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 11h:15m:16s remains)
INFO - root - 2017-12-01 05:49:48.242360: step 73840, loss = 0.50, batch loss = 0.35 (51.3 examples/sec; 0.156 sec/batch; 11h:12m:21s remains)
INFO - root - 2017-12-01 05:49:49.806929: step 73850, loss = 0.42, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 11h:10m:26s remains)
INFO - root - 2017-12-01 05:49:51.369163: step 73860, loss = 0.36, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 11h:09m:49s remains)
INFO - root - 2017-12-01 05:49:52.925470: step 73870, loss = 0.40, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 11h:20m:38s remains)
INFO - root - 2017-12-01 05:49:54.491374: step 73880, loss = 0.31, batch loss = 0.16 (52.4 examples/sec; 0.153 sec/batch; 10h:58m:14s remains)
INFO - root - 2017-12-01 05:49:56.070824: step 73890, loss = 0.38, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 11h:07m:43s remains)
INFO - root - 2017-12-01 05:49:57.634399: step 73900, loss = 0.32, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 11h:12m:45s remains)
INFO - root - 2017-12-01 05:49:59.243938: step 73910, loss = 0.36, batch loss = 0.21 (53.1 examples/sec; 0.151 sec/batch; 10h:49m:35s remains)
INFO - root - 2017-12-01 05:50:00.795282: step 73920, loss = 0.36, batch loss = 0.21 (52.9 examples/sec; 0.151 sec/batch; 10h:51m:47s remains)
INFO - root - 2017-12-01 05:50:02.348641: step 73930, loss = 0.40, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 11h:13m:53s remains)
INFO - root - 2017-12-01 05:50:03.911529: step 73940, loss = 0.35, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 11h:20m:42s remains)
INFO - root - 2017-12-01 05:50:05.466944: step 73950, loss = 0.37, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 11h:19m:12s remains)
INFO - root - 2017-12-01 05:50:07.040261: step 73960, loss = 0.33, batch loss = 0.18 (49.1 examples/sec; 0.163 sec/batch; 11h:41m:34s remains)
INFO - root - 2017-12-01 05:50:08.607615: step 73970, loss = 0.38, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 11h:08m:53s remains)
INFO - root - 2017-12-01 05:50:10.177376: step 73980, loss = 0.47, batch loss = 0.32 (51.2 examples/sec; 0.156 sec/batch; 11h:13m:52s remains)
INFO - root - 2017-12-01 05:50:11.760027: step 73990, loss = 0.38, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 11h:16m:31s remains)
INFO - root - 2017-12-01 05:50:13.305469: step 74000, loss = 0.39, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 11h:06m:53s remains)
INFO - root - 2017-12-01 05:50:14.959340: step 74010, loss = 0.35, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 11h:00m:31s remains)
INFO - root - 2017-12-01 05:50:16.529919: step 74020, loss = 0.42, batch loss = 0.28 (49.4 examples/sec; 0.162 sec/batch; 11h:37m:02s remains)
INFO - root - 2017-12-01 05:50:18.077796: step 74030, loss = 0.39, batch loss = 0.24 (53.0 examples/sec; 0.151 sec/batch; 10h:50m:49s remains)
INFO - root - 2017-12-01 05:50:19.648523: step 74040, loss = 0.38, batch loss = 0.23 (49.3 examples/sec; 0.162 sec/batch; 11h:38m:34s remains)
INFO - root - 2017-12-01 05:50:21.260552: step 74050, loss = 0.31, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 11h:24m:18s remains)
INFO - root - 2017-12-01 05:50:22.803997: step 74060, loss = 0.39, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 11h:08m:12s remains)
INFO - root - 2017-12-01 05:50:24.352190: step 74070, loss = 0.57, batch loss = 0.42 (51.9 examples/sec; 0.154 sec/batch; 11h:04m:04s remains)
INFO - root - 2017-12-01 05:50:25.922210: step 74080, loss = 0.51, batch loss = 0.36 (50.4 examples/sec; 0.159 sec/batch; 11h:24m:09s remains)
INFO - root - 2017-12-01 05:50:27.464375: step 74090, loss = 0.39, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 11h:06m:42s remains)
INFO - root - 2017-12-01 05:50:29.028916: step 74100, loss = 0.30, batch loss = 0.15 (52.0 examples/sec; 0.154 sec/batch; 11h:03m:02s remains)
INFO - root - 2017-12-01 05:50:30.652580: step 74110, loss = 0.44, batch loss = 0.29 (52.1 examples/sec; 0.154 sec/batch; 11h:01m:13s remains)
INFO - root - 2017-12-01 05:50:32.227477: step 74120, loss = 0.33, batch loss = 0.18 (52.7 examples/sec; 0.152 sec/batch; 10h:53m:12s remains)
INFO - root - 2017-12-01 05:50:33.797542: step 74130, loss = 0.33, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 11h:07m:53s remains)
INFO - root - 2017-12-01 05:50:35.354238: step 74140, loss = 0.43, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 11h:07m:26s remains)
INFO - root - 2017-12-01 05:50:36.902181: step 74150, loss = 0.40, batch loss = 0.25 (50.5 examples/sec; 0.158 sec/batch; 11h:22m:05s remains)
INFO - root - 2017-12-01 05:50:38.474856: step 74160, loss = 0.37, batch loss = 0.22 (48.3 examples/sec; 0.165 sec/batch; 11h:52m:31s remains)
INFO - root - 2017-12-01 05:50:40.030233: step 74170, loss = 0.37, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 11h:04m:13s remains)
INFO - root - 2017-12-01 05:50:41.605647: step 74180, loss = 0.31, batch loss = 0.16 (50.8 examples/sec; 0.157 sec/batch; 11h:18m:03s remains)
INFO - root - 2017-12-01 05:50:43.162257: step 74190, loss = 0.31, batch loss = 0.16 (52.4 examples/sec; 0.153 sec/batch; 10h:56m:56s remains)
INFO - root - 2017-12-01 05:50:44.742991: step 74200, loss = 0.37, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 11h:19m:52s remains)
INFO - root - 2017-12-01 05:50:46.388956: step 74210, loss = 0.34, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 11h:03m:02s remains)
INFO - root - 2017-12-01 05:50:47.971587: step 74220, loss = 0.38, batch loss = 0.23 (50.2 examples/sec; 0.160 sec/batch; 11h:26m:40s remains)
INFO - root - 2017-12-01 05:50:49.528680: step 74230, loss = 0.46, batch loss = 0.31 (51.8 examples/sec; 0.154 sec/batch; 11h:04m:44s remains)
INFO - root - 2017-12-01 05:50:51.084327: step 74240, loss = 0.39, batch loss = 0.24 (53.1 examples/sec; 0.151 sec/batch; 10h:48m:53s remains)
INFO - root - 2017-12-01 05:50:52.625919: step 74250, loss = 0.37, batch loss = 0.22 (52.7 examples/sec; 0.152 sec/batch; 10h:53m:59s remains)
INFO - root - 2017-12-01 05:50:54.179608: step 74260, loss = 0.39, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 11h:12m:30s remains)
INFO - root - 2017-12-01 05:50:55.759382: step 74270, loss = 0.36, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 11h:08m:26s remains)
INFO - root - 2017-12-01 05:50:57.317076: step 74280, loss = 0.67, batch loss = 0.53 (51.0 examples/sec; 0.157 sec/batch; 11h:15m:15s remains)
INFO - root - 2017-12-01 05:50:58.882965: step 74290, loss = 0.41, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 11h:14m:48s remains)
INFO - root - 2017-12-01 05:51:00.452212: step 74300, loss = 0.40, batch loss = 0.25 (52.2 examples/sec; 0.153 sec/batch; 10h:59m:59s remains)
INFO - root - 2017-12-01 05:51:02.069353: step 74310, loss = 0.44, batch loss = 0.29 (46.6 examples/sec; 0.171 sec/batch; 12h:17m:58s remains)
INFO - root - 2017-12-01 05:51:03.625273: step 74320, loss = 0.37, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 11h:14m:15s remains)
INFO - root - 2017-12-01 05:51:05.178816: step 74330, loss = 0.50, batch loss = 0.35 (52.0 examples/sec; 0.154 sec/batch; 11h:02m:07s remains)
INFO - root - 2017-12-01 05:51:06.753124: step 74340, loss = 0.51, batch loss = 0.37 (51.4 examples/sec; 0.156 sec/batch; 11h:09m:20s remains)
INFO - root - 2017-12-01 05:51:08.332453: step 74350, loss = 0.32, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 11h:12m:14s remains)
INFO - root - 2017-12-01 05:51:09.899670: step 74360, loss = 0.33, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 11h:03m:16s remains)
INFO - root - 2017-12-01 05:51:11.463781: step 74370, loss = 0.35, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 11h:11m:02s remains)
INFO - root - 2017-12-01 05:51:13.016715: step 74380, loss = 0.34, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 11h:26m:27s remains)
INFO - root - 2017-12-01 05:51:14.582738: step 74390, loss = 0.37, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 11h:06m:55s remains)
INFO - root - 2017-12-01 05:51:16.172397: step 74400, loss = 0.45, batch loss = 0.30 (49.8 examples/sec; 0.161 sec/batch; 11h:31m:01s remains)
INFO - root - 2017-12-01 05:51:17.871151: step 74410, loss = 0.41, batch loss = 0.26 (48.8 examples/sec; 0.164 sec/batch; 11h:44m:49s remains)
INFO - root - 2017-12-01 05:51:19.441562: step 74420, loss = 0.36, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 11h:18m:38s remains)
INFO - root - 2017-12-01 05:51:21.001976: step 74430, loss = 0.34, batch loss = 0.20 (52.7 examples/sec; 0.152 sec/batch; 10h:52m:44s remains)
INFO - root - 2017-12-01 05:51:22.568463: step 74440, loss = 0.36, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 11h:19m:42s remains)
INFO - root - 2017-12-01 05:51:24.140729: step 74450, loss = 0.33, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 11h:22m:05s remains)
INFO - root - 2017-12-01 05:51:25.704878: step 74460, loss = 0.45, batch loss = 0.31 (51.4 examples/sec; 0.156 sec/batch; 11h:09m:04s remains)
INFO - root - 2017-12-01 05:51:27.258210: step 74470, loss = 0.39, batch loss = 0.25 (49.8 examples/sec; 0.161 sec/batch; 11h:31m:19s remains)
INFO - root - 2017-12-01 05:51:28.814705: step 74480, loss = 0.37, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 10h:55m:28s remains)
INFO - root - 2017-12-01 05:51:30.386981: step 74490, loss = 0.33, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 11h:05m:08s remains)
INFO - root - 2017-12-01 05:51:31.938938: step 74500, loss = 0.39, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 11h:01m:31s remains)
INFO - root - 2017-12-01 05:51:33.572344: step 74510, loss = 0.39, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 11h:04m:18s remains)
INFO - root - 2017-12-01 05:51:35.131704: step 74520, loss = 0.35, batch loss = 0.20 (52.5 examples/sec; 0.152 sec/batch; 10h:54m:39s remains)
INFO - root - 2017-12-01 05:51:36.681153: step 74530, loss = 0.32, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 11h:10m:26s remains)
INFO - root - 2017-12-01 05:51:38.265238: step 74540, loss = 0.38, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 11h:10m:36s remains)
INFO - root - 2017-12-01 05:51:39.819479: step 74550, loss = 0.38, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 11h:20m:36s remains)
INFO - root - 2017-12-01 05:51:41.382748: step 74560, loss = 0.40, batch loss = 0.25 (49.1 examples/sec; 0.163 sec/batch; 11h:40m:30s remains)
INFO - root - 2017-12-01 05:51:42.946456: step 74570, loss = 0.35, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 11h:08m:25s remains)
INFO - root - 2017-12-01 05:51:44.544552: step 74580, loss = 0.35, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 11h:21m:56s remains)
INFO - root - 2017-12-01 05:51:46.100033: step 74590, loss = 0.39, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 11h:17m:45s remains)
INFO - root - 2017-12-01 05:51:47.660086: step 74600, loss = 0.45, batch loss = 0.30 (50.0 examples/sec; 0.160 sec/batch; 11h:27m:23s remains)
INFO - root - 2017-12-01 05:51:49.338242: step 74610, loss = 0.44, batch loss = 0.30 (50.0 examples/sec; 0.160 sec/batch; 11h:27m:24s remains)
INFO - root - 2017-12-01 05:51:50.897469: step 74620, loss = 0.37, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 11h:21m:59s remains)
INFO - root - 2017-12-01 05:51:52.469484: step 74630, loss = 0.36, batch loss = 0.21 (52.7 examples/sec; 0.152 sec/batch; 10h:51m:55s remains)
INFO - root - 2017-12-01 05:51:54.090107: step 74640, loss = 0.35, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 11h:18m:55s remains)
INFO - root - 2017-12-01 05:51:55.656004: step 74650, loss = 0.41, batch loss = 0.26 (49.1 examples/sec; 0.163 sec/batch; 11h:39m:58s remains)
INFO - root - 2017-12-01 05:51:57.247774: step 74660, loss = 0.38, batch loss = 0.23 (51.1 examples/sec; 0.156 sec/batch; 11h:12m:26s remains)
INFO - root - 2017-12-01 05:51:58.804326: step 74670, loss = 0.52, batch loss = 0.37 (52.5 examples/sec; 0.152 sec/batch; 10h:54m:30s remains)
INFO - root - 2017-12-01 05:52:00.349979: step 74680, loss = 0.33, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 11h:03m:16s remains)
INFO - root - 2017-12-01 05:52:01.920161: step 74690, loss = 0.38, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 11h:19m:48s remains)
INFO - root - 2017-12-01 05:52:03.472686: step 74700, loss = 0.36, batch loss = 0.21 (49.3 examples/sec; 0.162 sec/batch; 11h:37m:54s remains)
INFO - root - 2017-12-01 05:52:05.078985: step 74710, loss = 0.33, batch loss = 0.18 (53.2 examples/sec; 0.150 sec/batch; 10h:46m:24s remains)
INFO - root - 2017-12-01 05:52:06.637994: step 74720, loss = 0.35, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 11h:02m:14s remains)
INFO - root - 2017-12-01 05:52:08.178050: step 74730, loss = 0.42, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 11h:07m:42s remains)
INFO - root - 2017-12-01 05:52:09.743832: step 74740, loss = 0.40, batch loss = 0.25 (50.3 examples/sec; 0.159 sec/batch; 11h:22m:46s remains)
INFO - root - 2017-12-01 05:52:11.312367: step 74750, loss = 0.35, batch loss = 0.21 (51.1 examples/sec; 0.156 sec/batch; 11h:12m:08s remains)
INFO - root - 2017-12-01 05:52:12.892571: step 74760, loss = 0.36, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 11h:21m:21s remains)
INFO - root - 2017-12-01 05:52:14.462720: step 74770, loss = 0.49, batch loss = 0.34 (51.4 examples/sec; 0.156 sec/batch; 11h:08m:47s remains)
INFO - root - 2017-12-01 05:52:16.022523: step 74780, loss = 0.37, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 11h:14m:21s remains)
INFO - root - 2017-12-01 05:52:17.569029: step 74790, loss = 0.60, batch loss = 0.45 (52.5 examples/sec; 0.152 sec/batch; 10h:54m:14s remains)
INFO - root - 2017-12-01 05:52:19.127364: step 74800, loss = 0.43, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 11h:01m:38s remains)
INFO - root - 2017-12-01 05:52:20.767053: step 74810, loss = 0.41, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 11h:17m:30s remains)
INFO - root - 2017-12-01 05:52:22.317518: step 74820, loss = 0.36, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 11h:03m:08s remains)
INFO - root - 2017-12-01 05:52:23.874174: step 74830, loss = 0.74, batch loss = 0.59 (52.0 examples/sec; 0.154 sec/batch; 11h:00m:22s remains)
INFO - root - 2017-12-01 05:52:25.424960: step 74840, loss = 0.56, batch loss = 0.41 (51.4 examples/sec; 0.156 sec/batch; 11h:08m:13s remains)
INFO - root - 2017-12-01 05:52:26.977149: step 74850, loss = 0.37, batch loss = 0.22 (52.7 examples/sec; 0.152 sec/batch; 10h:51m:58s remains)
INFO - root - 2017-12-01 05:52:28.544290: step 74860, loss = 0.34, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 11h:01m:29s remains)
INFO - root - 2017-12-01 05:52:30.111444: step 74870, loss = 0.35, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 11h:22m:18s remains)
INFO - root - 2017-12-01 05:52:31.668258: step 74880, loss = 0.40, batch loss = 0.25 (50.0 examples/sec; 0.160 sec/batch; 11h:26m:52s remains)
INFO - root - 2017-12-01 05:52:33.242651: step 74890, loss = 0.40, batch loss = 0.25 (50.5 examples/sec; 0.158 sec/batch; 11h:19m:38s remains)
INFO - root - 2017-12-01 05:52:34.793779: step 74900, loss = 0.35, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 10h:52m:35s remains)
INFO - root - 2017-12-01 05:52:36.433417: step 74910, loss = 0.36, batch loss = 0.21 (49.9 examples/sec; 0.160 sec/batch; 11h:28m:18s remains)
INFO - root - 2017-12-01 05:52:37.988067: step 74920, loss = 0.41, batch loss = 0.26 (49.3 examples/sec; 0.162 sec/batch; 11h:37m:06s remains)
INFO - root - 2017-12-01 05:52:39.540177: step 74930, loss = 0.49, batch loss = 0.34 (51.6 examples/sec; 0.155 sec/batch; 11h:05m:34s remains)
INFO - root - 2017-12-01 05:52:41.102562: step 74940, loss = 0.36, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 11h:16m:40s remains)
INFO - root - 2017-12-01 05:52:42.692740: step 74950, loss = 0.33, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 11h:20m:53s remains)
INFO - root - 2017-12-01 05:52:44.249128: step 74960, loss = 0.55, batch loss = 0.40 (50.9 examples/sec; 0.157 sec/batch; 11h:14m:24s remains)
INFO - root - 2017-12-01 05:52:45.806372: step 74970, loss = 0.38, batch loss = 0.23 (49.7 examples/sec; 0.161 sec/batch; 11h:30m:23s remains)
INFO - root - 2017-12-01 05:52:47.369482: step 74980, loss = 0.40, batch loss = 0.25 (53.3 examples/sec; 0.150 sec/batch; 10h:44m:42s remains)
INFO - root - 2017-12-01 05:52:49.018822: step 74990, loss = 0.52, batch loss = 0.37 (51.1 examples/sec; 0.157 sec/batch; 11h:12m:27s remains)
INFO - root - 2017-12-01 05:52:50.582048: step 75000, loss = 0.38, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 10h:56m:29s remains)
INFO - root - 2017-12-01 05:52:52.205724: step 75010, loss = 0.33, batch loss = 0.18 (52.4 examples/sec; 0.153 sec/batch; 10h:55m:08s remains)
INFO - root - 2017-12-01 05:52:53.805007: step 75020, loss = 0.34, batch loss = 0.19 (48.3 examples/sec; 0.166 sec/batch; 11h:50m:45s remains)
INFO - root - 2017-12-01 05:52:55.404901: step 75030, loss = 0.39, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 10h:57m:44s remains)
INFO - root - 2017-12-01 05:52:56.953136: step 75040, loss = 0.35, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 11h:23m:38s remains)
INFO - root - 2017-12-01 05:52:58.524133: step 75050, loss = 0.34, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 11h:10m:03s remains)
INFO - root - 2017-12-01 05:53:00.073622: step 75060, loss = 0.34, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 11h:26m:43s remains)
INFO - root - 2017-12-01 05:53:01.626405: step 75070, loss = 0.36, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 11h:09m:29s remains)
INFO - root - 2017-12-01 05:53:03.188681: step 75080, loss = 0.39, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 11h:07m:13s remains)
INFO - root - 2017-12-01 05:53:04.745053: step 75090, loss = 0.43, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 11h:16m:47s remains)
INFO - root - 2017-12-01 05:53:06.288673: step 75100, loss = 0.38, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 11h:09m:17s remains)
INFO - root - 2017-12-01 05:53:07.904203: step 75110, loss = 0.40, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 11h:08m:22s remains)
INFO - root - 2017-12-01 05:53:09.511537: step 75120, loss = 0.43, batch loss = 0.29 (50.8 examples/sec; 0.157 sec/batch; 11h:15m:24s remains)
INFO - root - 2017-12-01 05:53:11.075547: step 75130, loss = 0.35, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 11h:14m:03s remains)
INFO - root - 2017-12-01 05:53:12.620861: step 75140, loss = 0.49, batch loss = 0.35 (50.7 examples/sec; 0.158 sec/batch; 11h:16m:27s remains)
INFO - root - 2017-12-01 05:53:14.182139: step 75150, loss = 0.36, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 11h:01m:14s remains)
INFO - root - 2017-12-01 05:53:15.742816: step 75160, loss = 0.41, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 11h:13m:25s remains)
INFO - root - 2017-12-01 05:53:17.311687: step 75170, loss = 0.33, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 11h:15m:19s remains)
INFO - root - 2017-12-01 05:53:18.868139: step 75180, loss = 0.57, batch loss = 0.42 (51.6 examples/sec; 0.155 sec/batch; 11h:04m:44s remains)
INFO - root - 2017-12-01 05:53:20.462426: step 75190, loss = 0.38, batch loss = 0.23 (48.7 examples/sec; 0.164 sec/batch; 11h:44m:10s remains)
INFO - root - 2017-12-01 05:53:22.010436: step 75200, loss = 0.39, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 10h:59m:46s remains)
INFO - root - 2017-12-01 05:53:23.655482: step 75210, loss = 0.36, batch loss = 0.21 (49.6 examples/sec; 0.161 sec/batch; 11h:31m:54s remains)
INFO - root - 2017-12-01 05:53:25.233376: step 75220, loss = 0.50, batch loss = 0.35 (49.8 examples/sec; 0.161 sec/batch; 11h:29m:25s remains)
INFO - root - 2017-12-01 05:53:26.803687: step 75230, loss = 0.40, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 11h:00m:20s remains)
INFO - root - 2017-12-01 05:53:28.391332: step 75240, loss = 0.43, batch loss = 0.29 (51.1 examples/sec; 0.157 sec/batch; 11h:11m:21s remains)
INFO - root - 2017-12-01 05:53:29.950900: step 75250, loss = 0.32, batch loss = 0.17 (50.8 examples/sec; 0.157 sec/batch; 11h:14m:48s remains)
INFO - root - 2017-12-01 05:53:31.509423: step 75260, loss = 0.35, batch loss = 0.20 (49.5 examples/sec; 0.162 sec/batch; 11h:32m:33s remains)
INFO - root - 2017-12-01 05:53:33.074424: step 75270, loss = 0.35, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 11h:07m:42s remains)
INFO - root - 2017-12-01 05:53:34.647188: step 75280, loss = 0.35, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 11h:06m:34s remains)
INFO - root - 2017-12-01 05:53:36.212131: step 75290, loss = 0.30, batch loss = 0.15 (51.1 examples/sec; 0.156 sec/batch; 11h:10m:45s remains)
INFO - root - 2017-12-01 05:53:37.772677: step 75300, loss = 0.34, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 11h:07m:26s remains)
INFO - root - 2017-12-01 05:53:39.415759: step 75310, loss = 0.39, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 11h:20m:31s remains)
INFO - root - 2017-12-01 05:53:40.980953: step 75320, loss = 0.47, batch loss = 0.32 (50.6 examples/sec; 0.158 sec/batch; 11h:17m:50s remains)
INFO - root - 2017-12-01 05:53:42.548195: step 75330, loss = 0.39, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 11h:10m:45s remains)
INFO - root - 2017-12-01 05:53:44.122976: step 75340, loss = 0.34, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 11h:19m:06s remains)
INFO - root - 2017-12-01 05:53:45.685173: step 75350, loss = 0.32, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 11h:09m:53s remains)
INFO - root - 2017-12-01 05:53:47.247497: step 75360, loss = 0.38, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 10h:59m:58s remains)
INFO - root - 2017-12-01 05:53:48.816032: step 75370, loss = 0.32, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 11h:04m:43s remains)
INFO - root - 2017-12-01 05:53:50.374960: step 75380, loss = 0.50, batch loss = 0.36 (49.9 examples/sec; 0.160 sec/batch; 11h:27m:17s remains)
INFO - root - 2017-12-01 05:53:51.920881: step 75390, loss = 0.41, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 11h:04m:12s remains)
INFO - root - 2017-12-01 05:53:53.481726: step 75400, loss = 0.33, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 10h:55m:11s remains)
INFO - root - 2017-12-01 05:53:55.113224: step 75410, loss = 0.32, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 11h:17m:12s remains)
INFO - root - 2017-12-01 05:53:56.690828: step 75420, loss = 0.42, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 10h:59m:21s remains)
INFO - root - 2017-12-01 05:53:58.248579: step 75430, loss = 0.41, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 11h:20m:24s remains)
INFO - root - 2017-12-01 05:53:59.818969: step 75440, loss = 0.49, batch loss = 0.35 (51.2 examples/sec; 0.156 sec/batch; 11h:09m:11s remains)
INFO - root - 2017-12-01 05:54:01.399033: step 75450, loss = 0.39, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 11h:06m:35s remains)
INFO - root - 2017-12-01 05:54:02.946065: step 75460, loss = 0.39, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 11h:01m:50s remains)
INFO - root - 2017-12-01 05:54:04.510209: step 75470, loss = 0.34, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 10h:58m:00s remains)
INFO - root - 2017-12-01 05:54:06.094847: step 75480, loss = 0.39, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 11h:16m:12s remains)
INFO - root - 2017-12-01 05:54:07.683152: step 75490, loss = 0.40, batch loss = 0.25 (50.8 examples/sec; 0.158 sec/batch; 11h:15m:10s remains)
INFO - root - 2017-12-01 05:54:09.244235: step 75500, loss = 0.36, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 11h:23m:24s remains)
INFO - root - 2017-12-01 05:54:10.857948: step 75510, loss = 0.39, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 10h:58m:31s remains)
INFO - root - 2017-12-01 05:54:12.444623: step 75520, loss = 0.51, batch loss = 0.37 (51.7 examples/sec; 0.155 sec/batch; 11h:02m:44s remains)
INFO - root - 2017-12-01 05:54:14.009630: step 75530, loss = 0.34, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 11h:04m:10s remains)
INFO - root - 2017-12-01 05:54:15.575700: step 75540, loss = 0.31, batch loss = 0.16 (53.2 examples/sec; 0.150 sec/batch; 10h:44m:21s remains)
INFO - root - 2017-12-01 05:54:17.137604: step 75550, loss = 0.34, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 10h:59m:49s remains)
INFO - root - 2017-12-01 05:54:18.748941: step 75560, loss = 0.37, batch loss = 0.22 (49.7 examples/sec; 0.161 sec/batch; 11h:29m:11s remains)
INFO - root - 2017-12-01 05:54:20.303350: step 75570, loss = 0.33, batch loss = 0.18 (52.5 examples/sec; 0.152 sec/batch; 10h:52m:53s remains)
INFO - root - 2017-12-01 05:54:21.868269: step 75580, loss = 0.40, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 11h:05m:35s remains)
INFO - root - 2017-12-01 05:54:23.416801: step 75590, loss = 0.38, batch loss = 0.23 (53.0 examples/sec; 0.151 sec/batch; 10h:46m:26s remains)
INFO - root - 2017-12-01 05:54:25.013192: step 75600, loss = 0.38, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 11h:13m:04s remains)
INFO - root - 2017-12-01 05:54:26.648910: step 75610, loss = 0.39, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 11h:13m:07s remains)
INFO - root - 2017-12-01 05:54:28.208328: step 75620, loss = 0.41, batch loss = 0.26 (52.1 examples/sec; 0.154 sec/batch; 10h:57m:55s remains)
INFO - root - 2017-12-01 05:54:29.767404: step 75630, loss = 0.40, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 11h:06m:57s remains)
INFO - root - 2017-12-01 05:54:31.344310: step 75640, loss = 0.42, batch loss = 0.27 (50.0 examples/sec; 0.160 sec/batch; 11h:25m:13s remains)
INFO - root - 2017-12-01 05:54:32.907082: step 75650, loss = 0.34, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 11h:10m:33s remains)
INFO - root - 2017-12-01 05:54:34.474981: step 75660, loss = 0.42, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 11h:06m:45s remains)
INFO - root - 2017-12-01 05:54:36.048530: step 75670, loss = 0.33, batch loss = 0.18 (49.8 examples/sec; 0.161 sec/batch; 11h:27m:35s remains)
INFO - root - 2017-12-01 05:54:37.598428: step 75680, loss = 0.31, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 11h:04m:35s remains)
INFO - root - 2017-12-01 05:54:39.165681: step 75690, loss = 0.31, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 11h:16m:13s remains)
INFO - root - 2017-12-01 05:54:40.722719: step 75700, loss = 0.41, batch loss = 0.26 (53.1 examples/sec; 0.151 sec/batch; 10h:45m:25s remains)
INFO - root - 2017-12-01 05:54:42.340086: step 75710, loss = 0.38, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 10h:54m:33s remains)
INFO - root - 2017-12-01 05:54:43.931203: step 75720, loss = 0.39, batch loss = 0.24 (49.3 examples/sec; 0.162 sec/batch; 11h:34m:25s remains)
INFO - root - 2017-12-01 05:54:45.502580: step 75730, loss = 0.47, batch loss = 0.32 (53.2 examples/sec; 0.150 sec/batch; 10h:43m:21s remains)
INFO - root - 2017-12-01 05:54:47.064205: step 75740, loss = 0.35, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 11h:01m:33s remains)
INFO - root - 2017-12-01 05:54:48.637578: step 75750, loss = 0.41, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 11h:16m:03s remains)
INFO - root - 2017-12-01 05:54:50.194627: step 75760, loss = 0.34, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 11h:06m:01s remains)
INFO - root - 2017-12-01 05:54:51.735907: step 75770, loss = 0.43, batch loss = 0.28 (52.7 examples/sec; 0.152 sec/batch; 10h:49m:51s remains)
INFO - root - 2017-12-01 05:54:53.297365: step 75780, loss = 0.47, batch loss = 0.32 (51.8 examples/sec; 0.155 sec/batch; 11h:01m:22s remains)
INFO - root - 2017-12-01 05:54:54.869966: step 75790, loss = 0.45, batch loss = 0.30 (50.8 examples/sec; 0.158 sec/batch; 11h:13m:53s remains)
INFO - root - 2017-12-01 05:54:56.451977: step 75800, loss = 0.32, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 11h:04m:25s remains)
INFO - root - 2017-12-01 05:54:58.071286: step 75810, loss = 0.35, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 11h:09m:59s remains)
INFO - root - 2017-12-01 05:54:59.647750: step 75820, loss = 0.44, batch loss = 0.30 (51.9 examples/sec; 0.154 sec/batch; 10h:59m:13s remains)
INFO - root - 2017-12-01 05:55:01.217586: step 75830, loss = 0.46, batch loss = 0.31 (50.1 examples/sec; 0.160 sec/batch; 11h:23m:42s remains)
INFO - root - 2017-12-01 05:55:02.774778: step 75840, loss = 0.47, batch loss = 0.33 (50.4 examples/sec; 0.159 sec/batch; 11h:19m:38s remains)
INFO - root - 2017-12-01 05:55:04.341692: step 75850, loss = 0.42, batch loss = 0.27 (52.6 examples/sec; 0.152 sec/batch; 10h:50m:41s remains)
INFO - root - 2017-12-01 05:55:05.900967: step 75860, loss = 0.36, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 11h:19m:46s remains)
INFO - root - 2017-12-01 05:55:07.476217: step 75870, loss = 0.52, batch loss = 0.37 (52.1 examples/sec; 0.153 sec/batch; 10h:56m:28s remains)
INFO - root - 2017-12-01 05:55:09.040850: step 75880, loss = 0.48, batch loss = 0.33 (50.4 examples/sec; 0.159 sec/batch; 11h:19m:03s remains)
INFO - root - 2017-12-01 05:55:10.597420: step 75890, loss = 0.43, batch loss = 0.28 (49.7 examples/sec; 0.161 sec/batch; 11h:28m:50s remains)
INFO - root - 2017-12-01 05:55:12.162381: step 75900, loss = 0.39, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 11h:09m:04s remains)
INFO - root - 2017-12-01 05:55:13.817276: step 75910, loss = 0.32, batch loss = 0.18 (49.4 examples/sec; 0.162 sec/batch; 11h:32m:49s remains)
INFO - root - 2017-12-01 05:55:15.364132: step 75920, loss = 0.36, batch loss = 0.21 (51.8 examples/sec; 0.155 sec/batch; 11h:00m:55s remains)
INFO - root - 2017-12-01 05:55:16.903791: step 75930, loss = 0.32, batch loss = 0.17 (52.5 examples/sec; 0.152 sec/batch; 10h:51m:09s remains)
INFO - root - 2017-12-01 05:55:18.464764: step 75940, loss = 0.48, batch loss = 0.34 (50.5 examples/sec; 0.158 sec/batch; 11h:17m:27s remains)
INFO - root - 2017-12-01 05:55:20.042749: step 75950, loss = 0.32, batch loss = 0.17 (50.7 examples/sec; 0.158 sec/batch; 11h:15m:02s remains)
INFO - root - 2017-12-01 05:55:21.583605: step 75960, loss = 0.45, batch loss = 0.30 (51.8 examples/sec; 0.154 sec/batch; 10h:59m:53s remains)
INFO - root - 2017-12-01 05:55:23.150763: step 75970, loss = 0.34, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 11h:17m:31s remains)
INFO - root - 2017-12-01 05:55:24.715278: step 75980, loss = 0.35, batch loss = 0.20 (49.0 examples/sec; 0.163 sec/batch; 11h:38m:42s remains)
INFO - root - 2017-12-01 05:55:26.284013: step 75990, loss = 0.33, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 11h:18m:31s remains)
INFO - root - 2017-12-01 05:55:27.833186: step 76000, loss = 0.42, batch loss = 0.28 (50.8 examples/sec; 0.158 sec/batch; 11h:13m:21s remains)
INFO - root - 2017-12-01 05:55:29.453446: step 76010, loss = 0.31, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 11h:17m:23s remains)
INFO - root - 2017-12-01 05:55:31.016154: step 76020, loss = 0.34, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 11h:24m:32s remains)
INFO - root - 2017-12-01 05:55:32.573094: step 76030, loss = 0.33, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 11h:07m:49s remains)
INFO - root - 2017-12-01 05:55:34.142098: step 76040, loss = 0.31, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 10h:58m:00s remains)
INFO - root - 2017-12-01 05:55:35.720079: step 76050, loss = 0.35, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 11h:17m:50s remains)
INFO - root - 2017-12-01 05:55:37.285370: step 76060, loss = 0.36, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 11h:22m:28s remains)
INFO - root - 2017-12-01 05:55:38.839470: step 76070, loss = 0.37, batch loss = 0.23 (49.1 examples/sec; 0.163 sec/batch; 11h:36m:58s remains)
INFO - root - 2017-12-01 05:55:40.424791: step 76080, loss = 0.40, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 11h:06m:53s remains)
INFO - root - 2017-12-01 05:55:42.032237: step 76090, loss = 0.41, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 11h:15m:48s remains)
INFO - root - 2017-12-01 05:55:43.572564: step 76100, loss = 0.35, batch loss = 0.21 (53.3 examples/sec; 0.150 sec/batch; 10h:41m:32s remains)
INFO - root - 2017-12-01 05:55:45.224344: step 76110, loss = 0.37, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 11h:15m:32s remains)
INFO - root - 2017-12-01 05:55:46.785677: step 76120, loss = 0.44, batch loss = 0.29 (50.6 examples/sec; 0.158 sec/batch; 11h:15m:03s remains)
INFO - root - 2017-12-01 05:55:48.342004: step 76130, loss = 0.32, batch loss = 0.17 (51.8 examples/sec; 0.154 sec/batch; 10h:59m:17s remains)
INFO - root - 2017-12-01 05:55:49.909172: step 76140, loss = 0.36, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 10h:51m:07s remains)
INFO - root - 2017-12-01 05:55:51.465945: step 76150, loss = 0.40, batch loss = 0.26 (51.8 examples/sec; 0.155 sec/batch; 11h:00m:17s remains)
INFO - root - 2017-12-01 05:55:53.035194: step 76160, loss = 0.33, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 11h:03m:50s remains)
INFO - root - 2017-12-01 05:55:54.600564: step 76170, loss = 0.42, batch loss = 0.27 (50.4 examples/sec; 0.159 sec/batch; 11h:17m:52s remains)
INFO - root - 2017-12-01 05:55:56.193365: step 76180, loss = 0.35, batch loss = 0.21 (48.2 examples/sec; 0.166 sec/batch; 11h:48m:32s remains)
INFO - root - 2017-12-01 05:55:57.771143: step 76190, loss = 0.41, batch loss = 0.27 (52.5 examples/sec; 0.153 sec/batch; 10h:51m:32s remains)
INFO - root - 2017-12-01 05:55:59.327728: step 76200, loss = 0.32, batch loss = 0.18 (53.0 examples/sec; 0.151 sec/batch; 10h:44m:56s remains)
INFO - root - 2017-12-01 05:56:00.950755: step 76210, loss = 0.37, batch loss = 0.22 (49.9 examples/sec; 0.160 sec/batch; 11h:24m:31s remains)
INFO - root - 2017-12-01 05:56:02.538226: step 76220, loss = 0.32, batch loss = 0.17 (52.4 examples/sec; 0.153 sec/batch; 10h:51m:52s remains)
INFO - root - 2017-12-01 05:56:04.096641: step 76230, loss = 0.34, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 11h:00m:29s remains)
INFO - root - 2017-12-01 05:56:05.674227: step 76240, loss = 0.36, batch loss = 0.22 (53.4 examples/sec; 0.150 sec/batch; 10h:39m:42s remains)
INFO - root - 2017-12-01 05:56:07.244995: step 76250, loss = 0.32, batch loss = 0.18 (52.2 examples/sec; 0.153 sec/batch; 10h:54m:45s remains)
INFO - root - 2017-12-01 05:56:08.797503: step 76260, loss = 0.33, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 10h:56m:56s remains)
INFO - root - 2017-12-01 05:56:10.377786: step 76270, loss = 0.42, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 11h:09m:49s remains)
INFO - root - 2017-12-01 05:56:11.962909: step 76280, loss = 0.29, batch loss = 0.15 (51.5 examples/sec; 0.155 sec/batch; 11h:03m:23s remains)
INFO - root - 2017-12-01 05:56:13.519144: step 76290, loss = 0.39, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 11h:06m:17s remains)
INFO - root - 2017-12-01 05:56:15.077797: step 76300, loss = 0.32, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 10h:57m:10s remains)
INFO - root - 2017-12-01 05:56:16.727812: step 76310, loss = 0.35, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 10h:53m:51s remains)
INFO - root - 2017-12-01 05:56:18.279708: step 76320, loss = 0.42, batch loss = 0.27 (51.8 examples/sec; 0.154 sec/batch; 10h:59m:21s remains)
INFO - root - 2017-12-01 05:56:19.848175: step 76330, loss = 0.44, batch loss = 0.29 (53.0 examples/sec; 0.151 sec/batch; 10h:44m:57s remains)
INFO - root - 2017-12-01 05:56:21.422862: step 76340, loss = 0.33, batch loss = 0.19 (51.8 examples/sec; 0.155 sec/batch; 10h:59m:45s remains)
INFO - root - 2017-12-01 05:56:22.993368: step 76350, loss = 0.52, batch loss = 0.38 (51.4 examples/sec; 0.156 sec/batch; 11h:04m:49s remains)
INFO - root - 2017-12-01 05:56:24.554298: step 76360, loss = 0.30, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 10h:57m:24s remains)
INFO - root - 2017-12-01 05:56:26.131781: step 76370, loss = 0.37, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 11h:15m:15s remains)
INFO - root - 2017-12-01 05:56:27.697729: step 76380, loss = 0.35, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 11h:12m:54s remains)
INFO - root - 2017-12-01 05:56:29.270727: step 76390, loss = 0.32, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 11h:00m:09s remains)
INFO - root - 2017-12-01 05:56:30.823186: step 76400, loss = 0.30, batch loss = 0.16 (50.8 examples/sec; 0.157 sec/batch; 11h:11m:31s remains)
INFO - root - 2017-12-01 05:56:32.469525: step 76410, loss = 0.43, batch loss = 0.28 (52.3 examples/sec; 0.153 sec/batch; 10h:52m:56s remains)
INFO - root - 2017-12-01 05:56:34.024310: step 76420, loss = 0.36, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 10h:56m:34s remains)
INFO - root - 2017-12-01 05:56:35.572342: step 76430, loss = 0.30, batch loss = 0.16 (52.3 examples/sec; 0.153 sec/batch; 10h:53m:01s remains)
INFO - root - 2017-12-01 05:56:37.130923: step 76440, loss = 0.35, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 10h:54m:01s remains)
INFO - root - 2017-12-01 05:56:38.720334: step 76450, loss = 0.39, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 11h:03m:56s remains)
INFO - root - 2017-12-01 05:56:40.307920: step 76460, loss = 0.31, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 11h:06m:24s remains)
INFO - root - 2017-12-01 05:56:41.864923: step 76470, loss = 0.50, batch loss = 0.35 (49.0 examples/sec; 0.163 sec/batch; 11h:37m:19s remains)
INFO - root - 2017-12-01 05:56:43.435765: step 76480, loss = 0.33, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 11h:05m:02s remains)
INFO - root - 2017-12-01 05:56:44.993947: step 76490, loss = 0.36, batch loss = 0.22 (52.8 examples/sec; 0.152 sec/batch; 10h:47m:03s remains)
INFO - root - 2017-12-01 05:56:46.540710: step 76500, loss = 0.38, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 10h:53m:35s remains)
INFO - root - 2017-12-01 05:56:48.139620: step 76510, loss = 0.43, batch loss = 0.28 (50.0 examples/sec; 0.160 sec/batch; 11h:22m:50s remains)
INFO - root - 2017-12-01 05:56:49.702141: step 76520, loss = 0.29, batch loss = 0.15 (51.6 examples/sec; 0.155 sec/batch; 11h:00m:56s remains)
INFO - root - 2017-12-01 05:56:51.275611: step 76530, loss = 0.32, batch loss = 0.18 (53.2 examples/sec; 0.150 sec/batch; 10h:41m:26s remains)
INFO - root - 2017-12-01 05:56:52.835066: step 76540, loss = 0.54, batch loss = 0.39 (52.5 examples/sec; 0.152 sec/batch; 10h:50m:03s remains)
INFO - root - 2017-12-01 05:56:54.409844: step 76550, loss = 0.41, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 11h:01m:55s remains)
INFO - root - 2017-12-01 05:56:55.986587: step 76560, loss = 0.40, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 11h:02m:25s remains)
INFO - root - 2017-12-01 05:56:57.544092: step 76570, loss = 0.49, batch loss = 0.34 (51.8 examples/sec; 0.154 sec/batch; 10h:58m:16s remains)
INFO - root - 2017-12-01 05:56:59.100808: step 76580, loss = 0.35, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 11h:09m:42s remains)
INFO - root - 2017-12-01 05:57:00.674735: step 76590, loss = 0.42, batch loss = 0.27 (51.7 examples/sec; 0.155 sec/batch; 10h:59m:58s remains)
INFO - root - 2017-12-01 05:57:02.241634: step 76600, loss = 0.41, batch loss = 0.27 (50.5 examples/sec; 0.158 sec/batch; 11h:15m:02s remains)
INFO - root - 2017-12-01 05:57:03.900116: step 76610, loss = 0.38, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 11h:03m:28s remains)
INFO - root - 2017-12-01 05:57:05.501853: step 76620, loss = 0.34, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 11h:05m:33s remains)
INFO - root - 2017-12-01 05:57:07.051410: step 76630, loss = 0.57, batch loss = 0.42 (53.0 examples/sec; 0.151 sec/batch; 10h:44m:00s remains)
INFO - root - 2017-12-01 05:57:08.606127: step 76640, loss = 0.33, batch loss = 0.18 (52.1 examples/sec; 0.154 sec/batch; 10h:54m:45s remains)
INFO - root - 2017-12-01 05:57:10.201876: step 76650, loss = 0.40, batch loss = 0.26 (49.4 examples/sec; 0.162 sec/batch; 11h:29m:56s remains)
INFO - root - 2017-12-01 05:57:11.768093: step 76660, loss = 0.32, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 11h:06m:29s remains)
INFO - root - 2017-12-01 05:57:13.337471: step 76670, loss = 0.40, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 11h:09m:25s remains)
INFO - root - 2017-12-01 05:57:14.902525: step 76680, loss = 0.38, batch loss = 0.23 (50.4 examples/sec; 0.159 sec/batch; 11h:16m:59s remains)
INFO - root - 2017-12-01 05:57:16.471672: step 76690, loss = 0.39, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 11h:07m:09s remains)
INFO - root - 2017-12-01 05:57:18.045548: step 76700, loss = 0.37, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 11h:12m:08s remains)
INFO - root - 2017-12-01 05:57:19.688862: step 76710, loss = 0.48, batch loss = 0.33 (51.4 examples/sec; 0.156 sec/batch; 11h:03m:53s remains)
INFO - root - 2017-12-01 05:57:21.249621: step 76720, loss = 0.33, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 11h:00m:53s remains)
INFO - root - 2017-12-01 05:57:22.818154: step 76730, loss = 0.36, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 11h:16m:12s remains)
INFO - root - 2017-12-01 05:57:24.388040: step 76740, loss = 0.42, batch loss = 0.27 (49.1 examples/sec; 0.163 sec/batch; 11h:34m:30s remains)
INFO - root - 2017-12-01 05:57:25.964260: step 76750, loss = 0.38, batch loss = 0.23 (50.5 examples/sec; 0.159 sec/batch; 11h:15m:37s remains)
INFO - root - 2017-12-01 05:57:27.566611: step 76760, loss = 0.32, batch loss = 0.18 (52.2 examples/sec; 0.153 sec/batch; 10h:53m:42s remains)
INFO - root - 2017-12-01 05:57:29.115489: step 76770, loss = 0.35, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 11h:12m:24s remains)
INFO - root - 2017-12-01 05:57:30.681761: step 76780, loss = 0.42, batch loss = 0.28 (49.8 examples/sec; 0.161 sec/batch; 11h:24m:14s remains)
INFO - root - 2017-12-01 05:57:32.257062: step 76790, loss = 0.40, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 10h:51m:45s remains)
INFO - root - 2017-12-01 05:57:33.807775: step 76800, loss = 0.38, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 10h:59m:32s remains)
INFO - root - 2017-12-01 05:57:35.443462: step 76810, loss = 0.42, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 10h:56m:10s remains)
INFO - root - 2017-12-01 05:57:37.001129: step 76820, loss = 0.39, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 10h:58m:13s remains)
INFO - root - 2017-12-01 05:57:38.572055: step 76830, loss = 0.47, batch loss = 0.32 (52.7 examples/sec; 0.152 sec/batch; 10h:47m:21s remains)
INFO - root - 2017-12-01 05:57:40.123461: step 76840, loss = 0.40, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 11h:13m:35s remains)
INFO - root - 2017-12-01 05:57:41.681645: step 76850, loss = 0.45, batch loss = 0.30 (52.5 examples/sec; 0.153 sec/batch; 10h:49m:47s remains)
INFO - root - 2017-12-01 05:57:43.236175: step 76860, loss = 0.46, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 11h:12m:37s remains)
INFO - root - 2017-12-01 05:57:44.808456: step 76870, loss = 0.42, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 10h:56m:59s remains)
INFO - root - 2017-12-01 05:57:46.372254: step 76880, loss = 0.43, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 10h:56m:35s remains)
INFO - root - 2017-12-01 05:57:47.942607: step 76890, loss = 0.37, batch loss = 0.22 (52.1 examples/sec; 0.153 sec/batch; 10h:53m:50s remains)
INFO - root - 2017-12-01 05:57:49.510613: step 76900, loss = 0.36, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 11h:13m:25s remains)
INFO - root - 2017-12-01 05:57:51.135964: step 76910, loss = 0.31, batch loss = 0.16 (52.1 examples/sec; 0.154 sec/batch; 10h:54m:30s remains)
INFO - root - 2017-12-01 05:57:52.707326: step 76920, loss = 0.46, batch loss = 0.31 (51.9 examples/sec; 0.154 sec/batch; 10h:56m:29s remains)
INFO - root - 2017-12-01 05:57:54.276119: step 76930, loss = 0.64, batch loss = 0.50 (49.8 examples/sec; 0.160 sec/batch; 11h:23m:38s remains)
INFO - root - 2017-12-01 05:57:55.839293: step 76940, loss = 0.45, batch loss = 0.30 (50.4 examples/sec; 0.159 sec/batch; 11h:15m:52s remains)
INFO - root - 2017-12-01 05:57:57.387451: step 76950, loss = 0.43, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 11h:17m:04s remains)
INFO - root - 2017-12-01 05:57:58.944570: step 76960, loss = 0.37, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 10h:57m:20s remains)
INFO - root - 2017-12-01 05:58:00.510519: step 76970, loss = 0.48, batch loss = 0.33 (50.6 examples/sec; 0.158 sec/batch; 11h:13m:45s remains)
INFO - root - 2017-12-01 05:58:02.074502: step 76980, loss = 0.40, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 11h:03m:35s remains)
INFO - root - 2017-12-01 05:58:03.633357: step 76990, loss = 0.41, batch loss = 0.26 (50.3 examples/sec; 0.159 sec/batch; 11h:17m:21s remains)
INFO - root - 2017-12-01 05:58:05.198264: step 77000, loss = 0.32, batch loss = 0.18 (49.4 examples/sec; 0.162 sec/batch; 11h:29m:45s remains)
INFO - root - 2017-12-01 05:58:06.813733: step 77010, loss = 0.41, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 10h:52m:03s remains)
INFO - root - 2017-12-01 05:58:08.373073: step 77020, loss = 0.33, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 11h:07m:13s remains)
INFO - root - 2017-12-01 05:58:09.939752: step 77030, loss = 0.44, batch loss = 0.30 (50.6 examples/sec; 0.158 sec/batch; 11h:13m:49s remains)
INFO - root - 2017-12-01 05:58:11.505435: step 77040, loss = 0.57, batch loss = 0.42 (52.1 examples/sec; 0.154 sec/batch; 10h:54m:14s remains)
INFO - root - 2017-12-01 05:58:13.061911: step 77050, loss = 0.38, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 10h:58m:18s remains)
INFO - root - 2017-12-01 05:58:14.627771: step 77060, loss = 0.45, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 10h:59m:33s remains)
INFO - root - 2017-12-01 05:58:16.193933: step 77070, loss = 0.35, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 11h:12m:54s remains)
INFO - root - 2017-12-01 05:58:17.750604: step 77080, loss = 0.34, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 11h:09m:51s remains)
INFO - root - 2017-12-01 05:58:19.302286: step 77090, loss = 0.57, batch loss = 0.43 (51.4 examples/sec; 0.156 sec/batch; 11h:02m:47s remains)
INFO - root - 2017-12-01 05:58:20.857174: step 77100, loss = 0.38, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 11h:07m:26s remains)
INFO - root - 2017-12-01 05:58:22.493016: step 77110, loss = 0.33, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 11h:06m:18s remains)
INFO - root - 2017-12-01 05:58:24.053756: step 77120, loss = 0.41, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 11h:01m:05s remains)
INFO - root - 2017-12-01 05:58:25.627680: step 77130, loss = 0.40, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 11h:01m:09s remains)
INFO - root - 2017-12-01 05:58:27.193382: step 77140, loss = 0.40, batch loss = 0.26 (52.1 examples/sec; 0.154 sec/batch; 10h:53m:51s remains)
INFO - root - 2017-12-01 05:58:28.766742: step 77150, loss = 0.34, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 11h:11m:06s remains)
INFO - root - 2017-12-01 05:58:30.339500: step 77160, loss = 0.35, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 11h:20m:08s remains)
INFO - root - 2017-12-01 05:58:31.895246: step 77170, loss = 0.38, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 10h:54m:47s remains)
INFO - root - 2017-12-01 05:58:33.454552: step 77180, loss = 0.36, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 10h:59m:40s remains)
INFO - root - 2017-12-01 05:58:35.021016: step 77190, loss = 0.42, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 11h:02m:24s remains)
INFO - root - 2017-12-01 05:58:36.599104: step 77200, loss = 0.38, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 11h:05m:23s remains)
INFO - root - 2017-12-01 05:58:38.305033: step 77210, loss = 0.29, batch loss = 0.14 (50.4 examples/sec; 0.159 sec/batch; 11h:15m:33s remains)
INFO - root - 2017-12-01 05:58:39.864569: step 77220, loss = 0.52, batch loss = 0.37 (49.7 examples/sec; 0.161 sec/batch; 11h:24m:59s remains)
INFO - root - 2017-12-01 05:58:41.440218: step 77230, loss = 0.32, batch loss = 0.18 (47.8 examples/sec; 0.167 sec/batch; 11h:52m:24s remains)
INFO - root - 2017-12-01 05:58:43.028259: step 77240, loss = 0.44, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 11h:00m:54s remains)
INFO - root - 2017-12-01 05:58:44.598614: step 77250, loss = 0.31, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 11h:12m:46s remains)
INFO - root - 2017-12-01 05:58:46.157947: step 77260, loss = 0.42, batch loss = 0.27 (50.0 examples/sec; 0.160 sec/batch; 11h:20m:36s remains)
INFO - root - 2017-12-01 05:58:47.719376: step 77270, loss = 0.38, batch loss = 0.24 (53.2 examples/sec; 0.150 sec/batch; 10h:39m:35s remains)
INFO - root - 2017-12-01 05:58:49.280495: step 77280, loss = 0.37, batch loss = 0.22 (52.8 examples/sec; 0.152 sec/batch; 10h:44m:29s remains)
INFO - root - 2017-12-01 05:58:50.847849: step 77290, loss = 0.54, batch loss = 0.39 (52.4 examples/sec; 0.153 sec/batch; 10h:48m:47s remains)
INFO - root - 2017-12-01 05:58:52.417628: step 77300, loss = 0.34, batch loss = 0.19 (49.7 examples/sec; 0.161 sec/batch; 11h:24m:52s remains)
INFO - root - 2017-12-01 05:58:54.045485: step 77310, loss = 0.37, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 11h:04m:13s remains)
INFO - root - 2017-12-01 05:58:55.597560: step 77320, loss = 0.43, batch loss = 0.29 (52.0 examples/sec; 0.154 sec/batch; 10h:54m:36s remains)
INFO - root - 2017-12-01 05:58:57.157514: step 77330, loss = 0.29, batch loss = 0.15 (51.2 examples/sec; 0.156 sec/batch; 11h:05m:01s remains)
INFO - root - 2017-12-01 05:58:58.717358: step 77340, loss = 0.30, batch loss = 0.15 (50.5 examples/sec; 0.158 sec/batch; 11h:13m:34s remains)
INFO - root - 2017-12-01 05:59:00.282891: step 77350, loss = 0.58, batch loss = 0.44 (50.5 examples/sec; 0.158 sec/batch; 11h:13m:59s remains)
INFO - root - 2017-12-01 05:59:01.866100: step 77360, loss = 0.44, batch loss = 0.30 (51.9 examples/sec; 0.154 sec/batch; 10h:55m:53s remains)
INFO - root - 2017-12-01 05:59:03.423264: step 77370, loss = 0.31, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 11h:06m:26s remains)
INFO - root - 2017-12-01 05:59:05.015599: step 77380, loss = 0.32, batch loss = 0.18 (49.4 examples/sec; 0.162 sec/batch; 11h:29m:14s remains)
INFO - root - 2017-12-01 05:59:06.576193: step 77390, loss = 0.49, batch loss = 0.35 (52.7 examples/sec; 0.152 sec/batch; 10h:45m:47s remains)
INFO - root - 2017-12-01 05:59:08.131212: step 77400, loss = 0.28, batch loss = 0.14 (50.1 examples/sec; 0.160 sec/batch; 11h:18m:33s remains)
INFO - root - 2017-12-01 05:59:09.770864: step 77410, loss = 0.44, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 11h:02m:11s remains)
INFO - root - 2017-12-01 05:59:11.355346: step 77420, loss = 0.36, batch loss = 0.21 (52.9 examples/sec; 0.151 sec/batch; 10h:42m:38s remains)
INFO - root - 2017-12-01 05:59:12.917973: step 77430, loss = 0.33, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 11h:08m:12s remains)
INFO - root - 2017-12-01 05:59:14.492267: step 77440, loss = 0.35, batch loss = 0.21 (51.1 examples/sec; 0.156 sec/batch; 11h:05m:00s remains)
INFO - root - 2017-12-01 05:59:16.052268: step 77450, loss = 0.30, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 11h:14m:29s remains)
INFO - root - 2017-12-01 05:59:17.607236: step 77460, loss = 0.37, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 10h:54m:29s remains)
INFO - root - 2017-12-01 05:59:19.186051: step 77470, loss = 0.32, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 10h:59m:02s remains)
INFO - root - 2017-12-01 05:59:20.754129: step 77480, loss = 0.38, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 10h:59m:57s remains)
INFO - root - 2017-12-01 05:59:22.318151: step 77490, loss = 0.40, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 11h:14m:20s remains)
INFO - root - 2017-12-01 05:59:23.884504: step 77500, loss = 0.29, batch loss = 0.14 (50.2 examples/sec; 0.159 sec/batch; 11h:17m:00s remains)
INFO - root - 2017-12-01 05:59:25.523658: step 77510, loss = 0.33, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 11h:06m:58s remains)
INFO - root - 2017-12-01 05:59:27.081678: step 77520, loss = 0.31, batch loss = 0.16 (51.7 examples/sec; 0.155 sec/batch; 10h:57m:22s remains)
INFO - root - 2017-12-01 05:59:28.648307: step 77530, loss = 0.42, batch loss = 0.27 (50.1 examples/sec; 0.160 sec/batch; 11h:18m:43s remains)
INFO - root - 2017-12-01 05:59:30.208616: step 77540, loss = 0.36, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 10h:58m:37s remains)
INFO - root - 2017-12-01 05:59:31.784955: step 77550, loss = 0.52, batch loss = 0.38 (50.5 examples/sec; 0.159 sec/batch; 11h:13m:41s remains)
INFO - root - 2017-12-01 05:59:33.348572: step 77560, loss = 0.30, batch loss = 0.16 (51.0 examples/sec; 0.157 sec/batch; 11h:06m:03s remains)
INFO - root - 2017-12-01 05:59:34.923430: step 77570, loss = 0.44, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 10h:59m:51s remains)
INFO - root - 2017-12-01 05:59:36.476002: step 77580, loss = 0.31, batch loss = 0.17 (52.8 examples/sec; 0.152 sec/batch; 10h:43m:58s remains)
INFO - root - 2017-12-01 05:59:38.038351: step 77590, loss = 0.32, batch loss = 0.18 (50.5 examples/sec; 0.159 sec/batch; 11h:13m:34s remains)
INFO - root - 2017-12-01 05:59:39.607608: step 77600, loss = 0.35, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 11h:02m:46s remains)
INFO - root - 2017-12-01 05:59:41.233096: step 77610, loss = 0.37, batch loss = 0.22 (49.7 examples/sec; 0.161 sec/batch; 11h:23m:39s remains)
INFO - root - 2017-12-01 05:59:42.804121: step 77620, loss = 0.45, batch loss = 0.31 (52.4 examples/sec; 0.153 sec/batch; 10h:48m:08s remains)
INFO - root - 2017-12-01 05:59:44.371517: step 77630, loss = 0.39, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 10h:54m:26s remains)
INFO - root - 2017-12-01 05:59:45.933615: step 77640, loss = 0.44, batch loss = 0.29 (50.5 examples/sec; 0.158 sec/batch; 11h:12m:14s remains)
INFO - root - 2017-12-01 05:59:47.495476: step 77650, loss = 0.35, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 11h:10m:35s remains)
INFO - root - 2017-12-01 05:59:49.058549: step 77660, loss = 0.43, batch loss = 0.28 (49.8 examples/sec; 0.161 sec/batch; 11h:22m:14s remains)
INFO - root - 2017-12-01 05:59:50.625903: step 77670, loss = 0.35, batch loss = 0.21 (52.9 examples/sec; 0.151 sec/batch; 10h:42m:22s remains)
INFO - root - 2017-12-01 05:59:52.201204: step 77680, loss = 0.33, batch loss = 0.18 (51.1 examples/sec; 0.156 sec/batch; 11h:04m:36s remains)
INFO - root - 2017-12-01 05:59:53.763406: step 77690, loss = 0.32, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 11h:08m:48s remains)
INFO - root - 2017-12-01 05:59:55.356713: step 77700, loss = 0.40, batch loss = 0.25 (48.5 examples/sec; 0.165 sec/batch; 11h:40m:20s remains)
INFO - root - 2017-12-01 05:59:56.988165: step 77710, loss = 0.48, batch loss = 0.34 (50.7 examples/sec; 0.158 sec/batch; 11h:10m:18s remains)
INFO - root - 2017-12-01 05:59:58.551289: step 77720, loss = 0.37, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 11h:15m:15s remains)
INFO - root - 2017-12-01 06:00:00.114455: step 77730, loss = 0.34, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 11h:11m:08s remains)
INFO - root - 2017-12-01 06:00:01.702391: step 77740, loss = 0.30, batch loss = 0.16 (50.3 examples/sec; 0.159 sec/batch; 11h:14m:56s remains)
INFO - root - 2017-12-01 06:00:03.272303: step 77750, loss = 0.33, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 11h:16m:35s remains)
INFO - root - 2017-12-01 06:00:04.840083: step 77760, loss = 0.31, batch loss = 0.17 (48.4 examples/sec; 0.165 sec/batch; 11h:42m:08s remains)
INFO - root - 2017-12-01 06:00:06.430231: step 77770, loss = 0.34, batch loss = 0.20 (49.6 examples/sec; 0.161 sec/batch; 11h:24m:50s remains)
INFO - root - 2017-12-01 06:00:07.998086: step 77780, loss = 0.43, batch loss = 0.29 (50.2 examples/sec; 0.159 sec/batch; 11h:16m:16s remains)
INFO - root - 2017-12-01 06:00:09.569400: step 77790, loss = 0.40, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 10h:59m:33s remains)
INFO - root - 2017-12-01 06:00:11.144141: step 77800, loss = 0.34, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 11h:08m:47s remains)
INFO - root - 2017-12-01 06:00:12.805783: step 77810, loss = 0.50, batch loss = 0.36 (50.2 examples/sec; 0.159 sec/batch; 11h:15m:53s remains)
INFO - root - 2017-12-01 06:00:14.367570: step 77820, loss = 0.48, batch loss = 0.33 (52.3 examples/sec; 0.153 sec/batch; 10h:48m:56s remains)
INFO - root - 2017-12-01 06:00:15.924802: step 77830, loss = 0.36, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 10h:58m:04s remains)
INFO - root - 2017-12-01 06:00:17.480186: step 77840, loss = 0.38, batch loss = 0.24 (53.4 examples/sec; 0.150 sec/batch; 10h:35m:18s remains)
INFO - root - 2017-12-01 06:00:19.047132: step 77850, loss = 0.38, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 11h:04m:45s remains)
INFO - root - 2017-12-01 06:00:20.618366: step 77860, loss = 0.36, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 10h:58m:19s remains)
INFO - root - 2017-12-01 06:00:22.167112: step 77870, loss = 0.39, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 11h:04m:50s remains)
INFO - root - 2017-12-01 06:00:23.730355: step 77880, loss = 0.32, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 10h:56m:41s remains)
INFO - root - 2017-12-01 06:00:25.288673: step 77890, loss = 0.34, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 11h:18m:40s remains)
INFO - root - 2017-12-01 06:00:26.861964: step 77900, loss = 0.33, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 11h:06m:30s remains)
INFO - root - 2017-12-01 06:00:28.474451: step 77910, loss = 0.46, batch loss = 0.32 (50.8 examples/sec; 0.157 sec/batch; 11h:08m:01s remains)
INFO - root - 2017-12-01 06:00:30.029877: step 77920, loss = 0.33, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 10h:53m:02s remains)
INFO - root - 2017-12-01 06:00:31.607962: step 77930, loss = 0.53, batch loss = 0.38 (50.7 examples/sec; 0.158 sec/batch; 11h:09m:28s remains)
INFO - root - 2017-12-01 06:00:33.157714: step 77940, loss = 0.36, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 10h:54m:08s remains)
INFO - root - 2017-12-01 06:00:34.737168: step 77950, loss = 0.36, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 11h:15m:12s remains)
INFO - root - 2017-12-01 06:00:36.291158: step 77960, loss = 0.34, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 11h:11m:39s remains)
INFO - root - 2017-12-01 06:00:37.869243: step 77970, loss = 0.34, batch loss = 0.20 (49.6 examples/sec; 0.161 sec/batch; 11h:23m:42s remains)
INFO - root - 2017-12-01 06:00:39.445126: step 77980, loss = 0.38, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 10h:55m:51s remains)
INFO - root - 2017-12-01 06:00:41.015132: step 77990, loss = 0.35, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 10h:55m:05s remains)
INFO - root - 2017-12-01 06:00:42.568822: step 78000, loss = 0.43, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 11h:02m:13s remains)
INFO - root - 2017-12-01 06:00:44.217626: step 78010, loss = 0.30, batch loss = 0.16 (52.6 examples/sec; 0.152 sec/batch; 10h:44m:52s remains)
INFO - root - 2017-12-01 06:00:45.779607: step 78020, loss = 0.39, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 11h:06m:56s remains)
INFO - root - 2017-12-01 06:00:47.346500: step 78030, loss = 0.35, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 10h:51m:27s remains)
INFO - root - 2017-12-01 06:00:48.910709: step 78040, loss = 0.30, batch loss = 0.16 (53.2 examples/sec; 0.151 sec/batch; 10h:38m:18s remains)
INFO - root - 2017-12-01 06:00:50.473698: step 78050, loss = 0.31, batch loss = 0.17 (52.4 examples/sec; 0.153 sec/batch; 10h:47m:24s remains)
INFO - root - 2017-12-01 06:00:52.052676: step 78060, loss = 0.46, batch loss = 0.32 (51.3 examples/sec; 0.156 sec/batch; 11h:01m:27s remains)
INFO - root - 2017-12-01 06:00:53.620954: step 78070, loss = 0.41, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 11h:08m:41s remains)
INFO - root - 2017-12-01 06:00:55.206816: step 78080, loss = 0.31, batch loss = 0.16 (48.1 examples/sec; 0.166 sec/batch; 11h:44m:46s remains)
INFO - root - 2017-12-01 06:00:56.790295: step 78090, loss = 0.36, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 11h:03m:53s remains)
INFO - root - 2017-12-01 06:00:58.363567: step 78100, loss = 0.30, batch loss = 0.15 (51.9 examples/sec; 0.154 sec/batch; 10h:53m:26s remains)
INFO - root - 2017-12-01 06:00:59.987465: step 78110, loss = 0.35, batch loss = 0.21 (53.9 examples/sec; 0.149 sec/batch; 10h:29m:44s remains)
INFO - root - 2017-12-01 06:01:01.565562: step 78120, loss = 0.32, batch loss = 0.17 (51.8 examples/sec; 0.154 sec/batch; 10h:54m:29s remains)
INFO - root - 2017-12-01 06:01:03.144663: step 78130, loss = 0.31, batch loss = 0.17 (48.6 examples/sec; 0.164 sec/batch; 11h:37m:09s remains)
INFO - root - 2017-12-01 06:01:04.697142: step 78140, loss = 0.40, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 11h:05m:04s remains)
INFO - root - 2017-12-01 06:01:06.258264: step 78150, loss = 0.31, batch loss = 0.17 (52.6 examples/sec; 0.152 sec/batch; 10h:44m:22s remains)
INFO - root - 2017-12-01 06:01:07.824683: step 78160, loss = 0.35, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 11h:06m:23s remains)
INFO - root - 2017-12-01 06:01:09.415586: step 78170, loss = 0.35, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 11h:06m:06s remains)
INFO - root - 2017-12-01 06:01:10.981318: step 78180, loss = 0.30, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 10h:52m:02s remains)
INFO - root - 2017-12-01 06:01:12.552514: step 78190, loss = 0.34, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 11h:10m:35s remains)
INFO - root - 2017-12-01 06:01:14.124316: step 78200, loss = 0.36, batch loss = 0.22 (48.4 examples/sec; 0.165 sec/batch; 11h:40m:13s remains)
INFO - root - 2017-12-01 06:01:15.781469: step 78210, loss = 0.30, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 10h:57m:38s remains)
INFO - root - 2017-12-01 06:01:17.354367: step 78220, loss = 0.42, batch loss = 0.28 (53.0 examples/sec; 0.151 sec/batch; 10h:39m:20s remains)
INFO - root - 2017-12-01 06:01:18.897810: step 78230, loss = 0.35, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 11h:00m:44s remains)
INFO - root - 2017-12-01 06:01:20.458982: step 78240, loss = 0.39, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 10h:56m:43s remains)
INFO - root - 2017-12-01 06:01:22.040740: step 78250, loss = 0.40, batch loss = 0.26 (48.8 examples/sec; 0.164 sec/batch; 11h:34m:13s remains)
INFO - root - 2017-12-01 06:01:23.600604: step 78260, loss = 0.41, batch loss = 0.27 (53.1 examples/sec; 0.151 sec/batch; 10h:38m:16s remains)
INFO - root - 2017-12-01 06:01:25.194763: step 78270, loss = 0.38, batch loss = 0.24 (50.8 examples/sec; 0.158 sec/batch; 11h:07m:51s remains)
INFO - root - 2017-12-01 06:01:26.774588: step 78280, loss = 0.42, batch loss = 0.27 (50.5 examples/sec; 0.158 sec/batch; 11h:10m:58s remains)
INFO - root - 2017-12-01 06:01:28.322398: step 78290, loss = 0.38, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 10h:54m:08s remains)
INFO - root - 2017-12-01 06:01:29.896577: step 78300, loss = 0.48, batch loss = 0.34 (52.6 examples/sec; 0.152 sec/batch; 10h:44m:43s remains)
INFO - root - 2017-12-01 06:01:31.516077: step 78310, loss = 0.37, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 11h:14m:04s remains)
INFO - root - 2017-12-01 06:01:33.073112: step 78320, loss = 0.37, batch loss = 0.22 (49.9 examples/sec; 0.160 sec/batch; 11h:18m:30s remains)
INFO - root - 2017-12-01 06:01:34.636381: step 78330, loss = 0.37, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 10h:55m:29s remains)
INFO - root - 2017-12-01 06:01:36.218625: step 78340, loss = 0.33, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 11h:03m:26s remains)
INFO - root - 2017-12-01 06:01:37.784036: step 78350, loss = 0.36, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 11h:14m:36s remains)
INFO - root - 2017-12-01 06:01:39.365891: step 78360, loss = 0.43, batch loss = 0.28 (44.3 examples/sec; 0.181 sec/batch; 12h:44m:42s remains)
INFO - root - 2017-12-01 06:01:40.928522: step 78370, loss = 0.33, batch loss = 0.18 (48.8 examples/sec; 0.164 sec/batch; 11h:33m:48s remains)
INFO - root - 2017-12-01 06:01:42.518128: step 78380, loss = 0.31, batch loss = 0.17 (51.8 examples/sec; 0.154 sec/batch; 10h:53m:43s remains)
INFO - root - 2017-12-01 06:01:44.088769: step 78390, loss = 0.38, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 11h:10m:33s remains)
INFO - root - 2017-12-01 06:01:45.671049: step 78400, loss = 0.37, batch loss = 0.23 (48.2 examples/sec; 0.166 sec/batch; 11h:43m:03s remains)
INFO - root - 2017-12-01 06:01:47.324635: step 78410, loss = 0.32, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 11h:10m:47s remains)
INFO - root - 2017-12-01 06:01:48.893223: step 78420, loss = 0.37, batch loss = 0.23 (50.0 examples/sec; 0.160 sec/batch; 11h:17m:10s remains)
INFO - root - 2017-12-01 06:01:50.443661: step 78430, loss = 0.42, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 11h:03m:36s remains)
INFO - root - 2017-12-01 06:01:52.007022: step 78440, loss = 0.36, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 11h:00m:20s remains)
INFO - root - 2017-12-01 06:01:53.569279: step 78450, loss = 0.29, batch loss = 0.15 (52.3 examples/sec; 0.153 sec/batch; 10h:47m:50s remains)
INFO - root - 2017-12-01 06:01:55.140992: step 78460, loss = 0.37, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 11h:07m:05s remains)
INFO - root - 2017-12-01 06:01:56.691599: step 78470, loss = 0.35, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 10h:46m:58s remains)
INFO - root - 2017-12-01 06:01:58.251385: step 78480, loss = 0.36, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 10h:51m:41s remains)
INFO - root - 2017-12-01 06:01:59.808625: step 78490, loss = 0.38, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 10h:48m:35s remains)
INFO - root - 2017-12-01 06:02:01.369865: step 78500, loss = 0.39, batch loss = 0.25 (53.5 examples/sec; 0.149 sec/batch; 10h:32m:31s remains)
INFO - root - 2017-12-01 06:02:03.001950: step 78510, loss = 0.51, batch loss = 0.36 (51.1 examples/sec; 0.157 sec/batch; 11h:02m:59s remains)
INFO - root - 2017-12-01 06:02:04.594800: step 78520, loss = 0.38, batch loss = 0.24 (53.0 examples/sec; 0.151 sec/batch; 10h:39m:12s remains)
INFO - root - 2017-12-01 06:02:06.174463: step 78530, loss = 0.42, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 10h:57m:12s remains)
INFO - root - 2017-12-01 06:02:07.729905: step 78540, loss = 0.41, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 11h:03m:13s remains)
INFO - root - 2017-12-01 06:02:09.291716: step 78550, loss = 0.44, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 11h:01m:14s remains)
INFO - root - 2017-12-01 06:02:10.857325: step 78560, loss = 0.36, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 10h:47m:04s remains)
INFO - root - 2017-12-01 06:02:12.448346: step 78570, loss = 0.35, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 11h:11m:41s remains)
INFO - root - 2017-12-01 06:02:14.027712: step 78580, loss = 0.36, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 11h:13m:36s remains)
INFO - root - 2017-12-01 06:02:15.592347: step 78590, loss = 0.35, batch loss = 0.20 (49.2 examples/sec; 0.163 sec/batch; 11h:28m:15s remains)
INFO - root - 2017-12-01 06:02:17.172405: step 78600, loss = 0.49, batch loss = 0.34 (51.4 examples/sec; 0.156 sec/batch; 10h:58m:12s remains)
INFO - root - 2017-12-01 06:02:18.783373: step 78610, loss = 0.63, batch loss = 0.48 (50.9 examples/sec; 0.157 sec/batch; 11h:04m:46s remains)
INFO - root - 2017-12-01 06:02:20.344647: step 78620, loss = 0.34, batch loss = 0.19 (51.8 examples/sec; 0.155 sec/batch; 10h:53m:57s remains)
INFO - root - 2017-12-01 06:02:21.905844: step 78630, loss = 0.55, batch loss = 0.41 (50.6 examples/sec; 0.158 sec/batch; 11h:08m:48s remains)
INFO - root - 2017-12-01 06:02:23.502109: step 78640, loss = 0.32, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 11h:12m:07s remains)
INFO - root - 2017-12-01 06:02:25.096812: step 78650, loss = 0.33, batch loss = 0.19 (49.4 examples/sec; 0.162 sec/batch; 11h:24m:56s remains)
INFO - root - 2017-12-01 06:02:26.663578: step 78660, loss = 0.42, batch loss = 0.27 (52.8 examples/sec; 0.151 sec/batch; 10h:40m:45s remains)
INFO - root - 2017-12-01 06:02:28.231175: step 78670, loss = 0.44, batch loss = 0.30 (51.7 examples/sec; 0.155 sec/batch; 10h:54m:01s remains)
INFO - root - 2017-12-01 06:02:29.800605: step 78680, loss = 0.42, batch loss = 0.28 (51.1 examples/sec; 0.157 sec/batch; 11h:02m:18s remains)
INFO - root - 2017-12-01 06:02:31.366657: step 78690, loss = 0.39, batch loss = 0.25 (49.9 examples/sec; 0.160 sec/batch; 11h:18m:46s remains)
INFO - root - 2017-12-01 06:02:32.920245: step 78700, loss = 0.41, batch loss = 0.26 (49.7 examples/sec; 0.161 sec/batch; 11h:20m:47s remains)
INFO - root - 2017-12-01 06:02:34.571600: step 78710, loss = 0.34, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 11h:14m:57s remains)
INFO - root - 2017-12-01 06:02:36.134156: step 78720, loss = 0.43, batch loss = 0.29 (50.4 examples/sec; 0.159 sec/batch; 11h:11m:24s remains)
INFO - root - 2017-12-01 06:02:37.688229: step 78730, loss = 0.39, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 10h:51m:12s remains)
INFO - root - 2017-12-01 06:02:39.244512: step 78740, loss = 0.36, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 10h:50m:37s remains)
INFO - root - 2017-12-01 06:02:40.814498: step 78750, loss = 0.37, batch loss = 0.22 (52.9 examples/sec; 0.151 sec/batch; 10h:39m:59s remains)
INFO - root - 2017-12-01 06:02:42.376470: step 78760, loss = 0.37, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 11h:04m:07s remains)
INFO - root - 2017-12-01 06:02:43.944173: step 78770, loss = 0.35, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 11h:10m:46s remains)
INFO - root - 2017-12-01 06:02:45.501808: step 78780, loss = 0.30, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 10h:57m:00s remains)
INFO - root - 2017-12-01 06:02:47.070535: step 78790, loss = 0.43, batch loss = 0.29 (48.7 examples/sec; 0.164 sec/batch; 11h:34m:31s remains)
INFO - root - 2017-12-01 06:02:48.640066: step 78800, loss = 0.31, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 11h:07m:58s remains)
INFO - root - 2017-12-01 06:02:50.259317: step 78810, loss = 0.33, batch loss = 0.18 (49.4 examples/sec; 0.162 sec/batch; 11h:24m:20s remains)
INFO - root - 2017-12-01 06:02:51.803872: step 78820, loss = 0.36, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 10h:54m:45s remains)
INFO - root - 2017-12-01 06:02:53.377076: step 78830, loss = 0.46, batch loss = 0.32 (50.6 examples/sec; 0.158 sec/batch; 11h:07m:58s remains)
INFO - root - 2017-12-01 06:02:54.943616: step 78840, loss = 0.37, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 10h:57m:42s remains)
INFO - root - 2017-12-01 06:02:56.518164: step 78850, loss = 0.30, batch loss = 0.16 (51.0 examples/sec; 0.157 sec/batch; 11h:02m:40s remains)
INFO - root - 2017-12-01 06:02:58.075542: step 78860, loss = 0.36, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 10h:56m:25s remains)
INFO - root - 2017-12-01 06:02:59.637789: step 78870, loss = 0.34, batch loss = 0.19 (52.7 examples/sec; 0.152 sec/batch; 10h:41m:29s remains)
INFO - root - 2017-12-01 06:03:01.224430: step 78880, loss = 0.39, batch loss = 0.25 (50.3 examples/sec; 0.159 sec/batch; 11h:12m:22s remains)
INFO - root - 2017-12-01 06:03:02.808243: step 78890, loss = 0.34, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 11h:11m:02s remains)
INFO - root - 2017-12-01 06:03:04.371689: step 78900, loss = 0.29, batch loss = 0.15 (51.8 examples/sec; 0.155 sec/batch; 10h:53m:18s remains)
INFO - root - 2017-12-01 06:03:06.026675: step 78910, loss = 0.35, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 11h:12m:37s remains)
INFO - root - 2017-12-01 06:03:07.582309: step 78920, loss = 0.33, batch loss = 0.18 (50.5 examples/sec; 0.159 sec/batch; 11h:10m:00s remains)
INFO - root - 2017-12-01 06:03:09.151334: step 78930, loss = 0.38, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 11h:09m:27s remains)
INFO - root - 2017-12-01 06:03:10.734438: step 78940, loss = 0.42, batch loss = 0.28 (47.9 examples/sec; 0.167 sec/batch; 11h:46m:13s remains)
INFO - root - 2017-12-01 06:03:12.287400: step 78950, loss = 0.33, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 10h:54m:26s remains)
INFO - root - 2017-12-01 06:03:13.857412: step 78960, loss = 0.36, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 11h:04m:20s remains)
INFO - root - 2017-12-01 06:03:15.442123: step 78970, loss = 0.35, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 10h:47m:08s remains)
INFO - root - 2017-12-01 06:03:17.049299: step 78980, loss = 0.34, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 10h:57m:53s remains)
INFO - root - 2017-12-01 06:03:18.593290: step 78990, loss = 0.41, batch loss = 0.27 (51.7 examples/sec; 0.155 sec/batch; 10h:54m:18s remains)
INFO - root - 2017-12-01 06:03:20.159534: step 79000, loss = 0.39, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 11h:10m:11s remains)
INFO - root - 2017-12-01 06:03:21.812409: step 79010, loss = 0.39, batch loss = 0.25 (48.9 examples/sec; 0.164 sec/batch; 11h:31m:33s remains)
INFO - root - 2017-12-01 06:03:23.393863: step 79020, loss = 0.47, batch loss = 0.33 (49.9 examples/sec; 0.160 sec/batch; 11h:17m:51s remains)
INFO - root - 2017-12-01 06:03:24.961378: step 79030, loss = 0.41, batch loss = 0.27 (53.8 examples/sec; 0.149 sec/batch; 10h:28m:35s remains)
INFO - root - 2017-12-01 06:03:26.518582: step 79040, loss = 0.40, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 10h:50m:32s remains)
INFO - root - 2017-12-01 06:03:28.103267: step 79050, loss = 0.36, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 11h:04m:50s remains)
INFO - root - 2017-12-01 06:03:29.693073: step 79060, loss = 0.51, batch loss = 0.37 (48.3 examples/sec; 0.166 sec/batch; 11h:39m:40s remains)
INFO - root - 2017-12-01 06:03:31.239086: step 79070, loss = 0.31, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 11h:00m:15s remains)
INFO - root - 2017-12-01 06:03:32.814058: step 79080, loss = 0.37, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 10h:41m:04s remains)
INFO - root - 2017-12-01 06:03:34.398771: step 79090, loss = 0.29, batch loss = 0.15 (51.0 examples/sec; 0.157 sec/batch; 11h:01m:57s remains)
INFO - root - 2017-12-01 06:03:35.977374: step 79100, loss = 0.40, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 10h:49m:35s remains)
INFO - root - 2017-12-01 06:03:37.587862: step 79110, loss = 0.31, batch loss = 0.17 (49.5 examples/sec; 0.162 sec/batch; 11h:22m:06s remains)
INFO - root - 2017-12-01 06:03:39.146988: step 79120, loss = 0.32, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 11h:05m:47s remains)
INFO - root - 2017-12-01 06:03:40.712691: step 79130, loss = 0.31, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 11h:10m:49s remains)
INFO - root - 2017-12-01 06:03:42.270810: step 79140, loss = 0.32, batch loss = 0.17 (50.8 examples/sec; 0.157 sec/batch; 11h:04m:54s remains)
INFO - root - 2017-12-01 06:03:43.854316: step 79150, loss = 0.45, batch loss = 0.31 (50.5 examples/sec; 0.159 sec/batch; 11h:09m:26s remains)
INFO - root - 2017-12-01 06:03:45.407144: step 79160, loss = 0.32, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 11h:02m:53s remains)
INFO - root - 2017-12-01 06:03:46.979191: step 79170, loss = 0.48, batch loss = 0.33 (50.1 examples/sec; 0.160 sec/batch; 11h:13m:35s remains)
INFO - root - 2017-12-01 06:03:48.548246: step 79180, loss = 0.45, batch loss = 0.30 (49.5 examples/sec; 0.162 sec/batch; 11h:22m:57s remains)
INFO - root - 2017-12-01 06:03:50.109878: step 79190, loss = 0.42, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 10h:53m:40s remains)
INFO - root - 2017-12-01 06:03:51.684278: step 79200, loss = 0.31, batch loss = 0.17 (50.7 examples/sec; 0.158 sec/batch; 11h:06m:02s remains)
INFO - root - 2017-12-01 06:03:53.316052: step 79210, loss = 0.44, batch loss = 0.29 (49.5 examples/sec; 0.162 sec/batch; 11h:22m:38s remains)
INFO - root - 2017-12-01 06:03:54.883190: step 79220, loss = 0.39, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 10h:57m:04s remains)
INFO - root - 2017-12-01 06:03:56.434764: step 79230, loss = 0.32, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 10h:45m:30s remains)
INFO - root - 2017-12-01 06:03:58.010574: step 79240, loss = 0.31, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 11h:06m:03s remains)
INFO - root - 2017-12-01 06:03:59.583557: step 79250, loss = 0.39, batch loss = 0.25 (48.0 examples/sec; 0.167 sec/batch; 11h:43m:59s remains)
INFO - root - 2017-12-01 06:04:01.138936: step 79260, loss = 0.39, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 11h:00m:42s remains)
INFO - root - 2017-12-01 06:04:02.687615: step 79270, loss = 0.38, batch loss = 0.24 (52.1 examples/sec; 0.154 sec/batch; 10h:47m:54s remains)
INFO - root - 2017-12-01 06:04:04.277151: step 79280, loss = 0.32, batch loss = 0.18 (49.3 examples/sec; 0.162 sec/batch; 11h:25m:00s remains)
INFO - root - 2017-12-01 06:04:05.837870: step 79290, loss = 0.39, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 11h:00m:40s remains)
INFO - root - 2017-12-01 06:04:07.390706: step 79300, loss = 0.32, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 11h:05m:24s remains)
INFO - root - 2017-12-01 06:04:09.046991: step 79310, loss = 0.32, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 10h:51m:32s remains)
INFO - root - 2017-12-01 06:04:10.617298: step 79320, loss = 0.32, batch loss = 0.18 (48.5 examples/sec; 0.165 sec/batch; 11h:35m:24s remains)
INFO - root - 2017-12-01 06:04:12.195252: step 79330, loss = 0.34, batch loss = 0.20 (49.1 examples/sec; 0.163 sec/batch; 11h:26m:58s remains)
INFO - root - 2017-12-01 06:04:13.788582: step 79340, loss = 0.30, batch loss = 0.16 (52.4 examples/sec; 0.153 sec/batch; 10h:43m:34s remains)
INFO - root - 2017-12-01 06:04:15.371615: step 79350, loss = 0.32, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 11h:02m:54s remains)
INFO - root - 2017-12-01 06:04:16.933717: step 79360, loss = 0.35, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 11h:01m:19s remains)
INFO - root - 2017-12-01 06:04:18.504608: step 79370, loss = 0.38, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 10h:52m:11s remains)
INFO - root - 2017-12-01 06:04:20.086091: step 79380, loss = 0.47, batch loss = 0.33 (52.2 examples/sec; 0.153 sec/batch; 10h:46m:06s remains)
INFO - root - 2017-12-01 06:04:21.666375: step 79390, loss = 0.31, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 11h:00m:49s remains)
INFO - root - 2017-12-01 06:04:23.248058: step 79400, loss = 0.30, batch loss = 0.16 (49.0 examples/sec; 0.163 sec/batch; 11h:29m:01s remains)
INFO - root - 2017-12-01 06:04:24.924638: step 79410, loss = 0.39, batch loss = 0.25 (47.9 examples/sec; 0.167 sec/batch; 11h:44m:34s remains)
INFO - root - 2017-12-01 06:04:26.502423: step 79420, loss = 0.41, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 10h:57m:55s remains)
INFO - root - 2017-12-01 06:04:28.076701: step 79430, loss = 0.32, batch loss = 0.18 (50.0 examples/sec; 0.160 sec/batch; 11h:15m:08s remains)
INFO - root - 2017-12-01 06:04:29.654540: step 79440, loss = 0.45, batch loss = 0.31 (50.4 examples/sec; 0.159 sec/batch; 11h:09m:15s remains)
INFO - root - 2017-12-01 06:04:31.224852: step 79450, loss = 0.38, batch loss = 0.24 (49.2 examples/sec; 0.163 sec/batch; 11h:25m:59s remains)
INFO - root - 2017-12-01 06:04:32.802082: step 79460, loss = 0.40, batch loss = 0.25 (52.4 examples/sec; 0.153 sec/batch; 10h:44m:06s remains)
INFO - root - 2017-12-01 06:04:34.364286: step 79470, loss = 0.39, batch loss = 0.25 (52.6 examples/sec; 0.152 sec/batch; 10h:41m:19s remains)
INFO - root - 2017-12-01 06:04:35.936813: step 79480, loss = 0.41, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 11h:01m:37s remains)
INFO - root - 2017-12-01 06:04:37.497787: step 79490, loss = 0.36, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 11h:10m:24s remains)
INFO - root - 2017-12-01 06:04:39.056859: step 79500, loss = 0.37, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 11h:11m:46s remains)
INFO - root - 2017-12-01 06:04:40.672493: step 79510, loss = 0.48, batch loss = 0.34 (51.1 examples/sec; 0.157 sec/batch; 11h:00m:11s remains)
INFO - root - 2017-12-01 06:04:42.241207: step 79520, loss = 0.39, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 10h:54m:51s remains)
INFO - root - 2017-12-01 06:04:43.806753: step 79530, loss = 0.33, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 11h:12m:08s remains)
INFO - root - 2017-12-01 06:04:45.380035: step 79540, loss = 0.40, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 11h:07m:14s remains)
INFO - root - 2017-12-01 06:04:46.949410: step 79550, loss = 0.36, batch loss = 0.21 (48.6 examples/sec; 0.165 sec/batch; 11h:33m:43s remains)
INFO - root - 2017-12-01 06:04:48.509667: step 79560, loss = 0.39, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 10h:58m:34s remains)
INFO - root - 2017-12-01 06:04:50.063547: step 79570, loss = 0.37, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 10h:55m:10s remains)
INFO - root - 2017-12-01 06:04:51.633817: step 79580, loss = 0.36, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 10h:42m:48s remains)
INFO - root - 2017-12-01 06:04:53.194924: step 79590, loss = 0.36, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 10h:45m:32s remains)
INFO - root - 2017-12-01 06:04:54.769981: step 79600, loss = 0.40, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 11h:04m:26s remains)
INFO - root - 2017-12-01 06:04:56.385151: step 79610, loss = 0.31, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 11h:06m:43s remains)
INFO - root - 2017-12-01 06:04:57.952533: step 79620, loss = 0.42, batch loss = 0.28 (52.9 examples/sec; 0.151 sec/batch; 10h:37m:03s remains)
INFO - root - 2017-12-01 06:04:59.512930: step 79630, loss = 0.45, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 10h:58m:35s remains)
INFO - root - 2017-12-01 06:05:01.075680: step 79640, loss = 0.60, batch loss = 0.45 (51.3 examples/sec; 0.156 sec/batch; 10h:57m:45s remains)
INFO - root - 2017-12-01 06:05:02.640464: step 79650, loss = 0.37, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 11h:11m:35s remains)
INFO - root - 2017-12-01 06:05:04.200695: step 79660, loss = 0.34, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 11h:03m:10s remains)
INFO - root - 2017-12-01 06:05:05.787242: step 79670, loss = 0.36, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 10h:50m:35s remains)
INFO - root - 2017-12-01 06:05:07.351856: step 79680, loss = 0.36, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 11h:03m:08s remains)
INFO - root - 2017-12-01 06:05:08.918044: step 79690, loss = 0.31, batch loss = 0.16 (50.6 examples/sec; 0.158 sec/batch; 11h:06m:23s remains)
INFO - root - 2017-12-01 06:05:10.478938: step 79700, loss = 0.39, batch loss = 0.25 (52.4 examples/sec; 0.153 sec/batch; 10h:43m:28s remains)
INFO - root - 2017-12-01 06:05:12.085637: step 79710, loss = 0.42, batch loss = 0.28 (52.0 examples/sec; 0.154 sec/batch; 10h:48m:16s remains)
INFO - root - 2017-12-01 06:05:13.656618: step 79720, loss = 0.37, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 10h:59m:42s remains)
INFO - root - 2017-12-01 06:05:15.231830: step 79730, loss = 0.36, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 11h:08m:05s remains)
INFO - root - 2017-12-01 06:05:16.788803: step 79740, loss = 0.42, batch loss = 0.28 (50.2 examples/sec; 0.160 sec/batch; 11h:11m:59s remains)
INFO - root - 2017-12-01 06:05:18.346577: step 79750, loss = 0.38, batch loss = 0.24 (53.6 examples/sec; 0.149 sec/batch; 10h:28m:46s remains)
INFO - root - 2017-12-01 06:05:19.930717: step 79760, loss = 0.33, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 10h:51m:46s remains)
INFO - root - 2017-12-01 06:05:21.484859: step 79770, loss = 0.39, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 10h:55m:43s remains)
INFO - root - 2017-12-01 06:05:23.045418: step 79780, loss = 0.42, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 10h:54m:42s remains)
INFO - root - 2017-12-01 06:05:24.607982: step 79790, loss = 0.34, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 10h:54m:31s remains)
INFO - root - 2017-12-01 06:05:26.182548: step 79800, loss = 0.38, batch loss = 0.24 (52.5 examples/sec; 0.152 sec/batch; 10h:42m:03s remains)
INFO - root - 2017-12-01 06:05:27.784932: step 79810, loss = 0.33, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 11h:08m:11s remains)
INFO - root - 2017-12-01 06:05:29.358409: step 79820, loss = 0.51, batch loss = 0.37 (47.5 examples/sec; 0.168 sec/batch; 11h:48m:33s remains)
INFO - root - 2017-12-01 06:05:30.926485: step 79830, loss = 0.39, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 10h:41m:56s remains)
INFO - root - 2017-12-01 06:05:32.484882: step 79840, loss = 0.36, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 11h:06m:40s remains)
INFO - root - 2017-12-01 06:05:34.034955: step 79850, loss = 0.40, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 10h:49m:40s remains)
INFO - root - 2017-12-01 06:05:35.584972: step 79860, loss = 0.40, batch loss = 0.26 (50.5 examples/sec; 0.159 sec/batch; 11h:07m:27s remains)
INFO - root - 2017-12-01 06:05:37.139707: step 79870, loss = 0.45, batch loss = 0.30 (51.0 examples/sec; 0.157 sec/batch; 11h:00m:11s remains)
INFO - root - 2017-12-01 06:05:38.704679: step 79880, loss = 0.34, batch loss = 0.19 (49.4 examples/sec; 0.162 sec/batch; 11h:21m:14s remains)
INFO - root - 2017-12-01 06:05:40.256157: step 79890, loss = 0.50, batch loss = 0.36 (52.9 examples/sec; 0.151 sec/batch; 10h:37m:13s remains)
INFO - root - 2017-12-01 06:05:41.811707: step 79900, loss = 0.43, batch loss = 0.29 (51.4 examples/sec; 0.156 sec/batch; 10h:55m:05s remains)
INFO - root - 2017-12-01 06:05:43.443428: step 79910, loss = 0.33, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 10h:48m:41s remains)
INFO - root - 2017-12-01 06:05:45.011621: step 79920, loss = 0.49, batch loss = 0.35 (50.8 examples/sec; 0.158 sec/batch; 11h:03m:32s remains)
INFO - root - 2017-12-01 06:05:46.570676: step 79930, loss = 0.37, batch loss = 0.22 (52.8 examples/sec; 0.152 sec/batch; 10h:37m:53s remains)
INFO - root - 2017-12-01 06:05:48.150690: step 79940, loss = 0.38, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 11h:00m:19s remains)
INFO - root - 2017-12-01 06:05:49.711065: step 79950, loss = 0.30, batch loss = 0.15 (50.8 examples/sec; 0.157 sec/batch; 11h:02m:54s remains)
INFO - root - 2017-12-01 06:05:51.266416: step 79960, loss = 0.43, batch loss = 0.29 (51.0 examples/sec; 0.157 sec/batch; 11h:00m:20s remains)
INFO - root - 2017-12-01 06:05:52.832002: step 79970, loss = 0.30, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 10h:48m:24s remains)
INFO - root - 2017-12-01 06:05:54.406661: step 79980, loss = 0.32, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 10h:54m:28s remains)
INFO - root - 2017-12-01 06:05:55.975448: step 79990, loss = 0.32, batch loss = 0.18 (51.1 examples/sec; 0.156 sec/batch; 10h:58m:34s remains)
INFO - root - 2017-12-01 06:05:57.554669: step 80000, loss = 0.37, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 11h:10m:04s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-80000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-80000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-01 06:05:59.558034: step 80010, loss = 0.33, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 11h:02m:42s remains)
INFO - root - 2017-12-01 06:06:01.115195: step 80020, loss = 0.36, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 11h:04m:41s remains)
INFO - root - 2017-12-01 06:06:02.700616: step 80030, loss = 0.40, batch loss = 0.26 (47.2 examples/sec; 0.169 sec/batch; 11h:52m:47s remains)
INFO - root - 2017-12-01 06:06:04.267924: step 80040, loss = 0.32, batch loss = 0.18 (49.9 examples/sec; 0.160 sec/batch; 11h:14m:40s remains)
INFO - root - 2017-12-01 06:06:05.845995: step 80050, loss = 0.35, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 10h:54m:18s remains)
INFO - root - 2017-12-01 06:06:07.428976: step 80060, loss = 0.41, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 11h:09m:38s remains)
INFO - root - 2017-12-01 06:06:08.996736: step 80070, loss = 0.48, batch loss = 0.34 (52.7 examples/sec; 0.152 sec/batch; 10h:38m:47s remains)
INFO - root - 2017-12-01 06:06:10.562611: step 80080, loss = 0.34, batch loss = 0.20 (51.8 examples/sec; 0.155 sec/batch; 10h:50m:07s remains)
INFO - root - 2017-12-01 06:06:12.137415: step 80090, loss = 0.31, batch loss = 0.17 (49.2 examples/sec; 0.163 sec/batch; 11h:24m:44s remains)
INFO - root - 2017-12-01 06:06:13.700779: step 80100, loss = 0.36, batch loss = 0.22 (49.4 examples/sec; 0.162 sec/batch; 11h:20m:35s remains)
INFO - root - 2017-12-01 06:06:15.352117: step 80110, loss = 0.42, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 10h:55m:43s remains)
INFO - root - 2017-12-01 06:06:16.915759: step 80120, loss = 0.42, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 11h:05m:50s remains)
INFO - root - 2017-12-01 06:06:18.481873: step 80130, loss = 0.32, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 11h:02m:25s remains)
INFO - root - 2017-12-01 06:06:20.066973: step 80140, loss = 0.34, batch loss = 0.20 (52.7 examples/sec; 0.152 sec/batch; 10h:38m:36s remains)
INFO - root - 2017-12-01 06:06:21.627577: step 80150, loss = 0.62, batch loss = 0.48 (51.8 examples/sec; 0.154 sec/batch; 10h:49m:16s remains)
INFO - root - 2017-12-01 06:06:23.196720: step 80160, loss = 0.30, batch loss = 0.16 (51.0 examples/sec; 0.157 sec/batch; 11h:00m:17s remains)
INFO - root - 2017-12-01 06:06:24.777177: step 80170, loss = 0.36, batch loss = 0.22 (45.6 examples/sec; 0.176 sec/batch; 12h:18m:10s remains)
INFO - root - 2017-12-01 06:06:26.362852: step 80180, loss = 0.45, batch loss = 0.31 (50.1 examples/sec; 0.160 sec/batch; 11h:10m:58s remains)
INFO - root - 2017-12-01 06:06:27.928094: step 80190, loss = 0.34, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 11h:00m:45s remains)
INFO - root - 2017-12-01 06:06:29.514555: step 80200, loss = 0.29, batch loss = 0.15 (49.8 examples/sec; 0.161 sec/batch; 11h:15m:40s remains)
INFO - root - 2017-12-01 06:06:31.168942: step 80210, loss = 0.31, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 11h:01m:11s remains)
INFO - root - 2017-12-01 06:06:32.725845: step 80220, loss = 0.29, batch loss = 0.15 (51.2 examples/sec; 0.156 sec/batch; 10h:56m:27s remains)
INFO - root - 2017-12-01 06:06:34.298001: step 80230, loss = 0.35, batch loss = 0.21 (48.0 examples/sec; 0.167 sec/batch; 11h:40m:37s remains)
INFO - root - 2017-12-01 06:06:35.880299: step 80240, loss = 0.42, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 10h:50m:17s remains)
INFO - root - 2017-12-01 06:06:37.432726: step 80250, loss = 0.43, batch loss = 0.29 (52.4 examples/sec; 0.153 sec/batch; 10h:41m:35s remains)
INFO - root - 2017-12-01 06:06:39.003563: step 80260, loss = 0.35, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 10h:56m:35s remains)
INFO - root - 2017-12-01 06:06:40.565017: step 80270, loss = 0.34, batch loss = 0.20 (48.2 examples/sec; 0.166 sec/batch; 11h:37m:04s remains)
INFO - root - 2017-12-01 06:06:42.123422: step 80280, loss = 0.33, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 10h:53m:35s remains)
INFO - root - 2017-12-01 06:06:43.708957: step 80290, loss = 0.32, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 11h:02m:20s remains)
INFO - root - 2017-12-01 06:06:45.282446: step 80300, loss = 0.33, batch loss = 0.19 (50.1 examples/sec; 0.160 sec/batch; 11h:10m:43s remains)
INFO - root - 2017-12-01 06:06:46.891420: step 80310, loss = 0.35, batch loss = 0.21 (53.2 examples/sec; 0.150 sec/batch; 10h:31m:51s remains)
INFO - root - 2017-12-01 06:06:48.455776: step 80320, loss = 0.33, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 11h:05m:19s remains)
INFO - root - 2017-12-01 06:06:50.028073: step 80330, loss = 0.38, batch loss = 0.24 (52.7 examples/sec; 0.152 sec/batch; 10h:37m:55s remains)
INFO - root - 2017-12-01 06:06:51.585834: step 80340, loss = 0.39, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 11h:04m:07s remains)
INFO - root - 2017-12-01 06:06:53.149352: step 80350, loss = 0.38, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 10h:50m:49s remains)
INFO - root - 2017-12-01 06:06:54.716651: step 80360, loss = 0.30, batch loss = 0.16 (49.9 examples/sec; 0.160 sec/batch; 11h:13m:23s remains)
INFO - root - 2017-12-01 06:06:56.304140: step 80370, loss = 0.41, batch loss = 0.27 (48.2 examples/sec; 0.166 sec/batch; 11h:37m:57s remains)
INFO - root - 2017-12-01 06:06:57.849878: step 80380, loss = 0.32, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 10h:46m:24s remains)
INFO - root - 2017-12-01 06:06:59.420590: step 80390, loss = 0.33, batch loss = 0.19 (50.5 examples/sec; 0.159 sec/batch; 11h:06m:16s remains)
INFO - root - 2017-12-01 06:07:00.994287: step 80400, loss = 0.40, batch loss = 0.25 (53.2 examples/sec; 0.151 sec/batch; 10h:32m:25s remains)
INFO - root - 2017-12-01 06:07:02.607884: step 80410, loss = 0.34, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 11h:04m:34s remains)
INFO - root - 2017-12-01 06:07:04.168038: step 80420, loss = 0.33, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 11h:01m:52s remains)
INFO - root - 2017-12-01 06:07:05.729003: step 80430, loss = 0.33, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 11h:01m:59s remains)
INFO - root - 2017-12-01 06:07:07.301977: step 80440, loss = 0.32, batch loss = 0.18 (53.1 examples/sec; 0.151 sec/batch; 10h:32m:39s remains)
INFO - root - 2017-12-01 06:07:08.892592: step 80450, loss = 0.38, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 10h:46m:15s remains)
INFO - root - 2017-12-01 06:07:10.461221: step 80460, loss = 0.43, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 10h:56m:01s remains)
INFO - root - 2017-12-01 06:07:12.041437: step 80470, loss = 0.34, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 10h:49m:41s remains)
INFO - root - 2017-12-01 06:07:13.606834: step 80480, loss = 0.49, batch loss = 0.35 (52.5 examples/sec; 0.152 sec/batch; 10h:40m:07s remains)
INFO - root - 2017-12-01 06:07:15.178918: step 80490, loss = 0.36, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 10h:43m:33s remains)
INFO - root - 2017-12-01 06:07:16.747589: step 80500, loss = 0.34, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 10h:59m:52s remains)
INFO - root - 2017-12-01 06:07:18.390826: step 80510, loss = 0.31, batch loss = 0.17 (52.4 examples/sec; 0.153 sec/batch; 10h:41m:26s remains)
INFO - root - 2017-12-01 06:07:19.941704: step 80520, loss = 0.35, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 11h:01m:06s remains)
INFO - root - 2017-12-01 06:07:21.492983: step 80530, loss = 0.32, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 10h:57m:18s remains)
INFO - root - 2017-12-01 06:07:23.078486: step 80540, loss = 0.38, batch loss = 0.24 (49.0 examples/sec; 0.163 sec/batch; 11h:26m:16s remains)
INFO - root - 2017-12-01 06:07:24.649761: step 80550, loss = 0.34, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 10h:47m:49s remains)
INFO - root - 2017-12-01 06:07:26.199372: step 80560, loss = 0.36, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 10h:46m:15s remains)
INFO - root - 2017-12-01 06:07:27.738883: step 80570, loss = 0.49, batch loss = 0.35 (52.6 examples/sec; 0.152 sec/batch; 10h:38m:13s remains)
INFO - root - 2017-12-01 06:07:29.310275: step 80580, loss = 0.34, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 11h:03m:25s remains)
INFO - root - 2017-12-01 06:07:30.857283: step 80590, loss = 0.48, batch loss = 0.34 (50.8 examples/sec; 0.157 sec/batch; 11h:00m:33s remains)
INFO - root - 2017-12-01 06:07:32.404687: step 80600, loss = 0.33, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 10h:49m:22s remains)
INFO - root - 2017-12-01 06:07:34.042630: step 80610, loss = 0.37, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 10h:48m:15s remains)
INFO - root - 2017-12-01 06:07:35.610583: step 80620, loss = 0.33, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 10h:58m:33s remains)
INFO - root - 2017-12-01 06:07:37.162874: step 80630, loss = 0.45, batch loss = 0.31 (51.1 examples/sec; 0.156 sec/batch; 10h:56m:37s remains)
INFO - root - 2017-12-01 06:07:38.723930: step 80640, loss = 0.32, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 10h:53m:06s remains)
INFO - root - 2017-12-01 06:07:40.315359: step 80650, loss = 0.40, batch loss = 0.26 (52.1 examples/sec; 0.153 sec/batch; 10h:43m:55s remains)
INFO - root - 2017-12-01 06:07:41.882369: step 80660, loss = 0.30, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 11h:05m:49s remains)
INFO - root - 2017-12-01 06:07:43.438976: step 80670, loss = 0.34, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 11h:07m:20s remains)
INFO - root - 2017-12-01 06:07:44.993879: step 80680, loss = 0.33, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 10h:59m:31s remains)
INFO - root - 2017-12-01 06:07:46.549299: step 80690, loss = 0.44, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 10h:51m:51s remains)
INFO - root - 2017-12-01 06:07:48.109666: step 80700, loss = 0.35, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 10h:42m:57s remains)
INFO - root - 2017-12-01 06:07:49.764027: step 80710, loss = 0.33, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 11h:12m:25s remains)
INFO - root - 2017-12-01 06:07:51.325514: step 80720, loss = 0.37, batch loss = 0.23 (52.8 examples/sec; 0.152 sec/batch; 10h:36m:21s remains)
INFO - root - 2017-12-01 06:07:52.882869: step 80730, loss = 0.33, batch loss = 0.18 (52.4 examples/sec; 0.153 sec/batch; 10h:40m:34s remains)
INFO - root - 2017-12-01 06:07:54.481049: step 80740, loss = 0.38, batch loss = 0.24 (49.7 examples/sec; 0.161 sec/batch; 11h:15m:49s remains)
INFO - root - 2017-12-01 06:07:56.044594: step 80750, loss = 0.45, batch loss = 0.31 (51.5 examples/sec; 0.155 sec/batch; 10h:51m:48s remains)
INFO - root - 2017-12-01 06:07:57.606743: step 80760, loss = 0.40, batch loss = 0.26 (52.3 examples/sec; 0.153 sec/batch; 10h:41m:15s remains)
INFO - root - 2017-12-01 06:07:59.185278: step 80770, loss = 0.37, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 10h:47m:47s remains)
INFO - root - 2017-12-01 06:08:00.772091: step 80780, loss = 0.35, batch loss = 0.21 (50.5 examples/sec; 0.159 sec/batch; 11h:05m:05s remains)
INFO - root - 2017-12-01 06:08:02.316203: step 80790, loss = 0.30, batch loss = 0.16 (51.0 examples/sec; 0.157 sec/batch; 10h:58m:06s remains)
INFO - root - 2017-12-01 06:08:03.873454: step 80800, loss = 0.37, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 10h:59m:35s remains)
INFO - root - 2017-12-01 06:08:05.498054: step 80810, loss = 0.42, batch loss = 0.28 (52.7 examples/sec; 0.152 sec/batch; 10h:36m:17s remains)
INFO - root - 2017-12-01 06:08:07.055808: step 80820, loss = 0.32, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 10h:50m:45s remains)
INFO - root - 2017-12-01 06:08:08.630901: step 80830, loss = 0.37, batch loss = 0.23 (46.3 examples/sec; 0.173 sec/batch; 12h:05m:30s remains)
INFO - root - 2017-12-01 06:08:10.211134: step 80840, loss = 0.36, batch loss = 0.22 (49.5 examples/sec; 0.162 sec/batch; 11h:18m:30s remains)
INFO - root - 2017-12-01 06:08:11.795377: step 80850, loss = 0.35, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 10h:50m:41s remains)
INFO - root - 2017-12-01 06:08:13.356049: step 80860, loss = 0.47, batch loss = 0.33 (51.1 examples/sec; 0.157 sec/batch; 10h:57m:06s remains)
INFO - root - 2017-12-01 06:08:14.905812: step 80870, loss = 0.35, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 10h:58m:40s remains)
INFO - root - 2017-12-01 06:08:16.461439: step 80880, loss = 0.33, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 11h:00m:22s remains)
INFO - root - 2017-12-01 06:08:18.045282: step 80890, loss = 0.40, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 10h:49m:26s remains)
INFO - root - 2017-12-01 06:08:19.596608: step 80900, loss = 0.47, batch loss = 0.33 (51.8 examples/sec; 0.154 sec/batch; 10h:47m:25s remains)
INFO - root - 2017-12-01 06:08:21.206951: step 80910, loss = 0.42, batch loss = 0.28 (52.0 examples/sec; 0.154 sec/batch; 10h:45m:17s remains)
INFO - root - 2017-12-01 06:08:22.759666: step 80920, loss = 0.36, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 10h:55m:23s remains)
INFO - root - 2017-12-01 06:08:24.316667: step 80930, loss = 0.39, batch loss = 0.25 (53.1 examples/sec; 0.151 sec/batch; 10h:31m:17s remains)
INFO - root - 2017-12-01 06:08:25.911664: step 80940, loss = 0.29, batch loss = 0.15 (48.4 examples/sec; 0.165 sec/batch; 11h:32m:19s remains)
INFO - root - 2017-12-01 06:08:27.477397: step 80950, loss = 0.38, batch loss = 0.24 (47.3 examples/sec; 0.169 sec/batch; 11h:49m:42s remains)
INFO - root - 2017-12-01 06:08:29.029377: step 80960, loss = 0.34, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 10h:40m:11s remains)
INFO - root - 2017-12-01 06:08:30.594993: step 80970, loss = 0.35, batch loss = 0.20 (52.7 examples/sec; 0.152 sec/batch; 10h:35m:50s remains)
INFO - root - 2017-12-01 06:08:32.163820: step 80980, loss = 0.36, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 10h:49m:35s remains)
INFO - root - 2017-12-01 06:08:33.732782: step 80990, loss = 0.46, batch loss = 0.32 (50.6 examples/sec; 0.158 sec/batch; 11h:03m:04s remains)
INFO - root - 2017-12-01 06:08:35.306869: step 81000, loss = 0.55, batch loss = 0.41 (49.7 examples/sec; 0.161 sec/batch; 11h:14m:23s remains)
INFO - root - 2017-12-01 06:08:36.936635: step 81010, loss = 0.34, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 10h:42m:10s remains)
INFO - root - 2017-12-01 06:08:38.505079: step 81020, loss = 0.33, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 11h:02m:55s remains)
INFO - root - 2017-12-01 06:08:40.066629: step 81030, loss = 0.33, batch loss = 0.19 (52.1 examples/sec; 0.154 sec/batch; 10h:43m:31s remains)
INFO - root - 2017-12-01 06:08:41.652422: step 81040, loss = 0.34, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 10h:45m:31s remains)
INFO - root - 2017-12-01 06:08:43.202085: step 81050, loss = 0.35, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 10h:44m:46s remains)
INFO - root - 2017-12-01 06:08:44.766963: step 81060, loss = 0.57, batch loss = 0.43 (50.5 examples/sec; 0.158 sec/batch; 11h:03m:23s remains)
INFO - root - 2017-12-01 06:08:46.328352: step 81070, loss = 0.36, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 11h:02m:25s remains)
INFO - root - 2017-12-01 06:08:47.884421: step 81080, loss = 0.35, batch loss = 0.21 (51.1 examples/sec; 0.156 sec/batch; 10h:55m:29s remains)
INFO - root - 2017-12-01 06:08:49.442027: step 81090, loss = 0.49, batch loss = 0.35 (51.3 examples/sec; 0.156 sec/batch; 10h:53m:55s remains)
INFO - root - 2017-12-01 06:08:51.002513: step 81100, loss = 0.40, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 10h:35m:33s remains)
INFO - root - 2017-12-01 06:08:52.618144: step 81110, loss = 0.31, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 10h:51m:08s remains)
INFO - root - 2017-12-01 06:08:54.180160: step 81120, loss = 0.37, batch loss = 0.22 (49.5 examples/sec; 0.162 sec/batch; 11h:17m:36s remains)
INFO - root - 2017-12-01 06:08:55.743349: step 81130, loss = 0.29, batch loss = 0.15 (52.3 examples/sec; 0.153 sec/batch; 10h:41m:16s remains)
INFO - root - 2017-12-01 06:08:57.310257: step 81140, loss = 0.35, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 10h:44m:32s remains)
INFO - root - 2017-12-01 06:08:58.867393: step 81150, loss = 0.33, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 10h:59m:33s remains)
INFO - root - 2017-12-01 06:09:00.431413: step 81160, loss = 0.34, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 11h:01m:19s remains)
INFO - root - 2017-12-01 06:09:01.970067: step 81170, loss = 0.35, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 10h:49m:13s remains)
INFO - root - 2017-12-01 06:09:03.515803: step 81180, loss = 0.33, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 10h:38m:41s remains)
INFO - root - 2017-12-01 06:09:05.082357: step 81190, loss = 0.53, batch loss = 0.39 (50.0 examples/sec; 0.160 sec/batch; 11h:10m:49s remains)
INFO - root - 2017-12-01 06:09:06.663487: step 81200, loss = 0.41, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 10h:44m:50s remains)
INFO - root - 2017-12-01 06:09:08.297368: step 81210, loss = 0.57, batch loss = 0.43 (52.6 examples/sec; 0.152 sec/batch; 10h:36m:36s remains)
INFO - root - 2017-12-01 06:09:09.854351: step 81220, loss = 0.39, batch loss = 0.25 (53.0 examples/sec; 0.151 sec/batch; 10h:31m:39s remains)
INFO - root - 2017-12-01 06:09:11.436047: step 81230, loss = 0.37, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 10h:55m:47s remains)
INFO - root - 2017-12-01 06:09:12.988655: step 81240, loss = 0.34, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 10h:36m:42s remains)
INFO - root - 2017-12-01 06:09:14.559487: step 81250, loss = 0.44, batch loss = 0.30 (49.9 examples/sec; 0.160 sec/batch; 11h:11m:11s remains)
INFO - root - 2017-12-01 06:09:16.128328: step 81260, loss = 0.40, batch loss = 0.26 (52.3 examples/sec; 0.153 sec/batch; 10h:40m:40s remains)
INFO - root - 2017-12-01 06:09:17.689666: step 81270, loss = 0.40, batch loss = 0.26 (51.8 examples/sec; 0.155 sec/batch; 10h:47m:02s remains)
INFO - root - 2017-12-01 06:09:19.254196: step 81280, loss = 0.42, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 10h:47m:22s remains)
INFO - root - 2017-12-01 06:09:20.816511: step 81290, loss = 0.42, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 10h:56m:15s remains)
INFO - root - 2017-12-01 06:09:22.387266: step 81300, loss = 0.38, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 11h:05m:21s remains)
INFO - root - 2017-12-01 06:09:24.045870: step 81310, loss = 0.39, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 10h:47m:37s remains)
INFO - root - 2017-12-01 06:09:25.622180: step 81320, loss = 0.50, batch loss = 0.36 (49.3 examples/sec; 0.162 sec/batch; 11h:19m:02s remains)
INFO - root - 2017-12-01 06:09:27.173537: step 81330, loss = 0.40, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 10h:58m:15s remains)
INFO - root - 2017-12-01 06:09:28.767998: step 81340, loss = 0.41, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 11h:00m:51s remains)
INFO - root - 2017-12-01 06:09:30.352634: step 81350, loss = 0.31, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 10h:58m:28s remains)
INFO - root - 2017-12-01 06:09:31.906016: step 81360, loss = 0.33, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 11h:02m:42s remains)
INFO - root - 2017-12-01 06:09:33.474392: step 81370, loss = 0.33, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 10h:44m:18s remains)
INFO - root - 2017-12-01 06:09:35.045725: step 81380, loss = 0.46, batch loss = 0.32 (52.4 examples/sec; 0.153 sec/batch; 10h:38m:56s remains)
INFO - root - 2017-12-01 06:09:36.600353: step 81390, loss = 0.44, batch loss = 0.30 (50.6 examples/sec; 0.158 sec/batch; 11h:01m:11s remains)
INFO - root - 2017-12-01 06:09:38.154613: step 81400, loss = 0.33, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 10h:50m:00s remains)
INFO - root - 2017-12-01 06:09:39.764034: step 81410, loss = 0.36, batch loss = 0.22 (53.3 examples/sec; 0.150 sec/batch; 10h:27m:58s remains)
INFO - root - 2017-12-01 06:09:41.314454: step 81420, loss = 0.29, batch loss = 0.15 (52.0 examples/sec; 0.154 sec/batch; 10h:44m:12s remains)
INFO - root - 2017-12-01 06:09:42.861643: step 81430, loss = 0.33, batch loss = 0.19 (52.8 examples/sec; 0.151 sec/batch; 10h:33m:47s remains)
INFO - root - 2017-12-01 06:09:44.418825: step 81440, loss = 0.38, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 10h:55m:32s remains)
INFO - root - 2017-12-01 06:09:45.972488: step 81450, loss = 0.30, batch loss = 0.16 (51.7 examples/sec; 0.155 sec/batch; 10h:47m:17s remains)
INFO - root - 2017-12-01 06:09:47.527821: step 81460, loss = 0.51, batch loss = 0.37 (50.8 examples/sec; 0.157 sec/batch; 10h:58m:24s remains)
INFO - root - 2017-12-01 06:09:49.080757: step 81470, loss = 0.38, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 10h:53m:04s remains)
INFO - root - 2017-12-01 06:09:50.650412: step 81480, loss = 0.38, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 10h:46m:46s remains)
INFO - root - 2017-12-01 06:09:52.255828: step 81490, loss = 0.38, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 11h:00m:16s remains)
INFO - root - 2017-12-01 06:09:53.812266: step 81500, loss = 0.30, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 11h:00m:20s remains)
INFO - root - 2017-12-01 06:09:55.479470: step 81510, loss = 0.38, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 10h:40m:53s remains)
INFO - root - 2017-12-01 06:09:57.054453: step 81520, loss = 0.28, batch loss = 0.14 (51.3 examples/sec; 0.156 sec/batch; 10h:52m:04s remains)
INFO - root - 2017-12-01 06:09:58.604726: step 81530, loss = 0.35, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 11h:04m:16s remains)
INFO - root - 2017-12-01 06:10:00.171362: step 81540, loss = 0.34, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 10h:43m:58s remains)
INFO - root - 2017-12-01 06:10:01.755428: step 81550, loss = 0.33, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 10h:59m:05s remains)
INFO - root - 2017-12-01 06:10:03.324581: step 81560, loss = 0.41, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 10h:59m:52s remains)
INFO - root - 2017-12-01 06:10:04.881804: step 81570, loss = 0.44, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 10h:53m:49s remains)
INFO - root - 2017-12-01 06:10:06.445814: step 81580, loss = 0.38, batch loss = 0.24 (52.8 examples/sec; 0.151 sec/batch; 10h:33m:08s remains)
INFO - root - 2017-12-01 06:10:08.008553: step 81590, loss = 0.40, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 10h:53m:57s remains)
INFO - root - 2017-12-01 06:10:09.586910: step 81600, loss = 0.41, batch loss = 0.27 (51.2 examples/sec; 0.156 sec/batch; 10h:53m:28s remains)
INFO - root - 2017-12-01 06:10:11.220821: step 81610, loss = 0.32, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 10h:53m:44s remains)
INFO - root - 2017-12-01 06:10:12.773723: step 81620, loss = 0.32, batch loss = 0.18 (52.4 examples/sec; 0.153 sec/batch; 10h:38m:48s remains)
INFO - root - 2017-12-01 06:10:14.326534: step 81630, loss = 0.45, batch loss = 0.31 (52.1 examples/sec; 0.153 sec/batch; 10h:41m:42s remains)
INFO - root - 2017-12-01 06:10:15.901885: step 81640, loss = 0.39, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 10h:53m:25s remains)
INFO - root - 2017-12-01 06:10:17.453212: step 81650, loss = 0.36, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 10h:45m:43s remains)
INFO - root - 2017-12-01 06:10:19.018786: step 81660, loss = 0.34, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 10h:59m:41s remains)
INFO - root - 2017-12-01 06:10:20.627773: step 81670, loss = 0.49, batch loss = 0.35 (51.9 examples/sec; 0.154 sec/batch; 10h:44m:26s remains)
INFO - root - 2017-12-01 06:10:22.208412: step 81680, loss = 0.43, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 11h:04m:57s remains)
INFO - root - 2017-12-01 06:10:23.772302: step 81690, loss = 0.33, batch loss = 0.19 (49.6 examples/sec; 0.161 sec/batch; 11h:13m:45s remains)
INFO - root - 2017-12-01 06:10:25.340603: step 81700, loss = 0.37, batch loss = 0.23 (53.6 examples/sec; 0.149 sec/batch; 10h:24m:27s remains)
INFO - root - 2017-12-01 06:10:26.967418: step 81710, loss = 0.32, batch loss = 0.18 (49.5 examples/sec; 0.161 sec/batch; 11h:14m:51s remains)
INFO - root - 2017-12-01 06:10:28.522147: step 81720, loss = 0.37, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 10h:40m:24s remains)
INFO - root - 2017-12-01 06:10:30.088730: step 81730, loss = 0.40, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 10h:52m:50s remains)
INFO - root - 2017-12-01 06:10:31.673409: step 81740, loss = 0.44, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 10h:50m:32s remains)
INFO - root - 2017-12-01 06:10:33.230904: step 81750, loss = 0.32, batch loss = 0.18 (50.1 examples/sec; 0.160 sec/batch; 11h:06m:50s remains)
INFO - root - 2017-12-01 06:10:34.803629: step 81760, loss = 0.34, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 11h:06m:09s remains)
INFO - root - 2017-12-01 06:10:36.362751: step 81770, loss = 0.39, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 10h:52m:15s remains)
INFO - root - 2017-12-01 06:10:37.945752: step 81780, loss = 0.33, batch loss = 0.19 (48.8 examples/sec; 0.164 sec/batch; 11h:24m:51s remains)
INFO - root - 2017-12-01 06:10:39.503361: step 81790, loss = 0.35, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 10h:58m:59s remains)
INFO - root - 2017-12-01 06:10:41.082978: step 81800, loss = 0.37, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 11h:06m:22s remains)
INFO - root - 2017-12-01 06:10:42.726680: step 81810, loss = 0.32, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 10h:58m:47s remains)
INFO - root - 2017-12-01 06:10:44.283175: step 81820, loss = 0.33, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 10h:47m:36s remains)
INFO - root - 2017-12-01 06:10:45.841569: step 81830, loss = 0.52, batch loss = 0.39 (50.8 examples/sec; 0.157 sec/batch; 10h:57m:54s remains)
INFO - root - 2017-12-01 06:10:47.404910: step 81840, loss = 0.37, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 10h:47m:25s remains)
INFO - root - 2017-12-01 06:10:48.969707: step 81850, loss = 0.52, batch loss = 0.38 (52.4 examples/sec; 0.153 sec/batch; 10h:37m:54s remains)
INFO - root - 2017-12-01 06:10:50.538514: step 81860, loss = 0.33, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 10h:46m:18s remains)
INFO - root - 2017-12-01 06:10:52.104230: step 81870, loss = 0.36, batch loss = 0.23 (49.5 examples/sec; 0.161 sec/batch; 11h:14m:29s remains)
INFO - root - 2017-12-01 06:10:53.674392: step 81880, loss = 0.32, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 10h:51m:24s remains)
INFO - root - 2017-12-01 06:10:55.258957: step 81890, loss = 0.32, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 10h:55m:45s remains)
INFO - root - 2017-12-01 06:10:56.808709: step 81900, loss = 0.32, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 10h:43m:28s remains)
INFO - root - 2017-12-01 06:10:58.437109: step 81910, loss = 0.33, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 10h:52m:29s remains)
INFO - root - 2017-12-01 06:11:00.003834: step 81920, loss = 0.37, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 10h:38m:06s remains)
INFO - root - 2017-12-01 06:11:01.555967: step 81930, loss = 0.33, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 10h:48m:55s remains)
INFO - root - 2017-12-01 06:11:03.127952: step 81940, loss = 0.32, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 10h:56m:10s remains)
INFO - root - 2017-12-01 06:11:04.689439: step 81950, loss = 0.32, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 10h:47m:35s remains)
INFO - root - 2017-12-01 06:11:06.244160: step 81960, loss = 0.36, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 10h:59m:26s remains)
INFO - root - 2017-12-01 06:11:07.806216: step 81970, loss = 0.39, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 10h:48m:47s remains)
INFO - root - 2017-12-01 06:11:09.385571: step 81980, loss = 0.34, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 10h:40m:14s remains)
INFO - root - 2017-12-01 06:11:10.958817: step 81990, loss = 0.33, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 10h:57m:37s remains)
INFO - root - 2017-12-01 06:11:12.525470: step 82000, loss = 0.36, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 11h:03m:38s remains)
INFO - root - 2017-12-01 06:11:14.178528: step 82010, loss = 0.29, batch loss = 0.15 (50.7 examples/sec; 0.158 sec/batch; 10h:59m:23s remains)
INFO - root - 2017-12-01 06:11:15.741396: step 82020, loss = 0.41, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 10h:55m:11s remains)
INFO - root - 2017-12-01 06:11:17.306880: step 82030, loss = 0.39, batch loss = 0.25 (49.2 examples/sec; 0.163 sec/batch; 11h:19m:19s remains)
INFO - root - 2017-12-01 06:11:18.881601: step 82040, loss = 0.33, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 10h:51m:45s remains)
INFO - root - 2017-12-01 06:11:20.435921: step 82050, loss = 0.37, batch loss = 0.24 (52.9 examples/sec; 0.151 sec/batch; 10h:30m:43s remains)
INFO - root - 2017-12-01 06:11:22.022387: step 82060, loss = 0.31, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 11h:01m:55s remains)
INFO - root - 2017-12-01 06:11:23.578206: step 82070, loss = 0.37, batch loss = 0.23 (49.2 examples/sec; 0.162 sec/batch; 11h:18m:07s remains)
INFO - root - 2017-12-01 06:11:25.150732: step 82080, loss = 0.36, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 11h:00m:49s remains)
INFO - root - 2017-12-01 06:11:26.722790: step 82090, loss = 0.40, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 10h:46m:41s remains)
INFO - root - 2017-12-01 06:11:28.287814: step 82100, loss = 0.42, batch loss = 0.28 (51.8 examples/sec; 0.155 sec/batch; 10h:45m:08s remains)
INFO - root - 2017-12-01 06:11:29.929689: step 82110, loss = 0.35, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 10h:41m:10s remains)
INFO - root - 2017-12-01 06:11:31.480190: step 82120, loss = 0.28, batch loss = 0.15 (52.3 examples/sec; 0.153 sec/batch; 10h:37m:46s remains)
INFO - root - 2017-12-01 06:11:33.031956: step 82130, loss = 0.45, batch loss = 0.32 (51.5 examples/sec; 0.155 sec/batch; 10h:47m:43s remains)
INFO - root - 2017-12-01 06:11:34.588303: step 82140, loss = 0.38, batch loss = 0.24 (49.1 examples/sec; 0.163 sec/batch; 11h:19m:49s remains)
INFO - root - 2017-12-01 06:11:36.150154: step 82150, loss = 0.42, batch loss = 0.28 (49.9 examples/sec; 0.160 sec/batch; 11h:08m:30s remains)
INFO - root - 2017-12-01 06:11:37.712949: step 82160, loss = 0.43, batch loss = 0.29 (51.7 examples/sec; 0.155 sec/batch; 10h:45m:19s remains)
INFO - root - 2017-12-01 06:11:39.269530: step 82170, loss = 0.31, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 10h:39m:04s remains)
INFO - root - 2017-12-01 06:11:40.846404: step 82180, loss = 0.38, batch loss = 0.24 (50.1 examples/sec; 0.160 sec/batch; 11h:06m:47s remains)
INFO - root - 2017-12-01 06:11:42.431768: step 82190, loss = 0.35, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 10h:46m:18s remains)
INFO - root - 2017-12-01 06:11:43.977901: step 82200, loss = 0.38, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 10h:58m:01s remains)
INFO - root - 2017-12-01 06:11:45.604602: step 82210, loss = 0.31, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 10h:39m:04s remains)
INFO - root - 2017-12-01 06:11:47.176539: step 82220, loss = 0.31, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 11h:01m:43s remains)
INFO - root - 2017-12-01 06:11:48.729956: step 82230, loss = 0.41, batch loss = 0.27 (49.7 examples/sec; 0.161 sec/batch; 11h:11m:19s remains)
INFO - root - 2017-12-01 06:11:50.292842: step 82240, loss = 0.40, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 10h:51m:00s remains)
INFO - root - 2017-12-01 06:11:51.852704: step 82250, loss = 0.41, batch loss = 0.27 (51.1 examples/sec; 0.156 sec/batch; 10h:52m:26s remains)
INFO - root - 2017-12-01 06:11:53.420267: step 82260, loss = 0.34, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 11h:00m:47s remains)
INFO - root - 2017-12-01 06:11:54.993436: step 82270, loss = 0.34, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 11h:03m:40s remains)
INFO - root - 2017-12-01 06:11:56.564431: step 82280, loss = 0.35, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 10h:53m:15s remains)
INFO - root - 2017-12-01 06:11:58.120131: step 82290, loss = 0.37, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 10h:34m:38s remains)
INFO - root - 2017-12-01 06:11:59.677680: step 82300, loss = 0.45, batch loss = 0.31 (52.2 examples/sec; 0.153 sec/batch; 10h:39m:18s remains)
INFO - root - 2017-12-01 06:12:01.286237: step 82310, loss = 0.39, batch loss = 0.25 (49.4 examples/sec; 0.162 sec/batch; 11h:14m:41s remains)
INFO - root - 2017-12-01 06:12:02.860886: step 82320, loss = 0.43, batch loss = 0.29 (50.1 examples/sec; 0.160 sec/batch; 11h:05m:18s remains)
INFO - root - 2017-12-01 06:12:04.434474: step 82330, loss = 0.38, batch loss = 0.24 (49.3 examples/sec; 0.162 sec/batch; 11h:16m:08s remains)
INFO - root - 2017-12-01 06:12:06.001519: step 82340, loss = 0.46, batch loss = 0.32 (52.1 examples/sec; 0.153 sec/batch; 10h:39m:56s remains)
INFO - root - 2017-12-01 06:12:07.565719: step 82350, loss = 0.35, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 10h:52m:36s remains)
INFO - root - 2017-12-01 06:12:09.138028: step 82360, loss = 0.40, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 11h:00m:42s remains)
INFO - root - 2017-12-01 06:12:10.694399: step 82370, loss = 0.37, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 10h:41m:29s remains)
INFO - root - 2017-12-01 06:12:12.258783: step 82380, loss = 0.30, batch loss = 0.17 (52.3 examples/sec; 0.153 sec/batch; 10h:37m:18s remains)
INFO - root - 2017-12-01 06:12:13.838495: step 82390, loss = 0.32, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 10h:50m:35s remains)
INFO - root - 2017-12-01 06:12:15.415995: step 82400, loss = 0.31, batch loss = 0.17 (50.2 examples/sec; 0.159 sec/batch; 11h:03m:40s remains)
INFO - root - 2017-12-01 06:12:17.047797: step 82410, loss = 0.32, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 10h:50m:37s remains)
INFO - root - 2017-12-01 06:12:18.602048: step 82420, loss = 0.31, batch loss = 0.17 (51.8 examples/sec; 0.155 sec/batch; 10h:44m:12s remains)
INFO - root - 2017-12-01 06:12:20.187001: step 82430, loss = 0.49, batch loss = 0.35 (49.4 examples/sec; 0.162 sec/batch; 11h:15m:34s remains)
INFO - root - 2017-12-01 06:12:21.750047: step 82440, loss = 0.35, batch loss = 0.21 (51.1 examples/sec; 0.156 sec/batch; 10h:52m:12s remains)
INFO - root - 2017-12-01 06:12:23.331873: step 82450, loss = 0.51, batch loss = 0.37 (52.4 examples/sec; 0.153 sec/batch; 10h:35m:42s remains)
INFO - root - 2017-12-01 06:12:24.929004: step 82460, loss = 0.32, batch loss = 0.18 (49.4 examples/sec; 0.162 sec/batch; 11h:15m:17s remains)
INFO - root - 2017-12-01 06:12:26.487232: step 82470, loss = 0.34, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 11h:05m:32s remains)
INFO - root - 2017-12-01 06:12:28.073962: step 82480, loss = 0.31, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 10h:38m:46s remains)
INFO - root - 2017-12-01 06:12:29.655543: step 82490, loss = 0.36, batch loss = 0.23 (49.1 examples/sec; 0.163 sec/batch; 11h:19m:14s remains)
INFO - root - 2017-12-01 06:12:31.209822: step 82500, loss = 0.41, batch loss = 0.27 (50.5 examples/sec; 0.158 sec/batch; 11h:00m:06s remains)
INFO - root - 2017-12-01 06:12:32.810601: step 82510, loss = 0.37, batch loss = 0.23 (52.1 examples/sec; 0.153 sec/batch; 10h:39m:22s remains)
INFO - root - 2017-12-01 06:12:34.388407: step 82520, loss = 0.29, batch loss = 0.15 (50.6 examples/sec; 0.158 sec/batch; 10h:58m:46s remains)
INFO - root - 2017-12-01 06:12:35.953011: step 82530, loss = 0.32, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 10h:52m:26s remains)
INFO - root - 2017-12-01 06:12:37.489522: step 82540, loss = 0.42, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 10h:45m:05s remains)
INFO - root - 2017-12-01 06:12:39.037628: step 82550, loss = 0.37, batch loss = 0.23 (50.1 examples/sec; 0.160 sec/batch; 11h:05m:45s remains)
INFO - root - 2017-12-01 06:12:40.598925: step 82560, loss = 0.36, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 10h:38m:11s remains)
INFO - root - 2017-12-01 06:12:42.201782: step 82570, loss = 0.33, batch loss = 0.19 (47.2 examples/sec; 0.169 sec/batch; 11h:45m:58s remains)
INFO - root - 2017-12-01 06:12:43.789311: step 82580, loss = 0.34, batch loss = 0.20 (49.3 examples/sec; 0.162 sec/batch; 11h:16m:34s remains)
INFO - root - 2017-12-01 06:12:45.375442: step 82590, loss = 0.29, batch loss = 0.15 (48.0 examples/sec; 0.167 sec/batch; 11h:34m:04s remains)
INFO - root - 2017-12-01 06:12:46.954668: step 82600, loss = 0.33, batch loss = 0.19 (52.9 examples/sec; 0.151 sec/batch; 10h:29m:22s remains)
INFO - root - 2017-12-01 06:12:48.586785: step 82610, loss = 0.41, batch loss = 0.27 (49.2 examples/sec; 0.162 sec/batch; 11h:16m:39s remains)
INFO - root - 2017-12-01 06:12:50.150104: step 82620, loss = 0.31, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 10h:49m:11s remains)
INFO - root - 2017-12-01 06:12:51.721228: step 82630, loss = 0.35, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 10h:58m:27s remains)
INFO - root - 2017-12-01 06:12:53.280877: step 82640, loss = 0.35, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 10h:41m:20s remains)
INFO - root - 2017-12-01 06:12:54.866885: step 82650, loss = 0.39, batch loss = 0.25 (50.8 examples/sec; 0.157 sec/batch; 10h:55m:12s remains)
INFO - root - 2017-12-01 06:12:56.432026: step 82660, loss = 0.31, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 10h:42m:18s remains)
INFO - root - 2017-12-01 06:12:57.981890: step 82670, loss = 0.32, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 10h:55m:58s remains)
INFO - root - 2017-12-01 06:12:59.562572: step 82680, loss = 0.40, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 10h:47m:06s remains)
INFO - root - 2017-12-01 06:13:01.123715: step 82690, loss = 0.44, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 10h:54m:28s remains)
INFO - root - 2017-12-01 06:13:02.686231: step 82700, loss = 0.42, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 10h:49m:28s remains)
INFO - root - 2017-12-01 06:13:04.336016: step 82710, loss = 0.43, batch loss = 0.29 (52.0 examples/sec; 0.154 sec/batch; 10h:40m:23s remains)
INFO - root - 2017-12-01 06:13:05.900569: step 82720, loss = 0.32, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 10h:51m:47s remains)
INFO - root - 2017-12-01 06:13:07.479698: step 82730, loss = 0.37, batch loss = 0.23 (48.6 examples/sec; 0.165 sec/batch; 11h:25m:22s remains)
INFO - root - 2017-12-01 06:13:09.053467: step 82740, loss = 0.35, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 10h:56m:31s remains)
INFO - root - 2017-12-01 06:13:10.620569: step 82750, loss = 0.31, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 10h:54m:09s remains)
INFO - root - 2017-12-01 06:13:12.183803: step 82760, loss = 0.33, batch loss = 0.19 (49.0 examples/sec; 0.163 sec/batch; 11h:19m:48s remains)
INFO - root - 2017-12-01 06:13:13.745339: step 82770, loss = 0.44, batch loss = 0.30 (52.4 examples/sec; 0.153 sec/batch; 10h:35m:21s remains)
INFO - root - 2017-12-01 06:13:15.335953: step 82780, loss = 0.38, batch loss = 0.24 (49.8 examples/sec; 0.161 sec/batch; 11h:08m:08s remains)
INFO - root - 2017-12-01 06:13:16.915005: step 82790, loss = 0.39, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 10h:57m:49s remains)
INFO - root - 2017-12-01 06:13:18.483002: step 82800, loss = 0.40, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 10h:59m:35s remains)
INFO - root - 2017-12-01 06:13:20.123297: step 82810, loss = 0.32, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 10h:50m:03s remains)
INFO - root - 2017-12-01 06:13:21.687115: step 82820, loss = 0.35, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 10h:51m:59s remains)
INFO - root - 2017-12-01 06:13:23.244574: step 82830, loss = 0.31, batch loss = 0.17 (49.7 examples/sec; 0.161 sec/batch; 11h:09m:10s remains)
INFO - root - 2017-12-01 06:13:24.816548: step 82840, loss = 0.37, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 10h:46m:39s remains)
INFO - root - 2017-12-01 06:13:26.387918: step 82850, loss = 0.28, batch loss = 0.14 (51.8 examples/sec; 0.154 sec/batch; 10h:42m:06s remains)
INFO - root - 2017-12-01 06:13:27.948575: step 82860, loss = 0.35, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 10h:54m:08s remains)
INFO - root - 2017-12-01 06:13:29.518685: step 82870, loss = 0.35, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 10h:58m:50s remains)
INFO - root - 2017-12-01 06:13:31.087127: step 82880, loss = 0.37, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 10h:48m:43s remains)
INFO - root - 2017-12-01 06:13:32.657056: step 82890, loss = 0.29, batch loss = 0.15 (52.5 examples/sec; 0.152 sec/batch; 10h:33m:39s remains)
INFO - root - 2017-12-01 06:13:34.196301: step 82900, loss = 0.45, batch loss = 0.32 (53.5 examples/sec; 0.150 sec/batch; 10h:22m:06s remains)
INFO - root - 2017-12-01 06:13:35.806562: step 82910, loss = 0.35, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 10h:50m:05s remains)
INFO - root - 2017-12-01 06:13:37.385124: step 82920, loss = 0.42, batch loss = 0.28 (49.8 examples/sec; 0.161 sec/batch; 11h:08m:52s remains)
INFO - root - 2017-12-01 06:13:38.941659: step 82930, loss = 0.36, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 10h:59m:16s remains)
INFO - root - 2017-12-01 06:13:40.509067: step 82940, loss = 0.42, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 10h:46m:27s remains)
INFO - root - 2017-12-01 06:13:42.085677: step 82950, loss = 0.31, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 10h:48m:33s remains)
INFO - root - 2017-12-01 06:13:43.674880: step 82960, loss = 0.49, batch loss = 0.35 (48.5 examples/sec; 0.165 sec/batch; 11h:25m:42s remains)
INFO - root - 2017-12-01 06:13:45.255490: step 82970, loss = 0.36, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 10h:45m:10s remains)
INFO - root - 2017-12-01 06:13:46.805690: step 82980, loss = 0.31, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 10h:44m:39s remains)
INFO - root - 2017-12-01 06:13:48.349756: step 82990, loss = 0.48, batch loss = 0.34 (51.7 examples/sec; 0.155 sec/batch; 10h:43m:34s remains)
INFO - root - 2017-12-01 06:13:49.907359: step 83000, loss = 0.37, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 10h:57m:46s remains)
INFO - root - 2017-12-01 06:13:51.554890: step 83010, loss = 0.42, batch loss = 0.29 (50.4 examples/sec; 0.159 sec/batch; 11h:00m:32s remains)
INFO - root - 2017-12-01 06:13:53.111333: step 83020, loss = 0.33, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 10h:37m:43s remains)
INFO - root - 2017-12-01 06:13:54.670345: step 83030, loss = 0.43, batch loss = 0.29 (50.1 examples/sec; 0.160 sec/batch; 11h:04m:06s remains)
INFO - root - 2017-12-01 06:13:56.245284: step 83040, loss = 0.37, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 10h:51m:17s remains)
INFO - root - 2017-12-01 06:13:57.803369: step 83050, loss = 0.34, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 10h:40m:53s remains)
INFO - root - 2017-12-01 06:13:59.372731: step 83060, loss = 0.43, batch loss = 0.29 (51.1 examples/sec; 0.157 sec/batch; 10h:51m:28s remains)
INFO - root - 2017-12-01 06:14:00.940905: step 83070, loss = 0.37, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 11h:01m:12s remains)
INFO - root - 2017-12-01 06:14:02.492854: step 83080, loss = 0.32, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 10h:51m:42s remains)
INFO - root - 2017-12-01 06:14:04.056829: step 83090, loss = 0.44, batch loss = 0.30 (50.5 examples/sec; 0.158 sec/batch; 10h:58m:00s remains)
INFO - root - 2017-12-01 06:14:05.616817: step 83100, loss = 0.58, batch loss = 0.44 (51.4 examples/sec; 0.156 sec/batch; 10h:46m:26s remains)
INFO - root - 2017-12-01 06:14:07.229781: step 83110, loss = 0.29, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 10h:46m:09s remains)
INFO - root - 2017-12-01 06:14:08.807841: step 83120, loss = 0.33, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 10h:54m:22s remains)
INFO - root - 2017-12-01 06:14:10.374732: step 83130, loss = 0.35, batch loss = 0.21 (50.5 examples/sec; 0.159 sec/batch; 10h:58m:49s remains)
INFO - root - 2017-12-01 06:14:11.932345: step 83140, loss = 0.38, batch loss = 0.24 (50.0 examples/sec; 0.160 sec/batch; 11h:05m:33s remains)
INFO - root - 2017-12-01 06:14:13.504702: step 83150, loss = 0.31, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 10h:43m:06s remains)
INFO - root - 2017-12-01 06:14:15.072872: step 83160, loss = 0.38, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 10h:43m:48s remains)
INFO - root - 2017-12-01 06:14:16.643676: step 83170, loss = 0.33, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 11h:00m:56s remains)
INFO - root - 2017-12-01 06:14:18.211249: step 83180, loss = 0.31, batch loss = 0.18 (52.5 examples/sec; 0.152 sec/batch; 10h:33m:02s remains)
INFO - root - 2017-12-01 06:14:19.771558: step 83190, loss = 0.44, batch loss = 0.30 (50.1 examples/sec; 0.160 sec/batch; 11h:03m:42s remains)
INFO - root - 2017-12-01 06:14:21.338921: step 83200, loss = 0.33, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 10h:44m:41s remains)
INFO - root - 2017-12-01 06:14:22.947617: step 83210, loss = 0.35, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 10h:38m:30s remains)
INFO - root - 2017-12-01 06:14:24.509462: step 83220, loss = 0.49, batch loss = 0.36 (51.1 examples/sec; 0.156 sec/batch; 10h:49m:52s remains)
INFO - root - 2017-12-01 06:14:26.066158: step 83230, loss = 0.29, batch loss = 0.15 (52.4 examples/sec; 0.153 sec/batch; 10h:34m:45s remains)
INFO - root - 2017-12-01 06:14:27.641908: step 83240, loss = 0.33, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 10h:56m:02s remains)
INFO - root - 2017-12-01 06:14:29.199541: step 83250, loss = 0.30, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 10h:41m:01s remains)
INFO - root - 2017-12-01 06:14:30.758956: step 83260, loss = 0.33, batch loss = 0.19 (53.3 examples/sec; 0.150 sec/batch; 10h:23m:28s remains)
INFO - root - 2017-12-01 06:14:32.329329: step 83270, loss = 0.38, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 10h:49m:55s remains)
INFO - root - 2017-12-01 06:14:33.899041: step 83280, loss = 0.30, batch loss = 0.17 (52.3 examples/sec; 0.153 sec/batch; 10h:34m:50s remains)
INFO - root - 2017-12-01 06:14:35.461556: step 83290, loss = 0.35, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 10h:50m:20s remains)
INFO - root - 2017-12-01 06:14:37.027044: step 83300, loss = 0.33, batch loss = 0.19 (50.2 examples/sec; 0.159 sec/batch; 11h:02m:26s remains)
INFO - root - 2017-12-01 06:14:38.686070: step 83310, loss = 0.33, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 10h:59m:27s remains)
INFO - root - 2017-12-01 06:14:40.244905: step 83320, loss = 0.31, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 10h:58m:09s remains)
INFO - root - 2017-12-01 06:14:41.789604: step 83330, loss = 0.40, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 10h:48m:52s remains)
INFO - root - 2017-12-01 06:14:43.365409: step 83340, loss = 0.30, batch loss = 0.16 (49.5 examples/sec; 0.162 sec/batch; 11h:11m:19s remains)
INFO - root - 2017-12-01 06:14:44.931247: step 83350, loss = 0.46, batch loss = 0.32 (51.6 examples/sec; 0.155 sec/batch; 10h:44m:07s remains)
INFO - root - 2017-12-01 06:14:46.496400: step 83360, loss = 0.34, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 10h:49m:21s remains)
INFO - root - 2017-12-01 06:14:48.061380: step 83370, loss = 0.31, batch loss = 0.18 (50.0 examples/sec; 0.160 sec/batch; 11h:03m:43s remains)
INFO - root - 2017-12-01 06:14:49.617986: step 83380, loss = 0.32, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 10h:38m:18s remains)
INFO - root - 2017-12-01 06:14:51.206219: step 83390, loss = 0.33, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 10h:40m:51s remains)
INFO - root - 2017-12-01 06:14:52.758167: step 83400, loss = 0.29, batch loss = 0.15 (52.1 examples/sec; 0.154 sec/batch; 10h:37m:32s remains)
INFO - root - 2017-12-01 06:14:54.360748: step 83410, loss = 0.42, batch loss = 0.29 (52.0 examples/sec; 0.154 sec/batch; 10h:38m:57s remains)
INFO - root - 2017-12-01 06:14:55.921154: step 83420, loss = 0.43, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 10h:48m:27s remains)
INFO - root - 2017-12-01 06:14:57.474550: step 83430, loss = 0.40, batch loss = 0.27 (52.1 examples/sec; 0.154 sec/batch; 10h:37m:36s remains)
INFO - root - 2017-12-01 06:14:59.032542: step 83440, loss = 0.34, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 10h:51m:45s remains)
INFO - root - 2017-12-01 06:15:00.601993: step 83450, loss = 0.50, batch loss = 0.36 (50.3 examples/sec; 0.159 sec/batch; 11h:00m:33s remains)
INFO - root - 2017-12-01 06:15:02.154626: step 83460, loss = 0.35, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 10h:46m:45s remains)
INFO - root - 2017-12-01 06:15:03.726811: step 83470, loss = 0.31, batch loss = 0.17 (49.0 examples/sec; 0.163 sec/batch; 11h:18m:02s remains)
INFO - root - 2017-12-01 06:15:05.293953: step 83480, loss = 0.30, batch loss = 0.17 (53.0 examples/sec; 0.151 sec/batch; 10h:26m:56s remains)
INFO - root - 2017-12-01 06:15:06.856519: step 83490, loss = 0.35, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 10h:54m:40s remains)
INFO - root - 2017-12-01 06:15:08.413506: step 83500, loss = 0.36, batch loss = 0.22 (52.4 examples/sec; 0.153 sec/batch; 10h:34m:07s remains)
INFO - root - 2017-12-01 06:15:10.049563: step 83510, loss = 0.36, batch loss = 0.22 (49.9 examples/sec; 0.160 sec/batch; 11h:05m:00s remains)
INFO - root - 2017-12-01 06:15:11.649696: step 83520, loss = 0.47, batch loss = 0.33 (50.6 examples/sec; 0.158 sec/batch; 10h:56m:11s remains)
INFO - root - 2017-12-01 06:15:13.223930: step 83530, loss = 0.37, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 10h:50m:08s remains)
INFO - root - 2017-12-01 06:15:14.805436: step 83540, loss = 0.30, batch loss = 0.16 (48.9 examples/sec; 0.163 sec/batch; 11h:18m:11s remains)
INFO - root - 2017-12-01 06:15:16.381452: step 83550, loss = 0.45, batch loss = 0.31 (49.9 examples/sec; 0.160 sec/batch; 11h:05m:36s remains)
INFO - root - 2017-12-01 06:15:17.990265: step 83560, loss = 0.29, batch loss = 0.15 (50.9 examples/sec; 0.157 sec/batch; 10h:51m:43s remains)
INFO - root - 2017-12-01 06:15:19.552535: step 83570, loss = 0.38, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 10h:44m:17s remains)
INFO - root - 2017-12-01 06:15:21.146880: step 83580, loss = 0.34, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 10h:54m:12s remains)
INFO - root - 2017-12-01 06:15:22.731692: step 83590, loss = 0.37, batch loss = 0.24 (49.6 examples/sec; 0.161 sec/batch; 11h:09m:15s remains)
INFO - root - 2017-12-01 06:15:24.285879: step 83600, loss = 0.47, batch loss = 0.33 (51.0 examples/sec; 0.157 sec/batch; 10h:51m:12s remains)
INFO - root - 2017-12-01 06:15:25.924663: step 83610, loss = 0.30, batch loss = 0.16 (46.7 examples/sec; 0.171 sec/batch; 11h:50m:16s remains)
INFO - root - 2017-12-01 06:15:27.500096: step 83620, loss = 0.33, batch loss = 0.19 (49.7 examples/sec; 0.161 sec/batch; 11h:07m:42s remains)
INFO - root - 2017-12-01 06:15:29.055813: step 83630, loss = 0.41, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 10h:42m:50s remains)
INFO - root - 2017-12-01 06:15:30.647507: step 83640, loss = 0.32, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 10h:44m:24s remains)
INFO - root - 2017-12-01 06:15:32.196045: step 83650, loss = 0.33, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 10h:35m:06s remains)
INFO - root - 2017-12-01 06:15:33.761801: step 83660, loss = 0.34, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 10h:59m:18s remains)
INFO - root - 2017-12-01 06:15:35.326252: step 83670, loss = 0.37, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 10h:51m:30s remains)
INFO - root - 2017-12-01 06:15:36.878715: step 83680, loss = 0.42, batch loss = 0.28 (53.3 examples/sec; 0.150 sec/batch; 10h:22m:01s remains)
INFO - root - 2017-12-01 06:15:38.461091: step 83690, loss = 0.37, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 10h:52m:11s remains)
INFO - root - 2017-12-01 06:15:40.044551: step 83700, loss = 0.32, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 10h:52m:45s remains)
INFO - root - 2017-12-01 06:15:41.687095: step 83710, loss = 0.35, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 10h:54m:01s remains)
INFO - root - 2017-12-01 06:15:43.253661: step 83720, loss = 0.44, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 10h:51m:36s remains)
INFO - root - 2017-12-01 06:15:44.815142: step 83730, loss = 0.37, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 10h:53m:12s remains)
INFO - root - 2017-12-01 06:15:46.383295: step 83740, loss = 0.44, batch loss = 0.30 (49.8 examples/sec; 0.161 sec/batch; 11h:05m:57s remains)
INFO - root - 2017-12-01 06:15:47.934075: step 83750, loss = 0.39, batch loss = 0.25 (52.0 examples/sec; 0.154 sec/batch; 10h:37m:42s remains)
INFO - root - 2017-12-01 06:15:49.504062: step 83760, loss = 0.32, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 10h:46m:24s remains)
INFO - root - 2017-12-01 06:15:51.069219: step 83770, loss = 0.36, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 10h:35m:03s remains)
INFO - root - 2017-12-01 06:15:52.646293: step 83780, loss = 0.52, batch loss = 0.39 (49.9 examples/sec; 0.160 sec/batch; 11h:03m:56s remains)
INFO - root - 2017-12-01 06:15:54.196465: step 83790, loss = 0.36, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 10h:38m:39s remains)
INFO - root - 2017-12-01 06:15:55.756249: step 83800, loss = 0.29, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 10h:46m:18s remains)
INFO - root - 2017-12-01 06:15:57.445689: step 83810, loss = 0.31, batch loss = 0.17 (49.7 examples/sec; 0.161 sec/batch; 11h:07m:27s remains)
INFO - root - 2017-12-01 06:15:59.052791: step 83820, loss = 0.31, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 10h:44m:35s remains)
INFO - root - 2017-12-01 06:16:00.605734: step 83830, loss = 0.43, batch loss = 0.30 (50.8 examples/sec; 0.157 sec/batch; 10h:52m:02s remains)
INFO - root - 2017-12-01 06:16:02.157045: step 83840, loss = 0.35, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 10h:56m:14s remains)
INFO - root - 2017-12-01 06:16:03.715028: step 83850, loss = 0.46, batch loss = 0.33 (50.4 examples/sec; 0.159 sec/batch; 10h:58m:21s remains)
INFO - root - 2017-12-01 06:16:05.282135: step 83860, loss = 0.36, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 10h:45m:38s remains)
INFO - root - 2017-12-01 06:16:06.857566: step 83870, loss = 0.29, batch loss = 0.15 (50.8 examples/sec; 0.157 sec/batch; 10h:52m:25s remains)
INFO - root - 2017-12-01 06:16:08.430695: step 83880, loss = 0.40, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 10h:49m:52s remains)
INFO - root - 2017-12-01 06:16:10.002566: step 83890, loss = 0.67, batch loss = 0.53 (50.5 examples/sec; 0.159 sec/batch; 10h:56m:47s remains)
INFO - root - 2017-12-01 06:16:11.559060: step 83900, loss = 0.34, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 10h:59m:05s remains)
INFO - root - 2017-12-01 06:16:13.179697: step 83910, loss = 0.53, batch loss = 0.39 (50.9 examples/sec; 0.157 sec/batch; 10h:51m:12s remains)
INFO - root - 2017-12-01 06:16:14.750827: step 83920, loss = 0.35, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 10h:57m:38s remains)
INFO - root - 2017-12-01 06:16:16.315933: step 83930, loss = 0.33, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 10h:44m:31s remains)
INFO - root - 2017-12-01 06:16:17.868882: step 83940, loss = 0.34, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 10h:44m:22s remains)
INFO - root - 2017-12-01 06:16:19.439839: step 83950, loss = 0.35, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 10h:38m:51s remains)
INFO - root - 2017-12-01 06:16:21.005399: step 83960, loss = 0.39, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 10h:54m:29s remains)
INFO - root - 2017-12-01 06:16:22.569630: step 83970, loss = 0.38, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 10h:44m:55s remains)
INFO - root - 2017-12-01 06:16:24.110814: step 83980, loss = 0.35, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 10h:37m:48s remains)
INFO - root - 2017-12-01 06:16:25.673072: step 83990, loss = 0.36, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 10h:30m:27s remains)
INFO - root - 2017-12-01 06:16:27.256075: step 84000, loss = 0.41, batch loss = 0.27 (51.7 examples/sec; 0.155 sec/batch; 10h:41m:08s remains)
INFO - root - 2017-12-01 06:16:28.885895: step 84010, loss = 0.38, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 10h:51m:27s remains)
INFO - root - 2017-12-01 06:16:30.486819: step 84020, loss = 0.50, batch loss = 0.36 (52.3 examples/sec; 0.153 sec/batch; 10h:33m:33s remains)
INFO - root - 2017-12-01 06:16:32.043199: step 84030, loss = 0.32, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 10h:50m:22s remains)
INFO - root - 2017-12-01 06:16:33.615177: step 84040, loss = 0.29, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 10h:43m:35s remains)
INFO - root - 2017-12-01 06:16:35.185746: step 84050, loss = 0.41, batch loss = 0.27 (49.1 examples/sec; 0.163 sec/batch; 11h:14m:04s remains)
INFO - root - 2017-12-01 06:16:36.765498: step 84060, loss = 0.39, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 10h:39m:41s remains)
INFO - root - 2017-12-01 06:16:38.323907: step 84070, loss = 0.33, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 10h:36m:51s remains)
INFO - root - 2017-12-01 06:16:39.894988: step 84080, loss = 0.32, batch loss = 0.18 (49.6 examples/sec; 0.161 sec/batch; 11h:08m:02s remains)
INFO - root - 2017-12-01 06:16:41.450408: step 84090, loss = 0.32, batch loss = 0.18 (52.4 examples/sec; 0.153 sec/batch; 10h:32m:14s remains)
INFO - root - 2017-12-01 06:16:43.032800: step 84100, loss = 0.29, batch loss = 0.16 (49.4 examples/sec; 0.162 sec/batch; 11h:09m:47s remains)
INFO - root - 2017-12-01 06:16:44.664901: step 84110, loss = 0.39, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 10h:42m:59s remains)
INFO - root - 2017-12-01 06:16:46.219997: step 84120, loss = 0.34, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 10h:45m:42s remains)
INFO - root - 2017-12-01 06:16:47.779639: step 84130, loss = 0.33, batch loss = 0.19 (48.8 examples/sec; 0.164 sec/batch; 11h:19m:07s remains)
INFO - root - 2017-12-01 06:16:49.346881: step 84140, loss = 0.41, batch loss = 0.27 (52.3 examples/sec; 0.153 sec/batch; 10h:32m:59s remains)
INFO - root - 2017-12-01 06:16:50.911143: step 84150, loss = 0.39, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 10h:50m:18s remains)
INFO - root - 2017-12-01 06:16:52.459208: step 84160, loss = 0.44, batch loss = 0.30 (52.0 examples/sec; 0.154 sec/batch; 10h:36m:21s remains)
INFO - root - 2017-12-01 06:16:54.007183: step 84170, loss = 0.31, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 10h:49m:59s remains)
INFO - root - 2017-12-01 06:16:55.581325: step 84180, loss = 0.34, batch loss = 0.20 (53.0 examples/sec; 0.151 sec/batch; 10h:25m:16s remains)
INFO - root - 2017-12-01 06:16:57.116386: step 84190, loss = 0.44, batch loss = 0.30 (51.8 examples/sec; 0.154 sec/batch; 10h:39m:07s remains)
INFO - root - 2017-12-01 06:16:58.677988: step 84200, loss = 0.36, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 10h:39m:56s remains)
INFO - root - 2017-12-01 06:17:00.320625: step 84210, loss = 0.32, batch loss = 0.18 (49.3 examples/sec; 0.162 sec/batch; 11h:11m:19s remains)
INFO - root - 2017-12-01 06:17:01.881400: step 84220, loss = 0.34, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 10h:51m:10s remains)
INFO - root - 2017-12-01 06:17:03.453327: step 84230, loss = 0.32, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 10h:37m:34s remains)
INFO - root - 2017-12-01 06:17:05.026423: step 84240, loss = 0.41, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 10h:49m:58s remains)
INFO - root - 2017-12-01 06:17:06.583966: step 84250, loss = 0.32, batch loss = 0.18 (49.9 examples/sec; 0.160 sec/batch; 11h:03m:17s remains)
INFO - root - 2017-12-01 06:17:08.138835: step 84260, loss = 0.34, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 10h:32m:20s remains)
INFO - root - 2017-12-01 06:17:09.720110: step 84270, loss = 0.34, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 10h:41m:24s remains)
INFO - root - 2017-12-01 06:17:11.282694: step 84280, loss = 0.32, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 10h:32m:46s remains)
INFO - root - 2017-12-01 06:17:12.835592: step 84290, loss = 0.30, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 10h:33m:35s remains)
INFO - root - 2017-12-01 06:17:14.433573: step 84300, loss = 0.32, batch loss = 0.18 (47.0 examples/sec; 0.170 sec/batch; 11h:43m:23s remains)
INFO - root - 2017-12-01 06:17:16.044877: step 84310, loss = 0.42, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 10h:37m:23s remains)
INFO - root - 2017-12-01 06:17:17.610588: step 84320, loss = 0.43, batch loss = 0.29 (50.1 examples/sec; 0.160 sec/batch; 11h:00m:53s remains)
INFO - root - 2017-12-01 06:17:19.170872: step 84330, loss = 0.33, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 10h:45m:08s remains)
INFO - root - 2017-12-01 06:17:20.727001: step 84340, loss = 0.39, batch loss = 0.25 (50.3 examples/sec; 0.159 sec/batch; 10h:57m:13s remains)
INFO - root - 2017-12-01 06:17:22.284249: step 84350, loss = 0.43, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 10h:58m:25s remains)
INFO - root - 2017-12-01 06:17:23.871835: step 84360, loss = 0.58, batch loss = 0.44 (51.5 examples/sec; 0.155 sec/batch; 10h:42m:29s remains)
INFO - root - 2017-12-01 06:17:25.461415: step 84370, loss = 0.39, batch loss = 0.25 (44.9 examples/sec; 0.178 sec/batch; 12h:16m:05s remains)
INFO - root - 2017-12-01 06:17:27.042331: step 84380, loss = 0.37, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 10h:49m:06s remains)
INFO - root - 2017-12-01 06:17:28.604476: step 84390, loss = 0.37, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 10h:52m:23s remains)
INFO - root - 2017-12-01 06:17:30.177445: step 84400, loss = 0.39, batch loss = 0.25 (50.1 examples/sec; 0.160 sec/batch; 11h:00m:30s remains)
INFO - root - 2017-12-01 06:17:31.816843: step 84410, loss = 0.39, batch loss = 0.26 (52.1 examples/sec; 0.153 sec/batch; 10h:34m:25s remains)
INFO - root - 2017-12-01 06:17:33.373622: step 84420, loss = 0.36, batch loss = 0.23 (53.5 examples/sec; 0.150 sec/batch; 10h:18m:17s remains)
INFO - root - 2017-12-01 06:17:34.953464: step 84430, loss = 0.32, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 10h:51m:06s remains)
INFO - root - 2017-12-01 06:17:36.513350: step 84440, loss = 0.32, batch loss = 0.19 (49.7 examples/sec; 0.161 sec/batch; 11h:05m:32s remains)
INFO - root - 2017-12-01 06:17:38.061048: step 84450, loss = 0.42, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 10h:48m:38s remains)
INFO - root - 2017-12-01 06:17:39.625624: step 84460, loss = 0.34, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 10h:36m:50s remains)
INFO - root - 2017-12-01 06:17:41.209521: step 84470, loss = 0.34, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 10h:42m:53s remains)
INFO - root - 2017-12-01 06:17:42.766799: step 84480, loss = 0.32, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 10h:40m:53s remains)
INFO - root - 2017-12-01 06:17:44.343434: step 84490, loss = 0.50, batch loss = 0.36 (50.8 examples/sec; 0.158 sec/batch; 10h:51m:12s remains)
INFO - root - 2017-12-01 06:17:45.902476: step 84500, loss = 0.39, batch loss = 0.26 (53.1 examples/sec; 0.151 sec/batch; 10h:23m:03s remains)
INFO - root - 2017-12-01 06:17:47.544752: step 84510, loss = 0.30, batch loss = 0.16 (51.1 examples/sec; 0.157 sec/batch; 10h:47m:29s remains)
INFO - root - 2017-12-01 06:17:49.100242: step 84520, loss = 0.38, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 11h:02m:07s remains)
INFO - root - 2017-12-01 06:17:50.664206: step 84530, loss = 0.43, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 10h:41m:24s remains)
INFO - root - 2017-12-01 06:17:52.221956: step 84540, loss = 0.33, batch loss = 0.19 (52.7 examples/sec; 0.152 sec/batch; 10h:26m:45s remains)
INFO - root - 2017-12-01 06:17:53.768241: step 84550, loss = 0.35, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 10h:28m:47s remains)
INFO - root - 2017-12-01 06:17:55.339287: step 84560, loss = 0.33, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 10h:44m:05s remains)
INFO - root - 2017-12-01 06:17:56.903389: step 84570, loss = 0.53, batch loss = 0.39 (49.5 examples/sec; 0.162 sec/batch; 11h:08m:02s remains)
INFO - root - 2017-12-01 06:17:58.453119: step 84580, loss = 0.41, batch loss = 0.28 (49.3 examples/sec; 0.162 sec/batch; 11h:10m:52s remains)
INFO - root - 2017-12-01 06:18:00.009926: step 84590, loss = 0.37, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 10h:31m:04s remains)
INFO - root - 2017-12-01 06:18:01.568827: step 84600, loss = 0.40, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 10h:45m:42s remains)
INFO - root - 2017-12-01 06:18:03.201805: step 84610, loss = 0.36, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 10h:54m:31s remains)
INFO - root - 2017-12-01 06:18:04.769631: step 84620, loss = 0.40, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 10h:42m:08s remains)
INFO - root - 2017-12-01 06:18:06.387040: step 84630, loss = 0.34, batch loss = 0.20 (49.2 examples/sec; 0.163 sec/batch; 11h:11m:35s remains)
INFO - root - 2017-12-01 06:18:07.949288: step 84640, loss = 0.31, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 10h:31m:42s remains)
INFO - root - 2017-12-01 06:18:09.509717: step 84650, loss = 0.30, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 10h:56m:54s remains)
INFO - root - 2017-12-01 06:18:11.087436: step 84660, loss = 0.34, batch loss = 0.20 (53.5 examples/sec; 0.149 sec/batch; 10h:17m:18s remains)
INFO - root - 2017-12-01 06:18:12.706937: step 84670, loss = 0.50, batch loss = 0.36 (49.9 examples/sec; 0.160 sec/batch; 11h:01m:58s remains)
INFO - root - 2017-12-01 06:18:14.283917: step 84680, loss = 0.39, batch loss = 0.25 (50.8 examples/sec; 0.157 sec/batch; 10h:50m:08s remains)
INFO - root - 2017-12-01 06:18:15.860979: step 84690, loss = 0.33, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 10h:49m:49s remains)
INFO - root - 2017-12-01 06:18:17.450795: step 84700, loss = 0.30, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 10h:42m:21s remains)
INFO - root - 2017-12-01 06:18:19.071405: step 84710, loss = 0.32, batch loss = 0.19 (52.1 examples/sec; 0.154 sec/batch; 10h:34m:28s remains)
INFO - root - 2017-12-01 06:18:20.686653: step 84720, loss = 0.32, batch loss = 0.19 (48.8 examples/sec; 0.164 sec/batch; 11h:17m:33s remains)
INFO - root - 2017-12-01 06:18:22.260500: step 84730, loss = 0.34, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 10h:37m:08s remains)
INFO - root - 2017-12-01 06:18:23.847765: step 84740, loss = 0.39, batch loss = 0.25 (51.4 examples/sec; 0.155 sec/batch; 10h:42m:05s remains)
INFO - root - 2017-12-01 06:18:25.398327: step 84750, loss = 0.32, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 10h:38m:35s remains)
INFO - root - 2017-12-01 06:18:26.960337: step 84760, loss = 0.33, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 10h:40m:40s remains)
INFO - root - 2017-12-01 06:18:28.535648: step 84770, loss = 0.31, batch loss = 0.17 (50.2 examples/sec; 0.159 sec/batch; 10h:58m:02s remains)
INFO - root - 2017-12-01 06:18:30.091652: step 84780, loss = 0.31, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 10h:37m:08s remains)
INFO - root - 2017-12-01 06:18:31.654488: step 84790, loss = 0.36, batch loss = 0.23 (53.0 examples/sec; 0.151 sec/batch; 10h:23m:28s remains)
INFO - root - 2017-12-01 06:18:33.237478: step 84800, loss = 0.56, batch loss = 0.42 (51.0 examples/sec; 0.157 sec/batch; 10h:47m:06s remains)
INFO - root - 2017-12-01 06:18:34.842441: step 84810, loss = 0.36, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 10h:43m:19s remains)
INFO - root - 2017-12-01 06:18:36.400868: step 84820, loss = 0.38, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 10h:31m:53s remains)
INFO - root - 2017-12-01 06:18:37.969044: step 84830, loss = 0.36, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 10h:50m:42s remains)
INFO - root - 2017-12-01 06:18:39.556532: step 84840, loss = 0.32, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 10h:57m:43s remains)
INFO - root - 2017-12-01 06:18:41.119249: step 84850, loss = 0.35, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 10h:46m:15s remains)
INFO - root - 2017-12-01 06:18:42.672882: step 84860, loss = 0.31, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 10h:53m:58s remains)
INFO - root - 2017-12-01 06:18:44.244048: step 84870, loss = 0.42, batch loss = 0.28 (50.8 examples/sec; 0.157 sec/batch; 10h:49m:29s remains)
INFO - root - 2017-12-01 06:18:45.806669: step 84880, loss = 0.41, batch loss = 0.28 (52.1 examples/sec; 0.154 sec/batch; 10h:33m:30s remains)
INFO - root - 2017-12-01 06:18:47.375281: step 84890, loss = 0.31, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 10h:35m:59s remains)
INFO - root - 2017-12-01 06:18:48.939402: step 84900, loss = 0.33, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 10h:43m:44s remains)
INFO - root - 2017-12-01 06:18:50.565477: step 84910, loss = 0.33, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 10h:47m:11s remains)
INFO - root - 2017-12-01 06:18:52.117072: step 84920, loss = 0.56, batch loss = 0.42 (51.8 examples/sec; 0.154 sec/batch; 10h:36m:52s remains)
INFO - root - 2017-12-01 06:18:53.659041: step 84930, loss = 0.42, batch loss = 0.28 (52.5 examples/sec; 0.152 sec/batch; 10h:29m:07s remains)
INFO - root - 2017-12-01 06:18:55.230584: step 84940, loss = 0.31, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 10h:40m:32s remains)
INFO - root - 2017-12-01 06:18:56.811330: step 84950, loss = 0.28, batch loss = 0.14 (50.2 examples/sec; 0.159 sec/batch; 10h:57m:39s remains)
INFO - root - 2017-12-01 06:18:58.375300: step 84960, loss = 0.41, batch loss = 0.27 (52.5 examples/sec; 0.152 sec/batch; 10h:28m:52s remains)
INFO - root - 2017-12-01 06:18:59.943250: step 84970, loss = 0.39, batch loss = 0.26 (49.9 examples/sec; 0.160 sec/batch; 11h:01m:49s remains)
INFO - root - 2017-12-01 06:19:01.507107: step 84980, loss = 0.38, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 10h:41m:58s remains)
INFO - root - 2017-12-01 06:19:03.067082: step 84990, loss = 0.31, batch loss = 0.18 (49.7 examples/sec; 0.161 sec/batch; 11h:04m:30s remains)
INFO - root - 2017-12-01 06:19:04.639074: step 85000, loss = 0.35, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 10h:36m:32s remains)
INFO - root - 2017-12-01 06:19:06.243849: step 85010, loss = 0.39, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 10h:52m:24s remains)
INFO - root - 2017-12-01 06:19:07.816123: step 85020, loss = 0.34, batch loss = 0.20 (48.0 examples/sec; 0.167 sec/batch; 11h:27m:57s remains)
INFO - root - 2017-12-01 06:19:09.381570: step 85030, loss = 0.34, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 10h:53m:21s remains)
INFO - root - 2017-12-01 06:19:10.937761: step 85040, loss = 0.33, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 10h:43m:22s remains)
INFO - root - 2017-12-01 06:19:12.504201: step 85050, loss = 0.34, batch loss = 0.20 (52.1 examples/sec; 0.153 sec/batch; 10h:32m:55s remains)
INFO - root - 2017-12-01 06:19:14.073930: step 85060, loss = 0.32, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 10h:50m:53s remains)
INFO - root - 2017-12-01 06:19:15.638156: step 85070, loss = 0.38, batch loss = 0.24 (49.5 examples/sec; 0.161 sec/batch; 11h:05m:57s remains)
INFO - root - 2017-12-01 06:19:17.207864: step 85080, loss = 0.32, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 10h:31m:31s remains)
INFO - root - 2017-12-01 06:19:18.765025: step 85090, loss = 0.36, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 10h:37m:33s remains)
INFO - root - 2017-12-01 06:19:20.343256: step 85100, loss = 0.35, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 10h:49m:05s remains)
INFO - root - 2017-12-01 06:19:22.008939: step 85110, loss = 0.32, batch loss = 0.19 (51.8 examples/sec; 0.155 sec/batch; 10h:37m:20s remains)
INFO - root - 2017-12-01 06:19:23.563892: step 85120, loss = 0.35, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 10h:46m:27s remains)
INFO - root - 2017-12-01 06:19:25.129743: step 85130, loss = 0.33, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 10h:52m:15s remains)
INFO - root - 2017-12-01 06:19:26.697732: step 85140, loss = 0.36, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 10h:44m:24s remains)
INFO - root - 2017-12-01 06:19:28.272398: step 85150, loss = 0.28, batch loss = 0.15 (50.9 examples/sec; 0.157 sec/batch; 10h:48m:21s remains)
INFO - root - 2017-12-01 06:19:29.832324: step 85160, loss = 0.32, batch loss = 0.18 (52.2 examples/sec; 0.153 sec/batch; 10h:31m:11s remains)
INFO - root - 2017-12-01 06:19:31.394719: step 85170, loss = 0.55, batch loss = 0.41 (51.0 examples/sec; 0.157 sec/batch; 10h:47m:04s remains)
INFO - root - 2017-12-01 06:19:32.966025: step 85180, loss = 0.32, batch loss = 0.19 (48.9 examples/sec; 0.164 sec/batch; 11h:14m:46s remains)
INFO - root - 2017-12-01 06:19:34.513711: step 85190, loss = 0.32, batch loss = 0.19 (52.1 examples/sec; 0.153 sec/batch; 10h:32m:33s remains)
INFO - root - 2017-12-01 06:19:36.071518: step 85200, loss = 0.35, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 10h:49m:32s remains)
INFO - root - 2017-12-01 06:19:37.691929: step 85210, loss = 0.36, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 10h:45m:12s remains)
INFO - root - 2017-12-01 06:19:39.261564: step 85220, loss = 0.28, batch loss = 0.15 (52.0 examples/sec; 0.154 sec/batch; 10h:33m:44s remains)
INFO - root - 2017-12-01 06:19:40.851237: step 85230, loss = 0.34, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 10h:59m:53s remains)
INFO - root - 2017-12-01 06:19:42.413622: step 85240, loss = 0.37, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 10h:45m:19s remains)
INFO - root - 2017-12-01 06:19:43.970250: step 85250, loss = 0.37, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 10h:46m:48s remains)
INFO - root - 2017-12-01 06:19:45.532079: step 85260, loss = 0.41, batch loss = 0.28 (50.1 examples/sec; 0.160 sec/batch; 10h:58m:22s remains)
INFO - root - 2017-12-01 06:19:47.090069: step 85270, loss = 0.42, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 10h:42m:01s remains)
INFO - root - 2017-12-01 06:19:48.662245: step 85280, loss = 0.33, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 10h:45m:24s remains)
INFO - root - 2017-12-01 06:19:50.231668: step 85290, loss = 0.32, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 10h:41m:15s remains)
INFO - root - 2017-12-01 06:19:51.784094: step 85300, loss = 0.43, batch loss = 0.29 (50.5 examples/sec; 0.158 sec/batch; 10h:52m:28s remains)
INFO - root - 2017-12-01 06:19:53.396169: step 85310, loss = 0.33, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 10h:39m:27s remains)
INFO - root - 2017-12-01 06:19:55.012110: step 85320, loss = 0.52, batch loss = 0.38 (51.1 examples/sec; 0.157 sec/batch; 10h:45m:32s remains)
INFO - root - 2017-12-01 06:19:56.581308: step 85330, loss = 0.40, batch loss = 0.27 (49.8 examples/sec; 0.161 sec/batch; 11h:01m:26s remains)
INFO - root - 2017-12-01 06:19:58.150561: step 85340, loss = 0.30, batch loss = 0.16 (50.6 examples/sec; 0.158 sec/batch; 10h:51m:41s remains)
INFO - root - 2017-12-01 06:19:59.734496: step 85350, loss = 0.38, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 10h:31m:05s remains)
INFO - root - 2017-12-01 06:20:01.304032: step 85360, loss = 0.31, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 10h:55m:06s remains)
INFO - root - 2017-12-01 06:20:02.870931: step 85370, loss = 0.32, batch loss = 0.19 (49.6 examples/sec; 0.161 sec/batch; 11h:04m:07s remains)
INFO - root - 2017-12-01 06:20:04.425078: step 85380, loss = 0.32, batch loss = 0.19 (52.1 examples/sec; 0.153 sec/batch; 10h:31m:51s remains)
INFO - root - 2017-12-01 06:20:06.000303: step 85390, loss = 0.42, batch loss = 0.28 (53.0 examples/sec; 0.151 sec/batch; 10h:21m:16s remains)
INFO - root - 2017-12-01 06:20:07.583842: step 85400, loss = 0.39, batch loss = 0.26 (50.3 examples/sec; 0.159 sec/batch; 10h:55m:14s remains)
INFO - root - 2017-12-01 06:20:09.215418: step 85410, loss = 0.28, batch loss = 0.14 (49.1 examples/sec; 0.163 sec/batch; 11h:10m:53s remains)
INFO - root - 2017-12-01 06:20:10.790018: step 85420, loss = 0.36, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 10h:33m:19s remains)
INFO - root - 2017-12-01 06:20:12.348687: step 85430, loss = 0.27, batch loss = 0.14 (53.3 examples/sec; 0.150 sec/batch; 10h:17m:39s remains)
INFO - root - 2017-12-01 06:20:13.921240: step 85440, loss = 0.41, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 10h:45m:59s remains)
INFO - root - 2017-12-01 06:20:15.475508: step 85450, loss = 0.46, batch loss = 0.33 (52.4 examples/sec; 0.153 sec/batch; 10h:28m:18s remains)
INFO - root - 2017-12-01 06:20:17.060530: step 85460, loss = 0.49, batch loss = 0.35 (52.9 examples/sec; 0.151 sec/batch; 10h:23m:13s remains)
INFO - root - 2017-12-01 06:20:18.654389: step 85470, loss = 0.43, batch loss = 0.30 (50.5 examples/sec; 0.159 sec/batch; 10h:52m:39s remains)
INFO - root - 2017-12-01 06:20:20.229754: step 85480, loss = 0.37, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 10h:50m:20s remains)
INFO - root - 2017-12-01 06:20:21.792644: step 85490, loss = 0.33, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 10h:46m:46s remains)
INFO - root - 2017-12-01 06:20:23.344140: step 85500, loss = 0.30, batch loss = 0.17 (52.9 examples/sec; 0.151 sec/batch; 10h:22m:22s remains)
INFO - root - 2017-12-01 06:20:24.973955: step 85510, loss = 0.39, batch loss = 0.26 (50.1 examples/sec; 0.160 sec/batch; 10h:57m:19s remains)
INFO - root - 2017-12-01 06:20:26.554828: step 85520, loss = 0.32, batch loss = 0.18 (48.6 examples/sec; 0.165 sec/batch; 11h:18m:06s remains)
INFO - root - 2017-12-01 06:20:28.134814: step 85530, loss = 0.35, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 10h:25m:57s remains)
INFO - root - 2017-12-01 06:20:29.719194: step 85540, loss = 0.62, batch loss = 0.49 (50.3 examples/sec; 0.159 sec/batch; 10h:54m:51s remains)
INFO - root - 2017-12-01 06:20:31.272855: step 85550, loss = 0.29, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 10h:32m:46s remains)
INFO - root - 2017-12-01 06:20:32.834762: step 85560, loss = 0.38, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 10h:41m:07s remains)
INFO - root - 2017-12-01 06:20:34.407320: step 85570, loss = 0.33, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 10h:45m:34s remains)
INFO - root - 2017-12-01 06:20:35.973333: step 85580, loss = 0.34, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 10h:50m:15s remains)
INFO - root - 2017-12-01 06:20:37.539486: step 85590, loss = 0.33, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 11h:05m:29s remains)
INFO - root - 2017-12-01 06:20:39.097551: step 85600, loss = 0.32, batch loss = 0.18 (52.1 examples/sec; 0.154 sec/batch; 10h:32m:01s remains)
INFO - root - 2017-12-01 06:20:40.712156: step 85610, loss = 0.44, batch loss = 0.30 (51.0 examples/sec; 0.157 sec/batch; 10h:45m:41s remains)
INFO - root - 2017-12-01 06:20:42.285260: step 85620, loss = 0.32, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 10h:37m:59s remains)
INFO - root - 2017-12-01 06:20:43.834857: step 85630, loss = 0.33, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 10h:42m:48s remains)
INFO - root - 2017-12-01 06:20:45.396736: step 85640, loss = 0.31, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 10h:34m:20s remains)
INFO - root - 2017-12-01 06:20:46.963415: step 85650, loss = 0.31, batch loss = 0.17 (50.8 examples/sec; 0.157 sec/batch; 10h:47m:32s remains)
INFO - root - 2017-12-01 06:20:48.548176: step 85660, loss = 0.36, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 10h:52m:49s remains)
INFO - root - 2017-12-01 06:20:50.104021: step 85670, loss = 0.34, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 10h:59m:28s remains)
INFO - root - 2017-12-01 06:20:51.665786: step 85680, loss = 0.35, batch loss = 0.22 (53.0 examples/sec; 0.151 sec/batch; 10h:21m:14s remains)
INFO - root - 2017-12-01 06:20:53.238449: step 85690, loss = 0.34, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 10h:28m:55s remains)
INFO - root - 2017-12-01 06:20:54.787661: step 85700, loss = 0.51, batch loss = 0.37 (49.8 examples/sec; 0.161 sec/batch; 11h:00m:34s remains)
INFO - root - 2017-12-01 06:20:56.399893: step 85710, loss = 0.37, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 10h:45m:26s remains)
INFO - root - 2017-12-01 06:20:57.963209: step 85720, loss = 0.43, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 10h:46m:06s remains)
INFO - root - 2017-12-01 06:20:59.505447: step 85730, loss = 0.35, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 10h:34m:18s remains)
INFO - root - 2017-12-01 06:21:01.068357: step 85740, loss = 0.34, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 10h:38m:14s remains)
INFO - root - 2017-12-01 06:21:02.636347: step 85750, loss = 0.40, batch loss = 0.27 (49.8 examples/sec; 0.161 sec/batch; 11h:00m:10s remains)
INFO - root - 2017-12-01 06:21:04.208884: step 85760, loss = 0.41, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 10h:51m:30s remains)
INFO - root - 2017-12-01 06:21:05.777102: step 85770, loss = 0.39, batch loss = 0.26 (50.1 examples/sec; 0.160 sec/batch; 10h:56m:56s remains)
INFO - root - 2017-12-01 06:21:07.337916: step 85780, loss = 0.35, batch loss = 0.21 (51.8 examples/sec; 0.155 sec/batch; 10h:35m:21s remains)
INFO - root - 2017-12-01 06:21:08.908526: step 85790, loss = 0.29, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 10h:36m:52s remains)
INFO - root - 2017-12-01 06:21:10.484669: step 85800, loss = 0.41, batch loss = 0.28 (50.3 examples/sec; 0.159 sec/batch; 10h:53m:35s remains)
INFO - root - 2017-12-01 06:21:12.136721: step 85810, loss = 0.39, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 10h:45m:27s remains)
INFO - root - 2017-12-01 06:21:13.709234: step 85820, loss = 0.33, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 10h:50m:01s remains)
INFO - root - 2017-12-01 06:21:15.299146: step 85830, loss = 0.36, batch loss = 0.23 (49.6 examples/sec; 0.161 sec/batch; 11h:03m:28s remains)
INFO - root - 2017-12-01 06:21:16.881040: step 85840, loss = 0.39, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 10h:49m:56s remains)
INFO - root - 2017-12-01 06:21:18.467848: step 85850, loss = 0.32, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 10h:48m:51s remains)
INFO - root - 2017-12-01 06:21:20.031540: step 85860, loss = 0.32, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 10h:53m:46s remains)
INFO - root - 2017-12-01 06:21:21.590115: step 85870, loss = 0.34, batch loss = 0.21 (52.8 examples/sec; 0.151 sec/batch; 10h:22m:37s remains)
INFO - root - 2017-12-01 06:21:23.153442: step 85880, loss = 0.35, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 10h:43m:19s remains)
INFO - root - 2017-12-01 06:21:24.705719: step 85890, loss = 0.46, batch loss = 0.32 (53.1 examples/sec; 0.151 sec/batch; 10h:18m:54s remains)
INFO - root - 2017-12-01 06:21:26.288943: step 85900, loss = 0.34, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 10h:25m:09s remains)
INFO - root - 2017-12-01 06:21:27.903676: step 85910, loss = 0.35, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 10h:37m:29s remains)
INFO - root - 2017-12-01 06:21:29.486274: step 85920, loss = 0.31, batch loss = 0.17 (51.8 examples/sec; 0.155 sec/batch; 10h:34m:59s remains)
INFO - root - 2017-12-01 06:21:31.041556: step 85930, loss = 0.37, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 10h:30m:01s remains)
INFO - root - 2017-12-01 06:21:32.603708: step 85940, loss = 0.37, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 10h:48m:56s remains)
INFO - root - 2017-12-01 06:21:34.158609: step 85950, loss = 0.35, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 10h:58m:01s remains)
INFO - root - 2017-12-01 06:21:35.723856: step 85960, loss = 0.36, batch loss = 0.23 (50.4 examples/sec; 0.159 sec/batch; 10h:51m:45s remains)
INFO - root - 2017-12-01 06:21:37.288496: step 85970, loss = 0.31, batch loss = 0.17 (52.9 examples/sec; 0.151 sec/batch; 10h:21m:52s remains)
INFO - root - 2017-12-01 06:21:38.860042: step 85980, loss = 0.38, batch loss = 0.25 (52.2 examples/sec; 0.153 sec/batch; 10h:29m:17s remains)
INFO - root - 2017-12-01 06:21:40.426966: step 85990, loss = 0.32, batch loss = 0.19 (50.1 examples/sec; 0.160 sec/batch; 10h:55m:43s remains)
INFO - root - 2017-12-01 06:21:41.998029: step 86000, loss = 0.32, batch loss = 0.18 (48.7 examples/sec; 0.164 sec/batch; 11h:14m:28s remains)
INFO - root - 2017-12-01 06:21:43.633931: step 86010, loss = 0.33, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 10h:45m:25s remains)
INFO - root - 2017-12-01 06:21:45.221765: step 86020, loss = 0.61, batch loss = 0.48 (49.9 examples/sec; 0.160 sec/batch; 10h:58m:02s remains)
INFO - root - 2017-12-01 06:21:46.778579: step 86030, loss = 0.31, batch loss = 0.18 (53.1 examples/sec; 0.151 sec/batch; 10h:19m:11s remains)
INFO - root - 2017-12-01 06:21:48.330417: step 86040, loss = 0.37, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 10h:35m:32s remains)
INFO - root - 2017-12-01 06:21:49.900393: step 86050, loss = 0.43, batch loss = 0.30 (50.6 examples/sec; 0.158 sec/batch; 10h:49m:51s remains)
INFO - root - 2017-12-01 06:21:51.467564: step 86060, loss = 0.35, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 10h:46m:10s remains)
INFO - root - 2017-12-01 06:21:53.031420: step 86070, loss = 0.42, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 10h:42m:01s remains)
INFO - root - 2017-12-01 06:21:54.609308: step 86080, loss = 0.28, batch loss = 0.15 (52.5 examples/sec; 0.152 sec/batch; 10h:25m:27s remains)
INFO - root - 2017-12-01 06:21:56.182633: step 86090, loss = 0.36, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 10h:41m:16s remains)
INFO - root - 2017-12-01 06:21:57.737855: step 86100, loss = 0.34, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 10h:47m:40s remains)
INFO - root - 2017-12-01 06:21:59.351566: step 86110, loss = 0.33, batch loss = 0.20 (48.9 examples/sec; 0.164 sec/batch; 11h:12m:04s remains)
INFO - root - 2017-12-01 06:22:00.939529: step 86120, loss = 0.29, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 10h:33m:10s remains)
INFO - root - 2017-12-01 06:22:02.507987: step 86130, loss = 0.57, batch loss = 0.44 (50.7 examples/sec; 0.158 sec/batch; 10h:47m:46s remains)
INFO - root - 2017-12-01 06:22:04.081973: step 86140, loss = 0.35, batch loss = 0.22 (50.5 examples/sec; 0.159 sec/batch; 10h:50m:59s remains)
INFO - root - 2017-12-01 06:22:05.655960: step 86150, loss = 0.36, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 10h:45m:39s remains)
INFO - root - 2017-12-01 06:22:07.224497: step 86160, loss = 0.42, batch loss = 0.29 (51.8 examples/sec; 0.154 sec/batch; 10h:33m:54s remains)
INFO - root - 2017-12-01 06:22:08.786338: step 86170, loss = 0.33, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 10h:38m:14s remains)
INFO - root - 2017-12-01 06:22:10.362519: step 86180, loss = 0.35, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 10h:50m:24s remains)
INFO - root - 2017-12-01 06:22:11.918793: step 86190, loss = 0.31, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 10h:41m:00s remains)
INFO - root - 2017-12-01 06:22:13.511862: step 86200, loss = 0.29, batch loss = 0.16 (49.9 examples/sec; 0.160 sec/batch; 10h:57m:33s remains)
INFO - root - 2017-12-01 06:22:15.139940: step 86210, loss = 0.31, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 10h:50m:00s remains)
INFO - root - 2017-12-01 06:22:16.703314: step 86220, loss = 0.33, batch loss = 0.20 (52.8 examples/sec; 0.151 sec/batch; 10h:21m:47s remains)
INFO - root - 2017-12-01 06:22:18.263045: step 86230, loss = 0.38, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 10h:33m:39s remains)
INFO - root - 2017-12-01 06:22:19.834223: step 86240, loss = 0.31, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 10h:45m:35s remains)
INFO - root - 2017-12-01 06:22:21.388142: step 86250, loss = 0.47, batch loss = 0.34 (50.3 examples/sec; 0.159 sec/batch; 10h:53m:08s remains)
INFO - root - 2017-12-01 06:22:22.960232: step 86260, loss = 0.35, batch loss = 0.22 (49.7 examples/sec; 0.161 sec/batch; 11h:00m:50s remains)
INFO - root - 2017-12-01 06:22:24.535283: step 86270, loss = 0.41, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 10h:39m:28s remains)
INFO - root - 2017-12-01 06:22:26.092108: step 86280, loss = 0.35, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 10h:48m:31s remains)
INFO - root - 2017-12-01 06:22:27.671572: step 86290, loss = 0.34, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 10h:48m:54s remains)
INFO - root - 2017-12-01 06:22:29.225024: step 86300, loss = 0.40, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 10h:43m:58s remains)
INFO - root - 2017-12-01 06:22:30.842791: step 86310, loss = 0.40, batch loss = 0.27 (51.8 examples/sec; 0.155 sec/batch; 10h:34m:10s remains)
INFO - root - 2017-12-01 06:22:32.398689: step 86320, loss = 0.31, batch loss = 0.18 (52.4 examples/sec; 0.153 sec/batch; 10h:25m:59s remains)
INFO - root - 2017-12-01 06:22:33.972088: step 86330, loss = 0.33, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 10h:42m:05s remains)
INFO - root - 2017-12-01 06:22:35.517352: step 86340, loss = 0.36, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 10h:51m:47s remains)
INFO - root - 2017-12-01 06:22:37.079060: step 86350, loss = 0.34, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 10h:24m:41s remains)
INFO - root - 2017-12-01 06:22:38.667205: step 86360, loss = 0.44, batch loss = 0.31 (47.8 examples/sec; 0.167 sec/batch; 11h:27m:00s remains)
INFO - root - 2017-12-01 06:22:40.268839: step 86370, loss = 0.29, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 10h:46m:58s remains)
INFO - root - 2017-12-01 06:22:41.826388: step 86380, loss = 0.37, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 10h:52m:12s remains)
INFO - root - 2017-12-01 06:22:43.375774: step 86390, loss = 0.43, batch loss = 0.29 (52.8 examples/sec; 0.152 sec/batch; 10h:21m:50s remains)
INFO - root - 2017-12-01 06:22:44.947106: step 86400, loss = 0.70, batch loss = 0.57 (52.6 examples/sec; 0.152 sec/batch; 10h:23m:30s remains)
INFO - root - 2017-12-01 06:22:46.554603: step 86410, loss = 0.28, batch loss = 0.15 (50.7 examples/sec; 0.158 sec/batch; 10h:46m:51s remains)
INFO - root - 2017-12-01 06:22:48.111992: step 86420, loss = 0.38, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 10h:31m:55s remains)
INFO - root - 2017-12-01 06:22:49.674143: step 86430, loss = 0.34, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 10h:35m:55s remains)
INFO - root - 2017-12-01 06:22:51.245019: step 86440, loss = 0.36, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 10h:41m:51s remains)
INFO - root - 2017-12-01 06:22:52.817500: step 86450, loss = 0.41, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 10h:30m:54s remains)
INFO - root - 2017-12-01 06:22:54.446908: step 86460, loss = 0.37, batch loss = 0.23 (52.9 examples/sec; 0.151 sec/batch; 10h:19m:43s remains)
INFO - root - 2017-12-01 06:22:56.018556: step 86470, loss = 0.37, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 10h:26m:20s remains)
INFO - root - 2017-12-01 06:22:57.591073: step 86480, loss = 0.30, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 10h:52m:13s remains)
INFO - root - 2017-12-01 06:22:59.134247: step 86490, loss = 0.37, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 10h:43m:41s remains)
INFO - root - 2017-12-01 06:23:00.697379: step 86500, loss = 0.31, batch loss = 0.18 (49.5 examples/sec; 0.162 sec/batch; 11h:02m:10s remains)
INFO - root - 2017-12-01 06:23:02.332366: step 86510, loss = 0.39, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 10h:36m:25s remains)
INFO - root - 2017-12-01 06:23:03.888156: step 86520, loss = 0.35, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 10h:45m:50s remains)
INFO - root - 2017-12-01 06:23:05.449494: step 86530, loss = 0.31, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 10h:52m:24s remains)
INFO - root - 2017-12-01 06:23:07.001490: step 86540, loss = 0.38, batch loss = 0.25 (52.4 examples/sec; 0.153 sec/batch; 10h:26m:14s remains)
INFO - root - 2017-12-01 06:23:08.571780: step 86550, loss = 0.34, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 10h:30m:26s remains)
INFO - root - 2017-12-01 06:23:10.142190: step 86560, loss = 0.35, batch loss = 0.22 (49.4 examples/sec; 0.162 sec/batch; 11h:03m:32s remains)
INFO - root - 2017-12-01 06:23:11.719066: step 86570, loss = 0.35, batch loss = 0.22 (48.7 examples/sec; 0.164 sec/batch; 11h:13m:50s remains)
INFO - root - 2017-12-01 06:23:13.275241: step 86580, loss = 0.41, batch loss = 0.28 (50.3 examples/sec; 0.159 sec/batch; 10h:51m:37s remains)
INFO - root - 2017-12-01 06:23:14.854746: step 86590, loss = 0.38, batch loss = 0.25 (49.5 examples/sec; 0.162 sec/batch; 11h:02m:40s remains)
INFO - root - 2017-12-01 06:23:16.414486: step 86600, loss = 0.33, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 10h:28m:40s remains)
INFO - root - 2017-12-01 06:23:18.022652: step 86610, loss = 0.36, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 10h:48m:35s remains)
INFO - root - 2017-12-01 06:23:19.587557: step 86620, loss = 0.49, batch loss = 0.35 (48.6 examples/sec; 0.165 sec/batch; 11h:14m:46s remains)
INFO - root - 2017-12-01 06:23:21.206642: step 86630, loss = 0.32, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 10h:38m:04s remains)
INFO - root - 2017-12-01 06:23:22.761708: step 86640, loss = 0.30, batch loss = 0.17 (50.2 examples/sec; 0.159 sec/batch; 10h:53m:08s remains)
INFO - root - 2017-12-01 06:23:24.321359: step 86650, loss = 0.37, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 10h:37m:20s remains)
INFO - root - 2017-12-01 06:23:25.904883: step 86660, loss = 0.30, batch loss = 0.16 (49.9 examples/sec; 0.160 sec/batch; 10h:57m:00s remains)
INFO - root - 2017-12-01 06:23:27.480537: step 86670, loss = 0.40, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 10h:51m:10s remains)
INFO - root - 2017-12-01 06:23:29.049480: step 86680, loss = 0.42, batch loss = 0.29 (50.8 examples/sec; 0.157 sec/batch; 10h:44m:34s remains)
INFO - root - 2017-12-01 06:23:30.592633: step 86690, loss = 0.31, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 10h:41m:14s remains)
INFO - root - 2017-12-01 06:23:32.147703: step 86700, loss = 0.35, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 10h:29m:54s remains)
INFO - root - 2017-12-01 06:23:33.774771: step 86710, loss = 0.32, batch loss = 0.19 (49.2 examples/sec; 0.163 sec/batch; 11h:06m:31s remains)
INFO - root - 2017-12-01 06:23:35.332358: step 86720, loss = 0.39, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 10h:37m:21s remains)
INFO - root - 2017-12-01 06:23:36.884199: step 86730, loss = 0.36, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 10h:23m:34s remains)
INFO - root - 2017-12-01 06:23:38.453182: step 86740, loss = 0.39, batch loss = 0.26 (52.9 examples/sec; 0.151 sec/batch; 10h:18m:54s remains)
INFO - root - 2017-12-01 06:23:40.015069: step 86750, loss = 0.37, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 10h:39m:20s remains)
INFO - root - 2017-12-01 06:23:41.567027: step 86760, loss = 0.37, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 10h:28m:12s remains)
INFO - root - 2017-12-01 06:23:43.129511: step 86770, loss = 0.32, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 10h:42m:36s remains)
INFO - root - 2017-12-01 06:23:44.705091: step 86780, loss = 0.33, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 10h:55m:32s remains)
INFO - root - 2017-12-01 06:23:46.270676: step 86790, loss = 0.38, batch loss = 0.24 (53.6 examples/sec; 0.149 sec/batch; 10h:11m:06s remains)
INFO - root - 2017-12-01 06:23:47.827059: step 86800, loss = 0.38, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 10h:23m:52s remains)
INFO - root - 2017-12-01 06:23:49.471815: step 86810, loss = 0.30, batch loss = 0.17 (49.2 examples/sec; 0.163 sec/batch; 11h:06m:19s remains)
INFO - root - 2017-12-01 06:23:51.049256: step 86820, loss = 0.35, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 10h:38m:04s remains)
INFO - root - 2017-12-01 06:23:52.599318: step 86830, loss = 0.41, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 10h:41m:37s remains)
INFO - root - 2017-12-01 06:23:54.161800: step 86840, loss = 0.29, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 10h:29m:46s remains)
INFO - root - 2017-12-01 06:23:55.742790: step 86850, loss = 0.35, batch loss = 0.22 (49.6 examples/sec; 0.161 sec/batch; 11h:00m:15s remains)
INFO - root - 2017-12-01 06:23:57.311616: step 86860, loss = 0.35, batch loss = 0.21 (48.4 examples/sec; 0.165 sec/batch; 11h:16m:44s remains)
INFO - root - 2017-12-01 06:23:58.885527: step 86870, loss = 0.31, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 10h:31m:07s remains)
INFO - root - 2017-12-01 06:24:00.475602: step 86880, loss = 0.32, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 10h:46m:23s remains)
INFO - root - 2017-12-01 06:24:02.032072: step 86890, loss = 0.45, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 10h:45m:23s remains)
INFO - root - 2017-12-01 06:24:03.591477: step 86900, loss = 0.41, batch loss = 0.27 (52.4 examples/sec; 0.153 sec/batch; 10h:25m:17s remains)
INFO - root - 2017-12-01 06:24:05.242589: step 86910, loss = 0.36, batch loss = 0.23 (49.3 examples/sec; 0.162 sec/batch; 11h:04m:34s remains)
INFO - root - 2017-12-01 06:24:06.802712: step 86920, loss = 0.35, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 10h:39m:11s remains)
INFO - root - 2017-12-01 06:24:08.386488: step 86930, loss = 0.34, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 10h:43m:31s remains)
INFO - root - 2017-12-01 06:24:09.997131: step 86940, loss = 0.33, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 10h:47m:40s remains)
INFO - root - 2017-12-01 06:24:11.593290: step 86950, loss = 0.37, batch loss = 0.23 (53.8 examples/sec; 0.149 sec/batch; 10h:08m:37s remains)
INFO - root - 2017-12-01 06:24:13.162191: step 86960, loss = 0.41, batch loss = 0.27 (51.8 examples/sec; 0.154 sec/batch; 10h:31m:44s remains)
INFO - root - 2017-12-01 06:24:14.765253: step 86970, loss = 0.37, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 10h:40m:24s remains)
INFO - root - 2017-12-01 06:24:16.320403: step 86980, loss = 0.30, batch loss = 0.16 (50.6 examples/sec; 0.158 sec/batch; 10h:46m:57s remains)
INFO - root - 2017-12-01 06:24:17.907659: step 86990, loss = 0.34, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 10h:53m:26s remains)
INFO - root - 2017-12-01 06:24:19.460536: step 87000, loss = 0.45, batch loss = 0.32 (52.1 examples/sec; 0.154 sec/batch; 10h:28m:28s remains)
INFO - root - 2017-12-01 06:24:21.103742: step 87010, loss = 0.31, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 10h:42m:25s remains)
INFO - root - 2017-12-01 06:24:22.671294: step 87020, loss = 0.34, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 10h:39m:31s remains)
INFO - root - 2017-12-01 06:24:24.220817: step 87030, loss = 0.56, batch loss = 0.42 (50.3 examples/sec; 0.159 sec/batch; 10h:50m:17s remains)
INFO - root - 2017-12-01 06:24:25.824570: step 87040, loss = 0.33, batch loss = 0.20 (43.2 examples/sec; 0.185 sec/batch; 12h:37m:19s remains)
INFO - root - 2017-12-01 06:24:27.396977: step 87050, loss = 0.40, batch loss = 0.26 (50.2 examples/sec; 0.159 sec/batch; 10h:51m:42s remains)
INFO - root - 2017-12-01 06:24:28.965885: step 87060, loss = 0.34, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 10h:46m:40s remains)
INFO - root - 2017-12-01 06:24:30.528977: step 87070, loss = 0.38, batch loss = 0.25 (52.0 examples/sec; 0.154 sec/batch; 10h:29m:23s remains)
INFO - root - 2017-12-01 06:24:32.094032: step 87080, loss = 0.36, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 10h:47m:06s remains)
INFO - root - 2017-12-01 06:24:33.654853: step 87090, loss = 0.27, batch loss = 0.14 (51.6 examples/sec; 0.155 sec/batch; 10h:33m:40s remains)
INFO - root - 2017-12-01 06:24:35.217345: step 87100, loss = 0.35, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 10h:39m:01s remains)
INFO - root - 2017-12-01 06:24:36.864204: step 87110, loss = 0.33, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 10h:40m:37s remains)
INFO - root - 2017-12-01 06:24:38.430545: step 87120, loss = 0.34, batch loss = 0.20 (48.8 examples/sec; 0.164 sec/batch; 11h:10m:35s remains)
INFO - root - 2017-12-01 06:24:40.007868: step 87130, loss = 0.31, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 10h:45m:49s remains)
INFO - root - 2017-12-01 06:24:41.607620: step 87140, loss = 0.46, batch loss = 0.33 (50.0 examples/sec; 0.160 sec/batch; 10h:54m:38s remains)
INFO - root - 2017-12-01 06:24:43.166129: step 87150, loss = 0.34, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 10h:46m:07s remains)
INFO - root - 2017-12-01 06:24:44.718079: step 87160, loss = 0.37, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 10h:29m:32s remains)
INFO - root - 2017-12-01 06:24:46.288723: step 87170, loss = 0.33, batch loss = 0.19 (53.6 examples/sec; 0.149 sec/batch; 10h:10m:18s remains)
INFO - root - 2017-12-01 06:24:47.877163: step 87180, loss = 0.47, batch loss = 0.34 (50.5 examples/sec; 0.158 sec/batch; 10h:47m:42s remains)
INFO - root - 2017-12-01 06:24:49.444464: step 87190, loss = 0.33, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 10h:42m:28s remains)
INFO - root - 2017-12-01 06:24:51.020930: step 87200, loss = 0.40, batch loss = 0.27 (47.7 examples/sec; 0.168 sec/batch; 11h:26m:17s remains)
INFO - root - 2017-12-01 06:24:52.689163: step 87210, loss = 0.31, batch loss = 0.18 (50.0 examples/sec; 0.160 sec/batch; 10h:54m:07s remains)
INFO - root - 2017-12-01 06:24:54.245583: step 87220, loss = 0.33, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 10h:38m:47s remains)
INFO - root - 2017-12-01 06:24:55.821439: step 87230, loss = 0.34, batch loss = 0.21 (46.4 examples/sec; 0.173 sec/batch; 11h:45m:25s remains)
INFO - root - 2017-12-01 06:24:57.389387: step 87240, loss = 0.38, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 10h:25m:05s remains)
INFO - root - 2017-12-01 06:24:58.954185: step 87250, loss = 0.32, batch loss = 0.18 (49.4 examples/sec; 0.162 sec/batch; 11h:02m:36s remains)
INFO - root - 2017-12-01 06:25:00.524464: step 87260, loss = 0.31, batch loss = 0.18 (49.9 examples/sec; 0.160 sec/batch; 10h:55m:11s remains)
INFO - root - 2017-12-01 06:25:02.094036: step 87270, loss = 0.32, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 10h:43m:07s remains)
INFO - root - 2017-12-01 06:25:03.677043: step 87280, loss = 0.35, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 10h:34m:36s remains)
INFO - root - 2017-12-01 06:25:05.246208: step 87290, loss = 0.36, batch loss = 0.23 (50.4 examples/sec; 0.159 sec/batch; 10h:49m:05s remains)
INFO - root - 2017-12-01 06:25:06.812388: step 87300, loss = 0.30, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 10h:41m:05s remains)
INFO - root - 2017-12-01 06:25:08.464550: step 87310, loss = 0.32, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 10h:40m:36s remains)
INFO - root - 2017-12-01 06:25:10.022860: step 87320, loss = 0.37, batch loss = 0.24 (50.0 examples/sec; 0.160 sec/batch; 10h:54m:03s remains)
INFO - root - 2017-12-01 06:25:11.589584: step 87330, loss = 0.31, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 10h:34m:09s remains)
INFO - root - 2017-12-01 06:25:13.142145: step 87340, loss = 0.31, batch loss = 0.18 (52.5 examples/sec; 0.152 sec/batch; 10h:23m:03s remains)
INFO - root - 2017-12-01 06:25:14.710006: step 87350, loss = 0.36, batch loss = 0.23 (49.4 examples/sec; 0.162 sec/batch; 11h:01m:17s remains)
INFO - root - 2017-12-01 06:25:16.283314: step 87360, loss = 0.33, batch loss = 0.20 (49.8 examples/sec; 0.161 sec/batch; 10h:56m:23s remains)
INFO - root - 2017-12-01 06:25:17.855278: step 87370, loss = 0.44, batch loss = 0.31 (48.0 examples/sec; 0.167 sec/batch; 11h:20m:49s remains)
INFO - root - 2017-12-01 06:25:19.427439: step 87380, loss = 0.31, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 10h:34m:46s remains)
INFO - root - 2017-12-01 06:25:20.989732: step 87390, loss = 0.36, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 10h:43m:51s remains)
INFO - root - 2017-12-01 06:25:22.542517: step 87400, loss = 0.38, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 10h:32m:37s remains)
INFO - root - 2017-12-01 06:25:24.139426: step 87410, loss = 0.32, batch loss = 0.18 (51.8 examples/sec; 0.155 sec/batch; 10h:31m:13s remains)
INFO - root - 2017-12-01 06:25:25.711661: step 87420, loss = 0.29, batch loss = 0.16 (50.0 examples/sec; 0.160 sec/batch; 10h:53m:15s remains)
INFO - root - 2017-12-01 06:25:27.269527: step 87430, loss = 0.31, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 10h:28m:14s remains)
INFO - root - 2017-12-01 06:25:28.870155: step 87440, loss = 0.42, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 10h:42m:19s remains)
INFO - root - 2017-12-01 06:25:30.421766: step 87450, loss = 0.40, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 10h:49m:15s remains)
INFO - root - 2017-12-01 06:25:31.986350: step 87460, loss = 0.32, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 10h:51m:21s remains)
INFO - root - 2017-12-01 06:25:33.550667: step 87470, loss = 0.31, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 10h:31m:36s remains)
INFO - root - 2017-12-01 06:25:35.107231: step 87480, loss = 0.41, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 10h:40m:54s remains)
INFO - root - 2017-12-01 06:25:36.689380: step 87490, loss = 0.34, batch loss = 0.21 (50.0 examples/sec; 0.160 sec/batch; 10h:53m:16s remains)
INFO - root - 2017-12-01 06:25:38.244916: step 87500, loss = 0.33, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 10h:44m:44s remains)
INFO - root - 2017-12-01 06:25:39.898298: step 87510, loss = 0.44, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 10h:41m:31s remains)
INFO - root - 2017-12-01 06:25:41.450621: step 87520, loss = 0.35, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 10h:34m:39s remains)
INFO - root - 2017-12-01 06:25:43.002838: step 87530, loss = 0.37, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 10h:30m:10s remains)
INFO - root - 2017-12-01 06:25:44.556425: step 87540, loss = 0.33, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 10h:28m:15s remains)
INFO - root - 2017-12-01 06:25:46.136276: step 87550, loss = 0.33, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 10h:36m:32s remains)
INFO - root - 2017-12-01 06:25:47.694584: step 87560, loss = 0.32, batch loss = 0.19 (52.1 examples/sec; 0.154 sec/batch; 10h:26m:46s remains)
INFO - root - 2017-12-01 06:25:49.273467: step 87570, loss = 0.34, batch loss = 0.21 (51.1 examples/sec; 0.156 sec/batch; 10h:38m:34s remains)
INFO - root - 2017-12-01 06:25:50.822912: step 87580, loss = 0.40, batch loss = 0.27 (50.4 examples/sec; 0.159 sec/batch; 10h:48m:04s remains)
INFO - root - 2017-12-01 06:25:52.382330: step 87590, loss = 0.38, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 10h:34m:13s remains)
INFO - root - 2017-12-01 06:25:53.966382: step 87600, loss = 0.36, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 10h:40m:30s remains)
INFO - root - 2017-12-01 06:25:55.617340: step 87610, loss = 0.33, batch loss = 0.19 (49.2 examples/sec; 0.163 sec/batch; 11h:04m:19s remains)
INFO - root - 2017-12-01 06:25:57.199045: step 87620, loss = 0.40, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 10h:35m:22s remains)
INFO - root - 2017-12-01 06:25:58.764214: step 87630, loss = 0.54, batch loss = 0.40 (52.1 examples/sec; 0.154 sec/batch; 10h:26m:50s remains)
INFO - root - 2017-12-01 06:26:00.348683: step 87640, loss = 0.40, batch loss = 0.27 (49.6 examples/sec; 0.161 sec/batch; 10h:57m:51s remains)
INFO - root - 2017-12-01 06:26:01.910752: step 87650, loss = 0.35, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 10h:34m:54s remains)
INFO - root - 2017-12-01 06:26:03.497495: step 87660, loss = 0.34, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 10h:32m:12s remains)
INFO - root - 2017-12-01 06:26:05.047592: step 87670, loss = 0.29, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 10h:36m:23s remains)
INFO - root - 2017-12-01 06:26:06.620147: step 87680, loss = 0.38, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 10h:41m:39s remains)
INFO - root - 2017-12-01 06:26:08.181623: step 87690, loss = 0.32, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 10h:36m:14s remains)
INFO - root - 2017-12-01 06:26:09.738330: step 87700, loss = 0.36, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 10h:35m:13s remains)
INFO - root - 2017-12-01 06:26:11.359458: step 87710, loss = 0.32, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 10h:34m:32s remains)
INFO - root - 2017-12-01 06:26:12.921127: step 87720, loss = 0.47, batch loss = 0.34 (49.0 examples/sec; 0.163 sec/batch; 11h:06m:11s remains)
INFO - root - 2017-12-01 06:26:14.480612: step 87730, loss = 0.32, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 10h:29m:59s remains)
INFO - root - 2017-12-01 06:26:16.042707: step 87740, loss = 0.33, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 10h:38m:47s remains)
INFO - root - 2017-12-01 06:26:17.640893: step 87750, loss = 0.29, batch loss = 0.16 (51.7 examples/sec; 0.155 sec/batch; 10h:31m:08s remains)
INFO - root - 2017-12-01 06:26:19.194937: step 87760, loss = 0.36, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 10h:34m:58s remains)
INFO - root - 2017-12-01 06:26:20.757495: step 87770, loss = 0.34, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 10h:49m:05s remains)
INFO - root - 2017-12-01 06:26:22.298361: step 87780, loss = 0.41, batch loss = 0.28 (52.1 examples/sec; 0.154 sec/batch; 10h:26m:32s remains)
INFO - root - 2017-12-01 06:26:23.875103: step 87790, loss = 0.36, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 10h:24m:03s remains)
INFO - root - 2017-12-01 06:26:25.471904: step 87800, loss = 0.37, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 10h:54m:15s remains)
INFO - root - 2017-12-01 06:26:27.116571: step 87810, loss = 0.41, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 10h:29m:02s remains)
INFO - root - 2017-12-01 06:26:28.694120: step 87820, loss = 0.41, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 10h:35m:34s remains)
INFO - root - 2017-12-01 06:26:30.275218: step 87830, loss = 0.35, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 10h:46m:02s remains)
INFO - root - 2017-12-01 06:26:31.822162: step 87840, loss = 0.40, batch loss = 0.27 (52.8 examples/sec; 0.151 sec/batch; 10h:17m:34s remains)
INFO - root - 2017-12-01 06:26:33.391938: step 87850, loss = 0.32, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 10h:29m:53s remains)
INFO - root - 2017-12-01 06:26:34.956607: step 87860, loss = 0.35, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 10h:25m:53s remains)
INFO - root - 2017-12-01 06:26:36.520908: step 87870, loss = 0.38, batch loss = 0.25 (50.5 examples/sec; 0.158 sec/batch; 10h:46m:03s remains)
INFO - root - 2017-12-01 06:26:38.074657: step 87880, loss = 0.43, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 10h:34m:33s remains)
INFO - root - 2017-12-01 06:26:39.650353: step 87890, loss = 0.37, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 10h:33m:28s remains)
INFO - root - 2017-12-01 06:26:41.213932: step 87900, loss = 0.40, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 10h:37m:10s remains)
INFO - root - 2017-12-01 06:26:42.855791: step 87910, loss = 0.45, batch loss = 0.32 (50.5 examples/sec; 0.158 sec/batch; 10h:45m:43s remains)
INFO - root - 2017-12-01 06:26:44.417618: step 87920, loss = 0.38, batch loss = 0.24 (52.9 examples/sec; 0.151 sec/batch; 10h:16m:54s remains)
INFO - root - 2017-12-01 06:26:45.982593: step 87930, loss = 0.35, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 10h:40m:00s remains)
INFO - root - 2017-12-01 06:26:47.551840: step 87940, loss = 0.38, batch loss = 0.25 (50.2 examples/sec; 0.159 sec/batch; 10h:49m:08s remains)
INFO - root - 2017-12-01 06:26:49.105301: step 87950, loss = 0.32, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 10h:44m:09s remains)
INFO - root - 2017-12-01 06:26:50.672449: step 87960, loss = 0.36, batch loss = 0.22 (49.5 examples/sec; 0.162 sec/batch; 10h:58m:55s remains)
INFO - root - 2017-12-01 06:26:52.231660: step 87970, loss = 0.30, batch loss = 0.17 (52.3 examples/sec; 0.153 sec/batch; 10h:22m:58s remains)
INFO - root - 2017-12-01 06:26:53.788821: step 87980, loss = 0.34, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 10h:24m:03s remains)
INFO - root - 2017-12-01 06:26:55.372088: step 87990, loss = 0.33, batch loss = 0.20 (49.8 examples/sec; 0.161 sec/batch; 10h:55m:12s remains)
INFO - root - 2017-12-01 06:26:56.922509: step 88000, loss = 0.29, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 10h:28m:19s remains)
INFO - root - 2017-12-01 06:26:58.510634: step 88010, loss = 0.39, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 10h:32m:40s remains)
INFO - root - 2017-12-01 06:27:00.072614: step 88020, loss = 0.36, batch loss = 0.23 (53.8 examples/sec; 0.149 sec/batch; 10h:06m:16s remains)
INFO - root - 2017-12-01 06:27:01.665807: step 88030, loss = 0.43, batch loss = 0.30 (51.1 examples/sec; 0.156 sec/batch; 10h:37m:34s remains)
INFO - root - 2017-12-01 06:27:03.254403: step 88040, loss = 0.31, batch loss = 0.17 (48.9 examples/sec; 0.163 sec/batch; 11h:05m:56s remains)
INFO - root - 2017-12-01 06:27:04.839540: step 88050, loss = 0.36, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 10h:30m:46s remains)
INFO - root - 2017-12-01 06:27:06.393778: step 88060, loss = 0.36, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 10h:27m:18s remains)
INFO - root - 2017-12-01 06:27:07.957760: step 88070, loss = 0.33, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 10h:28m:42s remains)
INFO - root - 2017-12-01 06:27:09.524468: step 88080, loss = 0.34, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 10h:48m:38s remains)
INFO - root - 2017-12-01 06:27:11.107323: step 88090, loss = 0.38, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 10h:30m:45s remains)
INFO - root - 2017-12-01 06:27:12.658204: step 88100, loss = 0.34, batch loss = 0.20 (53.2 examples/sec; 0.150 sec/batch; 10h:12m:15s remains)
INFO - root - 2017-12-01 06:27:14.287835: step 88110, loss = 0.39, batch loss = 0.25 (49.0 examples/sec; 0.163 sec/batch; 11h:05m:39s remains)
INFO - root - 2017-12-01 06:27:15.856756: step 88120, loss = 0.33, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 10h:51m:46s remains)
INFO - root - 2017-12-01 06:27:17.430853: step 88130, loss = 0.32, batch loss = 0.19 (49.4 examples/sec; 0.162 sec/batch; 10h:59m:47s remains)
INFO - root - 2017-12-01 06:27:18.992297: step 88140, loss = 0.28, batch loss = 0.15 (51.0 examples/sec; 0.157 sec/batch; 10h:39m:27s remains)
INFO - root - 2017-12-01 06:27:20.571715: step 88150, loss = 0.42, batch loss = 0.28 (50.1 examples/sec; 0.160 sec/batch; 10h:49m:47s remains)
INFO - root - 2017-12-01 06:27:22.137895: step 88160, loss = 0.36, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 10h:36m:36s remains)
INFO - root - 2017-12-01 06:27:23.695231: step 88170, loss = 0.40, batch loss = 0.27 (52.6 examples/sec; 0.152 sec/batch; 10h:18m:48s remains)
INFO - root - 2017-12-01 06:27:25.261569: step 88180, loss = 0.32, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 10h:41m:15s remains)
INFO - root - 2017-12-01 06:27:26.841498: step 88190, loss = 0.33, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 10h:33m:15s remains)
INFO - root - 2017-12-01 06:27:28.391284: step 88200, loss = 0.46, batch loss = 0.32 (50.1 examples/sec; 0.160 sec/batch; 10h:50m:04s remains)
INFO - root - 2017-12-01 06:27:30.040847: step 88210, loss = 0.32, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 10h:42m:55s remains)
INFO - root - 2017-12-01 06:27:31.601475: step 88220, loss = 0.30, batch loss = 0.17 (50.7 examples/sec; 0.158 sec/batch; 10h:42m:17s remains)
INFO - root - 2017-12-01 06:27:33.164332: step 88230, loss = 0.37, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 10h:38m:20s remains)
INFO - root - 2017-12-01 06:27:34.722323: step 88240, loss = 0.31, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 10h:28m:40s remains)
INFO - root - 2017-12-01 06:27:36.292819: step 88250, loss = 0.32, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 10h:28m:04s remains)
INFO - root - 2017-12-01 06:27:37.844412: step 88260, loss = 0.44, batch loss = 0.30 (51.8 examples/sec; 0.155 sec/batch; 10h:28m:57s remains)
INFO - root - 2017-12-01 06:27:39.408122: step 88270, loss = 0.34, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 10h:40m:54s remains)
INFO - root - 2017-12-01 06:27:40.975164: step 88280, loss = 0.50, batch loss = 0.37 (50.1 examples/sec; 0.160 sec/batch; 10h:49m:59s remains)
INFO - root - 2017-12-01 06:27:42.537666: step 88290, loss = 0.31, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 10h:38m:25s remains)
INFO - root - 2017-12-01 06:27:44.103807: step 88300, loss = 0.33, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 10h:32m:15s remains)
INFO - root - 2017-12-01 06:27:45.732551: step 88310, loss = 0.34, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 10h:46m:39s remains)
INFO - root - 2017-12-01 06:27:47.303489: step 88320, loss = 0.36, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 10h:44m:23s remains)
INFO - root - 2017-12-01 06:27:48.856938: step 88330, loss = 0.33, batch loss = 0.20 (53.1 examples/sec; 0.151 sec/batch; 10h:12m:34s remains)
INFO - root - 2017-12-01 06:27:50.447029: step 88340, loss = 0.30, batch loss = 0.16 (50.8 examples/sec; 0.158 sec/batch; 10h:41m:27s remains)
INFO - root - 2017-12-01 06:27:52.008090: step 88350, loss = 0.37, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 10h:45m:43s remains)
INFO - root - 2017-12-01 06:27:53.545663: step 88360, loss = 0.30, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 10h:31m:52s remains)
INFO - root - 2017-12-01 06:27:55.099657: step 88370, loss = 0.29, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 10h:34m:07s remains)
INFO - root - 2017-12-01 06:27:56.673981: step 88380, loss = 0.63, batch loss = 0.50 (52.4 examples/sec; 0.153 sec/batch; 10h:21m:06s remains)
INFO - root - 2017-12-01 06:27:58.237540: step 88390, loss = 0.45, batch loss = 0.31 (51.9 examples/sec; 0.154 sec/batch; 10h:27m:30s remains)
INFO - root - 2017-12-01 06:27:59.804002: step 88400, loss = 0.30, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 10h:36m:06s remains)
INFO - root - 2017-12-01 06:28:01.415895: step 88410, loss = 0.35, batch loss = 0.22 (53.0 examples/sec; 0.151 sec/batch; 10h:14m:10s remains)
INFO - root - 2017-12-01 06:28:02.968050: step 88420, loss = 0.36, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 10h:22m:58s remains)
INFO - root - 2017-12-01 06:28:04.548860: step 88430, loss = 0.32, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 10h:27m:59s remains)
INFO - root - 2017-12-01 06:28:06.104477: step 88440, loss = 0.27, batch loss = 0.14 (51.4 examples/sec; 0.156 sec/batch; 10h:32m:54s remains)
INFO - root - 2017-12-01 06:28:07.657656: step 88450, loss = 0.34, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 10h:41m:43s remains)
INFO - root - 2017-12-01 06:28:09.227917: step 88460, loss = 0.29, batch loss = 0.16 (49.0 examples/sec; 0.163 sec/batch; 11h:04m:13s remains)
INFO - root - 2017-12-01 06:28:10.789431: step 88470, loss = 0.29, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 10h:25m:20s remains)
INFO - root - 2017-12-01 06:28:12.367807: step 88480, loss = 0.39, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 10h:29m:30s remains)
INFO - root - 2017-12-01 06:28:13.952112: step 88490, loss = 0.29, batch loss = 0.16 (51.0 examples/sec; 0.157 sec/batch; 10h:37m:55s remains)
INFO - root - 2017-12-01 06:28:15.504987: step 88500, loss = 0.29, batch loss = 0.15 (50.1 examples/sec; 0.160 sec/batch; 10h:49m:08s remains)
INFO - root - 2017-12-01 06:28:17.126404: step 88510, loss = 0.43, batch loss = 0.30 (51.1 examples/sec; 0.157 sec/batch; 10h:36m:32s remains)
INFO - root - 2017-12-01 06:28:18.703327: step 88520, loss = 0.31, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 10h:40m:08s remains)
INFO - root - 2017-12-01 06:28:20.257749: step 88530, loss = 0.33, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 10h:23m:00s remains)
INFO - root - 2017-12-01 06:28:21.825735: step 88540, loss = 0.32, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 10h:50m:05s remains)
INFO - root - 2017-12-01 06:28:23.393847: step 88550, loss = 0.36, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 10h:52m:02s remains)
INFO - root - 2017-12-01 06:28:24.953469: step 88560, loss = 0.44, batch loss = 0.31 (51.8 examples/sec; 0.154 sec/batch; 10h:27m:44s remains)
INFO - root - 2017-12-01 06:28:26.531996: step 88570, loss = 0.43, batch loss = 0.30 (49.9 examples/sec; 0.160 sec/batch; 10h:51m:37s remains)
INFO - root - 2017-12-01 06:28:28.079216: step 88580, loss = 0.55, batch loss = 0.42 (52.6 examples/sec; 0.152 sec/batch; 10h:18m:33s remains)
INFO - root - 2017-12-01 06:28:29.660115: step 88590, loss = 0.38, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 10h:32m:43s remains)
INFO - root - 2017-12-01 06:28:31.217050: step 88600, loss = 0.41, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 10h:26m:52s remains)
INFO - root - 2017-12-01 06:28:32.867067: step 88610, loss = 0.34, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 10h:38m:27s remains)
INFO - root - 2017-12-01 06:28:34.428941: step 88620, loss = 0.31, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 10h:33m:20s remains)
INFO - root - 2017-12-01 06:28:35.997538: step 88630, loss = 0.48, batch loss = 0.35 (51.7 examples/sec; 0.155 sec/batch; 10h:29m:00s remains)
INFO - root - 2017-12-01 06:28:37.577655: step 88640, loss = 0.36, batch loss = 0.23 (49.0 examples/sec; 0.163 sec/batch; 11h:03m:24s remains)
INFO - root - 2017-12-01 06:28:39.136401: step 88650, loss = 0.28, batch loss = 0.15 (50.1 examples/sec; 0.160 sec/batch; 10h:48m:29s remains)
INFO - root - 2017-12-01 06:28:40.722918: step 88660, loss = 0.38, batch loss = 0.25 (49.1 examples/sec; 0.163 sec/batch; 11h:01m:52s remains)
INFO - root - 2017-12-01 06:28:42.283282: step 88670, loss = 0.38, batch loss = 0.25 (50.5 examples/sec; 0.158 sec/batch; 10h:43m:59s remains)
INFO - root - 2017-12-01 06:28:43.843430: step 88680, loss = 0.31, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 10h:36m:14s remains)
INFO - root - 2017-12-01 06:28:45.384442: step 88690, loss = 0.35, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 10h:31m:08s remains)
INFO - root - 2017-12-01 06:28:46.947166: step 88700, loss = 0.38, batch loss = 0.24 (50.0 examples/sec; 0.160 sec/batch; 10h:50m:10s remains)
INFO - root - 2017-12-01 06:28:48.558422: step 88710, loss = 0.39, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 10h:22m:31s remains)
INFO - root - 2017-12-01 06:28:50.115143: step 88720, loss = 0.38, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 10h:29m:31s remains)
INFO - root - 2017-12-01 06:28:51.662810: step 88730, loss = 0.37, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 10h:42m:25s remains)
INFO - root - 2017-12-01 06:28:53.212479: step 88740, loss = 0.41, batch loss = 0.28 (50.0 examples/sec; 0.160 sec/batch; 10h:49m:40s remains)
INFO - root - 2017-12-01 06:28:54.769979: step 88750, loss = 0.32, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 10h:23m:03s remains)
INFO - root - 2017-12-01 06:28:56.332348: step 88760, loss = 0.34, batch loss = 0.21 (53.3 examples/sec; 0.150 sec/batch; 10h:09m:45s remains)
INFO - root - 2017-12-01 06:28:57.900323: step 88770, loss = 0.34, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 10h:37m:25s remains)
INFO - root - 2017-12-01 06:28:59.467112: step 88780, loss = 0.32, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 10h:40m:00s remains)
INFO - root - 2017-12-01 06:29:01.044546: step 88790, loss = 0.38, batch loss = 0.25 (50.0 examples/sec; 0.160 sec/batch; 10h:49m:14s remains)
INFO - root - 2017-12-01 06:29:02.613922: step 88800, loss = 0.33, batch loss = 0.20 (48.4 examples/sec; 0.165 sec/batch; 11h:11m:42s remains)
INFO - root - 2017-12-01 06:29:04.249914: step 88810, loss = 0.32, batch loss = 0.18 (50.1 examples/sec; 0.160 sec/batch; 10h:48m:54s remains)
INFO - root - 2017-12-01 06:29:05.808323: step 88820, loss = 0.52, batch loss = 0.39 (52.1 examples/sec; 0.153 sec/batch; 10h:23m:23s remains)
INFO - root - 2017-12-01 06:29:07.355673: step 88830, loss = 0.31, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 10h:33m:22s remains)
INFO - root - 2017-12-01 06:29:08.916215: step 88840, loss = 0.34, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 10h:22m:55s remains)
INFO - root - 2017-12-01 06:29:10.490949: step 88850, loss = 0.31, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 10h:21m:23s remains)
INFO - root - 2017-12-01 06:29:12.060471: step 88860, loss = 0.35, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 10h:31m:37s remains)
INFO - root - 2017-12-01 06:29:13.645587: step 88870, loss = 0.31, batch loss = 0.18 (53.4 examples/sec; 0.150 sec/batch; 10h:08m:50s remains)
INFO - root - 2017-12-01 06:29:15.197803: step 88880, loss = 0.34, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 10h:23m:33s remains)
INFO - root - 2017-12-01 06:29:16.767199: step 88890, loss = 0.32, batch loss = 0.19 (50.3 examples/sec; 0.159 sec/batch; 10h:46m:16s remains)
INFO - root - 2017-12-01 06:29:18.340685: step 88900, loss = 0.47, batch loss = 0.34 (49.6 examples/sec; 0.161 sec/batch; 10h:54m:28s remains)
INFO - root - 2017-12-01 06:29:19.961642: step 88910, loss = 0.30, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 10h:28m:07s remains)
INFO - root - 2017-12-01 06:29:21.550039: step 88920, loss = 0.32, batch loss = 0.19 (51.8 examples/sec; 0.155 sec/batch; 10h:27m:22s remains)
INFO - root - 2017-12-01 06:29:23.105286: step 88930, loss = 0.35, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 10h:34m:10s remains)
INFO - root - 2017-12-01 06:29:24.669449: step 88940, loss = 0.32, batch loss = 0.19 (48.5 examples/sec; 0.165 sec/batch; 11h:09m:09s remains)
INFO - root - 2017-12-01 06:29:26.248619: step 88950, loss = 0.35, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 10h:31m:20s remains)
INFO - root - 2017-12-01 06:29:27.801615: step 88960, loss = 0.36, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 10h:24m:03s remains)
INFO - root - 2017-12-01 06:29:29.376271: step 88970, loss = 0.40, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 10h:36m:42s remains)
INFO - root - 2017-12-01 06:29:30.955812: step 88980, loss = 0.31, batch loss = 0.18 (48.8 examples/sec; 0.164 sec/batch; 11h:05m:01s remains)
INFO - root - 2017-12-01 06:29:32.501281: step 88990, loss = 0.29, batch loss = 0.16 (53.6 examples/sec; 0.149 sec/batch; 10h:06m:00s remains)
INFO - root - 2017-12-01 06:29:34.072544: step 89000, loss = 0.38, batch loss = 0.25 (52.6 examples/sec; 0.152 sec/batch; 10h:16m:42s remains)
INFO - root - 2017-12-01 06:29:35.773177: step 89010, loss = 0.40, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 10h:22m:21s remains)
INFO - root - 2017-12-01 06:29:37.336152: step 89020, loss = 0.29, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 10h:44m:30s remains)
INFO - root - 2017-12-01 06:29:38.965190: step 89030, loss = 0.34, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 10h:18m:30s remains)
INFO - root - 2017-12-01 06:29:40.539525: step 89040, loss = 0.32, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 10h:37m:17s remains)
INFO - root - 2017-12-01 06:29:42.132627: step 89050, loss = 0.32, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 10h:29m:55s remains)
INFO - root - 2017-12-01 06:29:43.692483: step 89060, loss = 0.31, batch loss = 0.18 (48.8 examples/sec; 0.164 sec/batch; 11h:04m:49s remains)
INFO - root - 2017-12-01 06:29:45.246641: step 89070, loss = 0.53, batch loss = 0.40 (48.7 examples/sec; 0.164 sec/batch; 11h:06m:40s remains)
INFO - root - 2017-12-01 06:29:46.813713: step 89080, loss = 0.32, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 10h:16m:38s remains)
INFO - root - 2017-12-01 06:29:48.382453: step 89090, loss = 0.39, batch loss = 0.26 (52.9 examples/sec; 0.151 sec/batch; 10h:13m:18s remains)
INFO - root - 2017-12-01 06:29:49.938356: step 89100, loss = 0.44, batch loss = 0.30 (50.6 examples/sec; 0.158 sec/batch; 10h:40m:49s remains)
INFO - root - 2017-12-01 06:29:51.583478: step 89110, loss = 0.26, batch loss = 0.13 (51.7 examples/sec; 0.155 sec/batch; 10h:28m:00s remains)
INFO - root - 2017-12-01 06:29:53.142668: step 89120, loss = 0.44, batch loss = 0.31 (51.1 examples/sec; 0.157 sec/batch; 10h:35m:22s remains)
INFO - root - 2017-12-01 06:29:54.724311: step 89130, loss = 0.29, batch loss = 0.16 (50.5 examples/sec; 0.158 sec/batch; 10h:42m:33s remains)
INFO - root - 2017-12-01 06:29:56.295555: step 89140, loss = 0.35, batch loss = 0.22 (51.1 examples/sec; 0.156 sec/batch; 10h:34m:34s remains)
INFO - root - 2017-12-01 06:29:57.864929: step 89150, loss = 0.58, batch loss = 0.45 (51.1 examples/sec; 0.157 sec/batch; 10h:35m:27s remains)
INFO - root - 2017-12-01 06:29:59.430995: step 89160, loss = 0.30, batch loss = 0.17 (52.1 examples/sec; 0.153 sec/batch; 10h:22m:16s remains)
INFO - root - 2017-12-01 06:30:01.000487: step 89170, loss = 0.56, batch loss = 0.43 (52.0 examples/sec; 0.154 sec/batch; 10h:24m:14s remains)
INFO - root - 2017-12-01 06:30:02.586185: step 89180, loss = 0.32, batch loss = 0.19 (46.7 examples/sec; 0.171 sec/batch; 11h:34m:27s remains)
INFO - root - 2017-12-01 06:30:04.156768: step 89190, loss = 0.34, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 10h:46m:46s remains)
INFO - root - 2017-12-01 06:30:05.752665: step 89200, loss = 0.27, batch loss = 0.13 (49.2 examples/sec; 0.162 sec/batch; 10h:58m:51s remains)
INFO - root - 2017-12-01 06:30:07.391995: step 89210, loss = 0.33, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 10h:32m:47s remains)
INFO - root - 2017-12-01 06:30:08.964646: step 89220, loss = 0.42, batch loss = 0.29 (50.4 examples/sec; 0.159 sec/batch; 10h:43m:47s remains)
INFO - root - 2017-12-01 06:30:10.541854: step 89230, loss = 0.28, batch loss = 0.15 (51.2 examples/sec; 0.156 sec/batch; 10h:34m:06s remains)
INFO - root - 2017-12-01 06:30:12.107740: step 89240, loss = 0.57, batch loss = 0.44 (53.2 examples/sec; 0.150 sec/batch; 10h:09m:12s remains)
INFO - root - 2017-12-01 06:30:13.677117: step 89250, loss = 0.31, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 10h:24m:05s remains)
INFO - root - 2017-12-01 06:30:15.251232: step 89260, loss = 0.39, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 10h:21m:21s remains)
INFO - root - 2017-12-01 06:30:16.830053: step 89270, loss = 0.26, batch loss = 0.13 (50.7 examples/sec; 0.158 sec/batch; 10h:39m:53s remains)
INFO - root - 2017-12-01 06:30:18.402839: step 89280, loss = 0.38, batch loss = 0.25 (49.3 examples/sec; 0.162 sec/batch; 10h:57m:21s remains)
INFO - root - 2017-12-01 06:30:19.975463: step 89290, loss = 0.34, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 10h:19m:20s remains)
INFO - root - 2017-12-01 06:30:21.556605: step 89300, loss = 0.35, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 10h:26m:09s remains)
INFO - root - 2017-12-01 06:30:23.164355: step 89310, loss = 0.42, batch loss = 0.29 (51.7 examples/sec; 0.155 sec/batch; 10h:27m:02s remains)
INFO - root - 2017-12-01 06:30:24.727598: step 89320, loss = 0.31, batch loss = 0.18 (52.2 examples/sec; 0.153 sec/batch; 10h:21m:01s remains)
INFO - root - 2017-12-01 06:30:26.307988: step 89330, loss = 0.41, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 10h:27m:41s remains)
INFO - root - 2017-12-01 06:30:27.858009: step 89340, loss = 0.36, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 10h:20m:06s remains)
INFO - root - 2017-12-01 06:30:29.429835: step 89350, loss = 0.32, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 10h:32m:37s remains)
INFO - root - 2017-12-01 06:30:30.992222: step 89360, loss = 0.35, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 10h:31m:37s remains)
INFO - root - 2017-12-01 06:30:32.568459: step 89370, loss = 0.32, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 10h:38m:55s remains)
INFO - root - 2017-12-01 06:30:34.133865: step 89380, loss = 0.33, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 10h:41m:57s remains)
INFO - root - 2017-12-01 06:30:35.692321: step 89390, loss = 0.38, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 10h:39m:54s remains)
INFO - root - 2017-12-01 06:30:37.251410: step 89400, loss = 0.35, batch loss = 0.21 (49.5 examples/sec; 0.162 sec/batch; 10h:54m:36s remains)
INFO - root - 2017-12-01 06:30:38.911652: step 89410, loss = 0.45, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 10h:33m:36s remains)
INFO - root - 2017-12-01 06:30:40.482795: step 89420, loss = 0.33, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 10h:38m:06s remains)
INFO - root - 2017-12-01 06:30:42.056382: step 89430, loss = 0.44, batch loss = 0.31 (51.9 examples/sec; 0.154 sec/batch; 10h:24m:04s remains)
INFO - root - 2017-12-01 06:30:43.640917: step 89440, loss = 0.29, batch loss = 0.15 (51.9 examples/sec; 0.154 sec/batch; 10h:24m:44s remains)
INFO - root - 2017-12-01 06:30:45.206018: step 89450, loss = 0.34, batch loss = 0.21 (49.9 examples/sec; 0.160 sec/batch; 10h:49m:27s remains)
INFO - root - 2017-12-01 06:30:46.769650: step 89460, loss = 0.38, batch loss = 0.25 (49.2 examples/sec; 0.163 sec/batch; 10h:59m:03s remains)
INFO - root - 2017-12-01 06:30:48.325119: step 89470, loss = 0.34, batch loss = 0.20 (53.2 examples/sec; 0.150 sec/batch; 10h:08m:35s remains)
INFO - root - 2017-12-01 06:30:49.897906: step 89480, loss = 0.34, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 10h:17m:55s remains)
INFO - root - 2017-12-01 06:30:51.475289: step 89490, loss = 0.50, batch loss = 0.37 (49.2 examples/sec; 0.163 sec/batch; 10h:58m:09s remains)
INFO - root - 2017-12-01 06:30:53.038223: step 89500, loss = 0.31, batch loss = 0.18 (48.9 examples/sec; 0.164 sec/batch; 11h:02m:35s remains)
INFO - root - 2017-12-01 06:30:54.667473: step 89510, loss = 0.47, batch loss = 0.33 (51.9 examples/sec; 0.154 sec/batch; 10h:24m:27s remains)
INFO - root - 2017-12-01 06:30:56.239730: step 89520, loss = 0.36, batch loss = 0.23 (48.9 examples/sec; 0.164 sec/batch; 11h:02m:16s remains)
INFO - root - 2017-12-01 06:30:57.796899: step 89530, loss = 0.39, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 10h:33m:10s remains)
INFO - root - 2017-12-01 06:30:59.361926: step 89540, loss = 0.42, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 10h:31m:59s remains)
INFO - root - 2017-12-01 06:31:00.918822: step 89550, loss = 0.41, batch loss = 0.28 (50.0 examples/sec; 0.160 sec/batch; 10h:47m:48s remains)
INFO - root - 2017-12-01 06:31:02.491580: step 89560, loss = 0.33, batch loss = 0.20 (52.1 examples/sec; 0.153 sec/batch; 10h:21m:21s remains)
INFO - root - 2017-12-01 06:31:04.056551: step 89570, loss = 0.34, batch loss = 0.21 (49.4 examples/sec; 0.162 sec/batch; 10h:55m:21s remains)
INFO - root - 2017-12-01 06:31:05.619197: step 89580, loss = 0.42, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 10h:43m:17s remains)
INFO - root - 2017-12-01 06:31:07.179261: step 89590, loss = 0.54, batch loss = 0.41 (50.9 examples/sec; 0.157 sec/batch; 10h:36m:08s remains)
INFO - root - 2017-12-01 06:31:08.743767: step 89600, loss = 0.32, batch loss = 0.19 (52.9 examples/sec; 0.151 sec/batch; 10h:12m:05s remains)
INFO - root - 2017-12-01 06:31:10.393601: step 89610, loss = 0.41, batch loss = 0.28 (49.4 examples/sec; 0.162 sec/batch; 10h:55m:11s remains)
INFO - root - 2017-12-01 06:31:11.962946: step 89620, loss = 0.28, batch loss = 0.15 (53.3 examples/sec; 0.150 sec/batch; 10h:07m:15s remains)
INFO - root - 2017-12-01 06:31:13.533691: step 89630, loss = 0.43, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 10h:35m:38s remains)
INFO - root - 2017-12-01 06:31:15.099038: step 89640, loss = 0.31, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 10h:22m:21s remains)
INFO - root - 2017-12-01 06:31:16.670813: step 89650, loss = 0.30, batch loss = 0.17 (49.6 examples/sec; 0.161 sec/batch; 10h:52m:32s remains)
INFO - root - 2017-12-01 06:31:18.225332: step 89660, loss = 0.34, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 10h:30m:35s remains)
INFO - root - 2017-12-01 06:31:19.781268: step 89670, loss = 0.44, batch loss = 0.31 (52.7 examples/sec; 0.152 sec/batch; 10h:14m:38s remains)
INFO - root - 2017-12-01 06:31:21.367953: step 89680, loss = 0.49, batch loss = 0.36 (50.0 examples/sec; 0.160 sec/batch; 10h:47m:43s remains)
INFO - root - 2017-12-01 06:31:22.938100: step 89690, loss = 0.34, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 10h:20m:41s remains)
INFO - root - 2017-12-01 06:31:24.490198: step 89700, loss = 0.31, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 10h:24m:52s remains)
INFO - root - 2017-12-01 06:31:26.168302: step 89710, loss = 0.30, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 10h:34m:05s remains)
INFO - root - 2017-12-01 06:31:27.734569: step 89720, loss = 0.29, batch loss = 0.16 (49.1 examples/sec; 0.163 sec/batch; 10h:59m:07s remains)
INFO - root - 2017-12-01 06:31:29.297583: step 89730, loss = 0.32, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 10h:27m:46s remains)
INFO - root - 2017-12-01 06:31:30.871502: step 89740, loss = 0.36, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 10h:27m:26s remains)
INFO - root - 2017-12-01 06:31:32.456894: step 89750, loss = 0.36, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 10h:43m:06s remains)
INFO - root - 2017-12-01 06:31:34.018518: step 89760, loss = 0.34, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 10h:41m:40s remains)
INFO - root - 2017-12-01 06:31:35.576847: step 89770, loss = 0.34, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 10h:36m:52s remains)
INFO - root - 2017-12-01 06:31:37.131051: step 89780, loss = 0.40, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 10h:22m:40s remains)
INFO - root - 2017-12-01 06:31:38.716290: step 89790, loss = 0.28, batch loss = 0.15 (51.4 examples/sec; 0.156 sec/batch; 10h:29m:14s remains)
INFO - root - 2017-12-01 06:31:40.288566: step 89800, loss = 0.38, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 10h:33m:04s remains)
INFO - root - 2017-12-01 06:31:41.938134: step 89810, loss = 0.30, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 10h:23m:12s remains)
INFO - root - 2017-12-01 06:31:43.486600: step 89820, loss = 0.32, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 10h:21m:53s remains)
INFO - root - 2017-12-01 06:31:45.040459: step 89830, loss = 0.30, batch loss = 0.17 (50.5 examples/sec; 0.159 sec/batch; 10h:41m:20s remains)
INFO - root - 2017-12-01 06:31:46.607533: step 89840, loss = 0.34, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 10h:42m:55s remains)
INFO - root - 2017-12-01 06:31:48.158302: step 89850, loss = 0.36, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 10h:20m:00s remains)
INFO - root - 2017-12-01 06:31:49.716013: step 89860, loss = 0.33, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 10h:27m:19s remains)
INFO - root - 2017-12-01 06:31:51.283365: step 89870, loss = 0.28, batch loss = 0.15 (52.2 examples/sec; 0.153 sec/batch; 10h:20m:07s remains)
INFO - root - 2017-12-01 06:31:52.849051: step 89880, loss = 0.29, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 10h:35m:53s remains)
INFO - root - 2017-12-01 06:31:54.436435: step 89890, loss = 0.36, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 10h:44m:56s remains)
INFO - root - 2017-12-01 06:31:56.008279: step 89900, loss = 0.34, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 10h:22m:29s remains)
INFO - root - 2017-12-01 06:31:57.635716: step 89910, loss = 0.41, batch loss = 0.28 (50.1 examples/sec; 0.160 sec/batch; 10h:46m:11s remains)
INFO - root - 2017-12-01 06:31:59.192881: step 89920, loss = 0.36, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 10h:35m:03s remains)
INFO - root - 2017-12-01 06:32:00.762934: step 89930, loss = 0.39, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 10h:38m:31s remains)
INFO - root - 2017-12-01 06:32:02.325650: step 89940, loss = 0.32, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 10h:23m:49s remains)
INFO - root - 2017-12-01 06:32:03.885590: step 89950, loss = 0.32, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 10h:35m:32s remains)
INFO - root - 2017-12-01 06:32:05.460452: step 89960, loss = 0.29, batch loss = 0.16 (48.2 examples/sec; 0.166 sec/batch; 11h:11m:35s remains)
INFO - root - 2017-12-01 06:32:07.011820: step 89970, loss = 0.32, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 10h:17m:01s remains)
INFO - root - 2017-12-01 06:32:08.589345: step 89980, loss = 0.42, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 10h:34m:43s remains)
INFO - root - 2017-12-01 06:32:10.157866: step 89990, loss = 0.39, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 10h:28m:57s remains)
INFO - root - 2017-12-01 06:32:11.721402: step 90000, loss = 0.37, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 10h:28m:00s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-90000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-90000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-01 06:32:13.625241: step 90010, loss = 0.35, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 10h:42m:56s remains)
INFO - root - 2017-12-01 06:32:15.172409: step 90020, loss = 0.48, batch loss = 0.35 (52.8 examples/sec; 0.151 sec/batch; 10h:12m:07s remains)
INFO - root - 2017-12-01 06:32:16.741073: step 90030, loss = 0.37, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 10h:32m:42s remains)
INFO - root - 2017-12-01 06:32:18.295103: step 90040, loss = 0.32, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 10h:24m:54s remains)
INFO - root - 2017-12-01 06:32:19.853463: step 90050, loss = 0.31, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 10h:32m:40s remains)
INFO - root - 2017-12-01 06:32:21.424872: step 90060, loss = 0.33, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 10h:28m:15s remains)
INFO - root - 2017-12-01 06:32:22.999023: step 90070, loss = 0.36, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 10h:14m:24s remains)
INFO - root - 2017-12-01 06:32:24.557674: step 90080, loss = 0.40, batch loss = 0.27 (53.1 examples/sec; 0.151 sec/batch; 10h:09m:13s remains)
INFO - root - 2017-12-01 06:32:26.136867: step 90090, loss = 0.35, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 10h:36m:37s remains)
INFO - root - 2017-12-01 06:32:27.694486: step 90100, loss = 0.34, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 10h:30m:42s remains)
INFO - root - 2017-12-01 06:32:29.319643: step 90110, loss = 0.29, batch loss = 0.16 (52.6 examples/sec; 0.152 sec/batch; 10h:14m:24s remains)
INFO - root - 2017-12-01 06:32:30.902656: step 90120, loss = 0.51, batch loss = 0.38 (50.4 examples/sec; 0.159 sec/batch; 10h:40m:57s remains)
INFO - root - 2017-12-01 06:32:32.472701: step 90130, loss = 0.34, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 10h:36m:25s remains)
INFO - root - 2017-12-01 06:32:34.033200: step 90140, loss = 0.31, batch loss = 0.18 (49.3 examples/sec; 0.162 sec/batch; 10h:54m:48s remains)
INFO - root - 2017-12-01 06:32:35.611146: step 90150, loss = 0.37, batch loss = 0.24 (52.1 examples/sec; 0.154 sec/batch; 10h:20m:25s remains)
INFO - root - 2017-12-01 06:32:37.181217: step 90160, loss = 0.29, batch loss = 0.16 (52.2 examples/sec; 0.153 sec/batch; 10h:19m:17s remains)
INFO - root - 2017-12-01 06:32:38.746035: step 90170, loss = 0.31, batch loss = 0.18 (48.5 examples/sec; 0.165 sec/batch; 11h:06m:28s remains)
INFO - root - 2017-12-01 06:32:40.298091: step 90180, loss = 0.37, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 10h:32m:25s remains)
INFO - root - 2017-12-01 06:32:41.857363: step 90190, loss = 0.30, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 10h:24m:52s remains)
INFO - root - 2017-12-01 06:32:43.408147: step 90200, loss = 0.38, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 10h:34m:12s remains)
INFO - root - 2017-12-01 06:32:45.022715: step 90210, loss = 0.35, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 10h:33m:12s remains)
INFO - root - 2017-12-01 06:32:46.592551: step 90220, loss = 0.32, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 10h:22m:35s remains)
INFO - root - 2017-12-01 06:32:48.154313: step 90230, loss = 0.32, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 10h:31m:20s remains)
INFO - root - 2017-12-01 06:32:49.710530: step 90240, loss = 0.34, batch loss = 0.21 (53.5 examples/sec; 0.149 sec/batch; 10h:03m:26s remains)
INFO - root - 2017-12-01 06:32:51.289238: step 90250, loss = 0.35, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 10h:27m:45s remains)
INFO - root - 2017-12-01 06:32:52.850418: step 90260, loss = 0.34, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 10h:35m:18s remains)
INFO - root - 2017-12-01 06:32:54.421145: step 90270, loss = 0.30, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 10h:21m:08s remains)
INFO - root - 2017-12-01 06:32:55.991901: step 90280, loss = 0.40, batch loss = 0.27 (52.8 examples/sec; 0.152 sec/batch; 10h:11m:46s remains)
INFO - root - 2017-12-01 06:32:57.556098: step 90290, loss = 0.39, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 10h:29m:33s remains)
INFO - root - 2017-12-01 06:32:59.113369: step 90300, loss = 0.29, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 10h:31m:03s remains)
INFO - root - 2017-12-01 06:33:00.712700: step 90310, loss = 0.42, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 10h:25m:33s remains)
INFO - root - 2017-12-01 06:33:02.273973: step 90320, loss = 0.33, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 10h:30m:11s remains)
INFO - root - 2017-12-01 06:33:03.839050: step 90330, loss = 0.35, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 10h:32m:54s remains)
INFO - root - 2017-12-01 06:33:05.406034: step 90340, loss = 0.35, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 10h:33m:31s remains)
INFO - root - 2017-12-01 06:33:06.986056: step 90350, loss = 0.40, batch loss = 0.27 (48.1 examples/sec; 0.166 sec/batch; 11h:11m:43s remains)
INFO - root - 2017-12-01 06:33:08.545232: step 90360, loss = 0.33, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 10h:38m:01s remains)
INFO - root - 2017-12-01 06:33:10.110989: step 90370, loss = 0.34, batch loss = 0.21 (49.9 examples/sec; 0.160 sec/batch; 10h:46m:50s remains)
INFO - root - 2017-12-01 06:33:11.679948: step 90380, loss = 0.34, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 10h:21m:25s remains)
INFO - root - 2017-12-01 06:33:13.241152: step 90390, loss = 0.33, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 10h:38m:14s remains)
INFO - root - 2017-12-01 06:33:14.804259: step 90400, loss = 0.33, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 10h:17m:14s remains)
INFO - root - 2017-12-01 06:33:16.449532: step 90410, loss = 0.42, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 10h:26m:03s remains)
INFO - root - 2017-12-01 06:33:18.027751: step 90420, loss = 0.28, batch loss = 0.15 (50.4 examples/sec; 0.159 sec/batch; 10h:40m:54s remains)
INFO - root - 2017-12-01 06:33:19.582270: step 90430, loss = 0.33, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 10h:32m:51s remains)
INFO - root - 2017-12-01 06:33:21.146041: step 90440, loss = 0.35, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 10h:13m:53s remains)
INFO - root - 2017-12-01 06:33:22.717239: step 90450, loss = 0.36, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 10h:17m:05s remains)
INFO - root - 2017-12-01 06:33:24.273791: step 90460, loss = 0.36, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 10h:43m:09s remains)
INFO - root - 2017-12-01 06:33:25.852067: step 90470, loss = 0.31, batch loss = 0.18 (53.6 examples/sec; 0.149 sec/batch; 10h:02m:37s remains)
INFO - root - 2017-12-01 06:33:27.412861: step 90480, loss = 0.31, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 10h:31m:41s remains)
INFO - root - 2017-12-01 06:33:28.984897: step 90490, loss = 0.30, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 10h:40m:34s remains)
INFO - root - 2017-12-01 06:33:30.548496: step 90500, loss = 0.48, batch loss = 0.35 (50.7 examples/sec; 0.158 sec/batch; 10h:36m:10s remains)
INFO - root - 2017-12-01 06:33:32.190813: step 90510, loss = 0.43, batch loss = 0.30 (52.1 examples/sec; 0.153 sec/batch; 10h:18m:57s remains)
INFO - root - 2017-12-01 06:33:33.759010: step 90520, loss = 0.35, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 10h:35m:39s remains)
INFO - root - 2017-12-01 06:33:35.327480: step 90530, loss = 0.31, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 10h:32m:09s remains)
INFO - root - 2017-12-01 06:33:36.881677: step 90540, loss = 0.35, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 10h:38m:00s remains)
INFO - root - 2017-12-01 06:33:38.427027: step 90550, loss = 0.30, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 10h:25m:04s remains)
INFO - root - 2017-12-01 06:33:39.983063: step 90560, loss = 0.38, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 10h:24m:58s remains)
INFO - root - 2017-12-01 06:33:41.549315: step 90570, loss = 0.32, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 10h:30m:21s remains)
INFO - root - 2017-12-01 06:33:43.121691: step 90580, loss = 0.36, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 10h:17m:41s remains)
INFO - root - 2017-12-01 06:33:44.692549: step 90590, loss = 0.32, batch loss = 0.19 (50.3 examples/sec; 0.159 sec/batch; 10h:41m:36s remains)
INFO - root - 2017-12-01 06:33:46.272201: step 90600, loss = 0.31, batch loss = 0.18 (47.6 examples/sec; 0.168 sec/batch; 11h:17m:24s remains)
INFO - root - 2017-12-01 06:33:47.909567: step 90610, loss = 0.31, batch loss = 0.18 (52.1 examples/sec; 0.153 sec/batch; 10h:18m:39s remains)
INFO - root - 2017-12-01 06:33:49.470791: step 90620, loss = 0.33, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 10h:44m:30s remains)
INFO - root - 2017-12-01 06:33:51.024057: step 90630, loss = 0.36, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 10h:41m:40s remains)
INFO - root - 2017-12-01 06:33:52.593159: step 90640, loss = 0.30, batch loss = 0.17 (52.5 examples/sec; 0.152 sec/batch; 10h:14m:40s remains)
INFO - root - 2017-12-01 06:33:54.173007: step 90650, loss = 0.28, batch loss = 0.15 (51.8 examples/sec; 0.154 sec/batch; 10h:22m:32s remains)
INFO - root - 2017-12-01 06:33:55.731464: step 90660, loss = 0.45, batch loss = 0.32 (51.1 examples/sec; 0.157 sec/batch; 10h:30m:58s remains)
INFO - root - 2017-12-01 06:33:57.290222: step 90670, loss = 0.40, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 10h:37m:41s remains)
INFO - root - 2017-12-01 06:33:58.842954: step 90680, loss = 0.38, batch loss = 0.25 (49.8 examples/sec; 0.161 sec/batch; 10h:47m:46s remains)
INFO - root - 2017-12-01 06:34:00.407674: step 90690, loss = 0.36, batch loss = 0.23 (48.7 examples/sec; 0.164 sec/batch; 11h:02m:26s remains)
INFO - root - 2017-12-01 06:34:01.978109: step 90700, loss = 0.38, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 10h:23m:09s remains)
INFO - root - 2017-12-01 06:34:03.624857: step 90710, loss = 0.38, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 10h:27m:46s remains)
INFO - root - 2017-12-01 06:34:05.182560: step 90720, loss = 0.34, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 10h:16m:20s remains)
INFO - root - 2017-12-01 06:34:06.754232: step 90730, loss = 0.33, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 10h:22m:09s remains)
INFO - root - 2017-12-01 06:34:08.317243: step 90740, loss = 0.33, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 10h:43m:12s remains)
INFO - root - 2017-12-01 06:34:09.902240: step 90750, loss = 0.38, batch loss = 0.25 (48.9 examples/sec; 0.164 sec/batch; 10h:59m:44s remains)
INFO - root - 2017-12-01 06:34:11.495563: step 90760, loss = 0.34, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 10h:23m:26s remains)
INFO - root - 2017-12-01 06:34:13.054214: step 90770, loss = 0.34, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 10h:35m:28s remains)
INFO - root - 2017-12-01 06:34:14.623116: step 90780, loss = 0.32, batch loss = 0.19 (49.6 examples/sec; 0.161 sec/batch; 10h:49m:49s remains)
INFO - root - 2017-12-01 06:34:16.173501: step 90790, loss = 0.27, batch loss = 0.14 (51.1 examples/sec; 0.156 sec/batch; 10h:30m:15s remains)
INFO - root - 2017-12-01 06:34:17.741293: step 90800, loss = 0.31, batch loss = 0.18 (49.9 examples/sec; 0.160 sec/batch; 10h:45m:54s remains)
INFO - root - 2017-12-01 06:34:19.393529: step 90810, loss = 0.38, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 10h:39m:51s remains)
INFO - root - 2017-12-01 06:34:20.946324: step 90820, loss = 0.39, batch loss = 0.26 (50.0 examples/sec; 0.160 sec/batch; 10h:44m:43s remains)
INFO - root - 2017-12-01 06:34:22.523842: step 90830, loss = 0.36, batch loss = 0.23 (47.2 examples/sec; 0.170 sec/batch; 11h:23m:09s remains)
INFO - root - 2017-12-01 06:34:24.075462: step 90840, loss = 0.28, batch loss = 0.15 (50.8 examples/sec; 0.157 sec/batch; 10h:34m:20s remains)
INFO - root - 2017-12-01 06:34:25.658957: step 90850, loss = 0.40, batch loss = 0.27 (51.2 examples/sec; 0.156 sec/batch; 10h:29m:43s remains)
INFO - root - 2017-12-01 06:34:27.216105: step 90860, loss = 0.41, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 10h:25m:08s remains)
INFO - root - 2017-12-01 06:34:28.779263: step 90870, loss = 0.39, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 10h:22m:04s remains)
INFO - root - 2017-12-01 06:34:30.357009: step 90880, loss = 0.45, batch loss = 0.32 (51.6 examples/sec; 0.155 sec/batch; 10h:23m:58s remains)
INFO - root - 2017-12-01 06:34:31.923594: step 90890, loss = 0.40, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 10h:28m:00s remains)
INFO - root - 2017-12-01 06:34:33.493521: step 90900, loss = 0.38, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 10h:25m:40s remains)
INFO - root - 2017-12-01 06:34:35.139230: step 90910, loss = 0.37, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 10h:20m:35s remains)
INFO - root - 2017-12-01 06:34:36.703689: step 90920, loss = 0.31, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 10h:35m:33s remains)
INFO - root - 2017-12-01 06:34:38.265504: step 90930, loss = 0.33, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 10h:23m:04s remains)
INFO - root - 2017-12-01 06:34:39.832813: step 90940, loss = 0.41, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 10h:27m:35s remains)
INFO - root - 2017-12-01 06:34:41.401702: step 90950, loss = 0.43, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 10h:26m:18s remains)
INFO - root - 2017-12-01 06:34:42.954876: step 90960, loss = 0.47, batch loss = 0.35 (51.7 examples/sec; 0.155 sec/batch; 10h:22m:28s remains)
INFO - root - 2017-12-01 06:34:44.514917: step 90970, loss = 0.33, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 10h:25m:14s remains)
INFO - root - 2017-12-01 06:34:46.080175: step 90980, loss = 0.29, batch loss = 0.16 (50.3 examples/sec; 0.159 sec/batch; 10h:40m:16s remains)
INFO - root - 2017-12-01 06:34:47.634840: step 90990, loss = 0.31, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 10h:30m:01s remains)
INFO - root - 2017-12-01 06:34:49.188164: step 91000, loss = 0.46, batch loss = 0.33 (52.5 examples/sec; 0.152 sec/batch; 10h:13m:41s remains)
INFO - root - 2017-12-01 06:34:50.836732: step 91010, loss = 0.31, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 10h:27m:28s remains)
INFO - root - 2017-12-01 06:34:52.405171: step 91020, loss = 0.35, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 10h:26m:58s remains)
INFO - root - 2017-12-01 06:34:53.979786: step 91030, loss = 0.37, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 10h:20m:39s remains)
INFO - root - 2017-12-01 06:34:55.572964: step 91040, loss = 0.32, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 10h:27m:45s remains)
INFO - root - 2017-12-01 06:34:57.120190: step 91050, loss = 0.40, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 10h:36m:02s remains)
INFO - root - 2017-12-01 06:34:58.675424: step 91060, loss = 0.34, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 10h:40m:08s remains)
INFO - root - 2017-12-01 06:35:00.235231: step 91070, loss = 0.35, batch loss = 0.22 (53.5 examples/sec; 0.150 sec/batch; 10h:01m:35s remains)
INFO - root - 2017-12-01 06:35:01.814851: step 91080, loss = 0.30, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 10h:24m:33s remains)
INFO - root - 2017-12-01 06:35:03.372838: step 91090, loss = 0.36, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 10h:18m:26s remains)
INFO - root - 2017-12-01 06:35:04.922535: step 91100, loss = 0.35, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 10h:25m:43s remains)
INFO - root - 2017-12-01 06:35:06.572747: step 91110, loss = 0.34, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 10h:18m:18s remains)
INFO - root - 2017-12-01 06:35:08.134400: step 91120, loss = 0.50, batch loss = 0.37 (51.4 examples/sec; 0.156 sec/batch; 10h:25m:35s remains)
INFO - root - 2017-12-01 06:35:09.695468: step 91130, loss = 0.29, batch loss = 0.16 (50.0 examples/sec; 0.160 sec/batch; 10h:43m:31s remains)
INFO - root - 2017-12-01 06:35:11.257522: step 91140, loss = 0.33, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 10h:31m:09s remains)
INFO - root - 2017-12-01 06:35:12.812054: step 91150, loss = 0.35, batch loss = 0.22 (53.1 examples/sec; 0.151 sec/batch; 10h:06m:20s remains)
INFO - root - 2017-12-01 06:35:14.368880: step 91160, loss = 0.34, batch loss = 0.21 (49.0 examples/sec; 0.163 sec/batch; 10h:57m:10s remains)
INFO - root - 2017-12-01 06:35:15.924212: step 91170, loss = 0.37, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 10h:31m:43s remains)
INFO - root - 2017-12-01 06:35:17.497992: step 91180, loss = 0.30, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 10h:35m:43s remains)
INFO - root - 2017-12-01 06:35:19.059546: step 91190, loss = 0.34, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 10h:24m:55s remains)
INFO - root - 2017-12-01 06:35:20.640860: step 91200, loss = 0.39, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 10h:18m:23s remains)
INFO - root - 2017-12-01 06:35:22.276713: step 91210, loss = 0.29, batch loss = 0.16 (49.8 examples/sec; 0.161 sec/batch; 10h:46m:01s remains)
INFO - root - 2017-12-01 06:35:23.838173: step 91220, loss = 0.32, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 10h:27m:40s remains)
INFO - root - 2017-12-01 06:35:25.423506: step 91230, loss = 0.61, batch loss = 0.48 (51.2 examples/sec; 0.156 sec/batch; 10h:28m:04s remains)
INFO - root - 2017-12-01 06:35:26.995940: step 91240, loss = 0.27, batch loss = 0.14 (51.4 examples/sec; 0.156 sec/batch; 10h:25m:40s remains)
INFO - root - 2017-12-01 06:35:28.555328: step 91250, loss = 0.40, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 10h:35m:13s remains)
INFO - root - 2017-12-01 06:35:30.121999: step 91260, loss = 0.36, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 10h:30m:21s remains)
INFO - root - 2017-12-01 06:35:31.678143: step 91270, loss = 0.31, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 10h:24m:52s remains)
INFO - root - 2017-12-01 06:35:33.269479: step 91280, loss = 0.33, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 10h:33m:16s remains)
INFO - root - 2017-12-01 06:35:34.832244: step 91290, loss = 0.35, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 10h:23m:44s remains)
INFO - root - 2017-12-01 06:35:36.388457: step 91300, loss = 0.39, batch loss = 0.27 (52.3 examples/sec; 0.153 sec/batch; 10h:14m:59s remains)
INFO - root - 2017-12-01 06:35:38.042636: step 91310, loss = 0.30, batch loss = 0.17 (49.9 examples/sec; 0.160 sec/batch; 10h:44m:49s remains)
INFO - root - 2017-12-01 06:35:39.621276: step 91320, loss = 0.41, batch loss = 0.28 (49.5 examples/sec; 0.162 sec/batch; 10h:49m:14s remains)
INFO - root - 2017-12-01 06:35:41.194205: step 91330, loss = 0.32, batch loss = 0.19 (49.3 examples/sec; 0.162 sec/batch; 10h:52m:01s remains)
INFO - root - 2017-12-01 06:35:42.745863: step 91340, loss = 0.33, batch loss = 0.20 (52.7 examples/sec; 0.152 sec/batch; 10h:10m:19s remains)
INFO - root - 2017-12-01 06:35:44.312199: step 91350, loss = 0.31, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 10h:22m:42s remains)
INFO - root - 2017-12-01 06:35:45.898214: step 91360, loss = 0.32, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 10h:43m:09s remains)
INFO - root - 2017-12-01 06:35:47.456984: step 91370, loss = 0.44, batch loss = 0.31 (52.2 examples/sec; 0.153 sec/batch; 10h:15m:56s remains)
INFO - root - 2017-12-01 06:35:49.012011: step 91380, loss = 0.49, batch loss = 0.36 (51.5 examples/sec; 0.155 sec/batch; 10h:24m:01s remains)
INFO - root - 2017-12-01 06:35:50.589728: step 91390, loss = 0.29, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 10h:27m:40s remains)
INFO - root - 2017-12-01 06:35:52.151747: step 91400, loss = 0.31, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 10h:22m:37s remains)
INFO - root - 2017-12-01 06:35:53.743626: step 91410, loss = 0.35, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 10h:30m:33s remains)
INFO - root - 2017-12-01 06:35:55.303057: step 91420, loss = 0.33, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 10h:20m:41s remains)
INFO - root - 2017-12-01 06:35:56.889128: step 91430, loss = 0.31, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 10h:35m:21s remains)
INFO - root - 2017-12-01 06:35:58.463820: step 91440, loss = 0.32, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 10h:19m:16s remains)
INFO - root - 2017-12-01 06:36:00.015705: step 91450, loss = 0.45, batch loss = 0.32 (50.9 examples/sec; 0.157 sec/batch; 10h:31m:17s remains)
INFO - root - 2017-12-01 06:36:01.591018: step 91460, loss = 0.37, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 10h:37m:58s remains)
INFO - root - 2017-12-01 06:36:03.166758: step 91470, loss = 0.29, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 10h:23m:41s remains)
INFO - root - 2017-12-01 06:36:04.772137: step 91480, loss = 0.39, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 10h:30m:42s remains)
INFO - root - 2017-12-01 06:36:06.346230: step 91490, loss = 0.41, batch loss = 0.28 (52.2 examples/sec; 0.153 sec/batch; 10h:15m:53s remains)
INFO - root - 2017-12-01 06:36:07.948173: step 91500, loss = 0.34, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 10h:37m:55s remains)
INFO - root - 2017-12-01 06:36:09.621151: step 91510, loss = 0.38, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 10h:23m:18s remains)
INFO - root - 2017-12-01 06:36:11.234368: step 91520, loss = 0.31, batch loss = 0.19 (49.3 examples/sec; 0.162 sec/batch; 10h:51m:05s remains)
INFO - root - 2017-12-01 06:36:12.793710: step 91530, loss = 0.33, batch loss = 0.20 (53.0 examples/sec; 0.151 sec/batch; 10h:06m:33s remains)
INFO - root - 2017-12-01 06:36:14.360140: step 91540, loss = 0.35, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 10h:24m:47s remains)
INFO - root - 2017-12-01 06:36:15.923736: step 91550, loss = 0.31, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 10h:20m:23s remains)
INFO - root - 2017-12-01 06:36:17.493128: step 91560, loss = 0.46, batch loss = 0.33 (48.6 examples/sec; 0.165 sec/batch; 11h:00m:55s remains)
INFO - root - 2017-12-01 06:36:19.057929: step 91570, loss = 0.36, batch loss = 0.23 (49.7 examples/sec; 0.161 sec/batch; 10h:46m:06s remains)
INFO - root - 2017-12-01 06:36:20.624479: step 91580, loss = 0.33, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 10h:28m:52s remains)
INFO - root - 2017-12-01 06:36:22.208260: step 91590, loss = 0.42, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 10h:27m:28s remains)
INFO - root - 2017-12-01 06:36:23.773505: step 91600, loss = 0.34, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 10h:36m:52s remains)
INFO - root - 2017-12-01 06:36:25.446594: step 91610, loss = 0.38, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 10h:24m:32s remains)
INFO - root - 2017-12-01 06:36:27.008602: step 91620, loss = 0.39, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 10h:23m:25s remains)
INFO - root - 2017-12-01 06:36:28.582849: step 91630, loss = 0.31, batch loss = 0.18 (48.3 examples/sec; 0.165 sec/batch; 11h:04m:23s remains)
INFO - root - 2017-12-01 06:36:30.143792: step 91640, loss = 0.34, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 10h:17m:47s remains)
INFO - root - 2017-12-01 06:36:31.702684: step 91650, loss = 0.28, batch loss = 0.15 (51.8 examples/sec; 0.154 sec/batch; 10h:19m:50s remains)
INFO - root - 2017-12-01 06:36:33.276855: step 91660, loss = 0.36, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 10h:18m:32s remains)
INFO - root - 2017-12-01 06:36:34.835513: step 91670, loss = 0.32, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 10h:24m:46s remains)
INFO - root - 2017-12-01 06:36:36.419400: step 91680, loss = 0.29, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 10h:37m:11s remains)
INFO - root - 2017-12-01 06:36:37.971874: step 91690, loss = 0.32, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 10h:31m:44s remains)
INFO - root - 2017-12-01 06:36:39.536860: step 91700, loss = 0.42, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 10h:23m:51s remains)
INFO - root - 2017-12-01 06:36:41.178502: step 91710, loss = 0.40, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 10h:25m:01s remains)
INFO - root - 2017-12-01 06:36:42.726171: step 91720, loss = 0.31, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 10h:24m:34s remains)
INFO - root - 2017-12-01 06:36:44.294531: step 91730, loss = 0.39, batch loss = 0.26 (53.0 examples/sec; 0.151 sec/batch; 10h:06m:16s remains)
INFO - root - 2017-12-01 06:36:45.857074: step 91740, loss = 0.30, batch loss = 0.17 (52.1 examples/sec; 0.154 sec/batch; 10h:16m:05s remains)
INFO - root - 2017-12-01 06:36:47.416554: step 91750, loss = 0.37, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 10h:20m:33s remains)
INFO - root - 2017-12-01 06:36:48.997188: step 91760, loss = 0.44, batch loss = 0.31 (50.1 examples/sec; 0.160 sec/batch; 10h:40m:27s remains)
INFO - root - 2017-12-01 06:36:50.559921: step 91770, loss = 0.34, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 10h:27m:56s remains)
INFO - root - 2017-12-01 06:36:52.163871: step 91780, loss = 0.33, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 10h:32m:30s remains)
INFO - root - 2017-12-01 06:36:53.709268: step 91790, loss = 0.31, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 10h:21m:52s remains)
INFO - root - 2017-12-01 06:36:55.265433: step 91800, loss = 0.41, batch loss = 0.28 (50.2 examples/sec; 0.159 sec/batch; 10h:39m:35s remains)
INFO - root - 2017-12-01 06:36:56.922131: step 91810, loss = 0.32, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 10h:20m:28s remains)
INFO - root - 2017-12-01 06:36:58.473209: step 91820, loss = 0.31, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 10h:27m:53s remains)
INFO - root - 2017-12-01 06:37:00.036497: step 91830, loss = 0.31, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 10h:20m:19s remains)
INFO - root - 2017-12-01 06:37:01.597449: step 91840, loss = 0.34, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 10h:24m:36s remains)
INFO - root - 2017-12-01 06:37:03.194704: step 91850, loss = 0.39, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 10h:32m:36s remains)
INFO - root - 2017-12-01 06:37:04.745677: step 91860, loss = 0.36, batch loss = 0.23 (50.5 examples/sec; 0.159 sec/batch; 10h:35m:44s remains)
INFO - root - 2017-12-01 06:37:06.311165: step 91870, loss = 0.34, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 10h:28m:05s remains)
INFO - root - 2017-12-01 06:37:07.880499: step 91880, loss = 0.44, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 10h:29m:51s remains)
INFO - root - 2017-12-01 06:37:09.458682: step 91890, loss = 0.41, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 10h:25m:28s remains)
INFO - root - 2017-12-01 06:37:11.029189: step 91900, loss = 0.37, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 10h:34m:32s remains)
INFO - root - 2017-12-01 06:37:12.652466: step 91910, loss = 0.38, batch loss = 0.25 (52.0 examples/sec; 0.154 sec/batch; 10h:16m:46s remains)
INFO - root - 2017-12-01 06:37:14.224657: step 91920, loss = 0.31, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 10h:38m:49s remains)
INFO - root - 2017-12-01 06:37:15.789306: step 91930, loss = 0.32, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 10h:47m:45s remains)
INFO - root - 2017-12-01 06:37:17.352195: step 91940, loss = 0.36, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 10h:34m:43s remains)
INFO - root - 2017-12-01 06:37:18.915794: step 91950, loss = 0.35, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 10h:36m:31s remains)
INFO - root - 2017-12-01 06:37:20.479416: step 91960, loss = 0.28, batch loss = 0.15 (52.9 examples/sec; 0.151 sec/batch; 10h:05m:53s remains)
INFO - root - 2017-12-01 06:37:22.053731: step 91970, loss = 0.32, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 10h:17m:43s remains)
INFO - root - 2017-12-01 06:37:23.614646: step 91980, loss = 0.50, batch loss = 0.37 (51.0 examples/sec; 0.157 sec/batch; 10h:28m:24s remains)
INFO - root - 2017-12-01 06:37:25.175410: step 91990, loss = 0.35, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 10h:18m:29s remains)
INFO - root - 2017-12-01 06:37:26.756383: step 92000, loss = 0.44, batch loss = 0.31 (52.7 examples/sec; 0.152 sec/batch; 10h:08m:18s remains)
INFO - root - 2017-12-01 06:37:28.391090: step 92010, loss = 0.44, batch loss = 0.31 (51.3 examples/sec; 0.156 sec/batch; 10h:25m:12s remains)
INFO - root - 2017-12-01 06:37:29.947222: step 92020, loss = 0.33, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 10h:38m:48s remains)
INFO - root - 2017-12-01 06:37:31.525405: step 92030, loss = 0.45, batch loss = 0.32 (52.2 examples/sec; 0.153 sec/batch; 10h:13m:48s remains)
INFO - root - 2017-12-01 06:37:33.089587: step 92040, loss = 0.39, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 10h:19m:07s remains)
INFO - root - 2017-12-01 06:37:34.650572: step 92050, loss = 0.43, batch loss = 0.30 (51.4 examples/sec; 0.155 sec/batch; 10h:23m:09s remains)
INFO - root - 2017-12-01 06:37:36.227067: step 92060, loss = 0.64, batch loss = 0.51 (50.4 examples/sec; 0.159 sec/batch; 10h:35m:51s remains)
INFO - root - 2017-12-01 06:37:37.784548: step 92070, loss = 0.32, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 10h:24m:58s remains)
INFO - root - 2017-12-01 06:37:39.357937: step 92080, loss = 0.28, batch loss = 0.15 (50.8 examples/sec; 0.158 sec/batch; 10h:31m:10s remains)
INFO - root - 2017-12-01 06:37:40.926651: step 92090, loss = 0.29, batch loss = 0.17 (50.8 examples/sec; 0.157 sec/batch; 10h:30m:55s remains)
INFO - root - 2017-12-01 06:37:42.478985: step 92100, loss = 0.32, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 10h:09m:29s remains)
INFO - root - 2017-12-01 06:37:44.104606: step 92110, loss = 0.44, batch loss = 0.31 (51.3 examples/sec; 0.156 sec/batch; 10h:24m:27s remains)
INFO - root - 2017-12-01 06:37:45.688850: step 92120, loss = 0.33, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 10h:17m:12s remains)
INFO - root - 2017-12-01 06:37:47.255710: step 92130, loss = 0.39, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 10h:28m:17s remains)
INFO - root - 2017-12-01 06:37:48.812491: step 92140, loss = 0.37, batch loss = 0.24 (50.0 examples/sec; 0.160 sec/batch; 10h:40m:29s remains)
INFO - root - 2017-12-01 06:37:50.389019: step 92150, loss = 0.32, batch loss = 0.19 (49.3 examples/sec; 0.162 sec/batch; 10h:49m:23s remains)
INFO - root - 2017-12-01 06:37:51.952475: step 92160, loss = 0.33, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 10h:12m:07s remains)
INFO - root - 2017-12-01 06:37:53.520686: step 92170, loss = 0.42, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 10h:17m:42s remains)
INFO - root - 2017-12-01 06:37:55.096597: step 92180, loss = 0.30, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 10h:34m:15s remains)
INFO - root - 2017-12-01 06:37:56.658843: step 92190, loss = 0.43, batch loss = 0.30 (51.0 examples/sec; 0.157 sec/batch; 10h:28m:21s remains)
INFO - root - 2017-12-01 06:37:58.221217: step 92200, loss = 0.33, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 10h:15m:59s remains)
INFO - root - 2017-12-01 06:37:59.869272: step 92210, loss = 0.31, batch loss = 0.18 (50.1 examples/sec; 0.160 sec/batch; 10h:38m:56s remains)
INFO - root - 2017-12-01 06:38:01.429354: step 92220, loss = 0.33, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 10h:13m:48s remains)
INFO - root - 2017-12-01 06:38:03.023278: step 92230, loss = 0.27, batch loss = 0.14 (52.1 examples/sec; 0.154 sec/batch; 10h:14m:45s remains)
INFO - root - 2017-12-01 06:38:04.598384: step 92240, loss = 0.28, batch loss = 0.15 (51.5 examples/sec; 0.155 sec/batch; 10h:21m:57s remains)
INFO - root - 2017-12-01 06:38:06.160539: step 92250, loss = 0.32, batch loss = 0.19 (47.1 examples/sec; 0.170 sec/batch; 11h:19m:29s remains)
INFO - root - 2017-12-01 06:38:07.716980: step 92260, loss = 0.52, batch loss = 0.39 (51.7 examples/sec; 0.155 sec/batch; 10h:19m:21s remains)
INFO - root - 2017-12-01 06:38:09.306351: step 92270, loss = 0.32, batch loss = 0.19 (52.1 examples/sec; 0.153 sec/batch; 10h:14m:35s remains)
INFO - root - 2017-12-01 06:38:10.863009: step 92280, loss = 0.29, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 10h:28m:58s remains)
INFO - root - 2017-12-01 06:38:12.413056: step 92290, loss = 0.43, batch loss = 0.30 (51.1 examples/sec; 0.157 sec/batch; 10h:26m:41s remains)
INFO - root - 2017-12-01 06:38:13.967023: step 92300, loss = 0.45, batch loss = 0.32 (52.7 examples/sec; 0.152 sec/batch; 10h:07m:28s remains)
INFO - root - 2017-12-01 06:38:15.629085: step 92310, loss = 0.35, batch loss = 0.23 (50.0 examples/sec; 0.160 sec/batch; 10h:41m:08s remains)
INFO - root - 2017-12-01 06:38:17.214901: step 92320, loss = 0.40, batch loss = 0.28 (51.1 examples/sec; 0.157 sec/batch; 10h:27m:06s remains)
INFO - root - 2017-12-01 06:38:18.779002: step 92330, loss = 0.32, batch loss = 0.19 (48.7 examples/sec; 0.164 sec/batch; 10h:57m:06s remains)
INFO - root - 2017-12-01 06:38:20.345215: step 92340, loss = 0.31, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 10h:34m:52s remains)
INFO - root - 2017-12-01 06:38:21.935961: step 92350, loss = 0.27, batch loss = 0.14 (51.1 examples/sec; 0.157 sec/batch; 10h:26m:41s remains)
INFO - root - 2017-12-01 06:38:23.507287: step 92360, loss = 0.36, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 10h:20m:46s remains)
INFO - root - 2017-12-01 06:38:25.082291: step 92370, loss = 0.32, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 10h:27m:26s remains)
INFO - root - 2017-12-01 06:38:26.631514: step 92380, loss = 0.31, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 10h:16m:46s remains)
INFO - root - 2017-12-01 06:38:28.213253: step 92390, loss = 0.30, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 10h:32m:45s remains)
INFO - root - 2017-12-01 06:38:29.772245: step 92400, loss = 0.32, batch loss = 0.19 (50.2 examples/sec; 0.159 sec/batch; 10h:38m:15s remains)
INFO - root - 2017-12-01 06:38:31.434594: step 92410, loss = 0.34, batch loss = 0.21 (45.5 examples/sec; 0.176 sec/batch; 11h:43m:38s remains)
INFO - root - 2017-12-01 06:38:32.989509: step 92420, loss = 0.37, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 10h:18m:44s remains)
INFO - root - 2017-12-01 06:38:34.539781: step 92430, loss = 0.49, batch loss = 0.37 (50.0 examples/sec; 0.160 sec/batch; 10h:40m:29s remains)
INFO - root - 2017-12-01 06:38:36.110392: step 92440, loss = 0.40, batch loss = 0.27 (49.0 examples/sec; 0.163 sec/batch; 10h:53m:52s remains)
INFO - root - 2017-12-01 06:38:37.676908: step 92450, loss = 0.39, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 10h:20m:42s remains)
INFO - root - 2017-12-01 06:38:39.253079: step 92460, loss = 0.34, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 10h:21m:33s remains)
INFO - root - 2017-12-01 06:38:40.820713: step 92470, loss = 0.33, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 10h:30m:32s remains)
INFO - root - 2017-12-01 06:38:42.381679: step 92480, loss = 0.34, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 10h:19m:18s remains)
INFO - root - 2017-12-01 06:38:43.942706: step 92490, loss = 0.39, batch loss = 0.26 (52.4 examples/sec; 0.153 sec/batch; 10h:10m:12s remains)
INFO - root - 2017-12-01 06:38:45.502811: step 92500, loss = 0.34, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 10h:30m:47s remains)
INFO - root - 2017-12-01 06:38:47.113966: step 92510, loss = 0.31, batch loss = 0.18 (48.3 examples/sec; 0.166 sec/batch; 11h:02m:32s remains)
INFO - root - 2017-12-01 06:38:48.669337: step 92520, loss = 0.27, batch loss = 0.14 (50.6 examples/sec; 0.158 sec/batch; 10h:31m:52s remains)
INFO - root - 2017-12-01 06:38:50.241145: step 92530, loss = 0.47, batch loss = 0.34 (52.0 examples/sec; 0.154 sec/batch; 10h:15m:34s remains)
INFO - root - 2017-12-01 06:38:51.819815: step 92540, loss = 0.46, batch loss = 0.33 (49.6 examples/sec; 0.161 sec/batch; 10h:45m:36s remains)
INFO - root - 2017-12-01 06:38:53.371849: step 92550, loss = 0.35, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 10h:35m:57s remains)
INFO - root - 2017-12-01 06:38:54.951281: step 92560, loss = 0.40, batch loss = 0.28 (49.8 examples/sec; 0.161 sec/batch; 10h:42m:41s remains)
INFO - root - 2017-12-01 06:38:56.519085: step 92570, loss = 0.36, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 10h:22m:07s remains)
INFO - root - 2017-12-01 06:38:58.085397: step 92580, loss = 0.52, batch loss = 0.39 (50.1 examples/sec; 0.160 sec/batch; 10h:38m:54s remains)
INFO - root - 2017-12-01 06:38:59.651349: step 92590, loss = 0.30, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 10h:32m:32s remains)
INFO - root - 2017-12-01 06:39:01.220261: step 92600, loss = 0.27, batch loss = 0.14 (50.0 examples/sec; 0.160 sec/batch; 10h:39m:33s remains)
INFO - root - 2017-12-01 06:39:02.885784: step 92610, loss = 0.33, batch loss = 0.20 (51.8 examples/sec; 0.155 sec/batch; 10h:17m:43s remains)
INFO - root - 2017-12-01 06:39:04.431037: step 92620, loss = 0.29, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 10h:22m:02s remains)
INFO - root - 2017-12-01 06:39:05.990430: step 92630, loss = 0.30, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 10h:23m:45s remains)
INFO - root - 2017-12-01 06:39:07.549679: step 92640, loss = 0.34, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 10h:11m:22s remains)
INFO - root - 2017-12-01 06:39:09.129078: step 92650, loss = 0.33, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 10h:17m:17s remains)
INFO - root - 2017-12-01 06:39:10.686095: step 92660, loss = 0.40, batch loss = 0.28 (50.1 examples/sec; 0.160 sec/batch; 10h:38m:26s remains)
INFO - root - 2017-12-01 06:39:12.241030: step 92670, loss = 0.32, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 10h:29m:08s remains)
INFO - root - 2017-12-01 06:39:13.812897: step 92680, loss = 0.31, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 10h:25m:05s remains)
INFO - root - 2017-12-01 06:39:15.373803: step 92690, loss = 0.33, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 10h:35m:38s remains)
INFO - root - 2017-12-01 06:39:16.947954: step 92700, loss = 0.33, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 10h:27m:36s remains)
INFO - root - 2017-12-01 06:39:18.569328: step 92710, loss = 0.30, batch loss = 0.17 (53.1 examples/sec; 0.151 sec/batch; 10h:02m:10s remains)
INFO - root - 2017-12-01 06:39:20.134096: step 92720, loss = 0.44, batch loss = 0.31 (51.1 examples/sec; 0.157 sec/batch; 10h:25m:59s remains)
INFO - root - 2017-12-01 06:39:21.724116: step 92730, loss = 0.29, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 10h:21m:11s remains)
INFO - root - 2017-12-01 06:39:23.284680: step 92740, loss = 0.35, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 10h:31m:13s remains)
INFO - root - 2017-12-01 06:39:24.865315: step 92750, loss = 0.38, batch loss = 0.25 (50.0 examples/sec; 0.160 sec/batch; 10h:39m:05s remains)
INFO - root - 2017-12-01 06:39:26.419222: step 92760, loss = 0.31, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 10h:17m:03s remains)
INFO - root - 2017-12-01 06:39:28.017222: step 92770, loss = 0.34, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 10h:19m:59s remains)
INFO - root - 2017-12-01 06:39:29.568622: step 92780, loss = 0.45, batch loss = 0.32 (50.9 examples/sec; 0.157 sec/batch; 10h:28m:17s remains)
INFO - root - 2017-12-01 06:39:31.126854: step 92790, loss = 0.27, batch loss = 0.14 (50.2 examples/sec; 0.159 sec/batch; 10h:36m:09s remains)
INFO - root - 2017-12-01 06:39:32.691522: step 92800, loss = 0.32, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 10h:12m:11s remains)
INFO - root - 2017-12-01 06:39:34.360187: step 92810, loss = 0.37, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 10h:28m:20s remains)
INFO - root - 2017-12-01 06:39:35.906725: step 92820, loss = 0.38, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 10h:20m:07s remains)
INFO - root - 2017-12-01 06:39:37.471175: step 92830, loss = 0.32, batch loss = 0.20 (53.0 examples/sec; 0.151 sec/batch; 10h:02m:39s remains)
INFO - root - 2017-12-01 06:39:39.046598: step 92840, loss = 0.41, batch loss = 0.28 (51.1 examples/sec; 0.157 sec/batch; 10h:25m:34s remains)
INFO - root - 2017-12-01 06:39:40.605898: step 92850, loss = 0.38, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 10h:32m:03s remains)
INFO - root - 2017-12-01 06:39:42.180127: step 92860, loss = 0.39, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 10h:30m:28s remains)
INFO - root - 2017-12-01 06:39:43.734017: step 92870, loss = 0.29, batch loss = 0.16 (49.4 examples/sec; 0.162 sec/batch; 10h:47m:11s remains)
INFO - root - 2017-12-01 06:39:45.306411: step 92880, loss = 0.36, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 10h:31m:40s remains)
INFO - root - 2017-12-01 06:39:46.869105: step 92890, loss = 0.30, batch loss = 0.17 (50.8 examples/sec; 0.158 sec/batch; 10h:29m:24s remains)
INFO - root - 2017-12-01 06:39:48.418540: step 92900, loss = 0.34, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 10h:35m:12s remains)
INFO - root - 2017-12-01 06:39:50.026351: step 92910, loss = 0.39, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 10h:19m:47s remains)
INFO - root - 2017-12-01 06:39:51.592535: step 92920, loss = 0.31, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 10h:10m:43s remains)
INFO - root - 2017-12-01 06:39:53.154567: step 92930, loss = 0.28, batch loss = 0.15 (51.1 examples/sec; 0.156 sec/batch; 10h:24m:41s remains)
INFO - root - 2017-12-01 06:39:54.717473: step 92940, loss = 0.39, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 10h:18m:40s remains)
INFO - root - 2017-12-01 06:39:56.260612: step 92950, loss = 0.35, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 10h:14m:11s remains)
INFO - root - 2017-12-01 06:39:57.811789: step 92960, loss = 0.29, batch loss = 0.16 (52.1 examples/sec; 0.154 sec/batch; 10h:12m:49s remains)
INFO - root - 2017-12-01 06:39:59.383022: step 92970, loss = 0.31, batch loss = 0.19 (49.2 examples/sec; 0.163 sec/batch; 10h:48m:49s remains)
INFO - root - 2017-12-01 06:40:01.002683: step 92980, loss = 0.32, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 10h:26m:52s remains)
INFO - root - 2017-12-01 06:40:02.567944: step 92990, loss = 0.42, batch loss = 0.30 (50.2 examples/sec; 0.159 sec/batch; 10h:36m:10s remains)
INFO - root - 2017-12-01 06:40:04.119504: step 93000, loss = 0.38, batch loss = 0.25 (49.7 examples/sec; 0.161 sec/batch; 10h:43m:07s remains)
INFO - root - 2017-12-01 06:40:05.773251: step 93010, loss = 0.42, batch loss = 0.30 (47.3 examples/sec; 0.169 sec/batch; 11h:14m:23s remains)
INFO - root - 2017-12-01 06:40:07.339675: step 93020, loss = 0.34, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 10h:11m:19s remains)
INFO - root - 2017-12-01 06:40:08.889943: step 93030, loss = 0.41, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 10h:17m:14s remains)
INFO - root - 2017-12-01 06:40:10.451012: step 93040, loss = 0.33, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 10h:16m:26s remains)
INFO - root - 2017-12-01 06:40:12.031244: step 93050, loss = 0.35, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 10h:26m:40s remains)
INFO - root - 2017-12-01 06:40:13.598820: step 93060, loss = 0.36, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 10h:20m:43s remains)
INFO - root - 2017-12-01 06:40:15.162662: step 93070, loss = 0.40, batch loss = 0.27 (51.8 examples/sec; 0.155 sec/batch; 10h:16m:50s remains)
INFO - root - 2017-12-01 06:40:16.731746: step 93080, loss = 0.37, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 10h:10m:34s remains)
INFO - root - 2017-12-01 06:40:18.290559: step 93090, loss = 0.33, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 10h:18m:10s remains)
INFO - root - 2017-12-01 06:40:19.840289: step 93100, loss = 0.36, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 10h:29m:35s remains)
INFO - root - 2017-12-01 06:40:21.472259: step 93110, loss = 0.36, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 10h:25m:51s remains)
INFO - root - 2017-12-01 06:40:23.017786: step 93120, loss = 0.31, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 10h:25m:45s remains)
INFO - root - 2017-12-01 06:40:24.582561: step 93130, loss = 0.31, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 10h:21m:34s remains)
INFO - root - 2017-12-01 06:40:26.146454: step 93140, loss = 0.35, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 10h:13m:45s remains)
INFO - root - 2017-12-01 06:40:27.714441: step 93150, loss = 0.38, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 10h:26m:29s remains)
INFO - root - 2017-12-01 06:40:29.277338: step 93160, loss = 0.37, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 10h:19m:01s remains)
INFO - root - 2017-12-01 06:40:30.848706: step 93170, loss = 0.35, batch loss = 0.22 (52.4 examples/sec; 0.153 sec/batch; 10h:08m:46s remains)
INFO - root - 2017-12-01 06:40:32.430843: step 93180, loss = 0.31, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 10h:30m:30s remains)
INFO - root - 2017-12-01 06:40:33.979438: step 93190, loss = 0.30, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 10h:25m:04s remains)
INFO - root - 2017-12-01 06:40:35.539301: step 93200, loss = 0.34, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 10h:18m:45s remains)
INFO - root - 2017-12-01 06:40:37.184309: step 93210, loss = 0.36, batch loss = 0.23 (52.1 examples/sec; 0.153 sec/batch; 10h:11m:56s remains)
INFO - root - 2017-12-01 06:40:38.745783: step 93220, loss = 0.38, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 10h:22m:51s remains)
INFO - root - 2017-12-01 06:40:40.315518: step 93230, loss = 0.31, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 10h:32m:30s remains)
INFO - root - 2017-12-01 06:40:41.884792: step 93240, loss = 0.37, batch loss = 0.24 (52.4 examples/sec; 0.153 sec/batch; 10h:09m:19s remains)
INFO - root - 2017-12-01 06:40:43.449111: step 93250, loss = 0.51, batch loss = 0.38 (51.5 examples/sec; 0.155 sec/batch; 10h:19m:47s remains)
INFO - root - 2017-12-01 06:40:45.014225: step 93260, loss = 0.32, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 10h:15m:30s remains)
INFO - root - 2017-12-01 06:40:46.587299: step 93270, loss = 0.33, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 10h:35m:50s remains)
INFO - root - 2017-12-01 06:40:48.154378: step 93280, loss = 0.27, batch loss = 0.14 (50.4 examples/sec; 0.159 sec/batch; 10h:32m:33s remains)
INFO - root - 2017-12-01 06:40:49.696906: step 93290, loss = 0.35, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 10h:07m:51s remains)
INFO - root - 2017-12-01 06:40:51.258540: step 93300, loss = 0.41, batch loss = 0.29 (50.8 examples/sec; 0.158 sec/batch; 10h:28m:08s remains)
INFO - root - 2017-12-01 06:40:52.917760: step 93310, loss = 0.27, batch loss = 0.14 (49.0 examples/sec; 0.163 sec/batch; 10h:50m:41s remains)
INFO - root - 2017-12-01 06:40:54.476325: step 93320, loss = 0.42, batch loss = 0.29 (53.2 examples/sec; 0.150 sec/batch; 9h:59m:37s remains)
INFO - root - 2017-12-01 06:40:56.041116: step 93330, loss = 0.30, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 10h:14m:17s remains)
INFO - root - 2017-12-01 06:40:57.609260: step 93340, loss = 0.34, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 10h:28m:39s remains)
INFO - root - 2017-12-01 06:40:59.176378: step 93350, loss = 0.40, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 10h:19m:12s remains)
INFO - root - 2017-12-01 06:41:00.728704: step 93360, loss = 0.41, batch loss = 0.28 (52.1 examples/sec; 0.154 sec/batch; 10h:12m:17s remains)
INFO - root - 2017-12-01 06:41:02.304712: step 93370, loss = 0.49, batch loss = 0.36 (47.9 examples/sec; 0.167 sec/batch; 11h:05m:21s remains)
INFO - root - 2017-12-01 06:41:03.907724: step 93380, loss = 0.34, batch loss = 0.21 (50.0 examples/sec; 0.160 sec/batch; 10h:38m:07s remains)
INFO - root - 2017-12-01 06:41:05.471263: step 93390, loss = 0.49, batch loss = 0.37 (50.3 examples/sec; 0.159 sec/batch; 10h:34m:08s remains)
INFO - root - 2017-12-01 06:41:07.027332: step 93400, loss = 0.39, batch loss = 0.27 (52.3 examples/sec; 0.153 sec/batch; 10h:10m:02s remains)
INFO - root - 2017-12-01 06:41:08.680056: step 93410, loss = 0.43, batch loss = 0.30 (51.1 examples/sec; 0.157 sec/batch; 10h:24m:02s remains)
INFO - root - 2017-12-01 06:41:10.233479: step 93420, loss = 0.34, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 10h:20m:34s remains)
INFO - root - 2017-12-01 06:41:11.788236: step 93430, loss = 0.31, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 10h:29m:57s remains)
INFO - root - 2017-12-01 06:41:13.370245: step 93440, loss = 0.44, batch loss = 0.32 (51.1 examples/sec; 0.157 sec/batch; 10h:23m:58s remains)
INFO - root - 2017-12-01 06:41:14.925578: step 93450, loss = 0.38, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 10h:08m:51s remains)
INFO - root - 2017-12-01 06:41:16.490898: step 93460, loss = 0.32, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 10h:24m:44s remains)
INFO - root - 2017-12-01 06:41:18.068486: step 93470, loss = 0.41, batch loss = 0.28 (50.8 examples/sec; 0.157 sec/batch; 10h:27m:23s remains)
INFO - root - 2017-12-01 06:41:19.626751: step 93480, loss = 0.35, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 10h:05m:57s remains)
INFO - root - 2017-12-01 06:41:21.199736: step 93490, loss = 0.32, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 10h:25m:17s remains)
INFO - root - 2017-12-01 06:41:22.753009: step 93500, loss = 0.35, batch loss = 0.23 (52.1 examples/sec; 0.153 sec/batch; 10h:11m:08s remains)
INFO - root - 2017-12-01 06:41:24.411626: step 93510, loss = 0.42, batch loss = 0.29 (50.8 examples/sec; 0.157 sec/batch; 10h:26m:47s remains)
INFO - root - 2017-12-01 06:41:25.979551: step 93520, loss = 0.34, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 10h:20m:50s remains)
INFO - root - 2017-12-01 06:41:27.548543: step 93530, loss = 0.44, batch loss = 0.32 (51.6 examples/sec; 0.155 sec/batch; 10h:17m:52s remains)
INFO - root - 2017-12-01 06:41:29.094682: step 93540, loss = 0.35, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 10h:25m:55s remains)
INFO - root - 2017-12-01 06:41:30.657278: step 93550, loss = 0.40, batch loss = 0.27 (52.3 examples/sec; 0.153 sec/batch; 10h:09m:03s remains)
INFO - root - 2017-12-01 06:41:32.225635: step 93560, loss = 0.35, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 10h:17m:32s remains)
INFO - root - 2017-12-01 06:41:33.809752: step 93570, loss = 0.32, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 10h:28m:24s remains)
INFO - root - 2017-12-01 06:41:35.365570: step 93580, loss = 0.38, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 10h:29m:38s remains)
INFO - root - 2017-12-01 06:41:36.931657: step 93590, loss = 0.42, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 10h:18m:20s remains)
INFO - root - 2017-12-01 06:41:38.518392: step 93600, loss = 0.36, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 10h:19m:58s remains)
INFO - root - 2017-12-01 06:41:40.112610: step 93610, loss = 0.36, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 10h:24m:31s remains)
INFO - root - 2017-12-01 06:41:41.683117: step 93620, loss = 0.36, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 10h:18m:16s remains)
INFO - root - 2017-12-01 06:41:43.230567: step 93630, loss = 0.27, batch loss = 0.14 (51.2 examples/sec; 0.156 sec/batch; 10h:21m:32s remains)
INFO - root - 2017-12-01 06:41:44.781320: step 93640, loss = 0.30, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 10h:20m:51s remains)
INFO - root - 2017-12-01 06:41:46.346145: step 93650, loss = 0.31, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 10h:29m:23s remains)
INFO - root - 2017-12-01 06:41:47.916769: step 93660, loss = 0.34, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 10h:19m:54s remains)
INFO - root - 2017-12-01 06:41:49.472896: step 93670, loss = 0.38, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 10h:28m:21s remains)
INFO - root - 2017-12-01 06:41:51.029860: step 93680, loss = 0.33, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 10h:21m:35s remains)
INFO - root - 2017-12-01 06:41:52.587716: step 93690, loss = 0.45, batch loss = 0.32 (49.9 examples/sec; 0.160 sec/batch; 10h:37m:52s remains)
INFO - root - 2017-12-01 06:41:54.156837: step 93700, loss = 0.35, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 10h:22m:17s remains)
INFO - root - 2017-12-01 06:41:55.774572: step 93710, loss = 0.32, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 10h:42m:45s remains)
INFO - root - 2017-12-01 06:41:57.327926: step 93720, loss = 0.42, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 10h:18m:24s remains)
INFO - root - 2017-12-01 06:41:58.886760: step 93730, loss = 0.26, batch loss = 0.13 (54.0 examples/sec; 0.148 sec/batch; 9h:49m:54s remains)
INFO - root - 2017-12-01 06:42:00.455332: step 93740, loss = 0.33, batch loss = 0.21 (52.8 examples/sec; 0.152 sec/batch; 10h:03m:18s remains)
INFO - root - 2017-12-01 06:42:02.023109: step 93750, loss = 0.31, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 10h:25m:30s remains)
INFO - root - 2017-12-01 06:42:03.586039: step 93760, loss = 0.36, batch loss = 0.23 (49.2 examples/sec; 0.163 sec/batch; 10h:47m:24s remains)
INFO - root - 2017-12-01 06:42:05.153729: step 93770, loss = 0.29, batch loss = 0.17 (49.7 examples/sec; 0.161 sec/batch; 10h:40m:53s remains)
INFO - root - 2017-12-01 06:42:06.736897: step 93780, loss = 0.32, batch loss = 0.19 (52.1 examples/sec; 0.154 sec/batch; 10h:11m:17s remains)
INFO - root - 2017-12-01 06:42:08.289114: step 93790, loss = 0.35, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 10h:33m:02s remains)
INFO - root - 2017-12-01 06:42:09.863114: step 93800, loss = 0.35, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 10h:27m:48s remains)
INFO - root - 2017-12-01 06:42:11.505195: step 93810, loss = 0.40, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 10h:16m:12s remains)
INFO - root - 2017-12-01 06:42:13.085395: step 93820, loss = 0.36, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 10h:16m:42s remains)
INFO - root - 2017-12-01 06:42:14.657394: step 93830, loss = 0.45, batch loss = 0.33 (50.7 examples/sec; 0.158 sec/batch; 10h:27m:23s remains)
INFO - root - 2017-12-01 06:42:16.216122: step 93840, loss = 0.33, batch loss = 0.20 (52.1 examples/sec; 0.153 sec/batch; 10h:10m:25s remains)
INFO - root - 2017-12-01 06:42:17.808991: step 93850, loss = 0.38, batch loss = 0.25 (52.2 examples/sec; 0.153 sec/batch; 10h:09m:31s remains)
INFO - root - 2017-12-01 06:42:19.361667: step 93860, loss = 0.31, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 10h:16m:14s remains)
INFO - root - 2017-12-01 06:42:20.939011: step 93870, loss = 0.29, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 10h:17m:08s remains)
INFO - root - 2017-12-01 06:42:22.529201: step 93880, loss = 0.35, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 10h:31m:24s remains)
INFO - root - 2017-12-01 06:42:24.103429: step 93890, loss = 0.34, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 10h:09m:03s remains)
INFO - root - 2017-12-01 06:42:25.698231: step 93900, loss = 0.31, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 10h:25m:35s remains)
INFO - root - 2017-12-01 06:42:27.332908: step 93910, loss = 0.36, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 10h:24m:06s remains)
INFO - root - 2017-12-01 06:42:28.899940: step 93920, loss = 0.37, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 10h:21m:07s remains)
INFO - root - 2017-12-01 06:42:30.474038: step 93930, loss = 0.42, batch loss = 0.30 (48.7 examples/sec; 0.164 sec/batch; 10h:52m:32s remains)
INFO - root - 2017-12-01 06:42:32.041345: step 93940, loss = 0.35, batch loss = 0.22 (52.8 examples/sec; 0.152 sec/batch; 10h:02m:29s remains)
INFO - root - 2017-12-01 06:42:33.588808: step 93950, loss = 0.40, batch loss = 0.28 (52.4 examples/sec; 0.153 sec/batch; 10h:07m:06s remains)
INFO - root - 2017-12-01 06:42:35.166457: step 93960, loss = 0.30, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 10h:31m:04s remains)
INFO - root - 2017-12-01 06:42:36.728220: step 93970, loss = 0.46, batch loss = 0.33 (51.2 examples/sec; 0.156 sec/batch; 10h:20m:36s remains)
INFO - root - 2017-12-01 06:42:38.296801: step 93980, loss = 0.35, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 10h:22m:54s remains)
INFO - root - 2017-12-01 06:42:39.846035: step 93990, loss = 0.29, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 10h:20m:00s remains)
INFO - root - 2017-12-01 06:42:41.410060: step 94000, loss = 0.35, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 10h:19m:32s remains)
INFO - root - 2017-12-01 06:42:43.035261: step 94010, loss = 0.33, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 10h:16m:26s remains)
INFO - root - 2017-12-01 06:42:44.583660: step 94020, loss = 0.43, batch loss = 0.31 (51.9 examples/sec; 0.154 sec/batch; 10h:12m:40s remains)
INFO - root - 2017-12-01 06:42:46.167593: step 94030, loss = 0.43, batch loss = 0.31 (51.5 examples/sec; 0.155 sec/batch; 10h:17m:25s remains)
INFO - root - 2017-12-01 06:42:47.746139: step 94040, loss = 0.62, batch loss = 0.49 (49.8 examples/sec; 0.161 sec/batch; 10h:38m:45s remains)
INFO - root - 2017-12-01 06:42:49.296636: step 94050, loss = 0.30, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 10h:17m:05s remains)
INFO - root - 2017-12-01 06:42:50.860957: step 94060, loss = 0.42, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 10h:15m:49s remains)
INFO - root - 2017-12-01 06:42:52.417896: step 94070, loss = 0.29, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 10h:15m:42s remains)
INFO - root - 2017-12-01 06:42:53.996193: step 94080, loss = 0.28, batch loss = 0.15 (50.7 examples/sec; 0.158 sec/batch; 10h:27m:18s remains)
INFO - root - 2017-12-01 06:42:55.555611: step 94090, loss = 0.29, batch loss = 0.16 (51.8 examples/sec; 0.155 sec/batch; 10h:13m:57s remains)
INFO - root - 2017-12-01 06:42:57.163092: step 94100, loss = 0.34, batch loss = 0.21 (48.9 examples/sec; 0.164 sec/batch; 10h:50m:35s remains)
INFO - root - 2017-12-01 06:42:58.770425: step 94110, loss = 0.30, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 10h:31m:16s remains)
INFO - root - 2017-12-01 06:43:00.338518: step 94120, loss = 0.30, batch loss = 0.17 (50.8 examples/sec; 0.157 sec/batch; 10h:25m:27s remains)
INFO - root - 2017-12-01 06:43:01.918641: step 94130, loss = 0.39, batch loss = 0.26 (45.9 examples/sec; 0.174 sec/batch; 11h:31m:45s remains)
INFO - root - 2017-12-01 06:43:03.490004: step 94140, loss = 0.34, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 10h:14m:25s remains)
INFO - root - 2017-12-01 06:43:05.074408: step 94150, loss = 0.31, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 10h:19m:53s remains)
INFO - root - 2017-12-01 06:43:06.645307: step 94160, loss = 0.30, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 10h:20m:09s remains)
INFO - root - 2017-12-01 06:43:08.208211: step 94170, loss = 0.32, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 10h:19m:18s remains)
INFO - root - 2017-12-01 06:43:09.778613: step 94180, loss = 0.30, batch loss = 0.18 (49.8 examples/sec; 0.161 sec/batch; 10h:38m:23s remains)
INFO - root - 2017-12-01 06:43:11.362870: step 94190, loss = 0.36, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 10h:19m:56s remains)
INFO - root - 2017-12-01 06:43:12.931935: step 94200, loss = 0.37, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 10h:17m:43s remains)
INFO - root - 2017-12-01 06:43:14.573829: step 94210, loss = 0.49, batch loss = 0.36 (50.3 examples/sec; 0.159 sec/batch; 10h:32m:03s remains)
INFO - root - 2017-12-01 06:43:16.140872: step 94220, loss = 0.40, batch loss = 0.28 (50.3 examples/sec; 0.159 sec/batch; 10h:31m:37s remains)
INFO - root - 2017-12-01 06:43:17.704536: step 94230, loss = 0.29, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 10h:30m:01s remains)
INFO - root - 2017-12-01 06:43:19.272276: step 94240, loss = 0.38, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 10h:18m:13s remains)
INFO - root - 2017-12-01 06:43:20.861916: step 94250, loss = 0.29, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 10h:15m:05s remains)
INFO - root - 2017-12-01 06:43:22.452227: step 94260, loss = 0.37, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 10h:15m:32s remains)
INFO - root - 2017-12-01 06:43:24.004313: step 94270, loss = 0.34, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 10h:35m:32s remains)
INFO - root - 2017-12-01 06:43:25.580919: step 94280, loss = 0.28, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 10h:15m:55s remains)
INFO - root - 2017-12-01 06:43:27.172231: step 94290, loss = 0.35, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 10h:16m:32s remains)
INFO - root - 2017-12-01 06:43:28.742197: step 94300, loss = 0.33, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 10h:22m:31s remains)
INFO - root - 2017-12-01 06:43:30.401468: step 94310, loss = 0.31, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 10h:15m:20s remains)
INFO - root - 2017-12-01 06:43:31.980693: step 94320, loss = 0.36, batch loss = 0.24 (49.0 examples/sec; 0.163 sec/batch; 10h:48m:42s remains)
INFO - root - 2017-12-01 06:43:33.538496: step 94330, loss = 0.26, batch loss = 0.14 (51.3 examples/sec; 0.156 sec/batch; 10h:18m:29s remains)
INFO - root - 2017-12-01 06:43:35.102029: step 94340, loss = 0.32, batch loss = 0.19 (47.0 examples/sec; 0.170 sec/batch; 11h:15m:33s remains)
INFO - root - 2017-12-01 06:43:36.721286: step 94350, loss = 0.32, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 10h:26m:11s remains)
INFO - root - 2017-12-01 06:43:38.285663: step 94360, loss = 0.34, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 10h:19m:08s remains)
INFO - root - 2017-12-01 06:43:39.857598: step 94370, loss = 0.34, batch loss = 0.22 (53.3 examples/sec; 0.150 sec/batch; 9h:55m:40s remains)
INFO - root - 2017-12-01 06:43:41.418381: step 94380, loss = 0.31, batch loss = 0.18 (49.7 examples/sec; 0.161 sec/batch; 10h:38m:23s remains)
INFO - root - 2017-12-01 06:43:43.003317: step 94390, loss = 0.28, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 10h:11m:25s remains)
INFO - root - 2017-12-01 06:43:44.589173: step 94400, loss = 0.26, batch loss = 0.14 (50.4 examples/sec; 0.159 sec/batch; 10h:30m:16s remains)
INFO - root - 2017-12-01 06:43:46.221952: step 94410, loss = 0.33, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 10h:19m:40s remains)
INFO - root - 2017-12-01 06:43:47.809946: step 94420, loss = 0.34, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 10h:30m:58s remains)
INFO - root - 2017-12-01 06:43:49.374888: step 94430, loss = 0.46, batch loss = 0.33 (51.4 examples/sec; 0.156 sec/batch; 10h:17m:45s remains)
INFO - root - 2017-12-01 06:43:50.947457: step 94440, loss = 0.30, batch loss = 0.17 (53.0 examples/sec; 0.151 sec/batch; 9h:59m:26s remains)
INFO - root - 2017-12-01 06:43:52.518187: step 94450, loss = 0.25, batch loss = 0.12 (50.3 examples/sec; 0.159 sec/batch; 10h:30m:28s remains)
INFO - root - 2017-12-01 06:43:54.081544: step 94460, loss = 0.38, batch loss = 0.26 (49.8 examples/sec; 0.161 sec/batch; 10h:37m:24s remains)
INFO - root - 2017-12-01 06:43:55.654327: step 94470, loss = 0.31, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 10h:32m:05s remains)
INFO - root - 2017-12-01 06:43:57.241156: step 94480, loss = 0.40, batch loss = 0.27 (52.3 examples/sec; 0.153 sec/batch; 10h:06m:24s remains)
INFO - root - 2017-12-01 06:43:58.804742: step 94490, loss = 0.36, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 10h:19m:50s remains)
INFO - root - 2017-12-01 06:44:00.360836: step 94500, loss = 0.41, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 10h:28m:42s remains)
INFO - root - 2017-12-01 06:44:01.993038: step 94510, loss = 0.29, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 10h:23m:00s remains)
INFO - root - 2017-12-01 06:44:03.557395: step 94520, loss = 0.30, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 10h:22m:27s remains)
INFO - root - 2017-12-01 06:44:05.119943: step 94530, loss = 0.26, batch loss = 0.14 (51.1 examples/sec; 0.157 sec/batch; 10h:20m:43s remains)
INFO - root - 2017-12-01 06:44:06.678389: step 94540, loss = 0.31, batch loss = 0.18 (52.7 examples/sec; 0.152 sec/batch; 10h:02m:13s remains)
INFO - root - 2017-12-01 06:44:08.246844: step 94550, loss = 0.39, batch loss = 0.27 (52.1 examples/sec; 0.153 sec/batch; 10h:08m:25s remains)
INFO - root - 2017-12-01 06:44:09.825498: step 94560, loss = 0.28, batch loss = 0.15 (52.2 examples/sec; 0.153 sec/batch; 10h:08m:07s remains)
INFO - root - 2017-12-01 06:44:11.395675: step 94570, loss = 0.37, batch loss = 0.25 (50.3 examples/sec; 0.159 sec/batch; 10h:30m:31s remains)
INFO - root - 2017-12-01 06:44:12.968302: step 94580, loss = 0.38, batch loss = 0.25 (49.6 examples/sec; 0.161 sec/batch; 10h:40m:07s remains)
INFO - root - 2017-12-01 06:44:14.532887: step 94590, loss = 0.31, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 10h:05m:35s remains)
INFO - root - 2017-12-01 06:44:16.098633: step 94600, loss = 0.34, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 10h:16m:17s remains)
INFO - root - 2017-12-01 06:44:17.740225: step 94610, loss = 0.42, batch loss = 0.29 (49.7 examples/sec; 0.161 sec/batch; 10h:38m:04s remains)
INFO - root - 2017-12-01 06:44:19.297027: step 94620, loss = 0.37, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 10h:20m:08s remains)
INFO - root - 2017-12-01 06:44:20.856487: step 94630, loss = 0.33, batch loss = 0.20 (53.5 examples/sec; 0.149 sec/batch; 9h:52m:40s remains)
INFO - root - 2017-12-01 06:44:22.441920: step 94640, loss = 0.30, batch loss = 0.18 (50.0 examples/sec; 0.160 sec/batch; 10h:34m:03s remains)
INFO - root - 2017-12-01 06:44:24.002284: step 94650, loss = 0.34, batch loss = 0.22 (49.7 examples/sec; 0.161 sec/batch; 10h:37m:56s remains)
INFO - root - 2017-12-01 06:44:25.564979: step 94660, loss = 0.33, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 10h:30m:53s remains)
INFO - root - 2017-12-01 06:44:27.147792: step 94670, loss = 0.39, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 10h:22m:54s remains)
INFO - root - 2017-12-01 06:44:28.710932: step 94680, loss = 0.31, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 10h:20m:40s remains)
INFO - root - 2017-12-01 06:44:30.266796: step 94690, loss = 0.29, batch loss = 0.16 (52.4 examples/sec; 0.153 sec/batch; 10h:05m:12s remains)
INFO - root - 2017-12-01 06:44:31.832733: step 94700, loss = 0.45, batch loss = 0.32 (50.2 examples/sec; 0.159 sec/batch; 10h:31m:59s remains)
INFO - root - 2017-12-01 06:44:33.485580: step 94710, loss = 0.40, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 10h:25m:58s remains)
INFO - root - 2017-12-01 06:44:35.038258: step 94720, loss = 0.33, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 10h:28m:54s remains)
INFO - root - 2017-12-01 06:44:36.587913: step 94730, loss = 0.35, batch loss = 0.22 (49.6 examples/sec; 0.161 sec/batch; 10h:38m:34s remains)
INFO - root - 2017-12-01 06:44:38.130698: step 94740, loss = 0.30, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 10h:11m:43s remains)
INFO - root - 2017-12-01 06:44:39.701304: step 94750, loss = 0.44, batch loss = 0.31 (52.7 examples/sec; 0.152 sec/batch; 10h:01m:24s remains)
INFO - root - 2017-12-01 06:44:41.258757: step 94760, loss = 0.29, batch loss = 0.17 (52.7 examples/sec; 0.152 sec/batch; 10h:01m:00s remains)
INFO - root - 2017-12-01 06:44:42.830522: step 94770, loss = 0.36, batch loss = 0.23 (50.1 examples/sec; 0.160 sec/batch; 10h:33m:01s remains)
INFO - root - 2017-12-01 06:44:44.389889: step 94780, loss = 0.32, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 10h:12m:56s remains)
INFO - root - 2017-12-01 06:44:45.940990: step 94790, loss = 0.38, batch loss = 0.26 (52.4 examples/sec; 0.153 sec/batch; 10h:04m:24s remains)
INFO - root - 2017-12-01 06:44:47.494733: step 94800, loss = 0.40, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 10h:15m:46s remains)
INFO - root - 2017-12-01 06:44:49.111165: step 94810, loss = 0.30, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 10h:20m:57s remains)
INFO - root - 2017-12-01 06:44:50.679345: step 94820, loss = 0.35, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 10h:15m:56s remains)
INFO - root - 2017-12-01 06:44:52.248294: step 94830, loss = 0.43, batch loss = 0.31 (51.3 examples/sec; 0.156 sec/batch; 10h:17m:37s remains)
INFO - root - 2017-12-01 06:44:53.808202: step 94840, loss = 0.30, batch loss = 0.17 (52.9 examples/sec; 0.151 sec/batch; 9h:58m:58s remains)
INFO - root - 2017-12-01 06:44:55.363943: step 94850, loss = 0.32, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 10h:03m:37s remains)
INFO - root - 2017-12-01 06:44:56.934982: step 94860, loss = 0.48, batch loss = 0.36 (50.5 examples/sec; 0.159 sec/batch; 10h:27m:56s remains)
INFO - root - 2017-12-01 06:44:58.486984: step 94870, loss = 0.30, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 10h:23m:56s remains)
INFO - root - 2017-12-01 06:45:00.049025: step 94880, loss = 0.32, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 10h:19m:52s remains)
INFO - root - 2017-12-01 06:45:01.616617: step 94890, loss = 0.35, batch loss = 0.22 (52.4 examples/sec; 0.153 sec/batch; 10h:04m:27s remains)
INFO - root - 2017-12-01 06:45:03.173803: step 94900, loss = 0.27, batch loss = 0.14 (51.6 examples/sec; 0.155 sec/batch; 10h:13m:23s remains)
INFO - root - 2017-12-01 06:45:04.800871: step 94910, loss = 0.34, batch loss = 0.21 (51.8 examples/sec; 0.155 sec/batch; 10h:11m:55s remains)
INFO - root - 2017-12-01 06:45:06.369240: step 94920, loss = 0.44, batch loss = 0.32 (52.6 examples/sec; 0.152 sec/batch; 10h:01m:46s remains)
INFO - root - 2017-12-01 06:45:07.959848: step 94930, loss = 0.37, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 10h:24m:38s remains)
INFO - root - 2017-12-01 06:45:09.527857: step 94940, loss = 0.33, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 10h:21m:03s remains)
INFO - root - 2017-12-01 06:45:11.111639: step 94950, loss = 0.28, batch loss = 0.15 (43.6 examples/sec; 0.183 sec/batch; 12h:06m:00s remains)
INFO - root - 2017-12-01 06:45:12.688692: step 94960, loss = 0.42, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 10h:17m:59s remains)
INFO - root - 2017-12-01 06:45:14.261728: step 94970, loss = 0.31, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 10h:23m:21s remains)
INFO - root - 2017-12-01 06:45:15.819889: step 94980, loss = 0.36, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 10h:16m:20s remains)
INFO - root - 2017-12-01 06:45:17.388845: step 94990, loss = 0.36, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 10h:17m:28s remains)
INFO - root - 2017-12-01 06:45:18.972846: step 95000, loss = 0.34, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 10h:09m:33s remains)
INFO - root - 2017-12-01 06:45:20.589583: step 95010, loss = 0.28, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 10h:24m:22s remains)
INFO - root - 2017-12-01 06:45:22.158373: step 95020, loss = 0.34, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 10h:28m:35s remains)
INFO - root - 2017-12-01 06:45:23.714894: step 95030, loss = 0.49, batch loss = 0.36 (52.5 examples/sec; 0.152 sec/batch; 10h:02m:46s remains)
INFO - root - 2017-12-01 06:45:25.282226: step 95040, loss = 0.28, batch loss = 0.16 (50.5 examples/sec; 0.158 sec/batch; 10h:26m:33s remains)
INFO - root - 2017-12-01 06:45:26.848827: step 95050, loss = 0.56, batch loss = 0.44 (51.8 examples/sec; 0.154 sec/batch; 10h:11m:12s remains)
INFO - root - 2017-12-01 06:45:28.425951: step 95060, loss = 0.42, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 10h:17m:35s remains)
INFO - root - 2017-12-01 06:45:29.972523: step 95070, loss = 0.29, batch loss = 0.16 (53.4 examples/sec; 0.150 sec/batch; 9h:52m:28s remains)
INFO - root - 2017-12-01 06:45:31.549499: step 95080, loss = 0.36, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 10h:16m:51s remains)
INFO - root - 2017-12-01 06:45:33.109526: step 95090, loss = 0.31, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 10h:23m:14s remains)
INFO - root - 2017-12-01 06:45:34.686040: step 95100, loss = 0.33, batch loss = 0.20 (49.7 examples/sec; 0.161 sec/batch; 10h:36m:58s remains)
INFO - root - 2017-12-01 06:45:36.317482: step 95110, loss = 0.39, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 10h:27m:51s remains)
INFO - root - 2017-12-01 06:45:37.883841: step 95120, loss = 0.32, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 10h:10m:37s remains)
INFO - root - 2017-12-01 06:45:39.441636: step 95130, loss = 0.30, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 10h:21m:26s remains)
INFO - root - 2017-12-01 06:45:41.016700: step 95140, loss = 0.37, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 10h:11m:35s remains)
INFO - root - 2017-12-01 06:45:42.584687: step 95150, loss = 0.39, batch loss = 0.26 (52.5 examples/sec; 0.152 sec/batch; 10h:03m:06s remains)
INFO - root - 2017-12-01 06:45:44.145100: step 95160, loss = 0.42, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 10h:21m:20s remains)
INFO - root - 2017-12-01 06:45:45.703734: step 95170, loss = 0.41, batch loss = 0.28 (51.8 examples/sec; 0.154 sec/batch; 10h:10m:30s remains)
INFO - root - 2017-12-01 06:45:47.276474: step 95180, loss = 0.31, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 10h:13m:40s remains)
INFO - root - 2017-12-01 06:45:48.844106: step 95190, loss = 0.40, batch loss = 0.27 (48.2 examples/sec; 0.166 sec/batch; 10h:56m:13s remains)
INFO - root - 2017-12-01 06:45:50.418766: step 95200, loss = 0.38, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 10h:10m:52s remains)
INFO - root - 2017-12-01 06:45:52.067418: step 95210, loss = 0.37, batch loss = 0.25 (50.1 examples/sec; 0.160 sec/batch; 10h:32m:04s remains)
INFO - root - 2017-12-01 06:45:53.633178: step 95220, loss = 0.35, batch loss = 0.22 (53.2 examples/sec; 0.150 sec/batch; 9h:54m:12s remains)
INFO - root - 2017-12-01 06:45:55.211267: step 95230, loss = 0.36, batch loss = 0.24 (48.2 examples/sec; 0.166 sec/batch; 10h:56m:06s remains)
INFO - root - 2017-12-01 06:45:56.776818: step 95240, loss = 0.30, batch loss = 0.18 (51.1 examples/sec; 0.156 sec/batch; 10h:18m:38s remains)
INFO - root - 2017-12-01 06:45:58.326330: step 95250, loss = 0.31, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 10h:14m:31s remains)
INFO - root - 2017-12-01 06:45:59.886934: step 95260, loss = 0.36, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 10h:09m:11s remains)
INFO - root - 2017-12-01 06:46:01.466294: step 95270, loss = 0.28, batch loss = 0.16 (50.2 examples/sec; 0.159 sec/batch; 10h:29m:37s remains)
INFO - root - 2017-12-01 06:46:03.021602: step 95280, loss = 0.35, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 10h:24m:52s remains)
INFO - root - 2017-12-01 06:46:04.596611: step 95290, loss = 0.40, batch loss = 0.27 (48.9 examples/sec; 0.163 sec/batch; 10h:46m:16s remains)
INFO - root - 2017-12-01 06:46:06.171112: step 95300, loss = 0.42, batch loss = 0.30 (50.3 examples/sec; 0.159 sec/batch; 10h:28m:26s remains)
INFO - root - 2017-12-01 06:46:07.790959: step 95310, loss = 0.32, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 10h:08m:22s remains)
INFO - root - 2017-12-01 06:46:09.360713: step 95320, loss = 0.43, batch loss = 0.30 (51.8 examples/sec; 0.155 sec/batch; 10h:11m:01s remains)
INFO - root - 2017-12-01 06:46:10.938558: step 95330, loss = 0.43, batch loss = 0.30 (48.4 examples/sec; 0.165 sec/batch; 10h:53m:13s remains)
INFO - root - 2017-12-01 06:46:12.501905: step 95340, loss = 0.31, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 10h:27m:19s remains)
INFO - root - 2017-12-01 06:46:14.075399: step 95350, loss = 0.37, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 10h:01m:41s remains)
INFO - root - 2017-12-01 06:46:15.655346: step 95360, loss = 0.32, batch loss = 0.19 (52.1 examples/sec; 0.153 sec/batch; 10h:06m:38s remains)
INFO - root - 2017-12-01 06:46:17.224204: step 95370, loss = 0.34, batch loss = 0.21 (49.4 examples/sec; 0.162 sec/batch; 10h:39m:36s remains)
INFO - root - 2017-12-01 06:46:18.793130: step 95380, loss = 0.33, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 10h:07m:23s remains)
INFO - root - 2017-12-01 06:46:20.351722: step 95390, loss = 0.35, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 10h:11m:01s remains)
INFO - root - 2017-12-01 06:46:21.933853: step 95400, loss = 0.33, batch loss = 0.21 (49.8 examples/sec; 0.161 sec/batch; 10h:34m:39s remains)
INFO - root - 2017-12-01 06:46:23.556728: step 95410, loss = 0.44, batch loss = 0.32 (52.4 examples/sec; 0.153 sec/batch; 10h:03m:19s remains)
INFO - root - 2017-12-01 06:46:25.116191: step 95420, loss = 0.28, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 10h:17m:41s remains)
INFO - root - 2017-12-01 06:46:26.708267: step 95430, loss = 0.36, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 10h:20m:00s remains)
INFO - root - 2017-12-01 06:46:28.272580: step 95440, loss = 0.34, batch loss = 0.22 (49.0 examples/sec; 0.163 sec/batch; 10h:45m:35s remains)
INFO - root - 2017-12-01 06:46:29.838311: step 95450, loss = 0.46, batch loss = 0.33 (53.0 examples/sec; 0.151 sec/batch; 9h:56m:02s remains)
INFO - root - 2017-12-01 06:46:31.410991: step 95460, loss = 0.40, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 10h:12m:47s remains)
INFO - root - 2017-12-01 06:46:32.975036: step 95470, loss = 0.41, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 10h:23m:44s remains)
INFO - root - 2017-12-01 06:46:34.533492: step 95480, loss = 0.41, batch loss = 0.28 (49.8 examples/sec; 0.161 sec/batch; 10h:34m:51s remains)
INFO - root - 2017-12-01 06:46:36.089752: step 95490, loss = 0.34, batch loss = 0.21 (49.2 examples/sec; 0.163 sec/batch; 10h:42m:39s remains)
INFO - root - 2017-12-01 06:46:37.653666: step 95500, loss = 0.42, batch loss = 0.30 (52.0 examples/sec; 0.154 sec/batch; 10h:07m:37s remains)
INFO - root - 2017-12-01 06:46:39.271873: step 95510, loss = 0.36, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 10h:25m:49s remains)
INFO - root - 2017-12-01 06:46:40.843599: step 95520, loss = 0.34, batch loss = 0.21 (47.2 examples/sec; 0.170 sec/batch; 11h:09m:51s remains)
INFO - root - 2017-12-01 06:46:42.401469: step 95530, loss = 0.42, batch loss = 0.29 (52.1 examples/sec; 0.154 sec/batch; 10h:06m:41s remains)
INFO - root - 2017-12-01 06:46:43.956070: step 95540, loss = 0.32, batch loss = 0.20 (53.5 examples/sec; 0.150 sec/batch; 9h:50m:54s remains)
INFO - root - 2017-12-01 06:46:45.514916: step 95550, loss = 0.28, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 10h:07m:04s remains)
INFO - root - 2017-12-01 06:46:47.071101: step 95560, loss = 0.41, batch loss = 0.28 (51.1 examples/sec; 0.157 sec/batch; 10h:18m:32s remains)
INFO - root - 2017-12-01 06:46:48.623742: step 95570, loss = 0.32, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 10h:24m:30s remains)
INFO - root - 2017-12-01 06:46:50.195179: step 95580, loss = 0.31, batch loss = 0.19 (52.9 examples/sec; 0.151 sec/batch; 9h:56m:56s remains)
INFO - root - 2017-12-01 06:46:51.745388: step 95590, loss = 0.48, batch loss = 0.35 (52.1 examples/sec; 0.154 sec/batch; 10h:06m:22s remains)
INFO - root - 2017-12-01 06:46:53.326207: step 95600, loss = 0.32, batch loss = 0.19 (52.7 examples/sec; 0.152 sec/batch; 9h:59m:07s remains)
INFO - root - 2017-12-01 06:46:54.931086: step 95610, loss = 0.31, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 10h:14m:09s remains)
INFO - root - 2017-12-01 06:46:56.495751: step 95620, loss = 0.35, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 10h:26m:09s remains)
INFO - root - 2017-12-01 06:46:58.060855: step 95630, loss = 0.38, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 10h:11m:10s remains)
INFO - root - 2017-12-01 06:46:59.615231: step 95640, loss = 0.42, batch loss = 0.29 (50.8 examples/sec; 0.158 sec/batch; 10h:21m:57s remains)
INFO - root - 2017-12-01 06:47:01.197414: step 95650, loss = 0.38, batch loss = 0.26 (48.9 examples/sec; 0.164 sec/batch; 10h:45m:45s remains)
INFO - root - 2017-12-01 06:47:02.750248: step 95660, loss = 0.34, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 10h:30m:45s remains)
INFO - root - 2017-12-01 06:47:04.321927: step 95670, loss = 0.35, batch loss = 0.23 (49.6 examples/sec; 0.161 sec/batch; 10h:36m:57s remains)
INFO - root - 2017-12-01 06:47:05.894189: step 95680, loss = 0.34, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 10h:00m:11s remains)
INFO - root - 2017-12-01 06:47:07.468146: step 95690, loss = 0.37, batch loss = 0.25 (50.8 examples/sec; 0.157 sec/batch; 10h:21m:10s remains)
INFO - root - 2017-12-01 06:47:09.015014: step 95700, loss = 0.39, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 10h:18m:42s remains)
INFO - root - 2017-12-01 06:47:10.619166: step 95710, loss = 0.30, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 10h:25m:08s remains)
INFO - root - 2017-12-01 06:47:12.184601: step 95720, loss = 0.31, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 10h:08m:07s remains)
INFO - root - 2017-12-01 06:47:13.734687: step 95730, loss = 0.34, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 10h:08m:27s remains)
INFO - root - 2017-12-01 06:47:15.299030: step 95740, loss = 0.30, batch loss = 0.17 (50.7 examples/sec; 0.158 sec/batch; 10h:22m:03s remains)
INFO - root - 2017-12-01 06:47:16.890229: step 95750, loss = 0.28, batch loss = 0.16 (48.3 examples/sec; 0.166 sec/batch; 10h:53m:52s remains)
INFO - root - 2017-12-01 06:47:18.466398: step 95760, loss = 0.47, batch loss = 0.34 (51.2 examples/sec; 0.156 sec/batch; 10h:16m:32s remains)
INFO - root - 2017-12-01 06:47:20.030953: step 95770, loss = 0.31, batch loss = 0.18 (52.2 examples/sec; 0.153 sec/batch; 10h:04m:41s remains)
INFO - root - 2017-12-01 06:47:21.580689: step 95780, loss = 0.31, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 10h:12m:26s remains)
INFO - root - 2017-12-01 06:47:23.127801: step 95790, loss = 0.34, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 10h:20m:39s remains)
INFO - root - 2017-12-01 06:47:24.690646: step 95800, loss = 0.34, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 10h:10m:30s remains)
INFO - root - 2017-12-01 06:47:26.336931: step 95810, loss = 0.34, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 10h:25m:10s remains)
INFO - root - 2017-12-01 06:47:27.885898: step 95820, loss = 0.32, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 10h:14m:01s remains)
INFO - root - 2017-12-01 06:47:29.440854: step 95830, loss = 0.38, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 10h:13m:49s remains)
INFO - root - 2017-12-01 06:47:31.011248: step 95840, loss = 0.41, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 10h:11m:52s remains)
INFO - root - 2017-12-01 06:47:32.591501: step 95850, loss = 0.30, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 10h:17m:46s remains)
INFO - root - 2017-12-01 06:47:34.153648: step 95860, loss = 0.48, batch loss = 0.35 (51.2 examples/sec; 0.156 sec/batch; 10h:16m:23s remains)
INFO - root - 2017-12-01 06:47:35.715995: step 95870, loss = 0.34, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 10h:15m:13s remains)
INFO - root - 2017-12-01 06:47:37.272469: step 95880, loss = 0.38, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 9h:58m:07s remains)
INFO - root - 2017-12-01 06:47:38.822248: step 95890, loss = 0.34, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 10h:13m:16s remains)
INFO - root - 2017-12-01 06:47:40.448168: step 95900, loss = 0.34, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 10h:19m:37s remains)
INFO - root - 2017-12-01 06:47:42.107520: step 95910, loss = 0.37, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 10h:17m:22s remains)
INFO - root - 2017-12-01 06:47:43.660066: step 95920, loss = 0.36, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 10h:04m:37s remains)
INFO - root - 2017-12-01 06:47:45.220594: step 95930, loss = 0.32, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 10h:17m:05s remains)
INFO - root - 2017-12-01 06:47:46.811605: step 95940, loss = 0.34, batch loss = 0.21 (49.2 examples/sec; 0.163 sec/batch; 10h:40m:59s remains)
INFO - root - 2017-12-01 06:47:48.349425: step 95950, loss = 0.32, batch loss = 0.20 (52.5 examples/sec; 0.153 sec/batch; 10h:01m:18s remains)
INFO - root - 2017-12-01 06:47:49.932944: step 95960, loss = 0.34, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 10h:23m:35s remains)
INFO - root - 2017-12-01 06:47:51.496253: step 95970, loss = 0.30, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 10h:10m:59s remains)
INFO - root - 2017-12-01 06:47:53.062080: step 95980, loss = 0.47, batch loss = 0.34 (50.2 examples/sec; 0.159 sec/batch; 10h:28m:17s remains)
INFO - root - 2017-12-01 06:47:54.621787: step 95990, loss = 0.29, batch loss = 0.17 (49.6 examples/sec; 0.161 sec/batch; 10h:35m:54s remains)
INFO - root - 2017-12-01 06:47:56.190336: step 96000, loss = 0.35, batch loss = 0.22 (53.3 examples/sec; 0.150 sec/batch; 9h:51m:50s remains)
INFO - root - 2017-12-01 06:47:57.813892: step 96010, loss = 0.35, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 10h:16m:24s remains)
INFO - root - 2017-12-01 06:47:59.363842: step 96020, loss = 0.27, batch loss = 0.15 (52.4 examples/sec; 0.153 sec/batch; 10h:01m:11s remains)
INFO - root - 2017-12-01 06:48:00.929194: step 96030, loss = 0.41, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 10h:21m:19s remains)
INFO - root - 2017-12-01 06:48:02.479332: step 96040, loss = 0.33, batch loss = 0.20 (53.4 examples/sec; 0.150 sec/batch; 9h:50m:33s remains)
INFO - root - 2017-12-01 06:48:04.054213: step 96050, loss = 0.29, batch loss = 0.16 (52.5 examples/sec; 0.152 sec/batch; 10h:00m:38s remains)
INFO - root - 2017-12-01 06:48:05.621967: step 96060, loss = 0.37, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 10h:19m:23s remains)
INFO - root - 2017-12-01 06:48:07.188557: step 96070, loss = 0.29, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 10h:14m:35s remains)
INFO - root - 2017-12-01 06:48:08.742294: step 96080, loss = 0.42, batch loss = 0.29 (51.8 examples/sec; 0.154 sec/batch; 10h:08m:31s remains)
INFO - root - 2017-12-01 06:48:10.303191: step 96090, loss = 0.28, batch loss = 0.16 (52.8 examples/sec; 0.152 sec/batch; 9h:56m:56s remains)
INFO - root - 2017-12-01 06:48:11.875873: step 96100, loss = 0.31, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 10h:06m:41s remains)
INFO - root - 2017-12-01 06:48:13.516354: step 96110, loss = 0.42, batch loss = 0.29 (52.0 examples/sec; 0.154 sec/batch; 10h:06m:18s remains)
INFO - root - 2017-12-01 06:48:15.141124: step 96120, loss = 0.49, batch loss = 0.36 (52.0 examples/sec; 0.154 sec/batch; 10h:06m:11s remains)
INFO - root - 2017-12-01 06:48:16.701995: step 96130, loss = 0.36, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 10h:16m:13s remains)
INFO - root - 2017-12-01 06:48:18.272009: step 96140, loss = 0.35, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 10h:07m:38s remains)
INFO - root - 2017-12-01 06:48:19.833906: step 96150, loss = 0.35, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 10h:15m:07s remains)
INFO - root - 2017-12-01 06:48:21.399381: step 96160, loss = 0.31, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 10h:09m:00s remains)
INFO - root - 2017-12-01 06:48:22.973003: step 96170, loss = 0.29, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 10h:18m:40s remains)
INFO - root - 2017-12-01 06:48:24.531122: step 96180, loss = 0.32, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 10h:12m:21s remains)
INFO - root - 2017-12-01 06:48:26.111503: step 96190, loss = 0.35, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 10h:14m:21s remains)
INFO - root - 2017-12-01 06:48:27.683297: step 96200, loss = 0.31, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 10h:22m:25s remains)
INFO - root - 2017-12-01 06:48:29.302659: step 96210, loss = 0.30, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 10h:12m:32s remains)
INFO - root - 2017-12-01 06:48:30.870690: step 96220, loss = 0.32, batch loss = 0.20 (52.1 examples/sec; 0.153 sec/batch; 10h:04m:13s remains)
INFO - root - 2017-12-01 06:48:32.447726: step 96230, loss = 0.30, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 10h:18m:44s remains)
INFO - root - 2017-12-01 06:48:34.007585: step 96240, loss = 0.39, batch loss = 0.27 (50.2 examples/sec; 0.159 sec/batch; 10h:27m:44s remains)
INFO - root - 2017-12-01 06:48:35.572428: step 96250, loss = 0.33, batch loss = 0.21 (49.8 examples/sec; 0.161 sec/batch; 10h:33m:04s remains)
INFO - root - 2017-12-01 06:48:37.139116: step 96260, loss = 0.48, batch loss = 0.35 (52.8 examples/sec; 0.151 sec/batch; 9h:56m:28s remains)
INFO - root - 2017-12-01 06:48:38.710651: step 96270, loss = 0.54, batch loss = 0.42 (49.9 examples/sec; 0.160 sec/batch; 10h:31m:27s remains)
INFO - root - 2017-12-01 06:48:40.275150: step 96280, loss = 0.28, batch loss = 0.15 (52.1 examples/sec; 0.154 sec/batch; 10h:04m:59s remains)
INFO - root - 2017-12-01 06:48:41.858739: step 96290, loss = 0.32, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 10h:28m:06s remains)
INFO - root - 2017-12-01 06:48:43.426458: step 96300, loss = 0.32, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 10h:05m:02s remains)
INFO - root - 2017-12-01 06:48:45.062594: step 96310, loss = 0.31, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 10h:23m:50s remains)
INFO - root - 2017-12-01 06:48:46.621496: step 96320, loss = 0.33, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 10h:27m:39s remains)
INFO - root - 2017-12-01 06:48:48.188086: step 96330, loss = 0.32, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 10h:23m:41s remains)
INFO - root - 2017-12-01 06:48:49.758229: step 96340, loss = 0.29, batch loss = 0.17 (50.8 examples/sec; 0.157 sec/batch; 10h:19m:34s remains)
INFO - root - 2017-12-01 06:48:51.336925: step 96350, loss = 0.35, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 10h:18m:31s remains)
INFO - root - 2017-12-01 06:48:52.888882: step 96360, loss = 0.47, batch loss = 0.35 (50.8 examples/sec; 0.158 sec/batch; 10h:20m:03s remains)
INFO - root - 2017-12-01 06:48:54.447038: step 96370, loss = 0.27, batch loss = 0.15 (52.7 examples/sec; 0.152 sec/batch; 9h:57m:58s remains)
INFO - root - 2017-12-01 06:48:56.024731: step 96380, loss = 0.31, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 10h:18m:43s remains)
INFO - root - 2017-12-01 06:48:57.603179: step 96390, loss = 0.41, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 10h:06m:02s remains)
INFO - root - 2017-12-01 06:48:59.178809: step 96400, loss = 0.31, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 10h:21m:36s remains)
INFO - root - 2017-12-01 06:49:00.817791: step 96410, loss = 0.47, batch loss = 0.35 (51.5 examples/sec; 0.155 sec/batch; 10h:11m:48s remains)
INFO - root - 2017-12-01 06:49:02.391818: step 96420, loss = 0.33, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 10h:21m:39s remains)
INFO - root - 2017-12-01 06:49:03.957295: step 96430, loss = 0.38, batch loss = 0.25 (52.1 examples/sec; 0.153 sec/batch; 10h:03m:40s remains)
INFO - root - 2017-12-01 06:49:05.509690: step 96440, loss = 0.31, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 10h:05m:57s remains)
INFO - root - 2017-12-01 06:49:07.100317: step 96450, loss = 0.31, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 10h:06m:10s remains)
INFO - root - 2017-12-01 06:49:08.660599: step 96460, loss = 0.35, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 10h:11m:37s remains)
INFO - root - 2017-12-01 06:49:10.233561: step 96470, loss = 0.30, batch loss = 0.18 (49.2 examples/sec; 0.162 sec/batch; 10h:39m:04s remains)
INFO - root - 2017-12-01 06:49:11.795253: step 96480, loss = 0.57, batch loss = 0.45 (51.4 examples/sec; 0.156 sec/batch; 10h:12m:13s remains)
INFO - root - 2017-12-01 06:49:13.347296: step 96490, loss = 0.28, batch loss = 0.16 (51.0 examples/sec; 0.157 sec/batch; 10h:16m:38s remains)
INFO - root - 2017-12-01 06:49:14.901217: step 96500, loss = 0.36, batch loss = 0.24 (52.7 examples/sec; 0.152 sec/batch; 9h:56m:50s remains)
INFO - root - 2017-12-01 06:49:16.525158: step 96510, loss = 0.30, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 10h:18m:14s remains)
INFO - root - 2017-12-01 06:49:18.085326: step 96520, loss = 0.38, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 10h:01m:54s remains)
INFO - root - 2017-12-01 06:49:19.645831: step 96530, loss = 0.46, batch loss = 0.34 (53.0 examples/sec; 0.151 sec/batch; 9h:53m:05s remains)
INFO - root - 2017-12-01 06:49:21.215490: step 96540, loss = 0.31, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 10h:08m:15s remains)
INFO - root - 2017-12-01 06:49:22.773007: step 96550, loss = 0.32, batch loss = 0.19 (51.8 examples/sec; 0.155 sec/batch; 10h:07m:47s remains)
INFO - root - 2017-12-01 06:49:24.348426: step 96560, loss = 0.31, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 10h:13m:04s remains)
INFO - root - 2017-12-01 06:49:25.906390: step 96570, loss = 0.32, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 10h:11m:17s remains)
INFO - root - 2017-12-01 06:49:27.474631: step 96580, loss = 0.45, batch loss = 0.33 (52.1 examples/sec; 0.153 sec/batch; 10h:03m:24s remains)
INFO - root - 2017-12-01 06:49:29.053449: step 96590, loss = 0.43, batch loss = 0.31 (51.4 examples/sec; 0.156 sec/batch; 10h:12m:11s remains)
INFO - root - 2017-12-01 06:49:30.622696: step 96600, loss = 0.34, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 10h:19m:58s remains)
INFO - root - 2017-12-01 06:49:32.234026: step 96610, loss = 0.56, batch loss = 0.44 (51.0 examples/sec; 0.157 sec/batch; 10h:16m:41s remains)
INFO - root - 2017-12-01 06:49:33.797881: step 96620, loss = 0.33, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 10h:05m:57s remains)
INFO - root - 2017-12-01 06:49:35.367430: step 96630, loss = 0.33, batch loss = 0.21 (49.1 examples/sec; 0.163 sec/batch; 10h:40m:23s remains)
INFO - root - 2017-12-01 06:49:36.933034: step 96640, loss = 0.35, batch loss = 0.22 (49.9 examples/sec; 0.160 sec/batch; 10h:30m:18s remains)
INFO - root - 2017-12-01 06:49:38.502410: step 96650, loss = 0.36, batch loss = 0.23 (49.6 examples/sec; 0.161 sec/batch; 10h:33m:30s remains)
INFO - root - 2017-12-01 06:49:40.074131: step 96660, loss = 0.36, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 10h:17m:29s remains)
INFO - root - 2017-12-01 06:49:41.634980: step 96670, loss = 0.41, batch loss = 0.28 (51.8 examples/sec; 0.154 sec/batch; 10h:07m:01s remains)
INFO - root - 2017-12-01 06:49:43.203355: step 96680, loss = 0.39, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 10h:17m:37s remains)
INFO - root - 2017-12-01 06:49:44.766582: step 96690, loss = 0.34, batch loss = 0.21 (48.9 examples/sec; 0.163 sec/batch; 10h:42m:20s remains)
INFO - root - 2017-12-01 06:49:46.322229: step 96700, loss = 0.33, batch loss = 0.21 (53.2 examples/sec; 0.150 sec/batch; 9h:50m:32s remains)
INFO - root - 2017-12-01 06:49:47.966924: step 96710, loss = 0.32, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 10h:18m:00s remains)
INFO - root - 2017-12-01 06:49:49.525265: step 96720, loss = 0.36, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 10h:15m:40s remains)
INFO - root - 2017-12-01 06:49:51.091440: step 96730, loss = 0.42, batch loss = 0.29 (52.5 examples/sec; 0.152 sec/batch; 9h:58m:44s remains)
INFO - root - 2017-12-01 06:49:52.633454: step 96740, loss = 0.39, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 10h:02m:05s remains)
INFO - root - 2017-12-01 06:49:54.198574: step 96750, loss = 0.35, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 10h:02m:33s remains)
INFO - root - 2017-12-01 06:49:55.764271: step 96760, loss = 0.32, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 10h:23m:58s remains)
INFO - root - 2017-12-01 06:49:57.344517: step 96770, loss = 0.32, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 10h:19m:30s remains)
INFO - root - 2017-12-01 06:49:58.908166: step 96780, loss = 0.35, batch loss = 0.22 (49.9 examples/sec; 0.160 sec/batch; 10h:29m:20s remains)
INFO - root - 2017-12-01 06:50:00.473139: step 96790, loss = 0.32, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 10h:06m:03s remains)
INFO - root - 2017-12-01 06:50:02.026635: step 96800, loss = 0.36, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 10h:14m:52s remains)
INFO - root - 2017-12-01 06:50:03.618517: step 96810, loss = 0.29, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 10h:22m:17s remains)
INFO - root - 2017-12-01 06:50:05.182645: step 96820, loss = 0.34, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 10h:06m:46s remains)
INFO - root - 2017-12-01 06:50:06.747290: step 96830, loss = 0.37, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 10h:15m:32s remains)
INFO - root - 2017-12-01 06:50:08.325414: step 96840, loss = 0.34, batch loss = 0.21 (51.1 examples/sec; 0.156 sec/batch; 10h:14m:26s remains)
INFO - root - 2017-12-01 06:50:09.891137: step 96850, loss = 0.31, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 10h:07m:31s remains)
INFO - root - 2017-12-01 06:50:11.470616: step 96860, loss = 0.36, batch loss = 0.23 (47.7 examples/sec; 0.168 sec/batch; 10h:58m:00s remains)
INFO - root - 2017-12-01 06:50:13.046255: step 96870, loss = 0.34, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 10h:05m:17s remains)
INFO - root - 2017-12-01 06:50:14.596592: step 96880, loss = 0.33, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 10h:01m:22s remains)
INFO - root - 2017-12-01 06:50:16.161182: step 96890, loss = 0.41, batch loss = 0.28 (52.7 examples/sec; 0.152 sec/batch; 9h:55m:45s remains)
INFO - root - 2017-12-01 06:50:17.744401: step 96900, loss = 0.37, batch loss = 0.25 (48.4 examples/sec; 0.165 sec/batch; 10h:48m:47s remains)
INFO - root - 2017-12-01 06:50:19.380682: step 96910, loss = 0.28, batch loss = 0.15 (51.9 examples/sec; 0.154 sec/batch; 10h:05m:42s remains)
INFO - root - 2017-12-01 06:50:20.952868: step 96920, loss = 0.32, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 10h:19m:05s remains)
INFO - root - 2017-12-01 06:50:22.517102: step 96930, loss = 0.33, batch loss = 0.20 (53.2 examples/sec; 0.150 sec/batch; 9h:50m:27s remains)
INFO - root - 2017-12-01 06:50:24.080170: step 96940, loss = 0.37, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 10h:08m:11s remains)
INFO - root - 2017-12-01 06:50:25.643219: step 96950, loss = 0.35, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 10h:10m:20s remains)
INFO - root - 2017-12-01 06:50:27.211511: step 96960, loss = 0.34, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 10h:04m:04s remains)
INFO - root - 2017-12-01 06:50:28.767654: step 96970, loss = 0.35, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 10h:25m:48s remains)
INFO - root - 2017-12-01 06:50:30.323495: step 96980, loss = 0.31, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 10h:09m:37s remains)
INFO - root - 2017-12-01 06:50:31.890168: step 96990, loss = 0.33, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 10h:21m:15s remains)
INFO - root - 2017-12-01 06:50:33.459457: step 97000, loss = 0.32, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 10h:13m:20s remains)
INFO - root - 2017-12-01 06:50:35.102274: step 97010, loss = 0.33, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 10h:08m:14s remains)
INFO - root - 2017-12-01 06:50:36.674592: step 97020, loss = 0.34, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 10h:10m:20s remains)
INFO - root - 2017-12-01 06:50:38.232407: step 97030, loss = 0.27, batch loss = 0.14 (51.3 examples/sec; 0.156 sec/batch; 10h:11m:38s remains)
INFO - root - 2017-12-01 06:50:39.789053: step 97040, loss = 0.39, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 10h:07m:41s remains)
INFO - root - 2017-12-01 06:50:41.333547: step 97050, loss = 0.32, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 10h:18m:34s remains)
INFO - root - 2017-12-01 06:50:42.911920: step 97060, loss = 0.72, batch loss = 0.59 (51.5 examples/sec; 0.155 sec/batch; 10h:09m:55s remains)
INFO - root - 2017-12-01 06:50:44.474016: step 97070, loss = 0.35, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 10h:09m:44s remains)
INFO - root - 2017-12-01 06:50:46.045770: step 97080, loss = 0.36, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 10h:11m:31s remains)
INFO - root - 2017-12-01 06:50:47.612784: step 97090, loss = 0.28, batch loss = 0.16 (50.0 examples/sec; 0.160 sec/batch; 10h:27m:35s remains)
INFO - root - 2017-12-01 06:50:49.172647: step 97100, loss = 0.35, batch loss = 0.23 (53.9 examples/sec; 0.149 sec/batch; 9h:42m:46s remains)
INFO - root - 2017-12-01 06:50:50.784201: step 97110, loss = 0.28, batch loss = 0.16 (52.8 examples/sec; 0.152 sec/batch; 9h:54m:38s remains)
INFO - root - 2017-12-01 06:50:52.354013: step 97120, loss = 0.43, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 10h:16m:10s remains)
INFO - root - 2017-12-01 06:50:53.923919: step 97130, loss = 0.28, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 10h:22m:36s remains)
INFO - root - 2017-12-01 06:50:55.479667: step 97140, loss = 0.26, batch loss = 0.14 (51.3 examples/sec; 0.156 sec/batch; 10h:11m:50s remains)
INFO - root - 2017-12-01 06:50:57.034092: step 97150, loss = 0.41, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 10h:09m:16s remains)
INFO - root - 2017-12-01 06:50:58.589384: step 97160, loss = 0.38, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 10h:18m:54s remains)
INFO - root - 2017-12-01 06:51:00.196470: step 97170, loss = 0.39, batch loss = 0.27 (51.1 examples/sec; 0.156 sec/batch; 10h:13m:31s remains)
INFO - root - 2017-12-01 06:51:01.744503: step 97180, loss = 0.36, batch loss = 0.24 (49.7 examples/sec; 0.161 sec/batch; 10h:31m:44s remains)
INFO - root - 2017-12-01 06:51:03.306024: step 97190, loss = 0.34, batch loss = 0.22 (49.4 examples/sec; 0.162 sec/batch; 10h:34m:40s remains)
INFO - root - 2017-12-01 06:51:04.863995: step 97200, loss = 0.31, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 9h:59m:29s remains)
INFO - root - 2017-12-01 06:51:06.499743: step 97210, loss = 0.28, batch loss = 0.16 (49.8 examples/sec; 0.161 sec/batch; 10h:29m:53s remains)
INFO - root - 2017-12-01 06:51:08.062679: step 97220, loss = 0.47, batch loss = 0.35 (49.7 examples/sec; 0.161 sec/batch; 10h:30m:48s remains)
INFO - root - 2017-12-01 06:51:09.613284: step 97230, loss = 0.33, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 9h:57m:57s remains)
INFO - root - 2017-12-01 06:51:11.188010: step 97240, loss = 0.31, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 10h:17m:02s remains)
INFO - root - 2017-12-01 06:51:12.762807: step 97250, loss = 0.33, batch loss = 0.21 (49.9 examples/sec; 0.160 sec/batch; 10h:28m:37s remains)
INFO - root - 2017-12-01 06:51:14.312027: step 97260, loss = 0.39, batch loss = 0.27 (51.7 examples/sec; 0.155 sec/batch; 10h:06m:42s remains)
INFO - root - 2017-12-01 06:51:15.865306: step 97270, loss = 0.35, batch loss = 0.23 (51.8 examples/sec; 0.155 sec/batch; 10h:05m:59s remains)
INFO - root - 2017-12-01 06:51:17.425180: step 97280, loss = 0.40, batch loss = 0.27 (51.8 examples/sec; 0.154 sec/batch; 10h:05m:39s remains)
INFO - root - 2017-12-01 06:51:19.004190: step 97290, loss = 0.31, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 10h:17m:22s remains)
INFO - root - 2017-12-01 06:51:20.582095: step 97300, loss = 0.31, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 10h:19m:54s remains)
INFO - root - 2017-12-01 06:51:22.215073: step 97310, loss = 0.33, batch loss = 0.21 (49.0 examples/sec; 0.163 sec/batch; 10h:40m:01s remains)
INFO - root - 2017-12-01 06:51:23.777993: step 97320, loss = 0.46, batch loss = 0.34 (51.7 examples/sec; 0.155 sec/batch; 10h:06m:40s remains)
INFO - root - 2017-12-01 06:51:25.343404: step 97330, loss = 0.32, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 10h:17m:43s remains)
INFO - root - 2017-12-01 06:51:26.893843: step 97340, loss = 0.29, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 10h:12m:14s remains)
INFO - root - 2017-12-01 06:51:28.459792: step 97350, loss = 0.32, batch loss = 0.20 (49.0 examples/sec; 0.163 sec/batch; 10h:39m:59s remains)
INFO - root - 2017-12-01 06:51:30.034950: step 97360, loss = 0.32, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 10h:09m:40s remains)
INFO - root - 2017-12-01 06:51:31.590004: step 97370, loss = 0.37, batch loss = 0.25 (52.4 examples/sec; 0.153 sec/batch; 9h:58m:43s remains)
INFO - root - 2017-12-01 06:51:33.157776: step 97380, loss = 0.31, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 10h:20m:24s remains)
INFO - root - 2017-12-01 06:51:34.739954: step 97390, loss = 0.33, batch loss = 0.21 (49.8 examples/sec; 0.161 sec/batch; 10h:29m:43s remains)
INFO - root - 2017-12-01 06:51:36.300636: step 97400, loss = 0.32, batch loss = 0.19 (53.0 examples/sec; 0.151 sec/batch; 9h:51m:40s remains)
INFO - root - 2017-12-01 06:51:37.933067: step 97410, loss = 0.33, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 10h:13m:32s remains)
INFO - root - 2017-12-01 06:51:39.492993: step 97420, loss = 0.43, batch loss = 0.31 (52.1 examples/sec; 0.154 sec/batch; 10h:02m:04s remains)
INFO - root - 2017-12-01 06:51:41.055503: step 97430, loss = 0.39, batch loss = 0.27 (51.8 examples/sec; 0.154 sec/batch; 10h:05m:13s remains)
INFO - root - 2017-12-01 06:51:42.635588: step 97440, loss = 0.39, batch loss = 0.27 (50.4 examples/sec; 0.159 sec/batch; 10h:21m:41s remains)
INFO - root - 2017-12-01 06:51:44.197985: step 97450, loss = 0.47, batch loss = 0.34 (51.3 examples/sec; 0.156 sec/batch; 10h:10m:33s remains)
INFO - root - 2017-12-01 06:51:45.758419: step 97460, loss = 0.31, batch loss = 0.19 (51.1 examples/sec; 0.156 sec/batch; 10h:12m:49s remains)
INFO - root - 2017-12-01 06:51:47.325122: step 97470, loss = 0.43, batch loss = 0.31 (50.8 examples/sec; 0.158 sec/batch; 10h:17m:03s remains)
INFO - root - 2017-12-01 06:51:48.885915: step 97480, loss = 0.33, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 10h:02m:58s remains)
INFO - root - 2017-12-01 06:51:50.484500: step 97490, loss = 0.29, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 10h:21m:53s remains)
INFO - root - 2017-12-01 06:51:52.054051: step 97500, loss = 0.40, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 10h:19m:40s remains)
INFO - root - 2017-12-01 06:51:53.692027: step 97510, loss = 0.34, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 9h:59m:40s remains)
INFO - root - 2017-12-01 06:51:55.263438: step 97520, loss = 0.38, batch loss = 0.26 (50.3 examples/sec; 0.159 sec/batch; 10h:22m:37s remains)
INFO - root - 2017-12-01 06:51:56.831295: step 97530, loss = 0.32, batch loss = 0.20 (49.2 examples/sec; 0.162 sec/batch; 10h:36m:15s remains)
INFO - root - 2017-12-01 06:51:58.390173: step 97540, loss = 0.34, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 9h:57m:51s remains)
INFO - root - 2017-12-01 06:51:59.953236: step 97550, loss = 0.33, batch loss = 0.21 (53.6 examples/sec; 0.149 sec/batch; 9h:44m:19s remains)
INFO - root - 2017-12-01 06:52:01.539077: step 97560, loss = 0.33, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 10h:12m:44s remains)
INFO - root - 2017-12-01 06:52:03.095808: step 97570, loss = 0.29, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 10h:06m:20s remains)
INFO - root - 2017-12-01 06:52:04.671129: step 97580, loss = 0.37, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 10h:08m:07s remains)
INFO - root - 2017-12-01 06:52:06.273802: step 97590, loss = 0.33, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 10h:00m:28s remains)
INFO - root - 2017-12-01 06:52:07.833973: step 97600, loss = 0.32, batch loss = 0.20 (52.5 examples/sec; 0.152 sec/batch; 9h:56m:03s remains)
INFO - root - 2017-12-01 06:52:09.465019: step 97610, loss = 0.45, batch loss = 0.33 (52.5 examples/sec; 0.152 sec/batch; 9h:56m:30s remains)
INFO - root - 2017-12-01 06:52:11.049344: step 97620, loss = 0.47, batch loss = 0.35 (50.1 examples/sec; 0.160 sec/batch; 10h:25m:31s remains)
INFO - root - 2017-12-01 06:52:12.609667: step 97630, loss = 0.32, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 10h:14m:37s remains)
INFO - root - 2017-12-01 06:52:14.155408: step 97640, loss = 0.34, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 10h:23m:31s remains)
INFO - root - 2017-12-01 06:52:15.715980: step 97650, loss = 0.36, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 9h:59m:29s remains)
INFO - root - 2017-12-01 06:52:17.271670: step 97660, loss = 0.34, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 10h:02m:23s remains)
INFO - root - 2017-12-01 06:52:18.826389: step 97670, loss = 0.39, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 10h:03m:10s remains)
INFO - root - 2017-12-01 06:52:20.393549: step 97680, loss = 0.29, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 10h:07m:40s remains)
INFO - root - 2017-12-01 06:52:21.973019: step 97690, loss = 0.27, batch loss = 0.15 (49.3 examples/sec; 0.162 sec/batch; 10h:35m:33s remains)
INFO - root - 2017-12-01 06:52:23.534874: step 97700, loss = 0.43, batch loss = 0.31 (51.1 examples/sec; 0.157 sec/batch; 10h:13m:03s remains)
INFO - root - 2017-12-01 06:52:25.165177: step 97710, loss = 0.33, batch loss = 0.21 (43.9 examples/sec; 0.182 sec/batch; 11h:53m:24s remains)
INFO - root - 2017-12-01 06:52:26.722347: step 97720, loss = 0.36, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 10h:13m:05s remains)
INFO - root - 2017-12-01 06:52:28.296805: step 97730, loss = 0.30, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 10h:22m:44s remains)
INFO - root - 2017-12-01 06:52:29.863035: step 97740, loss = 0.24, batch loss = 0.12 (51.6 examples/sec; 0.155 sec/batch; 10h:07m:03s remains)
INFO - root - 2017-12-01 06:52:31.420425: step 97750, loss = 0.48, batch loss = 0.36 (51.7 examples/sec; 0.155 sec/batch; 10h:05m:11s remains)
INFO - root - 2017-12-01 06:52:32.986818: step 97760, loss = 0.30, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 10h:12m:25s remains)
INFO - root - 2017-12-01 06:52:34.551044: step 97770, loss = 0.42, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 10h:14m:17s remains)
INFO - root - 2017-12-01 06:52:36.122759: step 97780, loss = 0.27, batch loss = 0.14 (47.0 examples/sec; 0.170 sec/batch; 11h:06m:29s remains)
INFO - root - 2017-12-01 06:52:37.694046: step 97790, loss = 0.43, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 10h:11m:03s remains)
INFO - root - 2017-12-01 06:52:39.255439: step 97800, loss = 0.31, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 10h:02m:35s remains)
INFO - root - 2017-12-01 06:52:40.895926: step 97810, loss = 0.37, batch loss = 0.25 (48.8 examples/sec; 0.164 sec/batch; 10h:40m:35s remains)
INFO - root - 2017-12-01 06:52:42.480319: step 97820, loss = 0.37, batch loss = 0.25 (52.4 examples/sec; 0.153 sec/batch; 9h:57m:33s remains)
INFO - root - 2017-12-01 06:52:44.053290: step 97830, loss = 0.32, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 10h:01m:59s remains)
INFO - root - 2017-12-01 06:52:45.606841: step 97840, loss = 0.54, batch loss = 0.42 (52.3 examples/sec; 0.153 sec/batch; 9h:58m:17s remains)
INFO - root - 2017-12-01 06:52:47.150845: step 97850, loss = 0.30, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 10h:14m:06s remains)
INFO - root - 2017-12-01 06:52:48.723585: step 97860, loss = 0.36, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 9h:54m:14s remains)
INFO - root - 2017-12-01 06:52:50.285356: step 97870, loss = 0.30, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 10h:09m:41s remains)
INFO - root - 2017-12-01 06:52:51.864087: step 97880, loss = 0.39, batch loss = 0.27 (48.8 examples/sec; 0.164 sec/batch; 10h:40m:23s remains)
INFO - root - 2017-12-01 06:52:53.422974: step 97890, loss = 0.32, batch loss = 0.20 (49.8 examples/sec; 0.161 sec/batch; 10h:28m:02s remains)
INFO - root - 2017-12-01 06:52:54.966395: step 97900, loss = 0.44, batch loss = 0.31 (50.8 examples/sec; 0.157 sec/batch; 10h:15m:16s remains)
INFO - root - 2017-12-01 06:52:56.594158: step 97910, loss = 0.32, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 10h:01m:17s remains)
INFO - root - 2017-12-01 06:52:58.154374: step 97920, loss = 0.54, batch loss = 0.41 (50.9 examples/sec; 0.157 sec/batch; 10h:14m:53s remains)
INFO - root - 2017-12-01 06:52:59.720159: step 97930, loss = 0.35, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 10h:08m:10s remains)
INFO - root - 2017-12-01 06:53:01.279507: step 97940, loss = 0.38, batch loss = 0.26 (52.4 examples/sec; 0.153 sec/batch; 9h:56m:17s remains)
INFO - root - 2017-12-01 06:53:02.861158: step 97950, loss = 0.38, batch loss = 0.25 (51.8 examples/sec; 0.155 sec/batch; 10h:03m:58s remains)
INFO - root - 2017-12-01 06:53:04.421639: step 97960, loss = 0.36, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 10h:26m:19s remains)
INFO - root - 2017-12-01 06:53:05.990709: step 97970, loss = 0.32, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 10h:15m:34s remains)
INFO - root - 2017-12-01 06:53:07.546871: step 97980, loss = 0.38, batch loss = 0.26 (52.5 examples/sec; 0.152 sec/batch; 9h:56m:00s remains)
INFO - root - 2017-12-01 06:53:09.122658: step 97990, loss = 0.31, batch loss = 0.19 (53.2 examples/sec; 0.150 sec/batch; 9h:47m:38s remains)
INFO - root - 2017-12-01 06:53:10.689424: step 98000, loss = 0.35, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 10h:11m:58s remains)
INFO - root - 2017-12-01 06:53:12.321777: step 98010, loss = 0.31, batch loss = 0.18 (52.5 examples/sec; 0.152 sec/batch; 9h:55m:25s remains)
INFO - root - 2017-12-01 06:53:13.866662: step 98020, loss = 0.35, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 10h:13m:48s remains)
INFO - root - 2017-12-01 06:53:15.415288: step 98030, loss = 0.28, batch loss = 0.16 (52.5 examples/sec; 0.152 sec/batch; 9h:55m:37s remains)
INFO - root - 2017-12-01 06:53:16.997419: step 98040, loss = 0.31, batch loss = 0.19 (52.1 examples/sec; 0.154 sec/batch; 10h:00m:11s remains)
INFO - root - 2017-12-01 06:53:18.570366: step 98050, loss = 0.30, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 10h:10m:22s remains)
INFO - root - 2017-12-01 06:53:20.136694: step 98060, loss = 0.40, batch loss = 0.28 (48.9 examples/sec; 0.164 sec/batch; 10h:39m:41s remains)
INFO - root - 2017-12-01 06:53:21.691774: step 98070, loss = 0.33, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 9h:55m:32s remains)
INFO - root - 2017-12-01 06:53:23.258521: step 98080, loss = 0.27, batch loss = 0.15 (51.2 examples/sec; 0.156 sec/batch; 10h:11m:02s remains)
INFO - root - 2017-12-01 06:53:24.830425: step 98090, loss = 0.38, batch loss = 0.26 (50.8 examples/sec; 0.158 sec/batch; 10h:15m:41s remains)
INFO - root - 2017-12-01 06:53:26.397680: step 98100, loss = 0.41, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 10h:10m:17s remains)
INFO - root - 2017-12-01 06:53:28.048524: step 98110, loss = 0.31, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 10h:07m:10s remains)
INFO - root - 2017-12-01 06:53:29.613687: step 98120, loss = 0.30, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 10h:13m:04s remains)
INFO - root - 2017-12-01 06:53:31.179622: step 98130, loss = 0.32, batch loss = 0.20 (49.4 examples/sec; 0.162 sec/batch; 10h:32m:47s remains)
INFO - root - 2017-12-01 06:53:32.746278: step 98140, loss = 0.50, batch loss = 0.37 (51.0 examples/sec; 0.157 sec/batch; 10h:12m:56s remains)
INFO - root - 2017-12-01 06:53:34.297004: step 98150, loss = 0.36, batch loss = 0.24 (52.8 examples/sec; 0.152 sec/batch; 9h:51m:44s remains)
INFO - root - 2017-12-01 06:53:35.898302: step 98160, loss = 0.34, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 10h:17m:41s remains)
INFO - root - 2017-12-01 06:53:37.454451: step 98170, loss = 0.27, batch loss = 0.15 (50.0 examples/sec; 0.160 sec/batch; 10h:25m:02s remains)
INFO - root - 2017-12-01 06:53:39.012664: step 98180, loss = 0.27, batch loss = 0.15 (51.7 examples/sec; 0.155 sec/batch; 10h:03m:53s remains)
INFO - root - 2017-12-01 06:53:40.566653: step 98190, loss = 0.32, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 9h:59m:28s remains)
INFO - root - 2017-12-01 06:53:42.136070: step 98200, loss = 0.31, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 10h:00m:18s remains)
INFO - root - 2017-12-01 06:53:43.755245: step 98210, loss = 0.29, batch loss = 0.17 (50.0 examples/sec; 0.160 sec/batch; 10h:25m:15s remains)
INFO - root - 2017-12-01 06:53:45.336838: step 98220, loss = 0.29, batch loss = 0.16 (52.3 examples/sec; 0.153 sec/batch; 9h:57m:29s remains)
INFO - root - 2017-12-01 06:53:46.898440: step 98230, loss = 0.31, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 10h:14m:58s remains)
INFO - root - 2017-12-01 06:53:48.467986: step 98240, loss = 0.33, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 10h:04m:17s remains)
INFO - root - 2017-12-01 06:53:50.034688: step 98250, loss = 0.44, batch loss = 0.32 (51.7 examples/sec; 0.155 sec/batch; 10h:04m:20s remains)
INFO - root - 2017-12-01 06:53:51.596612: step 98260, loss = 0.35, batch loss = 0.23 (53.5 examples/sec; 0.150 sec/batch; 9h:43m:50s remains)
INFO - root - 2017-12-01 06:53:53.145688: step 98270, loss = 0.40, batch loss = 0.28 (51.1 examples/sec; 0.156 sec/batch; 10h:10m:41s remains)
INFO - root - 2017-12-01 06:53:54.734536: step 98280, loss = 0.34, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 9h:54m:50s remains)
INFO - root - 2017-12-01 06:53:56.304363: step 98290, loss = 0.35, batch loss = 0.23 (48.0 examples/sec; 0.167 sec/batch; 10h:50m:39s remains)
INFO - root - 2017-12-01 06:53:57.853440: step 98300, loss = 0.39, batch loss = 0.27 (52.3 examples/sec; 0.153 sec/batch; 9h:57m:36s remains)
INFO - root - 2017-12-01 06:53:59.494640: step 98310, loss = 0.30, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 10h:04m:21s remains)
INFO - root - 2017-12-01 06:54:01.059913: step 98320, loss = 0.37, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 10h:13m:26s remains)
INFO - root - 2017-12-01 06:54:02.641057: step 98330, loss = 0.51, batch loss = 0.39 (52.5 examples/sec; 0.152 sec/batch; 9h:55m:02s remains)
INFO - root - 2017-12-01 06:54:04.195280: step 98340, loss = 0.42, batch loss = 0.29 (53.2 examples/sec; 0.150 sec/batch; 9h:47m:05s remains)
INFO - root - 2017-12-01 06:54:05.757934: step 98350, loss = 0.43, batch loss = 0.30 (51.8 examples/sec; 0.154 sec/batch; 10h:02m:43s remains)
INFO - root - 2017-12-01 06:54:07.325345: step 98360, loss = 0.31, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 10h:12m:42s remains)
INFO - root - 2017-12-01 06:54:08.943771: step 98370, loss = 0.28, batch loss = 0.15 (46.2 examples/sec; 0.173 sec/batch; 11h:15m:11s remains)
INFO - root - 2017-12-01 06:54:10.520246: step 98380, loss = 0.30, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 10h:11m:47s remains)
INFO - root - 2017-12-01 06:54:12.087359: step 98390, loss = 0.29, batch loss = 0.17 (47.3 examples/sec; 0.169 sec/batch; 10h:59m:39s remains)
INFO - root - 2017-12-01 06:54:13.654837: step 98400, loss = 0.35, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 10h:01m:25s remains)
INFO - root - 2017-12-01 06:54:15.308433: step 98410, loss = 0.27, batch loss = 0.15 (50.6 examples/sec; 0.158 sec/batch; 10h:16m:17s remains)
INFO - root - 2017-12-01 06:54:16.871194: step 98420, loss = 0.30, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 10h:15m:49s remains)
INFO - root - 2017-12-01 06:54:18.421524: step 98430, loss = 0.34, batch loss = 0.22 (53.4 examples/sec; 0.150 sec/batch; 9h:43m:54s remains)
INFO - root - 2017-12-01 06:54:20.003823: step 98440, loss = 0.31, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 10h:05m:35s remains)
INFO - root - 2017-12-01 06:54:21.562231: step 98450, loss = 0.35, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 10h:17m:18s remains)
INFO - root - 2017-12-01 06:54:23.130400: step 98460, loss = 0.30, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 10h:13m:58s remains)
INFO - root - 2017-12-01 06:54:24.690582: step 98470, loss = 0.28, batch loss = 0.15 (49.3 examples/sec; 0.162 sec/batch; 10h:33m:23s remains)
INFO - root - 2017-12-01 06:54:26.264092: step 98480, loss = 0.47, batch loss = 0.35 (51.6 examples/sec; 0.155 sec/batch; 10h:05m:01s remains)
INFO - root - 2017-12-01 06:54:27.814478: step 98490, loss = 0.31, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 10h:17m:46s remains)
INFO - root - 2017-12-01 06:54:29.412512: step 98500, loss = 0.32, batch loss = 0.19 (50.2 examples/sec; 0.159 sec/batch; 10h:21m:12s remains)
INFO - root - 2017-12-01 06:54:31.052620: step 98510, loss = 0.39, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 10h:07m:11s remains)
INFO - root - 2017-12-01 06:54:32.608323: step 98520, loss = 0.36, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 10h:03m:47s remains)
INFO - root - 2017-12-01 06:54:34.183435: step 98530, loss = 0.34, batch loss = 0.21 (49.8 examples/sec; 0.161 sec/batch; 10h:26m:16s remains)
INFO - root - 2017-12-01 06:54:35.734168: step 98540, loss = 0.37, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 10h:15m:40s remains)
INFO - root - 2017-12-01 06:54:37.298642: step 98550, loss = 0.31, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 10h:19m:09s remains)
INFO - root - 2017-12-01 06:54:38.865512: step 98560, loss = 0.30, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 10h:03m:20s remains)
INFO - root - 2017-12-01 06:54:40.460904: step 98570, loss = 0.29, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 10h:07m:58s remains)
INFO - root - 2017-12-01 06:54:42.023012: step 98580, loss = 0.35, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 10h:04m:33s remains)
INFO - root - 2017-12-01 06:54:43.582732: step 98590, loss = 0.34, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 10h:01m:51s remains)
INFO - root - 2017-12-01 06:54:45.143479: step 98600, loss = 0.32, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 10h:10m:17s remains)
INFO - root - 2017-12-01 06:54:46.763983: step 98610, loss = 0.38, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 10h:16m:06s remains)
INFO - root - 2017-12-01 06:54:48.315733: step 98620, loss = 0.37, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 10h:03m:33s remains)
INFO - root - 2017-12-01 06:54:49.888372: step 98630, loss = 0.25, batch loss = 0.12 (48.3 examples/sec; 0.166 sec/batch; 10h:45m:20s remains)
INFO - root - 2017-12-01 06:54:51.451287: step 98640, loss = 0.48, batch loss = 0.36 (52.7 examples/sec; 0.152 sec/batch; 9h:51m:55s remains)
INFO - root - 2017-12-01 06:54:53.009541: step 98650, loss = 0.41, batch loss = 0.29 (51.0 examples/sec; 0.157 sec/batch; 10h:11m:45s remains)
INFO - root - 2017-12-01 06:54:54.593762: step 98660, loss = 0.40, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 10h:03m:14s remains)
INFO - root - 2017-12-01 06:54:56.147856: step 98670, loss = 0.33, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 10h:08m:48s remains)
INFO - root - 2017-12-01 06:54:57.714629: step 98680, loss = 0.52, batch loss = 0.40 (51.7 examples/sec; 0.155 sec/batch; 10h:03m:27s remains)
INFO - root - 2017-12-01 06:54:59.269777: step 98690, loss = 0.29, batch loss = 0.16 (52.7 examples/sec; 0.152 sec/batch; 9h:51m:55s remains)
INFO - root - 2017-12-01 06:55:00.886375: step 98700, loss = 0.31, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 9h:59m:55s remains)
INFO - root - 2017-12-01 06:55:02.502026: step 98710, loss = 0.30, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 10h:04m:48s remains)
INFO - root - 2017-12-01 06:55:04.086892: step 98720, loss = 0.38, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 10h:01m:41s remains)
INFO - root - 2017-12-01 06:55:05.650419: step 98730, loss = 0.32, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 10h:20m:18s remains)
INFO - root - 2017-12-01 06:55:07.220637: step 98740, loss = 0.36, batch loss = 0.24 (49.0 examples/sec; 0.163 sec/batch; 10h:36m:33s remains)
INFO - root - 2017-12-01 06:55:08.785030: step 98750, loss = 0.31, batch loss = 0.19 (53.0 examples/sec; 0.151 sec/batch; 9h:48m:10s remains)
INFO - root - 2017-12-01 06:55:10.338951: step 98760, loss = 0.47, batch loss = 0.35 (52.9 examples/sec; 0.151 sec/batch; 9h:49m:36s remains)
INFO - root - 2017-12-01 06:55:11.915590: step 98770, loss = 0.36, batch loss = 0.24 (50.8 examples/sec; 0.158 sec/batch; 10h:13m:42s remains)
INFO - root - 2017-12-01 06:55:13.478123: step 98780, loss = 0.44, batch loss = 0.32 (50.8 examples/sec; 0.158 sec/batch; 10h:13m:59s remains)
INFO - root - 2017-12-01 06:55:15.041700: step 98790, loss = 0.34, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 10h:02m:39s remains)
INFO - root - 2017-12-01 06:55:16.602661: step 98800, loss = 0.34, batch loss = 0.22 (53.3 examples/sec; 0.150 sec/batch; 9h:44m:42s remains)
INFO - root - 2017-12-01 06:55:18.244316: step 98810, loss = 0.31, batch loss = 0.19 (50.2 examples/sec; 0.159 sec/batch; 10h:20m:39s remains)
INFO - root - 2017-12-01 06:55:19.800299: step 98820, loss = 0.38, batch loss = 0.26 (49.4 examples/sec; 0.162 sec/batch; 10h:30m:44s remains)
INFO - root - 2017-12-01 06:55:21.380531: step 98830, loss = 0.35, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 10h:23m:47s remains)
INFO - root - 2017-12-01 06:55:22.946679: step 98840, loss = 0.34, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 9h:56m:48s remains)
INFO - root - 2017-12-01 06:55:24.514746: step 98850, loss = 0.31, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 10h:13m:00s remains)
INFO - root - 2017-12-01 06:55:26.067858: step 98860, loss = 0.44, batch loss = 0.32 (51.0 examples/sec; 0.157 sec/batch; 10h:11m:07s remains)
INFO - root - 2017-12-01 06:55:27.638574: step 98870, loss = 0.35, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 10h:02m:35s remains)
INFO - root - 2017-12-01 06:55:29.192406: step 98880, loss = 0.30, batch loss = 0.18 (52.5 examples/sec; 0.153 sec/batch; 9h:53m:50s remains)
INFO - root - 2017-12-01 06:55:30.766795: step 98890, loss = 0.31, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 10h:03m:47s remains)
INFO - root - 2017-12-01 06:55:32.326188: step 98900, loss = 0.33, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 10h:13m:54s remains)
INFO - root - 2017-12-01 06:55:33.927842: step 98910, loss = 0.32, batch loss = 0.20 (53.4 examples/sec; 0.150 sec/batch; 9h:43m:30s remains)
INFO - root - 2017-12-01 06:55:35.485108: step 98920, loss = 0.34, batch loss = 0.22 (49.3 examples/sec; 0.162 sec/batch; 10h:31m:07s remains)
INFO - root - 2017-12-01 06:55:37.070022: step 98930, loss = 0.29, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 10h:06m:09s remains)
INFO - root - 2017-12-01 06:55:38.627545: step 98940, loss = 0.34, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 10h:10m:48s remains)
INFO - root - 2017-12-01 06:55:40.204949: step 98950, loss = 0.40, batch loss = 0.28 (50.3 examples/sec; 0.159 sec/batch; 10h:19m:00s remains)
INFO - root - 2017-12-01 06:55:41.757830: step 98960, loss = 0.44, batch loss = 0.32 (53.2 examples/sec; 0.150 sec/batch; 9h:45m:43s remains)
INFO - root - 2017-12-01 06:55:43.342219: step 98970, loss = 0.35, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 9h:59m:27s remains)
INFO - root - 2017-12-01 06:55:44.894842: step 98980, loss = 0.32, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 10h:11m:06s remains)
INFO - root - 2017-12-01 06:55:46.491146: step 98990, loss = 0.26, batch loss = 0.14 (49.6 examples/sec; 0.161 sec/batch; 10h:27m:22s remains)
INFO - root - 2017-12-01 06:55:48.039651: step 99000, loss = 0.26, batch loss = 0.13 (51.2 examples/sec; 0.156 sec/batch; 10h:07m:54s remains)
INFO - root - 2017-12-01 06:55:49.685654: step 99010, loss = 0.32, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 10h:16m:45s remains)
INFO - root - 2017-12-01 06:55:51.244233: step 99020, loss = 0.31, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 10h:08m:27s remains)
INFO - root - 2017-12-01 06:55:52.812328: step 99030, loss = 0.31, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 10h:16m:18s remains)
INFO - root - 2017-12-01 06:55:54.378873: step 99040, loss = 0.55, batch loss = 0.43 (50.9 examples/sec; 0.157 sec/batch; 10h:11m:27s remains)
INFO - root - 2017-12-01 06:55:55.968930: step 99050, loss = 0.38, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 10h:08m:19s remains)
INFO - root - 2017-12-01 06:55:57.528201: step 99060, loss = 0.35, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 9h:57m:56s remains)
INFO - root - 2017-12-01 06:55:59.077026: step 99070, loss = 0.34, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 9h:54m:52s remains)
INFO - root - 2017-12-01 06:56:00.641847: step 99080, loss = 0.38, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 9h:59m:51s remains)
INFO - root - 2017-12-01 06:56:02.220819: step 99090, loss = 0.35, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 10h:09m:05s remains)
INFO - root - 2017-12-01 06:56:03.777352: step 99100, loss = 0.33, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 10h:15m:53s remains)
INFO - root - 2017-12-01 06:56:05.388925: step 99110, loss = 0.37, batch loss = 0.25 (52.6 examples/sec; 0.152 sec/batch; 9h:51m:03s remains)
INFO - root - 2017-12-01 06:56:06.932365: step 99120, loss = 0.37, batch loss = 0.25 (53.2 examples/sec; 0.150 sec/batch; 9h:44m:28s remains)
INFO - root - 2017-12-01 06:56:08.519718: step 99130, loss = 0.34, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 10h:03m:11s remains)
INFO - root - 2017-12-01 06:56:10.089054: step 99140, loss = 0.42, batch loss = 0.29 (50.8 examples/sec; 0.158 sec/batch; 10h:12m:59s remains)
INFO - root - 2017-12-01 06:56:11.649129: step 99150, loss = 0.31, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 10h:22m:05s remains)
INFO - root - 2017-12-01 06:56:13.197203: step 99160, loss = 0.31, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 9h:58m:43s remains)
INFO - root - 2017-12-01 06:56:14.760812: step 99170, loss = 0.46, batch loss = 0.34 (52.4 examples/sec; 0.153 sec/batch; 9h:53m:41s remains)
INFO - root - 2017-12-01 06:56:16.341460: step 99180, loss = 0.30, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 10h:03m:26s remains)
INFO - root - 2017-12-01 06:56:17.905770: step 99190, loss = 0.31, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 10h:10m:52s remains)
INFO - root - 2017-12-01 06:56:19.462974: step 99200, loss = 0.33, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 10h:15m:43s remains)
INFO - root - 2017-12-01 06:56:21.151631: step 99210, loss = 0.40, batch loss = 0.28 (49.6 examples/sec; 0.161 sec/batch; 10h:26m:33s remains)
INFO - root - 2017-12-01 06:56:22.715177: step 99220, loss = 0.31, batch loss = 0.19 (52.7 examples/sec; 0.152 sec/batch; 9h:50m:37s remains)
INFO - root - 2017-12-01 06:56:24.276071: step 99230, loss = 0.40, batch loss = 0.28 (52.8 examples/sec; 0.151 sec/batch; 9h:48m:47s remains)
INFO - root - 2017-12-01 06:56:25.856785: step 99240, loss = 0.30, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 10h:11m:19s remains)
INFO - root - 2017-12-01 06:56:27.409284: step 99250, loss = 0.53, batch loss = 0.41 (50.5 examples/sec; 0.158 sec/batch; 10h:15m:47s remains)
INFO - root - 2017-12-01 06:56:28.968948: step 99260, loss = 0.50, batch loss = 0.38 (51.5 examples/sec; 0.155 sec/batch; 10h:04m:13s remains)
INFO - root - 2017-12-01 06:56:30.529738: step 99270, loss = 0.29, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 9h:57m:51s remains)
INFO - root - 2017-12-01 06:56:32.115185: step 99280, loss = 0.43, batch loss = 0.31 (52.4 examples/sec; 0.153 sec/batch; 9h:53m:40s remains)
INFO - root - 2017-12-01 06:56:33.666334: step 99290, loss = 0.34, batch loss = 0.22 (51.8 examples/sec; 0.155 sec/batch; 10h:00m:41s remains)
INFO - root - 2017-12-01 06:56:35.248334: step 99300, loss = 0.42, batch loss = 0.30 (50.4 examples/sec; 0.159 sec/batch; 10h:17m:01s remains)
INFO - root - 2017-12-01 06:56:36.904006: step 99310, loss = 0.30, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 9h:59m:48s remains)
INFO - root - 2017-12-01 06:56:38.457465: step 99320, loss = 0.32, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 10h:08m:55s remains)
INFO - root - 2017-12-01 06:56:40.018889: step 99330, loss = 0.33, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 10h:11m:50s remains)
INFO - root - 2017-12-01 06:56:41.574849: step 99340, loss = 0.43, batch loss = 0.31 (50.0 examples/sec; 0.160 sec/batch; 10h:21m:22s remains)
INFO - root - 2017-12-01 06:56:43.172369: step 99350, loss = 0.35, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 9h:54m:31s remains)
INFO - root - 2017-12-01 06:56:44.745810: step 99360, loss = 0.34, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 10h:18m:46s remains)
INFO - root - 2017-12-01 06:56:46.330820: step 99370, loss = 0.41, batch loss = 0.29 (48.1 examples/sec; 0.166 sec/batch; 10h:46m:11s remains)
INFO - root - 2017-12-01 06:56:47.900976: step 99380, loss = 0.42, batch loss = 0.30 (52.1 examples/sec; 0.154 sec/batch; 9h:56m:41s remains)
INFO - root - 2017-12-01 06:56:49.477197: step 99390, loss = 0.33, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 9h:59m:12s remains)
INFO - root - 2017-12-01 06:56:51.051381: step 99400, loss = 0.37, batch loss = 0.25 (47.7 examples/sec; 0.168 sec/batch; 10h:51m:12s remains)
INFO - root - 2017-12-01 06:56:52.686639: step 99410, loss = 0.31, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 10h:05m:25s remains)
INFO - root - 2017-12-01 06:56:54.248130: step 99420, loss = 0.38, batch loss = 0.26 (50.8 examples/sec; 0.158 sec/batch; 10h:12m:16s remains)
INFO - root - 2017-12-01 06:56:55.815951: step 99430, loss = 0.31, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 10h:14m:52s remains)
INFO - root - 2017-12-01 06:56:57.390383: step 99440, loss = 0.34, batch loss = 0.22 (48.6 examples/sec; 0.164 sec/batch; 10h:38m:49s remains)
INFO - root - 2017-12-01 06:56:58.985000: step 99450, loss = 0.35, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 10h:01m:41s remains)
INFO - root - 2017-12-01 06:57:00.537897: step 99460, loss = 0.30, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 10h:11m:50s remains)
INFO - root - 2017-12-01 06:57:02.094886: step 99470, loss = 0.29, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 10h:18m:01s remains)
INFO - root - 2017-12-01 06:57:03.643510: step 99480, loss = 0.32, batch loss = 0.20 (52.7 examples/sec; 0.152 sec/batch; 9h:49m:06s remains)
INFO - root - 2017-12-01 06:57:05.215207: step 99490, loss = 0.32, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 9h:51m:39s remains)
INFO - root - 2017-12-01 06:57:06.818660: step 99500, loss = 0.40, batch loss = 0.28 (50.4 examples/sec; 0.159 sec/batch; 10h:16m:30s remains)
INFO - root - 2017-12-01 06:57:08.435886: step 99510, loss = 0.40, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 10h:04m:14s remains)
INFO - root - 2017-12-01 06:57:10.004229: step 99520, loss = 0.31, batch loss = 0.19 (50.1 examples/sec; 0.160 sec/batch; 10h:19m:59s remains)
INFO - root - 2017-12-01 06:57:11.561791: step 99530, loss = 0.31, batch loss = 0.19 (52.1 examples/sec; 0.154 sec/batch; 9h:56m:22s remains)
INFO - root - 2017-12-01 06:57:13.126587: step 99540, loss = 0.31, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 10h:21m:37s remains)
INFO - root - 2017-12-01 06:57:14.701712: step 99550, loss = 0.27, batch loss = 0.15 (49.3 examples/sec; 0.162 sec/batch; 10h:30m:26s remains)
INFO - root - 2017-12-01 06:57:16.263623: step 99560, loss = 0.39, batch loss = 0.27 (52.6 examples/sec; 0.152 sec/batch; 9h:49m:58s remains)
INFO - root - 2017-12-01 06:57:17.835374: step 99570, loss = 0.28, batch loss = 0.16 (51.8 examples/sec; 0.155 sec/batch; 10h:00m:01s remains)
INFO - root - 2017-12-01 06:57:19.393865: step 99580, loss = 0.30, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 10h:00m:28s remains)
INFO - root - 2017-12-01 06:57:20.948562: step 99590, loss = 0.31, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 10h:04m:11s remains)
INFO - root - 2017-12-01 06:57:22.528199: step 99600, loss = 0.42, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 10h:12m:30s remains)
INFO - root - 2017-12-01 06:57:24.142274: step 99610, loss = 0.27, batch loss = 0.15 (51.4 examples/sec; 0.156 sec/batch; 10h:03m:41s remains)
INFO - root - 2017-12-01 06:57:25.719167: step 99620, loss = 0.36, batch loss = 0.24 (49.5 examples/sec; 0.162 sec/batch; 10h:26m:56s remains)
INFO - root - 2017-12-01 06:57:27.288792: step 99630, loss = 0.26, batch loss = 0.14 (49.9 examples/sec; 0.160 sec/batch; 10h:22m:44s remains)
INFO - root - 2017-12-01 06:57:28.843879: step 99640, loss = 0.32, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 10h:09m:56s remains)
INFO - root - 2017-12-01 06:57:30.432385: step 99650, loss = 0.34, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 10h:05m:38s remains)
INFO - root - 2017-12-01 06:57:31.987758: step 99660, loss = 0.40, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 10h:13m:32s remains)
INFO - root - 2017-12-01 06:57:33.561320: step 99670, loss = 0.33, batch loss = 0.21 (49.4 examples/sec; 0.162 sec/batch; 10h:28m:11s remains)
INFO - root - 2017-12-01 06:57:35.121644: step 99680, loss = 0.30, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 10h:17m:03s remains)
INFO - root - 2017-12-01 06:57:36.696998: step 99690, loss = 0.42, batch loss = 0.30 (49.2 examples/sec; 0.163 sec/batch; 10h:30m:36s remains)
INFO - root - 2017-12-01 06:57:38.259063: step 99700, loss = 0.41, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 10h:09m:26s remains)
INFO - root - 2017-12-01 06:57:39.889692: step 99710, loss = 0.53, batch loss = 0.41 (50.9 examples/sec; 0.157 sec/batch; 10h:09m:52s remains)
INFO - root - 2017-12-01 06:57:41.435952: step 99720, loss = 0.30, batch loss = 0.18 (52.9 examples/sec; 0.151 sec/batch; 9h:46m:14s remains)
INFO - root - 2017-12-01 06:57:43.017760: step 99730, loss = 0.28, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 10h:04m:50s remains)
INFO - root - 2017-12-01 06:57:44.602359: step 99740, loss = 0.28, batch loss = 0.15 (52.1 examples/sec; 0.154 sec/batch; 9h:56m:13s remains)
INFO - root - 2017-12-01 06:57:46.141867: step 99750, loss = 0.31, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 9h:57m:50s remains)
INFO - root - 2017-12-01 06:57:47.710726: step 99760, loss = 0.25, batch loss = 0.13 (51.9 examples/sec; 0.154 sec/batch; 9h:58m:14s remains)
INFO - root - 2017-12-01 06:57:49.262377: step 99770, loss = 0.40, batch loss = 0.28 (52.2 examples/sec; 0.153 sec/batch; 9h:54m:52s remains)
INFO - root - 2017-12-01 06:57:50.813897: step 99780, loss = 0.36, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 9h:54m:43s remains)
INFO - root - 2017-12-01 06:57:52.371752: step 99790, loss = 0.37, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 10h:03m:58s remains)
INFO - root - 2017-12-01 06:57:53.953885: step 99800, loss = 0.58, batch loss = 0.46 (49.8 examples/sec; 0.161 sec/batch; 10h:23m:12s remains)
INFO - root - 2017-12-01 06:57:55.600767: step 99810, loss = 0.30, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 10h:03m:13s remains)
INFO - root - 2017-12-01 06:57:57.157444: step 99820, loss = 0.33, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 10h:05m:35s remains)
INFO - root - 2017-12-01 06:57:58.724387: step 99830, loss = 0.26, batch loss = 0.14 (49.7 examples/sec; 0.161 sec/batch; 10h:24m:40s remains)
INFO - root - 2017-12-01 06:58:00.374861: step 99840, loss = 0.32, batch loss = 0.20 (38.0 examples/sec; 0.211 sec/batch; 13h:36m:53s remains)
INFO - root - 2017-12-01 06:58:01.942050: step 99850, loss = 0.31, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 10h:00m:41s remains)
INFO - root - 2017-12-01 06:58:03.500440: step 99860, loss = 0.36, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 9h:57m:00s remains)
INFO - root - 2017-12-01 06:58:05.070408: step 99870, loss = 0.34, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 9h:56m:01s remains)
INFO - root - 2017-12-01 06:58:06.649159: step 99880, loss = 0.33, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 10h:14m:48s remains)
INFO - root - 2017-12-01 06:58:08.211911: step 99890, loss = 0.36, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 10h:16m:30s remains)
INFO - root - 2017-12-01 06:58:09.768566: step 99900, loss = 0.43, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 10h:08m:16s remains)
INFO - root - 2017-12-01 06:58:11.427283: step 99910, loss = 0.40, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 10h:00m:21s remains)
INFO - root - 2017-12-01 06:58:12.996699: step 99920, loss = 0.32, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 10h:01m:38s remains)
INFO - root - 2017-12-01 06:58:14.556202: step 99930, loss = 0.39, batch loss = 0.27 (49.7 examples/sec; 0.161 sec/batch; 10h:23m:39s remains)
INFO - root - 2017-12-01 06:58:16.106482: step 99940, loss = 0.35, batch loss = 0.23 (52.1 examples/sec; 0.153 sec/batch; 9h:54m:42s remains)
INFO - root - 2017-12-01 06:58:17.723522: step 99950, loss = 0.30, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 10h:05m:41s remains)
INFO - root - 2017-12-01 06:58:19.292231: step 99960, loss = 0.40, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 10h:05m:46s remains)
INFO - root - 2017-12-01 06:58:20.840452: step 99970, loss = 0.27, batch loss = 0.15 (52.6 examples/sec; 0.152 sec/batch; 9h:49m:07s remains)
INFO - root - 2017-12-01 06:58:22.397252: step 99980, loss = 0.36, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 9h:57m:30s remains)
INFO - root - 2017-12-01 06:58:23.951562: step 99990, loss = 0.37, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 10h:13m:06s remains)
INFO - root - 2017-12-01 06:58:25.509164: step 100000, loss = 0.30, batch loss = 0.18 (52.2 examples/sec; 0.153 sec/batch; 9h:53m:35s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-100000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-100000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-01 06:58:27.403868: step 100010, loss = 0.34, batch loss = 0.22 (47.3 examples/sec; 0.169 sec/batch; 10h:54m:49s remains)
INFO - root - 2017-12-01 06:58:28.957028: step 100020, loss = 0.29, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 10h:05m:03s remains)
INFO - root - 2017-12-01 06:58:30.521989: step 100030, loss = 0.40, batch loss = 0.28 (50.8 examples/sec; 0.158 sec/batch; 10h:10m:25s remains)
INFO - root - 2017-12-01 06:58:32.084030: step 100040, loss = 0.28, batch loss = 0.16 (52.1 examples/sec; 0.154 sec/batch; 9h:55m:11s remains)
INFO - root - 2017-12-01 06:58:33.645105: step 100050, loss = 0.31, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 10h:01m:44s remains)
INFO - root - 2017-12-01 06:58:35.224615: step 100060, loss = 0.30, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 10h:03m:53s remains)
INFO - root - 2017-12-01 06:58:36.776690: step 100070, loss = 0.28, batch loss = 0.16 (50.6 examples/sec; 0.158 sec/batch; 10h:11m:57s remains)
INFO - root - 2017-12-01 06:58:38.338385: step 100080, loss = 0.48, batch loss = 0.36 (48.9 examples/sec; 0.164 sec/batch; 10h:33m:48s remains)
INFO - root - 2017-12-01 06:58:39.910074: step 100090, loss = 0.28, batch loss = 0.16 (48.5 examples/sec; 0.165 sec/batch; 10h:38m:18s remains)
INFO - root - 2017-12-01 06:58:41.505019: step 100100, loss = 0.34, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 10h:06m:41s remains)
INFO - root - 2017-12-01 06:58:43.115405: step 100110, loss = 0.28, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 10h:00m:53s remains)
INFO - root - 2017-12-01 06:58:44.687003: step 100120, loss = 0.31, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 10h:00m:24s remains)
INFO - root - 2017-12-01 06:58:46.287280: step 100130, loss = 0.36, batch loss = 0.24 (47.6 examples/sec; 0.168 sec/batch; 10h:51m:29s remains)
INFO - root - 2017-12-01 06:58:47.838655: step 100140, loss = 0.32, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 10h:02m:51s remains)
INFO - root - 2017-12-01 06:58:49.396824: step 100150, loss = 0.40, batch loss = 0.28 (52.1 examples/sec; 0.154 sec/batch; 9h:55m:08s remains)
INFO - root - 2017-12-01 06:58:50.953804: step 100160, loss = 0.34, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 9h:49m:20s remains)
INFO - root - 2017-12-01 06:58:52.547668: step 100170, loss = 0.29, batch loss = 0.17 (50.8 examples/sec; 0.158 sec/batch; 10h:09m:52s remains)
INFO - root - 2017-12-01 06:58:54.100265: step 100180, loss = 0.33, batch loss = 0.21 (52.6 examples/sec; 0.152 sec/batch; 9h:49m:06s remains)
INFO - root - 2017-12-01 06:58:55.653448: step 100190, loss = 0.32, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 10h:09m:30s remains)
INFO - root - 2017-12-01 06:58:57.227186: step 100200, loss = 0.42, batch loss = 0.30 (51.1 examples/sec; 0.157 sec/batch; 10h:06m:20s remains)
INFO - root - 2017-12-01 06:58:58.840698: step 100210, loss = 0.36, batch loss = 0.24 (52.1 examples/sec; 0.154 sec/batch; 9h:54m:20s remains)
INFO - root - 2017-12-01 06:59:00.401192: step 100220, loss = 0.37, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 10h:11m:02s remains)
INFO - root - 2017-12-01 06:59:01.961962: step 100230, loss = 0.34, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 9h:59m:57s remains)
INFO - root - 2017-12-01 06:59:03.531010: step 100240, loss = 0.30, batch loss = 0.18 (52.5 examples/sec; 0.152 sec/batch; 9h:49m:40s remains)
INFO - root - 2017-12-01 06:59:05.103020: step 100250, loss = 0.36, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 10h:06m:43s remains)
INFO - root - 2017-12-01 06:59:06.678701: step 100260, loss = 0.32, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 9h:53m:35s remains)
INFO - root - 2017-12-01 06:59:08.224093: step 100270, loss = 0.43, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 10h:08m:38s remains)
INFO - root - 2017-12-01 06:59:09.801833: step 100280, loss = 0.29, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 10h:12m:06s remains)
INFO - root - 2017-12-01 06:59:11.373595: step 100290, loss = 0.33, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 9h:53m:20s remains)
INFO - root - 2017-12-01 06:59:12.934928: step 100300, loss = 0.33, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 9h:54m:36s remains)
INFO - root - 2017-12-01 06:59:14.541461: step 100310, loss = 0.33, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 10h:09m:08s remains)
INFO - root - 2017-12-01 06:59:16.102304: step 100320, loss = 0.40, batch loss = 0.28 (53.4 examples/sec; 0.150 sec/batch; 9h:39m:29s remains)
INFO - root - 2017-12-01 06:59:17.661878: step 100330, loss = 0.30, batch loss = 0.18 (52.6 examples/sec; 0.152 sec/batch; 9h:48m:47s remains)
INFO - root - 2017-12-01 06:59:19.220725: step 100340, loss = 0.37, batch loss = 0.25 (52.9 examples/sec; 0.151 sec/batch; 9h:45m:01s remains)
INFO - root - 2017-12-01 06:59:20.814224: step 100350, loss = 0.35, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 10h:08m:39s remains)
INFO - root - 2017-12-01 06:59:22.372034: step 100360, loss = 0.28, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 9h:57m:03s remains)
INFO - root - 2017-12-01 06:59:23.931289: step 100370, loss = 0.30, batch loss = 0.18 (52.7 examples/sec; 0.152 sec/batch; 9h:47m:03s remains)
INFO - root - 2017-12-01 06:59:25.522441: step 100380, loss = 0.39, batch loss = 0.27 (50.2 examples/sec; 0.159 sec/batch; 10h:16m:34s remains)
INFO - root - 2017-12-01 06:59:27.108089: step 100390, loss = 0.31, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 10h:00m:53s remains)
INFO - root - 2017-12-01 06:59:28.687367: step 100400, loss = 0.32, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 10h:08m:37s remains)
INFO - root - 2017-12-01 06:59:30.310010: step 100410, loss = 0.41, batch loss = 0.29 (51.8 examples/sec; 0.155 sec/batch; 9h:57m:44s remains)
INFO - root - 2017-12-01 06:59:31.878079: step 100420, loss = 0.37, batch loss = 0.25 (49.1 examples/sec; 0.163 sec/batch; 10h:30m:42s remains)
INFO - root - 2017-12-01 06:59:33.432206: step 100430, loss = 0.28, batch loss = 0.16 (53.5 examples/sec; 0.149 sec/batch; 9h:37m:58s remains)
INFO - root - 2017-12-01 06:59:34.981582: step 100440, loss = 0.33, batch loss = 0.21 (53.5 examples/sec; 0.150 sec/batch; 9h:38m:33s remains)
INFO - root - 2017-12-01 06:59:36.557884: step 100450, loss = 0.29, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 10h:14m:28s remains)
INFO - root - 2017-12-01 06:59:38.110821: step 100460, loss = 0.50, batch loss = 0.38 (50.6 examples/sec; 0.158 sec/batch; 10h:11m:08s remains)
INFO - root - 2017-12-01 06:59:39.668125: step 100470, loss = 0.35, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 10h:01m:21s remains)
INFO - root - 2017-12-01 06:59:41.231936: step 100480, loss = 0.42, batch loss = 0.30 (53.6 examples/sec; 0.149 sec/batch; 9h:37m:38s remains)
INFO - root - 2017-12-01 06:59:42.793963: step 100490, loss = 0.34, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 9h:51m:05s remains)
INFO - root - 2017-12-01 06:59:44.369615: step 100500, loss = 0.34, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 9h:57m:45s remains)
INFO - root - 2017-12-01 06:59:45.987519: step 100510, loss = 0.29, batch loss = 0.17 (52.9 examples/sec; 0.151 sec/batch; 9h:44m:59s remains)
INFO - root - 2017-12-01 06:59:47.549072: step 100520, loss = 0.28, batch loss = 0.16 (52.1 examples/sec; 0.154 sec/batch; 9h:53m:40s remains)
INFO - root - 2017-12-01 06:59:49.123984: step 100530, loss = 0.42, batch loss = 0.30 (51.0 examples/sec; 0.157 sec/batch; 10h:06m:39s remains)
INFO - root - 2017-12-01 06:59:50.672314: step 100540, loss = 0.32, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 10h:07m:15s remains)
INFO - root - 2017-12-01 06:59:52.243259: step 100550, loss = 0.34, batch loss = 0.22 (48.5 examples/sec; 0.165 sec/batch; 10h:37m:21s remains)
INFO - root - 2017-12-01 06:59:53.799299: step 100560, loss = 0.33, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 9h:56m:56s remains)
INFO - root - 2017-12-01 06:59:55.371843: step 100570, loss = 0.34, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 9h:52m:22s remains)
INFO - root - 2017-12-01 06:59:56.913204: step 100580, loss = 0.48, batch loss = 0.36 (53.2 examples/sec; 0.150 sec/batch; 9h:41m:30s remains)
INFO - root - 2017-12-01 06:59:58.503638: step 100590, loss = 0.50, batch loss = 0.38 (51.3 examples/sec; 0.156 sec/batch; 10h:02m:26s remains)
INFO - root - 2017-12-01 07:00:00.063334: step 100600, loss = 0.41, batch loss = 0.29 (50.0 examples/sec; 0.160 sec/batch; 10h:18m:19s remains)
INFO - root - 2017-12-01 07:00:01.685938: step 100610, loss = 0.33, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 9h:48m:24s remains)
INFO - root - 2017-12-01 07:00:03.245057: step 100620, loss = 0.40, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 10h:09m:16s remains)
INFO - root - 2017-12-01 07:00:04.801420: step 100630, loss = 0.35, batch loss = 0.23 (49.8 examples/sec; 0.161 sec/batch; 10h:21m:03s remains)
INFO - root - 2017-12-01 07:00:06.367166: step 100640, loss = 0.37, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 10h:13m:37s remains)
INFO - root - 2017-12-01 07:00:07.938953: step 100650, loss = 0.43, batch loss = 0.31 (52.9 examples/sec; 0.151 sec/batch; 9h:43m:50s remains)
INFO - root - 2017-12-01 07:00:09.545908: step 100660, loss = 0.27, batch loss = 0.15 (50.3 examples/sec; 0.159 sec/batch; 10h:14m:44s remains)
INFO - root - 2017-12-01 07:00:11.138560: step 100670, loss = 0.28, batch loss = 0.16 (49.1 examples/sec; 0.163 sec/batch; 10h:29m:49s remains)
INFO - root - 2017-12-01 07:00:12.736440: step 100680, loss = 0.30, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 9h:50m:48s remains)
INFO - root - 2017-12-01 07:00:14.300887: step 100690, loss = 0.43, batch loss = 0.31 (50.1 examples/sec; 0.160 sec/batch; 10h:16m:51s remains)
INFO - root - 2017-12-01 07:00:15.872144: step 100700, loss = 0.32, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 10h:16m:22s remains)
INFO - root - 2017-12-01 07:00:17.525370: step 100710, loss = 0.38, batch loss = 0.26 (50.3 examples/sec; 0.159 sec/batch; 10h:14m:14s remains)
INFO - root - 2017-12-01 07:00:19.088043: step 100720, loss = 0.34, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 9h:57m:51s remains)
INFO - root - 2017-12-01 07:00:20.649919: step 100730, loss = 0.30, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 9h:55m:16s remains)
INFO - root - 2017-12-01 07:00:22.217422: step 100740, loss = 0.37, batch loss = 0.25 (48.8 examples/sec; 0.164 sec/batch; 10h:33m:50s remains)
INFO - root - 2017-12-01 07:00:23.811727: step 100750, loss = 0.30, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 10h:02m:10s remains)
INFO - root - 2017-12-01 07:00:25.381805: step 100760, loss = 0.30, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 10h:09m:09s remains)
INFO - root - 2017-12-01 07:00:26.931281: step 100770, loss = 0.39, batch loss = 0.27 (51.2 examples/sec; 0.156 sec/batch; 10h:03m:48s remains)
INFO - root - 2017-12-01 07:00:28.508430: step 100780, loss = 0.35, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 9h:46m:35s remains)
INFO - root - 2017-12-01 07:00:30.079493: step 100790, loss = 0.31, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 9h:57m:41s remains)
INFO - root - 2017-12-01 07:00:31.626949: step 100800, loss = 0.28, batch loss = 0.16 (52.4 examples/sec; 0.153 sec/batch; 9h:49m:02s remains)
INFO - root - 2017-12-01 07:00:33.235473: step 100810, loss = 0.32, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 9h:50m:21s remains)
INFO - root - 2017-12-01 07:00:34.811297: step 100820, loss = 0.33, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 10h:05m:45s remains)
INFO - root - 2017-12-01 07:00:36.372089: step 100830, loss = 0.29, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 9h:55m:40s remains)
INFO - root - 2017-12-01 07:00:37.935686: step 100840, loss = 0.39, batch loss = 0.27 (51.1 examples/sec; 0.156 sec/batch; 10h:04m:04s remains)
INFO - root - 2017-12-01 07:00:39.496232: step 100850, loss = 0.50, batch loss = 0.38 (50.1 examples/sec; 0.160 sec/batch; 10h:16m:43s remains)
INFO - root - 2017-12-01 07:00:41.071042: step 100860, loss = 0.30, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 9h:55m:32s remains)
INFO - root - 2017-12-01 07:00:42.644186: step 100870, loss = 0.28, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 10h:08m:59s remains)
INFO - root - 2017-12-01 07:00:44.211510: step 100880, loss = 0.31, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 9h:49m:43s remains)
INFO - root - 2017-12-01 07:00:45.779502: step 100890, loss = 0.34, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 10h:14m:46s remains)
INFO - root - 2017-12-01 07:00:47.358239: step 100900, loss = 0.37, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 9h:59m:33s remains)
INFO - root - 2017-12-01 07:00:48.986857: step 100910, loss = 0.38, batch loss = 0.26 (50.8 examples/sec; 0.158 sec/batch; 10h:08m:12s remains)
INFO - root - 2017-12-01 07:00:50.571796: step 100920, loss = 0.35, batch loss = 0.23 (48.8 examples/sec; 0.164 sec/batch; 10h:32m:46s remains)
INFO - root - 2017-12-01 07:00:52.143900: step 100930, loss = 0.30, batch loss = 0.18 (52.6 examples/sec; 0.152 sec/batch; 9h:46m:43s remains)
INFO - root - 2017-12-01 07:00:53.723455: step 100940, loss = 0.32, batch loss = 0.20 (49.8 examples/sec; 0.161 sec/batch; 10h:19m:25s remains)
INFO - root - 2017-12-01 07:00:55.284845: step 100950, loss = 0.25, batch loss = 0.13 (50.2 examples/sec; 0.159 sec/batch; 10h:14m:32s remains)
INFO - root - 2017-12-01 07:00:56.856220: step 100960, loss = 0.35, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 10h:09m:43s remains)
INFO - root - 2017-12-01 07:00:58.437787: step 100970, loss = 0.31, batch loss = 0.20 (52.9 examples/sec; 0.151 sec/batch; 9h:43m:57s remains)
INFO - root - 2017-12-01 07:00:59.996863: step 100980, loss = 0.34, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 9h:57m:09s remains)
INFO - root - 2017-12-01 07:01:01.564278: step 100990, loss = 0.27, batch loss = 0.15 (51.2 examples/sec; 0.156 sec/batch; 10h:03m:12s remains)
INFO - root - 2017-12-01 07:01:03.130734: step 101000, loss = 0.34, batch loss = 0.22 (49.4 examples/sec; 0.162 sec/batch; 10h:24m:15s remains)
INFO - root - 2017-12-01 07:01:04.771990: step 101010, loss = 0.38, batch loss = 0.26 (50.8 examples/sec; 0.157 sec/batch; 10h:07m:02s remains)
INFO - root - 2017-12-01 07:01:06.330428: step 101020, loss = 0.34, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 10h:04m:00s remains)
INFO - root - 2017-12-01 07:01:07.901534: step 101030, loss = 0.29, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 9h:57m:09s remains)
INFO - root - 2017-12-01 07:01:09.474129: step 101040, loss = 0.32, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 9h:46m:51s remains)
INFO - root - 2017-12-01 07:01:11.059012: step 101050, loss = 0.41, batch loss = 0.29 (51.4 examples/sec; 0.156 sec/batch; 9h:59m:55s remains)
INFO - root - 2017-12-01 07:01:12.633639: step 101060, loss = 0.45, batch loss = 0.33 (50.2 examples/sec; 0.159 sec/batch; 10h:15m:05s remains)
INFO - root - 2017-12-01 07:01:14.207236: step 101070, loss = 0.38, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 10h:04m:42s remains)
INFO - root - 2017-12-01 07:01:15.815833: step 101080, loss = 0.32, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 10h:02m:56s remains)
INFO - root - 2017-12-01 07:01:17.415916: step 101090, loss = 0.35, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 10h:07m:40s remains)
INFO - root - 2017-12-01 07:01:18.966690: step 101100, loss = 0.37, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 9h:55m:36s remains)
INFO - root - 2017-12-01 07:01:20.599000: step 101110, loss = 0.32, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 10h:03m:15s remains)
INFO - root - 2017-12-01 07:01:22.157519: step 101120, loss = 0.40, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 10h:02m:20s remains)
INFO - root - 2017-12-01 07:01:23.716301: step 101130, loss = 0.34, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 9h:53m:54s remains)
INFO - root - 2017-12-01 07:01:25.302472: step 101140, loss = 0.30, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 10h:10m:10s remains)
INFO - root - 2017-12-01 07:01:26.854585: step 101150, loss = 0.48, batch loss = 0.36 (52.5 examples/sec; 0.153 sec/batch; 9h:48m:02s remains)
INFO - root - 2017-12-01 07:01:28.428366: step 101160, loss = 0.35, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 10h:07m:59s remains)
INFO - root - 2017-12-01 07:01:29.984296: step 101170, loss = 0.30, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 9h:54m:49s remains)
INFO - root - 2017-12-01 07:01:31.566559: step 101180, loss = 0.36, batch loss = 0.24 (49.8 examples/sec; 0.161 sec/batch; 10h:19m:13s remains)
INFO - root - 2017-12-01 07:01:33.127171: step 101190, loss = 0.44, batch loss = 0.32 (51.5 examples/sec; 0.155 sec/batch; 9h:58m:34s remains)
INFO - root - 2017-12-01 07:01:34.700488: step 101200, loss = 0.33, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 9h:59m:44s remains)
INFO - root - 2017-12-01 07:01:36.325004: step 101210, loss = 0.29, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 9h:58m:52s remains)
INFO - root - 2017-12-01 07:01:37.898365: step 101220, loss = 0.28, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 9h:52m:40s remains)
INFO - root - 2017-12-01 07:01:39.470582: step 101230, loss = 0.37, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 9h:59m:22s remains)
INFO - root - 2017-12-01 07:01:41.028940: step 101240, loss = 0.34, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 10h:04m:18s remains)
INFO - root - 2017-12-01 07:01:42.596879: step 101250, loss = 0.31, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 9h:48m:00s remains)
INFO - root - 2017-12-01 07:01:44.171697: step 101260, loss = 0.48, batch loss = 0.36 (50.7 examples/sec; 0.158 sec/batch; 10h:07m:51s remains)
INFO - root - 2017-12-01 07:01:45.738189: step 101270, loss = 0.34, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 10h:04m:50s remains)
INFO - root - 2017-12-01 07:01:47.298116: step 101280, loss = 0.28, batch loss = 0.17 (50.1 examples/sec; 0.160 sec/batch; 10h:14m:53s remains)
INFO - root - 2017-12-01 07:01:48.865104: step 101290, loss = 0.31, batch loss = 0.19 (49.7 examples/sec; 0.161 sec/batch; 10h:20m:07s remains)
INFO - root - 2017-12-01 07:01:50.431333: step 101300, loss = 0.26, batch loss = 0.14 (52.9 examples/sec; 0.151 sec/batch; 9h:43m:13s remains)
INFO - root - 2017-12-01 07:01:52.067462: step 101310, loss = 0.38, batch loss = 0.26 (45.5 examples/sec; 0.176 sec/batch; 11h:17m:32s remains)
INFO - root - 2017-12-01 07:01:53.622945: step 101320, loss = 0.34, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 10h:00m:17s remains)
INFO - root - 2017-12-01 07:01:55.185889: step 101330, loss = 0.46, batch loss = 0.34 (51.7 examples/sec; 0.155 sec/batch; 9h:56m:14s remains)
INFO - root - 2017-12-01 07:01:56.765893: step 101340, loss = 0.31, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 9h:47m:49s remains)
INFO - root - 2017-12-01 07:01:58.335138: step 101350, loss = 0.30, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 10h:07m:07s remains)
INFO - root - 2017-12-01 07:01:59.978272: step 101360, loss = 0.39, batch loss = 0.27 (33.7 examples/sec; 0.237 sec/batch; 15h:13m:52s remains)
INFO - root - 2017-12-01 07:02:01.554903: step 101370, loss = 0.32, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 10h:14m:20s remains)
INFO - root - 2017-12-01 07:02:03.117658: step 101380, loss = 0.29, batch loss = 0.17 (50.2 examples/sec; 0.159 sec/batch; 10h:13m:40s remains)
INFO - root - 2017-12-01 07:02:04.672725: step 101390, loss = 0.37, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 10h:11m:39s remains)
INFO - root - 2017-12-01 07:02:06.242036: step 101400, loss = 0.40, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 10h:00m:42s remains)
INFO - root - 2017-12-01 07:02:07.840550: step 101410, loss = 0.33, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 10h:06m:49s remains)
INFO - root - 2017-12-01 07:02:09.385961: step 101420, loss = 0.37, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 9h:53m:33s remains)
INFO - root - 2017-12-01 07:02:10.939544: step 101430, loss = 0.38, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 10h:01m:48s remains)
INFO - root - 2017-12-01 07:02:12.494048: step 101440, loss = 0.35, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 9h:49m:23s remains)
INFO - root - 2017-12-01 07:02:14.074678: step 101450, loss = 0.45, batch loss = 0.33 (51.5 examples/sec; 0.155 sec/batch; 9h:58m:42s remains)
INFO - root - 2017-12-01 07:02:15.628944: step 101460, loss = 0.39, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 9h:57m:46s remains)
INFO - root - 2017-12-01 07:02:17.201553: step 101470, loss = 0.38, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 10h:08m:34s remains)
INFO - root - 2017-12-01 07:02:18.783866: step 101480, loss = 0.35, batch loss = 0.23 (49.0 examples/sec; 0.163 sec/batch; 10h:28m:40s remains)
INFO - root - 2017-12-01 07:02:20.349937: step 101490, loss = 0.35, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 9h:47m:52s remains)
INFO - root - 2017-12-01 07:02:21.911085: step 101500, loss = 0.29, batch loss = 0.17 (52.6 examples/sec; 0.152 sec/batch; 9h:45m:39s remains)
INFO - root - 2017-12-01 07:02:23.533008: step 101510, loss = 0.29, batch loss = 0.17 (49.5 examples/sec; 0.161 sec/batch; 10h:21m:40s remains)
INFO - root - 2017-12-01 07:02:25.088122: step 101520, loss = 0.28, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 10h:01m:19s remains)
INFO - root - 2017-12-01 07:02:26.633998: step 101530, loss = 0.27, batch loss = 0.15 (53.0 examples/sec; 0.151 sec/batch; 9h:40m:34s remains)
INFO - root - 2017-12-01 07:02:28.202569: step 101540, loss = 0.26, batch loss = 0.14 (51.9 examples/sec; 0.154 sec/batch; 9h:53m:52s remains)
INFO - root - 2017-12-01 07:02:29.773220: step 101550, loss = 0.32, batch loss = 0.20 (49.8 examples/sec; 0.161 sec/batch; 10h:18m:28s remains)
INFO - root - 2017-12-01 07:02:31.334839: step 101560, loss = 0.31, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 10h:21m:51s remains)
INFO - root - 2017-12-01 07:02:32.902620: step 101570, loss = 0.30, batch loss = 0.18 (49.9 examples/sec; 0.160 sec/batch; 10h:16m:29s remains)
INFO - root - 2017-12-01 07:02:34.466800: step 101580, loss = 0.45, batch loss = 0.33 (51.2 examples/sec; 0.156 sec/batch; 10h:01m:44s remains)
INFO - root - 2017-12-01 07:02:36.069429: step 101590, loss = 0.32, batch loss = 0.20 (48.8 examples/sec; 0.164 sec/batch; 10h:30m:34s remains)
INFO - root - 2017-12-01 07:02:37.639601: step 101600, loss = 0.32, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 10h:16m:45s remains)
INFO - root - 2017-12-01 07:02:39.284953: step 101610, loss = 0.32, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 9h:53m:02s remains)
INFO - root - 2017-12-01 07:02:40.852078: step 101620, loss = 0.34, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 10h:10m:24s remains)
INFO - root - 2017-12-01 07:02:42.407253: step 101630, loss = 0.41, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 9h:53m:20s remains)
INFO - root - 2017-12-01 07:02:43.981179: step 101640, loss = 0.30, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 9h:58m:15s remains)
INFO - root - 2017-12-01 07:02:45.551143: step 101650, loss = 0.38, batch loss = 0.26 (52.3 examples/sec; 0.153 sec/batch; 9h:48m:04s remains)
INFO - root - 2017-12-01 07:02:47.111906: step 101660, loss = 0.31, batch loss = 0.19 (51.8 examples/sec; 0.155 sec/batch; 9h:54m:40s remains)
INFO - root - 2017-12-01 07:02:48.670882: step 101670, loss = 0.33, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 9h:56m:30s remains)
INFO - root - 2017-12-01 07:02:50.233173: step 101680, loss = 0.32, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 9h:59m:57s remains)
INFO - root - 2017-12-01 07:02:51.812737: step 101690, loss = 0.30, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 10h:00m:42s remains)
INFO - root - 2017-12-01 07:02:53.391316: step 101700, loss = 0.35, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 10h:07m:15s remains)
INFO - root - 2017-12-01 07:02:55.000440: step 101710, loss = 0.31, batch loss = 0.19 (49.1 examples/sec; 0.163 sec/batch; 10h:26m:14s remains)
INFO - root - 2017-12-01 07:02:56.569045: step 101720, loss = 0.25, batch loss = 0.13 (52.1 examples/sec; 0.154 sec/batch; 9h:50m:42s remains)
INFO - root - 2017-12-01 07:02:58.161396: step 101730, loss = 0.43, batch loss = 0.31 (50.8 examples/sec; 0.157 sec/batch; 10h:05m:43s remains)
INFO - root - 2017-12-01 07:02:59.716746: step 101740, loss = 0.55, batch loss = 0.43 (50.6 examples/sec; 0.158 sec/batch; 10h:07m:48s remains)
INFO - root - 2017-12-01 07:03:01.272994: step 101750, loss = 0.29, batch loss = 0.17 (48.4 examples/sec; 0.165 sec/batch; 10h:35m:36s remains)
INFO - root - 2017-12-01 07:03:02.839123: step 101760, loss = 0.32, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 9h:55m:34s remains)
INFO - root - 2017-12-01 07:03:04.419950: step 101770, loss = 0.29, batch loss = 0.18 (52.1 examples/sec; 0.153 sec/batch; 9h:50m:10s remains)
INFO - root - 2017-12-01 07:03:05.983987: step 101780, loss = 0.35, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 9h:53m:07s remains)
INFO - root - 2017-12-01 07:03:07.548603: step 101790, loss = 0.30, batch loss = 0.18 (50.1 examples/sec; 0.160 sec/batch; 10h:14m:26s remains)
INFO - root - 2017-12-01 07:03:09.098875: step 101800, loss = 0.36, batch loss = 0.25 (53.2 examples/sec; 0.150 sec/batch; 9h:37m:40s remains)
INFO - root - 2017-12-01 07:03:10.784487: step 101810, loss = 0.34, batch loss = 0.22 (49.9 examples/sec; 0.160 sec/batch; 10h:16m:22s remains)
INFO - root - 2017-12-01 07:03:12.354128: step 101820, loss = 0.38, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 10h:06m:38s remains)
INFO - root - 2017-12-01 07:03:13.919181: step 101830, loss = 0.29, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 10h:03m:38s remains)
INFO - root - 2017-12-01 07:03:15.522704: step 101840, loss = 0.29, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 9h:59m:27s remains)
INFO - root - 2017-12-01 07:03:17.069966: step 101850, loss = 0.38, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 9h:56m:21s remains)
INFO - root - 2017-12-01 07:03:18.666467: step 101860, loss = 0.27, batch loss = 0.15 (49.4 examples/sec; 0.162 sec/batch; 10h:22m:33s remains)
INFO - root - 2017-12-01 07:03:20.251168: step 101870, loss = 0.37, batch loss = 0.25 (50.5 examples/sec; 0.158 sec/batch; 10h:08m:51s remains)
INFO - root - 2017-12-01 07:03:21.826371: step 101880, loss = 0.40, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 9h:58m:26s remains)
INFO - root - 2017-12-01 07:03:23.389373: step 101890, loss = 0.35, batch loss = 0.23 (52.8 examples/sec; 0.152 sec/batch; 9h:42m:47s remains)
INFO - root - 2017-12-01 07:03:24.977426: step 101900, loss = 0.42, batch loss = 0.30 (51.1 examples/sec; 0.157 sec/batch; 10h:01m:41s remains)
INFO - root - 2017-12-01 07:03:26.621574: step 101910, loss = 0.33, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 10h:14m:03s remains)
INFO - root - 2017-12-01 07:03:28.187647: step 101920, loss = 0.39, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 10h:03m:33s remains)
INFO - root - 2017-12-01 07:03:29.754270: step 101930, loss = 0.28, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 9h:59m:22s remains)
INFO - root - 2017-12-01 07:03:31.322002: step 101940, loss = 0.37, batch loss = 0.25 (50.8 examples/sec; 0.157 sec/batch; 10h:04m:47s remains)
INFO - root - 2017-12-01 07:03:32.875944: step 101950, loss = 0.26, batch loss = 0.14 (53.9 examples/sec; 0.149 sec/batch; 9h:30m:40s remains)
INFO - root - 2017-12-01 07:03:34.440587: step 101960, loss = 0.32, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 9h:53m:08s remains)
INFO - root - 2017-12-01 07:03:35.997168: step 101970, loss = 0.26, batch loss = 0.15 (52.3 examples/sec; 0.153 sec/batch; 9h:47m:47s remains)
INFO - root - 2017-12-01 07:03:37.575717: step 101980, loss = 0.38, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 9h:56m:07s remains)
INFO - root - 2017-12-01 07:03:39.150959: step 101990, loss = 0.33, batch loss = 0.21 (49.6 examples/sec; 0.161 sec/batch; 10h:19m:29s remains)
INFO - root - 2017-12-01 07:03:40.717612: step 102000, loss = 0.32, batch loss = 0.20 (51.8 examples/sec; 0.155 sec/batch; 9h:53m:41s remains)
INFO - root - 2017-12-01 07:03:42.400048: step 102010, loss = 0.34, batch loss = 0.22 (48.0 examples/sec; 0.167 sec/batch; 10h:40m:25s remains)
INFO - root - 2017-12-01 07:03:43.968760: step 102020, loss = 0.34, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 10h:05m:03s remains)
INFO - root - 2017-12-01 07:03:45.536284: step 102030, loss = 0.42, batch loss = 0.30 (51.7 examples/sec; 0.155 sec/batch; 9h:54m:18s remains)
INFO - root - 2017-12-01 07:03:47.113097: step 102040, loss = 0.29, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 10h:08m:21s remains)
INFO - root - 2017-12-01 07:03:48.673557: step 102050, loss = 0.27, batch loss = 0.15 (49.0 examples/sec; 0.163 sec/batch; 10h:27m:37s remains)
INFO - root - 2017-12-01 07:03:50.232824: step 102060, loss = 0.34, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 9h:57m:57s remains)
INFO - root - 2017-12-01 07:03:51.795060: step 102070, loss = 0.27, batch loss = 0.15 (51.4 examples/sec; 0.156 sec/batch; 9h:57m:33s remains)
INFO - root - 2017-12-01 07:03:53.366166: step 102080, loss = 0.40, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 10h:05m:30s remains)
INFO - root - 2017-12-01 07:03:54.935817: step 102090, loss = 0.38, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 10h:01m:23s remains)
INFO - root - 2017-12-01 07:03:56.522125: step 102100, loss = 0.31, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 10h:20m:11s remains)
INFO - root - 2017-12-01 07:03:58.190716: step 102110, loss = 0.37, batch loss = 0.25 (49.8 examples/sec; 0.161 sec/batch; 10h:17m:09s remains)
INFO - root - 2017-12-01 07:03:59.747888: step 102120, loss = 0.34, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 10h:10m:08s remains)
INFO - root - 2017-12-01 07:04:01.293367: step 102130, loss = 0.28, batch loss = 0.16 (52.5 examples/sec; 0.152 sec/batch; 9h:44m:46s remains)
INFO - root - 2017-12-01 07:04:02.883064: step 102140, loss = 0.32, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 9h:50m:00s remains)
INFO - root - 2017-12-01 07:04:04.452970: step 102150, loss = 0.30, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 10h:01m:57s remains)
INFO - root - 2017-12-01 07:04:06.010466: step 102160, loss = 0.34, batch loss = 0.22 (48.7 examples/sec; 0.164 sec/batch; 10h:30m:24s remains)
INFO - root - 2017-12-01 07:04:07.578780: step 102170, loss = 0.32, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 10h:09m:38s remains)
INFO - root - 2017-12-01 07:04:09.139456: step 102180, loss = 0.26, batch loss = 0.14 (52.3 examples/sec; 0.153 sec/batch; 9h:46m:53s remains)
INFO - root - 2017-12-01 07:04:10.703934: step 102190, loss = 0.32, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 10h:02m:11s remains)
INFO - root - 2017-12-01 07:04:12.263786: step 102200, loss = 0.28, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 9h:54m:02s remains)
INFO - root - 2017-12-01 07:04:13.900049: step 102210, loss = 0.39, batch loss = 0.27 (52.7 examples/sec; 0.152 sec/batch; 9h:43m:01s remains)
INFO - root - 2017-12-01 07:04:15.484898: step 102220, loss = 0.41, batch loss = 0.29 (49.8 examples/sec; 0.161 sec/batch; 10h:16m:03s remains)
INFO - root - 2017-12-01 07:04:17.035072: step 102230, loss = 0.41, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 9h:59m:56s remains)
INFO - root - 2017-12-01 07:04:18.598990: step 102240, loss = 0.28, batch loss = 0.16 (50.2 examples/sec; 0.159 sec/batch; 10h:11m:58s remains)
INFO - root - 2017-12-01 07:04:20.166407: step 102250, loss = 0.37, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 9h:44m:59s remains)
INFO - root - 2017-12-01 07:04:21.721382: step 102260, loss = 0.30, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 9h:56m:27s remains)
INFO - root - 2017-12-01 07:04:23.281840: step 102270, loss = 0.32, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 9h:49m:21s remains)
INFO - root - 2017-12-01 07:04:24.858371: step 102280, loss = 0.30, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 10h:07m:18s remains)
INFO - root - 2017-12-01 07:04:26.406939: step 102290, loss = 0.27, batch loss = 0.15 (51.5 examples/sec; 0.155 sec/batch; 9h:55m:35s remains)
INFO - root - 2017-12-01 07:04:27.950636: step 102300, loss = 0.47, batch loss = 0.35 (52.1 examples/sec; 0.154 sec/batch; 9h:49m:31s remains)
INFO - root - 2017-12-01 07:04:29.602763: step 102310, loss = 0.33, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 10h:04m:32s remains)
INFO - root - 2017-12-01 07:04:31.153186: step 102320, loss = 0.31, batch loss = 0.19 (50.2 examples/sec; 0.159 sec/batch; 10h:11m:51s remains)
INFO - root - 2017-12-01 07:04:32.718057: step 102330, loss = 0.36, batch loss = 0.25 (52.2 examples/sec; 0.153 sec/batch; 9h:48m:11s remains)
INFO - root - 2017-12-01 07:04:34.289227: step 102340, loss = 0.35, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 9h:55m:51s remains)
INFO - root - 2017-12-01 07:04:35.848038: step 102350, loss = 0.45, batch loss = 0.34 (52.0 examples/sec; 0.154 sec/batch; 9h:50m:06s remains)
INFO - root - 2017-12-01 07:04:37.418392: step 102360, loss = 0.43, batch loss = 0.31 (50.3 examples/sec; 0.159 sec/batch; 10h:09m:46s remains)
INFO - root - 2017-12-01 07:04:38.979516: step 102370, loss = 0.28, batch loss = 0.17 (50.2 examples/sec; 0.159 sec/batch; 10h:11m:04s remains)
INFO - root - 2017-12-01 07:04:40.573317: step 102380, loss = 0.29, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 10h:09m:08s remains)
INFO - root - 2017-12-01 07:04:42.165306: step 102390, loss = 0.45, batch loss = 0.33 (50.0 examples/sec; 0.160 sec/batch; 10h:13m:41s remains)
INFO - root - 2017-12-01 07:04:43.724722: step 102400, loss = 0.37, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 10h:06m:11s remains)
INFO - root - 2017-12-01 07:04:45.307023: step 102410, loss = 0.50, batch loss = 0.38 (51.1 examples/sec; 0.156 sec/batch; 9h:59m:54s remains)
INFO - root - 2017-12-01 07:04:46.886483: step 102420, loss = 0.31, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 10h:02m:09s remains)
INFO - root - 2017-12-01 07:04:48.474904: step 102430, loss = 0.35, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 10h:05m:25s remains)
INFO - root - 2017-12-01 07:04:50.036083: step 102440, loss = 0.33, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 9h:59m:41s remains)
INFO - root - 2017-12-01 07:04:51.600441: step 102450, loss = 0.29, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 9h:56m:08s remains)
INFO - root - 2017-12-01 07:04:53.161623: step 102460, loss = 0.31, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 9h:48m:01s remains)
INFO - root - 2017-12-01 07:04:54.719894: step 102470, loss = 0.34, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 10h:02m:02s remains)
INFO - root - 2017-12-01 07:04:56.292322: step 102480, loss = 0.30, batch loss = 0.18 (49.5 examples/sec; 0.162 sec/batch; 10h:19m:59s remains)
INFO - root - 2017-12-01 07:04:57.868695: step 102490, loss = 0.39, batch loss = 0.27 (49.4 examples/sec; 0.162 sec/batch; 10h:20m:56s remains)
INFO - root - 2017-12-01 07:04:59.420900: step 102500, loss = 0.36, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 9h:51m:04s remains)
INFO - root - 2017-12-01 07:05:01.045033: step 102510, loss = 0.30, batch loss = 0.18 (50.0 examples/sec; 0.160 sec/batch; 10h:13m:10s remains)
INFO - root - 2017-12-01 07:05:02.603854: step 102520, loss = 0.26, batch loss = 0.15 (50.3 examples/sec; 0.159 sec/batch; 10h:09m:21s remains)
INFO - root - 2017-12-01 07:05:04.169352: step 102530, loss = 0.30, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 9h:54m:01s remains)
INFO - root - 2017-12-01 07:05:05.725720: step 102540, loss = 0.34, batch loss = 0.23 (48.5 examples/sec; 0.165 sec/batch; 10h:32m:14s remains)
INFO - root - 2017-12-01 07:05:07.290286: step 102550, loss = 0.39, batch loss = 0.28 (52.5 examples/sec; 0.152 sec/batch; 9h:44m:16s remains)
INFO - root - 2017-12-01 07:05:08.874074: step 102560, loss = 0.35, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 9h:53m:48s remains)
INFO - root - 2017-12-01 07:05:10.428171: step 102570, loss = 0.28, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 9h:55m:23s remains)
INFO - root - 2017-12-01 07:05:11.982495: step 102580, loss = 0.29, batch loss = 0.17 (52.3 examples/sec; 0.153 sec/batch; 9h:46m:38s remains)
INFO - root - 2017-12-01 07:05:13.550509: step 102590, loss = 0.30, batch loss = 0.18 (53.1 examples/sec; 0.151 sec/batch; 9h:37m:01s remains)
INFO - root - 2017-12-01 07:05:15.140081: step 102600, loss = 0.34, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 9h:52m:34s remains)
INFO - root - 2017-12-01 07:05:16.783728: step 102610, loss = 0.30, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 10h:03m:55s remains)
INFO - root - 2017-12-01 07:05:18.379215: step 102620, loss = 0.37, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 10h:02m:16s remains)
INFO - root - 2017-12-01 07:05:19.929414: step 102630, loss = 0.38, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 9h:53m:16s remains)
INFO - root - 2017-12-01 07:05:21.483390: step 102640, loss = 0.31, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 9h:51m:15s remains)
INFO - root - 2017-12-01 07:05:23.052643: step 102650, loss = 0.44, batch loss = 0.32 (52.7 examples/sec; 0.152 sec/batch; 9h:41m:24s remains)
INFO - root - 2017-12-01 07:05:24.630513: step 102660, loss = 0.36, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 9h:49m:30s remains)
INFO - root - 2017-12-01 07:05:26.193970: step 102670, loss = 0.34, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 10h:03m:40s remains)
INFO - root - 2017-12-01 07:05:27.754171: step 102680, loss = 0.33, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 10h:06m:16s remains)
INFO - root - 2017-12-01 07:05:29.334982: step 102690, loss = 0.31, batch loss = 0.19 (47.8 examples/sec; 0.167 sec/batch; 10h:41m:17s remains)
INFO - root - 2017-12-01 07:05:30.944469: step 102700, loss = 0.34, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 9h:56m:17s remains)
INFO - root - 2017-12-01 07:05:32.603492: step 102710, loss = 0.29, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 10h:03m:04s remains)
INFO - root - 2017-12-01 07:05:34.168885: step 102720, loss = 0.29, batch loss = 0.17 (50.8 examples/sec; 0.158 sec/batch; 10h:03m:16s remains)
INFO - root - 2017-12-01 07:05:35.736835: step 102730, loss = 0.32, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 10h:13m:53s remains)
INFO - root - 2017-12-01 07:05:37.299259: step 102740, loss = 0.35, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 9h:50m:22s remains)
INFO - root - 2017-12-01 07:05:38.854344: step 102750, loss = 0.26, batch loss = 0.14 (53.3 examples/sec; 0.150 sec/batch; 9h:35m:07s remains)
INFO - root - 2017-12-01 07:05:40.409262: step 102760, loss = 0.35, batch loss = 0.23 (52.9 examples/sec; 0.151 sec/batch; 9h:39m:13s remains)
INFO - root - 2017-12-01 07:05:42.026443: step 102770, loss = 0.31, batch loss = 0.19 (51.1 examples/sec; 0.156 sec/batch; 9h:59m:04s remains)
INFO - root - 2017-12-01 07:05:43.601935: step 102780, loss = 0.30, batch loss = 0.19 (49.4 examples/sec; 0.162 sec/batch; 10h:19m:56s remains)
INFO - root - 2017-12-01 07:05:45.165322: step 102790, loss = 0.30, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 9h:56m:09s remains)
INFO - root - 2017-12-01 07:05:46.727453: step 102800, loss = 0.32, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 9h:48m:46s remains)
INFO - root - 2017-12-01 07:05:48.342188: step 102810, loss = 0.31, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 9h:48m:34s remains)
INFO - root - 2017-12-01 07:05:49.895946: step 102820, loss = 0.43, batch loss = 0.31 (51.4 examples/sec; 0.155 sec/batch; 9h:55m:13s remains)
INFO - root - 2017-12-01 07:05:51.460597: step 102830, loss = 0.31, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 9h:58m:05s remains)
INFO - root - 2017-12-01 07:05:53.022727: step 102840, loss = 0.28, batch loss = 0.16 (52.4 examples/sec; 0.153 sec/batch; 9h:44m:36s remains)
INFO - root - 2017-12-01 07:05:54.593193: step 102850, loss = 0.31, batch loss = 0.19 (50.5 examples/sec; 0.159 sec/batch; 10h:06m:52s remains)
INFO - root - 2017-12-01 07:05:56.151297: step 102860, loss = 0.34, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 9h:47m:47s remains)
INFO - root - 2017-12-01 07:05:57.723147: step 102870, loss = 0.32, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 9h:46m:35s remains)
INFO - root - 2017-12-01 07:05:59.292800: step 102880, loss = 0.36, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 9h:51m:41s remains)
INFO - root - 2017-12-01 07:06:00.863360: step 102890, loss = 0.29, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 9h:54m:11s remains)
INFO - root - 2017-12-01 07:06:02.450663: step 102900, loss = 0.35, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 9h:59m:46s remains)
INFO - root - 2017-12-01 07:06:04.066706: step 102910, loss = 0.43, batch loss = 0.31 (51.9 examples/sec; 0.154 sec/batch; 9h:50m:06s remains)
INFO - root - 2017-12-01 07:06:05.627571: step 102920, loss = 0.31, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 10h:04m:51s remains)
INFO - root - 2017-12-01 07:06:07.191394: step 102930, loss = 0.26, batch loss = 0.15 (50.6 examples/sec; 0.158 sec/batch; 10h:04m:33s remains)
INFO - root - 2017-12-01 07:06:08.763227: step 102940, loss = 0.30, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 9h:44m:16s remains)
INFO - root - 2017-12-01 07:06:10.327554: step 102950, loss = 0.29, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 9h:58m:11s remains)
INFO - root - 2017-12-01 07:06:11.904100: step 102960, loss = 0.37, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 9h:54m:55s remains)
INFO - root - 2017-12-01 07:06:13.473396: step 102970, loss = 0.37, batch loss = 0.26 (50.2 examples/sec; 0.159 sec/batch; 10h:09m:27s remains)
INFO - root - 2017-12-01 07:06:15.036676: step 102980, loss = 0.34, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 10h:02m:31s remains)
INFO - root - 2017-12-01 07:06:16.594436: step 102990, loss = 0.34, batch loss = 0.23 (52.8 examples/sec; 0.151 sec/batch; 9h:39m:03s remains)
INFO - root - 2017-12-01 07:06:18.166751: step 103000, loss = 0.26, batch loss = 0.15 (52.0 examples/sec; 0.154 sec/batch; 9h:48m:27s remains)
INFO - root - 2017-12-01 07:06:19.789046: step 103010, loss = 0.28, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 9h:56m:05s remains)
INFO - root - 2017-12-01 07:06:21.356642: step 103020, loss = 0.34, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 10h:07m:23s remains)
INFO - root - 2017-12-01 07:06:22.932251: step 103030, loss = 0.30, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 9h:47m:55s remains)
INFO - root - 2017-12-01 07:06:24.492398: step 103040, loss = 0.46, batch loss = 0.34 (51.6 examples/sec; 0.155 sec/batch; 9h:52m:59s remains)
INFO - root - 2017-12-01 07:06:26.053154: step 103050, loss = 0.36, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 9h:57m:17s remains)
INFO - root - 2017-12-01 07:06:27.620444: step 103060, loss = 0.27, batch loss = 0.16 (47.2 examples/sec; 0.169 sec/batch; 10h:48m:06s remains)
INFO - root - 2017-12-01 07:06:29.193816: step 103070, loss = 0.32, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 10h:00m:22s remains)
INFO - root - 2017-12-01 07:06:30.746945: step 103080, loss = 0.36, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 9h:45m:11s remains)
INFO - root - 2017-12-01 07:06:32.313229: step 103090, loss = 0.32, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 9h:47m:47s remains)
INFO - root - 2017-12-01 07:06:33.881481: step 103100, loss = 0.33, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 10h:03m:13s remains)
INFO - root - 2017-12-01 07:06:35.542223: step 103110, loss = 0.32, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 9h:42m:05s remains)
INFO - root - 2017-12-01 07:06:37.095978: step 103120, loss = 0.31, batch loss = 0.19 (49.8 examples/sec; 0.161 sec/batch; 10h:13m:55s remains)
INFO - root - 2017-12-01 07:06:38.659673: step 103130, loss = 0.30, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 9h:55m:44s remains)
INFO - root - 2017-12-01 07:06:40.235791: step 103140, loss = 0.31, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 9h:55m:50s remains)
INFO - root - 2017-12-01 07:06:41.777873: step 103150, loss = 0.33, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 9h:44m:26s remains)
INFO - root - 2017-12-01 07:06:43.347180: step 103160, loss = 0.34, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 10h:10m:44s remains)
INFO - root - 2017-12-01 07:06:44.935580: step 103170, loss = 0.30, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 10h:04m:23s remains)
INFO - root - 2017-12-01 07:06:46.491794: step 103180, loss = 0.38, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 9h:53m:08s remains)
INFO - root - 2017-12-01 07:06:48.058255: step 103190, loss = 0.33, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 9h:44m:13s remains)
INFO - root - 2017-12-01 07:06:49.620783: step 103200, loss = 0.30, batch loss = 0.19 (51.8 examples/sec; 0.155 sec/batch; 9h:50m:41s remains)
INFO - root - 2017-12-01 07:06:51.252245: step 103210, loss = 0.30, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 9h:50m:05s remains)
INFO - root - 2017-12-01 07:06:52.836349: step 103220, loss = 0.29, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 10h:05m:01s remains)
INFO - root - 2017-12-01 07:06:54.443958: step 103230, loss = 0.31, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 9h:57m:25s remains)
INFO - root - 2017-12-01 07:06:56.015753: step 103240, loss = 0.32, batch loss = 0.20 (49.1 examples/sec; 0.163 sec/batch; 10h:22m:23s remains)
INFO - root - 2017-12-01 07:06:57.592512: step 103250, loss = 0.47, batch loss = 0.35 (50.4 examples/sec; 0.159 sec/batch; 10h:06m:39s remains)
INFO - root - 2017-12-01 07:06:59.147867: step 103260, loss = 0.29, batch loss = 0.17 (52.6 examples/sec; 0.152 sec/batch; 9h:40m:40s remains)
INFO - root - 2017-12-01 07:07:00.701896: step 103270, loss = 0.33, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 10h:00m:37s remains)
INFO - root - 2017-12-01 07:07:02.254659: step 103280, loss = 0.32, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 10h:01m:18s remains)
INFO - root - 2017-12-01 07:07:03.824930: step 103290, loss = 0.32, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 9h:52m:04s remains)
INFO - root - 2017-12-01 07:07:05.391124: step 103300, loss = 0.29, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 9h:55m:49s remains)
INFO - root - 2017-12-01 07:07:07.053053: step 103310, loss = 0.28, batch loss = 0.17 (50.0 examples/sec; 0.160 sec/batch; 10h:11m:22s remains)
INFO - root - 2017-12-01 07:07:08.620596: step 103320, loss = 0.31, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 9h:40m:55s remains)
INFO - root - 2017-12-01 07:07:10.184619: step 103330, loss = 0.31, batch loss = 0.19 (51.4 examples/sec; 0.155 sec/batch; 9h:53m:54s remains)
INFO - root - 2017-12-01 07:07:11.760692: step 103340, loss = 0.35, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 9h:48m:15s remains)
INFO - root - 2017-12-01 07:07:13.320091: step 103350, loss = 0.34, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 9h:51m:22s remains)
INFO - root - 2017-12-01 07:07:15.030269: step 103360, loss = 0.34, batch loss = 0.22 (51.1 examples/sec; 0.156 sec/batch; 9h:57m:29s remains)
INFO - root - 2017-12-01 07:07:16.597792: step 103370, loss = 0.35, batch loss = 0.23 (53.3 examples/sec; 0.150 sec/batch; 9h:33m:01s remains)
INFO - root - 2017-12-01 07:07:18.180520: step 103380, loss = 0.29, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 9h:58m:06s remains)
INFO - root - 2017-12-01 07:07:19.739664: step 103390, loss = 0.33, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 10h:00m:58s remains)
INFO - root - 2017-12-01 07:07:21.302641: step 103400, loss = 0.42, batch loss = 0.31 (50.6 examples/sec; 0.158 sec/batch; 10h:03m:47s remains)
INFO - root - 2017-12-01 07:07:22.950536: step 103410, loss = 0.36, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 9h:58m:09s remains)
INFO - root - 2017-12-01 07:07:24.522477: step 103420, loss = 0.31, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 10h:11m:32s remains)
INFO - root - 2017-12-01 07:07:26.074787: step 103430, loss = 0.31, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 10h:05m:35s remains)
INFO - root - 2017-12-01 07:07:27.626329: step 103440, loss = 0.30, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 10h:03m:34s remains)
INFO - root - 2017-12-01 07:07:29.196630: step 103450, loss = 0.34, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 9h:50m:10s remains)
INFO - root - 2017-12-01 07:07:30.754085: step 103460, loss = 0.28, batch loss = 0.16 (51.7 examples/sec; 0.155 sec/batch; 9h:51m:01s remains)
INFO - root - 2017-12-01 07:07:32.316199: step 103470, loss = 0.28, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 9h:52m:13s remains)
INFO - root - 2017-12-01 07:07:33.873836: step 103480, loss = 0.39, batch loss = 0.27 (50.2 examples/sec; 0.159 sec/batch; 10h:08m:07s remains)
INFO - root - 2017-12-01 07:07:35.447965: step 103490, loss = 0.37, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 9h:53m:57s remains)
INFO - root - 2017-12-01 07:07:37.006216: step 103500, loss = 0.34, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 9h:46m:52s remains)
INFO - root - 2017-12-01 07:07:38.683921: step 103510, loss = 0.36, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 10h:02m:05s remains)
INFO - root - 2017-12-01 07:07:40.275097: step 103520, loss = 0.42, batch loss = 0.30 (52.7 examples/sec; 0.152 sec/batch; 9h:39m:51s remains)
INFO - root - 2017-12-01 07:07:41.824199: step 103530, loss = 0.35, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 9h:54m:27s remains)
INFO - root - 2017-12-01 07:07:43.382457: step 103540, loss = 0.39, batch loss = 0.28 (49.6 examples/sec; 0.161 sec/batch; 10h:15m:00s remains)
INFO - root - 2017-12-01 07:07:44.948437: step 103550, loss = 0.39, batch loss = 0.27 (50.2 examples/sec; 0.160 sec/batch; 10h:08m:38s remains)
INFO - root - 2017-12-01 07:07:46.520075: step 103560, loss = 0.33, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 9h:47m:57s remains)
INFO - root - 2017-12-01 07:07:48.064074: step 103570, loss = 0.40, batch loss = 0.28 (53.6 examples/sec; 0.149 sec/batch; 9h:29m:08s remains)
INFO - root - 2017-12-01 07:07:49.625521: step 103580, loss = 0.33, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 10h:03m:46s remains)
INFO - root - 2017-12-01 07:07:51.174566: step 103590, loss = 0.41, batch loss = 0.29 (52.2 examples/sec; 0.153 sec/batch; 9h:44m:54s remains)
INFO - root - 2017-12-01 07:07:52.727652: step 103600, loss = 0.34, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 9h:59m:13s remains)
INFO - root - 2017-12-01 07:07:54.373156: step 103610, loss = 0.28, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 9h:53m:13s remains)
INFO - root - 2017-12-01 07:07:55.956359: step 103620, loss = 0.34, batch loss = 0.22 (47.3 examples/sec; 0.169 sec/batch; 10h:45m:15s remains)
INFO - root - 2017-12-01 07:07:57.497416: step 103630, loss = 0.34, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 9h:41m:25s remains)
INFO - root - 2017-12-01 07:07:59.069822: step 103640, loss = 0.39, batch loss = 0.27 (50.8 examples/sec; 0.158 sec/batch; 10h:00m:51s remains)
INFO - root - 2017-12-01 07:08:00.645668: step 103650, loss = 0.28, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 10h:05m:02s remains)
INFO - root - 2017-12-01 07:08:02.241893: step 103660, loss = 0.30, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 9h:57m:35s remains)
INFO - root - 2017-12-01 07:08:03.794170: step 103670, loss = 0.37, batch loss = 0.25 (52.1 examples/sec; 0.154 sec/batch; 9h:45m:31s remains)
INFO - root - 2017-12-01 07:08:05.359422: step 103680, loss = 0.30, batch loss = 0.18 (49.3 examples/sec; 0.162 sec/batch; 10h:19m:02s remains)
INFO - root - 2017-12-01 07:08:06.917554: step 103690, loss = 0.33, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 9h:50m:04s remains)
INFO - root - 2017-12-01 07:08:08.483143: step 103700, loss = 0.35, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 9h:43m:41s remains)
INFO - root - 2017-12-01 07:08:10.118190: step 103710, loss = 0.29, batch loss = 0.17 (47.6 examples/sec; 0.168 sec/batch; 10h:41m:18s remains)
INFO - root - 2017-12-01 07:08:11.688154: step 103720, loss = 0.28, batch loss = 0.17 (53.1 examples/sec; 0.151 sec/batch; 9h:34m:33s remains)
INFO - root - 2017-12-01 07:08:13.263589: step 103730, loss = 0.31, batch loss = 0.20 (50.5 examples/sec; 0.159 sec/batch; 10h:04m:34s remains)
INFO - root - 2017-12-01 07:08:14.826764: step 103740, loss = 0.33, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 9h:55m:50s remains)
INFO - root - 2017-12-01 07:08:16.381351: step 103750, loss = 0.35, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 9h:51m:01s remains)
INFO - root - 2017-12-01 07:08:17.928093: step 103760, loss = 0.32, batch loss = 0.20 (52.7 examples/sec; 0.152 sec/batch; 9h:38m:10s remains)
INFO - root - 2017-12-01 07:08:19.484593: step 103770, loss = 0.29, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 9h:44m:26s remains)
INFO - root - 2017-12-01 07:08:21.051417: step 103780, loss = 0.39, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 9h:52m:30s remains)
INFO - root - 2017-12-01 07:08:22.634361: step 103790, loss = 0.27, batch loss = 0.16 (48.6 examples/sec; 0.165 sec/batch; 10h:27m:29s remains)
INFO - root - 2017-12-01 07:08:24.181709: step 103800, loss = 0.31, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 9h:59m:12s remains)
INFO - root - 2017-12-01 07:08:25.832286: step 103810, loss = 0.40, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 9h:52m:13s remains)
INFO - root - 2017-12-01 07:08:27.394266: step 103820, loss = 0.45, batch loss = 0.33 (51.7 examples/sec; 0.155 sec/batch; 9h:49m:45s remains)
INFO - root - 2017-12-01 07:08:28.956341: step 103830, loss = 0.29, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 9h:46m:19s remains)
INFO - root - 2017-12-01 07:08:30.531167: step 103840, loss = 0.38, batch loss = 0.26 (52.3 examples/sec; 0.153 sec/batch; 9h:42m:28s remains)
INFO - root - 2017-12-01 07:08:32.087667: step 103850, loss = 0.31, batch loss = 0.19 (53.2 examples/sec; 0.150 sec/batch; 9h:32m:32s remains)
INFO - root - 2017-12-01 07:08:33.650379: step 103860, loss = 0.31, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 10h:02m:57s remains)
INFO - root - 2017-12-01 07:08:35.237484: step 103870, loss = 0.31, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 10h:02m:00s remains)
INFO - root - 2017-12-01 07:08:36.781491: step 103880, loss = 0.29, batch loss = 0.17 (52.8 examples/sec; 0.151 sec/batch; 9h:37m:00s remains)
INFO - root - 2017-12-01 07:08:38.349715: step 103890, loss = 0.25, batch loss = 0.13 (50.5 examples/sec; 0.158 sec/batch; 10h:03m:08s remains)
INFO - root - 2017-12-01 07:08:39.949971: step 103900, loss = 0.34, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 9h:46m:16s remains)
INFO - root - 2017-12-01 07:08:41.588788: step 103910, loss = 0.29, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 9h:52m:52s remains)
INFO - root - 2017-12-01 07:08:43.152269: step 103920, loss = 0.33, batch loss = 0.21 (52.6 examples/sec; 0.152 sec/batch; 9h:39m:48s remains)
INFO - root - 2017-12-01 07:08:44.712869: step 103930, loss = 0.42, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 9h:58m:08s remains)
INFO - root - 2017-12-01 07:08:46.274018: step 103940, loss = 0.29, batch loss = 0.18 (49.3 examples/sec; 0.162 sec/batch; 10h:18m:13s remains)
INFO - root - 2017-12-01 07:08:47.827107: step 103950, loss = 0.31, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 9h:51m:45s remains)
INFO - root - 2017-12-01 07:08:49.377865: step 103960, loss = 0.27, batch loss = 0.15 (50.9 examples/sec; 0.157 sec/batch; 9h:59m:04s remains)
INFO - root - 2017-12-01 07:08:50.938002: step 103970, loss = 0.29, batch loss = 0.17 (52.6 examples/sec; 0.152 sec/batch; 9h:38m:48s remains)
INFO - root - 2017-12-01 07:08:52.499395: step 103980, loss = 0.28, batch loss = 0.16 (51.1 examples/sec; 0.157 sec/batch; 9h:56m:44s remains)
INFO - root - 2017-12-01 07:08:54.089946: step 103990, loss = 0.23, batch loss = 0.12 (50.4 examples/sec; 0.159 sec/batch; 10h:04m:34s remains)
INFO - root - 2017-12-01 07:08:55.644423: step 104000, loss = 0.33, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 9h:43m:42s remains)
INFO - root - 2017-12-01 07:08:57.307718: step 104010, loss = 0.35, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 9h:50m:19s remains)
INFO - root - 2017-12-01 07:08:58.880644: step 104020, loss = 0.29, batch loss = 0.17 (52.1 examples/sec; 0.153 sec/batch; 9h:44m:15s remains)
INFO - root - 2017-12-01 07:09:00.456024: step 104030, loss = 0.35, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 9h:58m:13s remains)
INFO - root - 2017-12-01 07:09:02.015065: step 104040, loss = 0.41, batch loss = 0.30 (50.6 examples/sec; 0.158 sec/batch; 10h:02m:03s remains)
INFO - root - 2017-12-01 07:09:03.577179: step 104050, loss = 0.38, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 10h:01m:58s remains)
INFO - root - 2017-12-01 07:09:05.149040: step 104060, loss = 0.32, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 10h:09m:40s remains)
INFO - root - 2017-12-01 07:09:06.704337: step 104070, loss = 0.31, batch loss = 0.20 (52.7 examples/sec; 0.152 sec/batch; 9h:38m:21s remains)
INFO - root - 2017-12-01 07:09:08.312525: step 104080, loss = 0.37, batch loss = 0.25 (50.2 examples/sec; 0.159 sec/batch; 10h:06m:25s remains)
INFO - root - 2017-12-01 07:09:09.881259: step 104090, loss = 0.30, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 9h:52m:50s remains)
INFO - root - 2017-12-01 07:09:11.449538: step 104100, loss = 0.42, batch loss = 0.30 (50.2 examples/sec; 0.159 sec/batch; 10h:06m:06s remains)
INFO - root - 2017-12-01 07:09:13.087665: step 104110, loss = 0.33, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 9h:47m:33s remains)
INFO - root - 2017-12-01 07:09:14.661954: step 104120, loss = 0.29, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 10h:01m:25s remains)
INFO - root - 2017-12-01 07:09:16.213529: step 104130, loss = 0.44, batch loss = 0.32 (50.9 examples/sec; 0.157 sec/batch; 9h:58m:04s remains)
INFO - root - 2017-12-01 07:09:17.792785: step 104140, loss = 0.31, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 9h:43m:31s remains)
INFO - root - 2017-12-01 07:09:19.368593: step 104150, loss = 0.29, batch loss = 0.17 (51.8 examples/sec; 0.154 sec/batch; 9h:47m:45s remains)
INFO - root - 2017-12-01 07:09:20.939927: step 104160, loss = 0.29, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 9h:47m:21s remains)
INFO - root - 2017-12-01 07:09:22.496155: step 104170, loss = 0.45, batch loss = 0.34 (51.8 examples/sec; 0.155 sec/batch; 9h:48m:13s remains)
INFO - root - 2017-12-01 07:09:24.071557: step 104180, loss = 0.29, batch loss = 0.18 (49.6 examples/sec; 0.161 sec/batch; 10h:13m:57s remains)
INFO - root - 2017-12-01 07:09:25.633921: step 104190, loss = 0.31, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 10h:06m:28s remains)
INFO - root - 2017-12-01 07:09:27.204453: step 104200, loss = 0.33, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 10h:05m:41s remains)
INFO - root - 2017-12-01 07:09:28.830749: step 104210, loss = 0.31, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 9h:38m:11s remains)
INFO - root - 2017-12-01 07:09:30.395299: step 104220, loss = 0.33, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 9h:53m:54s remains)
INFO - root - 2017-12-01 07:09:31.982867: step 104230, loss = 0.30, batch loss = 0.18 (47.3 examples/sec; 0.169 sec/batch; 10h:43m:06s remains)
INFO - root - 2017-12-01 07:09:33.537478: step 104240, loss = 0.28, batch loss = 0.16 (51.7 examples/sec; 0.155 sec/batch; 9h:49m:08s remains)
INFO - root - 2017-12-01 07:09:35.098679: step 104250, loss = 0.36, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 9h:56m:25s remains)
INFO - root - 2017-12-01 07:09:36.662005: step 104260, loss = 0.30, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 9h:41m:06s remains)
INFO - root - 2017-12-01 07:09:38.243890: step 104270, loss = 0.34, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 9h:51m:35s remains)
INFO - root - 2017-12-01 07:09:39.803977: step 104280, loss = 0.28, batch loss = 0.17 (49.7 examples/sec; 0.161 sec/batch; 10h:12m:34s remains)
INFO - root - 2017-12-01 07:09:41.351753: step 104290, loss = 0.35, batch loss = 0.24 (52.5 examples/sec; 0.152 sec/batch; 9h:39m:23s remains)
INFO - root - 2017-12-01 07:09:42.920593: step 104300, loss = 0.32, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 9h:52m:52s remains)
INFO - root - 2017-12-01 07:09:44.570913: step 104310, loss = 0.30, batch loss = 0.19 (50.2 examples/sec; 0.160 sec/batch; 10h:06m:36s remains)
INFO - root - 2017-12-01 07:09:46.134662: step 104320, loss = 0.33, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 9h:45m:26s remains)
INFO - root - 2017-12-01 07:09:47.687105: step 104330, loss = 0.36, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 9h:44m:35s remains)
INFO - root - 2017-12-01 07:09:49.268623: step 104340, loss = 0.31, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 9h:55m:41s remains)
INFO - root - 2017-12-01 07:09:50.867690: step 104350, loss = 0.27, batch loss = 0.15 (50.2 examples/sec; 0.159 sec/batch; 10h:06m:11s remains)
INFO - root - 2017-12-01 07:09:52.419485: step 104360, loss = 0.26, batch loss = 0.14 (51.3 examples/sec; 0.156 sec/batch; 9h:52m:23s remains)
INFO - root - 2017-12-01 07:09:53.994498: step 104370, loss = 0.31, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 9h:38m:58s remains)
INFO - root - 2017-12-01 07:09:55.571939: step 104380, loss = 0.41, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 9h:46m:16s remains)
INFO - root - 2017-12-01 07:09:57.149803: step 104390, loss = 0.29, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 9h:48m:47s remains)
INFO - root - 2017-12-01 07:09:58.710813: step 104400, loss = 0.31, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 9h:56m:59s remains)
INFO - root - 2017-12-01 07:10:00.395470: step 104410, loss = 0.36, batch loss = 0.24 (49.8 examples/sec; 0.161 sec/batch; 10h:10m:39s remains)
INFO - root - 2017-12-01 07:10:01.952431: step 104420, loss = 0.28, batch loss = 0.17 (49.6 examples/sec; 0.161 sec/batch; 10h:13m:39s remains)
INFO - root - 2017-12-01 07:10:03.536187: step 104430, loss = 0.33, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 10h:06m:16s remains)
INFO - root - 2017-12-01 07:10:05.113325: step 104440, loss = 0.35, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 9h:56m:52s remains)
INFO - root - 2017-12-01 07:10:06.675060: step 104450, loss = 0.36, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 10h:00m:54s remains)
INFO - root - 2017-12-01 07:10:08.240699: step 104460, loss = 0.26, batch loss = 0.14 (52.1 examples/sec; 0.154 sec/batch; 9h:43m:44s remains)
INFO - root - 2017-12-01 07:10:09.823236: step 104470, loss = 0.36, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 10h:02m:58s remains)
INFO - root - 2017-12-01 07:10:11.388128: step 104480, loss = 0.35, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 9h:59m:08s remains)
INFO - root - 2017-12-01 07:10:12.960175: step 104490, loss = 0.29, batch loss = 0.17 (51.1 examples/sec; 0.156 sec/batch; 9h:54m:34s remains)
INFO - root - 2017-12-01 07:10:14.515964: step 104500, loss = 0.41, batch loss = 0.30 (50.6 examples/sec; 0.158 sec/batch; 10h:00m:18s remains)
INFO - root - 2017-12-01 07:10:16.151492: step 104510, loss = 0.35, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 9h:42m:21s remains)
INFO - root - 2017-12-01 07:10:17.712348: step 104520, loss = 0.32, batch loss = 0.21 (49.8 examples/sec; 0.160 sec/batch; 10h:09m:47s remains)
INFO - root - 2017-12-01 07:10:19.260234: step 104530, loss = 0.26, batch loss = 0.14 (49.9 examples/sec; 0.160 sec/batch; 10h:08m:43s remains)
INFO - root - 2017-12-01 07:10:20.816840: step 104540, loss = 0.28, batch loss = 0.16 (52.5 examples/sec; 0.152 sec/batch; 9h:39m:11s remains)
INFO - root - 2017-12-01 07:10:22.401208: step 104550, loss = 0.30, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 9h:46m:22s remains)
INFO - root - 2017-12-01 07:10:23.960228: step 104560, loss = 0.39, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 9h:48m:56s remains)
INFO - root - 2017-12-01 07:10:25.560053: step 104570, loss = 0.33, batch loss = 0.22 (49.5 examples/sec; 0.161 sec/batch; 10h:13m:27s remains)
INFO - root - 2017-12-01 07:10:27.113075: step 104580, loss = 0.36, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 9h:48m:45s remains)
INFO - root - 2017-12-01 07:10:28.665362: step 104590, loss = 0.36, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 9h:42m:21s remains)
INFO - root - 2017-12-01 07:10:30.230421: step 104600, loss = 0.30, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 9h:56m:25s remains)
INFO - root - 2017-12-01 07:10:31.843683: step 104610, loss = 0.28, batch loss = 0.16 (49.8 examples/sec; 0.161 sec/batch; 10h:09m:40s remains)
INFO - root - 2017-12-01 07:10:33.410300: step 104620, loss = 0.31, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 9h:46m:02s remains)
INFO - root - 2017-12-01 07:10:34.996941: step 104630, loss = 0.39, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 9h:49m:53s remains)
INFO - root - 2017-12-01 07:10:36.559096: step 104640, loss = 0.32, batch loss = 0.21 (49.0 examples/sec; 0.163 sec/batch; 10h:20m:22s remains)
INFO - root - 2017-12-01 07:10:38.124969: step 104650, loss = 0.28, batch loss = 0.16 (50.2 examples/sec; 0.159 sec/batch; 10h:05m:05s remains)
INFO - root - 2017-12-01 07:10:39.689422: step 104660, loss = 0.41, batch loss = 0.30 (52.5 examples/sec; 0.152 sec/batch; 9h:38m:47s remains)
INFO - root - 2017-12-01 07:10:41.261996: step 104670, loss = 0.28, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 10h:00m:50s remains)
INFO - root - 2017-12-01 07:10:42.822655: step 104680, loss = 0.38, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 9h:55m:44s remains)
INFO - root - 2017-12-01 07:10:44.385442: step 104690, loss = 0.35, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 9h:52m:34s remains)
INFO - root - 2017-12-01 07:10:45.944267: step 104700, loss = 0.42, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 9h:49m:50s remains)
INFO - root - 2017-12-01 07:10:47.593459: step 104710, loss = 0.31, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 9h:55m:43s remains)
INFO - root - 2017-12-01 07:10:49.165925: step 104720, loss = 0.33, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 10h:03m:17s remains)
INFO - root - 2017-12-01 07:10:50.715724: step 104730, loss = 0.36, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 9h:47m:13s remains)
INFO - root - 2017-12-01 07:10:52.288224: step 104740, loss = 0.33, batch loss = 0.21 (48.0 examples/sec; 0.167 sec/batch; 10h:32m:42s remains)
INFO - root - 2017-12-01 07:10:53.854579: step 104750, loss = 0.29, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 9h:45m:43s remains)
INFO - root - 2017-12-01 07:10:55.418292: step 104760, loss = 0.31, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 9h:50m:16s remains)
INFO - root - 2017-12-01 07:10:56.987958: step 104770, loss = 0.28, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 10h:00m:24s remains)
INFO - root - 2017-12-01 07:10:58.547836: step 104780, loss = 0.30, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 9h:52m:01s remains)
INFO - root - 2017-12-01 07:11:00.110756: step 104790, loss = 0.29, batch loss = 0.17 (53.1 examples/sec; 0.151 sec/batch; 9h:31m:34s remains)
INFO - root - 2017-12-01 07:11:01.692921: step 104800, loss = 0.25, batch loss = 0.14 (50.9 examples/sec; 0.157 sec/batch; 9h:55m:59s remains)
INFO - root - 2017-12-01 07:11:03.314795: step 104810, loss = 0.26, batch loss = 0.14 (52.1 examples/sec; 0.154 sec/batch; 9h:43m:00s remains)
INFO - root - 2017-12-01 07:11:04.875194: step 104820, loss = 0.36, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 9h:59m:35s remains)
INFO - root - 2017-12-01 07:11:06.450747: step 104830, loss = 0.39, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 9h:43m:35s remains)
INFO - root - 2017-12-01 07:11:08.009156: step 104840, loss = 0.35, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 9h:59m:10s remains)
INFO - root - 2017-12-01 07:11:09.567261: step 104850, loss = 0.35, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 9h:49m:03s remains)
INFO - root - 2017-12-01 07:11:11.122810: step 104860, loss = 0.36, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 9h:45m:59s remains)
INFO - root - 2017-12-01 07:11:12.691395: step 104870, loss = 0.41, batch loss = 0.30 (51.6 examples/sec; 0.155 sec/batch; 9h:48m:07s remains)
INFO - root - 2017-12-01 07:11:14.276112: step 104880, loss = 0.47, batch loss = 0.36 (51.7 examples/sec; 0.155 sec/batch; 9h:47m:01s remains)
INFO - root - 2017-12-01 07:11:15.831949: step 104890, loss = 0.26, batch loss = 0.15 (51.0 examples/sec; 0.157 sec/batch; 9h:54m:34s remains)
INFO - root - 2017-12-01 07:11:17.379982: step 104900, loss = 0.28, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 9h:56m:21s remains)
INFO - root - 2017-12-01 07:11:19.034211: step 104910, loss = 0.31, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 9h:57m:56s remains)
INFO - root - 2017-12-01 07:11:20.591990: step 104920, loss = 0.30, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 9h:48m:13s remains)
INFO - root - 2017-12-01 07:11:22.161654: step 104930, loss = 0.32, batch loss = 0.20 (49.2 examples/sec; 0.163 sec/batch; 10h:16m:59s remains)
INFO - root - 2017-12-01 07:11:23.722912: step 104940, loss = 0.29, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 9h:44m:33s remains)
INFO - root - 2017-12-01 07:11:25.295998: step 104950, loss = 0.36, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 9h:45m:06s remains)
INFO - root - 2017-12-01 07:11:26.885311: step 104960, loss = 0.38, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 9h:48m:49s remains)
INFO - root - 2017-12-01 07:11:28.456182: step 104970, loss = 0.32, batch loss = 0.20 (46.3 examples/sec; 0.173 sec/batch; 10h:55m:08s remains)
INFO - root - 2017-12-01 07:11:30.017323: step 104980, loss = 0.28, batch loss = 0.17 (52.8 examples/sec; 0.151 sec/batch; 9h:34m:15s remains)
INFO - root - 2017-12-01 07:11:31.585707: step 104990, loss = 0.42, batch loss = 0.31 (50.3 examples/sec; 0.159 sec/batch; 10h:03m:32s remains)
INFO - root - 2017-12-01 07:11:33.152934: step 105000, loss = 0.36, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 9h:44m:06s remains)
INFO - root - 2017-12-01 07:11:34.810259: step 105010, loss = 0.37, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 9h:56m:01s remains)
INFO - root - 2017-12-01 07:11:36.367020: step 105020, loss = 0.47, batch loss = 0.36 (51.4 examples/sec; 0.156 sec/batch; 9h:50m:10s remains)
INFO - root - 2017-12-01 07:11:37.931900: step 105030, loss = 0.29, batch loss = 0.17 (49.6 examples/sec; 0.161 sec/batch; 10h:11m:02s remains)
INFO - root - 2017-12-01 07:11:39.496414: step 105040, loss = 0.42, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 9h:49m:36s remains)
INFO - root - 2017-12-01 07:11:41.065399: step 105050, loss = 0.35, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 9h:54m:09s remains)
INFO - root - 2017-12-01 07:11:42.626513: step 105060, loss = 0.35, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 9h:51m:20s remains)
INFO - root - 2017-12-01 07:11:44.198495: step 105070, loss = 0.35, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 9h:48m:29s remains)
INFO - root - 2017-12-01 07:11:45.756702: step 105080, loss = 0.35, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 10h:03m:58s remains)
INFO - root - 2017-12-01 07:11:47.313129: step 105090, loss = 0.31, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 9h:50m:07s remains)
INFO - root - 2017-12-01 07:11:48.884292: step 105100, loss = 0.32, batch loss = 0.20 (52.7 examples/sec; 0.152 sec/batch; 9h:35m:44s remains)
INFO - root - 2017-12-01 07:11:50.508081: step 105110, loss = 0.47, batch loss = 0.35 (50.9 examples/sec; 0.157 sec/batch; 9h:55m:19s remains)
INFO - root - 2017-12-01 07:11:52.065005: step 105120, loss = 0.36, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 9h:49m:26s remains)
INFO - root - 2017-12-01 07:11:53.630579: step 105130, loss = 0.35, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 9h:49m:08s remains)
INFO - root - 2017-12-01 07:11:55.204708: step 105140, loss = 0.32, batch loss = 0.20 (52.7 examples/sec; 0.152 sec/batch; 9h:35m:14s remains)
INFO - root - 2017-12-01 07:11:56.821772: step 105150, loss = 0.33, batch loss = 0.22 (49.4 examples/sec; 0.162 sec/batch; 10h:13m:16s remains)
INFO - root - 2017-12-01 07:11:58.381471: step 105160, loss = 0.32, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 10h:00m:04s remains)
INFO - root - 2017-12-01 07:11:59.958958: step 105170, loss = 0.37, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 9h:47m:26s remains)
INFO - root - 2017-12-01 07:12:01.533643: step 105180, loss = 0.37, batch loss = 0.25 (52.6 examples/sec; 0.152 sec/batch; 9h:36m:35s remains)
INFO - root - 2017-12-01 07:12:03.090638: step 105190, loss = 0.34, batch loss = 0.22 (49.6 examples/sec; 0.161 sec/batch; 10h:10m:55s remains)
INFO - root - 2017-12-01 07:12:04.660219: step 105200, loss = 0.38, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 9h:49m:22s remains)
INFO - root - 2017-12-01 07:12:06.302694: step 105210, loss = 0.28, batch loss = 0.16 (52.4 examples/sec; 0.153 sec/batch; 9h:38m:09s remains)
INFO - root - 2017-12-01 07:12:07.869306: step 105220, loss = 0.30, batch loss = 0.18 (49.5 examples/sec; 0.162 sec/batch; 10h:12m:35s remains)
INFO - root - 2017-12-01 07:12:09.425010: step 105230, loss = 0.35, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 9h:58m:02s remains)
INFO - root - 2017-12-01 07:12:11.003847: step 105240, loss = 0.31, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 9h:54m:34s remains)
INFO - root - 2017-12-01 07:12:12.574466: step 105250, loss = 0.30, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 9h:53m:15s remains)
INFO - root - 2017-12-01 07:12:14.273390: step 105260, loss = 0.35, batch loss = 0.24 (28.2 examples/sec; 0.284 sec/batch; 17h:56m:15s remains)
INFO - root - 2017-12-01 07:12:15.849483: step 105270, loss = 0.73, batch loss = 0.61 (51.3 examples/sec; 0.156 sec/batch; 9h:50m:14s remains)
INFO - root - 2017-12-01 07:12:17.419399: step 105280, loss = 0.29, batch loss = 0.17 (48.0 examples/sec; 0.167 sec/batch; 10h:31m:38s remains)
INFO - root - 2017-12-01 07:12:19.019015: step 105290, loss = 0.26, batch loss = 0.15 (50.4 examples/sec; 0.159 sec/batch; 10h:00m:35s remains)
INFO - root - 2017-12-01 07:12:20.581957: step 105300, loss = 0.30, batch loss = 0.18 (50.0 examples/sec; 0.160 sec/batch; 10h:06m:22s remains)
INFO - root - 2017-12-01 07:12:22.234443: step 105310, loss = 0.38, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 9h:59m:05s remains)
INFO - root - 2017-12-01 07:12:23.804803: step 105320, loss = 0.30, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 9h:45m:22s remains)
INFO - root - 2017-12-01 07:12:25.385024: step 105330, loss = 0.33, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 10h:01m:27s remains)
INFO - root - 2017-12-01 07:12:26.947387: step 105340, loss = 0.27, batch loss = 0.15 (52.7 examples/sec; 0.152 sec/batch; 9h:35m:11s remains)
INFO - root - 2017-12-01 07:12:28.506130: step 105350, loss = 0.33, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 9h:53m:33s remains)
INFO - root - 2017-12-01 07:12:30.080361: step 105360, loss = 0.33, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 10h:04m:26s remains)
INFO - root - 2017-12-01 07:12:31.632165: step 105370, loss = 0.52, batch loss = 0.40 (51.6 examples/sec; 0.155 sec/batch; 9h:46m:46s remains)
INFO - root - 2017-12-01 07:12:33.188046: step 105380, loss = 0.36, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 9h:45m:21s remains)
INFO - root - 2017-12-01 07:12:34.750237: step 105390, loss = 0.32, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 9h:51m:53s remains)
INFO - root - 2017-12-01 07:12:36.316795: step 105400, loss = 0.38, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 9h:54m:37s remains)
INFO - root - 2017-12-01 07:12:37.942849: step 105410, loss = 0.35, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 9h:52m:48s remains)
INFO - root - 2017-12-01 07:12:39.510021: step 105420, loss = 0.29, batch loss = 0.18 (48.8 examples/sec; 0.164 sec/batch; 10h:19m:50s remains)
INFO - root - 2017-12-01 07:12:41.092368: step 105430, loss = 0.37, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 9h:54m:34s remains)
INFO - root - 2017-12-01 07:12:42.672851: step 105440, loss = 0.29, batch loss = 0.17 (50.2 examples/sec; 0.159 sec/batch; 10h:03m:26s remains)
INFO - root - 2017-12-01 07:12:44.223350: step 105450, loss = 0.35, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 10h:06m:55s remains)
INFO - root - 2017-12-01 07:12:45.786726: step 105460, loss = 0.31, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 9h:39m:57s remains)
INFO - root - 2017-12-01 07:12:47.340986: step 105470, loss = 0.33, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 9h:45m:28s remains)
INFO - root - 2017-12-01 07:12:48.915717: step 105480, loss = 0.26, batch loss = 0.15 (50.6 examples/sec; 0.158 sec/batch; 9h:58m:04s remains)
INFO - root - 2017-12-01 07:12:50.480827: step 105490, loss = 0.31, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 9h:56m:27s remains)
INFO - root - 2017-12-01 07:12:52.047896: step 105500, loss = 0.36, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 9h:56m:44s remains)
INFO - root - 2017-12-01 07:12:53.690523: step 105510, loss = 0.37, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 9h:48m:36s remains)
INFO - root - 2017-12-01 07:12:55.254469: step 105520, loss = 0.32, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 9h:54m:57s remains)
INFO - root - 2017-12-01 07:12:56.823176: step 105530, loss = 0.28, batch loss = 0.17 (49.9 examples/sec; 0.160 sec/batch; 10h:06m:53s remains)
INFO - root - 2017-12-01 07:12:58.371940: step 105540, loss = 0.43, batch loss = 0.32 (48.7 examples/sec; 0.164 sec/batch; 10h:21m:06s remains)
INFO - root - 2017-12-01 07:12:59.933675: step 105550, loss = 0.31, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 9h:44m:21s remains)
INFO - root - 2017-12-01 07:13:01.484584: step 105560, loss = 0.28, batch loss = 0.17 (53.0 examples/sec; 0.151 sec/batch; 9h:31m:08s remains)
INFO - root - 2017-12-01 07:13:03.055071: step 105570, loss = 0.33, batch loss = 0.22 (49.8 examples/sec; 0.161 sec/batch; 10h:07m:25s remains)
INFO - root - 2017-12-01 07:13:04.618763: step 105580, loss = 0.33, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 9h:56m:21s remains)
INFO - root - 2017-12-01 07:13:06.175132: step 105590, loss = 0.33, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 9h:44m:02s remains)
INFO - root - 2017-12-01 07:13:07.724679: step 105600, loss = 0.31, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 9h:54m:16s remains)
INFO - root - 2017-12-01 07:13:09.377089: step 105610, loss = 0.42, batch loss = 0.30 (50.5 examples/sec; 0.158 sec/batch; 9h:58m:41s remains)
INFO - root - 2017-12-01 07:13:10.925297: step 105620, loss = 0.31, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 9h:43m:02s remains)
INFO - root - 2017-12-01 07:13:12.516250: step 105630, loss = 0.32, batch loss = 0.21 (50.0 examples/sec; 0.160 sec/batch; 10h:04m:56s remains)
INFO - root - 2017-12-01 07:13:14.088386: step 105640, loss = 0.33, batch loss = 0.21 (48.8 examples/sec; 0.164 sec/batch; 10h:19m:24s remains)
INFO - root - 2017-12-01 07:13:15.662476: step 105650, loss = 0.26, batch loss = 0.15 (51.7 examples/sec; 0.155 sec/batch; 9h:44m:29s remains)
INFO - root - 2017-12-01 07:13:17.234584: step 105660, loss = 0.30, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 9h:45m:08s remains)
INFO - root - 2017-12-01 07:13:18.815820: step 105670, loss = 0.30, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 9h:58m:41s remains)
INFO - root - 2017-12-01 07:13:20.365460: step 105680, loss = 0.28, batch loss = 0.17 (50.0 examples/sec; 0.160 sec/batch; 10h:05m:19s remains)
INFO - root - 2017-12-01 07:13:21.932297: step 105690, loss = 0.33, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 9h:49m:38s remains)
INFO - root - 2017-12-01 07:13:23.487455: step 105700, loss = 0.34, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 10h:03m:29s remains)
INFO - root - 2017-12-01 07:13:25.129635: step 105710, loss = 0.28, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 9h:57m:15s remains)
INFO - root - 2017-12-01 07:13:26.688297: step 105720, loss = 0.33, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 9h:50m:51s remains)
INFO - root - 2017-12-01 07:13:28.256320: step 105730, loss = 0.33, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 10h:03m:11s remains)
INFO - root - 2017-12-01 07:13:29.806655: step 105740, loss = 0.30, batch loss = 0.19 (53.0 examples/sec; 0.151 sec/batch; 9h:30m:38s remains)
INFO - root - 2017-12-01 07:13:31.386763: step 105750, loss = 0.34, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 9h:56m:06s remains)
INFO - root - 2017-12-01 07:13:32.950834: step 105760, loss = 0.29, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 9h:58m:53s remains)
INFO - root - 2017-12-01 07:13:34.509644: step 105770, loss = 0.32, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 9h:41m:55s remains)
INFO - root - 2017-12-01 07:13:36.071127: step 105780, loss = 0.34, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 9h:45m:22s remains)
INFO - root - 2017-12-01 07:13:37.631863: step 105790, loss = 0.30, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 9h:42m:54s remains)
INFO - root - 2017-12-01 07:13:39.195633: step 105800, loss = 0.33, batch loss = 0.22 (53.2 examples/sec; 0.150 sec/batch; 9h:27m:45s remains)
INFO - root - 2017-12-01 07:13:40.846054: step 105810, loss = 0.30, batch loss = 0.19 (48.8 examples/sec; 0.164 sec/batch; 10h:19m:57s remains)
INFO - root - 2017-12-01 07:13:42.398521: step 105820, loss = 0.30, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 9h:37m:20s remains)
INFO - root - 2017-12-01 07:13:43.960421: step 105830, loss = 0.30, batch loss = 0.19 (53.6 examples/sec; 0.149 sec/batch; 9h:23m:40s remains)
INFO - root - 2017-12-01 07:13:45.535460: step 105840, loss = 0.25, batch loss = 0.14 (51.6 examples/sec; 0.155 sec/batch; 9h:46m:06s remains)
INFO - root - 2017-12-01 07:13:47.110162: step 105850, loss = 0.33, batch loss = 0.21 (49.7 examples/sec; 0.161 sec/batch; 10h:07m:48s remains)
INFO - root - 2017-12-01 07:13:48.669906: step 105860, loss = 0.38, batch loss = 0.26 (49.7 examples/sec; 0.161 sec/batch; 10h:08m:27s remains)
INFO - root - 2017-12-01 07:13:50.235663: step 105870, loss = 0.39, batch loss = 0.27 (50.4 examples/sec; 0.159 sec/batch; 9h:59m:46s remains)
INFO - root - 2017-12-01 07:13:51.813336: step 105880, loss = 0.35, batch loss = 0.24 (52.5 examples/sec; 0.152 sec/batch; 9h:35m:54s remains)
INFO - root - 2017-12-01 07:13:53.370017: step 105890, loss = 0.36, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 9h:53m:19s remains)
INFO - root - 2017-12-01 07:13:54.938916: step 105900, loss = 0.35, batch loss = 0.23 (49.6 examples/sec; 0.161 sec/batch; 10h:09m:10s remains)
INFO - root - 2017-12-01 07:13:56.599519: step 105910, loss = 0.34, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 9h:52m:49s remains)
INFO - root - 2017-12-01 07:13:58.157753: step 105920, loss = 0.34, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 9h:50m:17s remains)
INFO - root - 2017-12-01 07:13:59.709408: step 105930, loss = 0.29, batch loss = 0.18 (49.2 examples/sec; 0.163 sec/batch; 10h:14m:07s remains)
INFO - root - 2017-12-01 07:14:01.268792: step 105940, loss = 0.38, batch loss = 0.26 (52.4 examples/sec; 0.153 sec/batch; 9h:36m:02s remains)
INFO - root - 2017-12-01 07:14:02.814521: step 105950, loss = 0.35, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 9h:36m:22s remains)
INFO - root - 2017-12-01 07:14:04.391023: step 105960, loss = 0.41, batch loss = 0.30 (51.3 examples/sec; 0.156 sec/batch; 9h:49m:07s remains)
INFO - root - 2017-12-01 07:14:05.964485: step 105970, loss = 0.31, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 9h:46m:18s remains)
INFO - root - 2017-12-01 07:14:07.523637: step 105980, loss = 0.31, batch loss = 0.20 (48.5 examples/sec; 0.165 sec/batch; 10h:22m:51s remains)
INFO - root - 2017-12-01 07:14:09.090252: step 105990, loss = 0.39, batch loss = 0.28 (52.6 examples/sec; 0.152 sec/batch; 9h:34m:14s remains)
INFO - root - 2017-12-01 07:14:10.665062: step 106000, loss = 0.31, batch loss = 0.20 (52.8 examples/sec; 0.152 sec/batch; 9h:32m:13s remains)
INFO - root - 2017-12-01 07:14:12.323890: step 106010, loss = 0.33, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 9h:44m:36s remains)
INFO - root - 2017-12-01 07:14:13.921817: step 106020, loss = 0.30, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 9h:48m:19s remains)
INFO - root - 2017-12-01 07:14:15.481823: step 106030, loss = 0.38, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 9h:45m:41s remains)
INFO - root - 2017-12-01 07:14:17.031161: step 106040, loss = 0.44, batch loss = 0.32 (51.0 examples/sec; 0.157 sec/batch; 9h:51m:41s remains)
INFO - root - 2017-12-01 07:14:18.582112: step 106050, loss = 0.35, batch loss = 0.24 (52.7 examples/sec; 0.152 sec/batch; 9h:32m:42s remains)
INFO - root - 2017-12-01 07:14:20.140332: step 106060, loss = 0.33, batch loss = 0.22 (53.3 examples/sec; 0.150 sec/batch; 9h:26m:00s remains)
INFO - root - 2017-12-01 07:14:21.697005: step 106070, loss = 0.32, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 9h:37m:12s remains)
INFO - root - 2017-12-01 07:14:23.246156: step 106080, loss = 0.36, batch loss = 0.25 (52.0 examples/sec; 0.154 sec/batch; 9h:41m:06s remains)
INFO - root - 2017-12-01 07:14:24.812974: step 106090, loss = 0.34, batch loss = 0.22 (49.9 examples/sec; 0.160 sec/batch; 10h:04m:40s remains)
INFO - root - 2017-12-01 07:14:26.371622: step 106100, loss = 0.38, batch loss = 0.26 (50.5 examples/sec; 0.159 sec/batch; 9h:58m:06s remains)
INFO - root - 2017-12-01 07:14:27.977863: step 106110, loss = 0.34, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 9h:49m:19s remains)
INFO - root - 2017-12-01 07:14:29.537426: step 106120, loss = 0.46, batch loss = 0.35 (51.2 examples/sec; 0.156 sec/batch; 9h:49m:37s remains)
INFO - root - 2017-12-01 07:14:31.115913: step 106130, loss = 0.49, batch loss = 0.38 (51.6 examples/sec; 0.155 sec/batch; 9h:44m:47s remains)
INFO - root - 2017-12-01 07:14:32.671017: step 106140, loss = 0.32, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 9h:51m:23s remains)
INFO - root - 2017-12-01 07:14:34.238265: step 106150, loss = 0.44, batch loss = 0.33 (51.0 examples/sec; 0.157 sec/batch; 9h:51m:17s remains)
INFO - root - 2017-12-01 07:14:35.829575: step 106160, loss = 0.45, batch loss = 0.34 (51.9 examples/sec; 0.154 sec/batch; 9h:41m:26s remains)
INFO - root - 2017-12-01 07:14:37.390668: step 106170, loss = 0.28, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 9h:50m:50s remains)
INFO - root - 2017-12-01 07:14:38.951262: step 106180, loss = 0.29, batch loss = 0.17 (49.6 examples/sec; 0.161 sec/batch; 10h:08m:47s remains)
INFO - root - 2017-12-01 07:14:40.513980: step 106190, loss = 0.29, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 9h:37m:24s remains)
INFO - root - 2017-12-01 07:14:42.078040: step 106200, loss = 0.36, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 9h:58m:05s remains)
INFO - root - 2017-12-01 07:14:43.686221: step 106210, loss = 0.36, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 9h:51m:29s remains)
INFO - root - 2017-12-01 07:14:45.251642: step 106220, loss = 0.32, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 9h:57m:32s remains)
INFO - root - 2017-12-01 07:14:46.829141: step 106230, loss = 0.28, batch loss = 0.17 (49.5 examples/sec; 0.162 sec/batch; 10h:09m:58s remains)
INFO - root - 2017-12-01 07:14:48.407662: step 106240, loss = 0.46, batch loss = 0.34 (51.2 examples/sec; 0.156 sec/batch; 9h:49m:18s remains)
INFO - root - 2017-12-01 07:14:49.958859: step 106250, loss = 0.35, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 9h:47m:34s remains)
INFO - root - 2017-12-01 07:14:51.535151: step 106260, loss = 0.29, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 9h:54m:49s remains)
INFO - root - 2017-12-01 07:14:53.083450: step 106270, loss = 0.36, batch loss = 0.25 (50.1 examples/sec; 0.160 sec/batch; 10h:02m:16s remains)
INFO - root - 2017-12-01 07:14:54.647038: step 106280, loss = 0.29, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 9h:45m:24s remains)
INFO - root - 2017-12-01 07:14:56.214138: step 106290, loss = 0.44, batch loss = 0.33 (51.6 examples/sec; 0.155 sec/batch; 9h:44m:31s remains)
INFO - root - 2017-12-01 07:14:57.763902: step 106300, loss = 0.34, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 9h:45m:58s remains)
INFO - root - 2017-12-01 07:14:59.385601: step 106310, loss = 0.37, batch loss = 0.25 (52.9 examples/sec; 0.151 sec/batch; 9h:30m:14s remains)
INFO - root - 2017-12-01 07:15:00.974656: step 106320, loss = 0.32, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 9h:50m:18s remains)
INFO - root - 2017-12-01 07:15:02.550688: step 106330, loss = 0.33, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 9h:54m:21s remains)
INFO - root - 2017-12-01 07:15:04.132811: step 106340, loss = 0.30, batch loss = 0.19 (48.9 examples/sec; 0.163 sec/batch; 10h:16m:16s remains)
INFO - root - 2017-12-01 07:15:05.714482: step 106350, loss = 0.36, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 9h:36m:42s remains)
INFO - root - 2017-12-01 07:15:07.270571: step 106360, loss = 0.54, batch loss = 0.43 (52.0 examples/sec; 0.154 sec/batch; 9h:39m:44s remains)
INFO - root - 2017-12-01 07:15:08.847578: step 106370, loss = 0.29, batch loss = 0.17 (49.9 examples/sec; 0.160 sec/batch; 10h:04m:48s remains)
INFO - root - 2017-12-01 07:15:10.414519: step 106380, loss = 0.30, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 9h:58m:31s remains)
INFO - root - 2017-12-01 07:15:11.973769: step 106390, loss = 0.48, batch loss = 0.36 (51.9 examples/sec; 0.154 sec/batch; 9h:41m:18s remains)
INFO - root - 2017-12-01 07:15:13.563937: step 106400, loss = 0.34, batch loss = 0.23 (52.1 examples/sec; 0.153 sec/batch; 9h:38m:14s remains)
INFO - root - 2017-12-01 07:15:15.190943: step 106410, loss = 0.39, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 9h:42m:42s remains)
INFO - root - 2017-12-01 07:15:16.755460: step 106420, loss = 0.32, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 9h:44m:39s remains)
INFO - root - 2017-12-01 07:15:18.365250: step 106430, loss = 0.40, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 9h:58m:48s remains)
INFO - root - 2017-12-01 07:15:19.924932: step 106440, loss = 0.29, batch loss = 0.17 (51.8 examples/sec; 0.154 sec/batch; 9h:41m:37s remains)
INFO - root - 2017-12-01 07:15:21.501886: step 106450, loss = 0.26, batch loss = 0.14 (53.2 examples/sec; 0.150 sec/batch; 9h:26m:32s remains)
INFO - root - 2017-12-01 07:15:23.067355: step 106460, loss = 0.29, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 9h:59m:47s remains)
INFO - root - 2017-12-01 07:15:24.624626: step 106470, loss = 0.27, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 9h:45m:11s remains)
INFO - root - 2017-12-01 07:15:26.233646: step 106480, loss = 0.46, batch loss = 0.35 (50.4 examples/sec; 0.159 sec/batch; 9h:58m:19s remains)
INFO - root - 2017-12-01 07:15:27.795151: step 106490, loss = 0.28, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 9h:43m:08s remains)
INFO - root - 2017-12-01 07:15:29.354889: step 106500, loss = 0.28, batch loss = 0.16 (50.8 examples/sec; 0.158 sec/batch; 9h:53m:40s remains)
INFO - root - 2017-12-01 07:15:30.975940: step 106510, loss = 0.53, batch loss = 0.42 (50.0 examples/sec; 0.160 sec/batch; 10h:02m:17s remains)
INFO - root - 2017-12-01 07:15:32.534997: step 106520, loss = 0.28, batch loss = 0.16 (50.2 examples/sec; 0.159 sec/batch; 10h:00m:01s remains)
INFO - root - 2017-12-01 07:15:34.095736: step 106530, loss = 0.30, batch loss = 0.19 (51.8 examples/sec; 0.155 sec/batch; 9h:42m:09s remains)
INFO - root - 2017-12-01 07:15:35.675516: step 106540, loss = 0.32, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 9h:43m:50s remains)
INFO - root - 2017-12-01 07:15:37.224682: step 106550, loss = 0.31, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 9h:40m:23s remains)
INFO - root - 2017-12-01 07:15:38.795402: step 106560, loss = 0.40, batch loss = 0.29 (49.7 examples/sec; 0.161 sec/batch; 10h:05m:45s remains)
INFO - root - 2017-12-01 07:15:40.351129: step 106570, loss = 0.31, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 9h:50m:19s remains)
INFO - root - 2017-12-01 07:15:41.919829: step 106580, loss = 0.35, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 9h:48m:39s remains)
INFO - root - 2017-12-01 07:15:43.478278: step 106590, loss = 0.31, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 9h:33m:03s remains)
INFO - root - 2017-12-01 07:15:45.055056: step 106600, loss = 0.30, batch loss = 0.19 (49.8 examples/sec; 0.161 sec/batch; 10h:04m:34s remains)
INFO - root - 2017-12-01 07:15:46.690127: step 106610, loss = 0.43, batch loss = 0.32 (50.5 examples/sec; 0.158 sec/batch; 9h:55m:56s remains)
INFO - root - 2017-12-01 07:15:48.253705: step 106620, loss = 0.43, batch loss = 0.32 (51.1 examples/sec; 0.157 sec/batch; 9h:49m:54s remains)
INFO - root - 2017-12-01 07:15:49.815999: step 106630, loss = 0.30, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 9h:55m:03s remains)
INFO - root - 2017-12-01 07:15:51.379469: step 106640, loss = 0.32, batch loss = 0.21 (48.8 examples/sec; 0.164 sec/batch; 10h:17m:11s remains)
INFO - root - 2017-12-01 07:15:52.940281: step 106650, loss = 0.32, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 9h:42m:43s remains)
INFO - root - 2017-12-01 07:15:54.529030: step 106660, loss = 0.39, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 9h:44m:13s remains)
INFO - root - 2017-12-01 07:15:56.097246: step 106670, loss = 0.26, batch loss = 0.15 (50.5 examples/sec; 0.159 sec/batch; 9h:56m:44s remains)
INFO - root - 2017-12-01 07:15:57.654293: step 106680, loss = 0.33, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 9h:45m:09s remains)
INFO - root - 2017-12-01 07:15:59.217922: step 106690, loss = 0.31, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 9h:57m:22s remains)
INFO - root - 2017-12-01 07:16:00.780543: step 106700, loss = 0.32, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 9h:52m:58s remains)
INFO - root - 2017-12-01 07:16:02.444885: step 106710, loss = 0.30, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 9h:58m:19s remains)
INFO - root - 2017-12-01 07:16:04.021751: step 106720, loss = 0.36, batch loss = 0.25 (52.0 examples/sec; 0.154 sec/batch; 9h:38m:31s remains)
INFO - root - 2017-12-01 07:16:05.590697: step 106730, loss = 0.31, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 9h:55m:51s remains)
INFO - root - 2017-12-01 07:16:07.148154: step 106740, loss = 0.30, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 9h:53m:32s remains)
INFO - root - 2017-12-01 07:16:08.714708: step 106750, loss = 0.35, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 9h:45m:47s remains)
INFO - root - 2017-12-01 07:16:10.274982: step 106760, loss = 0.40, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 9h:48m:25s remains)
INFO - root - 2017-12-01 07:16:11.864727: step 106770, loss = 0.34, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 9h:39m:09s remains)
INFO - root - 2017-12-01 07:16:13.430067: step 106780, loss = 0.26, batch loss = 0.14 (50.8 examples/sec; 0.158 sec/batch; 9h:52m:55s remains)
INFO - root - 2017-12-01 07:16:14.996449: step 106790, loss = 0.45, batch loss = 0.33 (49.1 examples/sec; 0.163 sec/batch; 10h:13m:22s remains)
INFO - root - 2017-12-01 07:16:16.560501: step 106800, loss = 0.27, batch loss = 0.16 (50.1 examples/sec; 0.160 sec/batch; 10h:00m:41s remains)
INFO - root - 2017-12-01 07:16:18.166822: step 106810, loss = 0.31, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 9h:50m:21s remains)
INFO - root - 2017-12-01 07:16:19.732303: step 106820, loss = 0.33, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 9h:42m:57s remains)
INFO - root - 2017-12-01 07:16:21.305158: step 106830, loss = 0.31, batch loss = 0.19 (47.6 examples/sec; 0.168 sec/batch; 10h:31m:29s remains)
INFO - root - 2017-12-01 07:16:22.867002: step 106840, loss = 0.38, batch loss = 0.27 (52.8 examples/sec; 0.152 sec/batch; 9h:30m:06s remains)
INFO - root - 2017-12-01 07:16:24.415508: step 106850, loss = 0.45, batch loss = 0.34 (52.2 examples/sec; 0.153 sec/batch; 9h:36m:36s remains)
INFO - root - 2017-12-01 07:16:25.990639: step 106860, loss = 0.32, batch loss = 0.21 (49.8 examples/sec; 0.161 sec/batch; 10h:03m:54s remains)
INFO - root - 2017-12-01 07:16:27.537184: step 106870, loss = 0.29, batch loss = 0.17 (50.7 examples/sec; 0.158 sec/batch; 9h:52m:48s remains)
INFO - root - 2017-12-01 07:16:29.100749: step 106880, loss = 0.46, batch loss = 0.34 (52.0 examples/sec; 0.154 sec/batch; 9h:38m:21s remains)
INFO - root - 2017-12-01 07:16:30.664660: step 106890, loss = 0.31, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 9h:53m:28s remains)
INFO - root - 2017-12-01 07:16:32.256493: step 106900, loss = 0.33, batch loss = 0.21 (48.2 examples/sec; 0.166 sec/batch; 10h:24m:40s remains)
INFO - root - 2017-12-01 07:16:33.878857: step 106910, loss = 0.34, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 9h:57m:37s remains)
INFO - root - 2017-12-01 07:16:35.456107: step 106920, loss = 0.32, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 9h:43m:36s remains)
INFO - root - 2017-12-01 07:16:37.004871: step 106930, loss = 0.35, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 9h:53m:10s remains)
INFO - root - 2017-12-01 07:16:38.580394: step 106940, loss = 0.27, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 9h:46m:53s remains)
INFO - root - 2017-12-01 07:16:40.149871: step 106950, loss = 0.32, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 9h:43m:38s remains)
INFO - root - 2017-12-01 07:16:41.693365: step 106960, loss = 0.51, batch loss = 0.40 (51.6 examples/sec; 0.155 sec/batch; 9h:42m:56s remains)
INFO - root - 2017-12-01 07:16:43.271286: step 106970, loss = 0.33, batch loss = 0.21 (52.7 examples/sec; 0.152 sec/batch; 9h:31m:06s remains)
INFO - root - 2017-12-01 07:16:44.841734: step 106980, loss = 0.33, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 9h:36m:19s remains)
INFO - root - 2017-12-01 07:16:46.409008: step 106990, loss = 0.34, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 9h:50m:17s remains)
INFO - root - 2017-12-01 07:16:47.954664: step 107000, loss = 0.41, batch loss = 0.30 (50.8 examples/sec; 0.157 sec/batch; 9h:51m:53s remains)
INFO - root - 2017-12-01 07:16:49.606255: step 107010, loss = 0.31, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 9h:50m:57s remains)
INFO - root - 2017-12-01 07:16:51.192388: step 107020, loss = 0.31, batch loss = 0.20 (49.5 examples/sec; 0.162 sec/batch; 10h:07m:03s remains)
INFO - root - 2017-12-01 07:16:52.736805: step 107030, loss = 0.37, batch loss = 0.25 (52.8 examples/sec; 0.151 sec/batch; 9h:29m:16s remains)
INFO - root - 2017-12-01 07:16:54.292179: step 107040, loss = 0.33, batch loss = 0.21 (53.3 examples/sec; 0.150 sec/batch; 9h:23m:28s remains)
INFO - root - 2017-12-01 07:16:55.905639: step 107050, loss = 0.30, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 10h:07m:38s remains)
INFO - root - 2017-12-01 07:16:57.473583: step 107060, loss = 0.29, batch loss = 0.17 (49.6 examples/sec; 0.161 sec/batch; 10h:06m:12s remains)
INFO - root - 2017-12-01 07:16:59.046664: step 107070, loss = 0.33, batch loss = 0.21 (46.7 examples/sec; 0.171 sec/batch; 10h:42m:57s remains)
INFO - root - 2017-12-01 07:17:00.613289: step 107080, loss = 0.37, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 9h:38m:39s remains)
INFO - root - 2017-12-01 07:17:02.173384: step 107090, loss = 0.40, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 9h:52m:29s remains)
INFO - root - 2017-12-01 07:17:03.749085: step 107100, loss = 0.31, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 9h:51m:28s remains)
INFO - root - 2017-12-01 07:17:05.384382: step 107110, loss = 0.29, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 9h:46m:49s remains)
INFO - root - 2017-12-01 07:17:06.947281: step 107120, loss = 0.29, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 9h:38m:44s remains)
INFO - root - 2017-12-01 07:17:08.516313: step 107130, loss = 0.31, batch loss = 0.19 (50.3 examples/sec; 0.159 sec/batch; 9h:57m:37s remains)
INFO - root - 2017-12-01 07:17:10.094008: step 107140, loss = 0.34, batch loss = 0.22 (48.8 examples/sec; 0.164 sec/batch; 10h:16m:05s remains)
INFO - root - 2017-12-01 07:17:11.675411: step 107150, loss = 0.30, batch loss = 0.19 (49.8 examples/sec; 0.161 sec/batch; 10h:03m:21s remains)
INFO - root - 2017-12-01 07:17:13.263284: step 107160, loss = 0.30, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 9h:49m:51s remains)
INFO - root - 2017-12-01 07:17:14.823572: step 107170, loss = 0.28, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 9h:49m:49s remains)
INFO - root - 2017-12-01 07:17:16.386688: step 107180, loss = 0.27, batch loss = 0.15 (50.8 examples/sec; 0.157 sec/batch; 9h:51m:12s remains)
INFO - root - 2017-12-01 07:17:17.961870: step 107190, loss = 0.33, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 9h:49m:11s remains)
INFO - root - 2017-12-01 07:17:19.523528: step 107200, loss = 0.40, batch loss = 0.29 (52.3 examples/sec; 0.153 sec/batch; 9h:34m:46s remains)
INFO - root - 2017-12-01 07:17:21.129459: step 107210, loss = 0.28, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 9h:41m:11s remains)
INFO - root - 2017-12-01 07:17:22.705585: step 107220, loss = 0.32, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 9h:37m:14s remains)
INFO - root - 2017-12-01 07:17:24.315166: step 107230, loss = 0.34, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 9h:38m:35s remains)
INFO - root - 2017-12-01 07:17:25.907581: step 107240, loss = 0.32, batch loss = 0.20 (48.7 examples/sec; 0.164 sec/batch; 10h:17m:19s remains)
INFO - root - 2017-12-01 07:17:27.484897: step 107250, loss = 0.28, batch loss = 0.17 (50.8 examples/sec; 0.158 sec/batch; 9h:51m:19s remains)
INFO - root - 2017-12-01 07:17:29.040095: step 107260, loss = 0.33, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 9h:38m:34s remains)
INFO - root - 2017-12-01 07:17:30.599332: step 107270, loss = 0.28, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 9h:56m:01s remains)
INFO - root - 2017-12-01 07:17:32.173207: step 107280, loss = 0.31, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 10h:02m:01s remains)
INFO - root - 2017-12-01 07:17:33.746995: step 107290, loss = 0.39, batch loss = 0.28 (52.1 examples/sec; 0.153 sec/batch; 9h:36m:04s remains)
INFO - root - 2017-12-01 07:17:35.307284: step 107300, loss = 0.32, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 9h:56m:57s remains)
INFO - root - 2017-12-01 07:17:36.962301: step 107310, loss = 0.43, batch loss = 0.31 (49.2 examples/sec; 0.163 sec/batch; 10h:10m:06s remains)
INFO - root - 2017-12-01 07:17:38.557658: step 107320, loss = 0.37, batch loss = 0.26 (49.3 examples/sec; 0.162 sec/batch; 10h:08m:40s remains)
INFO - root - 2017-12-01 07:17:40.129483: step 107330, loss = 0.32, batch loss = 0.21 (48.2 examples/sec; 0.166 sec/batch; 10h:23m:05s remains)
INFO - root - 2017-12-01 07:17:41.699026: step 107340, loss = 0.29, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 9h:50m:12s remains)
INFO - root - 2017-12-01 07:17:43.248247: step 107350, loss = 0.26, batch loss = 0.15 (51.9 examples/sec; 0.154 sec/batch; 9h:38m:40s remains)
INFO - root - 2017-12-01 07:17:44.808874: step 107360, loss = 0.38, batch loss = 0.27 (53.0 examples/sec; 0.151 sec/batch; 9h:26m:16s remains)
INFO - root - 2017-12-01 07:17:46.382631: step 107370, loss = 0.29, batch loss = 0.18 (52.1 examples/sec; 0.154 sec/batch; 9h:36m:22s remains)
INFO - root - 2017-12-01 07:17:47.950532: step 107380, loss = 0.36, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 9h:45m:28s remains)
INFO - root - 2017-12-01 07:17:49.526461: step 107390, loss = 0.29, batch loss = 0.18 (49.2 examples/sec; 0.162 sec/batch; 10h:09m:28s remains)
INFO - root - 2017-12-01 07:17:51.094124: step 107400, loss = 0.32, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 9h:56m:36s remains)
INFO - root - 2017-12-01 07:17:52.698898: step 107410, loss = 0.29, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 9h:50m:48s remains)
INFO - root - 2017-12-01 07:17:54.282708: step 107420, loss = 0.40, batch loss = 0.29 (47.7 examples/sec; 0.168 sec/batch; 10h:29m:36s remains)
INFO - root - 2017-12-01 07:17:55.852529: step 107430, loss = 0.33, batch loss = 0.21 (49.2 examples/sec; 0.163 sec/batch; 10h:09m:54s remains)
INFO - root - 2017-12-01 07:17:57.422698: step 107440, loss = 0.29, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 9h:43m:33s remains)
INFO - root - 2017-12-01 07:17:58.994012: step 107450, loss = 0.47, batch loss = 0.36 (50.0 examples/sec; 0.160 sec/batch; 9h:59m:37s remains)
INFO - root - 2017-12-01 07:18:00.553359: step 107460, loss = 0.44, batch loss = 0.33 (50.2 examples/sec; 0.159 sec/batch; 9h:57m:52s remains)
INFO - root - 2017-12-01 07:18:02.121275: step 107470, loss = 0.50, batch loss = 0.39 (51.4 examples/sec; 0.156 sec/batch; 9h:43m:55s remains)
INFO - root - 2017-12-01 07:18:03.678706: step 107480, loss = 0.40, batch loss = 0.29 (53.6 examples/sec; 0.149 sec/batch; 9h:19m:55s remains)
INFO - root - 2017-12-01 07:18:05.270360: step 107490, loss = 0.30, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 9h:55m:21s remains)
INFO - root - 2017-12-01 07:18:06.822824: step 107500, loss = 0.41, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 9h:52m:05s remains)
INFO - root - 2017-12-01 07:18:08.502577: step 107510, loss = 0.33, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 9h:35m:12s remains)
INFO - root - 2017-12-01 07:18:10.091848: step 107520, loss = 0.51, batch loss = 0.40 (49.8 examples/sec; 0.161 sec/batch; 10h:02m:38s remains)
INFO - root - 2017-12-01 07:18:11.682301: step 107530, loss = 0.35, batch loss = 0.23 (48.7 examples/sec; 0.164 sec/batch; 10h:15m:23s remains)
INFO - root - 2017-12-01 07:18:13.274009: step 107540, loss = 0.33, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 9h:49m:46s remains)
INFO - root - 2017-12-01 07:18:14.837764: step 107550, loss = 0.30, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 9h:33m:49s remains)
INFO - root - 2017-12-01 07:18:16.400081: step 107560, loss = 0.47, batch loss = 0.36 (53.5 examples/sec; 0.150 sec/batch; 9h:20m:58s remains)
INFO - root - 2017-12-01 07:18:18.007412: step 107570, loss = 0.29, batch loss = 0.18 (50.0 examples/sec; 0.160 sec/batch; 9h:59m:41s remains)
INFO - root - 2017-12-01 07:18:19.578811: step 107580, loss = 0.33, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 9h:59m:09s remains)
INFO - root - 2017-12-01 07:18:21.151788: step 107590, loss = 0.47, batch loss = 0.36 (50.1 examples/sec; 0.160 sec/batch; 9h:58m:31s remains)
INFO - root - 2017-12-01 07:18:22.720970: step 107600, loss = 0.32, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 9h:55m:59s remains)
INFO - root - 2017-12-01 07:18:24.337041: step 107610, loss = 0.31, batch loss = 0.20 (49.7 examples/sec; 0.161 sec/batch; 10h:03m:00s remains)
INFO - root - 2017-12-01 07:18:25.886865: step 107620, loss = 0.36, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 9h:44m:52s remains)
INFO - root - 2017-12-01 07:18:27.458128: step 107630, loss = 0.29, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 9h:42m:35s remains)
INFO - root - 2017-12-01 07:18:29.009809: step 107640, loss = 0.31, batch loss = 0.20 (53.6 examples/sec; 0.149 sec/batch; 9h:19m:22s remains)
INFO - root - 2017-12-01 07:18:30.573110: step 107650, loss = 0.28, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 9h:36m:45s remains)
INFO - root - 2017-12-01 07:18:32.144655: step 107660, loss = 0.39, batch loss = 0.27 (49.8 examples/sec; 0.161 sec/batch; 10h:02m:22s remains)
INFO - root - 2017-12-01 07:18:33.697202: step 107670, loss = 0.30, batch loss = 0.19 (53.8 examples/sec; 0.149 sec/batch; 9h:17m:01s remains)
INFO - root - 2017-12-01 07:18:35.264419: step 107680, loss = 0.28, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 9h:49m:03s remains)
INFO - root - 2017-12-01 07:18:36.824526: step 107690, loss = 0.36, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 9h:38m:48s remains)
INFO - root - 2017-12-01 07:18:38.387686: step 107700, loss = 0.34, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 9h:45m:06s remains)
INFO - root - 2017-12-01 07:18:40.005975: step 107710, loss = 0.37, batch loss = 0.26 (50.8 examples/sec; 0.157 sec/batch; 9h:49m:41s remains)
INFO - root - 2017-12-01 07:18:41.552726: step 107720, loss = 0.32, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 9h:36m:53s remains)
INFO - root - 2017-12-01 07:18:43.129359: step 107730, loss = 0.30, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 9h:45m:30s remains)
INFO - root - 2017-12-01 07:18:44.716298: step 107740, loss = 0.30, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 9h:54m:14s remains)
INFO - root - 2017-12-01 07:18:46.275360: step 107750, loss = 0.33, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 9h:53m:41s remains)
INFO - root - 2017-12-01 07:18:47.844265: step 107760, loss = 0.32, batch loss = 0.21 (48.8 examples/sec; 0.164 sec/batch; 10h:13m:33s remains)
INFO - root - 2017-12-01 07:18:49.446397: step 107770, loss = 0.29, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 9h:51m:29s remains)
INFO - root - 2017-12-01 07:18:51.000805: step 107780, loss = 0.27, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 9h:42m:38s remains)
INFO - root - 2017-12-01 07:18:52.560136: step 107790, loss = 0.34, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 9h:52m:42s remains)
INFO - root - 2017-12-01 07:18:54.120317: step 107800, loss = 0.28, batch loss = 0.17 (53.2 examples/sec; 0.150 sec/batch; 9h:22m:53s remains)
INFO - root - 2017-12-01 07:18:55.739911: step 107810, loss = 0.32, batch loss = 0.21 (48.0 examples/sec; 0.167 sec/batch; 10h:23m:34s remains)
INFO - root - 2017-12-01 07:18:57.300942: step 107820, loss = 0.30, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 9h:45m:36s remains)
INFO - root - 2017-12-01 07:18:58.872278: step 107830, loss = 0.33, batch loss = 0.22 (46.5 examples/sec; 0.172 sec/batch; 10h:44m:15s remains)
INFO - root - 2017-12-01 07:19:00.432662: step 107840, loss = 0.31, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 9h:36m:27s remains)
INFO - root - 2017-12-01 07:19:01.990169: step 107850, loss = 0.29, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 9h:37m:41s remains)
INFO - root - 2017-12-01 07:19:03.557419: step 107860, loss = 0.31, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 9h:38m:18s remains)
INFO - root - 2017-12-01 07:19:05.130198: step 107870, loss = 0.35, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 9h:49m:44s remains)
INFO - root - 2017-12-01 07:19:06.682407: step 107880, loss = 0.29, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 9h:52m:02s remains)
INFO - root - 2017-12-01 07:19:08.229422: step 107890, loss = 0.46, batch loss = 0.35 (50.5 examples/sec; 0.158 sec/batch; 9h:52m:38s remains)
INFO - root - 2017-12-01 07:19:09.790483: step 107900, loss = 0.32, batch loss = 0.20 (53.9 examples/sec; 0.148 sec/batch; 9h:15m:05s remains)
INFO - root - 2017-12-01 07:19:11.449540: step 107910, loss = 0.28, batch loss = 0.17 (49.9 examples/sec; 0.160 sec/batch; 10h:00m:41s remains)
INFO - root - 2017-12-01 07:19:13.003052: step 107920, loss = 0.35, batch loss = 0.24 (52.8 examples/sec; 0.152 sec/batch; 9h:27m:21s remains)
INFO - root - 2017-12-01 07:19:14.602038: step 107930, loss = 0.34, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 9h:37m:53s remains)
INFO - root - 2017-12-01 07:19:16.168499: step 107940, loss = 0.35, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 9h:50m:03s remains)
INFO - root - 2017-12-01 07:19:17.720775: step 107950, loss = 0.41, batch loss = 0.30 (50.8 examples/sec; 0.158 sec/batch; 9h:49m:40s remains)
INFO - root - 2017-12-01 07:19:19.280588: step 107960, loss = 0.37, batch loss = 0.25 (50.5 examples/sec; 0.158 sec/batch; 9h:52m:33s remains)
INFO - root - 2017-12-01 07:19:20.855045: step 107970, loss = 0.27, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 9h:37m:56s remains)
INFO - root - 2017-12-01 07:19:22.410424: step 107980, loss = 0.35, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 9h:29m:05s remains)
INFO - root - 2017-12-01 07:19:23.984238: step 107990, loss = 0.42, batch loss = 0.30 (50.8 examples/sec; 0.158 sec/batch; 9h:49m:44s remains)
INFO - root - 2017-12-01 07:19:25.544481: step 108000, loss = 0.30, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 9h:52m:11s remains)
INFO - root - 2017-12-01 07:19:27.200976: step 108010, loss = 0.41, batch loss = 0.30 (51.9 examples/sec; 0.154 sec/batch; 9h:36m:15s remains)
INFO - root - 2017-12-01 07:19:28.765503: step 108020, loss = 0.28, batch loss = 0.16 (50.1 examples/sec; 0.160 sec/batch; 9h:57m:12s remains)
INFO - root - 2017-12-01 07:19:30.312776: step 108030, loss = 0.34, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 9h:38m:45s remains)
INFO - root - 2017-12-01 07:19:31.853953: step 108040, loss = 0.27, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 9h:40m:49s remains)
INFO - root - 2017-12-01 07:19:33.413503: step 108050, loss = 0.34, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 9h:31m:57s remains)
INFO - root - 2017-12-01 07:19:34.963998: step 108060, loss = 0.29, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 9h:50m:50s remains)
INFO - root - 2017-12-01 07:19:36.552357: step 108070, loss = 0.33, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 9h:49m:16s remains)
INFO - root - 2017-12-01 07:19:38.111682: step 108080, loss = 0.52, batch loss = 0.41 (50.4 examples/sec; 0.159 sec/batch; 9h:53m:12s remains)
INFO - root - 2017-12-01 07:19:39.675180: step 108090, loss = 0.31, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 9h:40m:20s remains)
INFO - root - 2017-12-01 07:19:41.241902: step 108100, loss = 0.30, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 9h:35m:25s remains)
INFO - root - 2017-12-01 07:19:42.878832: step 108110, loss = 0.43, batch loss = 0.32 (51.5 examples/sec; 0.155 sec/batch; 9h:41m:05s remains)
INFO - root - 2017-12-01 07:19:44.440919: step 108120, loss = 0.28, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 9h:43m:05s remains)
INFO - root - 2017-12-01 07:19:45.982290: step 108130, loss = 0.33, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 9h:31m:57s remains)
INFO - root - 2017-12-01 07:19:47.577021: step 108140, loss = 0.35, batch loss = 0.24 (52.1 examples/sec; 0.154 sec/batch; 9h:34m:11s remains)
INFO - root - 2017-12-01 07:19:49.131658: step 108150, loss = 0.37, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 9h:42m:48s remains)
INFO - root - 2017-12-01 07:19:50.709813: step 108160, loss = 0.31, batch loss = 0.19 (49.4 examples/sec; 0.162 sec/batch; 10h:05m:45s remains)
INFO - root - 2017-12-01 07:19:52.287101: step 108170, loss = 0.30, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 9h:28m:29s remains)
INFO - root - 2017-12-01 07:19:53.851830: step 108180, loss = 0.40, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 9h:47m:46s remains)
INFO - root - 2017-12-01 07:19:55.432611: step 108190, loss = 0.52, batch loss = 0.41 (52.3 examples/sec; 0.153 sec/batch; 9h:32m:12s remains)
INFO - root - 2017-12-01 07:19:56.992658: step 108200, loss = 0.35, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 9h:54m:49s remains)
INFO - root - 2017-12-01 07:19:58.668383: step 108210, loss = 0.30, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 9h:37m:08s remains)
INFO - root - 2017-12-01 07:20:00.246210: step 108220, loss = 0.31, batch loss = 0.20 (48.6 examples/sec; 0.165 sec/batch; 10h:15m:46s remains)
INFO - root - 2017-12-01 07:20:01.830997: step 108230, loss = 0.34, batch loss = 0.23 (50.4 examples/sec; 0.159 sec/batch; 9h:53m:10s remains)
INFO - root - 2017-12-01 07:20:03.386770: step 108240, loss = 0.32, batch loss = 0.21 (51.8 examples/sec; 0.155 sec/batch; 9h:37m:44s remains)
INFO - root - 2017-12-01 07:20:04.963434: step 108250, loss = 0.34, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 9h:39m:01s remains)
INFO - root - 2017-12-01 07:20:06.518253: step 108260, loss = 0.38, batch loss = 0.27 (52.5 examples/sec; 0.152 sec/batch; 9h:29m:49s remains)
INFO - root - 2017-12-01 07:20:08.088972: step 108270, loss = 0.29, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 9h:42m:39s remains)
INFO - root - 2017-12-01 07:20:09.655619: step 108280, loss = 0.38, batch loss = 0.27 (50.5 examples/sec; 0.158 sec/batch; 9h:52m:00s remains)
INFO - root - 2017-12-01 07:20:11.245854: step 108290, loss = 0.37, batch loss = 0.25 (51.1 examples/sec; 0.156 sec/batch; 9h:44m:39s remains)
INFO - root - 2017-12-01 07:20:12.796761: step 108300, loss = 0.29, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 9h:46m:39s remains)
INFO - root - 2017-12-01 07:20:14.405825: step 108310, loss = 0.29, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 9h:45m:00s remains)
INFO - root - 2017-12-01 07:20:15.963525: step 108320, loss = 0.33, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 9h:49m:43s remains)
INFO - root - 2017-12-01 07:20:17.524466: step 108330, loss = 0.39, batch loss = 0.28 (50.1 examples/sec; 0.160 sec/batch; 9h:56m:06s remains)
INFO - root - 2017-12-01 07:20:19.089955: step 108340, loss = 0.30, batch loss = 0.19 (51.1 examples/sec; 0.156 sec/batch; 9h:44m:21s remains)
INFO - root - 2017-12-01 07:20:20.657942: step 108350, loss = 0.36, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 9h:44m:14s remains)
INFO - root - 2017-12-01 07:20:22.235335: step 108360, loss = 0.32, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 9h:45m:22s remains)
INFO - root - 2017-12-01 07:20:23.817751: step 108370, loss = 0.34, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 9h:51m:44s remains)
INFO - root - 2017-12-01 07:20:25.395058: step 108380, loss = 0.36, batch loss = 0.25 (49.8 examples/sec; 0.161 sec/batch; 10h:00m:13s remains)
INFO - root - 2017-12-01 07:20:26.973615: step 108390, loss = 0.38, batch loss = 0.27 (51.2 examples/sec; 0.156 sec/batch; 9h:43m:30s remains)
INFO - root - 2017-12-01 07:20:28.546176: step 108400, loss = 0.44, batch loss = 0.32 (51.9 examples/sec; 0.154 sec/batch; 9h:36m:07s remains)
INFO - root - 2017-12-01 07:20:30.149620: step 108410, loss = 0.27, batch loss = 0.16 (51.1 examples/sec; 0.157 sec/batch; 9h:45m:02s remains)
INFO - root - 2017-12-01 07:20:31.708108: step 108420, loss = 0.34, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 9h:35m:34s remains)
INFO - root - 2017-12-01 07:20:33.281881: step 108430, loss = 0.37, batch loss = 0.26 (50.2 examples/sec; 0.159 sec/batch; 9h:54m:39s remains)
INFO - root - 2017-12-01 07:20:34.871702: step 108440, loss = 0.28, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 9h:51m:17s remains)
INFO - root - 2017-12-01 07:20:36.427227: step 108450, loss = 0.39, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 9h:43m:13s remains)
INFO - root - 2017-12-01 07:20:37.967660: step 108460, loss = 0.27, batch loss = 0.15 (51.4 examples/sec; 0.156 sec/batch; 9h:40m:50s remains)
INFO - root - 2017-12-01 07:20:39.532805: step 108470, loss = 0.37, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 9h:44m:45s remains)
INFO - root - 2017-12-01 07:20:41.109865: step 108480, loss = 0.31, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 9h:32m:07s remains)
INFO - root - 2017-12-01 07:20:42.673892: step 108490, loss = 0.36, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 9h:46m:18s remains)
INFO - root - 2017-12-01 07:20:44.237761: step 108500, loss = 0.31, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 9h:50m:32s remains)
INFO - root - 2017-12-01 07:20:45.887884: step 108510, loss = 0.29, batch loss = 0.18 (51.1 examples/sec; 0.156 sec/batch; 9h:43m:56s remains)
INFO - root - 2017-12-01 07:20:47.458989: step 108520, loss = 0.36, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 9h:49m:34s remains)
INFO - root - 2017-12-01 07:20:49.013488: step 108530, loss = 0.36, batch loss = 0.25 (51.1 examples/sec; 0.156 sec/batch; 9h:43m:56s remains)
INFO - root - 2017-12-01 07:20:50.579547: step 108540, loss = 0.27, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 9h:40m:56s remains)
INFO - root - 2017-12-01 07:20:52.147535: step 108550, loss = 0.39, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 9h:37m:45s remains)
INFO - root - 2017-12-01 07:20:53.702605: step 108560, loss = 0.33, batch loss = 0.22 (51.1 examples/sec; 0.156 sec/batch; 9h:43m:50s remains)
INFO - root - 2017-12-01 07:20:55.255940: step 108570, loss = 0.29, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 9h:42m:24s remains)
INFO - root - 2017-12-01 07:20:56.822396: step 108580, loss = 0.31, batch loss = 0.20 (48.9 examples/sec; 0.164 sec/batch; 10h:10m:56s remains)
INFO - root - 2017-12-01 07:20:58.411737: step 108590, loss = 0.46, batch loss = 0.34 (52.1 examples/sec; 0.153 sec/batch; 9h:32m:48s remains)
INFO - root - 2017-12-01 07:20:59.963579: step 108600, loss = 0.38, batch loss = 0.27 (52.1 examples/sec; 0.153 sec/batch; 9h:32m:28s remains)
INFO - root - 2017-12-01 07:21:01.614638: step 108610, loss = 0.31, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 9h:37m:47s remains)
INFO - root - 2017-12-01 07:21:03.184571: step 108620, loss = 0.30, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 9h:33m:35s remains)
INFO - root - 2017-12-01 07:21:04.766266: step 108630, loss = 0.29, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 9h:47m:42s remains)
INFO - root - 2017-12-01 07:21:06.328810: step 108640, loss = 0.31, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 9h:50m:44s remains)
INFO - root - 2017-12-01 07:21:07.895476: step 108650, loss = 0.36, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 9h:34m:28s remains)
INFO - root - 2017-12-01 07:21:09.464645: step 108660, loss = 0.47, batch loss = 0.36 (51.8 examples/sec; 0.154 sec/batch; 9h:35m:48s remains)
INFO - root - 2017-12-01 07:21:11.040995: step 108670, loss = 0.27, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 9h:39m:49s remains)
INFO - root - 2017-12-01 07:21:12.604901: step 108680, loss = 0.26, batch loss = 0.14 (51.6 examples/sec; 0.155 sec/batch; 9h:37m:50s remains)
INFO - root - 2017-12-01 07:21:14.164145: step 108690, loss = 0.43, batch loss = 0.32 (51.8 examples/sec; 0.154 sec/batch; 9h:36m:00s remains)
INFO - root - 2017-12-01 07:21:15.732417: step 108700, loss = 0.42, batch loss = 0.31 (51.7 examples/sec; 0.155 sec/batch; 9h:37m:30s remains)
INFO - root - 2017-12-01 07:21:17.366946: step 108710, loss = 0.38, batch loss = 0.27 (49.0 examples/sec; 0.163 sec/batch; 10h:09m:10s remains)
INFO - root - 2017-12-01 07:21:18.933088: step 108720, loss = 0.30, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 9h:45m:50s remains)
INFO - root - 2017-12-01 07:21:20.519866: step 108730, loss = 0.35, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 9h:41m:32s remains)
INFO - root - 2017-12-01 07:21:22.070398: step 108740, loss = 0.32, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 9h:36m:00s remains)
INFO - root - 2017-12-01 07:21:23.633126: step 108750, loss = 0.57, batch loss = 0.45 (51.7 examples/sec; 0.155 sec/batch; 9h:36m:59s remains)
INFO - root - 2017-12-01 07:21:25.206065: step 108760, loss = 0.32, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 9h:42m:27s remains)
INFO - root - 2017-12-01 07:21:26.769301: step 108770, loss = 0.39, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 9h:48m:45s remains)
INFO - root - 2017-12-01 07:21:28.328144: step 108780, loss = 0.31, batch loss = 0.19 (52.7 examples/sec; 0.152 sec/batch; 9h:25m:34s remains)
INFO - root - 2017-12-01 07:21:29.905360: step 108790, loss = 0.31, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 9h:33m:18s remains)
INFO - root - 2017-12-01 07:21:31.478774: step 108800, loss = 0.29, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 9h:41m:22s remains)
INFO - root - 2017-12-01 07:21:33.061949: step 108810, loss = 0.38, batch loss = 0.27 (53.1 examples/sec; 0.151 sec/batch; 9h:21m:42s remains)
INFO - root - 2017-12-01 07:21:34.632184: step 108820, loss = 0.39, batch loss = 0.28 (52.8 examples/sec; 0.151 sec/batch; 9h:24m:23s remains)
INFO - root - 2017-12-01 07:21:36.202528: step 108830, loss = 0.25, batch loss = 0.14 (52.1 examples/sec; 0.154 sec/batch; 9h:32m:24s remains)
INFO - root - 2017-12-01 07:21:37.783093: step 108840, loss = 0.26, batch loss = 0.15 (50.0 examples/sec; 0.160 sec/batch; 9h:56m:47s remains)
INFO - root - 2017-12-01 07:21:39.340739: step 108850, loss = 0.26, batch loss = 0.15 (50.2 examples/sec; 0.159 sec/batch; 9h:53m:46s remains)
INFO - root - 2017-12-01 07:21:40.899385: step 108860, loss = 0.31, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 9h:50m:00s remains)
INFO - root - 2017-12-01 07:21:42.456207: step 108870, loss = 0.29, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 9h:49m:32s remains)
INFO - root - 2017-12-01 07:21:44.009105: step 108880, loss = 0.34, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 9h:38m:49s remains)
INFO - root - 2017-12-01 07:21:45.578568: step 108890, loss = 0.26, batch loss = 0.14 (51.3 examples/sec; 0.156 sec/batch; 9h:40m:54s remains)
INFO - root - 2017-12-01 07:21:47.148684: step 108900, loss = 0.26, batch loss = 0.14 (51.2 examples/sec; 0.156 sec/batch; 9h:42m:22s remains)
INFO - root - 2017-12-01 07:21:48.825932: step 108910, loss = 0.29, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 9h:41m:10s remains)
INFO - root - 2017-12-01 07:21:50.391068: step 108920, loss = 0.41, batch loss = 0.30 (50.1 examples/sec; 0.160 sec/batch; 9h:54m:26s remains)
INFO - root - 2017-12-01 07:21:51.961253: step 108930, loss = 0.37, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 9h:31m:20s remains)
INFO - root - 2017-12-01 07:21:53.551587: step 108940, loss = 0.36, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 9h:34m:28s remains)
INFO - root - 2017-12-01 07:21:55.129220: step 108950, loss = 0.28, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 9h:41m:15s remains)
INFO - root - 2017-12-01 07:21:56.676755: step 108960, loss = 0.42, batch loss = 0.31 (52.5 examples/sec; 0.153 sec/batch; 9h:28m:10s remains)
INFO - root - 2017-12-01 07:21:58.230383: step 108970, loss = 0.33, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 9h:32m:15s remains)
INFO - root - 2017-12-01 07:21:59.801478: step 108980, loss = 0.46, batch loss = 0.35 (51.9 examples/sec; 0.154 sec/batch; 9h:34m:06s remains)
INFO - root - 2017-12-01 07:22:01.381919: step 108990, loss = 0.39, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 9h:47m:18s remains)
INFO - root - 2017-12-01 07:22:02.953987: step 109000, loss = 0.33, batch loss = 0.22 (49.8 examples/sec; 0.161 sec/batch; 9h:58m:02s remains)
INFO - root - 2017-12-01 07:22:04.592741: step 109010, loss = 0.31, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 9h:33m:01s remains)
INFO - root - 2017-12-01 07:22:06.162499: step 109020, loss = 0.30, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 9h:26m:55s remains)
INFO - root - 2017-12-01 07:22:07.705596: step 109030, loss = 0.30, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 9h:38m:08s remains)
INFO - root - 2017-12-01 07:22:09.282752: step 109040, loss = 0.39, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 9h:47m:33s remains)
INFO - root - 2017-12-01 07:22:10.863639: step 109050, loss = 0.30, batch loss = 0.18 (48.8 examples/sec; 0.164 sec/batch; 10h:10m:00s remains)
INFO - root - 2017-12-01 07:22:12.435528: step 109060, loss = 0.29, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 9h:36m:30s remains)
INFO - root - 2017-12-01 07:22:13.986649: step 109070, loss = 0.33, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 9h:55m:40s remains)
INFO - root - 2017-12-01 07:22:15.545399: step 109080, loss = 0.27, batch loss = 0.16 (49.4 examples/sec; 0.162 sec/batch; 10h:03m:23s remains)
INFO - root - 2017-12-01 07:22:17.116419: step 109090, loss = 0.41, batch loss = 0.30 (52.8 examples/sec; 0.152 sec/batch; 9h:24m:18s remains)
INFO - root - 2017-12-01 07:22:18.681739: step 109100, loss = 0.26, batch loss = 0.15 (51.8 examples/sec; 0.155 sec/batch; 9h:35m:33s remains)
INFO - root - 2017-12-01 07:22:20.331763: step 109110, loss = 0.29, batch loss = 0.18 (49.1 examples/sec; 0.163 sec/batch; 10h:06m:02s remains)
INFO - root - 2017-12-01 07:22:21.900782: step 109120, loss = 0.32, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 9h:37m:46s remains)
INFO - root - 2017-12-01 07:22:23.468031: step 109130, loss = 0.29, batch loss = 0.17 (50.2 examples/sec; 0.159 sec/batch; 9h:53m:44s remains)
INFO - root - 2017-12-01 07:22:25.029101: step 109140, loss = 0.33, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 9h:44m:49s remains)
INFO - root - 2017-12-01 07:22:26.580232: step 109150, loss = 0.30, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 9h:35m:37s remains)
INFO - root - 2017-12-01 07:22:28.127929: step 109160, loss = 0.34, batch loss = 0.23 (52.1 examples/sec; 0.154 sec/batch; 9h:31m:55s remains)
INFO - root - 2017-12-01 07:22:29.666333: step 109170, loss = 0.32, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 9h:28m:32s remains)
INFO - root - 2017-12-01 07:22:31.301112: step 109180, loss = 0.40, batch loss = 0.28 (52.6 examples/sec; 0.152 sec/batch; 9h:26m:05s remains)
INFO - root - 2017-12-01 07:22:32.849944: step 109190, loss = 0.37, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 9h:42m:51s remains)
INFO - root - 2017-12-01 07:22:34.416558: step 109200, loss = 0.37, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 9h:49m:08s remains)
INFO - root - 2017-12-01 07:22:36.068665: step 109210, loss = 0.36, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 9h:33m:43s remains)
INFO - root - 2017-12-01 07:22:37.625918: step 109220, loss = 0.34, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 9h:51m:22s remains)
INFO - root - 2017-12-01 07:22:39.188219: step 109230, loss = 0.30, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 9h:38m:12s remains)
INFO - root - 2017-12-01 07:22:40.748603: step 109240, loss = 0.25, batch loss = 0.14 (51.9 examples/sec; 0.154 sec/batch; 9h:33m:42s remains)
INFO - root - 2017-12-01 07:22:42.326288: step 109250, loss = 0.32, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 9h:30m:39s remains)
INFO - root - 2017-12-01 07:22:43.896948: step 109260, loss = 0.45, batch loss = 0.34 (51.2 examples/sec; 0.156 sec/batch; 9h:41m:22s remains)
INFO - root - 2017-12-01 07:22:45.454063: step 109270, loss = 0.27, batch loss = 0.16 (52.3 examples/sec; 0.153 sec/batch; 9h:29m:36s remains)
INFO - root - 2017-12-01 07:22:47.024276: step 109280, loss = 0.31, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 9h:43m:15s remains)
INFO - root - 2017-12-01 07:22:48.605810: step 109290, loss = 0.50, batch loss = 0.39 (51.9 examples/sec; 0.154 sec/batch; 9h:33m:39s remains)
INFO - root - 2017-12-01 07:22:50.164595: step 109300, loss = 0.30, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 9h:50m:22s remains)
INFO - root - 2017-12-01 07:22:51.796306: step 109310, loss = 0.34, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 9h:24m:15s remains)
INFO - root - 2017-12-01 07:22:53.371206: step 109320, loss = 0.28, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 9h:40m:12s remains)
INFO - root - 2017-12-01 07:22:54.927137: step 109330, loss = 0.31, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 9h:42m:06s remains)
INFO - root - 2017-12-01 07:22:56.486604: step 109340, loss = 0.30, batch loss = 0.18 (50.1 examples/sec; 0.160 sec/batch; 9h:54m:23s remains)
INFO - root - 2017-12-01 07:22:58.047884: step 109350, loss = 0.39, batch loss = 0.28 (48.0 examples/sec; 0.167 sec/batch; 10h:20m:11s remains)
INFO - root - 2017-12-01 07:22:59.625969: step 109360, loss = 0.39, batch loss = 0.28 (52.1 examples/sec; 0.154 sec/batch; 9h:30m:58s remains)
INFO - root - 2017-12-01 07:23:01.199681: step 109370, loss = 0.32, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 9h:51m:38s remains)
INFO - root - 2017-12-01 07:23:02.767311: step 109380, loss = 0.26, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 9h:40m:10s remains)
INFO - root - 2017-12-01 07:23:04.325465: step 109390, loss = 0.29, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 9h:28m:18s remains)
INFO - root - 2017-12-01 07:23:05.890766: step 109400, loss = 0.35, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 9h:38m:20s remains)
INFO - root - 2017-12-01 07:23:07.500151: step 109410, loss = 0.29, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 9h:43m:53s remains)
INFO - root - 2017-12-01 07:23:09.079152: step 109420, loss = 0.29, batch loss = 0.18 (48.4 examples/sec; 0.165 sec/batch; 10h:14m:56s remains)
INFO - root - 2017-12-01 07:23:10.638408: step 109430, loss = 0.32, batch loss = 0.21 (52.6 examples/sec; 0.152 sec/batch; 9h:25m:42s remains)
INFO - root - 2017-12-01 07:23:12.227120: step 109440, loss = 0.28, batch loss = 0.17 (52.1 examples/sec; 0.154 sec/batch; 9h:31m:09s remains)
INFO - root - 2017-12-01 07:23:13.784803: step 109450, loss = 0.35, batch loss = 0.24 (49.9 examples/sec; 0.160 sec/batch; 9h:56m:28s remains)
INFO - root - 2017-12-01 07:23:15.351368: step 109460, loss = 0.30, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 10h:00m:34s remains)
INFO - root - 2017-12-01 07:23:16.910598: step 109470, loss = 0.27, batch loss = 0.16 (50.3 examples/sec; 0.159 sec/batch; 9h:50m:50s remains)
INFO - root - 2017-12-01 07:23:18.469475: step 109480, loss = 0.36, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 9h:39m:23s remains)
INFO - root - 2017-12-01 07:23:20.052376: step 109490, loss = 0.27, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 9h:43m:48s remains)
INFO - root - 2017-12-01 07:23:21.608587: step 109500, loss = 0.43, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 9h:45m:55s remains)
INFO - root - 2017-12-01 07:23:23.216180: step 109510, loss = 0.27, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 9h:44m:37s remains)
INFO - root - 2017-12-01 07:23:24.785865: step 109520, loss = 0.33, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 9h:49m:51s remains)
INFO - root - 2017-12-01 07:23:26.363084: step 109530, loss = 0.33, batch loss = 0.22 (49.8 examples/sec; 0.161 sec/batch; 9h:56m:50s remains)
INFO - root - 2017-12-01 07:23:27.940416: step 109540, loss = 0.26, batch loss = 0.15 (50.2 examples/sec; 0.159 sec/batch; 9h:52m:07s remains)
INFO - root - 2017-12-01 07:23:29.488266: step 109550, loss = 0.30, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 9h:26m:20s remains)
INFO - root - 2017-12-01 07:23:31.057229: step 109560, loss = 0.37, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 9h:23m:40s remains)
INFO - root - 2017-12-01 07:23:32.680806: step 109570, loss = 0.39, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 9h:43m:27s remains)
INFO - root - 2017-12-01 07:23:34.236624: step 109580, loss = 0.35, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 9h:51m:24s remains)
INFO - root - 2017-12-01 07:23:35.809318: step 109590, loss = 0.33, batch loss = 0.21 (52.6 examples/sec; 0.152 sec/batch; 9h:24m:44s remains)
INFO - root - 2017-12-01 07:23:37.373385: step 109600, loss = 0.34, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 9h:32m:48s remains)
INFO - root - 2017-12-01 07:23:38.978762: step 109610, loss = 0.40, batch loss = 0.29 (50.1 examples/sec; 0.160 sec/batch; 9h:52m:47s remains)
INFO - root - 2017-12-01 07:23:40.553191: step 109620, loss = 0.26, batch loss = 0.15 (48.5 examples/sec; 0.165 sec/batch; 10h:12m:53s remains)
INFO - root - 2017-12-01 07:23:42.138546: step 109630, loss = 0.36, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 9h:46m:48s remains)
INFO - root - 2017-12-01 07:23:43.713852: step 109640, loss = 0.50, batch loss = 0.39 (51.8 examples/sec; 0.154 sec/batch; 9h:33m:21s remains)
INFO - root - 2017-12-01 07:23:45.281853: step 109650, loss = 0.29, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 9h:43m:20s remains)
INFO - root - 2017-12-01 07:23:46.824428: step 109660, loss = 0.37, batch loss = 0.26 (50.3 examples/sec; 0.159 sec/batch; 9h:50m:13s remains)
INFO - root - 2017-12-01 07:23:48.405202: step 109670, loss = 0.25, batch loss = 0.14 (50.6 examples/sec; 0.158 sec/batch; 9h:47m:15s remains)
INFO - root - 2017-12-01 07:23:49.965243: step 109680, loss = 0.29, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 9h:31m:02s remains)
INFO - root - 2017-12-01 07:23:51.529220: step 109690, loss = 0.29, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 9h:40m:43s remains)
INFO - root - 2017-12-01 07:23:53.083873: step 109700, loss = 0.30, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 9h:42m:17s remains)
INFO - root - 2017-12-01 07:23:54.728312: step 109710, loss = 0.33, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 9h:31m:01s remains)
INFO - root - 2017-12-01 07:23:56.302392: step 109720, loss = 0.31, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 9h:47m:48s remains)
INFO - root - 2017-12-01 07:23:57.848362: step 109730, loss = 0.29, batch loss = 0.18 (49.6 examples/sec; 0.161 sec/batch; 9h:58m:37s remains)
INFO - root - 2017-12-01 07:23:59.413352: step 109740, loss = 0.34, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 9h:50m:35s remains)
INFO - root - 2017-12-01 07:24:00.977938: step 109750, loss = 0.32, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 9h:39m:40s remains)
INFO - root - 2017-12-01 07:24:02.544865: step 109760, loss = 0.27, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 9h:43m:42s remains)
INFO - root - 2017-12-01 07:24:04.112331: step 109770, loss = 0.49, batch loss = 0.38 (51.4 examples/sec; 0.156 sec/batch; 9h:38m:09s remains)
INFO - root - 2017-12-01 07:24:05.670397: step 109780, loss = 0.44, batch loss = 0.33 (50.0 examples/sec; 0.160 sec/batch; 9h:53m:57s remains)
INFO - root - 2017-12-01 07:24:07.242974: step 109790, loss = 0.45, batch loss = 0.33 (49.2 examples/sec; 0.163 sec/batch; 10h:03m:23s remains)
INFO - root - 2017-12-01 07:24:08.846893: step 109800, loss = 0.30, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 9h:49m:13s remains)
INFO - root - 2017-12-01 07:24:10.486564: step 109810, loss = 0.32, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 9h:29m:45s remains)
INFO - root - 2017-12-01 07:24:12.055156: step 109820, loss = 0.27, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 9h:32m:35s remains)
INFO - root - 2017-12-01 07:24:13.660237: step 109830, loss = 0.36, batch loss = 0.25 (50.0 examples/sec; 0.160 sec/batch; 9h:53m:16s remains)
INFO - root - 2017-12-01 07:24:15.226605: step 109840, loss = 0.33, batch loss = 0.22 (53.4 examples/sec; 0.150 sec/batch; 9h:16m:07s remains)
INFO - root - 2017-12-01 07:24:16.816105: step 109850, loss = 0.29, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 9h:30m:51s remains)
INFO - root - 2017-12-01 07:24:18.380258: step 109860, loss = 0.45, batch loss = 0.34 (51.5 examples/sec; 0.155 sec/batch; 9h:36m:05s remains)
INFO - root - 2017-12-01 07:24:19.974307: step 109870, loss = 0.35, batch loss = 0.24 (49.6 examples/sec; 0.161 sec/batch; 9h:58m:11s remains)
INFO - root - 2017-12-01 07:24:21.564695: step 109880, loss = 0.38, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 9h:32m:54s remains)
INFO - root - 2017-12-01 07:24:23.136382: step 109890, loss = 0.33, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 9h:37m:03s remains)
INFO - root - 2017-12-01 07:24:24.700467: step 109900, loss = 0.27, batch loss = 0.16 (50.2 examples/sec; 0.159 sec/batch; 9h:50m:56s remains)
INFO - root - 2017-12-01 07:24:26.388644: step 109910, loss = 0.33, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 9h:53m:01s remains)
INFO - root - 2017-12-01 07:24:27.939259: step 109920, loss = 0.26, batch loss = 0.15 (50.9 examples/sec; 0.157 sec/batch; 9h:43m:15s remains)
INFO - root - 2017-12-01 07:24:29.505826: step 109930, loss = 0.38, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 9h:34m:33s remains)
INFO - root - 2017-12-01 07:24:31.070572: step 109940, loss = 0.26, batch loss = 0.15 (52.6 examples/sec; 0.152 sec/batch; 9h:24m:03s remains)
INFO - root - 2017-12-01 07:24:32.642258: step 109950, loss = 0.34, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 9h:34m:55s remains)
INFO - root - 2017-12-01 07:24:34.186561: step 109960, loss = 0.31, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 9h:35m:54s remains)
INFO - root - 2017-12-01 07:24:35.751513: step 109970, loss = 0.28, batch loss = 0.17 (49.9 examples/sec; 0.160 sec/batch; 9h:54m:12s remains)
INFO - root - 2017-12-01 07:24:37.311684: step 109980, loss = 0.32, batch loss = 0.20 (49.3 examples/sec; 0.162 sec/batch; 10h:01m:43s remains)
INFO - root - 2017-12-01 07:24:38.890853: step 109990, loss = 0.36, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 9h:32m:07s remains)
INFO - root - 2017-12-01 07:24:40.461981: step 110000, loss = 0.42, batch loss = 0.31 (51.7 examples/sec; 0.155 sec/batch; 9h:34m:05s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-110000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-110000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-01 07:24:42.405608: step 110010, loss = 0.36, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 9h:40m:45s remains)
INFO - root - 2017-12-01 07:24:43.946027: step 110020, loss = 0.39, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 9h:37m:19s remains)
INFO - root - 2017-12-01 07:24:45.499210: step 110030, loss = 0.39, batch loss = 0.28 (52.8 examples/sec; 0.151 sec/batch; 9h:21m:29s remains)
INFO - root - 2017-12-01 07:24:47.063723: step 110040, loss = 0.33, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 9h:39m:51s remains)
INFO - root - 2017-12-01 07:24:48.633265: step 110050, loss = 0.49, batch loss = 0.38 (50.8 examples/sec; 0.157 sec/batch; 9h:43m:41s remains)
INFO - root - 2017-12-01 07:24:50.191836: step 110060, loss = 0.31, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 9h:51m:17s remains)
INFO - root - 2017-12-01 07:24:51.752671: step 110070, loss = 0.37, batch loss = 0.25 (49.7 examples/sec; 0.161 sec/batch; 9h:56m:35s remains)
INFO - root - 2017-12-01 07:24:53.318128: step 110080, loss = 0.36, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 9h:34m:26s remains)
INFO - root - 2017-12-01 07:24:54.902530: step 110090, loss = 0.41, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 9h:42m:12s remains)
INFO - root - 2017-12-01 07:24:56.460061: step 110100, loss = 0.26, batch loss = 0.15 (50.7 examples/sec; 0.158 sec/batch; 9h:44m:25s remains)
INFO - root - 2017-12-01 07:24:58.063961: step 110110, loss = 0.36, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 9h:41m:59s remains)
INFO - root - 2017-12-01 07:24:59.628369: step 110120, loss = 0.32, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 9h:27m:05s remains)
INFO - root - 2017-12-01 07:25:01.192563: step 110130, loss = 0.31, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 9h:27m:59s remains)
INFO - root - 2017-12-01 07:25:02.764072: step 110140, loss = 0.33, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 9h:44m:59s remains)
INFO - root - 2017-12-01 07:25:04.331531: step 110150, loss = 0.38, batch loss = 0.27 (49.8 examples/sec; 0.161 sec/batch; 9h:55m:31s remains)
INFO - root - 2017-12-01 07:25:05.890506: step 110160, loss = 0.30, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 9h:23m:42s remains)
INFO - root - 2017-12-01 07:25:07.443091: step 110170, loss = 0.30, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 9h:26m:08s remains)
INFO - root - 2017-12-01 07:25:09.028493: step 110180, loss = 0.37, batch loss = 0.26 (50.8 examples/sec; 0.157 sec/batch; 9h:43m:23s remains)
INFO - root - 2017-12-01 07:25:10.593271: step 110190, loss = 0.43, batch loss = 0.31 (50.2 examples/sec; 0.160 sec/batch; 9h:51m:00s remains)
INFO - root - 2017-12-01 07:25:12.165403: step 110200, loss = 0.26, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 9h:38m:08s remains)
INFO - root - 2017-12-01 07:25:13.826252: step 110210, loss = 0.26, batch loss = 0.15 (50.6 examples/sec; 0.158 sec/batch; 9h:45m:19s remains)
INFO - root - 2017-12-01 07:25:15.392467: step 110220, loss = 0.38, batch loss = 0.27 (48.6 examples/sec; 0.164 sec/batch; 10h:09m:14s remains)
INFO - root - 2017-12-01 07:25:16.957144: step 110230, loss = 0.37, batch loss = 0.26 (52.9 examples/sec; 0.151 sec/batch; 9h:20m:41s remains)
INFO - root - 2017-12-01 07:25:18.521985: step 110240, loss = 0.33, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 9h:41m:11s remains)
INFO - root - 2017-12-01 07:25:20.098695: step 110250, loss = 0.31, batch loss = 0.20 (49.0 examples/sec; 0.163 sec/batch; 10h:04m:50s remains)
INFO - root - 2017-12-01 07:25:21.666086: step 110260, loss = 0.38, batch loss = 0.27 (49.9 examples/sec; 0.160 sec/batch; 9h:54m:01s remains)
INFO - root - 2017-12-01 07:25:23.231200: step 110270, loss = 0.46, batch loss = 0.35 (51.2 examples/sec; 0.156 sec/batch; 9h:38m:11s remains)
INFO - root - 2017-12-01 07:25:24.828124: step 110280, loss = 0.35, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 9h:34m:35s remains)
INFO - root - 2017-12-01 07:25:26.396112: step 110290, loss = 0.38, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 9h:46m:24s remains)
INFO - root - 2017-12-01 07:25:27.950305: step 110300, loss = 0.32, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 9h:50m:40s remains)
INFO - root - 2017-12-01 07:25:29.587161: step 110310, loss = 0.30, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 9h:27m:37s remains)
INFO - root - 2017-12-01 07:25:31.164617: step 110320, loss = 0.25, batch loss = 0.14 (50.4 examples/sec; 0.159 sec/batch; 9h:48m:21s remains)
INFO - root - 2017-12-01 07:25:32.729120: step 110330, loss = 0.26, batch loss = 0.15 (50.8 examples/sec; 0.157 sec/batch; 9h:43m:03s remains)
INFO - root - 2017-12-01 07:25:34.284974: step 110340, loss = 0.34, batch loss = 0.23 (52.8 examples/sec; 0.151 sec/batch; 9h:20m:47s remains)
INFO - root - 2017-12-01 07:25:35.853253: step 110350, loss = 0.33, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 9h:44m:53s remains)
INFO - root - 2017-12-01 07:25:37.414832: step 110360, loss = 0.31, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 9h:39m:09s remains)
INFO - root - 2017-12-01 07:25:38.975441: step 110370, loss = 0.58, batch loss = 0.46 (51.2 examples/sec; 0.156 sec/batch; 9h:38m:57s remains)
INFO - root - 2017-12-01 07:25:40.533523: step 110380, loss = 0.34, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 9h:43m:47s remains)
INFO - root - 2017-12-01 07:25:42.111609: step 110390, loss = 0.35, batch loss = 0.24 (49.7 examples/sec; 0.161 sec/batch; 9h:56m:27s remains)
INFO - root - 2017-12-01 07:25:43.670168: step 110400, loss = 0.40, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 9h:41m:35s remains)
INFO - root - 2017-12-01 07:25:45.276841: step 110410, loss = 0.35, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 9h:47m:07s remains)
INFO - root - 2017-12-01 07:25:46.845649: step 110420, loss = 0.27, batch loss = 0.16 (51.1 examples/sec; 0.156 sec/batch; 9h:39m:03s remains)
INFO - root - 2017-12-01 07:25:48.394113: step 110430, loss = 0.36, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 9h:34m:40s remains)
INFO - root - 2017-12-01 07:25:49.933201: step 110440, loss = 0.31, batch loss = 0.20 (53.7 examples/sec; 0.149 sec/batch; 9h:11m:05s remains)
INFO - root - 2017-12-01 07:25:51.482950: step 110450, loss = 0.40, batch loss = 0.29 (51.4 examples/sec; 0.156 sec/batch; 9h:36m:04s remains)
INFO - root - 2017-12-01 07:25:53.038184: step 110460, loss = 0.36, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 9h:31m:44s remains)
INFO - root - 2017-12-01 07:25:54.589479: step 110470, loss = 0.35, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 9h:29m:48s remains)
INFO - root - 2017-12-01 07:25:56.148123: step 110480, loss = 0.31, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 9h:45m:33s remains)
INFO - root - 2017-12-01 07:25:57.702401: step 110490, loss = 0.27, batch loss = 0.16 (52.6 examples/sec; 0.152 sec/batch; 9h:22m:50s remains)
INFO - root - 2017-12-01 07:25:59.288776: step 110500, loss = 0.30, batch loss = 0.19 (47.2 examples/sec; 0.170 sec/batch; 10h:27m:28s remains)
INFO - root - 2017-12-01 07:26:00.932379: step 110510, loss = 0.36, batch loss = 0.25 (49.5 examples/sec; 0.162 sec/batch; 9h:57m:49s remains)
INFO - root - 2017-12-01 07:26:02.506740: step 110520, loss = 0.31, batch loss = 0.20 (52.5 examples/sec; 0.152 sec/batch; 9h:24m:05s remains)
INFO - root - 2017-12-01 07:26:04.063003: step 110530, loss = 0.32, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 9h:38m:21s remains)
INFO - root - 2017-12-01 07:26:05.617992: step 110540, loss = 0.32, batch loss = 0.21 (52.8 examples/sec; 0.151 sec/batch; 9h:20m:17s remains)
INFO - root - 2017-12-01 07:26:07.175437: step 110550, loss = 0.34, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 9h:41m:47s remains)
INFO - root - 2017-12-01 07:26:08.757187: step 110560, loss = 0.32, batch loss = 0.21 (49.0 examples/sec; 0.163 sec/batch; 10h:04m:12s remains)
INFO - root - 2017-12-01 07:26:10.330798: step 110570, loss = 0.50, batch loss = 0.38 (52.7 examples/sec; 0.152 sec/batch; 9h:21m:46s remains)
INFO - root - 2017-12-01 07:26:11.904955: step 110580, loss = 0.29, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 9h:30m:36s remains)
INFO - root - 2017-12-01 07:26:13.469992: step 110590, loss = 0.26, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 9h:36m:27s remains)
INFO - root - 2017-12-01 07:26:15.038060: step 110600, loss = 0.42, batch loss = 0.31 (49.2 examples/sec; 0.163 sec/batch; 10h:01m:02s remains)
INFO - root - 2017-12-01 07:26:16.687669: step 110610, loss = 0.30, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 9h:43m:08s remains)
INFO - root - 2017-12-01 07:26:18.244601: step 110620, loss = 0.32, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 9h:50m:05s remains)
INFO - root - 2017-12-01 07:26:19.804432: step 110630, loss = 0.34, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 9h:35m:05s remains)
INFO - root - 2017-12-01 07:26:21.372213: step 110640, loss = 0.28, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 9h:34m:42s remains)
INFO - root - 2017-12-01 07:26:22.934011: step 110650, loss = 0.32, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 9h:28m:57s remains)
INFO - root - 2017-12-01 07:26:24.499389: step 110660, loss = 0.36, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 9h:38m:58s remains)
INFO - root - 2017-12-01 07:26:26.058581: step 110670, loss = 0.36, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 9h:47m:22s remains)
INFO - root - 2017-12-01 07:26:27.616950: step 110680, loss = 0.32, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 9h:43m:14s remains)
INFO - root - 2017-12-01 07:26:29.188968: step 110690, loss = 0.37, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 9h:31m:06s remains)
INFO - root - 2017-12-01 07:26:30.778925: step 110700, loss = 0.32, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 9h:45m:08s remains)
INFO - root - 2017-12-01 07:26:32.401029: step 110710, loss = 0.31, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 9h:35m:45s remains)
INFO - root - 2017-12-01 07:26:33.961849: step 110720, loss = 0.34, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 9h:47m:33s remains)
INFO - root - 2017-12-01 07:26:35.537526: step 110730, loss = 0.31, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 9h:39m:34s remains)
INFO - root - 2017-12-01 07:26:37.103371: step 110740, loss = 0.24, batch loss = 0.13 (51.1 examples/sec; 0.157 sec/batch; 9h:38m:47s remains)
INFO - root - 2017-12-01 07:26:38.673419: step 110750, loss = 0.42, batch loss = 0.31 (48.1 examples/sec; 0.166 sec/batch; 10h:14m:31s remains)
INFO - root - 2017-12-01 07:26:40.252740: step 110760, loss = 0.28, batch loss = 0.17 (52.4 examples/sec; 0.153 sec/batch; 9h:23m:57s remains)
INFO - root - 2017-12-01 07:26:41.814157: step 110770, loss = 0.29, batch loss = 0.18 (52.2 examples/sec; 0.153 sec/batch; 9h:26m:46s remains)
INFO - root - 2017-12-01 07:26:43.376375: step 110780, loss = 0.34, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 9h:36m:58s remains)
INFO - root - 2017-12-01 07:26:44.932766: step 110790, loss = 0.30, batch loss = 0.19 (49.4 examples/sec; 0.162 sec/batch; 9h:58m:54s remains)
INFO - root - 2017-12-01 07:26:46.483146: step 110800, loss = 0.38, batch loss = 0.27 (51.2 examples/sec; 0.156 sec/batch; 9h:37m:16s remains)
INFO - root - 2017-12-01 07:26:48.132061: step 110810, loss = 0.40, batch loss = 0.29 (51.8 examples/sec; 0.155 sec/batch; 9h:30m:54s remains)
INFO - root - 2017-12-01 07:26:49.695079: step 110820, loss = 0.30, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 9h:45m:52s remains)
INFO - root - 2017-12-01 07:26:51.253726: step 110830, loss = 0.27, batch loss = 0.16 (48.7 examples/sec; 0.164 sec/batch; 10h:06m:56s remains)
INFO - root - 2017-12-01 07:26:52.813230: step 110840, loss = 0.35, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 9h:34m:10s remains)
INFO - root - 2017-12-01 07:26:54.380847: step 110850, loss = 0.31, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 9h:31m:16s remains)
INFO - root - 2017-12-01 07:26:55.966470: step 110860, loss = 0.26, batch loss = 0.15 (50.2 examples/sec; 0.159 sec/batch; 9h:48m:25s remains)
INFO - root - 2017-12-01 07:26:57.536278: step 110870, loss = 0.32, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 9h:41m:05s remains)
INFO - root - 2017-12-01 07:26:59.130659: step 110880, loss = 0.25, batch loss = 0.14 (50.6 examples/sec; 0.158 sec/batch; 9h:44m:16s remains)
INFO - root - 2017-12-01 07:27:00.678232: step 110890, loss = 0.43, batch loss = 0.32 (50.2 examples/sec; 0.159 sec/batch; 9h:48m:13s remains)
INFO - root - 2017-12-01 07:27:02.257591: step 110900, loss = 0.31, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 9h:40m:44s remains)
INFO - root - 2017-12-01 07:27:03.882049: step 110910, loss = 0.35, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 9h:30m:32s remains)
INFO - root - 2017-12-01 07:27:05.470294: step 110920, loss = 0.31, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 9h:38m:27s remains)
INFO - root - 2017-12-01 07:27:07.054595: step 110930, loss = 0.40, batch loss = 0.29 (49.6 examples/sec; 0.161 sec/batch; 9h:55m:52s remains)
INFO - root - 2017-12-01 07:27:08.614697: step 110940, loss = 0.44, batch loss = 0.33 (52.1 examples/sec; 0.153 sec/batch; 9h:26m:37s remains)
INFO - root - 2017-12-01 07:27:10.191140: step 110950, loss = 0.34, batch loss = 0.23 (49.5 examples/sec; 0.162 sec/batch; 9h:56m:22s remains)
INFO - root - 2017-12-01 07:27:11.780487: step 110960, loss = 0.35, batch loss = 0.24 (48.2 examples/sec; 0.166 sec/batch; 10h:12m:29s remains)
INFO - root - 2017-12-01 07:27:13.359869: step 110970, loss = 0.33, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 9h:40m:30s remains)
INFO - root - 2017-12-01 07:27:14.931898: step 110980, loss = 0.40, batch loss = 0.29 (52.2 examples/sec; 0.153 sec/batch; 9h:26m:01s remains)
INFO - root - 2017-12-01 07:27:16.505672: step 110990, loss = 0.28, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 9h:37m:13s remains)
INFO - root - 2017-12-01 07:27:18.080686: step 111000, loss = 0.32, batch loss = 0.21 (49.2 examples/sec; 0.162 sec/batch; 9h:59m:45s remains)
INFO - root - 2017-12-01 07:27:19.717031: step 111010, loss = 0.34, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 9h:43m:41s remains)
INFO - root - 2017-12-01 07:27:21.306460: step 111020, loss = 0.38, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 9h:47m:26s remains)
INFO - root - 2017-12-01 07:27:22.858819: step 111030, loss = 0.46, batch loss = 0.35 (51.8 examples/sec; 0.154 sec/batch; 9h:30m:10s remains)
INFO - root - 2017-12-01 07:27:24.434567: step 111040, loss = 0.35, batch loss = 0.24 (48.8 examples/sec; 0.164 sec/batch; 10h:04m:59s remains)
INFO - root - 2017-12-01 07:27:26.010516: step 111050, loss = 0.33, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 9h:41m:39s remains)
INFO - root - 2017-12-01 07:27:27.572876: step 111060, loss = 0.35, batch loss = 0.24 (49.3 examples/sec; 0.162 sec/batch; 9h:58m:38s remains)
INFO - root - 2017-12-01 07:27:29.127030: step 111070, loss = 0.34, batch loss = 0.22 (49.2 examples/sec; 0.162 sec/batch; 9h:59m:29s remains)
INFO - root - 2017-12-01 07:27:30.692810: step 111080, loss = 0.39, batch loss = 0.28 (49.4 examples/sec; 0.162 sec/batch; 9h:58m:07s remains)
INFO - root - 2017-12-01 07:27:32.265869: step 111090, loss = 0.32, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 9h:32m:37s remains)
INFO - root - 2017-12-01 07:27:33.831646: step 111100, loss = 0.26, batch loss = 0.15 (52.0 examples/sec; 0.154 sec/batch; 9h:27m:51s remains)
INFO - root - 2017-12-01 07:27:35.448287: step 111110, loss = 0.35, batch loss = 0.24 (48.4 examples/sec; 0.165 sec/batch; 10h:09m:50s remains)
INFO - root - 2017-12-01 07:27:37.013539: step 111120, loss = 0.40, batch loss = 0.29 (53.7 examples/sec; 0.149 sec/batch; 9h:09m:23s remains)
INFO - root - 2017-12-01 07:27:38.569304: step 111130, loss = 0.29, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 9h:27m:05s remains)
INFO - root - 2017-12-01 07:27:40.125383: step 111140, loss = 0.38, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 9h:38m:38s remains)
INFO - root - 2017-12-01 07:27:41.706530: step 111150, loss = 0.36, batch loss = 0.25 (50.1 examples/sec; 0.160 sec/batch; 9h:49m:19s remains)
INFO - root - 2017-12-01 07:27:43.261352: step 111160, loss = 0.38, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 9h:31m:26s remains)
INFO - root - 2017-12-01 07:27:44.825564: step 111170, loss = 0.37, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 9h:19m:41s remains)
INFO - root - 2017-12-01 07:27:46.394621: step 111180, loss = 0.39, batch loss = 0.28 (50.3 examples/sec; 0.159 sec/batch; 9h:46m:10s remains)
INFO - root - 2017-12-01 07:27:47.967032: step 111190, loss = 0.28, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 9h:37m:57s remains)
INFO - root - 2017-12-01 07:27:49.528996: step 111200, loss = 0.31, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 9h:38m:06s remains)
INFO - root - 2017-12-01 07:27:51.204752: step 111210, loss = 0.31, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 9h:38m:06s remains)
INFO - root - 2017-12-01 07:27:52.751790: step 111220, loss = 0.30, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 9h:27m:04s remains)
INFO - root - 2017-12-01 07:27:54.302194: step 111230, loss = 0.47, batch loss = 0.36 (51.1 examples/sec; 0.157 sec/batch; 9h:37m:51s remains)
INFO - root - 2017-12-01 07:27:55.865942: step 111240, loss = 0.41, batch loss = 0.30 (52.0 examples/sec; 0.154 sec/batch; 9h:27m:47s remains)
INFO - root - 2017-12-01 07:27:57.436930: step 111250, loss = 0.40, batch loss = 0.29 (52.4 examples/sec; 0.153 sec/batch; 9h:22m:50s remains)
INFO - root - 2017-12-01 07:27:59.008878: step 111260, loss = 0.33, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 9h:48m:25s remains)
INFO - root - 2017-12-01 07:28:00.584725: step 111270, loss = 0.29, batch loss = 0.18 (49.4 examples/sec; 0.162 sec/batch; 9h:57m:33s remains)
INFO - root - 2017-12-01 07:28:02.168132: step 111280, loss = 0.27, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 9h:42m:06s remains)
INFO - root - 2017-12-01 07:28:03.759192: step 111290, loss = 0.31, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 9h:42m:17s remains)
INFO - root - 2017-12-01 07:28:05.317646: step 111300, loss = 0.33, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 9h:33m:54s remains)
INFO - root - 2017-12-01 07:28:06.958813: step 111310, loss = 0.34, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 9h:30m:59s remains)
INFO - root - 2017-12-01 07:28:08.525724: step 111320, loss = 0.31, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 9h:36m:58s remains)
INFO - root - 2017-12-01 07:28:10.100826: step 111330, loss = 0.35, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 9h:46m:18s remains)
INFO - root - 2017-12-01 07:28:11.647457: step 111340, loss = 0.30, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 9h:32m:33s remains)
INFO - root - 2017-12-01 07:28:13.236633: step 111350, loss = 0.33, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 9h:24m:14s remains)
INFO - root - 2017-12-01 07:28:14.794669: step 111360, loss = 0.28, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 9h:24m:50s remains)
INFO - root - 2017-12-01 07:28:16.356884: step 111370, loss = 0.35, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 9h:38m:15s remains)
INFO - root - 2017-12-01 07:28:17.921802: step 111380, loss = 0.31, batch loss = 0.20 (53.4 examples/sec; 0.150 sec/batch; 9h:12m:32s remains)
INFO - root - 2017-12-01 07:28:19.475001: step 111390, loss = 0.30, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 9h:22m:21s remains)
INFO - root - 2017-12-01 07:28:21.037774: step 111400, loss = 0.34, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 9h:43m:06s remains)
INFO - root - 2017-12-01 07:28:22.655177: step 111410, loss = 0.28, batch loss = 0.17 (51.1 examples/sec; 0.156 sec/batch; 9h:36m:29s remains)
INFO - root - 2017-12-01 07:28:24.223084: step 111420, loss = 0.26, batch loss = 0.15 (52.9 examples/sec; 0.151 sec/batch; 9h:16m:46s remains)
INFO - root - 2017-12-01 07:28:25.797994: step 111430, loss = 0.26, batch loss = 0.15 (51.4 examples/sec; 0.156 sec/batch; 9h:33m:18s remains)
INFO - root - 2017-12-01 07:28:27.358218: step 111440, loss = 0.62, batch loss = 0.51 (52.0 examples/sec; 0.154 sec/batch; 9h:26m:39s remains)
INFO - root - 2017-12-01 07:28:28.923646: step 111450, loss = 0.43, batch loss = 0.32 (50.9 examples/sec; 0.157 sec/batch; 9h:38m:31s remains)
INFO - root - 2017-12-01 07:28:30.482549: step 111460, loss = 0.32, batch loss = 0.21 (49.7 examples/sec; 0.161 sec/batch; 9h:53m:03s remains)
INFO - root - 2017-12-01 07:28:32.035110: step 111470, loss = 0.34, batch loss = 0.23 (49.4 examples/sec; 0.162 sec/batch; 9h:56m:18s remains)
INFO - root - 2017-12-01 07:28:33.602382: step 111480, loss = 0.41, batch loss = 0.30 (52.9 examples/sec; 0.151 sec/batch; 9h:17m:03s remains)
INFO - root - 2017-12-01 07:28:35.188556: step 111490, loss = 0.28, batch loss = 0.17 (50.8 examples/sec; 0.157 sec/batch; 9h:40m:00s remains)
INFO - root - 2017-12-01 07:28:36.739641: step 111500, loss = 0.32, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 9h:40m:01s remains)
INFO - root - 2017-12-01 07:28:38.376433: step 111510, loss = 0.40, batch loss = 0.29 (52.4 examples/sec; 0.153 sec/batch; 9h:22m:37s remains)
INFO - root - 2017-12-01 07:28:39.920955: step 111520, loss = 0.50, batch loss = 0.39 (51.8 examples/sec; 0.155 sec/batch; 9h:29m:16s remains)
INFO - root - 2017-12-01 07:28:41.505385: step 111530, loss = 0.35, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 9h:31m:05s remains)
INFO - root - 2017-12-01 07:28:43.059191: step 111540, loss = 0.28, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 9h:45m:24s remains)
INFO - root - 2017-12-01 07:28:44.628682: step 111550, loss = 0.28, batch loss = 0.17 (50.7 examples/sec; 0.158 sec/batch; 9h:41m:01s remains)
INFO - root - 2017-12-01 07:28:46.197832: step 111560, loss = 0.34, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 9h:33m:14s remains)
INFO - root - 2017-12-01 07:28:47.758007: step 111570, loss = 0.31, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 9h:40m:53s remains)
INFO - root - 2017-12-01 07:28:49.356665: step 111580, loss = 0.38, batch loss = 0.27 (51.1 examples/sec; 0.156 sec/batch; 9h:36m:06s remains)
INFO - root - 2017-12-01 07:28:50.904959: step 111590, loss = 0.30, batch loss = 0.19 (48.8 examples/sec; 0.164 sec/batch; 10h:03m:43s remains)
INFO - root - 2017-12-01 07:28:52.473893: step 111600, loss = 0.33, batch loss = 0.22 (52.9 examples/sec; 0.151 sec/batch; 9h:17m:08s remains)
INFO - root - 2017-12-01 07:28:54.108513: step 111610, loss = 0.31, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 9h:25m:18s remains)
INFO - root - 2017-12-01 07:28:55.654525: step 111620, loss = 0.31, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 9h:31m:57s remains)
INFO - root - 2017-12-01 07:28:57.222801: step 111630, loss = 0.33, batch loss = 0.22 (52.8 examples/sec; 0.152 sec/batch; 9h:17m:52s remains)
INFO - root - 2017-12-01 07:28:58.785881: step 111640, loss = 0.40, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 9h:38m:27s remains)
INFO - root - 2017-12-01 07:29:00.353732: step 111650, loss = 0.24, batch loss = 0.13 (51.4 examples/sec; 0.156 sec/batch; 9h:32m:29s remains)
INFO - root - 2017-12-01 07:29:01.911848: step 111660, loss = 0.45, batch loss = 0.34 (50.8 examples/sec; 0.158 sec/batch; 9h:39m:55s remains)
INFO - root - 2017-12-01 07:29:03.465859: step 111670, loss = 0.27, batch loss = 0.16 (48.3 examples/sec; 0.166 sec/batch; 10h:09m:42s remains)
INFO - root - 2017-12-01 07:29:05.025438: step 111680, loss = 0.38, batch loss = 0.27 (51.7 examples/sec; 0.155 sec/batch; 9h:28m:57s remains)
INFO - root - 2017-12-01 07:29:06.575931: step 111690, loss = 0.31, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 9h:30m:00s remains)
INFO - root - 2017-12-01 07:29:08.146938: step 111700, loss = 0.45, batch loss = 0.34 (51.4 examples/sec; 0.156 sec/batch; 9h:32m:59s remains)
INFO - root - 2017-12-01 07:29:09.791809: step 111710, loss = 0.33, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 9h:33m:01s remains)
INFO - root - 2017-12-01 07:29:11.366726: step 111720, loss = 0.31, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 9h:46m:13s remains)
INFO - root - 2017-12-01 07:29:12.942978: step 111730, loss = 0.34, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 9h:40m:57s remains)
INFO - root - 2017-12-01 07:29:14.528620: step 111740, loss = 0.31, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 9h:45m:22s remains)
INFO - root - 2017-12-01 07:29:16.076131: step 111750, loss = 0.27, batch loss = 0.16 (52.5 examples/sec; 0.152 sec/batch; 9h:20m:52s remains)
INFO - root - 2017-12-01 07:29:17.642805: step 111760, loss = 0.32, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 9h:27m:47s remains)
INFO - root - 2017-12-01 07:29:19.225059: step 111770, loss = 0.31, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 9h:49m:18s remains)
INFO - root - 2017-12-01 07:29:20.777448: step 111780, loss = 0.37, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 9h:38m:05s remains)
INFO - root - 2017-12-01 07:29:22.334096: step 111790, loss = 0.27, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 9h:31m:34s remains)
INFO - root - 2017-12-01 07:29:23.899456: step 111800, loss = 0.33, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 9h:47m:58s remains)
INFO - root - 2017-12-01 07:29:25.529740: step 111810, loss = 0.34, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 9h:31m:37s remains)
INFO - root - 2017-12-01 07:29:27.092151: step 111820, loss = 0.33, batch loss = 0.22 (49.7 examples/sec; 0.161 sec/batch; 9h:52m:06s remains)
INFO - root - 2017-12-01 07:29:28.653059: step 111830, loss = 0.41, batch loss = 0.30 (52.2 examples/sec; 0.153 sec/batch; 9h:23m:45s remains)
INFO - root - 2017-12-01 07:29:30.223451: step 111840, loss = 0.29, batch loss = 0.18 (52.6 examples/sec; 0.152 sec/batch; 9h:19m:24s remains)
INFO - root - 2017-12-01 07:29:31.802359: step 111850, loss = 0.25, batch loss = 0.14 (50.2 examples/sec; 0.159 sec/batch; 9h:46m:01s remains)
INFO - root - 2017-12-01 07:29:33.368592: step 111860, loss = 0.29, batch loss = 0.18 (50.1 examples/sec; 0.160 sec/batch; 9h:47m:12s remains)
INFO - root - 2017-12-01 07:29:34.935115: step 111870, loss = 0.27, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 9h:34m:49s remains)
INFO - root - 2017-12-01 07:29:36.502483: step 111880, loss = 0.30, batch loss = 0.19 (49.5 examples/sec; 0.161 sec/batch; 9h:53m:42s remains)
INFO - root - 2017-12-01 07:29:38.078336: step 111890, loss = 0.34, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 9h:29m:04s remains)
INFO - root - 2017-12-01 07:29:39.620929: step 111900, loss = 0.32, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 9h:33m:41s remains)
INFO - root - 2017-12-01 07:29:41.231706: step 111910, loss = 0.31, batch loss = 0.20 (49.6 examples/sec; 0.161 sec/batch; 9h:53m:25s remains)
INFO - root - 2017-12-01 07:29:42.810330: step 111920, loss = 0.40, batch loss = 0.30 (51.9 examples/sec; 0.154 sec/batch; 9h:27m:01s remains)
INFO - root - 2017-12-01 07:29:44.375341: step 111930, loss = 0.32, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 9h:29m:38s remains)
INFO - root - 2017-12-01 07:29:45.934206: step 111940, loss = 0.36, batch loss = 0.25 (48.9 examples/sec; 0.164 sec/batch; 10h:01m:54s remains)
INFO - root - 2017-12-01 07:29:47.496014: step 111950, loss = 0.38, batch loss = 0.27 (49.2 examples/sec; 0.162 sec/batch; 9h:57m:16s remains)
INFO - root - 2017-12-01 07:29:49.060462: step 111960, loss = 0.29, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 9h:31m:44s remains)
INFO - root - 2017-12-01 07:29:50.641578: step 111970, loss = 0.30, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 9h:21m:50s remains)
INFO - root - 2017-12-01 07:29:52.198143: step 111980, loss = 0.32, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 9h:38m:14s remains)
INFO - root - 2017-12-01 07:29:53.767127: step 111990, loss = 0.28, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 9h:44m:16s remains)
INFO - root - 2017-12-01 07:29:55.322082: step 112000, loss = 0.33, batch loss = 0.22 (49.8 examples/sec; 0.161 sec/batch; 9h:50m:26s remains)
INFO - root - 2017-12-01 07:29:56.930125: step 112010, loss = 0.31, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 9h:27m:44s remains)
INFO - root - 2017-12-01 07:29:58.483745: step 112020, loss = 0.29, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 9h:37m:41s remains)
INFO - root - 2017-12-01 07:30:00.056406: step 112030, loss = 0.42, batch loss = 0.31 (49.6 examples/sec; 0.161 sec/batch; 9h:53m:10s remains)
INFO - root - 2017-12-01 07:30:01.622921: step 112040, loss = 0.40, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 9h:34m:01s remains)
INFO - root - 2017-12-01 07:30:03.189645: step 112050, loss = 0.27, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 9h:29m:35s remains)
INFO - root - 2017-12-01 07:30:04.750323: step 112060, loss = 0.38, batch loss = 0.27 (51.7 examples/sec; 0.155 sec/batch; 9h:28m:02s remains)
INFO - root - 2017-12-01 07:30:06.322305: step 112070, loss = 0.38, batch loss = 0.27 (46.2 examples/sec; 0.173 sec/batch; 10h:35m:42s remains)
INFO - root - 2017-12-01 07:30:08.024202: step 112080, loss = 0.32, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 9h:41m:51s remains)
INFO - root - 2017-12-01 07:30:09.600744: step 112090, loss = 0.30, batch loss = 0.19 (50.2 examples/sec; 0.159 sec/batch; 9h:45m:40s remains)
INFO - root - 2017-12-01 07:30:11.160282: step 112100, loss = 0.36, batch loss = 0.25 (49.8 examples/sec; 0.161 sec/batch; 9h:50m:04s remains)
INFO - root - 2017-12-01 07:30:12.826390: step 112110, loss = 0.39, batch loss = 0.28 (49.4 examples/sec; 0.162 sec/batch; 9h:54m:21s remains)
INFO - root - 2017-12-01 07:30:14.418844: step 112120, loss = 0.27, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 9h:29m:21s remains)
INFO - root - 2017-12-01 07:30:15.984175: step 112130, loss = 0.36, batch loss = 0.25 (49.9 examples/sec; 0.160 sec/batch; 9h:48m:58s remains)
INFO - root - 2017-12-01 07:30:17.539131: step 112140, loss = 0.32, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 9h:33m:43s remains)
INFO - root - 2017-12-01 07:30:19.096999: step 112150, loss = 0.27, batch loss = 0.16 (51.8 examples/sec; 0.155 sec/batch; 9h:27m:27s remains)
INFO - root - 2017-12-01 07:30:20.667485: step 112160, loss = 0.37, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 9h:30m:33s remains)
INFO - root - 2017-12-01 07:30:22.247121: step 112170, loss = 0.59, batch loss = 0.48 (48.9 examples/sec; 0.164 sec/batch; 10h:00m:38s remains)
INFO - root - 2017-12-01 07:30:23.802165: step 112180, loss = 0.35, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 9h:44m:08s remains)
INFO - root - 2017-12-01 07:30:25.379447: step 112190, loss = 0.31, batch loss = 0.21 (49.4 examples/sec; 0.162 sec/batch; 9h:54m:42s remains)
INFO - root - 2017-12-01 07:30:26.934038: step 112200, loss = 0.25, batch loss = 0.14 (52.4 examples/sec; 0.153 sec/batch; 9h:20m:27s remains)
INFO - root - 2017-12-01 07:30:28.566931: step 112210, loss = 0.32, batch loss = 0.21 (53.1 examples/sec; 0.151 sec/batch; 9h:12m:57s remains)
INFO - root - 2017-12-01 07:30:30.127466: step 112220, loss = 0.27, batch loss = 0.16 (51.7 examples/sec; 0.155 sec/batch; 9h:28m:00s remains)
INFO - root - 2017-12-01 07:30:31.689826: step 112230, loss = 0.43, batch loss = 0.32 (51.0 examples/sec; 0.157 sec/batch; 9h:36m:20s remains)
INFO - root - 2017-12-01 07:30:33.233902: step 112240, loss = 0.25, batch loss = 0.14 (50.4 examples/sec; 0.159 sec/batch; 9h:42m:43s remains)
INFO - root - 2017-12-01 07:30:34.785288: step 112250, loss = 0.31, batch loss = 0.20 (53.1 examples/sec; 0.151 sec/batch; 9h:13m:18s remains)
INFO - root - 2017-12-01 07:30:36.349419: step 112260, loss = 0.33, batch loss = 0.22 (52.8 examples/sec; 0.152 sec/batch; 9h:16m:22s remains)
INFO - root - 2017-12-01 07:30:37.894885: step 112270, loss = 0.34, batch loss = 0.23 (51.8 examples/sec; 0.155 sec/batch; 9h:27m:10s remains)
INFO - root - 2017-12-01 07:30:39.455180: step 112280, loss = 0.31, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 9h:37m:09s remains)
INFO - root - 2017-12-01 07:30:41.055285: step 112290, loss = 0.26, batch loss = 0.15 (50.0 examples/sec; 0.160 sec/batch; 9h:47m:45s remains)
INFO - root - 2017-12-01 07:30:42.625575: step 112300, loss = 0.36, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 9h:28m:26s remains)
INFO - root - 2017-12-01 07:30:44.261997: step 112310, loss = 0.47, batch loss = 0.36 (49.4 examples/sec; 0.162 sec/batch; 9h:54m:50s remains)
INFO - root - 2017-12-01 07:30:45.822664: step 112320, loss = 0.33, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 9h:31m:03s remains)
INFO - root - 2017-12-01 07:30:47.387365: step 112330, loss = 0.35, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 9h:27m:42s remains)
INFO - root - 2017-12-01 07:30:48.986570: step 112340, loss = 0.30, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 9h:38m:13s remains)
INFO - root - 2017-12-01 07:30:50.541133: step 112350, loss = 0.32, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 9h:40m:14s remains)
INFO - root - 2017-12-01 07:30:52.094372: step 112360, loss = 0.44, batch loss = 0.33 (52.0 examples/sec; 0.154 sec/batch; 9h:24m:24s remains)
INFO - root - 2017-12-01 07:30:53.666408: step 112370, loss = 0.36, batch loss = 0.25 (50.8 examples/sec; 0.157 sec/batch; 9h:37m:46s remains)
INFO - root - 2017-12-01 07:30:55.224094: step 112380, loss = 0.34, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 9h:19m:52s remains)
INFO - root - 2017-12-01 07:30:56.780964: step 112390, loss = 0.28, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 9h:36m:54s remains)
INFO - root - 2017-12-01 07:30:58.346018: step 112400, loss = 0.38, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 9h:39m:35s remains)
INFO - root - 2017-12-01 07:31:00.011959: step 112410, loss = 0.28, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 9h:27m:05s remains)
INFO - root - 2017-12-01 07:31:01.587407: step 112420, loss = 0.32, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 9h:33m:35s remains)
INFO - root - 2017-12-01 07:31:03.144884: step 112430, loss = 0.31, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 9h:32m:28s remains)
INFO - root - 2017-12-01 07:31:04.710147: step 112440, loss = 0.27, batch loss = 0.16 (52.4 examples/sec; 0.153 sec/batch; 9h:20m:08s remains)
INFO - root - 2017-12-01 07:31:06.285341: step 112450, loss = 0.28, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 9h:36m:50s remains)
INFO - root - 2017-12-01 07:31:07.850204: step 112460, loss = 0.36, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 9h:41m:40s remains)
INFO - root - 2017-12-01 07:31:09.414423: step 112470, loss = 0.32, batch loss = 0.21 (50.0 examples/sec; 0.160 sec/batch; 9h:46m:39s remains)
INFO - root - 2017-12-01 07:31:10.995233: step 112480, loss = 0.30, batch loss = 0.19 (48.6 examples/sec; 0.165 sec/batch; 10h:03m:20s remains)
INFO - root - 2017-12-01 07:31:12.596393: step 112490, loss = 0.35, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 9h:33m:28s remains)
INFO - root - 2017-12-01 07:31:14.172721: step 112500, loss = 0.26, batch loss = 0.15 (50.0 examples/sec; 0.160 sec/batch; 9h:46m:21s remains)
INFO - root - 2017-12-01 07:31:15.802957: step 112510, loss = 0.38, batch loss = 0.27 (52.4 examples/sec; 0.153 sec/batch; 9h:20m:00s remains)
INFO - root - 2017-12-01 07:31:17.364549: step 112520, loss = 0.49, batch loss = 0.38 (51.3 examples/sec; 0.156 sec/batch; 9h:31m:35s remains)
INFO - root - 2017-12-01 07:31:18.946049: step 112530, loss = 0.37, batch loss = 0.26 (49.2 examples/sec; 0.162 sec/batch; 9h:55m:33s remains)
INFO - root - 2017-12-01 07:31:20.502705: step 112540, loss = 0.33, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 9h:32m:32s remains)
INFO - root - 2017-12-01 07:31:22.053562: step 112550, loss = 0.28, batch loss = 0.17 (50.8 examples/sec; 0.158 sec/batch; 9h:37m:45s remains)
INFO - root - 2017-12-01 07:31:23.636698: step 112560, loss = 0.29, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 9h:25m:44s remains)
INFO - root - 2017-12-01 07:31:25.199858: step 112570, loss = 0.28, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 9h:41m:56s remains)
INFO - root - 2017-12-01 07:31:26.785870: step 112580, loss = 0.36, batch loss = 0.25 (49.3 examples/sec; 0.162 sec/batch; 9h:54m:14s remains)
INFO - root - 2017-12-01 07:31:28.345984: step 112590, loss = 0.31, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 9h:25m:16s remains)
INFO - root - 2017-12-01 07:31:29.916746: step 112600, loss = 0.28, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 9h:24m:33s remains)
INFO - root - 2017-12-01 07:31:31.549859: step 112610, loss = 0.29, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 9h:24m:36s remains)
INFO - root - 2017-12-01 07:31:33.116423: step 112620, loss = 0.32, batch loss = 0.21 (53.6 examples/sec; 0.149 sec/batch; 9h:07m:11s remains)
INFO - root - 2017-12-01 07:31:34.700029: step 112630, loss = 0.44, batch loss = 0.33 (52.0 examples/sec; 0.154 sec/batch; 9h:23m:57s remains)
INFO - root - 2017-12-01 07:31:36.261958: step 112640, loss = 0.33, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 9h:46m:48s remains)
INFO - root - 2017-12-01 07:31:37.820765: step 112650, loss = 0.38, batch loss = 0.27 (49.8 examples/sec; 0.161 sec/batch; 9h:49m:06s remains)
INFO - root - 2017-12-01 07:31:39.373988: step 112660, loss = 0.41, batch loss = 0.31 (49.5 examples/sec; 0.162 sec/batch; 9h:52m:06s remains)
INFO - root - 2017-12-01 07:31:40.969015: step 112670, loss = 0.32, batch loss = 0.21 (50.0 examples/sec; 0.160 sec/batch; 9h:46m:19s remains)
INFO - root - 2017-12-01 07:31:42.546565: step 112680, loss = 0.25, batch loss = 0.14 (51.4 examples/sec; 0.156 sec/batch; 9h:30m:17s remains)
INFO - root - 2017-12-01 07:31:44.127957: step 112690, loss = 0.33, batch loss = 0.22 (48.0 examples/sec; 0.167 sec/batch; 10h:10m:46s remains)
INFO - root - 2017-12-01 07:31:45.720912: step 112700, loss = 0.36, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 9h:26m:46s remains)
INFO - root - 2017-12-01 07:31:47.337853: step 112710, loss = 0.32, batch loss = 0.21 (53.0 examples/sec; 0.151 sec/batch; 9h:13m:15s remains)
INFO - root - 2017-12-01 07:31:48.915748: step 112720, loss = 0.34, batch loss = 0.23 (48.1 examples/sec; 0.166 sec/batch; 10h:09m:33s remains)
INFO - root - 2017-12-01 07:31:50.507297: step 112730, loss = 0.28, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 9h:26m:17s remains)
INFO - root - 2017-12-01 07:31:52.069307: step 112740, loss = 0.33, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 9h:38m:12s remains)
INFO - root - 2017-12-01 07:31:53.647157: step 112750, loss = 0.29, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 9h:38m:18s remains)
INFO - root - 2017-12-01 07:31:55.190447: step 112760, loss = 0.47, batch loss = 0.36 (50.3 examples/sec; 0.159 sec/batch; 9h:43m:00s remains)
INFO - root - 2017-12-01 07:31:56.749442: step 112770, loss = 0.32, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 9h:36m:20s remains)
INFO - root - 2017-12-01 07:31:58.320467: step 112780, loss = 0.28, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 9h:28m:52s remains)
INFO - root - 2017-12-01 07:31:59.882254: step 112790, loss = 0.38, batch loss = 0.28 (49.5 examples/sec; 0.162 sec/batch; 9h:52m:16s remains)
INFO - root - 2017-12-01 07:32:01.448628: step 112800, loss = 0.31, batch loss = 0.20 (49.3 examples/sec; 0.162 sec/batch; 9h:54m:17s remains)
INFO - root - 2017-12-01 07:32:03.096961: step 112810, loss = 0.27, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 9h:41m:01s remains)
INFO - root - 2017-12-01 07:32:04.662751: step 112820, loss = 0.45, batch loss = 0.34 (50.2 examples/sec; 0.159 sec/batch; 9h:43m:42s remains)
INFO - root - 2017-12-01 07:32:06.254798: step 112830, loss = 0.34, batch loss = 0.24 (42.9 examples/sec; 0.187 sec/batch; 11h:23m:19s remains)
INFO - root - 2017-12-01 07:32:07.817863: step 112840, loss = 0.29, batch loss = 0.18 (52.5 examples/sec; 0.152 sec/batch; 9h:18m:02s remains)
INFO - root - 2017-12-01 07:32:09.401455: step 112850, loss = 0.29, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 9h:36m:39s remains)
INFO - root - 2017-12-01 07:32:10.981268: step 112860, loss = 0.43, batch loss = 0.32 (50.8 examples/sec; 0.158 sec/batch; 9h:36m:46s remains)
INFO - root - 2017-12-01 07:32:12.534148: step 112870, loss = 0.51, batch loss = 0.40 (52.3 examples/sec; 0.153 sec/batch; 9h:20m:26s remains)
INFO - root - 2017-12-01 07:32:14.125223: step 112880, loss = 0.29, batch loss = 0.18 (45.2 examples/sec; 0.177 sec/batch; 10h:47m:18s remains)
INFO - root - 2017-12-01 07:32:15.700165: step 112890, loss = 0.25, batch loss = 0.14 (49.0 examples/sec; 0.163 sec/batch; 9h:57m:01s remains)
INFO - root - 2017-12-01 07:32:17.253593: step 112900, loss = 0.33, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 9h:24m:31s remains)
INFO - root - 2017-12-01 07:32:18.907254: step 112910, loss = 0.27, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 9h:34m:59s remains)
INFO - root - 2017-12-01 07:32:20.474306: step 112920, loss = 0.29, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 9h:39m:34s remains)
INFO - root - 2017-12-01 07:32:22.029692: step 112930, loss = 0.30, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 9h:22m:34s remains)
INFO - root - 2017-12-01 07:32:23.592228: step 112940, loss = 0.49, batch loss = 0.38 (52.9 examples/sec; 0.151 sec/batch; 9h:13m:14s remains)
INFO - root - 2017-12-01 07:32:25.167380: step 112950, loss = 0.30, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 9h:22m:35s remains)
INFO - root - 2017-12-01 07:32:26.733474: step 112960, loss = 0.30, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 9h:24m:42s remains)
INFO - root - 2017-12-01 07:32:28.295786: step 112970, loss = 0.36, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 9h:39m:06s remains)
INFO - root - 2017-12-01 07:32:29.861736: step 112980, loss = 0.50, batch loss = 0.39 (52.7 examples/sec; 0.152 sec/batch; 9h:15m:18s remains)
INFO - root - 2017-12-01 07:32:31.436704: step 112990, loss = 0.31, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 9h:45m:51s remains)
INFO - root - 2017-12-01 07:32:33.002716: step 113000, loss = 0.26, batch loss = 0.15 (50.9 examples/sec; 0.157 sec/batch; 9h:34m:59s remains)
INFO - root - 2017-12-01 07:32:34.682907: step 113010, loss = 0.32, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 9h:33m:30s remains)
INFO - root - 2017-12-01 07:32:36.246329: step 113020, loss = 0.31, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 9h:46m:09s remains)
INFO - root - 2017-12-01 07:32:37.806553: step 113030, loss = 0.35, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 9h:31m:00s remains)
INFO - root - 2017-12-01 07:32:39.367097: step 113040, loss = 0.30, batch loss = 0.19 (50.2 examples/sec; 0.160 sec/batch; 9h:43m:27s remains)
INFO - root - 2017-12-01 07:32:40.930366: step 113050, loss = 0.29, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 9h:33m:34s remains)
INFO - root - 2017-12-01 07:32:42.500201: step 113060, loss = 0.25, batch loss = 0.15 (51.0 examples/sec; 0.157 sec/batch; 9h:33m:29s remains)
INFO - root - 2017-12-01 07:32:44.064961: step 113070, loss = 0.31, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 9h:24m:15s remains)
INFO - root - 2017-12-01 07:32:45.647956: step 113080, loss = 0.32, batch loss = 0.21 (49.6 examples/sec; 0.161 sec/batch; 9h:50m:20s remains)
INFO - root - 2017-12-01 07:32:47.210666: step 113090, loss = 0.33, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 9h:15m:44s remains)
INFO - root - 2017-12-01 07:32:48.788803: step 113100, loss = 0.26, batch loss = 0.15 (52.3 examples/sec; 0.153 sec/batch; 9h:19m:46s remains)
INFO - root - 2017-12-01 07:32:50.402123: step 113110, loss = 0.29, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 9h:26m:20s remains)
INFO - root - 2017-12-01 07:32:51.953233: step 113120, loss = 0.32, batch loss = 0.21 (52.6 examples/sec; 0.152 sec/batch; 9h:15m:49s remains)
INFO - root - 2017-12-01 07:32:53.526532: step 113130, loss = 0.26, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 9h:28m:44s remains)
INFO - root - 2017-12-01 07:32:55.094291: step 113140, loss = 0.23, batch loss = 0.12 (51.0 examples/sec; 0.157 sec/batch; 9h:33m:52s remains)
INFO - root - 2017-12-01 07:32:56.676115: step 113150, loss = 0.28, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 9h:41m:06s remains)
INFO - root - 2017-12-01 07:32:58.231289: step 113160, loss = 0.28, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 9h:25m:59s remains)
INFO - root - 2017-12-01 07:32:59.782751: step 113170, loss = 0.35, batch loss = 0.25 (52.8 examples/sec; 0.151 sec/batch; 9h:13m:35s remains)
INFO - root - 2017-12-01 07:33:01.358597: step 113180, loss = 0.37, batch loss = 0.26 (49.5 examples/sec; 0.162 sec/batch; 9h:50m:39s remains)
INFO - root - 2017-12-01 07:33:02.922343: step 113190, loss = 0.35, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 9h:34m:58s remains)
INFO - root - 2017-12-01 07:33:04.475840: step 113200, loss = 0.34, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 9h:34m:12s remains)
INFO - root - 2017-12-01 07:33:06.097454: step 113210, loss = 0.42, batch loss = 0.31 (51.4 examples/sec; 0.156 sec/batch; 9h:29m:13s remains)
INFO - root - 2017-12-01 07:33:07.661378: step 113220, loss = 0.30, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 9h:24m:06s remains)
INFO - root - 2017-12-01 07:33:09.221106: step 113230, loss = 0.32, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 9h:23m:06s remains)
INFO - root - 2017-12-01 07:33:10.781961: step 113240, loss = 0.40, batch loss = 0.29 (49.0 examples/sec; 0.163 sec/batch; 9h:56m:50s remains)
INFO - root - 2017-12-01 07:33:12.340416: step 113250, loss = 0.29, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 9h:26m:13s remains)
INFO - root - 2017-12-01 07:33:13.920228: step 113260, loss = 0.56, batch loss = 0.46 (47.6 examples/sec; 0.168 sec/batch; 10h:13m:35s remains)
INFO - root - 2017-12-01 07:33:15.463373: step 113270, loss = 0.28, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 9h:20m:05s remains)
INFO - root - 2017-12-01 07:33:17.041698: step 113280, loss = 0.28, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 9h:37m:51s remains)
INFO - root - 2017-12-01 07:33:18.624435: step 113290, loss = 0.36, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 9h:30m:39s remains)
INFO - root - 2017-12-01 07:33:20.185188: step 113300, loss = 0.33, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 9h:21m:19s remains)
INFO - root - 2017-12-01 07:33:21.819581: step 113310, loss = 0.43, batch loss = 0.32 (50.0 examples/sec; 0.160 sec/batch; 9h:44m:26s remains)
INFO - root - 2017-12-01 07:33:23.391677: step 113320, loss = 0.37, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 9h:39m:44s remains)
INFO - root - 2017-12-01 07:33:24.967308: step 113330, loss = 0.33, batch loss = 0.22 (52.4 examples/sec; 0.153 sec/batch; 9h:17m:45s remains)
INFO - root - 2017-12-01 07:33:26.524224: step 113340, loss = 0.48, batch loss = 0.38 (52.7 examples/sec; 0.152 sec/batch; 9h:14m:30s remains)
INFO - root - 2017-12-01 07:33:28.079242: step 113350, loss = 0.34, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 9h:25m:46s remains)
INFO - root - 2017-12-01 07:33:29.636711: step 113360, loss = 0.31, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 9h:26m:11s remains)
INFO - root - 2017-12-01 07:33:31.206001: step 113370, loss = 0.29, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 9h:39m:20s remains)
INFO - root - 2017-12-01 07:33:32.765936: step 113380, loss = 0.32, batch loss = 0.22 (52.8 examples/sec; 0.151 sec/batch; 9h:13m:11s remains)
INFO - root - 2017-12-01 07:33:34.337952: step 113390, loss = 0.28, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 9h:42m:19s remains)
INFO - root - 2017-12-01 07:33:35.912763: step 113400, loss = 0.27, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 9h:26m:30s remains)
INFO - root - 2017-12-01 07:33:37.517797: step 113410, loss = 0.35, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 9h:31m:32s remains)
INFO - root - 2017-12-01 07:33:39.082895: step 113420, loss = 0.31, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 9h:27m:30s remains)
INFO - root - 2017-12-01 07:33:40.653774: step 113430, loss = 0.32, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 9h:38m:30s remains)
INFO - root - 2017-12-01 07:33:42.221088: step 113440, loss = 0.35, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 9h:22m:25s remains)
INFO - root - 2017-12-01 07:33:43.775553: step 113450, loss = 0.26, batch loss = 0.15 (49.7 examples/sec; 0.161 sec/batch; 9h:48m:07s remains)
INFO - root - 2017-12-01 07:33:45.343961: step 113460, loss = 0.28, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 9h:28m:14s remains)
INFO - root - 2017-12-01 07:33:46.920542: step 113470, loss = 0.36, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 9h:31m:57s remains)
INFO - root - 2017-12-01 07:33:48.477799: step 113480, loss = 0.32, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 9h:28m:10s remains)
INFO - root - 2017-12-01 07:33:50.044103: step 113490, loss = 0.28, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 9h:30m:06s remains)
INFO - root - 2017-12-01 07:33:51.607389: step 113500, loss = 0.35, batch loss = 0.24 (49.1 examples/sec; 0.163 sec/batch; 9h:54m:26s remains)
INFO - root - 2017-12-01 07:33:53.214370: step 113510, loss = 0.29, batch loss = 0.18 (52.4 examples/sec; 0.153 sec/batch; 9h:17m:02s remains)
INFO - root - 2017-12-01 07:33:54.795870: step 113520, loss = 0.31, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 9h:26m:51s remains)
INFO - root - 2017-12-01 07:33:56.372620: step 113530, loss = 0.30, batch loss = 0.19 (49.4 examples/sec; 0.162 sec/batch; 9h:51m:17s remains)
INFO - root - 2017-12-01 07:33:57.937382: step 113540, loss = 0.31, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 9h:29m:14s remains)
INFO - root - 2017-12-01 07:33:59.524861: step 113550, loss = 0.47, batch loss = 0.36 (51.1 examples/sec; 0.157 sec/batch; 9h:31m:21s remains)
INFO - root - 2017-12-01 07:34:01.085055: step 113560, loss = 0.30, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 9h:35m:24s remains)
INFO - root - 2017-12-01 07:34:02.648160: step 113570, loss = 0.36, batch loss = 0.26 (50.2 examples/sec; 0.159 sec/batch; 9h:41m:28s remains)
INFO - root - 2017-12-01 07:34:04.211975: step 113580, loss = 0.30, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 9h:24m:20s remains)
INFO - root - 2017-12-01 07:34:05.791623: step 113590, loss = 0.39, batch loss = 0.29 (52.2 examples/sec; 0.153 sec/batch; 9h:18m:59s remains)
INFO - root - 2017-12-01 07:34:07.353687: step 113600, loss = 0.40, batch loss = 0.30 (51.7 examples/sec; 0.155 sec/batch; 9h:24m:28s remains)
INFO - root - 2017-12-01 07:34:08.968472: step 113610, loss = 0.27, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 9h:35m:44s remains)
INFO - root - 2017-12-01 07:34:10.559744: step 113620, loss = 0.28, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 9h:39m:40s remains)
INFO - root - 2017-12-01 07:34:12.136269: step 113630, loss = 0.29, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 9h:31m:36s remains)
INFO - root - 2017-12-01 07:34:13.698943: step 113640, loss = 0.33, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 9h:23m:04s remains)
INFO - root - 2017-12-01 07:34:15.269322: step 113650, loss = 0.36, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 9h:29m:31s remains)
INFO - root - 2017-12-01 07:34:16.833506: step 113660, loss = 0.42, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 9h:32m:56s remains)
INFO - root - 2017-12-01 07:34:18.400725: step 113670, loss = 0.29, batch loss = 0.19 (49.7 examples/sec; 0.161 sec/batch; 9h:47m:16s remains)
INFO - root - 2017-12-01 07:34:19.968383: step 113680, loss = 0.28, batch loss = 0.17 (49.7 examples/sec; 0.161 sec/batch; 9h:47m:21s remains)
INFO - root - 2017-12-01 07:34:21.530393: step 113690, loss = 0.32, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 9h:35m:06s remains)
INFO - root - 2017-12-01 07:34:23.130530: step 113700, loss = 0.40, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 9h:26m:24s remains)
INFO - root - 2017-12-01 07:34:24.759011: step 113710, loss = 0.26, batch loss = 0.15 (51.6 examples/sec; 0.155 sec/batch; 9h:25m:52s remains)
INFO - root - 2017-12-01 07:34:26.318587: step 113720, loss = 0.34, batch loss = 0.23 (52.5 examples/sec; 0.152 sec/batch; 9h:16m:02s remains)
INFO - root - 2017-12-01 07:34:27.886918: step 113730, loss = 0.41, batch loss = 0.30 (50.8 examples/sec; 0.158 sec/batch; 9h:34m:26s remains)
INFO - root - 2017-12-01 07:34:29.428324: step 113740, loss = 0.33, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 9h:18m:31s remains)
INFO - root - 2017-12-01 07:34:30.999204: step 113750, loss = 0.29, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 9h:29m:53s remains)
INFO - root - 2017-12-01 07:34:32.545226: step 113760, loss = 0.38, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 9h:28m:55s remains)
INFO - root - 2017-12-01 07:34:34.090244: step 113770, loss = 0.34, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 9h:21m:27s remains)
INFO - root - 2017-12-01 07:34:35.652548: step 113780, loss = 0.35, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 9h:22m:30s remains)
INFO - root - 2017-12-01 07:34:37.216875: step 113790, loss = 0.40, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 9h:25m:26s remains)
INFO - root - 2017-12-01 07:34:38.779292: step 113800, loss = 0.37, batch loss = 0.26 (52.3 examples/sec; 0.153 sec/batch; 9h:17m:05s remains)
INFO - root - 2017-12-01 07:34:40.430663: step 113810, loss = 0.32, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 9h:17m:06s remains)
INFO - root - 2017-12-01 07:34:42.015235: step 113820, loss = 0.34, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 9h:29m:05s remains)
INFO - root - 2017-12-01 07:34:43.580125: step 113830, loss = 0.36, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 9h:36m:19s remains)
INFO - root - 2017-12-01 07:34:45.140028: step 113840, loss = 0.34, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 9h:24m:28s remains)
INFO - root - 2017-12-01 07:34:46.710977: step 113850, loss = 0.27, batch loss = 0.16 (49.0 examples/sec; 0.163 sec/batch; 9h:54m:24s remains)
INFO - root - 2017-12-01 07:34:48.280043: step 113860, loss = 0.36, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 9h:26m:22s remains)
INFO - root - 2017-12-01 07:34:49.851419: step 113870, loss = 0.29, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 9h:33m:41s remains)
INFO - root - 2017-12-01 07:34:51.428687: step 113880, loss = 0.29, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 9h:39m:42s remains)
INFO - root - 2017-12-01 07:34:52.990507: step 113890, loss = 0.37, batch loss = 0.26 (50.3 examples/sec; 0.159 sec/batch; 9h:39m:13s remains)
INFO - root - 2017-12-01 07:34:54.542695: step 113900, loss = 0.33, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 9h:20m:13s remains)
INFO - root - 2017-12-01 07:34:56.145760: step 113910, loss = 0.30, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 9h:30m:46s remains)
INFO - root - 2017-12-01 07:34:57.696628: step 113920, loss = 0.29, batch loss = 0.18 (52.7 examples/sec; 0.152 sec/batch; 9h:13m:03s remains)
INFO - root - 2017-12-01 07:34:59.242938: step 113930, loss = 0.30, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 9h:14m:39s remains)
INFO - root - 2017-12-01 07:35:00.813299: step 113940, loss = 0.37, batch loss = 0.26 (49.6 examples/sec; 0.161 sec/batch; 9h:47m:06s remains)
INFO - root - 2017-12-01 07:35:02.379112: step 113950, loss = 0.31, batch loss = 0.20 (51.8 examples/sec; 0.155 sec/batch; 9h:22m:57s remains)
INFO - root - 2017-12-01 07:35:03.951367: step 113960, loss = 0.38, batch loss = 0.28 (50.1 examples/sec; 0.160 sec/batch; 9h:41m:42s remains)
INFO - root - 2017-12-01 07:35:05.526642: step 113970, loss = 0.42, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 9h:31m:47s remains)
INFO - root - 2017-12-01 07:35:07.072550: step 113980, loss = 0.31, batch loss = 0.21 (49.1 examples/sec; 0.163 sec/batch; 9h:53m:20s remains)
INFO - root - 2017-12-01 07:35:08.654264: step 113990, loss = 0.29, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 9h:30m:12s remains)
INFO - root - 2017-12-01 07:35:10.219611: step 114000, loss = 0.40, batch loss = 0.29 (52.2 examples/sec; 0.153 sec/batch; 9h:18m:00s remains)
INFO - root - 2017-12-01 07:35:11.839126: step 114010, loss = 0.31, batch loss = 0.20 (49.3 examples/sec; 0.162 sec/batch; 9h:51m:16s remains)
INFO - root - 2017-12-01 07:35:13.425260: step 114020, loss = 0.30, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 9h:28m:19s remains)
INFO - root - 2017-12-01 07:35:14.985973: step 114030, loss = 0.36, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 9h:17m:39s remains)
INFO - root - 2017-12-01 07:35:16.552674: step 114040, loss = 0.27, batch loss = 0.16 (52.1 examples/sec; 0.154 sec/batch; 9h:19m:14s remains)
INFO - root - 2017-12-01 07:35:18.113726: step 114050, loss = 0.32, batch loss = 0.21 (49.9 examples/sec; 0.160 sec/batch; 9h:44m:09s remains)
INFO - root - 2017-12-01 07:35:19.688349: step 114060, loss = 0.29, batch loss = 0.18 (52.9 examples/sec; 0.151 sec/batch; 9h:10m:09s remains)
INFO - root - 2017-12-01 07:35:21.279535: step 114070, loss = 0.40, batch loss = 0.29 (51.8 examples/sec; 0.154 sec/batch; 9h:22m:06s remains)
INFO - root - 2017-12-01 07:35:22.854351: step 114080, loss = 0.39, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 9h:35m:29s remains)
INFO - root - 2017-12-01 07:35:24.409987: step 114090, loss = 0.30, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 9h:17m:58s remains)
INFO - root - 2017-12-01 07:35:25.994607: step 114100, loss = 0.27, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 9h:26m:39s remains)
INFO - root - 2017-12-01 07:35:27.625531: step 114110, loss = 0.36, batch loss = 0.26 (50.0 examples/sec; 0.160 sec/batch; 9h:42m:12s remains)
INFO - root - 2017-12-01 07:35:29.179118: step 114120, loss = 0.30, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 9h:17m:08s remains)
INFO - root - 2017-12-01 07:35:30.759814: step 114130, loss = 0.30, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 9h:29m:01s remains)
INFO - root - 2017-12-01 07:35:32.307409: step 114140, loss = 0.31, batch loss = 0.20 (52.8 examples/sec; 0.151 sec/batch; 9h:11m:07s remains)
INFO - root - 2017-12-01 07:35:33.852271: step 114150, loss = 0.32, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 9h:23m:52s remains)
INFO - root - 2017-12-01 07:35:35.413888: step 114160, loss = 0.32, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 9h:32m:49s remains)
INFO - root - 2017-12-01 07:35:36.971270: step 114170, loss = 0.41, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 9h:25m:01s remains)
INFO - root - 2017-12-01 07:35:38.530728: step 114180, loss = 0.27, batch loss = 0.17 (52.5 examples/sec; 0.152 sec/batch; 9h:14m:28s remains)
INFO - root - 2017-12-01 07:35:40.093047: step 114190, loss = 0.36, batch loss = 0.25 (53.2 examples/sec; 0.150 sec/batch; 9h:07m:29s remains)
INFO - root - 2017-12-01 07:35:41.724040: step 114200, loss = 0.22, batch loss = 0.11 (50.9 examples/sec; 0.157 sec/batch; 9h:32m:12s remains)
INFO - root - 2017-12-01 07:35:43.356306: step 114210, loss = 0.28, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 9h:31m:33s remains)
INFO - root - 2017-12-01 07:35:44.943321: step 114220, loss = 0.28, batch loss = 0.17 (49.8 examples/sec; 0.160 sec/batch; 9h:43m:52s remains)
INFO - root - 2017-12-01 07:35:46.504802: step 114230, loss = 0.36, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 9h:28m:34s remains)
INFO - root - 2017-12-01 07:35:48.046916: step 114240, loss = 0.32, batch loss = 0.22 (53.1 examples/sec; 0.151 sec/batch; 9h:08m:30s remains)
INFO - root - 2017-12-01 07:35:49.606760: step 114250, loss = 0.35, batch loss = 0.25 (53.2 examples/sec; 0.150 sec/batch; 9h:06m:41s remains)
INFO - root - 2017-12-01 07:35:51.159190: step 114260, loss = 0.35, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 9h:13m:52s remains)
INFO - root - 2017-12-01 07:35:52.716683: step 114270, loss = 0.33, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 9h:19m:25s remains)
INFO - root - 2017-12-01 07:35:54.278699: step 114280, loss = 0.29, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 9h:32m:40s remains)
INFO - root - 2017-12-01 07:35:55.854749: step 114290, loss = 0.43, batch loss = 0.32 (50.0 examples/sec; 0.160 sec/batch; 9h:42m:15s remains)
INFO - root - 2017-12-01 07:35:57.409043: step 114300, loss = 0.37, batch loss = 0.27 (50.0 examples/sec; 0.160 sec/batch; 9h:41m:59s remains)
INFO - root - 2017-12-01 07:35:59.020052: step 114310, loss = 0.26, batch loss = 0.15 (50.0 examples/sec; 0.160 sec/batch; 9h:42m:00s remains)
INFO - root - 2017-12-01 07:36:00.580320: step 114320, loss = 0.30, batch loss = 0.19 (50.1 examples/sec; 0.160 sec/batch; 9h:41m:00s remains)
INFO - root - 2017-12-01 07:36:02.138734: step 114330, loss = 0.32, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 9h:22m:07s remains)
INFO - root - 2017-12-01 07:36:03.699024: step 114340, loss = 0.29, batch loss = 0.18 (53.2 examples/sec; 0.151 sec/batch; 9h:07m:14s remains)
INFO - root - 2017-12-01 07:36:05.277494: step 114350, loss = 0.38, batch loss = 0.27 (48.0 examples/sec; 0.167 sec/batch; 10h:05m:47s remains)
INFO - root - 2017-12-01 07:36:06.866969: step 114360, loss = 0.30, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 9h:26m:15s remains)
INFO - root - 2017-12-01 07:36:08.424551: step 114370, loss = 0.33, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 9h:15m:26s remains)
INFO - root - 2017-12-01 07:36:09.990639: step 114380, loss = 0.35, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 9h:26m:26s remains)
INFO - root - 2017-12-01 07:36:11.593358: step 114390, loss = 0.34, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 9h:31m:22s remains)
INFO - root - 2017-12-01 07:36:13.173018: step 114400, loss = 0.30, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 9h:38m:45s remains)
INFO - root - 2017-12-01 07:36:14.820147: step 114410, loss = 0.54, batch loss = 0.44 (50.7 examples/sec; 0.158 sec/batch; 9h:34m:03s remains)
INFO - root - 2017-12-01 07:36:16.378704: step 114420, loss = 0.31, batch loss = 0.20 (50.5 examples/sec; 0.159 sec/batch; 9h:36m:07s remains)
INFO - root - 2017-12-01 07:36:17.947250: step 114430, loss = 0.35, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 9h:34m:56s remains)
INFO - root - 2017-12-01 07:36:19.513467: step 114440, loss = 0.33, batch loss = 0.22 (48.5 examples/sec; 0.165 sec/batch; 9h:59m:39s remains)
INFO - root - 2017-12-01 07:36:21.090308: step 114450, loss = 0.32, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 9h:22m:45s remains)
INFO - root - 2017-12-01 07:36:22.645257: step 114460, loss = 0.32, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 9h:31m:23s remains)
INFO - root - 2017-12-01 07:36:24.214261: step 114470, loss = 0.35, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 9h:25m:55s remains)
INFO - root - 2017-12-01 07:36:25.773791: step 114480, loss = 0.31, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 9h:24m:26s remains)
INFO - root - 2017-12-01 07:36:27.330840: step 114490, loss = 0.32, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 9h:16m:29s remains)
INFO - root - 2017-12-01 07:36:28.918154: step 114500, loss = 0.27, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 9h:19m:06s remains)
INFO - root - 2017-12-01 07:36:30.535488: step 114510, loss = 0.25, batch loss = 0.15 (50.5 examples/sec; 0.158 sec/batch; 9h:35m:49s remains)
INFO - root - 2017-12-01 07:36:32.095184: step 114520, loss = 0.36, batch loss = 0.26 (53.1 examples/sec; 0.151 sec/batch; 9h:06m:51s remains)
INFO - root - 2017-12-01 07:36:33.658924: step 114530, loss = 0.32, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 9h:15m:35s remains)
INFO - root - 2017-12-01 07:36:35.226551: step 114540, loss = 0.30, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 9h:42m:04s remains)
INFO - root - 2017-12-01 07:36:36.782843: step 114550, loss = 0.31, batch loss = 0.21 (51.1 examples/sec; 0.156 sec/batch; 9h:28m:27s remains)
INFO - root - 2017-12-01 07:36:38.353146: step 114560, loss = 0.30, batch loss = 0.19 (49.8 examples/sec; 0.161 sec/batch; 9h:43m:25s remains)
INFO - root - 2017-12-01 07:36:39.915629: step 114570, loss = 0.31, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 9h:29m:43s remains)
INFO - root - 2017-12-01 07:36:41.491248: step 114580, loss = 0.33, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 9h:33m:14s remains)
INFO - root - 2017-12-01 07:36:43.059340: step 114590, loss = 0.29, batch loss = 0.18 (49.3 examples/sec; 0.162 sec/batch; 9h:48m:51s remains)
INFO - root - 2017-12-01 07:36:44.626080: step 114600, loss = 0.35, batch loss = 0.24 (50.8 examples/sec; 0.158 sec/batch; 9h:31m:59s remains)
INFO - root - 2017-12-01 07:36:46.255988: step 114610, loss = 0.32, batch loss = 0.21 (52.8 examples/sec; 0.152 sec/batch; 9h:10m:14s remains)
INFO - root - 2017-12-01 07:36:47.830862: step 114620, loss = 0.28, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 9h:32m:20s remains)
INFO - root - 2017-12-01 07:36:49.394634: step 114630, loss = 0.40, batch loss = 0.29 (50.2 examples/sec; 0.159 sec/batch; 9h:38m:56s remains)
INFO - root - 2017-12-01 07:36:50.966504: step 114640, loss = 0.33, batch loss = 0.22 (47.7 examples/sec; 0.168 sec/batch; 10h:08m:45s remains)
INFO - root - 2017-12-01 07:36:52.576758: step 114650, loss = 0.24, batch loss = 0.13 (50.7 examples/sec; 0.158 sec/batch; 9h:32m:30s remains)
INFO - root - 2017-12-01 07:36:54.131269: step 114660, loss = 0.26, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 9h:26m:20s remains)
INFO - root - 2017-12-01 07:36:55.692064: step 114670, loss = 0.30, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 9h:19m:24s remains)
INFO - root - 2017-12-01 07:36:57.294001: step 114680, loss = 0.39, batch loss = 0.28 (52.5 examples/sec; 0.152 sec/batch; 9h:13m:30s remains)
INFO - root - 2017-12-01 07:36:58.871720: step 114690, loss = 0.29, batch loss = 0.18 (48.4 examples/sec; 0.165 sec/batch; 9h:59m:29s remains)
INFO - root - 2017-12-01 07:37:00.439395: step 114700, loss = 0.29, batch loss = 0.18 (50.0 examples/sec; 0.160 sec/batch; 9h:40m:47s remains)
INFO - root - 2017-12-01 07:37:02.099480: step 114710, loss = 0.24, batch loss = 0.13 (51.2 examples/sec; 0.156 sec/batch; 9h:26m:37s remains)
INFO - root - 2017-12-01 07:37:03.640556: step 114720, loss = 0.27, batch loss = 0.17 (50.7 examples/sec; 0.158 sec/batch; 9h:32m:44s remains)
INFO - root - 2017-12-01 07:37:05.201590: step 114730, loss = 0.28, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 9h:22m:36s remains)
INFO - root - 2017-12-01 07:37:06.747444: step 114740, loss = 0.30, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 9h:26m:55s remains)
INFO - root - 2017-12-01 07:37:08.326680: step 114750, loss = 0.33, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 9h:28m:54s remains)
INFO - root - 2017-12-01 07:37:09.888663: step 114760, loss = 0.30, batch loss = 0.19 (52.9 examples/sec; 0.151 sec/batch; 9h:08m:50s remains)
INFO - root - 2017-12-01 07:37:11.439374: step 114770, loss = 0.34, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 9h:37m:01s remains)
INFO - root - 2017-12-01 07:37:12.990904: step 114780, loss = 0.28, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 9h:23m:18s remains)
INFO - root - 2017-12-01 07:37:14.556555: step 114790, loss = 0.28, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 9h:27m:16s remains)
INFO - root - 2017-12-01 07:37:16.093468: step 114800, loss = 0.33, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 9h:13m:06s remains)
INFO - root - 2017-12-01 07:37:17.716307: step 114810, loss = 0.29, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 9h:29m:14s remains)
INFO - root - 2017-12-01 07:37:19.255275: step 114820, loss = 0.33, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 9h:17m:59s remains)
INFO - root - 2017-12-01 07:37:20.816686: step 114830, loss = 0.31, batch loss = 0.20 (49.1 examples/sec; 0.163 sec/batch; 9h:50m:44s remains)
INFO - root - 2017-12-01 07:37:22.366786: step 114840, loss = 0.32, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 9h:35m:38s remains)
INFO - root - 2017-12-01 07:37:23.931386: step 114850, loss = 0.27, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 9h:35m:37s remains)
INFO - root - 2017-12-01 07:37:25.496071: step 114860, loss = 0.38, batch loss = 0.27 (52.7 examples/sec; 0.152 sec/batch; 9h:11m:06s remains)
INFO - root - 2017-12-01 07:37:27.058527: step 114870, loss = 0.35, batch loss = 0.24 (52.5 examples/sec; 0.152 sec/batch; 9h:12m:33s remains)
INFO - root - 2017-12-01 07:37:28.642381: step 114880, loss = 0.39, batch loss = 0.29 (50.4 examples/sec; 0.159 sec/batch; 9h:35m:46s remains)
INFO - root - 2017-12-01 07:37:30.202183: step 114890, loss = 0.31, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 9h:30m:22s remains)
INFO - root - 2017-12-01 07:37:31.754562: step 114900, loss = 0.29, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 9h:14m:39s remains)
INFO - root - 2017-12-01 07:37:33.403357: step 114910, loss = 0.31, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 9h:21m:26s remains)
INFO - root - 2017-12-01 07:37:34.954834: step 114920, loss = 0.31, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 9h:30m:50s remains)
INFO - root - 2017-12-01 07:37:36.499711: step 114930, loss = 0.38, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 9h:23m:07s remains)
INFO - root - 2017-12-01 07:37:38.070111: step 114940, loss = 0.40, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 9h:25m:41s remains)
INFO - root - 2017-12-01 07:37:39.632134: step 114950, loss = 0.30, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 9h:28m:33s remains)
INFO - root - 2017-12-01 07:37:41.203145: step 114960, loss = 0.44, batch loss = 0.34 (52.4 examples/sec; 0.153 sec/batch; 9h:13m:33s remains)
INFO - root - 2017-12-01 07:37:42.768574: step 114970, loss = 0.31, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 9h:39m:37s remains)
INFO - root - 2017-12-01 07:37:44.328110: step 114980, loss = 0.31, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 9h:24m:15s remains)
INFO - root - 2017-12-01 07:37:45.899935: step 114990, loss = 0.25, batch loss = 0.14 (50.6 examples/sec; 0.158 sec/batch; 9h:33m:27s remains)
INFO - root - 2017-12-01 07:37:47.455080: step 115000, loss = 0.31, batch loss = 0.20 (52.5 examples/sec; 0.152 sec/batch; 9h:12m:37s remains)
INFO - root - 2017-12-01 07:37:49.091989: step 115010, loss = 0.28, batch loss = 0.17 (47.6 examples/sec; 0.168 sec/batch; 10h:09m:31s remains)
INFO - root - 2017-12-01 07:37:50.677332: step 115020, loss = 0.34, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 9h:15m:09s remains)
INFO - root - 2017-12-01 07:37:52.223299: step 115030, loss = 0.45, batch loss = 0.35 (52.3 examples/sec; 0.153 sec/batch; 9h:14m:30s remains)
INFO - root - 2017-12-01 07:37:53.789378: step 115040, loss = 0.30, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 9h:34m:02s remains)
INFO - root - 2017-12-01 07:37:55.361931: step 115050, loss = 0.32, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 9h:33m:03s remains)
INFO - root - 2017-12-01 07:37:56.929176: step 115060, loss = 0.31, batch loss = 0.20 (49.5 examples/sec; 0.162 sec/batch; 9h:45m:30s remains)
INFO - root - 2017-12-01 07:37:58.508803: step 115070, loss = 0.27, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 9h:19m:26s remains)
INFO - root - 2017-12-01 07:38:00.063630: step 115080, loss = 0.29, batch loss = 0.19 (49.6 examples/sec; 0.161 sec/batch; 9h:44m:30s remains)
INFO - root - 2017-12-01 07:38:01.619370: step 115090, loss = 0.31, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 9h:38m:57s remains)
INFO - root - 2017-12-01 07:38:03.173897: step 115100, loss = 0.30, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 9h:20m:28s remains)
INFO - root - 2017-12-01 07:38:04.834132: step 115110, loss = 0.38, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 9h:32m:15s remains)
INFO - root - 2017-12-01 07:38:06.397281: step 115120, loss = 0.34, batch loss = 0.23 (49.2 examples/sec; 0.163 sec/batch; 9h:49m:19s remains)
INFO - root - 2017-12-01 07:38:07.976108: step 115130, loss = 0.33, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 9h:26m:27s remains)
INFO - root - 2017-12-01 07:38:09.564976: step 115140, loss = 0.27, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 9h:29m:16s remains)
INFO - root - 2017-12-01 07:38:11.150609: step 115150, loss = 0.30, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 9h:36m:29s remains)
INFO - root - 2017-12-01 07:38:12.723833: step 115160, loss = 0.34, batch loss = 0.23 (51.1 examples/sec; 0.156 sec/batch; 9h:26m:46s remains)
INFO - root - 2017-12-01 07:38:14.367634: step 115170, loss = 0.40, batch loss = 0.29 (49.8 examples/sec; 0.161 sec/batch; 9h:41m:23s remains)
INFO - root - 2017-12-01 07:38:15.928387: step 115180, loss = 0.29, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 9h:35m:14s remains)
INFO - root - 2017-12-01 07:38:17.483180: step 115190, loss = 0.37, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 9h:09m:22s remains)
INFO - root - 2017-12-01 07:38:19.041802: step 115200, loss = 0.31, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 9h:22m:16s remains)
INFO - root - 2017-12-01 07:38:20.661791: step 115210, loss = 0.34, batch loss = 0.23 (53.5 examples/sec; 0.150 sec/batch; 9h:01m:49s remains)
INFO - root - 2017-12-01 07:38:22.218517: step 115220, loss = 0.31, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 9h:23m:38s remains)
INFO - root - 2017-12-01 07:38:23.785350: step 115230, loss = 0.32, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 9h:13m:26s remains)
INFO - root - 2017-12-01 07:38:25.354698: step 115240, loss = 0.29, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 9h:35m:35s remains)
INFO - root - 2017-12-01 07:38:26.936978: step 115250, loss = 0.31, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 9h:24m:39s remains)
INFO - root - 2017-12-01 07:38:28.494656: step 115260, loss = 0.52, batch loss = 0.42 (53.4 examples/sec; 0.150 sec/batch; 9h:02m:24s remains)
INFO - root - 2017-12-01 07:38:30.067968: step 115270, loss = 0.47, batch loss = 0.36 (51.9 examples/sec; 0.154 sec/batch; 9h:17m:47s remains)
INFO - root - 2017-12-01 07:38:31.621367: step 115280, loss = 0.29, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 9h:18m:08s remains)
INFO - root - 2017-12-01 07:38:33.177121: step 115290, loss = 0.33, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 9h:28m:41s remains)
INFO - root - 2017-12-01 07:38:34.744390: step 115300, loss = 0.28, batch loss = 0.17 (49.8 examples/sec; 0.161 sec/batch; 9h:41m:18s remains)
INFO - root - 2017-12-01 07:38:36.344599: step 115310, loss = 0.34, batch loss = 0.23 (53.4 examples/sec; 0.150 sec/batch; 9h:02m:18s remains)
INFO - root - 2017-12-01 07:38:37.914007: step 115320, loss = 0.29, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 9h:24m:07s remains)
INFO - root - 2017-12-01 07:38:39.486459: step 115330, loss = 0.32, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 9h:27m:35s remains)
INFO - root - 2017-12-01 07:38:41.042827: step 115340, loss = 0.35, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 9h:26m:02s remains)
INFO - root - 2017-12-01 07:38:42.595889: step 115350, loss = 0.35, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 9h:21m:55s remains)
INFO - root - 2017-12-01 07:38:44.145797: step 115360, loss = 0.28, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 9h:28m:21s remains)
INFO - root - 2017-12-01 07:38:45.722655: step 115370, loss = 0.36, batch loss = 0.25 (52.6 examples/sec; 0.152 sec/batch; 9h:10m:22s remains)
INFO - root - 2017-12-01 07:38:47.273076: step 115380, loss = 0.37, batch loss = 0.26 (50.8 examples/sec; 0.158 sec/batch; 9h:30m:12s remains)
INFO - root - 2017-12-01 07:38:48.836914: step 115390, loss = 0.40, batch loss = 0.29 (51.7 examples/sec; 0.155 sec/batch; 9h:19m:46s remains)
INFO - root - 2017-12-01 07:38:50.379285: step 115400, loss = 0.40, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 9h:22m:29s remains)
INFO - root - 2017-12-01 07:38:52.015333: step 115410, loss = 0.36, batch loss = 0.25 (52.4 examples/sec; 0.153 sec/batch; 9h:12m:45s remains)
INFO - root - 2017-12-01 07:38:53.573498: step 115420, loss = 0.38, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 9h:25m:11s remains)
INFO - root - 2017-12-01 07:38:55.148033: step 115430, loss = 0.46, batch loss = 0.36 (51.8 examples/sec; 0.154 sec/batch; 9h:18m:47s remains)
INFO - root - 2017-12-01 07:38:56.717682: step 115440, loss = 0.33, batch loss = 0.22 (49.6 examples/sec; 0.161 sec/batch; 9h:43m:40s remains)
INFO - root - 2017-12-01 07:38:58.280104: step 115450, loss = 0.42, batch loss = 0.31 (49.3 examples/sec; 0.162 sec/batch; 9h:46m:42s remains)
INFO - root - 2017-12-01 07:38:59.852490: step 115460, loss = 0.25, batch loss = 0.14 (50.7 examples/sec; 0.158 sec/batch; 9h:30m:50s remains)
INFO - root - 2017-12-01 07:39:01.423531: step 115470, loss = 0.30, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 9h:13m:49s remains)
INFO - root - 2017-12-01 07:39:02.991876: step 115480, loss = 0.29, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 9h:23m:52s remains)
INFO - root - 2017-12-01 07:39:04.556910: step 115490, loss = 0.31, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 9h:27m:20s remains)
INFO - root - 2017-12-01 07:39:06.123656: step 115500, loss = 0.38, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 9h:14m:26s remains)
INFO - root - 2017-12-01 07:39:07.813250: step 115510, loss = 0.36, batch loss = 0.25 (52.0 examples/sec; 0.154 sec/batch; 9h:16m:33s remains)
INFO - root - 2017-12-01 07:39:09.380332: step 115520, loss = 0.53, batch loss = 0.42 (52.0 examples/sec; 0.154 sec/batch; 9h:16m:25s remains)
INFO - root - 2017-12-01 07:39:10.978838: step 115530, loss = 0.35, batch loss = 0.24 (47.7 examples/sec; 0.168 sec/batch; 10h:06m:53s remains)
INFO - root - 2017-12-01 07:39:12.536750: step 115540, loss = 0.29, batch loss = 0.18 (49.8 examples/sec; 0.161 sec/batch; 9h:40m:33s remains)
INFO - root - 2017-12-01 07:39:14.109053: step 115550, loss = 0.29, batch loss = 0.19 (50.3 examples/sec; 0.159 sec/batch; 9h:35m:36s remains)
INFO - root - 2017-12-01 07:39:15.679103: step 115560, loss = 0.40, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 9h:23m:38s remains)
INFO - root - 2017-12-01 07:39:17.229195: step 115570, loss = 0.35, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 9h:31m:37s remains)
INFO - root - 2017-12-01 07:39:18.798628: step 115580, loss = 0.39, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 9h:21m:28s remains)
INFO - root - 2017-12-01 07:39:20.370188: step 115590, loss = 0.32, batch loss = 0.21 (52.6 examples/sec; 0.152 sec/batch; 9h:09m:31s remains)
INFO - root - 2017-12-01 07:39:21.938522: step 115600, loss = 0.40, batch loss = 0.29 (51.4 examples/sec; 0.156 sec/batch; 9h:22m:10s remains)
INFO - root - 2017-12-01 07:39:23.582323: step 115610, loss = 0.33, batch loss = 0.23 (48.0 examples/sec; 0.167 sec/batch; 10h:02m:22s remains)
INFO - root - 2017-12-01 07:39:25.176835: step 115620, loss = 0.42, batch loss = 0.31 (50.4 examples/sec; 0.159 sec/batch; 9h:34m:17s remains)
INFO - root - 2017-12-01 07:39:26.742555: step 115630, loss = 0.31, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 9h:31m:31s remains)
INFO - root - 2017-12-01 07:39:28.293099: step 115640, loss = 0.35, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 9h:28m:29s remains)
INFO - root - 2017-12-01 07:39:29.857049: step 115650, loss = 0.26, batch loss = 0.15 (52.2 examples/sec; 0.153 sec/batch; 9h:13m:44s remains)
INFO - root - 2017-12-01 07:39:31.435341: step 115660, loss = 0.26, batch loss = 0.15 (47.6 examples/sec; 0.168 sec/batch; 10h:07m:02s remains)
INFO - root - 2017-12-01 07:39:32.995458: step 115670, loss = 0.32, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 9h:24m:30s remains)
INFO - root - 2017-12-01 07:39:34.562723: step 115680, loss = 0.29, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 9h:27m:04s remains)
INFO - root - 2017-12-01 07:39:36.122058: step 115690, loss = 0.27, batch loss = 0.17 (50.2 examples/sec; 0.159 sec/batch; 9h:35m:28s remains)
INFO - root - 2017-12-01 07:39:37.682284: step 115700, loss = 0.27, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 9h:22m:44s remains)
INFO - root - 2017-12-01 07:39:39.305994: step 115710, loss = 0.27, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 9h:25m:01s remains)
INFO - root - 2017-12-01 07:39:40.865828: step 115720, loss = 0.28, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 9h:15m:20s remains)
INFO - root - 2017-12-01 07:39:42.422384: step 115730, loss = 0.28, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 9h:24m:35s remains)
INFO - root - 2017-12-01 07:39:43.979538: step 115740, loss = 0.32, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 9h:10m:16s remains)
INFO - root - 2017-12-01 07:39:45.546642: step 115750, loss = 0.25, batch loss = 0.15 (52.1 examples/sec; 0.154 sec/batch; 9h:14m:32s remains)
INFO - root - 2017-12-01 07:39:47.130790: step 115760, loss = 0.34, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 9h:26m:23s remains)
INFO - root - 2017-12-01 07:39:48.686518: step 115770, loss = 0.31, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 9h:30m:41s remains)
INFO - root - 2017-12-01 07:39:50.248239: step 115780, loss = 0.44, batch loss = 0.33 (49.8 examples/sec; 0.161 sec/batch; 9h:40m:11s remains)
INFO - root - 2017-12-01 07:39:51.815860: step 115790, loss = 0.29, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 9h:37m:44s remains)
INFO - root - 2017-12-01 07:39:53.388699: step 115800, loss = 0.37, batch loss = 0.26 (52.3 examples/sec; 0.153 sec/batch; 9h:12m:15s remains)
INFO - root - 2017-12-01 07:39:54.993080: step 115810, loss = 0.28, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 9h:20m:29s remains)
INFO - root - 2017-12-01 07:39:56.566404: step 115820, loss = 0.30, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 9h:18m:30s remains)
INFO - root - 2017-12-01 07:39:58.115830: step 115830, loss = 0.37, batch loss = 0.26 (52.1 examples/sec; 0.154 sec/batch; 9h:14m:56s remains)
INFO - root - 2017-12-01 07:39:59.689686: step 115840, loss = 0.37, batch loss = 0.27 (51.8 examples/sec; 0.154 sec/batch; 9h:17m:21s remains)
INFO - root - 2017-12-01 07:40:01.268549: step 115850, loss = 0.26, batch loss = 0.15 (48.3 examples/sec; 0.166 sec/batch; 9h:57m:48s remains)
INFO - root - 2017-12-01 07:40:02.822016: step 115860, loss = 0.29, batch loss = 0.18 (49.8 examples/sec; 0.161 sec/batch; 9h:40m:32s remains)
INFO - root - 2017-12-01 07:40:04.392555: step 115870, loss = 0.26, batch loss = 0.16 (48.6 examples/sec; 0.165 sec/batch; 9h:54m:13s remains)
INFO - root - 2017-12-01 07:40:05.997187: step 115880, loss = 0.33, batch loss = 0.22 (50.5 examples/sec; 0.159 sec/batch; 9h:32m:25s remains)
INFO - root - 2017-12-01 07:40:07.544229: step 115890, loss = 0.27, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 9h:16m:01s remains)
INFO - root - 2017-12-01 07:40:09.135861: step 115900, loss = 0.38, batch loss = 0.28 (48.1 examples/sec; 0.166 sec/batch; 10h:00m:22s remains)
INFO - root - 2017-12-01 07:40:10.802356: step 115910, loss = 0.27, batch loss = 0.16 (48.5 examples/sec; 0.165 sec/batch; 9h:55m:17s remains)
INFO - root - 2017-12-01 07:40:12.360582: step 115920, loss = 0.32, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 9h:13m:38s remains)
INFO - root - 2017-12-01 07:40:13.920649: step 115930, loss = 0.29, batch loss = 0.19 (52.8 examples/sec; 0.152 sec/batch; 9h:07m:07s remains)
INFO - root - 2017-12-01 07:40:15.508966: step 115940, loss = 0.38, batch loss = 0.27 (51.7 examples/sec; 0.155 sec/batch; 9h:18m:27s remains)
INFO - root - 2017-12-01 07:40:17.060917: step 115950, loss = 0.24, batch loss = 0.14 (51.2 examples/sec; 0.156 sec/batch; 9h:23m:39s remains)
INFO - root - 2017-12-01 07:40:18.621015: step 115960, loss = 0.33, batch loss = 0.22 (49.7 examples/sec; 0.161 sec/batch; 9h:40m:36s remains)
INFO - root - 2017-12-01 07:40:20.184756: step 115970, loss = 0.29, batch loss = 0.18 (51.8 examples/sec; 0.155 sec/batch; 9h:17m:53s remains)
INFO - root - 2017-12-01 07:40:21.795405: step 115980, loss = 0.31, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 9h:18m:55s remains)
INFO - root - 2017-12-01 07:40:23.345465: step 115990, loss = 0.42, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 9h:24m:16s remains)
INFO - root - 2017-12-01 07:40:24.904098: step 116000, loss = 0.26, batch loss = 0.15 (51.5 examples/sec; 0.155 sec/batch; 9h:20m:32s remains)
INFO - root - 2017-12-01 07:40:26.574280: step 116010, loss = 0.34, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 9h:21m:27s remains)
INFO - root - 2017-12-01 07:40:28.130363: step 116020, loss = 0.25, batch loss = 0.15 (50.6 examples/sec; 0.158 sec/batch; 9h:30m:29s remains)
INFO - root - 2017-12-01 07:40:29.704687: step 116030, loss = 0.29, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 9h:16m:33s remains)
INFO - root - 2017-12-01 07:40:31.262827: step 116040, loss = 0.26, batch loss = 0.15 (48.6 examples/sec; 0.165 sec/batch; 9h:53m:47s remains)
INFO - root - 2017-12-01 07:40:32.829217: step 116050, loss = 0.30, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 9h:23m:11s remains)
INFO - root - 2017-12-01 07:40:34.431372: step 116060, loss = 0.29, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 9h:21m:20s remains)
INFO - root - 2017-12-01 07:40:36.000726: step 116070, loss = 0.33, batch loss = 0.23 (53.7 examples/sec; 0.149 sec/batch; 8h:57m:52s remains)
INFO - root - 2017-12-01 07:40:37.575220: step 116080, loss = 0.31, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 9h:18m:33s remains)
INFO - root - 2017-12-01 07:40:39.152344: step 116090, loss = 0.35, batch loss = 0.24 (49.2 examples/sec; 0.163 sec/batch; 9h:46m:35s remains)
INFO - root - 2017-12-01 07:40:40.725448: step 116100, loss = 0.37, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 9h:27m:16s remains)
INFO - root - 2017-12-01 07:40:42.399841: step 116110, loss = 0.30, batch loss = 0.19 (48.5 examples/sec; 0.165 sec/batch; 9h:55m:11s remains)
INFO - root - 2017-12-01 07:40:43.968111: step 116120, loss = 0.33, batch loss = 0.22 (49.0 examples/sec; 0.163 sec/batch; 9h:48m:22s remains)
INFO - root - 2017-12-01 07:40:45.545220: step 116130, loss = 0.35, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 9h:23m:04s remains)
INFO - root - 2017-12-01 07:40:47.107256: step 116140, loss = 0.26, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 9h:23m:00s remains)
INFO - root - 2017-12-01 07:40:48.683596: step 116150, loss = 0.38, batch loss = 0.28 (50.4 examples/sec; 0.159 sec/batch; 9h:31m:56s remains)
INFO - root - 2017-12-01 07:40:50.270349: step 116160, loss = 0.26, batch loss = 0.15 (48.3 examples/sec; 0.166 sec/batch; 9h:57m:45s remains)
INFO - root - 2017-12-01 07:40:51.834807: step 116170, loss = 0.29, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 9h:18m:45s remains)
INFO - root - 2017-12-01 07:40:53.397993: step 116180, loss = 0.28, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 9h:25m:55s remains)
INFO - root - 2017-12-01 07:40:54.986795: step 116190, loss = 0.26, batch loss = 0.15 (48.6 examples/sec; 0.164 sec/batch; 9h:52m:58s remains)
INFO - root - 2017-12-01 07:40:56.577545: step 116200, loss = 0.27, batch loss = 0.17 (48.4 examples/sec; 0.165 sec/batch; 9h:55m:38s remains)
INFO - root - 2017-12-01 07:40:58.203808: step 116210, loss = 0.38, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 9h:24m:59s remains)
INFO - root - 2017-12-01 07:40:59.769108: step 116220, loss = 0.31, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 9h:33m:47s remains)
INFO - root - 2017-12-01 07:41:01.320409: step 116230, loss = 0.37, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 9h:33m:50s remains)
INFO - root - 2017-12-01 07:41:02.868933: step 116240, loss = 0.29, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 9h:23m:33s remains)
INFO - root - 2017-12-01 07:41:04.449031: step 116250, loss = 0.26, batch loss = 0.15 (52.1 examples/sec; 0.154 sec/batch; 9h:13m:40s remains)
INFO - root - 2017-12-01 07:41:06.009580: step 116260, loss = 0.29, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 9h:30m:24s remains)
INFO - root - 2017-12-01 07:41:07.577684: step 116270, loss = 0.23, batch loss = 0.13 (49.9 examples/sec; 0.160 sec/batch; 9h:38m:15s remains)
INFO - root - 2017-12-01 07:41:09.142948: step 116280, loss = 0.27, batch loss = 0.16 (50.0 examples/sec; 0.160 sec/batch; 9h:36m:17s remains)
INFO - root - 2017-12-01 07:41:10.723820: step 116290, loss = 0.34, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 9h:28m:58s remains)
INFO - root - 2017-12-01 07:41:12.311917: step 116300, loss = 0.33, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 9h:33m:51s remains)
INFO - root - 2017-12-01 07:41:13.911580: step 116310, loss = 0.41, batch loss = 0.30 (51.6 examples/sec; 0.155 sec/batch; 9h:18m:09s remains)
INFO - root - 2017-12-01 07:41:15.483362: step 116320, loss = 0.30, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 9h:24m:11s remains)
INFO - root - 2017-12-01 07:41:17.053921: step 116330, loss = 0.33, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 9h:15m:55s remains)
INFO - root - 2017-12-01 07:41:18.608422: step 116340, loss = 0.27, batch loss = 0.16 (50.8 examples/sec; 0.158 sec/batch; 9h:27m:49s remains)
INFO - root - 2017-12-01 07:41:20.171573: step 116350, loss = 0.32, batch loss = 0.22 (48.7 examples/sec; 0.164 sec/batch; 9h:52m:21s remains)
INFO - root - 2017-12-01 07:41:21.737764: step 116360, loss = 0.38, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 9h:26m:08s remains)
INFO - root - 2017-12-01 07:41:23.304993: step 116370, loss = 0.33, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 9h:07m:15s remains)
INFO - root - 2017-12-01 07:41:24.859316: step 116380, loss = 0.30, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 9h:26m:27s remains)
INFO - root - 2017-12-01 07:41:26.428757: step 116390, loss = 0.28, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 9h:22m:33s remains)
INFO - root - 2017-12-01 07:41:28.000669: step 116400, loss = 0.35, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 9h:20m:57s remains)
INFO - root - 2017-12-01 07:41:29.612408: step 116410, loss = 0.27, batch loss = 0.16 (52.1 examples/sec; 0.154 sec/batch; 9h:12m:55s remains)
INFO - root - 2017-12-01 07:41:31.169059: step 116420, loss = 0.27, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 9h:22m:30s remains)
INFO - root - 2017-12-01 07:41:32.734042: step 116430, loss = 0.35, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 9h:19m:34s remains)
INFO - root - 2017-12-01 07:41:34.295417: step 116440, loss = 0.48, batch loss = 0.38 (51.5 examples/sec; 0.155 sec/batch; 9h:19m:07s remains)
INFO - root - 2017-12-01 07:41:35.871926: step 116450, loss = 0.41, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 9h:22m:40s remains)
INFO - root - 2017-12-01 07:41:37.425159: step 116460, loss = 0.27, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 9h:14m:55s remains)
INFO - root - 2017-12-01 07:41:38.986502: step 116470, loss = 0.31, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 9h:23m:26s remains)
INFO - root - 2017-12-01 07:41:40.570378: step 116480, loss = 0.29, batch loss = 0.19 (49.3 examples/sec; 0.162 sec/batch; 9h:44m:16s remains)
INFO - root - 2017-12-01 07:41:42.137688: step 116490, loss = 0.35, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 9h:15m:04s remains)
INFO - root - 2017-12-01 07:41:43.691188: step 116500, loss = 0.32, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 9h:20m:21s remains)
INFO - root - 2017-12-01 07:41:45.295549: step 116510, loss = 0.30, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 9h:15m:34s remains)
INFO - root - 2017-12-01 07:41:46.858789: step 116520, loss = 0.34, batch loss = 0.24 (49.5 examples/sec; 0.161 sec/batch; 9h:41m:17s remains)
INFO - root - 2017-12-01 07:41:48.401067: step 116530, loss = 0.30, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 9h:23m:59s remains)
INFO - root - 2017-12-01 07:41:49.960643: step 116540, loss = 0.35, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 9h:22m:03s remains)
INFO - root - 2017-12-01 07:41:51.522896: step 116550, loss = 0.39, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 9h:24m:54s remains)
INFO - root - 2017-12-01 07:41:53.081781: step 116560, loss = 0.35, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 9h:20m:16s remains)
INFO - root - 2017-12-01 07:41:54.639272: step 116570, loss = 0.29, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 9h:24m:56s remains)
INFO - root - 2017-12-01 07:41:56.212826: step 116580, loss = 0.29, batch loss = 0.18 (50.0 examples/sec; 0.160 sec/batch; 9h:36m:02s remains)
INFO - root - 2017-12-01 07:41:57.782116: step 116590, loss = 0.40, batch loss = 0.29 (52.5 examples/sec; 0.152 sec/batch; 9h:08m:03s remains)
INFO - root - 2017-12-01 07:41:59.348440: step 116600, loss = 0.37, batch loss = 0.27 (51.9 examples/sec; 0.154 sec/batch; 9h:14m:45s remains)
INFO - root - 2017-12-01 07:42:00.953065: step 116610, loss = 0.35, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 9h:24m:52s remains)
INFO - root - 2017-12-01 07:42:02.514569: step 116620, loss = 0.38, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 9h:17m:53s remains)
INFO - root - 2017-12-01 07:42:04.094356: step 116630, loss = 0.28, batch loss = 0.17 (52.1 examples/sec; 0.154 sec/batch; 9h:12m:32s remains)
INFO - root - 2017-12-01 07:42:05.652765: step 116640, loss = 0.27, batch loss = 0.16 (52.3 examples/sec; 0.153 sec/batch; 9h:10m:38s remains)
INFO - root - 2017-12-01 07:42:07.222095: step 116650, loss = 0.29, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 9h:15m:17s remains)
INFO - root - 2017-12-01 07:42:08.805955: step 116660, loss = 0.30, batch loss = 0.19 (47.7 examples/sec; 0.168 sec/batch; 10h:02m:51s remains)
INFO - root - 2017-12-01 07:42:10.395016: step 116670, loss = 0.32, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 9h:21m:24s remains)
INFO - root - 2017-12-01 07:42:11.975407: step 116680, loss = 0.30, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 9h:35m:29s remains)
INFO - root - 2017-12-01 07:42:13.519427: step 116690, loss = 0.35, batch loss = 0.25 (53.2 examples/sec; 0.150 sec/batch; 9h:01m:18s remains)
INFO - root - 2017-12-01 07:42:15.079160: step 116700, loss = 0.26, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 9h:19m:32s remains)
INFO - root - 2017-12-01 07:42:16.714207: step 116710, loss = 0.29, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 9h:25m:40s remains)
INFO - root - 2017-12-01 07:42:18.283552: step 116720, loss = 0.33, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 9h:12m:03s remains)
INFO - root - 2017-12-01 07:42:19.872169: step 116730, loss = 0.34, batch loss = 0.24 (53.2 examples/sec; 0.150 sec/batch; 9h:00m:57s remains)
INFO - root - 2017-12-01 07:42:21.436976: step 116740, loss = 0.24, batch loss = 0.13 (52.9 examples/sec; 0.151 sec/batch; 9h:03m:34s remains)
INFO - root - 2017-12-01 07:42:22.996217: step 116750, loss = 0.32, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 9h:19m:14s remains)
INFO - root - 2017-12-01 07:42:24.551889: step 116760, loss = 0.34, batch loss = 0.23 (49.8 examples/sec; 0.161 sec/batch; 9h:37m:56s remains)
INFO - root - 2017-12-01 07:42:26.117863: step 116770, loss = 0.43, batch loss = 0.33 (51.8 examples/sec; 0.154 sec/batch; 9h:14m:51s remains)
INFO - root - 2017-12-01 07:42:27.676351: step 116780, loss = 0.32, batch loss = 0.21 (52.7 examples/sec; 0.152 sec/batch; 9h:05m:57s remains)
INFO - root - 2017-12-01 07:42:29.244138: step 116790, loss = 0.45, batch loss = 0.35 (50.1 examples/sec; 0.160 sec/batch; 9h:34m:34s remains)
INFO - root - 2017-12-01 07:42:30.811844: step 116800, loss = 0.43, batch loss = 0.33 (52.0 examples/sec; 0.154 sec/batch; 9h:13m:21s remains)
INFO - root - 2017-12-01 07:42:32.443394: step 116810, loss = 0.35, batch loss = 0.24 (52.7 examples/sec; 0.152 sec/batch; 9h:06m:12s remains)
INFO - root - 2017-12-01 07:42:34.021523: step 116820, loss = 0.27, batch loss = 0.16 (50.0 examples/sec; 0.160 sec/batch; 9h:35m:26s remains)
INFO - root - 2017-12-01 07:42:35.615629: step 116830, loss = 0.39, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 9h:17m:50s remains)
INFO - root - 2017-12-01 07:42:37.170814: step 116840, loss = 0.39, batch loss = 0.28 (50.0 examples/sec; 0.160 sec/batch; 9h:34m:40s remains)
INFO - root - 2017-12-01 07:42:38.728171: step 116850, loss = 0.26, batch loss = 0.15 (52.6 examples/sec; 0.152 sec/batch; 9h:06m:21s remains)
INFO - root - 2017-12-01 07:42:40.299813: step 116860, loss = 0.36, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 9h:29m:18s remains)
INFO - root - 2017-12-01 07:42:41.861381: step 116870, loss = 0.33, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 9h:18m:53s remains)
INFO - root - 2017-12-01 07:42:43.410054: step 116880, loss = 0.27, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 9h:23m:24s remains)
INFO - root - 2017-12-01 07:42:44.975859: step 116890, loss = 0.34, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 9h:30m:22s remains)
INFO - root - 2017-12-01 07:42:46.532848: step 116900, loss = 0.23, batch loss = 0.12 (52.8 examples/sec; 0.152 sec/batch; 9h:04m:56s remains)
INFO - root - 2017-12-01 07:42:48.193663: step 116910, loss = 0.34, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 9h:06m:35s remains)
INFO - root - 2017-12-01 07:42:49.749180: step 116920, loss = 0.32, batch loss = 0.22 (49.4 examples/sec; 0.162 sec/batch; 9h:42m:11s remains)
INFO - root - 2017-12-01 07:42:51.310367: step 116930, loss = 0.34, batch loss = 0.24 (52.5 examples/sec; 0.152 sec/batch; 9h:07m:35s remains)
INFO - root - 2017-12-01 07:42:52.893996: step 116940, loss = 0.31, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 9h:28m:05s remains)
INFO - root - 2017-12-01 07:42:54.467169: step 116950, loss = 0.39, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 9h:27m:55s remains)
INFO - root - 2017-12-01 07:42:56.037942: step 116960, loss = 0.27, batch loss = 0.17 (50.1 examples/sec; 0.160 sec/batch; 9h:33m:50s remains)
INFO - root - 2017-12-01 07:42:57.601615: step 116970, loss = 0.31, batch loss = 0.21 (51.1 examples/sec; 0.156 sec/batch; 9h:21m:59s remains)
INFO - root - 2017-12-01 07:42:59.165240: step 116980, loss = 0.27, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 9h:15m:59s remains)
INFO - root - 2017-12-01 07:43:00.725807: step 116990, loss = 0.25, batch loss = 0.15 (50.6 examples/sec; 0.158 sec/batch; 9h:27m:22s remains)
INFO - root - 2017-12-01 07:43:02.317620: step 117000, loss = 0.35, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 9h:28m:14s remains)
INFO - root - 2017-12-01 07:43:03.975446: step 117010, loss = 0.28, batch loss = 0.18 (48.3 examples/sec; 0.166 sec/batch; 9h:55m:17s remains)
INFO - root - 2017-12-01 07:43:05.526867: step 117020, loss = 0.27, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 9h:18m:35s remains)
INFO - root - 2017-12-01 07:43:07.086031: step 117030, loss = 0.27, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 9h:23m:56s remains)
INFO - root - 2017-12-01 07:43:08.661692: step 117040, loss = 0.35, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 9h:15m:16s remains)
INFO - root - 2017-12-01 07:43:10.218484: step 117050, loss = 0.32, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 9h:32m:14s remains)
INFO - root - 2017-12-01 07:43:11.780408: step 117060, loss = 0.48, batch loss = 0.37 (50.5 examples/sec; 0.159 sec/batch; 9h:29m:19s remains)
INFO - root - 2017-12-01 07:43:13.351279: step 117070, loss = 0.34, batch loss = 0.23 (50.8 examples/sec; 0.157 sec/batch; 9h:25m:01s remains)
INFO - root - 2017-12-01 07:43:14.900897: step 117080, loss = 0.28, batch loss = 0.17 (51.1 examples/sec; 0.156 sec/batch; 9h:21m:42s remains)
INFO - root - 2017-12-01 07:43:16.480626: step 117090, loss = 0.37, batch loss = 0.27 (48.4 examples/sec; 0.165 sec/batch; 9h:53m:23s remains)
INFO - root - 2017-12-01 07:43:18.047485: step 117100, loss = 0.26, batch loss = 0.15 (52.0 examples/sec; 0.154 sec/batch; 9h:12m:00s remains)
INFO - root - 2017-12-01 07:43:19.659206: step 117110, loss = 0.29, batch loss = 0.18 (49.9 examples/sec; 0.160 sec/batch; 9h:35m:31s remains)
INFO - root - 2017-12-01 07:43:21.214754: step 117120, loss = 0.28, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 9h:09m:09s remains)
INFO - root - 2017-12-01 07:43:22.772084: step 117130, loss = 0.38, batch loss = 0.27 (50.4 examples/sec; 0.159 sec/batch; 9h:29m:15s remains)
INFO - root - 2017-12-01 07:43:24.330001: step 117140, loss = 0.39, batch loss = 0.28 (49.0 examples/sec; 0.163 sec/batch; 9h:46m:12s remains)
INFO - root - 2017-12-01 07:43:25.895878: step 117150, loss = 0.25, batch loss = 0.15 (49.9 examples/sec; 0.160 sec/batch; 9h:35m:43s remains)
INFO - root - 2017-12-01 07:43:27.473505: step 117160, loss = 0.29, batch loss = 0.18 (49.4 examples/sec; 0.162 sec/batch; 9h:41m:31s remains)
INFO - root - 2017-12-01 07:43:29.022208: step 117170, loss = 0.26, batch loss = 0.15 (52.3 examples/sec; 0.153 sec/batch; 9h:09m:28s remains)
INFO - root - 2017-12-01 07:43:30.595717: step 117180, loss = 0.36, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 9h:08m:58s remains)
INFO - root - 2017-12-01 07:43:32.158859: step 117190, loss = 0.26, batch loss = 0.15 (51.7 examples/sec; 0.155 sec/batch; 9h:15m:12s remains)
INFO - root - 2017-12-01 07:43:33.721333: step 117200, loss = 0.37, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 9h:26m:16s remains)
INFO - root - 2017-12-01 07:43:35.399209: step 117210, loss = 0.41, batch loss = 0.31 (50.6 examples/sec; 0.158 sec/batch; 9h:27m:22s remains)
INFO - root - 2017-12-01 07:43:36.974846: step 117220, loss = 0.27, batch loss = 0.17 (49.1 examples/sec; 0.163 sec/batch; 9h:44m:17s remains)
INFO - root - 2017-12-01 07:43:38.533812: step 117230, loss = 0.31, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 9h:15m:46s remains)
INFO - root - 2017-12-01 07:43:40.088798: step 117240, loss = 0.32, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 9h:22m:24s remains)
INFO - root - 2017-12-01 07:43:41.649454: step 117250, loss = 0.25, batch loss = 0.15 (51.9 examples/sec; 0.154 sec/batch; 9h:12m:32s remains)
INFO - root - 2017-12-01 07:43:43.201673: step 117260, loss = 0.31, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 9h:11m:34s remains)
INFO - root - 2017-12-01 07:43:44.770022: step 117270, loss = 0.28, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 9h:25m:14s remains)
INFO - root - 2017-12-01 07:43:46.332536: step 117280, loss = 0.40, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 9h:17m:01s remains)
INFO - root - 2017-12-01 07:43:47.885332: step 117290, loss = 0.30, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 9h:21m:04s remains)
INFO - root - 2017-12-01 07:43:49.465834: step 117300, loss = 0.31, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 9h:13m:45s remains)
INFO - root - 2017-12-01 07:43:51.107416: step 117310, loss = 0.34, batch loss = 0.24 (48.6 examples/sec; 0.164 sec/batch; 9h:49m:46s remains)
INFO - root - 2017-12-01 07:43:52.670492: step 117320, loss = 0.26, batch loss = 0.16 (52.8 examples/sec; 0.152 sec/batch; 9h:03m:43s remains)
INFO - root - 2017-12-01 07:43:54.239749: step 117330, loss = 0.29, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 9h:19m:45s remains)
INFO - root - 2017-12-01 07:43:55.794705: step 117340, loss = 0.35, batch loss = 0.24 (50.0 examples/sec; 0.160 sec/batch; 9h:34m:19s remains)
INFO - root - 2017-12-01 07:43:57.331856: step 117350, loss = 0.28, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 9h:21m:36s remains)
INFO - root - 2017-12-01 07:43:58.897752: step 117360, loss = 0.31, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 9h:19m:52s remains)
INFO - root - 2017-12-01 07:44:00.464487: step 117370, loss = 0.30, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 9h:07m:34s remains)
INFO - root - 2017-12-01 07:44:02.031839: step 117380, loss = 0.28, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 9h:11m:14s remains)
INFO - root - 2017-12-01 07:44:03.646133: step 117390, loss = 0.28, batch loss = 0.17 (49.8 examples/sec; 0.161 sec/batch; 9h:35m:43s remains)
INFO - root - 2017-12-01 07:44:05.196954: step 117400, loss = 0.25, batch loss = 0.14 (49.2 examples/sec; 0.162 sec/batch; 9h:42m:32s remains)
INFO - root - 2017-12-01 07:44:06.812193: step 117410, loss = 0.35, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 9h:16m:34s remains)
INFO - root - 2017-12-01 07:44:08.363782: step 117420, loss = 0.30, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 9h:08m:05s remains)
INFO - root - 2017-12-01 07:44:09.938921: step 117430, loss = 0.46, batch loss = 0.36 (51.4 examples/sec; 0.156 sec/batch; 9h:18m:22s remains)
INFO - root - 2017-12-01 07:44:11.494784: step 117440, loss = 0.27, batch loss = 0.16 (51.1 examples/sec; 0.156 sec/batch; 9h:20m:42s remains)
INFO - root - 2017-12-01 07:44:13.059750: step 117450, loss = 0.27, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 9h:25m:09s remains)
INFO - root - 2017-12-01 07:44:14.623735: step 117460, loss = 0.32, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 9h:17m:59s remains)
INFO - root - 2017-12-01 07:44:16.191220: step 117470, loss = 0.24, batch loss = 0.14 (51.5 examples/sec; 0.155 sec/batch; 9h:16m:49s remains)
INFO - root - 2017-12-01 07:44:17.758305: step 117480, loss = 0.31, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 9h:28m:52s remains)
INFO - root - 2017-12-01 07:44:19.315695: step 117490, loss = 0.34, batch loss = 0.23 (49.4 examples/sec; 0.162 sec/batch; 9h:39m:45s remains)
INFO - root - 2017-12-01 07:44:20.872523: step 117500, loss = 0.35, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 9h:08m:21s remains)
INFO - root - 2017-12-01 07:44:22.493561: step 117510, loss = 0.29, batch loss = 0.18 (49.1 examples/sec; 0.163 sec/batch; 9h:43m:13s remains)
INFO - root - 2017-12-01 07:44:24.075379: step 117520, loss = 0.34, batch loss = 0.24 (49.4 examples/sec; 0.162 sec/batch; 9h:40m:08s remains)
INFO - root - 2017-12-01 07:44:25.622027: step 117530, loss = 0.35, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 9h:11m:22s remains)
INFO - root - 2017-12-01 07:44:27.190875: step 117540, loss = 0.36, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 9h:14m:52s remains)
INFO - root - 2017-12-01 07:44:28.751130: step 117550, loss = 0.33, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 9h:14m:34s remains)
INFO - root - 2017-12-01 07:44:30.324938: step 117560, loss = 0.33, batch loss = 0.23 (49.5 examples/sec; 0.162 sec/batch; 9h:39m:27s remains)
INFO - root - 2017-12-01 07:44:31.875046: step 117570, loss = 0.35, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 9h:25m:14s remains)
INFO - root - 2017-12-01 07:44:33.436511: step 117580, loss = 0.37, batch loss = 0.27 (48.9 examples/sec; 0.164 sec/batch; 9h:46m:07s remains)
INFO - root - 2017-12-01 07:44:35.014682: step 117590, loss = 0.29, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 9h:21m:33s remains)
INFO - root - 2017-12-01 07:44:36.569243: step 117600, loss = 0.31, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 9h:09m:57s remains)
INFO - root - 2017-12-01 07:44:38.213627: step 117610, loss = 0.32, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 9h:15m:23s remains)
INFO - root - 2017-12-01 07:44:39.767641: step 117620, loss = 0.25, batch loss = 0.14 (52.5 examples/sec; 0.152 sec/batch; 9h:05m:41s remains)
INFO - root - 2017-12-01 07:44:41.343141: step 117630, loss = 0.26, batch loss = 0.15 (50.9 examples/sec; 0.157 sec/batch; 9h:22m:34s remains)
INFO - root - 2017-12-01 07:44:42.914714: step 117640, loss = 0.28, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 9h:20m:47s remains)
INFO - root - 2017-12-01 07:44:44.479377: step 117650, loss = 0.45, batch loss = 0.34 (49.1 examples/sec; 0.163 sec/batch; 9h:43m:15s remains)
INFO - root - 2017-12-01 07:44:46.057704: step 117660, loss = 0.31, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 9h:20m:52s remains)
INFO - root - 2017-12-01 07:44:47.614051: step 117670, loss = 0.27, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 9h:22m:18s remains)
INFO - root - 2017-12-01 07:44:49.177558: step 117680, loss = 0.27, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 9h:25m:11s remains)
INFO - root - 2017-12-01 07:44:50.720563: step 117690, loss = 0.29, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 9h:24m:50s remains)
INFO - root - 2017-12-01 07:44:52.287618: step 117700, loss = 0.32, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 9h:15m:50s remains)
INFO - root - 2017-12-01 07:44:53.942546: step 117710, loss = 0.41, batch loss = 0.31 (51.1 examples/sec; 0.157 sec/batch; 9h:20m:20s remains)
INFO - root - 2017-12-01 07:44:55.507080: step 117720, loss = 0.38, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 9h:27m:11s remains)
INFO - root - 2017-12-01 07:44:57.063482: step 117730, loss = 0.32, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 9h:15m:38s remains)
INFO - root - 2017-12-01 07:44:58.627024: step 117740, loss = 0.31, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 9h:06m:47s remains)
INFO - root - 2017-12-01 07:45:00.209225: step 117750, loss = 0.35, batch loss = 0.24 (52.4 examples/sec; 0.153 sec/batch; 9h:06m:47s remains)
INFO - root - 2017-12-01 07:45:01.785838: step 117760, loss = 0.41, batch loss = 0.31 (50.5 examples/sec; 0.159 sec/batch; 9h:27m:17s remains)
INFO - root - 2017-12-01 07:45:03.348534: step 117770, loss = 0.35, batch loss = 0.24 (49.7 examples/sec; 0.161 sec/batch; 9h:35m:55s remains)
INFO - root - 2017-12-01 07:45:04.921615: step 117780, loss = 0.45, batch loss = 0.34 (51.6 examples/sec; 0.155 sec/batch; 9h:14m:29s remains)
INFO - root - 2017-12-01 07:45:06.483463: step 117790, loss = 0.38, batch loss = 0.27 (50.3 examples/sec; 0.159 sec/batch; 9h:29m:19s remains)
INFO - root - 2017-12-01 07:45:08.046459: step 117800, loss = 0.27, batch loss = 0.16 (51.1 examples/sec; 0.157 sec/batch; 9h:20m:02s remains)
INFO - root - 2017-12-01 07:45:09.739597: step 117810, loss = 0.29, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 9h:07m:23s remains)
INFO - root - 2017-12-01 07:45:11.314637: step 117820, loss = 0.28, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 9h:23m:57s remains)
INFO - root - 2017-12-01 07:45:12.886323: step 117830, loss = 0.27, batch loss = 0.17 (52.1 examples/sec; 0.154 sec/batch; 9h:09m:12s remains)
INFO - root - 2017-12-01 07:45:14.445629: step 117840, loss = 0.30, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 9h:14m:37s remains)
INFO - root - 2017-12-01 07:45:16.029374: step 117850, loss = 0.27, batch loss = 0.17 (52.4 examples/sec; 0.153 sec/batch; 9h:06m:36s remains)
INFO - root - 2017-12-01 07:45:17.586476: step 117860, loss = 0.24, batch loss = 0.14 (50.8 examples/sec; 0.157 sec/batch; 9h:23m:18s remains)
INFO - root - 2017-12-01 07:45:19.151991: step 117870, loss = 0.30, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 9h:26m:35s remains)
INFO - root - 2017-12-01 07:45:20.723735: step 117880, loss = 0.26, batch loss = 0.16 (52.3 examples/sec; 0.153 sec/batch; 9h:07m:11s remains)
INFO - root - 2017-12-01 07:45:22.291237: step 117890, loss = 0.35, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 9h:14m:43s remains)
INFO - root - 2017-12-01 07:45:23.852549: step 117900, loss = 0.36, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 9h:25m:54s remains)
INFO - root - 2017-12-01 07:45:25.478985: step 117910, loss = 0.31, batch loss = 0.21 (52.8 examples/sec; 0.151 sec/batch; 9h:01m:39s remains)
INFO - root - 2017-12-01 07:45:27.045594: step 117920, loss = 0.31, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 9h:16m:37s remains)
INFO - root - 2017-12-01 07:45:28.617135: step 117930, loss = 0.41, batch loss = 0.30 (51.1 examples/sec; 0.156 sec/batch; 9h:19m:24s remains)
INFO - root - 2017-12-01 07:45:30.181030: step 117940, loss = 0.32, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 9h:25m:44s remains)
INFO - root - 2017-12-01 07:45:31.745685: step 117950, loss = 0.31, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 9h:11m:27s remains)
INFO - root - 2017-12-01 07:45:33.315551: step 117960, loss = 0.30, batch loss = 0.19 (52.1 examples/sec; 0.154 sec/batch; 9h:09m:18s remains)
INFO - root - 2017-12-01 07:45:34.876880: step 117970, loss = 0.28, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 9h:14m:11s remains)
INFO - root - 2017-12-01 07:45:36.442757: step 117980, loss = 0.28, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 9h:18m:16s remains)
INFO - root - 2017-12-01 07:45:38.019175: step 117990, loss = 0.27, batch loss = 0.16 (49.4 examples/sec; 0.162 sec/batch; 9h:38m:56s remains)
INFO - root - 2017-12-01 07:45:39.567692: step 118000, loss = 0.27, batch loss = 0.17 (52.3 examples/sec; 0.153 sec/batch; 9h:06m:37s remains)
INFO - root - 2017-12-01 07:45:41.192941: step 118010, loss = 0.26, batch loss = 0.16 (51.0 examples/sec; 0.157 sec/batch; 9h:20m:30s remains)
INFO - root - 2017-12-01 07:45:42.785609: step 118020, loss = 0.30, batch loss = 0.20 (49.5 examples/sec; 0.162 sec/batch; 9h:37m:19s remains)
INFO - root - 2017-12-01 07:45:44.346645: step 118030, loss = 0.28, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 9h:25m:30s remains)
INFO - root - 2017-12-01 07:45:45.906221: step 118040, loss = 0.29, batch loss = 0.18 (52.2 examples/sec; 0.153 sec/batch; 9h:07m:42s remains)
INFO - root - 2017-12-01 07:45:47.473050: step 118050, loss = 0.26, batch loss = 0.15 (51.4 examples/sec; 0.156 sec/batch; 9h:16m:22s remains)
INFO - root - 2017-12-01 07:45:49.042047: step 118060, loss = 0.39, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 9h:24m:01s remains)
INFO - root - 2017-12-01 07:45:50.601884: step 118070, loss = 0.39, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 9h:25m:16s remains)
INFO - root - 2017-12-01 07:45:52.164996: step 118080, loss = 0.27, batch loss = 0.16 (53.3 examples/sec; 0.150 sec/batch; 8h:56m:19s remains)
INFO - root - 2017-12-01 07:45:53.734120: step 118090, loss = 0.32, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 9h:26m:02s remains)
INFO - root - 2017-12-01 07:45:55.303313: step 118100, loss = 0.42, batch loss = 0.31 (51.1 examples/sec; 0.157 sec/batch; 9h:19m:24s remains)
INFO - root - 2017-12-01 07:45:56.910866: step 118110, loss = 0.27, batch loss = 0.16 (48.8 examples/sec; 0.164 sec/batch; 9h:45m:30s remains)
INFO - root - 2017-12-01 07:45:58.494996: step 118120, loss = 0.31, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 9h:11m:30s remains)
INFO - root - 2017-12-01 07:46:00.057280: step 118130, loss = 0.38, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 9h:23m:16s remains)
INFO - root - 2017-12-01 07:46:01.615262: step 118140, loss = 0.29, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 9h:20m:05s remains)
INFO - root - 2017-12-01 07:46:03.177609: step 118150, loss = 0.38, batch loss = 0.28 (51.1 examples/sec; 0.157 sec/batch; 9h:19m:28s remains)
INFO - root - 2017-12-01 07:46:04.753654: step 118160, loss = 0.30, batch loss = 0.19 (53.0 examples/sec; 0.151 sec/batch; 8h:59m:37s remains)
INFO - root - 2017-12-01 07:46:06.317167: step 118170, loss = 0.31, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 9h:20m:18s remains)
INFO - root - 2017-12-01 07:46:07.886952: step 118180, loss = 0.33, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 9h:17m:31s remains)
INFO - root - 2017-12-01 07:46:09.447783: step 118190, loss = 0.31, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 9h:29m:56s remains)
INFO - root - 2017-12-01 07:46:11.001096: step 118200, loss = 0.31, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 9h:14m:02s remains)
INFO - root - 2017-12-01 07:46:12.605806: step 118210, loss = 0.32, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 9h:16m:05s remains)
INFO - root - 2017-12-01 07:46:14.161492: step 118220, loss = 0.38, batch loss = 0.28 (52.7 examples/sec; 0.152 sec/batch; 9h:02m:23s remains)
INFO - root - 2017-12-01 07:46:15.719435: step 118230, loss = 0.38, batch loss = 0.28 (51.1 examples/sec; 0.157 sec/batch; 9h:19m:33s remains)
INFO - root - 2017-12-01 07:46:17.276876: step 118240, loss = 0.34, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 9h:11m:17s remains)
INFO - root - 2017-12-01 07:46:18.844043: step 118250, loss = 0.31, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 9h:17m:32s remains)
INFO - root - 2017-12-01 07:46:20.396298: step 118260, loss = 0.33, batch loss = 0.23 (53.7 examples/sec; 0.149 sec/batch; 8h:52m:00s remains)
INFO - root - 2017-12-01 07:46:21.967385: step 118270, loss = 0.33, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 9h:09m:30s remains)
INFO - root - 2017-12-01 07:46:23.532659: step 118280, loss = 0.55, batch loss = 0.44 (50.8 examples/sec; 0.158 sec/batch; 9h:22m:29s remains)
INFO - root - 2017-12-01 07:46:25.096141: step 118290, loss = 0.26, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 9h:27m:09s remains)
INFO - root - 2017-12-01 07:46:26.668066: step 118300, loss = 0.29, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 9h:09m:06s remains)
INFO - root - 2017-12-01 07:46:28.286720: step 118310, loss = 0.43, batch loss = 0.33 (50.8 examples/sec; 0.157 sec/batch; 9h:22m:08s remains)
INFO - root - 2017-12-01 07:46:29.848043: step 118320, loss = 0.27, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 9h:13m:27s remains)
INFO - root - 2017-12-01 07:46:31.406430: step 118330, loss = 0.32, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 9h:09m:53s remains)
INFO - root - 2017-12-01 07:46:32.966809: step 118340, loss = 0.36, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 9h:06m:10s remains)
INFO - root - 2017-12-01 07:46:34.570693: step 118350, loss = 0.29, batch loss = 0.18 (49.9 examples/sec; 0.160 sec/batch; 9h:32m:38s remains)
INFO - root - 2017-12-01 07:46:36.128495: step 118360, loss = 0.32, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 9h:27m:23s remains)
INFO - root - 2017-12-01 07:46:37.684312: step 118370, loss = 0.31, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 9h:09m:24s remains)
INFO - root - 2017-12-01 07:46:39.241113: step 118380, loss = 0.33, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 9h:19m:13s remains)
INFO - root - 2017-12-01 07:46:40.808829: step 118390, loss = 0.35, batch loss = 0.24 (52.1 examples/sec; 0.154 sec/batch; 9h:08m:21s remains)
INFO - root - 2017-12-01 07:46:42.386309: step 118400, loss = 0.38, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 9h:15m:54s remains)
INFO - root - 2017-12-01 07:46:43.983642: step 118410, loss = 0.32, batch loss = 0.22 (49.6 examples/sec; 0.161 sec/batch; 9h:35m:25s remains)
INFO - root - 2017-12-01 07:46:45.545596: step 118420, loss = 0.41, batch loss = 0.31 (53.3 examples/sec; 0.150 sec/batch; 8h:55m:22s remains)
INFO - root - 2017-12-01 07:46:47.132755: step 118430, loss = 0.28, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 9h:20m:28s remains)
INFO - root - 2017-12-01 07:46:48.689387: step 118440, loss = 0.35, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 9h:09m:39s remains)
INFO - root - 2017-12-01 07:46:50.254156: step 118450, loss = 0.30, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 9h:30m:38s remains)
INFO - root - 2017-12-01 07:46:51.819851: step 118460, loss = 0.36, batch loss = 0.25 (52.2 examples/sec; 0.153 sec/batch; 9h:06m:40s remains)
INFO - root - 2017-12-01 07:46:53.382236: step 118470, loss = 0.46, batch loss = 0.35 (50.8 examples/sec; 0.157 sec/batch; 9h:21m:28s remains)
INFO - root - 2017-12-01 07:46:54.949688: step 118480, loss = 0.34, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 9h:15m:47s remains)
INFO - root - 2017-12-01 07:46:56.512322: step 118490, loss = 0.28, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 9h:19m:10s remains)
INFO - root - 2017-12-01 07:46:58.069205: step 118500, loss = 0.31, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 9h:29m:00s remains)
INFO - root - 2017-12-01 07:46:59.723259: step 118510, loss = 0.36, batch loss = 0.25 (50.2 examples/sec; 0.159 sec/batch; 9h:28m:23s remains)
INFO - root - 2017-12-01 07:47:01.289016: step 118520, loss = 0.35, batch loss = 0.25 (49.8 examples/sec; 0.161 sec/batch; 9h:33m:23s remains)
INFO - root - 2017-12-01 07:47:02.879659: step 118530, loss = 0.28, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 9h:13m:15s remains)
INFO - root - 2017-12-01 07:47:04.454809: step 118540, loss = 0.34, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 9h:24m:49s remains)
INFO - root - 2017-12-01 07:47:06.018431: step 118550, loss = 0.30, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 9h:10m:19s remains)
INFO - root - 2017-12-01 07:47:07.564839: step 118560, loss = 0.32, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 9h:20m:40s remains)
INFO - root - 2017-12-01 07:47:09.119512: step 118570, loss = 0.38, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 9h:15m:04s remains)
INFO - root - 2017-12-01 07:47:10.692820: step 118580, loss = 0.39, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 9h:15m:28s remains)
INFO - root - 2017-12-01 07:47:12.259821: step 118590, loss = 0.30, batch loss = 0.20 (50.5 examples/sec; 0.159 sec/batch; 9h:25m:18s remains)
INFO - root - 2017-12-01 07:47:13.876744: step 118600, loss = 0.29, batch loss = 0.18 (49.2 examples/sec; 0.162 sec/batch; 9h:39m:15s remains)
INFO - root - 2017-12-01 07:47:15.549929: step 118610, loss = 0.28, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 9h:19m:12s remains)
INFO - root - 2017-12-01 07:47:17.104429: step 118620, loss = 0.30, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 9h:23m:36s remains)
INFO - root - 2017-12-01 07:47:18.672491: step 118630, loss = 0.37, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 9h:01m:30s remains)
INFO - root - 2017-12-01 07:47:20.236376: step 118640, loss = 0.24, batch loss = 0.14 (50.9 examples/sec; 0.157 sec/batch; 9h:19m:45s remains)
INFO - root - 2017-12-01 07:47:21.806476: step 118650, loss = 0.31, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 9h:09m:42s remains)
INFO - root - 2017-12-01 07:47:23.365561: step 118660, loss = 0.42, batch loss = 0.31 (51.2 examples/sec; 0.156 sec/batch; 9h:17m:13s remains)
INFO - root - 2017-12-01 07:47:24.929504: step 118670, loss = 0.26, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 9h:16m:06s remains)
INFO - root - 2017-12-01 07:47:26.502112: step 118680, loss = 0.34, batch loss = 0.24 (52.8 examples/sec; 0.152 sec/batch; 9h:00m:05s remains)
INFO - root - 2017-12-01 07:47:28.064395: step 118690, loss = 0.31, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 9h:26m:03s remains)
INFO - root - 2017-12-01 07:47:29.680466: step 118700, loss = 0.33, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 9h:13m:54s remains)
INFO - root - 2017-12-01 07:47:31.322883: step 118710, loss = 0.36, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 9h:19m:46s remains)
INFO - root - 2017-12-01 07:47:32.892703: step 118720, loss = 0.29, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 9h:25m:16s remains)
INFO - root - 2017-12-01 07:47:34.443010: step 118730, loss = 0.33, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 9h:28m:42s remains)
INFO - root - 2017-12-01 07:47:36.002254: step 118740, loss = 0.40, batch loss = 0.29 (52.5 examples/sec; 0.152 sec/batch; 9h:02m:37s remains)
INFO - root - 2017-12-01 07:47:37.575806: step 118750, loss = 0.37, batch loss = 0.27 (51.9 examples/sec; 0.154 sec/batch; 9h:08m:46s remains)
INFO - root - 2017-12-01 07:47:39.148028: step 118760, loss = 0.28, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 9h:15m:27s remains)
INFO - root - 2017-12-01 07:47:40.728311: step 118770, loss = 0.30, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 9h:23m:58s remains)
INFO - root - 2017-12-01 07:47:42.281800: step 118780, loss = 0.32, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 9h:12m:29s remains)
INFO - root - 2017-12-01 07:47:43.845264: step 118790, loss = 0.31, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 9h:04m:51s remains)
INFO - root - 2017-12-01 07:47:45.409755: step 118800, loss = 0.47, batch loss = 0.36 (51.8 examples/sec; 0.154 sec/batch; 9h:09m:49s remains)
INFO - root - 2017-12-01 07:47:47.055850: step 118810, loss = 0.31, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 9h:22m:16s remains)
INFO - root - 2017-12-01 07:47:48.605639: step 118820, loss = 0.29, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 9h:23m:55s remains)
INFO - root - 2017-12-01 07:47:50.182442: step 118830, loss = 0.35, batch loss = 0.25 (52.6 examples/sec; 0.152 sec/batch; 9h:01m:36s remains)
INFO - root - 2017-12-01 07:47:51.751688: step 118840, loss = 0.36, batch loss = 0.26 (49.2 examples/sec; 0.163 sec/batch; 9h:38m:50s remains)
INFO - root - 2017-12-01 07:47:53.334054: step 118850, loss = 0.37, batch loss = 0.27 (49.5 examples/sec; 0.162 sec/batch; 9h:35m:45s remains)
INFO - root - 2017-12-01 07:47:54.899700: step 118860, loss = 0.26, batch loss = 0.15 (51.2 examples/sec; 0.156 sec/batch; 9h:16m:31s remains)
INFO - root - 2017-12-01 07:47:56.471468: step 118870, loss = 0.36, batch loss = 0.26 (53.1 examples/sec; 0.151 sec/batch; 8h:56m:23s remains)
INFO - root - 2017-12-01 07:47:58.062316: step 118880, loss = 0.27, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 9h:23m:53s remains)
INFO - root - 2017-12-01 07:47:59.608065: step 118890, loss = 0.35, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 9h:08m:40s remains)
INFO - root - 2017-12-01 07:48:01.157571: step 118900, loss = 0.34, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 9h:07m:55s remains)
INFO - root - 2017-12-01 07:48:02.802644: step 118910, loss = 0.24, batch loss = 0.13 (50.4 examples/sec; 0.159 sec/batch; 9h:24m:40s remains)
INFO - root - 2017-12-01 07:48:04.367751: step 118920, loss = 0.27, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 9h:26m:05s remains)
INFO - root - 2017-12-01 07:48:05.948753: step 118930, loss = 0.28, batch loss = 0.18 (52.2 examples/sec; 0.153 sec/batch; 9h:05m:06s remains)
INFO - root - 2017-12-01 07:48:07.531794: step 118940, loss = 0.26, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 9h:09m:11s remains)
INFO - root - 2017-12-01 07:48:09.089705: step 118950, loss = 0.26, batch loss = 0.15 (50.6 examples/sec; 0.158 sec/batch; 9h:22m:36s remains)
INFO - root - 2017-12-01 07:48:10.671314: step 118960, loss = 0.28, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 9h:18m:11s remains)
INFO - root - 2017-12-01 07:48:12.276285: step 118970, loss = 0.31, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 9h:28m:07s remains)
INFO - root - 2017-12-01 07:48:13.871632: step 118980, loss = 0.28, batch loss = 0.17 (48.7 examples/sec; 0.164 sec/batch; 9h:44m:40s remains)
INFO - root - 2017-12-01 07:48:15.428068: step 118990, loss = 0.26, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 9h:11m:47s remains)
INFO - root - 2017-12-01 07:48:17.003675: step 119000, loss = 0.49, batch loss = 0.39 (49.8 examples/sec; 0.161 sec/batch; 9h:31m:47s remains)
INFO - root - 2017-12-01 07:48:18.674330: step 119010, loss = 0.24, batch loss = 0.14 (53.1 examples/sec; 0.151 sec/batch; 8h:56m:05s remains)
INFO - root - 2017-12-01 07:48:20.244532: step 119020, loss = 0.32, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 9h:18m:30s remains)
INFO - root - 2017-12-01 07:48:21.807139: step 119030, loss = 0.37, batch loss = 0.27 (51.7 examples/sec; 0.155 sec/batch; 9h:10m:20s remains)
INFO - root - 2017-12-01 07:48:23.366715: step 119040, loss = 0.33, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 9h:09m:58s remains)
INFO - root - 2017-12-01 07:48:24.945303: step 119050, loss = 0.34, batch loss = 0.23 (49.3 examples/sec; 0.162 sec/batch; 9h:37m:19s remains)
INFO - root - 2017-12-01 07:48:26.539148: step 119060, loss = 0.47, batch loss = 0.37 (51.4 examples/sec; 0.156 sec/batch; 9h:13m:37s remains)
INFO - root - 2017-12-01 07:48:28.111650: step 119070, loss = 0.32, batch loss = 0.22 (49.0 examples/sec; 0.163 sec/batch; 9h:40m:53s remains)
INFO - root - 2017-12-01 07:48:29.670717: step 119080, loss = 0.39, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 9h:25m:55s remains)
INFO - root - 2017-12-01 07:48:31.229974: step 119090, loss = 0.30, batch loss = 0.20 (50.0 examples/sec; 0.160 sec/batch; 9h:28m:48s remains)
INFO - root - 2017-12-01 07:48:32.807770: step 119100, loss = 0.24, batch loss = 0.14 (52.7 examples/sec; 0.152 sec/batch; 9h:00m:01s remains)
INFO - root - 2017-12-01 07:48:34.457636: step 119110, loss = 0.27, batch loss = 0.17 (49.7 examples/sec; 0.161 sec/batch; 9h:32m:44s remains)
INFO - root - 2017-12-01 07:48:36.028857: step 119120, loss = 0.31, batch loss = 0.20 (52.8 examples/sec; 0.152 sec/batch; 8h:59m:12s remains)
INFO - root - 2017-12-01 07:48:37.597352: step 119130, loss = 0.31, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 9h:06m:24s remains)
INFO - root - 2017-12-01 07:48:39.156896: step 119140, loss = 0.31, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 9h:18m:00s remains)
INFO - root - 2017-12-01 07:48:40.716737: step 119150, loss = 0.29, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 9h:03m:48s remains)
INFO - root - 2017-12-01 07:48:42.287529: step 119160, loss = 0.31, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 9h:14m:56s remains)
INFO - root - 2017-12-01 07:48:43.856374: step 119170, loss = 0.32, batch loss = 0.21 (47.6 examples/sec; 0.168 sec/batch; 9h:57m:53s remains)
INFO - root - 2017-12-01 07:48:45.407127: step 119180, loss = 0.27, batch loss = 0.16 (52.2 examples/sec; 0.153 sec/batch; 9h:04m:32s remains)
INFO - root - 2017-12-01 07:48:46.988529: step 119190, loss = 0.29, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 9h:17m:44s remains)
INFO - root - 2017-12-01 07:48:48.545267: step 119200, loss = 0.36, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 9h:17m:28s remains)
INFO - root - 2017-12-01 07:48:50.200307: step 119210, loss = 0.25, batch loss = 0.15 (50.5 examples/sec; 0.158 sec/batch; 9h:22m:37s remains)
INFO - root - 2017-12-01 07:48:51.776712: step 119220, loss = 0.28, batch loss = 0.18 (49.2 examples/sec; 0.162 sec/batch; 9h:37m:30s remains)
INFO - root - 2017-12-01 07:48:53.331900: step 119230, loss = 0.30, batch loss = 0.20 (49.8 examples/sec; 0.161 sec/batch; 9h:30m:48s remains)
INFO - root - 2017-12-01 07:48:54.885193: step 119240, loss = 0.34, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 9h:04m:39s remains)
INFO - root - 2017-12-01 07:48:56.436794: step 119250, loss = 0.30, batch loss = 0.20 (52.5 examples/sec; 0.152 sec/batch; 9h:01m:50s remains)
INFO - root - 2017-12-01 07:48:57.997185: step 119260, loss = 0.29, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 9h:08m:06s remains)
INFO - root - 2017-12-01 07:48:59.572154: step 119270, loss = 0.30, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 9h:30m:14s remains)
INFO - root - 2017-12-01 07:49:01.145575: step 119280, loss = 0.34, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 9h:14m:03s remains)
INFO - root - 2017-12-01 07:49:02.694320: step 119290, loss = 0.43, batch loss = 0.32 (51.8 examples/sec; 0.154 sec/batch; 9h:08m:46s remains)
INFO - root - 2017-12-01 07:49:04.262880: step 119300, loss = 0.26, batch loss = 0.16 (50.5 examples/sec; 0.158 sec/batch; 9h:22m:51s remains)
INFO - root - 2017-12-01 07:49:05.865921: step 119310, loss = 0.27, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 9h:18m:40s remains)
INFO - root - 2017-12-01 07:49:07.430210: step 119320, loss = 0.38, batch loss = 0.28 (51.7 examples/sec; 0.155 sec/batch; 9h:09m:34s remains)
INFO - root - 2017-12-01 07:49:09.009254: step 119330, loss = 0.31, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 9h:07m:28s remains)
INFO - root - 2017-12-01 07:49:10.565894: step 119340, loss = 0.37, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 9h:17m:41s remains)
INFO - root - 2017-12-01 07:49:12.153744: step 119350, loss = 0.32, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 9h:21m:15s remains)
INFO - root - 2017-12-01 07:49:13.698964: step 119360, loss = 0.27, batch loss = 0.17 (52.1 examples/sec; 0.154 sec/batch; 9h:05m:18s remains)
INFO - root - 2017-12-01 07:49:15.249387: step 119370, loss = 0.37, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 9h:06m:14s remains)
INFO - root - 2017-12-01 07:49:16.813467: step 119380, loss = 0.30, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 9h:14m:09s remains)
INFO - root - 2017-12-01 07:49:18.376072: step 119390, loss = 0.33, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 9h:14m:21s remains)
INFO - root - 2017-12-01 07:49:19.953261: step 119400, loss = 0.31, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 9h:15m:31s remains)
INFO - root - 2017-12-01 07:49:21.626781: step 119410, loss = 0.41, batch loss = 0.31 (51.7 examples/sec; 0.155 sec/batch; 9h:09m:13s remains)
INFO - root - 2017-12-01 07:49:23.189561: step 119420, loss = 0.32, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 9h:21m:56s remains)
INFO - root - 2017-12-01 07:49:24.726642: step 119430, loss = 0.32, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 9h:14m:44s remains)
INFO - root - 2017-12-01 07:49:26.293441: step 119440, loss = 0.28, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 9h:13m:39s remains)
INFO - root - 2017-12-01 07:49:27.849686: step 119450, loss = 0.26, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 9h:14m:46s remains)
INFO - root - 2017-12-01 07:49:29.431628: step 119460, loss = 0.28, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 9h:09m:15s remains)
INFO - root - 2017-12-01 07:49:30.986710: step 119470, loss = 0.27, batch loss = 0.17 (52.3 examples/sec; 0.153 sec/batch; 9h:02m:35s remains)
INFO - root - 2017-12-01 07:49:32.555638: step 119480, loss = 0.29, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 9h:28m:40s remains)
INFO - root - 2017-12-01 07:49:34.116091: step 119490, loss = 0.31, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 9h:04m:09s remains)
INFO - root - 2017-12-01 07:49:35.676365: step 119500, loss = 0.29, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 9h:07m:54s remains)
INFO - root - 2017-12-01 07:49:37.293800: step 119510, loss = 0.25, batch loss = 0.15 (50.8 examples/sec; 0.158 sec/batch; 9h:19m:25s remains)
INFO - root - 2017-12-01 07:49:38.871542: step 119520, loss = 0.27, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 9h:11m:33s remains)
INFO - root - 2017-12-01 07:49:40.437656: step 119530, loss = 0.27, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 9h:20m:33s remains)
INFO - root - 2017-12-01 07:49:42.016952: step 119540, loss = 0.31, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 9h:07m:01s remains)
INFO - root - 2017-12-01 07:49:43.576524: step 119550, loss = 0.28, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 9h:20m:44s remains)
INFO - root - 2017-12-01 07:49:45.134462: step 119560, loss = 0.29, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 9h:18m:08s remains)
INFO - root - 2017-12-01 07:49:46.710758: step 119570, loss = 0.37, batch loss = 0.27 (47.9 examples/sec; 0.167 sec/batch; 9h:52m:34s remains)
INFO - root - 2017-12-01 07:49:48.281714: step 119580, loss = 0.49, batch loss = 0.39 (51.4 examples/sec; 0.156 sec/batch; 9h:12m:43s remains)
INFO - root - 2017-12-01 07:49:49.840280: step 119590, loss = 0.33, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 9h:10m:02s remains)
INFO - root - 2017-12-01 07:49:51.423006: step 119600, loss = 0.31, batch loss = 0.20 (49.6 examples/sec; 0.161 sec/batch; 9h:32m:00s remains)
INFO - root - 2017-12-01 07:49:53.066132: step 119610, loss = 0.34, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 9h:23m:13s remains)
INFO - root - 2017-12-01 07:49:54.638085: step 119620, loss = 0.25, batch loss = 0.15 (50.3 examples/sec; 0.159 sec/batch; 9h:24m:33s remains)
INFO - root - 2017-12-01 07:49:56.204885: step 119630, loss = 0.28, batch loss = 0.18 (51.8 examples/sec; 0.155 sec/batch; 9h:08m:23s remains)
INFO - root - 2017-12-01 07:49:57.742797: step 119640, loss = 0.30, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 9h:07m:35s remains)
INFO - root - 2017-12-01 07:49:59.299235: step 119650, loss = 0.34, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 9h:14m:15s remains)
INFO - root - 2017-12-01 07:50:00.863540: step 119660, loss = 0.26, batch loss = 0.16 (52.2 examples/sec; 0.153 sec/batch; 9h:04m:09s remains)
INFO - root - 2017-12-01 07:50:02.433514: step 119670, loss = 0.31, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 9h:12m:35s remains)
INFO - root - 2017-12-01 07:50:03.992218: step 119680, loss = 0.32, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 9h:18m:24s remains)
INFO - root - 2017-12-01 07:50:05.557429: step 119690, loss = 0.30, batch loss = 0.19 (51.1 examples/sec; 0.156 sec/batch; 9h:14m:53s remains)
INFO - root - 2017-12-01 07:50:07.120901: step 119700, loss = 0.30, batch loss = 0.19 (53.5 examples/sec; 0.149 sec/batch; 8h:49m:58s remains)
INFO - root - 2017-12-01 07:50:08.740560: step 119710, loss = 0.37, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 9h:12m:50s remains)
INFO - root - 2017-12-01 07:50:10.332183: step 119720, loss = 0.35, batch loss = 0.24 (48.5 examples/sec; 0.165 sec/batch; 9h:44m:51s remains)
INFO - root - 2017-12-01 07:50:11.906630: step 119730, loss = 0.28, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 9h:16m:41s remains)
INFO - root - 2017-12-01 07:50:13.495554: step 119740, loss = 0.41, batch loss = 0.30 (51.9 examples/sec; 0.154 sec/batch; 9h:07m:04s remains)
INFO - root - 2017-12-01 07:50:15.056199: step 119750, loss = 0.25, batch loss = 0.15 (51.0 examples/sec; 0.157 sec/batch; 9h:16m:01s remains)
INFO - root - 2017-12-01 07:50:16.626396: step 119760, loss = 0.29, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 9h:09m:14s remains)
INFO - root - 2017-12-01 07:50:18.196908: step 119770, loss = 0.31, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 9h:02m:57s remains)
INFO - root - 2017-12-01 07:50:19.756675: step 119780, loss = 0.32, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 9h:02m:37s remains)
INFO - root - 2017-12-01 07:50:21.343820: step 119790, loss = 0.26, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 9h:11m:37s remains)
INFO - root - 2017-12-01 07:50:22.910704: step 119800, loss = 0.37, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 9h:20m:35s remains)
INFO - root - 2017-12-01 07:50:24.550673: step 119810, loss = 0.33, batch loss = 0.23 (51.4 examples/sec; 0.155 sec/batch; 9h:11m:11s remains)
INFO - root - 2017-12-01 07:50:26.108304: step 119820, loss = 0.28, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 9h:19m:26s remains)
INFO - root - 2017-12-01 07:50:27.665653: step 119830, loss = 0.34, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 9h:13m:58s remains)
INFO - root - 2017-12-01 07:50:29.227446: step 119840, loss = 0.35, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 9h:15m:33s remains)
INFO - root - 2017-12-01 07:50:30.802281: step 119850, loss = 0.40, batch loss = 0.30 (51.3 examples/sec; 0.156 sec/batch; 9h:12m:18s remains)
INFO - root - 2017-12-01 07:50:32.374498: step 119860, loss = 0.27, batch loss = 0.17 (50.1 examples/sec; 0.160 sec/batch; 9h:25m:46s remains)
INFO - root - 2017-12-01 07:50:33.924065: step 119870, loss = 0.38, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 9h:16m:01s remains)
INFO - root - 2017-12-01 07:50:35.499585: step 119880, loss = 0.29, batch loss = 0.19 (48.7 examples/sec; 0.164 sec/batch; 9h:42m:28s remains)
INFO - root - 2017-12-01 07:50:37.053841: step 119890, loss = 0.26, batch loss = 0.16 (52.6 examples/sec; 0.152 sec/batch; 8h:59m:17s remains)
INFO - root - 2017-12-01 07:50:38.618993: step 119900, loss = 0.26, batch loss = 0.15 (53.0 examples/sec; 0.151 sec/batch; 8h:54m:58s remains)
INFO - root - 2017-12-01 07:50:40.284672: step 119910, loss = 0.31, batch loss = 0.20 (49.0 examples/sec; 0.163 sec/batch; 9h:39m:01s remains)
INFO - root - 2017-12-01 07:50:41.848491: step 119920, loss = 0.32, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 9h:02m:09s remains)
INFO - root - 2017-12-01 07:50:43.417196: step 119930, loss = 0.38, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 9h:20m:24s remains)
INFO - root - 2017-12-01 07:50:44.988831: step 119940, loss = 0.29, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 9h:13m:15s remains)
INFO - root - 2017-12-01 07:50:46.541812: step 119950, loss = 0.34, batch loss = 0.24 (52.4 examples/sec; 0.153 sec/batch; 9h:01m:10s remains)
INFO - root - 2017-12-01 07:50:48.099291: step 119960, loss = 0.27, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 9h:10m:11s remains)
INFO - root - 2017-12-01 07:50:49.688966: step 119970, loss = 0.30, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 9h:26m:44s remains)
INFO - root - 2017-12-01 07:50:51.238543: step 119980, loss = 0.34, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 9h:08m:06s remains)
INFO - root - 2017-12-01 07:50:52.806551: step 119990, loss = 0.26, batch loss = 0.16 (50.0 examples/sec; 0.160 sec/batch; 9h:26m:58s remains)
INFO - root - 2017-12-01 07:50:54.363539: step 120000, loss = 0.40, batch loss = 0.29 (52.1 examples/sec; 0.153 sec/batch; 9h:03m:33s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-120000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-120000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-01 07:50:56.247320: step 120010, loss = 0.33, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 9h:08m:24s remains)
INFO - root - 2017-12-01 07:50:57.802714: step 120020, loss = 0.30, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 9h:09m:23s remains)
INFO - root - 2017-12-01 07:50:59.385935: step 120030, loss = 0.26, batch loss = 0.15 (52.4 examples/sec; 0.153 sec/batch; 9h:01m:04s remains)
INFO - root - 2017-12-01 07:51:00.951675: step 120040, loss = 0.40, batch loss = 0.30 (50.6 examples/sec; 0.158 sec/batch; 9h:19m:58s remains)
INFO - root - 2017-12-01 07:51:02.517733: step 120050, loss = 0.24, batch loss = 0.14 (51.7 examples/sec; 0.155 sec/batch; 9h:07m:55s remains)
INFO - root - 2017-12-01 07:51:04.085069: step 120060, loss = 0.34, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 9h:01m:25s remains)
INFO - root - 2017-12-01 07:51:05.661926: step 120070, loss = 0.29, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 9h:14m:37s remains)
INFO - root - 2017-12-01 07:51:07.216141: step 120080, loss = 0.32, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 9h:07m:52s remains)
INFO - root - 2017-12-01 07:51:08.776417: step 120090, loss = 0.27, batch loss = 0.17 (50.2 examples/sec; 0.159 sec/batch; 9h:24m:18s remains)
INFO - root - 2017-12-01 07:51:10.365113: step 120100, loss = 0.25, batch loss = 0.14 (47.7 examples/sec; 0.168 sec/batch; 9h:53m:05s remains)
INFO - root - 2017-12-01 07:51:12.031616: step 120110, loss = 0.25, batch loss = 0.15 (50.4 examples/sec; 0.159 sec/batch; 9h:22m:03s remains)
INFO - root - 2017-12-01 07:51:13.598493: step 120120, loss = 0.30, batch loss = 0.20 (52.9 examples/sec; 0.151 sec/batch; 8h:55m:19s remains)
INFO - root - 2017-12-01 07:51:15.164659: step 120130, loss = 0.35, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 9h:07m:22s remains)
INFO - root - 2017-12-01 07:51:16.737884: step 120140, loss = 0.38, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 9h:20m:10s remains)
INFO - root - 2017-12-01 07:51:18.304383: step 120150, loss = 0.31, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 9h:17m:00s remains)
INFO - root - 2017-12-01 07:51:19.860450: step 120160, loss = 0.28, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 9h:11m:08s remains)
INFO - root - 2017-12-01 07:51:21.431735: step 120170, loss = 0.31, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 9h:15m:03s remains)
INFO - root - 2017-12-01 07:51:23.012790: step 120180, loss = 0.47, batch loss = 0.37 (52.3 examples/sec; 0.153 sec/batch; 9h:01m:45s remains)
INFO - root - 2017-12-01 07:51:24.584414: step 120190, loss = 0.25, batch loss = 0.14 (50.6 examples/sec; 0.158 sec/batch; 9h:18m:58s remains)
INFO - root - 2017-12-01 07:51:26.155645: step 120200, loss = 0.35, batch loss = 0.25 (51.8 examples/sec; 0.155 sec/batch; 9h:06m:44s remains)
INFO - root - 2017-12-01 07:51:27.788023: step 120210, loss = 0.32, batch loss = 0.22 (51.1 examples/sec; 0.156 sec/batch; 9h:13m:25s remains)
INFO - root - 2017-12-01 07:51:29.347006: step 120220, loss = 0.27, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 9h:22m:10s remains)
INFO - root - 2017-12-01 07:51:30.916236: step 120230, loss = 0.25, batch loss = 0.15 (49.6 examples/sec; 0.161 sec/batch; 9h:30m:53s remains)
INFO - root - 2017-12-01 07:51:32.496884: step 120240, loss = 0.27, batch loss = 0.16 (50.8 examples/sec; 0.158 sec/batch; 9h:17m:30s remains)
INFO - root - 2017-12-01 07:51:34.067329: step 120250, loss = 0.43, batch loss = 0.33 (50.9 examples/sec; 0.157 sec/batch; 9h:16m:06s remains)
INFO - root - 2017-12-01 07:51:35.636277: step 120260, loss = 0.44, batch loss = 0.34 (50.6 examples/sec; 0.158 sec/batch; 9h:18m:59s remains)
INFO - root - 2017-12-01 07:51:37.190895: step 120270, loss = 0.34, batch loss = 0.24 (50.2 examples/sec; 0.159 sec/batch; 9h:23m:58s remains)
INFO - root - 2017-12-01 07:51:38.753781: step 120280, loss = 0.26, batch loss = 0.16 (53.1 examples/sec; 0.151 sec/batch; 8h:53m:11s remains)
INFO - root - 2017-12-01 07:51:40.319600: step 120290, loss = 0.24, batch loss = 0.14 (50.7 examples/sec; 0.158 sec/batch; 9h:17m:34s remains)
INFO - root - 2017-12-01 07:51:41.891045: step 120300, loss = 0.35, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 9h:11m:46s remains)
INFO - root - 2017-12-01 07:51:43.507090: step 120310, loss = 0.28, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 9h:00m:48s remains)
INFO - root - 2017-12-01 07:51:45.065647: step 120320, loss = 0.28, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 9h:09m:20s remains)
INFO - root - 2017-12-01 07:51:46.624423: step 120330, loss = 0.28, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 9h:07m:16s remains)
INFO - root - 2017-12-01 07:51:48.175990: step 120340, loss = 0.30, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 9h:12m:05s remains)
INFO - root - 2017-12-01 07:51:49.754341: step 120350, loss = 0.32, batch loss = 0.21 (48.6 examples/sec; 0.165 sec/batch; 9h:42m:37s remains)
INFO - root - 2017-12-01 07:51:51.315554: step 120360, loss = 0.34, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 9h:15m:52s remains)
INFO - root - 2017-12-01 07:51:52.888659: step 120370, loss = 0.26, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 9h:06m:02s remains)
INFO - root - 2017-12-01 07:51:54.527798: step 120380, loss = 0.29, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 9h:19m:23s remains)
INFO - root - 2017-12-01 07:51:56.090069: step 120390, loss = 0.28, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 9h:09m:22s remains)
INFO - root - 2017-12-01 07:51:57.652252: step 120400, loss = 0.35, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 9h:07m:38s remains)
INFO - root - 2017-12-01 07:51:59.290120: step 120410, loss = 0.38, batch loss = 0.28 (49.2 examples/sec; 0.163 sec/batch; 9h:35m:07s remains)
INFO - root - 2017-12-01 07:52:00.849680: step 120420, loss = 0.25, batch loss = 0.15 (52.8 examples/sec; 0.152 sec/batch; 8h:55m:56s remains)
INFO - root - 2017-12-01 07:52:02.417944: step 120430, loss = 0.31, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 9h:15m:21s remains)
INFO - root - 2017-12-01 07:52:03.994606: step 120440, loss = 0.40, batch loss = 0.30 (49.5 examples/sec; 0.161 sec/batch; 9h:30m:40s remains)
INFO - root - 2017-12-01 07:52:05.562976: step 120450, loss = 0.27, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 9h:05m:03s remains)
INFO - root - 2017-12-01 07:52:07.141471: step 120460, loss = 0.30, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 9h:01m:10s remains)
INFO - root - 2017-12-01 07:52:08.693292: step 120470, loss = 0.31, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 8h:58m:53s remains)
INFO - root - 2017-12-01 07:52:10.238924: step 120480, loss = 0.33, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 8h:55m:54s remains)
INFO - root - 2017-12-01 07:52:11.799577: step 120490, loss = 0.28, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 9h:15m:36s remains)
INFO - root - 2017-12-01 07:52:13.348987: step 120500, loss = 0.28, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 9h:15m:46s remains)
INFO - root - 2017-12-01 07:52:14.953230: step 120510, loss = 0.39, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 9h:10m:59s remains)
INFO - root - 2017-12-01 07:52:16.521102: step 120520, loss = 0.37, batch loss = 0.27 (51.2 examples/sec; 0.156 sec/batch; 9h:12m:06s remains)
INFO - root - 2017-12-01 07:52:18.091176: step 120530, loss = 0.35, batch loss = 0.25 (50.2 examples/sec; 0.159 sec/batch; 9h:23m:08s remains)
INFO - root - 2017-12-01 07:52:19.650765: step 120540, loss = 0.32, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 9h:21m:08s remains)
INFO - root - 2017-12-01 07:52:21.219695: step 120550, loss = 0.37, batch loss = 0.27 (48.8 examples/sec; 0.164 sec/batch; 9h:39m:32s remains)
INFO - root - 2017-12-01 07:52:22.796646: step 120560, loss = 0.30, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 9h:00m:20s remains)
INFO - root - 2017-12-01 07:52:24.369498: step 120570, loss = 0.35, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 9h:06m:50s remains)
INFO - root - 2017-12-01 07:52:25.964804: step 120580, loss = 0.38, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 9h:07m:43s remains)
INFO - root - 2017-12-01 07:52:27.531330: step 120590, loss = 0.26, batch loss = 0.15 (51.6 examples/sec; 0.155 sec/batch; 9h:07m:38s remains)
INFO - root - 2017-12-01 07:52:29.106211: step 120600, loss = 0.30, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 9h:13m:35s remains)
INFO - root - 2017-12-01 07:52:30.759920: step 120610, loss = 0.45, batch loss = 0.34 (53.0 examples/sec; 0.151 sec/batch; 8h:53m:29s remains)
INFO - root - 2017-12-01 07:52:32.327987: step 120620, loss = 0.29, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 9h:15m:15s remains)
INFO - root - 2017-12-01 07:52:33.898997: step 120630, loss = 0.35, batch loss = 0.25 (50.8 examples/sec; 0.158 sec/batch; 9h:16m:24s remains)
INFO - root - 2017-12-01 07:52:35.464120: step 120640, loss = 0.34, batch loss = 0.23 (49.7 examples/sec; 0.161 sec/batch; 9h:28m:22s remains)
INFO - root - 2017-12-01 07:52:37.024771: step 120650, loss = 0.33, batch loss = 0.23 (49.1 examples/sec; 0.163 sec/batch; 9h:34m:42s remains)
INFO - root - 2017-12-01 07:52:38.616733: step 120660, loss = 0.28, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 9h:06m:11s remains)
INFO - root - 2017-12-01 07:52:40.193567: step 120670, loss = 0.25, batch loss = 0.15 (50.9 examples/sec; 0.157 sec/batch; 9h:14m:51s remains)
INFO - root - 2017-12-01 07:52:41.750129: step 120680, loss = 0.26, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 9h:06m:51s remains)
INFO - root - 2017-12-01 07:52:43.305005: step 120690, loss = 0.35, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 9h:07m:12s remains)
INFO - root - 2017-12-01 07:52:44.872834: step 120700, loss = 0.32, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 9h:07m:57s remains)
INFO - root - 2017-12-01 07:52:46.518237: step 120710, loss = 0.27, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 9h:20m:22s remains)
INFO - root - 2017-12-01 07:52:48.069608: step 120720, loss = 0.29, batch loss = 0.19 (52.9 examples/sec; 0.151 sec/batch; 8h:53m:32s remains)
INFO - root - 2017-12-01 07:52:49.643204: step 120730, loss = 0.33, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 9h:04m:56s remains)
INFO - root - 2017-12-01 07:52:51.209822: step 120740, loss = 0.41, batch loss = 0.31 (52.8 examples/sec; 0.152 sec/batch; 8h:55m:07s remains)
INFO - root - 2017-12-01 07:52:52.754496: step 120750, loss = 0.32, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 9h:08m:41s remains)
INFO - root - 2017-12-01 07:52:54.319100: step 120760, loss = 0.29, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 9h:29m:57s remains)
INFO - root - 2017-12-01 07:52:55.875754: step 120770, loss = 0.36, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 9h:09m:43s remains)
INFO - root - 2017-12-01 07:52:57.423012: step 120780, loss = 0.27, batch loss = 0.16 (53.1 examples/sec; 0.151 sec/batch; 8h:51m:50s remains)
INFO - root - 2017-12-01 07:52:58.976393: step 120790, loss = 0.31, batch loss = 0.21 (53.5 examples/sec; 0.150 sec/batch; 8h:47m:39s remains)
INFO - root - 2017-12-01 07:53:00.534330: step 120800, loss = 0.26, batch loss = 0.15 (51.9 examples/sec; 0.154 sec/batch; 9h:03m:23s remains)
INFO - root - 2017-12-01 07:53:02.148348: step 120810, loss = 0.32, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 9h:04m:35s remains)
INFO - root - 2017-12-01 07:53:03.709108: step 120820, loss = 0.27, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 9h:03m:47s remains)
INFO - root - 2017-12-01 07:53:05.267769: step 120830, loss = 0.26, batch loss = 0.16 (51.7 examples/sec; 0.155 sec/batch; 9h:06m:05s remains)
INFO - root - 2017-12-01 07:53:06.837812: step 120840, loss = 0.28, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 9h:06m:27s remains)
INFO - root - 2017-12-01 07:53:08.409717: step 120850, loss = 0.29, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 9h:16m:32s remains)
INFO - root - 2017-12-01 07:53:10.010395: step 120860, loss = 0.30, batch loss = 0.19 (49.4 examples/sec; 0.162 sec/batch; 9h:31m:15s remains)
INFO - root - 2017-12-01 07:53:11.642672: step 120870, loss = 0.31, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 9h:19m:22s remains)
INFO - root - 2017-12-01 07:53:13.218246: step 120880, loss = 0.27, batch loss = 0.16 (49.6 examples/sec; 0.161 sec/batch; 9h:28m:26s remains)
INFO - root - 2017-12-01 07:53:14.777801: step 120890, loss = 0.27, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 9h:16m:46s remains)
INFO - root - 2017-12-01 07:53:16.346482: step 120900, loss = 0.36, batch loss = 0.26 (52.3 examples/sec; 0.153 sec/batch; 8h:59m:36s remains)
INFO - root - 2017-12-01 07:53:17.959222: step 120910, loss = 0.32, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 9h:14m:15s remains)
INFO - root - 2017-12-01 07:53:19.504448: step 120920, loss = 0.34, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 9h:13m:17s remains)
INFO - root - 2017-12-01 07:53:21.096600: step 120930, loss = 0.27, batch loss = 0.16 (48.2 examples/sec; 0.166 sec/batch; 9h:45m:25s remains)
INFO - root - 2017-12-01 07:53:22.657984: step 120940, loss = 0.32, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 9h:21m:30s remains)
INFO - root - 2017-12-01 07:53:24.242528: step 120950, loss = 0.42, batch loss = 0.32 (50.2 examples/sec; 0.159 sec/batch; 9h:22m:20s remains)
INFO - root - 2017-12-01 07:53:25.811366: step 120960, loss = 0.31, batch loss = 0.21 (48.6 examples/sec; 0.165 sec/batch; 9h:40m:39s remains)
INFO - root - 2017-12-01 07:53:27.361406: step 120970, loss = 0.29, batch loss = 0.19 (51.8 examples/sec; 0.155 sec/batch; 9h:04m:43s remains)
INFO - root - 2017-12-01 07:53:28.938275: step 120980, loss = 0.49, batch loss = 0.39 (52.3 examples/sec; 0.153 sec/batch; 8h:59m:09s remains)
INFO - root - 2017-12-01 07:53:30.505158: step 120990, loss = 0.32, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 9h:09m:25s remains)
INFO - root - 2017-12-01 07:53:32.070757: step 121000, loss = 0.32, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 9h:13m:54s remains)
INFO - root - 2017-12-01 07:53:33.762975: step 121010, loss = 0.29, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 9h:11m:05s remains)
INFO - root - 2017-12-01 07:53:35.320591: step 121020, loss = 0.28, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 9h:17m:28s remains)
INFO - root - 2017-12-01 07:53:36.879691: step 121030, loss = 0.45, batch loss = 0.35 (52.7 examples/sec; 0.152 sec/batch; 8h:55m:16s remains)
INFO - root - 2017-12-01 07:53:38.438979: step 121040, loss = 0.28, batch loss = 0.18 (52.1 examples/sec; 0.153 sec/batch; 9h:00m:48s remains)
INFO - root - 2017-12-01 07:53:40.009169: step 121050, loss = 0.22, batch loss = 0.12 (51.8 examples/sec; 0.155 sec/batch; 9h:04m:30s remains)
INFO - root - 2017-12-01 07:53:41.564184: step 121060, loss = 0.31, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 9h:00m:05s remains)
INFO - root - 2017-12-01 07:53:43.122883: step 121070, loss = 0.29, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 9h:05m:22s remains)
INFO - root - 2017-12-01 07:53:44.691005: step 121080, loss = 0.27, batch loss = 0.16 (50.0 examples/sec; 0.160 sec/batch; 9h:23m:26s remains)
INFO - root - 2017-12-01 07:53:46.264332: step 121090, loss = 0.34, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 9h:10m:50s remains)
INFO - root - 2017-12-01 07:53:47.826235: step 121100, loss = 0.32, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 8h:58m:52s remains)
INFO - root - 2017-12-01 07:53:49.431126: step 121110, loss = 0.27, batch loss = 0.17 (52.1 examples/sec; 0.154 sec/batch; 9h:01m:26s remains)
INFO - root - 2017-12-01 07:53:50.991674: step 121120, loss = 0.25, batch loss = 0.15 (52.6 examples/sec; 0.152 sec/batch; 8h:55m:22s remains)
INFO - root - 2017-12-01 07:53:52.548866: step 121130, loss = 0.35, batch loss = 0.25 (53.0 examples/sec; 0.151 sec/batch; 8h:51m:54s remains)
INFO - root - 2017-12-01 07:53:54.127554: step 121140, loss = 0.26, batch loss = 0.16 (52.9 examples/sec; 0.151 sec/batch; 8h:52m:49s remains)
INFO - root - 2017-12-01 07:53:55.695647: step 121150, loss = 0.26, batch loss = 0.16 (48.8 examples/sec; 0.164 sec/batch; 9h:37m:10s remains)
INFO - root - 2017-12-01 07:53:57.264756: step 121160, loss = 0.37, batch loss = 0.27 (49.7 examples/sec; 0.161 sec/batch; 9h:27m:09s remains)
INFO - root - 2017-12-01 07:53:58.824653: step 121170, loss = 0.31, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 9h:10m:11s remains)
INFO - root - 2017-12-01 07:54:00.403732: step 121180, loss = 0.30, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 8h:58m:59s remains)
INFO - root - 2017-12-01 07:54:01.967183: step 121190, loss = 0.40, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 9h:13m:16s remains)
INFO - root - 2017-12-01 07:54:03.537997: step 121200, loss = 0.27, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 9h:01m:54s remains)
INFO - root - 2017-12-01 07:54:05.200448: step 121210, loss = 0.40, batch loss = 0.30 (50.2 examples/sec; 0.159 sec/batch; 9h:21m:30s remains)
INFO - root - 2017-12-01 07:54:06.776232: step 121220, loss = 0.34, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 9h:15m:15s remains)
INFO - root - 2017-12-01 07:54:08.328183: step 121230, loss = 0.40, batch loss = 0.30 (50.0 examples/sec; 0.160 sec/batch; 9h:23m:05s remains)
INFO - root - 2017-12-01 07:54:09.888314: step 121240, loss = 0.31, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 9h:08m:19s remains)
INFO - root - 2017-12-01 07:54:11.444000: step 121250, loss = 0.34, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 9h:13m:21s remains)
INFO - root - 2017-12-01 07:54:13.011619: step 121260, loss = 0.32, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 9h:18m:58s remains)
INFO - root - 2017-12-01 07:54:14.573569: step 121270, loss = 0.32, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 9h:19m:26s remains)
INFO - root - 2017-12-01 07:54:16.141928: step 121280, loss = 0.31, batch loss = 0.20 (53.3 examples/sec; 0.150 sec/batch; 8h:48m:16s remains)
INFO - root - 2017-12-01 07:54:17.710276: step 121290, loss = 0.31, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 9h:10m:31s remains)
INFO - root - 2017-12-01 07:54:19.284684: step 121300, loss = 0.45, batch loss = 0.35 (50.2 examples/sec; 0.159 sec/batch; 9h:20m:33s remains)
INFO - root - 2017-12-01 07:54:20.941447: step 121310, loss = 0.33, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 9h:19m:18s remains)
INFO - root - 2017-12-01 07:54:22.549245: step 121320, loss = 0.36, batch loss = 0.26 (50.3 examples/sec; 0.159 sec/batch; 9h:19m:42s remains)
INFO - root - 2017-12-01 07:54:24.102153: step 121330, loss = 0.33, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 9h:03m:28s remains)
INFO - root - 2017-12-01 07:54:25.646953: step 121340, loss = 0.37, batch loss = 0.26 (53.0 examples/sec; 0.151 sec/batch; 8h:51m:08s remains)
INFO - root - 2017-12-01 07:54:27.213891: step 121350, loss = 0.28, batch loss = 0.18 (48.6 examples/sec; 0.165 sec/batch; 9h:39m:25s remains)
INFO - root - 2017-12-01 07:54:28.780443: step 121360, loss = 0.32, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 8h:56m:26s remains)
INFO - root - 2017-12-01 07:54:30.352849: step 121370, loss = 0.34, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 9h:09m:05s remains)
INFO - root - 2017-12-01 07:54:31.917401: step 121380, loss = 0.27, batch loss = 0.17 (49.5 examples/sec; 0.162 sec/batch; 9h:28m:20s remains)
INFO - root - 2017-12-01 07:54:33.469077: step 121390, loss = 0.35, batch loss = 0.25 (49.3 examples/sec; 0.162 sec/batch; 9h:31m:26s remains)
INFO - root - 2017-12-01 07:54:35.050019: step 121400, loss = 0.33, batch loss = 0.23 (51.1 examples/sec; 0.156 sec/batch; 9h:10m:19s remains)
INFO - root - 2017-12-01 07:54:36.693548: step 121410, loss = 0.25, batch loss = 0.14 (48.7 examples/sec; 0.164 sec/batch; 9h:38m:20s remains)
INFO - root - 2017-12-01 07:54:38.260428: step 121420, loss = 0.35, batch loss = 0.25 (52.1 examples/sec; 0.153 sec/batch; 8h:59m:48s remains)
INFO - root - 2017-12-01 07:54:39.824690: step 121430, loss = 0.25, batch loss = 0.15 (51.1 examples/sec; 0.156 sec/batch; 9h:10m:17s remains)
INFO - root - 2017-12-01 07:54:41.412554: step 121440, loss = 0.26, batch loss = 0.15 (50.6 examples/sec; 0.158 sec/batch; 9h:15m:53s remains)
INFO - root - 2017-12-01 07:54:42.983528: step 121450, loss = 0.32, batch loss = 0.22 (49.5 examples/sec; 0.162 sec/batch; 9h:28m:51s remains)
INFO - root - 2017-12-01 07:54:44.556981: step 121460, loss = 0.23, batch loss = 0.13 (48.1 examples/sec; 0.166 sec/batch; 9h:45m:26s remains)
INFO - root - 2017-12-01 07:54:46.115439: step 121470, loss = 0.32, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 9h:17m:50s remains)
INFO - root - 2017-12-01 07:54:47.687857: step 121480, loss = 0.39, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 9h:19m:04s remains)
INFO - root - 2017-12-01 07:54:49.247123: step 121490, loss = 0.25, batch loss = 0.15 (50.6 examples/sec; 0.158 sec/batch; 9h:15m:53s remains)
INFO - root - 2017-12-01 07:54:50.813701: step 121500, loss = 0.29, batch loss = 0.19 (49.1 examples/sec; 0.163 sec/batch; 9h:32m:53s remains)
INFO - root - 2017-12-01 07:54:52.446294: step 121510, loss = 0.46, batch loss = 0.36 (50.4 examples/sec; 0.159 sec/batch; 9h:18m:27s remains)
INFO - root - 2017-12-01 07:54:54.003948: step 121520, loss = 0.27, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 9h:00m:41s remains)
INFO - root - 2017-12-01 07:54:55.578896: step 121530, loss = 0.29, batch loss = 0.19 (53.4 examples/sec; 0.150 sec/batch; 8h:46m:23s remains)
INFO - root - 2017-12-01 07:54:57.163397: step 121540, loss = 0.40, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 9h:12m:55s remains)
INFO - root - 2017-12-01 07:54:58.733299: step 121550, loss = 0.28, batch loss = 0.18 (49.9 examples/sec; 0.160 sec/batch; 9h:23m:56s remains)
INFO - root - 2017-12-01 07:55:00.293654: step 121560, loss = 0.35, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 9h:14m:24s remains)
INFO - root - 2017-12-01 07:55:01.886961: step 121570, loss = 0.42, batch loss = 0.32 (52.2 examples/sec; 0.153 sec/batch; 8h:58m:48s remains)
INFO - root - 2017-12-01 07:55:03.432786: step 121580, loss = 0.26, batch loss = 0.16 (51.0 examples/sec; 0.157 sec/batch; 9h:11m:34s remains)
INFO - root - 2017-12-01 07:55:05.033299: step 121590, loss = 0.32, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 9h:14m:20s remains)
INFO - root - 2017-12-01 07:55:06.603762: step 121600, loss = 0.34, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 9h:23m:24s remains)
INFO - root - 2017-12-01 07:55:08.264505: step 121610, loss = 0.34, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 9h:02m:22s remains)
INFO - root - 2017-12-01 07:55:09.811036: step 121620, loss = 0.31, batch loss = 0.21 (49.9 examples/sec; 0.160 sec/batch; 9h:23m:20s remains)
INFO - root - 2017-12-01 07:55:11.375254: step 121630, loss = 0.33, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 9h:07m:44s remains)
INFO - root - 2017-12-01 07:55:12.964435: step 121640, loss = 0.27, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 9h:17m:41s remains)
INFO - root - 2017-12-01 07:55:14.535939: step 121650, loss = 0.40, batch loss = 0.30 (51.7 examples/sec; 0.155 sec/batch; 9h:04m:09s remains)
INFO - root - 2017-12-01 07:55:16.094218: step 121660, loss = 0.34, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 9h:06m:08s remains)
INFO - root - 2017-12-01 07:55:17.649526: step 121670, loss = 0.25, batch loss = 0.15 (50.1 examples/sec; 0.160 sec/batch; 9h:21m:31s remains)
INFO - root - 2017-12-01 07:55:19.220101: step 121680, loss = 0.38, batch loss = 0.28 (49.3 examples/sec; 0.162 sec/batch; 9h:29m:54s remains)
INFO - root - 2017-12-01 07:55:20.824995: step 121690, loss = 0.28, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 9h:11m:23s remains)
INFO - root - 2017-12-01 07:55:22.419661: step 121700, loss = 0.49, batch loss = 0.39 (48.5 examples/sec; 0.165 sec/batch; 9h:40m:00s remains)
INFO - root - 2017-12-01 07:55:24.020651: step 121710, loss = 0.36, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 9h:04m:48s remains)
INFO - root - 2017-12-01 07:55:25.588791: step 121720, loss = 0.26, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 9h:12m:01s remains)
INFO - root - 2017-12-01 07:55:27.175261: step 121730, loss = 0.30, batch loss = 0.19 (50.1 examples/sec; 0.160 sec/batch; 9h:20m:33s remains)
INFO - root - 2017-12-01 07:55:28.735481: step 121740, loss = 0.29, batch loss = 0.19 (52.7 examples/sec; 0.152 sec/batch; 8h:52m:58s remains)
INFO - root - 2017-12-01 07:55:30.293760: step 121750, loss = 0.28, batch loss = 0.17 (52.3 examples/sec; 0.153 sec/batch; 8h:57m:32s remains)
INFO - root - 2017-12-01 07:55:31.848805: step 121760, loss = 0.28, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 9h:02m:00s remains)
INFO - root - 2017-12-01 07:55:33.441538: step 121770, loss = 0.30, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 9h:22m:58s remains)
INFO - root - 2017-12-01 07:55:35.012030: step 121780, loss = 0.28, batch loss = 0.18 (48.5 examples/sec; 0.165 sec/batch; 9h:39m:10s remains)
INFO - root - 2017-12-01 07:55:36.603333: step 121790, loss = 0.34, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 9h:11m:21s remains)
INFO - root - 2017-12-01 07:55:38.180618: step 121800, loss = 0.34, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 9h:00m:47s remains)
INFO - root - 2017-12-01 07:55:39.812030: step 121810, loss = 0.49, batch loss = 0.38 (52.0 examples/sec; 0.154 sec/batch; 9h:00m:13s remains)
INFO - root - 2017-12-01 07:55:41.379979: step 121820, loss = 0.34, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 9h:01m:47s remains)
INFO - root - 2017-12-01 07:55:42.941016: step 121830, loss = 0.28, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 9h:05m:56s remains)
INFO - root - 2017-12-01 07:55:44.486794: step 121840, loss = 0.34, batch loss = 0.24 (52.5 examples/sec; 0.152 sec/batch; 8h:54m:49s remains)
INFO - root - 2017-12-01 07:55:46.049222: step 121850, loss = 0.28, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 9h:02m:52s remains)
INFO - root - 2017-12-01 07:55:47.603225: step 121860, loss = 0.31, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 9h:01m:54s remains)
INFO - root - 2017-12-01 07:55:49.171521: step 121870, loss = 0.46, batch loss = 0.35 (51.4 examples/sec; 0.156 sec/batch; 9h:06m:05s remains)
INFO - root - 2017-12-01 07:55:50.729182: step 121880, loss = 0.30, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 9h:04m:57s remains)
INFO - root - 2017-12-01 07:55:52.295627: step 121890, loss = 0.27, batch loss = 0.17 (50.7 examples/sec; 0.158 sec/batch; 9h:13m:50s remains)
INFO - root - 2017-12-01 07:55:53.854040: step 121900, loss = 0.33, batch loss = 0.23 (49.0 examples/sec; 0.163 sec/batch; 9h:32m:57s remains)
INFO - root - 2017-12-01 07:55:55.455913: step 121910, loss = 0.37, batch loss = 0.27 (52.4 examples/sec; 0.153 sec/batch; 8h:56m:01s remains)
INFO - root - 2017-12-01 07:55:57.014581: step 121920, loss = 0.32, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 8h:59m:31s remains)
INFO - root - 2017-12-01 07:55:58.589015: step 121930, loss = 0.40, batch loss = 0.30 (49.7 examples/sec; 0.161 sec/batch; 9h:25m:18s remains)
INFO - root - 2017-12-01 07:56:00.167802: step 121940, loss = 0.40, batch loss = 0.30 (49.0 examples/sec; 0.163 sec/batch; 9h:33m:20s remains)
INFO - root - 2017-12-01 07:56:01.720412: step 121950, loss = 0.30, batch loss = 0.20 (53.1 examples/sec; 0.151 sec/batch; 8h:48m:41s remains)
INFO - root - 2017-12-01 07:56:03.297327: step 121960, loss = 0.35, batch loss = 0.24 (52.1 examples/sec; 0.154 sec/batch; 8h:59m:15s remains)
INFO - root - 2017-12-01 07:56:04.853962: step 121970, loss = 0.34, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 9h:08m:12s remains)
INFO - root - 2017-12-01 07:56:06.424601: step 121980, loss = 0.36, batch loss = 0.26 (50.3 examples/sec; 0.159 sec/batch; 9h:18m:29s remains)
INFO - root - 2017-12-01 07:56:07.984441: step 121990, loss = 0.24, batch loss = 0.14 (50.6 examples/sec; 0.158 sec/batch; 9h:14m:56s remains)
INFO - root - 2017-12-01 07:56:09.551936: step 122000, loss = 0.35, batch loss = 0.25 (52.9 examples/sec; 0.151 sec/batch; 8h:50m:30s remains)
INFO - root - 2017-12-01 07:56:11.167741: step 122010, loss = 0.40, batch loss = 0.30 (50.2 examples/sec; 0.159 sec/batch; 9h:19m:22s remains)
INFO - root - 2017-12-01 07:56:12.730829: step 122020, loss = 0.32, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 9h:07m:06s remains)
INFO - root - 2017-12-01 07:56:14.276994: step 122030, loss = 0.24, batch loss = 0.13 (51.7 examples/sec; 0.155 sec/batch; 9h:02m:53s remains)
INFO - root - 2017-12-01 07:56:15.838227: step 122040, loss = 0.29, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 8h:55m:42s remains)
INFO - root - 2017-12-01 07:56:17.408664: step 122050, loss = 0.27, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 9h:17m:52s remains)
INFO - root - 2017-12-01 07:56:18.983629: step 122060, loss = 0.33, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 9h:18m:07s remains)
INFO - root - 2017-12-01 07:56:20.542623: step 122070, loss = 0.39, batch loss = 0.29 (50.1 examples/sec; 0.160 sec/batch; 9h:20m:30s remains)
INFO - root - 2017-12-01 07:56:22.099800: step 122080, loss = 0.31, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 8h:54m:15s remains)
INFO - root - 2017-12-01 07:56:23.682259: step 122090, loss = 0.26, batch loss = 0.16 (50.3 examples/sec; 0.159 sec/batch; 9h:17m:48s remains)
INFO - root - 2017-12-01 07:56:25.242928: step 122100, loss = 0.36, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 9h:01m:10s remains)
INFO - root - 2017-12-01 07:56:26.889587: step 122110, loss = 0.29, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 8h:54m:14s remains)
INFO - root - 2017-12-01 07:56:28.447424: step 122120, loss = 0.29, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 8h:57m:22s remains)
INFO - root - 2017-12-01 07:56:30.004663: step 122130, loss = 0.29, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 9h:16m:11s remains)
INFO - root - 2017-12-01 07:56:31.566748: step 122140, loss = 0.27, batch loss = 0.17 (49.2 examples/sec; 0.163 sec/batch; 9h:30m:26s remains)
INFO - root - 2017-12-01 07:56:33.127404: step 122150, loss = 0.35, batch loss = 0.25 (49.9 examples/sec; 0.160 sec/batch; 9h:21m:58s remains)
INFO - root - 2017-12-01 07:56:34.686612: step 122160, loss = 0.32, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 9h:00m:06s remains)
INFO - root - 2017-12-01 07:56:36.270539: step 122170, loss = 0.29, batch loss = 0.19 (47.7 examples/sec; 0.168 sec/batch; 9h:47m:40s remains)
INFO - root - 2017-12-01 07:56:37.825166: step 122180, loss = 0.29, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 9h:02m:28s remains)
INFO - root - 2017-12-01 07:56:39.390527: step 122190, loss = 0.32, batch loss = 0.22 (51.8 examples/sec; 0.155 sec/batch; 9h:01m:38s remains)
INFO - root - 2017-12-01 07:56:40.950096: step 122200, loss = 0.24, batch loss = 0.14 (50.8 examples/sec; 0.157 sec/batch; 9h:11m:35s remains)
INFO - root - 2017-12-01 07:56:42.560940: step 122210, loss = 0.39, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 9h:04m:13s remains)
INFO - root - 2017-12-01 07:56:44.136441: step 122220, loss = 0.27, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 9h:16m:28s remains)
INFO - root - 2017-12-01 07:56:45.707069: step 122230, loss = 0.36, batch loss = 0.25 (49.3 examples/sec; 0.162 sec/batch; 9h:28m:40s remains)
INFO - root - 2017-12-01 07:56:47.265891: step 122240, loss = 0.29, batch loss = 0.19 (54.0 examples/sec; 0.148 sec/batch; 8h:39m:08s remains)
INFO - root - 2017-12-01 07:56:48.842582: step 122250, loss = 0.26, batch loss = 0.15 (51.9 examples/sec; 0.154 sec/batch; 8h:59m:44s remains)
INFO - root - 2017-12-01 07:56:50.393008: step 122260, loss = 0.29, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 9h:06m:15s remains)
INFO - root - 2017-12-01 07:56:51.970464: step 122270, loss = 0.49, batch loss = 0.39 (51.2 examples/sec; 0.156 sec/batch; 9h:07m:27s remains)
INFO - root - 2017-12-01 07:56:53.544210: step 122280, loss = 0.30, batch loss = 0.20 (48.5 examples/sec; 0.165 sec/batch; 9h:38m:11s remains)
INFO - root - 2017-12-01 07:56:55.118304: step 122290, loss = 0.34, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 9h:03m:57s remains)
INFO - root - 2017-12-01 07:56:56.692565: step 122300, loss = 0.40, batch loss = 0.29 (50.8 examples/sec; 0.157 sec/batch; 9h:11m:19s remains)
INFO - root - 2017-12-01 07:56:58.317618: step 122310, loss = 0.34, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 9h:12m:17s remains)
INFO - root - 2017-12-01 07:56:59.890139: step 122320, loss = 0.28, batch loss = 0.18 (51.8 examples/sec; 0.155 sec/batch; 9h:01m:21s remains)
INFO - root - 2017-12-01 07:57:01.460118: step 122330, loss = 0.26, batch loss = 0.16 (52.8 examples/sec; 0.152 sec/batch; 8h:50m:47s remains)
INFO - root - 2017-12-01 07:57:03.027993: step 122340, loss = 0.25, batch loss = 0.15 (51.1 examples/sec; 0.156 sec/batch; 9h:08m:05s remains)
INFO - root - 2017-12-01 07:57:04.605171: step 122350, loss = 0.55, batch loss = 0.44 (52.1 examples/sec; 0.153 sec/batch; 8h:57m:33s remains)
INFO - root - 2017-12-01 07:57:06.180698: step 122360, loss = 0.33, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 9h:05m:14s remains)
INFO - root - 2017-12-01 07:57:07.745477: step 122370, loss = 0.22, batch loss = 0.12 (49.5 examples/sec; 0.162 sec/batch; 9h:25m:54s remains)
INFO - root - 2017-12-01 07:57:09.300527: step 122380, loss = 0.30, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 9h:12m:08s remains)
INFO - root - 2017-12-01 07:57:10.891360: step 122390, loss = 0.26, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 9h:07m:39s remains)
INFO - root - 2017-12-01 07:57:12.479927: step 122400, loss = 0.33, batch loss = 0.23 (50.0 examples/sec; 0.160 sec/batch; 9h:19m:57s remains)
INFO - root - 2017-12-01 07:57:14.148578: step 122410, loss = 0.29, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 9h:00m:17s remains)
INFO - root - 2017-12-01 07:57:15.726227: step 122420, loss = 0.28, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 9h:15m:54s remains)
INFO - root - 2017-12-01 07:57:17.312240: step 122430, loss = 0.30, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 9h:02m:12s remains)
INFO - root - 2017-12-01 07:57:18.870149: step 122440, loss = 0.26, batch loss = 0.16 (51.7 examples/sec; 0.155 sec/batch; 9h:01m:20s remains)
INFO - root - 2017-12-01 07:57:20.454058: step 122450, loss = 0.34, batch loss = 0.23 (49.6 examples/sec; 0.161 sec/batch; 9h:25m:03s remains)
INFO - root - 2017-12-01 07:57:22.026010: step 122460, loss = 0.42, batch loss = 0.32 (52.7 examples/sec; 0.152 sec/batch; 8h:51m:39s remains)
INFO - root - 2017-12-01 07:57:23.609877: step 122470, loss = 0.29, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 9h:26m:00s remains)
INFO - root - 2017-12-01 07:57:25.169710: step 122480, loss = 0.31, batch loss = 0.21 (52.8 examples/sec; 0.151 sec/batch; 8h:49m:54s remains)
INFO - root - 2017-12-01 07:57:26.750671: step 122490, loss = 0.35, batch loss = 0.25 (50.1 examples/sec; 0.160 sec/batch; 9h:19m:26s remains)
INFO - root - 2017-12-01 07:57:28.313021: step 122500, loss = 0.30, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 9h:07m:44s remains)
INFO - root - 2017-12-01 07:57:29.907657: step 122510, loss = 0.31, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 8h:58m:07s remains)
INFO - root - 2017-12-01 07:57:31.474517: step 122520, loss = 0.30, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 9h:00m:38s remains)
INFO - root - 2017-12-01 07:57:33.068307: step 122530, loss = 0.35, batch loss = 0.25 (48.3 examples/sec; 0.166 sec/batch; 9h:39m:46s remains)
INFO - root - 2017-12-01 07:57:34.648901: step 122540, loss = 0.24, batch loss = 0.14 (50.0 examples/sec; 0.160 sec/batch; 9h:20m:06s remains)
INFO - root - 2017-12-01 07:57:36.201718: step 122550, loss = 0.36, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 9h:02m:39s remains)
INFO - root - 2017-12-01 07:57:37.780783: step 122560, loss = 0.38, batch loss = 0.27 (52.1 examples/sec; 0.153 sec/batch; 8h:56m:53s remains)
INFO - root - 2017-12-01 07:57:39.345292: step 122570, loss = 0.34, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 8h:52m:09s remains)
INFO - root - 2017-12-01 07:57:40.918254: step 122580, loss = 0.30, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 9h:15m:02s remains)
INFO - root - 2017-12-01 07:57:42.479081: step 122590, loss = 0.28, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 9h:03m:15s remains)
INFO - root - 2017-12-01 07:57:44.031628: step 122600, loss = 0.28, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 9h:02m:02s remains)
INFO - root - 2017-12-01 07:57:45.648488: step 122610, loss = 0.32, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 9h:05m:49s remains)
INFO - root - 2017-12-01 07:57:47.209103: step 122620, loss = 0.29, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 9h:09m:27s remains)
INFO - root - 2017-12-01 07:57:48.766290: step 122630, loss = 0.33, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 9h:01m:08s remains)
INFO - root - 2017-12-01 07:57:50.328420: step 122640, loss = 0.32, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 9h:00m:04s remains)
INFO - root - 2017-12-01 07:57:51.880491: step 122650, loss = 0.29, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 9h:05m:56s remains)
INFO - root - 2017-12-01 07:57:53.435062: step 122660, loss = 0.35, batch loss = 0.24 (50.8 examples/sec; 0.158 sec/batch; 9h:11m:10s remains)
INFO - root - 2017-12-01 07:57:54.984458: step 122670, loss = 0.27, batch loss = 0.17 (52.7 examples/sec; 0.152 sec/batch; 8h:50m:45s remains)
INFO - root - 2017-12-01 07:57:56.567686: step 122680, loss = 0.25, batch loss = 0.15 (50.4 examples/sec; 0.159 sec/batch; 9h:15m:18s remains)
INFO - root - 2017-12-01 07:57:58.116183: step 122690, loss = 0.27, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 9h:04m:29s remains)
INFO - root - 2017-12-01 07:57:59.683791: step 122700, loss = 0.29, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 9h:03m:06s remains)
INFO - root - 2017-12-01 07:58:01.339991: step 122710, loss = 0.25, batch loss = 0.15 (49.4 examples/sec; 0.162 sec/batch; 9h:26m:00s remains)
INFO - root - 2017-12-01 07:58:02.892880: step 122720, loss = 0.35, batch loss = 0.25 (50.8 examples/sec; 0.157 sec/batch; 9h:10m:11s remains)
INFO - root - 2017-12-01 07:58:04.452936: step 122730, loss = 0.34, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 8h:52m:05s remains)
INFO - root - 2017-12-01 07:58:06.028399: step 122740, loss = 0.28, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 9h:07m:55s remains)
INFO - root - 2017-12-01 07:58:07.611799: step 122750, loss = 0.26, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 9h:04m:43s remains)
INFO - root - 2017-12-01 07:58:09.172731: step 122760, loss = 0.26, batch loss = 0.16 (49.7 examples/sec; 0.161 sec/batch; 9h:23m:05s remains)
INFO - root - 2017-12-01 07:58:10.742490: step 122770, loss = 0.32, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 9h:01m:22s remains)
INFO - root - 2017-12-01 07:58:12.304091: step 122780, loss = 0.42, batch loss = 0.32 (51.5 examples/sec; 0.155 sec/batch; 9h:03m:17s remains)
INFO - root - 2017-12-01 07:58:13.872315: step 122790, loss = 0.29, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 9h:02m:50s remains)
INFO - root - 2017-12-01 07:58:15.427268: step 122800, loss = 0.33, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 9h:03m:58s remains)
INFO - root - 2017-12-01 07:58:17.043352: step 122810, loss = 0.28, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 9h:11m:03s remains)
INFO - root - 2017-12-01 07:58:18.603820: step 122820, loss = 0.28, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 9h:00m:40s remains)
INFO - root - 2017-12-01 07:58:20.163354: step 122830, loss = 0.32, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 9h:07m:43s remains)
INFO - root - 2017-12-01 07:58:21.725468: step 122840, loss = 0.30, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 9h:05m:38s remains)
INFO - root - 2017-12-01 07:58:23.274087: step 122850, loss = 0.28, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 9h:01m:51s remains)
INFO - root - 2017-12-01 07:58:24.825270: step 122860, loss = 0.45, batch loss = 0.35 (51.3 examples/sec; 0.156 sec/batch; 9h:04m:48s remains)
INFO - root - 2017-12-01 07:58:26.387807: step 122870, loss = 0.24, batch loss = 0.14 (52.7 examples/sec; 0.152 sec/batch; 8h:50m:16s remains)
INFO - root - 2017-12-01 07:58:27.958922: step 122880, loss = 0.28, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 9h:08m:12s remains)
INFO - root - 2017-12-01 07:58:29.517618: step 122890, loss = 0.39, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 9h:09m:03s remains)
INFO - root - 2017-12-01 07:58:31.080429: step 122900, loss = 0.41, batch loss = 0.31 (50.5 examples/sec; 0.158 sec/batch; 9h:13m:18s remains)
INFO - root - 2017-12-01 07:58:32.723763: step 122910, loss = 0.37, batch loss = 0.27 (51.8 examples/sec; 0.154 sec/batch; 8h:59m:33s remains)
INFO - root - 2017-12-01 07:58:34.309525: step 122920, loss = 0.42, batch loss = 0.31 (50.6 examples/sec; 0.158 sec/batch; 9h:12m:29s remains)
INFO - root - 2017-12-01 07:58:35.870974: step 122930, loss = 0.33, batch loss = 0.23 (50.5 examples/sec; 0.159 sec/batch; 9h:13m:47s remains)
INFO - root - 2017-12-01 07:58:37.438441: step 122940, loss = 0.26, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 9h:04m:52s remains)
INFO - root - 2017-12-01 07:58:38.988245: step 122950, loss = 0.29, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 9h:06m:56s remains)
INFO - root - 2017-12-01 07:58:40.562837: step 122960, loss = 0.34, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 9h:05m:52s remains)
INFO - root - 2017-12-01 07:58:42.144140: step 122970, loss = 0.25, batch loss = 0.14 (48.2 examples/sec; 0.166 sec/batch; 9h:39m:57s remains)
INFO - root - 2017-12-01 07:58:43.701181: step 122980, loss = 0.44, batch loss = 0.33 (52.5 examples/sec; 0.152 sec/batch; 8h:52m:05s remains)
INFO - root - 2017-12-01 07:58:45.266263: step 122990, loss = 0.28, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 9h:10m:35s remains)
INFO - root - 2017-12-01 07:58:46.821276: step 123000, loss = 0.42, batch loss = 0.32 (52.1 examples/sec; 0.153 sec/batch; 8h:55m:47s remains)
INFO - root - 2017-12-01 07:58:48.427504: step 123010, loss = 0.44, batch loss = 0.34 (51.8 examples/sec; 0.154 sec/batch; 8h:58m:42s remains)
INFO - root - 2017-12-01 07:58:49.985689: step 123020, loss = 0.37, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 9h:01m:46s remains)
INFO - root - 2017-12-01 07:58:51.563894: step 123030, loss = 0.29, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 8h:59m:57s remains)
INFO - root - 2017-12-01 07:58:53.119463: step 123040, loss = 0.30, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 9h:02m:56s remains)
INFO - root - 2017-12-01 07:58:54.681411: step 123050, loss = 0.28, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 9h:06m:33s remains)
INFO - root - 2017-12-01 07:58:56.242342: step 123060, loss = 0.29, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 9h:18m:52s remains)
INFO - root - 2017-12-01 07:58:57.818557: step 123070, loss = 0.29, batch loss = 0.19 (48.1 examples/sec; 0.166 sec/batch; 9h:40m:02s remains)
INFO - root - 2017-12-01 07:58:59.382687: step 123080, loss = 0.56, batch loss = 0.46 (51.9 examples/sec; 0.154 sec/batch; 8h:57m:46s remains)
INFO - root - 2017-12-01 07:59:00.946458: step 123090, loss = 0.31, batch loss = 0.21 (49.9 examples/sec; 0.160 sec/batch; 9h:20m:04s remains)
INFO - root - 2017-12-01 07:59:02.510802: step 123100, loss = 0.33, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 9h:12m:12s remains)
INFO - root - 2017-12-01 07:59:04.153428: step 123110, loss = 0.38, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 9h:02m:21s remains)
INFO - root - 2017-12-01 07:59:05.731252: step 123120, loss = 0.33, batch loss = 0.23 (49.4 examples/sec; 0.162 sec/batch; 9h:24m:48s remains)
INFO - root - 2017-12-01 07:59:07.286762: step 123130, loss = 0.28, batch loss = 0.18 (52.5 examples/sec; 0.152 sec/batch; 8h:51m:50s remains)
INFO - root - 2017-12-01 07:59:08.853657: step 123140, loss = 0.25, batch loss = 0.15 (49.8 examples/sec; 0.161 sec/batch; 9h:20m:21s remains)
INFO - root - 2017-12-01 07:59:10.429241: step 123150, loss = 0.35, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 9h:11m:33s remains)
INFO - root - 2017-12-01 07:59:11.991866: step 123160, loss = 0.28, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 9h:01m:23s remains)
INFO - root - 2017-12-01 07:59:13.570410: step 123170, loss = 0.22, batch loss = 0.12 (52.0 examples/sec; 0.154 sec/batch; 8h:57m:00s remains)
INFO - root - 2017-12-01 07:59:15.137622: step 123180, loss = 0.38, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 9h:00m:54s remains)
INFO - root - 2017-12-01 07:59:16.701587: step 123190, loss = 0.33, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 9h:09m:35s remains)
INFO - root - 2017-12-01 07:59:18.261518: step 123200, loss = 0.28, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 8h:56m:55s remains)
INFO - root - 2017-12-01 07:59:19.893985: step 123210, loss = 0.25, batch loss = 0.15 (51.6 examples/sec; 0.155 sec/batch; 9h:00m:43s remains)
INFO - root - 2017-12-01 07:59:21.488135: step 123220, loss = 0.29, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 9h:07m:15s remains)
INFO - root - 2017-12-01 07:59:23.045558: step 123230, loss = 0.26, batch loss = 0.16 (50.1 examples/sec; 0.160 sec/batch; 9h:16m:31s remains)
INFO - root - 2017-12-01 07:59:24.595294: step 123240, loss = 0.33, batch loss = 0.23 (50.8 examples/sec; 0.157 sec/batch; 9h:09m:02s remains)
INFO - root - 2017-12-01 07:59:26.178565: step 123250, loss = 0.27, batch loss = 0.17 (48.5 examples/sec; 0.165 sec/batch; 9h:35m:16s remains)
INFO - root - 2017-12-01 07:59:27.741174: step 123260, loss = 0.33, batch loss = 0.23 (53.2 examples/sec; 0.150 sec/batch; 8h:44m:46s remains)
INFO - root - 2017-12-01 07:59:29.291803: step 123270, loss = 0.30, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 8h:56m:29s remains)
INFO - root - 2017-12-01 07:59:30.853294: step 123280, loss = 0.31, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 9h:02m:58s remains)
INFO - root - 2017-12-01 07:59:32.428494: step 123290, loss = 0.31, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 9h:14m:04s remains)
INFO - root - 2017-12-01 07:59:33.982103: step 123300, loss = 0.39, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 8h:57m:06s remains)
INFO - root - 2017-12-01 07:59:35.595122: step 123310, loss = 0.36, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 8h:57m:03s remains)
INFO - root - 2017-12-01 07:59:37.159383: step 123320, loss = 0.36, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 9h:11m:27s remains)
INFO - root - 2017-12-01 07:59:38.718636: step 123330, loss = 0.33, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 9h:19m:12s remains)
INFO - root - 2017-12-01 07:59:40.309873: step 123340, loss = 0.30, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 8h:52m:54s remains)
INFO - root - 2017-12-01 07:59:41.877768: step 123350, loss = 0.27, batch loss = 0.17 (50.8 examples/sec; 0.157 sec/batch; 9h:08m:59s remains)
INFO - root - 2017-12-01 07:59:43.436932: step 123360, loss = 0.31, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 9h:02m:31s remains)
INFO - root - 2017-12-01 07:59:45.001071: step 123370, loss = 0.30, batch loss = 0.20 (49.4 examples/sec; 0.162 sec/batch; 9h:24m:47s remains)
INFO - root - 2017-12-01 07:59:46.562755: step 123380, loss = 0.34, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 9h:02m:46s remains)
INFO - root - 2017-12-01 07:59:48.120219: step 123390, loss = 0.28, batch loss = 0.18 (52.7 examples/sec; 0.152 sec/batch; 8h:49m:29s remains)
INFO - root - 2017-12-01 07:59:49.703579: step 123400, loss = 0.45, batch loss = 0.35 (51.3 examples/sec; 0.156 sec/batch; 9h:03m:35s remains)
INFO - root - 2017-12-01 07:59:51.299708: step 123410, loss = 0.45, batch loss = 0.35 (52.4 examples/sec; 0.153 sec/batch; 8h:52m:21s remains)
INFO - root - 2017-12-01 07:59:52.848073: step 123420, loss = 0.30, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 9h:16m:10s remains)
INFO - root - 2017-12-01 07:59:54.417048: step 123430, loss = 0.29, batch loss = 0.19 (49.3 examples/sec; 0.162 sec/batch; 9h:25m:32s remains)
INFO - root - 2017-12-01 07:59:55.998606: step 123440, loss = 0.37, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 9h:07m:48s remains)
INFO - root - 2017-12-01 07:59:57.564718: step 123450, loss = 0.27, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 9h:06m:11s remains)
INFO - root - 2017-12-01 07:59:59.110715: step 123460, loss = 0.37, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 9h:07m:58s remains)
INFO - root - 2017-12-01 08:00:00.672791: step 123470, loss = 0.30, batch loss = 0.20 (48.1 examples/sec; 0.166 sec/batch; 9h:39m:11s remains)
INFO - root - 2017-12-01 08:00:02.256718: step 123480, loss = 0.29, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 9h:02m:12s remains)
INFO - root - 2017-12-01 08:00:03.811975: step 123490, loss = 0.37, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 9h:07m:15s remains)
INFO - root - 2017-12-01 08:00:05.377593: step 123500, loss = 0.27, batch loss = 0.17 (49.9 examples/sec; 0.160 sec/batch; 9h:18m:28s remains)
INFO - root - 2017-12-01 08:00:07.022156: step 123510, loss = 0.33, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 8h:57m:48s remains)
INFO - root - 2017-12-01 08:00:08.588285: step 123520, loss = 0.25, batch loss = 0.15 (51.5 examples/sec; 0.155 sec/batch; 9h:00m:34s remains)
INFO - root - 2017-12-01 08:00:10.146073: step 123530, loss = 0.27, batch loss = 0.17 (50.2 examples/sec; 0.159 sec/batch; 9h:14m:51s remains)
INFO - root - 2017-12-01 08:00:11.720067: step 123540, loss = 0.32, batch loss = 0.22 (48.2 examples/sec; 0.166 sec/batch; 9h:37m:49s remains)
INFO - root - 2017-12-01 08:00:13.300678: step 123550, loss = 0.25, batch loss = 0.15 (51.5 examples/sec; 0.155 sec/batch; 9h:00m:47s remains)
INFO - root - 2017-12-01 08:00:14.853856: step 123560, loss = 0.30, batch loss = 0.20 (52.9 examples/sec; 0.151 sec/batch; 8h:47m:02s remains)
INFO - root - 2017-12-01 08:00:16.424640: step 123570, loss = 0.34, batch loss = 0.24 (50.1 examples/sec; 0.160 sec/batch; 9h:15m:47s remains)
INFO - root - 2017-12-01 08:00:18.000111: step 123580, loss = 0.32, batch loss = 0.22 (48.4 examples/sec; 0.165 sec/batch; 9h:35m:28s remains)
INFO - root - 2017-12-01 08:00:19.567872: step 123590, loss = 0.33, batch loss = 0.23 (53.1 examples/sec; 0.151 sec/batch; 8h:45m:00s remains)
INFO - root - 2017-12-01 08:00:21.151105: step 123600, loss = 0.30, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 9h:08m:40s remains)
INFO - root - 2017-12-01 08:00:22.772018: step 123610, loss = 0.29, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 8h:49m:32s remains)
INFO - root - 2017-12-01 08:00:24.355625: step 123620, loss = 0.32, batch loss = 0.22 (49.3 examples/sec; 0.162 sec/batch; 9h:25m:21s remains)
INFO - root - 2017-12-01 08:00:25.927908: step 123630, loss = 0.26, batch loss = 0.16 (51.0 examples/sec; 0.157 sec/batch; 9h:05m:43s remains)
INFO - root - 2017-12-01 08:00:27.497283: step 123640, loss = 0.29, batch loss = 0.19 (48.7 examples/sec; 0.164 sec/batch; 9h:31m:56s remains)
INFO - root - 2017-12-01 08:00:29.082863: step 123650, loss = 0.31, batch loss = 0.21 (47.1 examples/sec; 0.170 sec/batch; 9h:51m:19s remains)
INFO - root - 2017-12-01 08:00:30.713458: step 123660, loss = 0.31, batch loss = 0.21 (48.1 examples/sec; 0.166 sec/batch; 9h:38m:22s remains)
INFO - root - 2017-12-01 08:00:32.283500: step 123670, loss = 0.28, batch loss = 0.18 (52.2 examples/sec; 0.153 sec/batch; 8h:53m:42s remains)
INFO - root - 2017-12-01 08:00:33.836605: step 123680, loss = 0.30, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 9h:12m:01s remains)
INFO - root - 2017-12-01 08:00:35.401464: step 123690, loss = 0.32, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 8h:57m:21s remains)
INFO - root - 2017-12-01 08:00:36.968045: step 123700, loss = 0.27, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 9h:00m:23s remains)
INFO - root - 2017-12-01 08:00:38.568636: step 123710, loss = 0.34, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 9h:02m:04s remains)
INFO - root - 2017-12-01 08:00:40.155821: step 123720, loss = 0.28, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 9h:11m:58s remains)
INFO - root - 2017-12-01 08:00:41.713668: step 123730, loss = 0.29, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 9h:08m:18s remains)
INFO - root - 2017-12-01 08:00:43.289964: step 123740, loss = 0.26, batch loss = 0.16 (51.7 examples/sec; 0.155 sec/batch; 8h:58m:39s remains)
INFO - root - 2017-12-01 08:00:44.855202: step 123750, loss = 0.34, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 8h:49m:26s remains)
INFO - root - 2017-12-01 08:00:46.422611: step 123760, loss = 0.31, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 9h:08m:38s remains)
INFO - root - 2017-12-01 08:00:48.000360: step 123770, loss = 0.32, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 9h:01m:39s remains)
INFO - root - 2017-12-01 08:00:49.564245: step 123780, loss = 0.28, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 9h:11m:37s remains)
INFO - root - 2017-12-01 08:00:51.122753: step 123790, loss = 0.26, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 9h:12m:41s remains)
INFO - root - 2017-12-01 08:00:52.672666: step 123800, loss = 0.30, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 9h:13m:51s remains)
INFO - root - 2017-12-01 08:00:54.287625: step 123810, loss = 0.34, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 8h:53m:01s remains)
INFO - root - 2017-12-01 08:00:55.868424: step 123820, loss = 0.38, batch loss = 0.28 (49.1 examples/sec; 0.163 sec/batch; 9h:26m:19s remains)
INFO - root - 2017-12-01 08:00:57.439301: step 123830, loss = 0.32, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 9h:09m:26s remains)
INFO - root - 2017-12-01 08:00:59.007671: step 123840, loss = 0.25, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 9h:02m:03s remains)
INFO - root - 2017-12-01 08:01:00.566244: step 123850, loss = 0.31, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 9h:03m:09s remains)
INFO - root - 2017-12-01 08:01:02.152981: step 123860, loss = 0.30, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 9h:04m:09s remains)
INFO - root - 2017-12-01 08:01:03.729474: step 123870, loss = 0.30, batch loss = 0.20 (49.5 examples/sec; 0.162 sec/batch; 9h:21m:50s remains)
INFO - root - 2017-12-01 08:01:05.317263: step 123880, loss = 0.32, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 9h:06m:32s remains)
INFO - root - 2017-12-01 08:01:06.886605: step 123890, loss = 0.41, batch loss = 0.31 (50.6 examples/sec; 0.158 sec/batch; 9h:10m:01s remains)
INFO - root - 2017-12-01 08:01:08.443741: step 123900, loss = 0.26, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 8h:59m:29s remains)
INFO - root - 2017-12-01 08:01:10.099331: step 123910, loss = 0.28, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 9h:10m:04s remains)
INFO - root - 2017-12-01 08:01:11.671993: step 123920, loss = 0.29, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 9h:09m:11s remains)
INFO - root - 2017-12-01 08:01:13.235454: step 123930, loss = 0.33, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 9h:13m:02s remains)
INFO - root - 2017-12-01 08:01:14.791146: step 123940, loss = 0.31, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 8h:54m:17s remains)
INFO - root - 2017-12-01 08:01:16.373213: step 123950, loss = 0.30, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 9h:05m:15s remains)
INFO - root - 2017-12-01 08:01:17.938838: step 123960, loss = 0.29, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 9h:07m:01s remains)
INFO - root - 2017-12-01 08:01:19.498620: step 123970, loss = 0.36, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 9h:01m:02s remains)
INFO - root - 2017-12-01 08:01:21.064162: step 123980, loss = 0.30, batch loss = 0.20 (49.7 examples/sec; 0.161 sec/batch; 9h:19m:23s remains)
INFO - root - 2017-12-01 08:01:22.638149: step 123990, loss = 0.32, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 8h:55m:40s remains)
INFO - root - 2017-12-01 08:01:24.190983: step 124000, loss = 0.25, batch loss = 0.15 (52.7 examples/sec; 0.152 sec/batch; 8h:47m:25s remains)
INFO - root - 2017-12-01 08:01:25.809018: step 124010, loss = 0.34, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 8h:55m:34s remains)
INFO - root - 2017-12-01 08:01:27.364204: step 124020, loss = 0.23, batch loss = 0.13 (52.6 examples/sec; 0.152 sec/batch; 8h:48m:30s remains)
INFO - root - 2017-12-01 08:01:28.909810: step 124030, loss = 0.37, batch loss = 0.27 (53.4 examples/sec; 0.150 sec/batch; 8h:40m:30s remains)
INFO - root - 2017-12-01 08:01:30.479088: step 124040, loss = 0.55, batch loss = 0.45 (52.3 examples/sec; 0.153 sec/batch; 8h:51m:31s remains)
INFO - root - 2017-12-01 08:01:32.055000: step 124050, loss = 0.41, batch loss = 0.31 (52.0 examples/sec; 0.154 sec/batch; 8h:54m:03s remains)
INFO - root - 2017-12-01 08:01:33.632309: step 124060, loss = 0.30, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 8h:57m:30s remains)
INFO - root - 2017-12-01 08:01:35.196445: step 124070, loss = 0.29, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 8h:58m:39s remains)
INFO - root - 2017-12-01 08:01:36.776746: step 124080, loss = 0.30, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 8h:57m:39s remains)
INFO - root - 2017-12-01 08:01:38.333665: step 124090, loss = 0.40, batch loss = 0.30 (51.7 examples/sec; 0.155 sec/batch; 8h:57m:23s remains)
INFO - root - 2017-12-01 08:01:39.904122: step 124100, loss = 0.34, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 9h:10m:59s remains)
INFO - root - 2017-12-01 08:01:41.562896: step 124110, loss = 0.32, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 9h:07m:18s remains)
INFO - root - 2017-12-01 08:01:43.113594: step 124120, loss = 0.29, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 8h:59m:22s remains)
INFO - root - 2017-12-01 08:01:44.664265: step 124130, loss = 0.25, batch loss = 0.15 (50.1 examples/sec; 0.160 sec/batch; 9h:14m:54s remains)
INFO - root - 2017-12-01 08:01:46.234289: step 124140, loss = 0.30, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 8h:55m:33s remains)
INFO - root - 2017-12-01 08:01:47.803839: step 124150, loss = 0.38, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 9h:02m:50s remains)
INFO - root - 2017-12-01 08:01:49.369339: step 124160, loss = 0.31, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 8h:54m:17s remains)
INFO - root - 2017-12-01 08:01:50.917317: step 124170, loss = 0.37, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 9h:03m:51s remains)
INFO - root - 2017-12-01 08:01:52.470012: step 124180, loss = 0.25, batch loss = 0.15 (51.1 examples/sec; 0.156 sec/batch; 9h:03m:02s remains)
INFO - root - 2017-12-01 08:01:54.022285: step 124190, loss = 0.34, batch loss = 0.24 (50.8 examples/sec; 0.157 sec/batch; 9h:06m:21s remains)
INFO - root - 2017-12-01 08:01:55.587557: step 124200, loss = 0.27, batch loss = 0.17 (50.2 examples/sec; 0.160 sec/batch; 9h:13m:45s remains)
INFO - root - 2017-12-01 08:01:57.254064: step 124210, loss = 0.29, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 8h:52m:23s remains)
INFO - root - 2017-12-01 08:01:58.816858: step 124220, loss = 0.25, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 8h:58m:14s remains)
INFO - root - 2017-12-01 08:02:00.380361: step 124230, loss = 0.35, batch loss = 0.26 (47.9 examples/sec; 0.167 sec/batch; 9h:40m:12s remains)
INFO - root - 2017-12-01 08:02:01.943200: step 124240, loss = 0.35, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 9h:00m:19s remains)
INFO - root - 2017-12-01 08:02:03.510829: step 124250, loss = 0.33, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 9h:03m:46s remains)
INFO - root - 2017-12-01 08:02:05.067451: step 124260, loss = 0.35, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 9h:11m:10s remains)
INFO - root - 2017-12-01 08:02:06.631375: step 124270, loss = 0.38, batch loss = 0.28 (51.5 examples/sec; 0.155 sec/batch; 8h:59m:23s remains)
INFO - root - 2017-12-01 08:02:08.218508: step 124280, loss = 0.34, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 9h:07m:27s remains)
INFO - root - 2017-12-01 08:02:09.782570: step 124290, loss = 0.35, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 9h:07m:03s remains)
INFO - root - 2017-12-01 08:02:11.338758: step 124300, loss = 0.35, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 9h:00m:07s remains)
INFO - root - 2017-12-01 08:02:12.965877: step 124310, loss = 0.34, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 8h:56m:59s remains)
INFO - root - 2017-12-01 08:02:14.558704: step 124320, loss = 0.31, batch loss = 0.21 (49.4 examples/sec; 0.162 sec/batch; 9h:22m:23s remains)
INFO - root - 2017-12-01 08:02:16.124727: step 124330, loss = 0.28, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 8h:53m:30s remains)
INFO - root - 2017-12-01 08:02:17.680752: step 124340, loss = 0.31, batch loss = 0.21 (52.7 examples/sec; 0.152 sec/batch; 8h:47m:07s remains)
INFO - root - 2017-12-01 08:02:19.262104: step 124350, loss = 0.40, batch loss = 0.30 (51.7 examples/sec; 0.155 sec/batch; 8h:57m:05s remains)
INFO - root - 2017-12-01 08:02:20.829834: step 124360, loss = 0.30, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 9h:02m:51s remains)
INFO - root - 2017-12-01 08:02:22.393264: step 124370, loss = 0.33, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 9h:08m:16s remains)
INFO - root - 2017-12-01 08:02:23.970798: step 124380, loss = 0.26, batch loss = 0.16 (48.6 examples/sec; 0.165 sec/batch; 9h:31m:06s remains)
INFO - root - 2017-12-01 08:02:25.553215: step 124390, loss = 0.33, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 9h:06m:30s remains)
INFO - root - 2017-12-01 08:02:27.142161: step 124400, loss = 0.27, batch loss = 0.17 (49.0 examples/sec; 0.163 sec/batch; 9h:25m:54s remains)
INFO - root - 2017-12-01 08:02:28.761084: step 124410, loss = 0.27, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 8h:58m:39s remains)
INFO - root - 2017-12-01 08:02:30.319941: step 124420, loss = 0.25, batch loss = 0.15 (51.8 examples/sec; 0.154 sec/batch; 8h:55m:26s remains)
INFO - root - 2017-12-01 08:02:31.887618: step 124430, loss = 0.34, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 8h:58m:48s remains)
INFO - root - 2017-12-01 08:02:33.455416: step 124440, loss = 0.33, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 9h:07m:05s remains)
INFO - root - 2017-12-01 08:02:35.003368: step 124450, loss = 0.29, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 8h:55m:36s remains)
INFO - root - 2017-12-01 08:02:36.583332: step 124460, loss = 0.49, batch loss = 0.39 (49.7 examples/sec; 0.161 sec/batch; 9h:18m:37s remains)
INFO - root - 2017-12-01 08:02:38.148016: step 124470, loss = 0.26, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 8h:53m:30s remains)
INFO - root - 2017-12-01 08:02:39.727276: step 124480, loss = 0.44, batch loss = 0.34 (50.1 examples/sec; 0.160 sec/batch; 9h:13m:31s remains)
INFO - root - 2017-12-01 08:02:41.303960: step 124490, loss = 0.44, batch loss = 0.34 (49.5 examples/sec; 0.162 sec/batch; 9h:20m:44s remains)
INFO - root - 2017-12-01 08:02:42.890078: step 124500, loss = 0.33, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 9h:01m:33s remains)
INFO - root - 2017-12-01 08:02:44.519591: step 124510, loss = 0.30, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 9h:16m:08s remains)
INFO - root - 2017-12-01 08:02:46.093414: step 124520, loss = 0.32, batch loss = 0.22 (48.4 examples/sec; 0.165 sec/batch; 9h:32m:23s remains)
INFO - root - 2017-12-01 08:02:47.657359: step 124530, loss = 0.29, batch loss = 0.19 (50.3 examples/sec; 0.159 sec/batch; 9h:11m:01s remains)
INFO - root - 2017-12-01 08:02:49.232526: step 124540, loss = 0.31, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 9h:05m:28s remains)
INFO - root - 2017-12-01 08:02:50.799748: step 124550, loss = 0.37, batch loss = 0.27 (50.0 examples/sec; 0.160 sec/batch; 9h:14m:19s remains)
INFO - root - 2017-12-01 08:02:52.355378: step 124560, loss = 0.26, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 8h:52m:57s remains)
INFO - root - 2017-12-01 08:02:53.915679: step 124570, loss = 0.36, batch loss = 0.26 (53.3 examples/sec; 0.150 sec/batch; 8h:39m:40s remains)
INFO - root - 2017-12-01 08:02:55.497102: step 124580, loss = 0.34, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 8h:58m:36s remains)
INFO - root - 2017-12-01 08:02:57.074607: step 124590, loss = 0.30, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 9h:09m:50s remains)
INFO - root - 2017-12-01 08:02:58.634582: step 124600, loss = 0.27, batch loss = 0.17 (51.1 examples/sec; 0.156 sec/batch; 9h:02m:07s remains)
INFO - root - 2017-12-01 08:03:00.282979: step 124610, loss = 0.29, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 9h:20m:21s remains)
INFO - root - 2017-12-01 08:03:01.851595: step 124620, loss = 0.40, batch loss = 0.30 (50.4 examples/sec; 0.159 sec/batch; 9h:09m:48s remains)
INFO - root - 2017-12-01 08:03:03.423703: step 124630, loss = 0.34, batch loss = 0.24 (50.2 examples/sec; 0.159 sec/batch; 9h:12m:25s remains)
INFO - root - 2017-12-01 08:03:05.015070: step 124640, loss = 0.40, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 9h:04m:39s remains)
INFO - root - 2017-12-01 08:03:06.562676: step 124650, loss = 0.39, batch loss = 0.29 (51.8 examples/sec; 0.155 sec/batch; 8h:55m:13s remains)
INFO - root - 2017-12-01 08:03:08.142363: step 124660, loss = 0.27, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 9h:09m:33s remains)
INFO - root - 2017-12-01 08:03:09.700637: step 124670, loss = 0.37, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 8h:50m:43s remains)
INFO - root - 2017-12-01 08:03:11.280645: step 124680, loss = 0.34, batch loss = 0.24 (49.8 examples/sec; 0.161 sec/batch; 9h:16m:37s remains)
INFO - root - 2017-12-01 08:03:12.848104: step 124690, loss = 0.35, batch loss = 0.26 (50.3 examples/sec; 0.159 sec/batch; 9h:10m:24s remains)
INFO - root - 2017-12-01 08:03:14.413423: step 124700, loss = 0.30, batch loss = 0.20 (49.5 examples/sec; 0.162 sec/batch; 9h:19m:51s remains)
INFO - root - 2017-12-01 08:03:16.071002: step 124710, loss = 0.41, batch loss = 0.31 (52.2 examples/sec; 0.153 sec/batch; 8h:50m:35s remains)
INFO - root - 2017-12-01 08:03:17.633664: step 124720, loss = 0.35, batch loss = 0.25 (50.3 examples/sec; 0.159 sec/batch; 9h:11m:17s remains)
INFO - root - 2017-12-01 08:03:19.206639: step 124730, loss = 0.38, batch loss = 0.28 (49.0 examples/sec; 0.163 sec/batch; 9h:25m:28s remains)
INFO - root - 2017-12-01 08:03:20.798620: step 124740, loss = 0.27, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 9h:08m:13s remains)
INFO - root - 2017-12-01 08:03:22.397480: step 124750, loss = 0.44, batch loss = 0.34 (49.5 examples/sec; 0.162 sec/batch; 9h:19m:32s remains)
INFO - root - 2017-12-01 08:03:23.950974: step 124760, loss = 0.41, batch loss = 0.31 (50.3 examples/sec; 0.159 sec/batch; 9h:10m:36s remains)
INFO - root - 2017-12-01 08:03:25.507074: step 124770, loss = 0.35, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 8h:59m:47s remains)
INFO - root - 2017-12-01 08:03:27.088483: step 124780, loss = 0.29, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 8h:47m:04s remains)
INFO - root - 2017-12-01 08:03:28.656434: step 124790, loss = 0.26, batch loss = 0.16 (50.5 examples/sec; 0.158 sec/batch; 9h:08m:38s remains)
INFO - root - 2017-12-01 08:03:30.214200: step 124800, loss = 0.31, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 9h:07m:23s remains)
INFO - root - 2017-12-01 08:03:31.831254: step 124810, loss = 0.36, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 9h:02m:45s remains)
INFO - root - 2017-12-01 08:03:33.385867: step 124820, loss = 0.36, batch loss = 0.26 (51.8 examples/sec; 0.155 sec/batch; 8h:54m:52s remains)
INFO - root - 2017-12-01 08:03:34.963364: step 124830, loss = 0.31, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 9h:09m:44s remains)
INFO - root - 2017-12-01 08:03:36.533624: step 124840, loss = 0.27, batch loss = 0.17 (50.1 examples/sec; 0.160 sec/batch; 9h:12m:24s remains)
INFO - root - 2017-12-01 08:03:38.096545: step 124850, loss = 0.29, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 8h:56m:48s remains)
INFO - root - 2017-12-01 08:03:39.672740: step 124860, loss = 0.29, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 8h:53m:21s remains)
INFO - root - 2017-12-01 08:03:41.237579: step 124870, loss = 0.28, batch loss = 0.18 (51.8 examples/sec; 0.155 sec/batch; 8h:54m:42s remains)
INFO - root - 2017-12-01 08:03:42.796799: step 124880, loss = 0.42, batch loss = 0.32 (50.8 examples/sec; 0.157 sec/batch; 9h:04m:50s remains)
INFO - root - 2017-12-01 08:03:44.352025: step 124890, loss = 0.37, batch loss = 0.27 (49.5 examples/sec; 0.161 sec/batch; 9h:18m:41s remains)
INFO - root - 2017-12-01 08:03:45.925591: step 124900, loss = 0.27, batch loss = 0.17 (52.1 examples/sec; 0.154 sec/batch; 8h:51m:37s remains)
INFO - root - 2017-12-01 08:03:47.552357: step 124910, loss = 0.32, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 9h:02m:04s remains)
INFO - root - 2017-12-01 08:03:49.097995: step 124920, loss = 0.29, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 8h:57m:18s remains)
INFO - root - 2017-12-01 08:03:50.659234: step 124930, loss = 0.30, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 9h:01m:50s remains)
INFO - root - 2017-12-01 08:03:52.238944: step 124940, loss = 0.27, batch loss = 0.17 (51.1 examples/sec; 0.156 sec/batch; 9h:01m:04s remains)
INFO - root - 2017-12-01 08:03:53.789879: step 124950, loss = 0.28, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 8h:59m:20s remains)
INFO - root - 2017-12-01 08:03:55.352626: step 124960, loss = 0.31, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 9h:05m:04s remains)
INFO - root - 2017-12-01 08:03:56.924331: step 124970, loss = 0.32, batch loss = 0.22 (49.2 examples/sec; 0.162 sec/batch; 9h:21m:56s remains)
INFO - root - 2017-12-01 08:03:58.491084: step 124980, loss = 0.29, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 9h:03m:13s remains)
INFO - root - 2017-12-01 08:04:00.078736: step 124990, loss = 0.23, batch loss = 0.14 (50.8 examples/sec; 0.158 sec/batch; 9h:05m:07s remains)
INFO - root - 2017-12-01 08:04:01.631680: step 125000, loss = 0.32, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 9h:01m:18s remains)
INFO - root - 2017-12-01 08:04:03.233603: step 125010, loss = 0.27, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 8h:57m:01s remains)
INFO - root - 2017-12-01 08:04:04.798517: step 125020, loss = 0.30, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 8h:50m:13s remains)
INFO - root - 2017-12-01 08:04:06.363743: step 125030, loss = 0.38, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 9h:02m:24s remains)
INFO - root - 2017-12-01 08:04:07.935195: step 125040, loss = 0.30, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 8h:49m:53s remains)
INFO - root - 2017-12-01 08:04:09.489410: step 125050, loss = 0.29, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 9h:07m:37s remains)
INFO - root - 2017-12-01 08:04:11.052979: step 125060, loss = 0.42, batch loss = 0.33 (51.4 examples/sec; 0.156 sec/batch; 8h:58m:09s remains)
INFO - root - 2017-12-01 08:04:12.609854: step 125070, loss = 0.43, batch loss = 0.33 (52.7 examples/sec; 0.152 sec/batch; 8h:44m:47s remains)
INFO - root - 2017-12-01 08:04:14.199295: step 125080, loss = 0.41, batch loss = 0.31 (51.9 examples/sec; 0.154 sec/batch; 8h:53m:20s remains)
INFO - root - 2017-12-01 08:04:15.755683: step 125090, loss = 0.40, batch loss = 0.30 (51.0 examples/sec; 0.157 sec/batch; 9h:02m:15s remains)
INFO - root - 2017-12-01 08:04:17.325276: step 125100, loss = 0.31, batch loss = 0.21 (49.6 examples/sec; 0.161 sec/batch; 9h:17m:07s remains)
INFO - root - 2017-12-01 08:04:18.980910: step 125110, loss = 0.30, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 8h:57m:13s remains)
INFO - root - 2017-12-01 08:04:20.548660: step 125120, loss = 0.34, batch loss = 0.24 (47.8 examples/sec; 0.167 sec/batch; 9h:38m:49s remains)
INFO - root - 2017-12-01 08:04:22.121415: step 125130, loss = 0.40, batch loss = 0.30 (49.6 examples/sec; 0.161 sec/batch; 9h:17m:25s remains)
INFO - root - 2017-12-01 08:04:23.723619: step 125140, loss = 0.29, batch loss = 0.19 (50.5 examples/sec; 0.159 sec/batch; 9h:07m:47s remains)
INFO - root - 2017-12-01 08:04:25.276106: step 125150, loss = 0.38, batch loss = 0.28 (51.1 examples/sec; 0.157 sec/batch; 9h:01m:23s remains)
INFO - root - 2017-12-01 08:04:26.839517: step 125160, loss = 0.32, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 9h:10m:19s remains)
INFO - root - 2017-12-01 08:04:28.389060: step 125170, loss = 0.36, batch loss = 0.26 (51.1 examples/sec; 0.157 sec/batch; 9h:01m:19s remains)
INFO - root - 2017-12-01 08:04:29.957326: step 125180, loss = 0.37, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 8h:55m:51s remains)
INFO - root - 2017-12-01 08:04:31.503542: step 125190, loss = 0.31, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 9h:01m:41s remains)
INFO - root - 2017-12-01 08:04:33.064736: step 125200, loss = 0.29, batch loss = 0.19 (51.1 examples/sec; 0.156 sec/batch; 9h:00m:23s remains)
INFO - root - 2017-12-01 08:04:34.667147: step 125210, loss = 0.25, batch loss = 0.15 (51.7 examples/sec; 0.155 sec/batch; 8h:54m:23s remains)
INFO - root - 2017-12-01 08:04:36.236019: step 125220, loss = 0.24, batch loss = 0.14 (50.9 examples/sec; 0.157 sec/batch; 9h:02m:36s remains)
INFO - root - 2017-12-01 08:04:37.798471: step 125230, loss = 0.38, batch loss = 0.28 (52.0 examples/sec; 0.154 sec/batch; 8h:51m:57s remains)
INFO - root - 2017-12-01 08:04:39.358482: step 125240, loss = 0.29, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 8h:49m:29s remains)
INFO - root - 2017-12-01 08:04:40.947139: step 125250, loss = 0.29, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 8h:59m:31s remains)
INFO - root - 2017-12-01 08:04:42.506470: step 125260, loss = 0.34, batch loss = 0.24 (50.0 examples/sec; 0.160 sec/batch; 9h:12m:43s remains)
INFO - root - 2017-12-01 08:04:44.084416: step 125270, loss = 0.27, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 8h:53m:57s remains)
INFO - root - 2017-12-01 08:04:45.661001: step 125280, loss = 0.38, batch loss = 0.28 (50.0 examples/sec; 0.160 sec/batch; 9h:12m:45s remains)
INFO - root - 2017-12-01 08:04:47.225058: step 125290, loss = 0.29, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 9h:06m:11s remains)
INFO - root - 2017-12-01 08:04:48.779243: step 125300, loss = 0.29, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 8h:57m:55s remains)
INFO - root - 2017-12-01 08:04:50.436617: step 125310, loss = 0.38, batch loss = 0.28 (49.5 examples/sec; 0.162 sec/batch; 9h:18m:02s remains)
INFO - root - 2017-12-01 08:04:52.002818: step 125320, loss = 0.34, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 8h:59m:57s remains)
INFO - root - 2017-12-01 08:04:53.584188: step 125330, loss = 0.41, batch loss = 0.31 (50.0 examples/sec; 0.160 sec/batch; 9h:12m:28s remains)
INFO - root - 2017-12-01 08:04:55.174430: step 125340, loss = 0.35, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 8h:54m:32s remains)
INFO - root - 2017-12-01 08:04:56.742690: step 125350, loss = 0.26, batch loss = 0.16 (50.2 examples/sec; 0.159 sec/batch; 9h:09m:42s remains)
INFO - root - 2017-12-01 08:04:58.276235: step 125360, loss = 0.29, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 9h:03m:52s remains)
INFO - root - 2017-12-01 08:04:59.839106: step 125370, loss = 0.33, batch loss = 0.24 (49.3 examples/sec; 0.162 sec/batch; 9h:20m:33s remains)
INFO - root - 2017-12-01 08:05:01.419510: step 125380, loss = 0.25, batch loss = 0.15 (52.7 examples/sec; 0.152 sec/batch; 8h:43m:48s remains)
INFO - root - 2017-12-01 08:05:02.965102: step 125390, loss = 0.39, batch loss = 0.29 (53.3 examples/sec; 0.150 sec/batch; 8h:38m:29s remains)
INFO - root - 2017-12-01 08:05:04.545817: step 125400, loss = 0.30, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 8h:53m:40s remains)
INFO - root - 2017-12-01 08:05:06.149216: step 125410, loss = 0.28, batch loss = 0.18 (53.4 examples/sec; 0.150 sec/batch; 8h:37m:25s remains)
INFO - root - 2017-12-01 08:05:07.711319: step 125420, loss = 0.33, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 9h:03m:51s remains)
INFO - root - 2017-12-01 08:05:09.271951: step 125430, loss = 0.41, batch loss = 0.31 (52.2 examples/sec; 0.153 sec/batch; 8h:49m:22s remains)
INFO - root - 2017-12-01 08:05:10.825088: step 125440, loss = 0.32, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 9h:07m:22s remains)
INFO - root - 2017-12-01 08:05:12.405123: step 125450, loss = 0.32, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 9h:05m:26s remains)
INFO - root - 2017-12-01 08:05:13.955845: step 125460, loss = 0.35, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 8h:59m:40s remains)
INFO - root - 2017-12-01 08:05:15.511020: step 125470, loss = 0.26, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 9h:02m:47s remains)
INFO - root - 2017-12-01 08:05:17.075031: step 125480, loss = 0.32, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 9h:07m:27s remains)
INFO - root - 2017-12-01 08:05:18.642751: step 125490, loss = 0.36, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 9h:00m:56s remains)
INFO - root - 2017-12-01 08:05:20.206362: step 125500, loss = 0.24, batch loss = 0.14 (50.3 examples/sec; 0.159 sec/batch; 9h:08m:31s remains)
INFO - root - 2017-12-01 08:05:21.867346: step 125510, loss = 0.24, batch loss = 0.14 (51.9 examples/sec; 0.154 sec/batch; 8h:51m:52s remains)
INFO - root - 2017-12-01 08:05:23.424556: step 125520, loss = 0.37, batch loss = 0.27 (51.1 examples/sec; 0.156 sec/batch; 8h:59m:36s remains)
INFO - root - 2017-12-01 08:05:24.991874: step 125530, loss = 0.32, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 9h:05m:00s remains)
INFO - root - 2017-12-01 08:05:26.557071: step 125540, loss = 0.29, batch loss = 0.19 (52.1 examples/sec; 0.153 sec/batch; 8h:49m:26s remains)
INFO - root - 2017-12-01 08:05:28.137650: step 125550, loss = 0.31, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 9h:06m:24s remains)
INFO - root - 2017-12-01 08:05:29.713813: step 125560, loss = 0.30, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 9h:12m:46s remains)
INFO - root - 2017-12-01 08:05:31.289147: step 125570, loss = 0.31, batch loss = 0.22 (49.0 examples/sec; 0.163 sec/batch; 9h:23m:06s remains)
INFO - root - 2017-12-01 08:05:32.865201: step 125580, loss = 0.46, batch loss = 0.36 (51.6 examples/sec; 0.155 sec/batch; 8h:54m:10s remains)
INFO - root - 2017-12-01 08:05:34.417155: step 125590, loss = 0.31, batch loss = 0.22 (53.1 examples/sec; 0.151 sec/batch; 8h:39m:27s remains)
INFO - root - 2017-12-01 08:05:35.986020: step 125600, loss = 0.29, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 8h:59m:43s remains)
INFO - root - 2017-12-01 08:05:37.595144: step 125610, loss = 0.34, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 9h:05m:50s remains)
INFO - root - 2017-12-01 08:05:39.163345: step 125620, loss = 0.32, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 8h:59m:15s remains)
INFO - root - 2017-12-01 08:05:40.736993: step 125630, loss = 0.29, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 9h:12m:39s remains)
INFO - root - 2017-12-01 08:05:42.317739: step 125640, loss = 0.39, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 9h:08m:27s remains)
INFO - root - 2017-12-01 08:05:43.882547: step 125650, loss = 0.42, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 9h:04m:29s remains)
INFO - root - 2017-12-01 08:05:45.445582: step 125660, loss = 0.34, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 8h:47m:05s remains)
INFO - root - 2017-12-01 08:05:47.013725: step 125670, loss = 0.31, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 8h:52m:25s remains)
INFO - root - 2017-12-01 08:05:48.591349: step 125680, loss = 0.36, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 9h:07m:31s remains)
INFO - root - 2017-12-01 08:05:50.142034: step 125690, loss = 0.34, batch loss = 0.24 (49.5 examples/sec; 0.162 sec/batch; 9h:16m:46s remains)
INFO - root - 2017-12-01 08:05:51.699109: step 125700, loss = 0.28, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 8h:52m:18s remains)
INFO - root - 2017-12-01 08:05:53.318153: step 125710, loss = 0.37, batch loss = 0.27 (50.8 examples/sec; 0.157 sec/batch; 9h:02m:38s remains)
INFO - root - 2017-12-01 08:05:54.867092: step 125720, loss = 0.26, batch loss = 0.16 (51.7 examples/sec; 0.155 sec/batch; 8h:53m:34s remains)
INFO - root - 2017-12-01 08:05:56.423899: step 125730, loss = 0.34, batch loss = 0.24 (52.1 examples/sec; 0.154 sec/batch; 8h:49m:33s remains)
INFO - root - 2017-12-01 08:05:57.991277: step 125740, loss = 0.37, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 8h:47m:45s remains)
INFO - root - 2017-12-01 08:05:59.546794: step 125750, loss = 0.33, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 8h:51m:16s remains)
INFO - root - 2017-12-01 08:06:01.129768: step 125760, loss = 0.29, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 9h:01m:46s remains)
INFO - root - 2017-12-01 08:06:02.687489: step 125770, loss = 0.26, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 9h:01m:11s remains)
INFO - root - 2017-12-01 08:06:04.267624: step 125780, loss = 0.32, batch loss = 0.22 (48.4 examples/sec; 0.165 sec/batch; 9h:29m:34s remains)
INFO - root - 2017-12-01 08:06:05.875836: step 125790, loss = 0.33, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 8h:56m:25s remains)
INFO - root - 2017-12-01 08:06:07.464351: step 125800, loss = 0.28, batch loss = 0.18 (49.8 examples/sec; 0.161 sec/batch; 9h:13m:34s remains)
INFO - root - 2017-12-01 08:06:09.130813: step 125810, loss = 0.34, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 8h:58m:56s remains)
INFO - root - 2017-12-01 08:06:10.712923: step 125820, loss = 0.26, batch loss = 0.16 (48.4 examples/sec; 0.165 sec/batch; 9h:29m:29s remains)
INFO - root - 2017-12-01 08:06:12.276160: step 125830, loss = 0.31, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 8h:57m:50s remains)
INFO - root - 2017-12-01 08:06:13.847315: step 125840, loss = 0.32, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 8h:45m:08s remains)
INFO - root - 2017-12-01 08:06:15.421577: step 125850, loss = 0.30, batch loss = 0.20 (51.8 examples/sec; 0.155 sec/batch; 8h:52m:18s remains)
INFO - root - 2017-12-01 08:06:16.973735: step 125860, loss = 0.26, batch loss = 0.16 (50.1 examples/sec; 0.160 sec/batch; 9h:10m:22s remains)
INFO - root - 2017-12-01 08:06:18.539591: step 125870, loss = 0.29, batch loss = 0.19 (48.6 examples/sec; 0.164 sec/batch; 9h:26m:25s remains)
INFO - root - 2017-12-01 08:06:20.120104: step 125880, loss = 0.37, batch loss = 0.27 (52.4 examples/sec; 0.153 sec/batch; 8h:45m:32s remains)
INFO - root - 2017-12-01 08:06:21.685869: step 125890, loss = 0.34, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 8h:50m:36s remains)
INFO - root - 2017-12-01 08:06:23.254098: step 125900, loss = 0.39, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 8h:57m:13s remains)
INFO - root - 2017-12-01 08:06:24.901864: step 125910, loss = 0.27, batch loss = 0.17 (50.7 examples/sec; 0.158 sec/batch; 9h:03m:46s remains)
INFO - root - 2017-12-01 08:06:26.463709: step 125920, loss = 0.25, batch loss = 0.15 (51.2 examples/sec; 0.156 sec/batch; 8h:57m:48s remains)
INFO - root - 2017-12-01 08:06:28.029248: step 125930, loss = 0.36, batch loss = 0.26 (49.8 examples/sec; 0.161 sec/batch; 9h:13m:27s remains)
INFO - root - 2017-12-01 08:06:29.590018: step 125940, loss = 0.24, batch loss = 0.14 (52.5 examples/sec; 0.152 sec/batch; 8h:44m:46s remains)
INFO - root - 2017-12-01 08:06:31.170166: step 125950, loss = 0.27, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 8h:59m:31s remains)
INFO - root - 2017-12-01 08:06:32.720304: step 125960, loss = 0.34, batch loss = 0.24 (52.7 examples/sec; 0.152 sec/batch; 8h:42m:04s remains)
INFO - root - 2017-12-01 08:06:34.301865: step 125970, loss = 0.40, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 9h:01m:26s remains)
INFO - root - 2017-12-01 08:06:35.850779: step 125980, loss = 0.36, batch loss = 0.26 (51.1 examples/sec; 0.157 sec/batch; 8h:59m:15s remains)
INFO - root - 2017-12-01 08:06:37.414829: step 125990, loss = 0.30, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 8h:53m:22s remains)
INFO - root - 2017-12-01 08:06:38.998054: step 126000, loss = 0.30, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 8h:57m:54s remains)
INFO - root - 2017-12-01 08:06:40.650911: step 126010, loss = 0.27, batch loss = 0.17 (49.1 examples/sec; 0.163 sec/batch; 9h:20m:34s remains)
INFO - root - 2017-12-01 08:06:42.291817: step 126020, loss = 0.29, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 9h:02m:09s remains)
INFO - root - 2017-12-01 08:06:43.842795: step 126030, loss = 0.33, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 8h:56m:14s remains)
INFO - root - 2017-12-01 08:06:45.409137: step 126040, loss = 0.25, batch loss = 0.15 (51.8 examples/sec; 0.154 sec/batch; 8h:51m:13s remains)
INFO - root - 2017-12-01 08:06:46.989050: step 126050, loss = 0.28, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 8h:57m:39s remains)
INFO - root - 2017-12-01 08:06:48.561042: step 126060, loss = 0.33, batch loss = 0.23 (45.9 examples/sec; 0.174 sec/batch; 10h:00m:16s remains)
INFO - root - 2017-12-01 08:06:50.143769: step 126070, loss = 0.30, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 9h:11m:07s remains)
INFO - root - 2017-12-01 08:06:51.709562: step 126080, loss = 0.24, batch loss = 0.14 (53.3 examples/sec; 0.150 sec/batch; 8h:36m:18s remains)
INFO - root - 2017-12-01 08:06:53.253774: step 126090, loss = 0.30, batch loss = 0.20 (48.7 examples/sec; 0.164 sec/batch; 9h:25m:22s remains)
INFO - root - 2017-12-01 08:06:54.822528: step 126100, loss = 0.39, batch loss = 0.29 (51.4 examples/sec; 0.156 sec/batch; 8h:55m:14s remains)
INFO - root - 2017-12-01 08:06:56.455497: step 126110, loss = 0.52, batch loss = 0.42 (51.9 examples/sec; 0.154 sec/batch; 8h:50m:25s remains)
INFO - root - 2017-12-01 08:06:58.033376: step 126120, loss = 0.29, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 9h:00m:20s remains)
INFO - root - 2017-12-01 08:06:59.604233: step 126130, loss = 0.27, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 8h:58m:30s remains)
INFO - root - 2017-12-01 08:07:01.168211: step 126140, loss = 0.32, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 9h:01m:55s remains)
INFO - root - 2017-12-01 08:07:02.720236: step 126150, loss = 0.26, batch loss = 0.17 (52.3 examples/sec; 0.153 sec/batch; 8h:45m:50s remains)
INFO - root - 2017-12-01 08:07:04.263849: step 126160, loss = 0.39, batch loss = 0.29 (53.4 examples/sec; 0.150 sec/batch; 8h:35m:40s remains)
INFO - root - 2017-12-01 08:07:05.823875: step 126170, loss = 0.29, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 8h:44m:07s remains)
INFO - root - 2017-12-01 08:07:07.383280: step 126180, loss = 0.32, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 8h:59m:21s remains)
INFO - root - 2017-12-01 08:07:08.937388: step 126190, loss = 0.31, batch loss = 0.22 (50.8 examples/sec; 0.158 sec/batch; 9h:01m:46s remains)
INFO - root - 2017-12-01 08:07:10.497562: step 126200, loss = 0.29, batch loss = 0.19 (50.1 examples/sec; 0.160 sec/batch; 9h:09m:05s remains)
INFO - root - 2017-12-01 08:07:12.117561: step 126210, loss = 0.33, batch loss = 0.23 (52.1 examples/sec; 0.154 sec/batch; 8h:48m:24s remains)
INFO - root - 2017-12-01 08:07:13.689534: step 126220, loss = 0.38, batch loss = 0.29 (52.0 examples/sec; 0.154 sec/batch; 8h:49m:15s remains)
INFO - root - 2017-12-01 08:07:15.257828: step 126230, loss = 0.44, batch loss = 0.34 (51.3 examples/sec; 0.156 sec/batch; 8h:56m:23s remains)
INFO - root - 2017-12-01 08:07:16.815820: step 126240, loss = 0.29, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 8h:50m:31s remains)
INFO - root - 2017-12-01 08:07:18.367177: step 126250, loss = 0.32, batch loss = 0.23 (49.6 examples/sec; 0.161 sec/batch; 9h:14m:32s remains)
INFO - root - 2017-12-01 08:07:19.947904: step 126260, loss = 0.29, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 8h:56m:21s remains)
INFO - root - 2017-12-01 08:07:21.519812: step 126270, loss = 0.34, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 8h:56m:56s remains)
INFO - root - 2017-12-01 08:07:23.084691: step 126280, loss = 0.30, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 9h:02m:49s remains)
INFO - root - 2017-12-01 08:07:24.650525: step 126290, loss = 0.29, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 8h:55m:57s remains)
INFO - root - 2017-12-01 08:07:26.195495: step 126300, loss = 0.35, batch loss = 0.25 (53.7 examples/sec; 0.149 sec/batch; 8h:32m:01s remains)
INFO - root - 2017-12-01 08:07:27.820383: step 126310, loss = 0.47, batch loss = 0.37 (51.2 examples/sec; 0.156 sec/batch; 8h:56m:49s remains)
INFO - root - 2017-12-01 08:07:29.372789: step 126320, loss = 0.35, batch loss = 0.25 (50.5 examples/sec; 0.158 sec/batch; 9h:04m:37s remains)
INFO - root - 2017-12-01 08:07:30.932356: step 126330, loss = 0.28, batch loss = 0.18 (49.6 examples/sec; 0.161 sec/batch; 9h:14m:19s remains)
INFO - root - 2017-12-01 08:07:32.503170: step 126340, loss = 0.32, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 9h:02m:14s remains)
INFO - root - 2017-12-01 08:07:34.080271: step 126350, loss = 0.31, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 8h:47m:26s remains)
INFO - root - 2017-12-01 08:07:35.655722: step 126360, loss = 0.30, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 8h:54m:53s remains)
INFO - root - 2017-12-01 08:07:37.241459: step 126370, loss = 0.28, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 8h:52m:50s remains)
INFO - root - 2017-12-01 08:07:38.805319: step 126380, loss = 0.47, batch loss = 0.38 (52.2 examples/sec; 0.153 sec/batch; 8h:46m:54s remains)
INFO - root - 2017-12-01 08:07:40.355257: step 126390, loss = 0.24, batch loss = 0.15 (51.5 examples/sec; 0.155 sec/batch; 8h:53m:48s remains)
INFO - root - 2017-12-01 08:07:41.933518: step 126400, loss = 0.32, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 8h:59m:40s remains)
INFO - root - 2017-12-01 08:07:43.582485: step 126410, loss = 0.26, batch loss = 0.16 (51.1 examples/sec; 0.157 sec/batch; 8h:57m:38s remains)
INFO - root - 2017-12-01 08:07:45.154276: step 126420, loss = 0.27, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 9h:06m:17s remains)
INFO - root - 2017-12-01 08:07:46.713365: step 126430, loss = 0.34, batch loss = 0.24 (50.8 examples/sec; 0.157 sec/batch; 9h:00m:50s remains)
INFO - root - 2017-12-01 08:07:48.265273: step 126440, loss = 0.48, batch loss = 0.39 (50.5 examples/sec; 0.158 sec/batch; 9h:04m:10s remains)
INFO - root - 2017-12-01 08:07:49.822437: step 126450, loss = 0.36, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 8h:41m:07s remains)
INFO - root - 2017-12-01 08:07:51.419259: step 126460, loss = 0.29, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 8h:52m:39s remains)
INFO - root - 2017-12-01 08:07:52.972929: step 126470, loss = 0.48, batch loss = 0.38 (52.4 examples/sec; 0.153 sec/batch; 8h:44m:08s remains)
INFO - root - 2017-12-01 08:07:54.539123: step 126480, loss = 0.29, batch loss = 0.19 (49.3 examples/sec; 0.162 sec/batch; 9h:17m:02s remains)
INFO - root - 2017-12-01 08:07:56.110798: step 126490, loss = 0.28, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 8h:55m:47s remains)
INFO - root - 2017-12-01 08:07:57.675498: step 126500, loss = 0.29, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 8h:41m:44s remains)
INFO - root - 2017-12-01 08:07:59.319118: step 126510, loss = 0.28, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 8h:51m:13s remains)
INFO - root - 2017-12-01 08:08:00.875002: step 126520, loss = 0.31, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 8h:43m:11s remains)
INFO - root - 2017-12-01 08:08:02.433468: step 126530, loss = 0.31, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 8h:42m:15s remains)
INFO - root - 2017-12-01 08:08:03.990672: step 126540, loss = 0.25, batch loss = 0.15 (50.9 examples/sec; 0.157 sec/batch; 8h:59m:01s remains)
INFO - root - 2017-12-01 08:08:05.559551: step 126550, loss = 0.25, batch loss = 0.15 (51.1 examples/sec; 0.156 sec/batch; 8h:57m:02s remains)
INFO - root - 2017-12-01 08:08:07.125719: step 126560, loss = 0.27, batch loss = 0.18 (49.0 examples/sec; 0.163 sec/batch; 9h:20m:10s remains)
INFO - root - 2017-12-01 08:08:08.683759: step 126570, loss = 0.30, batch loss = 0.20 (48.9 examples/sec; 0.164 sec/batch; 9h:21m:14s remains)
INFO - root - 2017-12-01 08:08:10.264816: step 126580, loss = 0.25, batch loss = 0.16 (52.3 examples/sec; 0.153 sec/batch; 8h:45m:11s remains)
INFO - root - 2017-12-01 08:08:11.822521: step 126590, loss = 0.27, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 8h:52m:02s remains)
INFO - root - 2017-12-01 08:08:13.388269: step 126600, loss = 0.27, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 8h:55m:47s remains)
INFO - root - 2017-12-01 08:08:15.008978: step 126610, loss = 0.32, batch loss = 0.22 (52.4 examples/sec; 0.153 sec/batch; 8h:43m:26s remains)
INFO - root - 2017-12-01 08:08:16.563315: step 126620, loss = 0.36, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 8h:54m:57s remains)
INFO - root - 2017-12-01 08:08:18.111738: step 126630, loss = 0.30, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 8h:49m:36s remains)
INFO - root - 2017-12-01 08:08:19.680635: step 126640, loss = 0.41, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 8h:59m:42s remains)
INFO - root - 2017-12-01 08:08:21.247480: step 126650, loss = 0.27, batch loss = 0.18 (48.9 examples/sec; 0.164 sec/batch; 9h:21m:04s remains)
INFO - root - 2017-12-01 08:08:22.823988: step 126660, loss = 0.23, batch loss = 0.13 (51.3 examples/sec; 0.156 sec/batch; 8h:54m:46s remains)
INFO - root - 2017-12-01 08:08:24.397351: step 126670, loss = 0.28, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 8h:51m:27s remains)
INFO - root - 2017-12-01 08:08:25.958663: step 126680, loss = 0.32, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 8h:50m:39s remains)
INFO - root - 2017-12-01 08:08:27.512452: step 126690, loss = 0.31, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 8h:56m:06s remains)
INFO - root - 2017-12-01 08:08:29.074994: step 126700, loss = 0.32, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 8h:55m:33s remains)
INFO - root - 2017-12-01 08:08:30.706623: step 126710, loss = 0.24, batch loss = 0.14 (51.8 examples/sec; 0.154 sec/batch; 8h:49m:45s remains)
INFO - root - 2017-12-01 08:08:32.293634: step 126720, loss = 0.57, batch loss = 0.47 (52.0 examples/sec; 0.154 sec/batch; 8h:47m:57s remains)
INFO - root - 2017-12-01 08:08:33.851653: step 126730, loss = 0.32, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 8h:44m:02s remains)
INFO - root - 2017-12-01 08:08:35.415025: step 126740, loss = 0.27, batch loss = 0.17 (52.6 examples/sec; 0.152 sec/batch; 8h:41m:22s remains)
INFO - root - 2017-12-01 08:08:36.999426: step 126750, loss = 0.26, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 9h:03m:59s remains)
INFO - root - 2017-12-01 08:08:38.554204: step 126760, loss = 0.36, batch loss = 0.26 (49.8 examples/sec; 0.161 sec/batch; 9h:11m:19s remains)
INFO - root - 2017-12-01 08:08:40.104469: step 126770, loss = 0.30, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 8h:49m:16s remains)
INFO - root - 2017-12-01 08:08:41.658658: step 126780, loss = 0.29, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 8h:59m:39s remains)
INFO - root - 2017-12-01 08:08:43.245834: step 126790, loss = 0.27, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 8h:54m:11s remains)
INFO - root - 2017-12-01 08:08:44.818083: step 126800, loss = 0.31, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 9h:02m:20s remains)
INFO - root - 2017-12-01 08:08:46.442408: step 126810, loss = 0.29, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 8h:42m:59s remains)
INFO - root - 2017-12-01 08:08:48.000565: step 126820, loss = 0.41, batch loss = 0.31 (50.5 examples/sec; 0.158 sec/batch; 9h:02m:47s remains)
INFO - root - 2017-12-01 08:08:49.570379: step 126830, loss = 0.35, batch loss = 0.26 (50.8 examples/sec; 0.158 sec/batch; 9h:00m:19s remains)
INFO - root - 2017-12-01 08:08:51.147712: step 126840, loss = 0.25, batch loss = 0.15 (49.2 examples/sec; 0.163 sec/batch; 9h:17m:35s remains)
INFO - root - 2017-12-01 08:08:52.693344: step 126850, loss = 0.30, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 8h:52m:41s remains)
INFO - root - 2017-12-01 08:08:54.267348: step 126860, loss = 0.24, batch loss = 0.14 (50.2 examples/sec; 0.159 sec/batch; 9h:06m:25s remains)
INFO - root - 2017-12-01 08:08:55.854737: step 126870, loss = 0.30, batch loss = 0.21 (49.3 examples/sec; 0.162 sec/batch; 9h:16m:28s remains)
INFO - root - 2017-12-01 08:08:57.406107: step 126880, loss = 0.30, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 8h:52m:38s remains)
INFO - root - 2017-12-01 08:08:58.961905: step 126890, loss = 0.27, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 9h:05m:29s remains)
INFO - root - 2017-12-01 08:09:00.523294: step 126900, loss = 0.29, batch loss = 0.20 (49.3 examples/sec; 0.162 sec/batch; 9h:16m:26s remains)
INFO - root - 2017-12-01 08:09:02.185979: step 126910, loss = 0.32, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 8h:53m:36s remains)
INFO - root - 2017-12-01 08:09:03.733846: step 126920, loss = 0.27, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 8h:47m:02s remains)
INFO - root - 2017-12-01 08:09:05.297343: step 126930, loss = 0.28, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 8h:58m:57s remains)
INFO - root - 2017-12-01 08:09:06.862654: step 126940, loss = 0.28, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 8h:51m:39s remains)
INFO - root - 2017-12-01 08:09:08.431123: step 126950, loss = 0.28, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 8h:48m:02s remains)
INFO - root - 2017-12-01 08:09:10.014010: step 126960, loss = 0.24, batch loss = 0.14 (49.9 examples/sec; 0.160 sec/batch; 9h:08m:43s remains)
INFO - root - 2017-12-01 08:09:11.584754: step 126970, loss = 0.27, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 8h:57m:39s remains)
INFO - root - 2017-12-01 08:09:13.162805: step 126980, loss = 0.41, batch loss = 0.31 (52.3 examples/sec; 0.153 sec/batch; 8h:43m:43s remains)
INFO - root - 2017-12-01 08:09:14.756421: step 126990, loss = 0.35, batch loss = 0.26 (49.5 examples/sec; 0.161 sec/batch; 9h:13m:00s remains)
INFO - root - 2017-12-01 08:09:16.319037: step 127000, loss = 0.30, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 8h:49m:46s remains)
INFO - root - 2017-12-01 08:09:17.970213: step 127010, loss = 0.30, batch loss = 0.20 (49.8 examples/sec; 0.161 sec/batch; 9h:09m:54s remains)
INFO - root - 2017-12-01 08:09:19.537587: step 127020, loss = 0.28, batch loss = 0.18 (48.9 examples/sec; 0.164 sec/batch; 9h:20m:21s remains)
INFO - root - 2017-12-01 08:09:21.094065: step 127030, loss = 0.29, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 8h:45m:00s remains)
INFO - root - 2017-12-01 08:09:22.653032: step 127040, loss = 0.37, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 9h:00m:09s remains)
INFO - root - 2017-12-01 08:09:24.243244: step 127050, loss = 0.33, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 8h:54m:18s remains)
INFO - root - 2017-12-01 08:09:25.803342: step 127060, loss = 0.32, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 9h:00m:02s remains)
INFO - root - 2017-12-01 08:09:27.371376: step 127070, loss = 0.25, batch loss = 0.15 (51.9 examples/sec; 0.154 sec/batch; 8h:48m:11s remains)
INFO - root - 2017-12-01 08:09:28.916292: step 127080, loss = 0.31, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 8h:46m:02s remains)
INFO - root - 2017-12-01 08:09:30.487818: step 127090, loss = 0.27, batch loss = 0.18 (52.1 examples/sec; 0.153 sec/batch; 8h:45m:18s remains)
INFO - root - 2017-12-01 08:09:32.073317: step 127100, loss = 0.25, batch loss = 0.15 (52.6 examples/sec; 0.152 sec/batch; 8h:41m:01s remains)
INFO - root - 2017-12-01 08:09:33.735783: step 127110, loss = 0.28, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 8h:52m:31s remains)
INFO - root - 2017-12-01 08:09:35.302695: step 127120, loss = 0.29, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 8h:54m:35s remains)
INFO - root - 2017-12-01 08:09:36.874293: step 127130, loss = 0.36, batch loss = 0.26 (50.8 examples/sec; 0.158 sec/batch; 8h:59m:27s remains)
INFO - root - 2017-12-01 08:09:38.433415: step 127140, loss = 0.33, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 8h:43m:58s remains)
INFO - root - 2017-12-01 08:09:40.015497: step 127150, loss = 0.32, batch loss = 0.22 (49.6 examples/sec; 0.161 sec/batch; 9h:11m:28s remains)
INFO - root - 2017-12-01 08:09:41.584228: step 127160, loss = 0.46, batch loss = 0.36 (52.2 examples/sec; 0.153 sec/batch; 8h:44m:55s remains)
INFO - root - 2017-12-01 08:09:43.175293: step 127170, loss = 0.47, batch loss = 0.37 (51.4 examples/sec; 0.156 sec/batch; 8h:52m:55s remains)
INFO - root - 2017-12-01 08:09:44.723386: step 127180, loss = 0.28, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 8h:46m:38s remains)
INFO - root - 2017-12-01 08:09:46.298412: step 127190, loss = 0.24, batch loss = 0.15 (52.6 examples/sec; 0.152 sec/batch; 8h:40m:43s remains)
INFO - root - 2017-12-01 08:09:47.859029: step 127200, loss = 0.36, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 8h:46m:06s remains)
INFO - root - 2017-12-01 08:09:49.465233: step 127210, loss = 0.36, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 8h:57m:55s remains)
INFO - root - 2017-12-01 08:09:51.018645: step 127220, loss = 0.30, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 8h:50m:01s remains)
INFO - root - 2017-12-01 08:09:52.577525: step 127230, loss = 0.32, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 8h:41m:12s remains)
INFO - root - 2017-12-01 08:09:54.140485: step 127240, loss = 0.23, batch loss = 0.13 (52.1 examples/sec; 0.153 sec/batch; 8h:45m:02s remains)
INFO - root - 2017-12-01 08:09:55.717517: step 127250, loss = 0.39, batch loss = 0.30 (49.5 examples/sec; 0.162 sec/batch; 9h:13m:04s remains)
INFO - root - 2017-12-01 08:09:57.280703: step 127260, loss = 0.28, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 8h:53m:16s remains)
INFO - root - 2017-12-01 08:09:58.844953: step 127270, loss = 0.22, batch loss = 0.12 (51.7 examples/sec; 0.155 sec/batch; 8h:49m:25s remains)
INFO - root - 2017-12-01 08:10:00.415815: step 127280, loss = 0.27, batch loss = 0.17 (51.1 examples/sec; 0.156 sec/batch; 8h:55m:02s remains)
INFO - root - 2017-12-01 08:10:01.979835: step 127290, loss = 0.41, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 8h:49m:51s remains)
INFO - root - 2017-12-01 08:10:03.545400: step 127300, loss = 0.46, batch loss = 0.36 (51.2 examples/sec; 0.156 sec/batch; 8h:54m:53s remains)
INFO - root - 2017-12-01 08:10:05.186005: step 127310, loss = 0.31, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 8h:43m:42s remains)
INFO - root - 2017-12-01 08:10:06.761221: step 127320, loss = 0.23, batch loss = 0.13 (50.6 examples/sec; 0.158 sec/batch; 9h:00m:50s remains)
INFO - root - 2017-12-01 08:10:08.323017: step 127330, loss = 0.30, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 8h:59m:35s remains)
INFO - root - 2017-12-01 08:10:09.898378: step 127340, loss = 0.29, batch loss = 0.19 (53.1 examples/sec; 0.151 sec/batch; 8h:35m:33s remains)
INFO - root - 2017-12-01 08:10:11.445608: step 127350, loss = 0.27, batch loss = 0.17 (53.0 examples/sec; 0.151 sec/batch; 8h:36m:06s remains)
INFO - root - 2017-12-01 08:10:13.014679: step 127360, loss = 0.26, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 8h:46m:22s remains)
INFO - root - 2017-12-01 08:10:14.594425: step 127370, loss = 0.29, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 9h:12m:54s remains)
INFO - root - 2017-12-01 08:10:16.151798: step 127380, loss = 0.28, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 9h:06m:52s remains)
INFO - root - 2017-12-01 08:10:17.693162: step 127390, loss = 0.31, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 8h:59m:52s remains)
INFO - root - 2017-12-01 08:10:19.232568: step 127400, loss = 0.28, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 8h:50m:46s remains)
INFO - root - 2017-12-01 08:10:20.908696: step 127410, loss = 0.32, batch loss = 0.22 (49.0 examples/sec; 0.163 sec/batch; 9h:17m:30s remains)
INFO - root - 2017-12-01 08:10:22.474903: step 127420, loss = 0.29, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 8h:46m:55s remains)
INFO - root - 2017-12-01 08:10:24.033094: step 127430, loss = 0.28, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 9h:01m:01s remains)
INFO - root - 2017-12-01 08:10:25.610364: step 127440, loss = 0.38, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 9h:01m:33s remains)
INFO - root - 2017-12-01 08:10:27.171915: step 127450, loss = 0.26, batch loss = 0.16 (50.6 examples/sec; 0.158 sec/batch; 9h:00m:02s remains)
INFO - root - 2017-12-01 08:10:28.744754: step 127460, loss = 0.33, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 8h:51m:19s remains)
INFO - root - 2017-12-01 08:10:30.291517: step 127470, loss = 0.23, batch loss = 0.13 (51.8 examples/sec; 0.154 sec/batch; 8h:47m:55s remains)
INFO - root - 2017-12-01 08:10:31.838335: step 127480, loss = 0.31, batch loss = 0.21 (53.4 examples/sec; 0.150 sec/batch; 8h:31m:37s remains)
INFO - root - 2017-12-01 08:10:33.389565: step 127490, loss = 0.42, batch loss = 0.32 (52.6 examples/sec; 0.152 sec/batch; 8h:39m:41s remains)
INFO - root - 2017-12-01 08:10:34.959469: step 127500, loss = 0.24, batch loss = 0.14 (51.6 examples/sec; 0.155 sec/batch; 8h:50m:12s remains)
INFO - root - 2017-12-01 08:10:36.577493: step 127510, loss = 0.40, batch loss = 0.30 (51.8 examples/sec; 0.155 sec/batch; 8h:47m:59s remains)
INFO - root - 2017-12-01 08:10:38.138733: step 127520, loss = 0.25, batch loss = 0.15 (52.0 examples/sec; 0.154 sec/batch; 8h:45m:28s remains)
INFO - root - 2017-12-01 08:10:39.696744: step 127530, loss = 0.34, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 8h:59m:29s remains)
INFO - root - 2017-12-01 08:10:41.286504: step 127540, loss = 0.24, batch loss = 0.14 (50.9 examples/sec; 0.157 sec/batch; 8h:57m:01s remains)
INFO - root - 2017-12-01 08:10:42.836977: step 127550, loss = 0.37, batch loss = 0.27 (50.1 examples/sec; 0.160 sec/batch; 9h:05m:47s remains)
INFO - root - 2017-12-01 08:10:44.403935: step 127560, loss = 0.27, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 8h:55m:38s remains)
INFO - root - 2017-12-01 08:10:45.988505: step 127570, loss = 0.31, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 8h:57m:57s remains)
INFO - root - 2017-12-01 08:10:47.557931: step 127580, loss = 0.43, batch loss = 0.33 (51.1 examples/sec; 0.156 sec/batch; 8h:54m:21s remains)
INFO - root - 2017-12-01 08:10:49.111282: step 127590, loss = 0.24, batch loss = 0.15 (51.6 examples/sec; 0.155 sec/batch; 8h:49m:58s remains)
INFO - root - 2017-12-01 08:10:50.679468: step 127600, loss = 0.40, batch loss = 0.30 (49.9 examples/sec; 0.160 sec/batch; 9h:07m:48s remains)
INFO - root - 2017-12-01 08:10:52.332749: step 127610, loss = 0.30, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 9h:07m:22s remains)
INFO - root - 2017-12-01 08:10:53.876343: step 127620, loss = 0.36, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 8h:38m:26s remains)
INFO - root - 2017-12-01 08:10:55.424797: step 127630, loss = 0.30, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 8h:43m:26s remains)
INFO - root - 2017-12-01 08:10:57.018487: step 127640, loss = 0.23, batch loss = 0.14 (51.0 examples/sec; 0.157 sec/batch; 8h:55m:35s remains)
INFO - root - 2017-12-01 08:10:58.575606: step 127650, loss = 0.36, batch loss = 0.27 (51.9 examples/sec; 0.154 sec/batch; 8h:46m:24s remains)
INFO - root - 2017-12-01 08:11:00.139518: step 127660, loss = 0.31, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 9h:02m:09s remains)
INFO - root - 2017-12-01 08:11:01.698278: step 127670, loss = 0.23, batch loss = 0.14 (50.8 examples/sec; 0.158 sec/batch; 8h:57m:49s remains)
INFO - root - 2017-12-01 08:11:03.257965: step 127680, loss = 0.31, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 8h:41m:03s remains)
INFO - root - 2017-12-01 08:11:04.843039: step 127690, loss = 0.44, batch loss = 0.35 (52.5 examples/sec; 0.153 sec/batch; 8h:40m:35s remains)
INFO - root - 2017-12-01 08:11:06.413048: step 127700, loss = 0.46, batch loss = 0.36 (50.5 examples/sec; 0.158 sec/batch; 9h:00m:56s remains)
INFO - root - 2017-12-01 08:11:08.089308: step 127710, loss = 0.43, batch loss = 0.34 (51.8 examples/sec; 0.155 sec/batch; 8h:47m:35s remains)
INFO - root - 2017-12-01 08:11:09.650003: step 127720, loss = 0.25, batch loss = 0.15 (50.0 examples/sec; 0.160 sec/batch; 9h:05m:55s remains)
INFO - root - 2017-12-01 08:11:11.214504: step 127730, loss = 0.39, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 8h:45m:49s remains)
INFO - root - 2017-12-01 08:11:12.760479: step 127740, loss = 0.32, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 8h:40m:58s remains)
INFO - root - 2017-12-01 08:11:14.309307: step 127750, loss = 0.32, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 8h:42m:37s remains)
INFO - root - 2017-12-01 08:11:15.890674: step 127760, loss = 0.21, batch loss = 0.11 (50.7 examples/sec; 0.158 sec/batch; 8h:58m:35s remains)
INFO - root - 2017-12-01 08:11:17.471493: step 127770, loss = 0.37, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 8h:52m:04s remains)
INFO - root - 2017-12-01 08:11:19.030467: step 127780, loss = 0.23, batch loss = 0.14 (48.8 examples/sec; 0.164 sec/batch; 9h:18m:55s remains)
INFO - root - 2017-12-01 08:11:20.594252: step 127790, loss = 0.40, batch loss = 0.31 (51.4 examples/sec; 0.156 sec/batch; 8h:51m:19s remains)
INFO - root - 2017-12-01 08:11:22.162914: step 127800, loss = 0.30, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 8h:59m:48s remains)
INFO - root - 2017-12-01 08:11:23.783831: step 127810, loss = 0.36, batch loss = 0.26 (50.0 examples/sec; 0.160 sec/batch; 9h:06m:07s remains)
INFO - root - 2017-12-01 08:11:25.349254: step 127820, loss = 0.26, batch loss = 0.16 (50.5 examples/sec; 0.158 sec/batch; 9h:00m:19s remains)
INFO - root - 2017-12-01 08:11:26.915468: step 127830, loss = 0.25, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 8h:46m:32s remains)
INFO - root - 2017-12-01 08:11:28.471162: step 127840, loss = 0.31, batch loss = 0.21 (52.9 examples/sec; 0.151 sec/batch; 8h:35m:23s remains)
INFO - root - 2017-12-01 08:11:30.041269: step 127850, loss = 0.39, batch loss = 0.29 (50.8 examples/sec; 0.158 sec/batch; 8h:57m:16s remains)
INFO - root - 2017-12-01 08:11:31.607480: step 127860, loss = 0.29, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 9h:00m:59s remains)
INFO - root - 2017-12-01 08:11:33.163488: step 127870, loss = 0.27, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 8h:42m:30s remains)
INFO - root - 2017-12-01 08:11:34.718642: step 127880, loss = 0.31, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 8h:58m:22s remains)
INFO - root - 2017-12-01 08:11:36.305524: step 127890, loss = 0.30, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 8h:50m:59s remains)
INFO - root - 2017-12-01 08:11:37.856825: step 127900, loss = 0.30, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 8h:56m:25s remains)
INFO - root - 2017-12-01 08:11:39.516728: step 127910, loss = 0.37, batch loss = 0.27 (52.3 examples/sec; 0.153 sec/batch; 8h:41m:59s remains)
INFO - root - 2017-12-01 08:11:41.090275: step 127920, loss = 0.28, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 8h:57m:27s remains)
INFO - root - 2017-12-01 08:11:42.652659: step 127930, loss = 0.23, batch loss = 0.13 (50.2 examples/sec; 0.159 sec/batch; 9h:03m:09s remains)
INFO - root - 2017-12-01 08:11:44.212207: step 127940, loss = 0.34, batch loss = 0.24 (50.0 examples/sec; 0.160 sec/batch; 9h:05m:56s remains)
INFO - root - 2017-12-01 08:11:45.772610: step 127950, loss = 0.28, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 8h:50m:10s remains)
INFO - root - 2017-12-01 08:11:47.355514: step 127960, loss = 0.32, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 8h:59m:19s remains)
INFO - root - 2017-12-01 08:11:48.928253: step 127970, loss = 0.39, batch loss = 0.29 (50.8 examples/sec; 0.158 sec/batch; 8h:57m:19s remains)
INFO - root - 2017-12-01 08:11:50.487854: step 127980, loss = 0.43, batch loss = 0.33 (50.4 examples/sec; 0.159 sec/batch; 9h:00m:59s remains)
INFO - root - 2017-12-01 08:11:52.045757: step 127990, loss = 0.31, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 8h:52m:49s remains)
INFO - root - 2017-12-01 08:11:53.626507: step 128000, loss = 0.28, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 8h:51m:22s remains)
INFO - root - 2017-12-01 08:11:55.273746: step 128010, loss = 0.48, batch loss = 0.38 (49.2 examples/sec; 0.162 sec/batch; 9h:13m:42s remains)
INFO - root - 2017-12-01 08:11:56.870072: step 128020, loss = 0.24, batch loss = 0.14 (51.8 examples/sec; 0.154 sec/batch; 8h:46m:04s remains)
INFO - root - 2017-12-01 08:11:58.434500: step 128030, loss = 0.34, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 8h:53m:40s remains)
INFO - root - 2017-12-01 08:11:59.985349: step 128040, loss = 0.23, batch loss = 0.13 (50.1 examples/sec; 0.160 sec/batch; 9h:04m:11s remains)
INFO - root - 2017-12-01 08:12:01.553520: step 128050, loss = 0.27, batch loss = 0.17 (50.1 examples/sec; 0.160 sec/batch; 9h:04m:28s remains)
INFO - root - 2017-12-01 08:12:03.152985: step 128060, loss = 0.30, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 8h:48m:15s remains)
INFO - root - 2017-12-01 08:12:04.715468: step 128070, loss = 0.38, batch loss = 0.28 (49.2 examples/sec; 0.162 sec/batch; 9h:13m:29s remains)
INFO - root - 2017-12-01 08:12:06.291172: step 128080, loss = 0.45, batch loss = 0.35 (49.4 examples/sec; 0.162 sec/batch; 9h:11m:45s remains)
INFO - root - 2017-12-01 08:12:07.863836: step 128090, loss = 0.26, batch loss = 0.16 (52.5 examples/sec; 0.152 sec/batch; 8h:39m:23s remains)
INFO - root - 2017-12-01 08:12:09.420655: step 128100, loss = 0.30, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 8h:52m:54s remains)
INFO - root - 2017-12-01 08:12:11.129966: step 128110, loss = 0.41, batch loss = 0.31 (52.7 examples/sec; 0.152 sec/batch; 8h:37m:18s remains)
INFO - root - 2017-12-01 08:12:12.694474: step 128120, loss = 0.28, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 8h:57m:59s remains)
INFO - root - 2017-12-01 08:12:14.253616: step 128130, loss = 0.41, batch loss = 0.32 (51.6 examples/sec; 0.155 sec/batch; 8h:48m:20s remains)
INFO - root - 2017-12-01 08:12:15.806632: step 128140, loss = 0.35, batch loss = 0.25 (52.2 examples/sec; 0.153 sec/batch; 8h:41m:51s remains)
INFO - root - 2017-12-01 08:12:17.377496: step 128150, loss = 0.34, batch loss = 0.24 (52.7 examples/sec; 0.152 sec/batch; 8h:36m:55s remains)
INFO - root - 2017-12-01 08:12:18.952784: step 128160, loss = 0.26, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 8h:44m:54s remains)
INFO - root - 2017-12-01 08:12:20.504778: step 128170, loss = 0.25, batch loss = 0.15 (50.5 examples/sec; 0.158 sec/batch; 8h:59m:05s remains)
INFO - root - 2017-12-01 08:12:22.073239: step 128180, loss = 0.27, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 8h:53m:04s remains)
INFO - root - 2017-12-01 08:12:23.632243: step 128190, loss = 0.27, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 8h:51m:59s remains)
INFO - root - 2017-12-01 08:12:25.212108: step 128200, loss = 0.40, batch loss = 0.30 (50.6 examples/sec; 0.158 sec/batch; 8h:58m:16s remains)
INFO - root - 2017-12-01 08:12:26.833725: step 128210, loss = 0.29, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 8h:51m:44s remains)
INFO - root - 2017-12-01 08:12:28.373645: step 128220, loss = 0.31, batch loss = 0.22 (53.0 examples/sec; 0.151 sec/batch; 8h:34m:20s remains)
INFO - root - 2017-12-01 08:12:29.929795: step 128230, loss = 0.44, batch loss = 0.34 (52.0 examples/sec; 0.154 sec/batch; 8h:43m:35s remains)
INFO - root - 2017-12-01 08:12:31.495661: step 128240, loss = 0.27, batch loss = 0.17 (53.1 examples/sec; 0.151 sec/batch; 8h:32m:46s remains)
INFO - root - 2017-12-01 08:12:33.074567: step 128250, loss = 0.32, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 8h:50m:01s remains)
INFO - root - 2017-12-01 08:12:34.636642: step 128260, loss = 0.40, batch loss = 0.30 (50.9 examples/sec; 0.157 sec/batch; 8h:54m:57s remains)
INFO - root - 2017-12-01 08:12:36.202821: step 128270, loss = 0.31, batch loss = 0.21 (49.8 examples/sec; 0.161 sec/batch; 9h:06m:34s remains)
INFO - root - 2017-12-01 08:12:37.769037: step 128280, loss = 0.52, batch loss = 0.42 (50.5 examples/sec; 0.158 sec/batch; 8h:58m:55s remains)
INFO - root - 2017-12-01 08:12:39.327159: step 128290, loss = 0.27, batch loss = 0.17 (51.8 examples/sec; 0.154 sec/batch; 8h:45m:14s remains)
INFO - root - 2017-12-01 08:12:40.892575: step 128300, loss = 0.29, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 8h:45m:40s remains)
INFO - root - 2017-12-01 08:12:42.515947: step 128310, loss = 0.31, batch loss = 0.21 (49.3 examples/sec; 0.162 sec/batch; 9h:11m:57s remains)
INFO - root - 2017-12-01 08:12:44.099139: step 128320, loss = 0.26, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 8h:43m:43s remains)
INFO - root - 2017-12-01 08:12:45.660344: step 128330, loss = 0.31, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 8h:57m:02s remains)
INFO - root - 2017-12-01 08:12:47.226579: step 128340, loss = 0.37, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 8h:57m:15s remains)
INFO - root - 2017-12-01 08:12:48.783007: step 128350, loss = 0.23, batch loss = 0.14 (50.1 examples/sec; 0.160 sec/batch; 9h:02m:51s remains)
INFO - root - 2017-12-01 08:12:50.345755: step 128360, loss = 0.26, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 8h:47m:16s remains)
INFO - root - 2017-12-01 08:12:51.926356: step 128370, loss = 0.36, batch loss = 0.26 (52.1 examples/sec; 0.154 sec/batch; 8h:42m:38s remains)
INFO - root - 2017-12-01 08:12:53.499313: step 128380, loss = 0.35, batch loss = 0.25 (49.4 examples/sec; 0.162 sec/batch; 9h:10m:30s remains)
INFO - root - 2017-12-01 08:12:55.058351: step 128390, loss = 0.28, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 9h:00m:03s remains)
INFO - root - 2017-12-01 08:12:56.621007: step 128400, loss = 0.29, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 8h:46m:35s remains)
INFO - root - 2017-12-01 08:12:58.262569: step 128410, loss = 0.31, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 8h:54m:53s remains)
INFO - root - 2017-12-01 08:12:59.824506: step 128420, loss = 0.34, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 8h:48m:57s remains)
INFO - root - 2017-12-01 08:13:01.386479: step 128430, loss = 0.27, batch loss = 0.18 (49.3 examples/sec; 0.162 sec/batch; 9h:12m:13s remains)
INFO - root - 2017-12-01 08:13:02.935432: step 128440, loss = 0.30, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 8h:55m:51s remains)
INFO - root - 2017-12-01 08:13:04.517743: step 128450, loss = 0.30, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 9h:02m:11s remains)
INFO - root - 2017-12-01 08:13:06.071436: step 128460, loss = 0.25, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 8h:59m:28s remains)
INFO - root - 2017-12-01 08:13:07.657589: step 128470, loss = 0.36, batch loss = 0.27 (48.8 examples/sec; 0.164 sec/batch; 9h:17m:32s remains)
INFO - root - 2017-12-01 08:13:09.229633: step 128480, loss = 0.28, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 8h:44m:43s remains)
INFO - root - 2017-12-01 08:13:10.773874: step 128490, loss = 0.26, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 8h:44m:28s remains)
INFO - root - 2017-12-01 08:13:12.334291: step 128500, loss = 0.30, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 8h:45m:12s remains)
INFO - root - 2017-12-01 08:13:13.957767: step 128510, loss = 0.46, batch loss = 0.36 (52.8 examples/sec; 0.151 sec/batch; 8h:35m:02s remains)
INFO - root - 2017-12-01 08:13:15.563041: step 128520, loss = 0.30, batch loss = 0.21 (52.8 examples/sec; 0.152 sec/batch; 8h:35m:27s remains)
INFO - root - 2017-12-01 08:13:17.120670: step 128530, loss = 0.28, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 8h:52m:10s remains)
INFO - root - 2017-12-01 08:13:18.691707: step 128540, loss = 0.39, batch loss = 0.29 (50.6 examples/sec; 0.158 sec/batch; 8h:56m:59s remains)
INFO - root - 2017-12-01 08:13:20.265030: step 128550, loss = 0.28, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 8h:49m:09s remains)
INFO - root - 2017-12-01 08:13:21.818933: step 128560, loss = 0.26, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 8h:54m:18s remains)
INFO - root - 2017-12-01 08:13:23.381999: step 128570, loss = 0.50, batch loss = 0.41 (52.1 examples/sec; 0.154 sec/batch; 8h:42m:07s remains)
INFO - root - 2017-12-01 08:13:24.949699: step 128580, loss = 0.33, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 8h:40m:21s remains)
INFO - root - 2017-12-01 08:13:26.514509: step 128590, loss = 0.38, batch loss = 0.28 (50.1 examples/sec; 0.160 sec/batch; 9h:02m:55s remains)
INFO - root - 2017-12-01 08:13:28.075193: step 128600, loss = 0.34, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 8h:51m:29s remains)
INFO - root - 2017-12-01 08:13:29.707384: step 128610, loss = 0.34, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 8h:52m:52s remains)
INFO - root - 2017-12-01 08:13:31.257628: step 128620, loss = 0.43, batch loss = 0.33 (50.1 examples/sec; 0.160 sec/batch; 9h:02m:42s remains)
INFO - root - 2017-12-01 08:13:32.822695: step 128630, loss = 0.29, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 9h:02m:09s remains)
INFO - root - 2017-12-01 08:13:34.376302: step 128640, loss = 0.37, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 8h:46m:56s remains)
INFO - root - 2017-12-01 08:13:35.962573: step 128650, loss = 0.33, batch loss = 0.24 (50.8 examples/sec; 0.158 sec/batch; 8h:55m:11s remains)
INFO - root - 2017-12-01 08:13:37.560977: step 128660, loss = 0.32, batch loss = 0.23 (50.4 examples/sec; 0.159 sec/batch; 8h:58m:48s remains)
INFO - root - 2017-12-01 08:13:39.104094: step 128670, loss = 0.22, batch loss = 0.12 (52.7 examples/sec; 0.152 sec/batch; 8h:35m:42s remains)
INFO - root - 2017-12-01 08:13:40.679593: step 128680, loss = 0.27, batch loss = 0.17 (52.1 examples/sec; 0.154 sec/batch; 8h:41m:55s remains)
INFO - root - 2017-12-01 08:13:42.263254: step 128690, loss = 0.26, batch loss = 0.17 (50.2 examples/sec; 0.159 sec/batch; 9h:01m:38s remains)
INFO - root - 2017-12-01 08:13:43.838932: step 128700, loss = 0.30, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 8h:56m:01s remains)
INFO - root - 2017-12-01 08:13:45.464898: step 128710, loss = 0.29, batch loss = 0.19 (52.1 examples/sec; 0.153 sec/batch; 8h:41m:08s remains)
INFO - root - 2017-12-01 08:13:47.030274: step 128720, loss = 0.30, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 8h:42m:05s remains)
INFO - root - 2017-12-01 08:13:48.586517: step 128730, loss = 0.38, batch loss = 0.29 (50.5 examples/sec; 0.158 sec/batch; 8h:57m:58s remains)
INFO - root - 2017-12-01 08:13:50.157240: step 128740, loss = 0.28, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 8h:53m:21s remains)
INFO - root - 2017-12-01 08:13:51.730526: step 128750, loss = 0.26, batch loss = 0.16 (50.8 examples/sec; 0.157 sec/batch; 8h:54m:49s remains)
INFO - root - 2017-12-01 08:13:53.282450: step 128760, loss = 0.32, batch loss = 0.23 (53.6 examples/sec; 0.149 sec/batch; 8h:26m:28s remains)
INFO - root - 2017-12-01 08:13:54.855154: step 128770, loss = 0.27, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 8h:57m:34s remains)
INFO - root - 2017-12-01 08:13:56.433547: step 128780, loss = 0.33, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 9h:01m:03s remains)
INFO - root - 2017-12-01 08:13:58.002913: step 128790, loss = 0.37, batch loss = 0.27 (52.6 examples/sec; 0.152 sec/batch; 8h:35m:59s remains)
INFO - root - 2017-12-01 08:13:59.552452: step 128800, loss = 0.33, batch loss = 0.23 (52.8 examples/sec; 0.151 sec/batch; 8h:33m:58s remains)
INFO - root - 2017-12-01 08:14:01.194234: step 128810, loss = 0.36, batch loss = 0.26 (49.1 examples/sec; 0.163 sec/batch; 9h:13m:38s remains)
INFO - root - 2017-12-01 08:14:02.754801: step 128820, loss = 0.37, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 8h:49m:04s remains)
INFO - root - 2017-12-01 08:14:04.330100: step 128830, loss = 0.34, batch loss = 0.24 (53.4 examples/sec; 0.150 sec/batch; 8h:28m:50s remains)
INFO - root - 2017-12-01 08:14:05.879997: step 128840, loss = 0.32, batch loss = 0.22 (49.7 examples/sec; 0.161 sec/batch; 9h:05m:58s remains)
INFO - root - 2017-12-01 08:14:07.436010: step 128850, loss = 0.25, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 8h:49m:16s remains)
INFO - root - 2017-12-01 08:14:08.991336: step 128860, loss = 0.27, batch loss = 0.18 (49.9 examples/sec; 0.160 sec/batch; 9h:03m:54s remains)
INFO - root - 2017-12-01 08:14:10.567955: step 128870, loss = 0.25, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 8h:49m:16s remains)
INFO - root - 2017-12-01 08:14:12.131042: step 128880, loss = 0.27, batch loss = 0.18 (52.1 examples/sec; 0.154 sec/batch; 8h:41m:33s remains)
INFO - root - 2017-12-01 08:14:13.688020: step 128890, loss = 0.31, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 8h:36m:21s remains)
INFO - root - 2017-12-01 08:14:15.278810: step 128900, loss = 0.26, batch loss = 0.16 (50.0 examples/sec; 0.160 sec/batch; 9h:02m:55s remains)
INFO - root - 2017-12-01 08:14:16.932172: step 128910, loss = 0.34, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 8h:47m:42s remains)
INFO - root - 2017-12-01 08:14:18.486769: step 128920, loss = 0.25, batch loss = 0.15 (50.1 examples/sec; 0.160 sec/batch; 9h:02m:07s remains)
INFO - root - 2017-12-01 08:14:20.043418: step 128930, loss = 0.29, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 8h:42m:42s remains)
INFO - root - 2017-12-01 08:14:21.624060: step 128940, loss = 0.28, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 8h:35m:54s remains)
INFO - root - 2017-12-01 08:14:23.179366: step 128950, loss = 0.25, batch loss = 0.15 (51.4 examples/sec; 0.156 sec/batch; 8h:47m:47s remains)
INFO - root - 2017-12-01 08:14:24.739434: step 128960, loss = 0.25, batch loss = 0.15 (52.7 examples/sec; 0.152 sec/batch; 8h:35m:23s remains)
INFO - root - 2017-12-01 08:14:26.314580: step 128970, loss = 0.30, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 8h:53m:39s remains)
INFO - root - 2017-12-01 08:14:27.879204: step 128980, loss = 0.34, batch loss = 0.25 (52.4 examples/sec; 0.153 sec/batch; 8h:37m:55s remains)
INFO - root - 2017-12-01 08:14:29.428756: step 128990, loss = 0.27, batch loss = 0.17 (52.6 examples/sec; 0.152 sec/batch; 8h:35m:46s remains)
INFO - root - 2017-12-01 08:14:31.000031: step 129000, loss = 0.27, batch loss = 0.17 (49.6 examples/sec; 0.161 sec/batch; 9h:06m:37s remains)
INFO - root - 2017-12-01 08:14:32.621970: step 129010, loss = 0.27, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 8h:47m:52s remains)
INFO - root - 2017-12-01 08:14:34.171005: step 129020, loss = 0.41, batch loss = 0.32 (52.1 examples/sec; 0.154 sec/batch; 8h:41m:09s remains)
INFO - root - 2017-12-01 08:14:35.742461: step 129030, loss = 0.27, batch loss = 0.17 (52.6 examples/sec; 0.152 sec/batch; 8h:35m:51s remains)
INFO - root - 2017-12-01 08:14:37.318188: step 129040, loss = 0.29, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 8h:45m:34s remains)
INFO - root - 2017-12-01 08:14:38.877880: step 129050, loss = 0.39, batch loss = 0.30 (51.2 examples/sec; 0.156 sec/batch; 8h:50m:15s remains)
INFO - root - 2017-12-01 08:14:40.465013: step 129060, loss = 0.38, batch loss = 0.28 (48.1 examples/sec; 0.166 sec/batch; 9h:24m:13s remains)
INFO - root - 2017-12-01 08:14:42.036393: step 129070, loss = 0.32, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 8h:45m:20s remains)
INFO - root - 2017-12-01 08:14:43.583961: step 129080, loss = 0.33, batch loss = 0.23 (53.2 examples/sec; 0.150 sec/batch; 8h:30m:01s remains)
INFO - root - 2017-12-01 08:14:45.134169: step 129090, loss = 0.29, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 8h:54m:16s remains)
INFO - root - 2017-12-01 08:14:46.694762: step 129100, loss = 0.29, batch loss = 0.20 (49.4 examples/sec; 0.162 sec/batch; 9h:09m:24s remains)
INFO - root - 2017-12-01 08:14:48.342110: step 129110, loss = 0.37, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 8h:56m:32s remains)
INFO - root - 2017-12-01 08:14:49.920947: step 129120, loss = 0.28, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 8h:46m:40s remains)
INFO - root - 2017-12-01 08:14:51.479674: step 129130, loss = 0.29, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 8h:49m:05s remains)
INFO - root - 2017-12-01 08:14:53.035463: step 129140, loss = 0.39, batch loss = 0.30 (52.2 examples/sec; 0.153 sec/batch; 8h:39m:17s remains)
INFO - root - 2017-12-01 08:14:54.609732: step 129150, loss = 0.27, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 8h:45m:04s remains)
INFO - root - 2017-12-01 08:14:56.170439: step 129160, loss = 0.35, batch loss = 0.25 (52.1 examples/sec; 0.154 sec/batch; 8h:40m:49s remains)
INFO - root - 2017-12-01 08:14:57.745166: step 129170, loss = 0.25, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 8h:49m:56s remains)
INFO - root - 2017-12-01 08:14:59.300666: step 129180, loss = 0.25, batch loss = 0.16 (50.6 examples/sec; 0.158 sec/batch; 8h:55m:34s remains)
INFO - root - 2017-12-01 08:15:00.864346: step 129190, loss = 0.44, batch loss = 0.34 (46.3 examples/sec; 0.173 sec/batch; 9h:46m:02s remains)
INFO - root - 2017-12-01 08:15:02.433700: step 129200, loss = 0.26, batch loss = 0.16 (52.8 examples/sec; 0.151 sec/batch; 8h:32m:54s remains)
INFO - root - 2017-12-01 08:15:04.038126: step 129210, loss = 0.27, batch loss = 0.17 (51.8 examples/sec; 0.154 sec/batch; 8h:42m:59s remains)
INFO - root - 2017-12-01 08:15:05.604636: step 129220, loss = 0.37, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 8h:47m:51s remains)
INFO - root - 2017-12-01 08:15:07.176342: step 129230, loss = 0.25, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 8h:48m:11s remains)
INFO - root - 2017-12-01 08:15:08.745465: step 129240, loss = 0.33, batch loss = 0.23 (51.1 examples/sec; 0.157 sec/batch; 8h:50m:45s remains)
INFO - root - 2017-12-01 08:15:10.322463: step 129250, loss = 0.33, batch loss = 0.24 (49.3 examples/sec; 0.162 sec/batch; 9h:09m:31s remains)
INFO - root - 2017-12-01 08:15:11.903685: step 129260, loss = 0.26, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 8h:49m:03s remains)
INFO - root - 2017-12-01 08:15:13.465671: step 129270, loss = 0.26, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 8h:48m:13s remains)
INFO - root - 2017-12-01 08:15:15.024081: step 129280, loss = 0.26, batch loss = 0.16 (51.0 examples/sec; 0.157 sec/batch; 8h:51m:25s remains)
INFO - root - 2017-12-01 08:15:16.593549: step 129290, loss = 0.34, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 8h:55m:08s remains)
INFO - root - 2017-12-01 08:15:18.156804: step 129300, loss = 0.24, batch loss = 0.15 (50.1 examples/sec; 0.160 sec/batch; 9h:00m:20s remains)
INFO - root - 2017-12-01 08:15:19.799229: step 129310, loss = 0.36, batch loss = 0.27 (52.3 examples/sec; 0.153 sec/batch; 8h:37m:55s remains)
INFO - root - 2017-12-01 08:15:21.362684: step 129320, loss = 0.29, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 8h:54m:45s remains)
INFO - root - 2017-12-01 08:15:22.916694: step 129330, loss = 0.37, batch loss = 0.27 (51.2 examples/sec; 0.156 sec/batch; 8h:48m:35s remains)
INFO - root - 2017-12-01 08:15:24.488346: step 129340, loss = 0.28, batch loss = 0.19 (48.5 examples/sec; 0.165 sec/batch; 9h:18m:15s remains)
INFO - root - 2017-12-01 08:15:26.085577: step 129350, loss = 0.27, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 8h:52m:07s remains)
INFO - root - 2017-12-01 08:15:27.646458: step 129360, loss = 0.40, batch loss = 0.31 (51.4 examples/sec; 0.156 sec/batch; 8h:46m:31s remains)
INFO - root - 2017-12-01 08:15:29.201691: step 129370, loss = 0.30, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 8h:52m:32s remains)
INFO - root - 2017-12-01 08:15:30.768011: step 129380, loss = 0.30, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 8h:45m:53s remains)
INFO - root - 2017-12-01 08:15:32.337784: step 129390, loss = 0.26, batch loss = 0.16 (50.5 examples/sec; 0.158 sec/batch; 8h:56m:25s remains)
INFO - root - 2017-12-01 08:15:33.914163: step 129400, loss = 0.26, batch loss = 0.16 (52.1 examples/sec; 0.154 sec/batch; 8h:40m:12s remains)
INFO - root - 2017-12-01 08:15:35.527848: step 129410, loss = 0.33, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 8h:41m:36s remains)
INFO - root - 2017-12-01 08:15:37.087179: step 129420, loss = 0.33, batch loss = 0.23 (53.5 examples/sec; 0.149 sec/batch; 8h:25m:47s remains)
INFO - root - 2017-12-01 08:15:38.655047: step 129430, loss = 0.21, batch loss = 0.11 (50.7 examples/sec; 0.158 sec/batch; 8h:53m:40s remains)
INFO - root - 2017-12-01 08:15:40.234484: step 129440, loss = 0.54, batch loss = 0.44 (50.8 examples/sec; 0.158 sec/batch; 8h:53m:07s remains)
INFO - root - 2017-12-01 08:15:41.820862: step 129450, loss = 0.27, batch loss = 0.17 (47.8 examples/sec; 0.167 sec/batch; 9h:26m:29s remains)
INFO - root - 2017-12-01 08:15:43.396998: step 129460, loss = 0.30, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 8h:45m:57s remains)
INFO - root - 2017-12-01 08:15:44.947910: step 129470, loss = 0.28, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 8h:46m:55s remains)
INFO - root - 2017-12-01 08:15:46.515496: step 129480, loss = 0.25, batch loss = 0.15 (51.0 examples/sec; 0.157 sec/batch; 8h:50m:59s remains)
INFO - root - 2017-12-01 08:15:48.086718: step 129490, loss = 0.32, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 8h:45m:17s remains)
INFO - root - 2017-12-01 08:15:49.630084: step 129500, loss = 0.33, batch loss = 0.24 (52.5 examples/sec; 0.152 sec/batch; 8h:35m:36s remains)
INFO - root - 2017-12-01 08:15:51.294768: step 129510, loss = 0.35, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 8h:48m:02s remains)
INFO - root - 2017-12-01 08:15:52.854696: step 129520, loss = 0.30, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 8h:49m:49s remains)
INFO - root - 2017-12-01 08:15:54.417926: step 129530, loss = 0.31, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 8h:40m:55s remains)
INFO - root - 2017-12-01 08:15:56.001940: step 129540, loss = 0.28, batch loss = 0.19 (49.6 examples/sec; 0.161 sec/batch; 9h:05m:14s remains)
INFO - root - 2017-12-01 08:15:57.568231: step 129550, loss = 0.28, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 8h:49m:41s remains)
INFO - root - 2017-12-01 08:15:59.131891: step 129560, loss = 0.44, batch loss = 0.34 (50.8 examples/sec; 0.158 sec/batch; 8h:52m:57s remains)
INFO - root - 2017-12-01 08:16:00.690843: step 129570, loss = 0.31, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 8h:41m:46s remains)
INFO - root - 2017-12-01 08:16:02.273950: step 129580, loss = 0.30, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 8h:40m:09s remains)
INFO - root - 2017-12-01 08:16:03.835419: step 129590, loss = 0.34, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 8h:53m:48s remains)
INFO - root - 2017-12-01 08:16:05.397381: step 129600, loss = 0.27, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 8h:43m:27s remains)
INFO - root - 2017-12-01 08:16:07.046237: step 129610, loss = 0.44, batch loss = 0.35 (52.0 examples/sec; 0.154 sec/batch; 8h:40m:03s remains)
INFO - root - 2017-12-01 08:16:08.617748: step 129620, loss = 0.31, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 8h:53m:01s remains)
INFO - root - 2017-12-01 08:16:10.179385: step 129630, loss = 0.41, batch loss = 0.31 (52.0 examples/sec; 0.154 sec/batch; 8h:40m:24s remains)
INFO - root - 2017-12-01 08:16:11.751077: step 129640, loss = 0.37, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 8h:49m:59s remains)
INFO - root - 2017-12-01 08:16:13.309988: step 129650, loss = 0.30, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 8h:37m:07s remains)
INFO - root - 2017-12-01 08:16:14.869333: step 129660, loss = 0.29, batch loss = 0.19 (50.3 examples/sec; 0.159 sec/batch; 8h:57m:16s remains)
INFO - root - 2017-12-01 08:16:16.443060: step 129670, loss = 0.31, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 8h:47m:57s remains)
INFO - root - 2017-12-01 08:16:17.998868: step 129680, loss = 0.24, batch loss = 0.14 (50.8 examples/sec; 0.158 sec/batch; 8h:52m:49s remains)
INFO - root - 2017-12-01 08:16:19.568106: step 129690, loss = 0.31, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 8h:49m:09s remains)
INFO - root - 2017-12-01 08:16:21.124971: step 129700, loss = 0.29, batch loss = 0.19 (50.2 examples/sec; 0.159 sec/batch; 8h:58m:33s remains)
INFO - root - 2017-12-01 08:16:22.749851: step 129710, loss = 0.35, batch loss = 0.25 (49.8 examples/sec; 0.161 sec/batch; 9h:02m:53s remains)
INFO - root - 2017-12-01 08:16:24.311494: step 129720, loss = 0.33, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 8h:36m:52s remains)
INFO - root - 2017-12-01 08:16:25.877927: step 129730, loss = 0.34, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 8h:46m:01s remains)
INFO - root - 2017-12-01 08:16:27.447182: step 129740, loss = 0.28, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 8h:43m:04s remains)
INFO - root - 2017-12-01 08:16:29.001750: step 129750, loss = 0.34, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 8h:54m:43s remains)
INFO - root - 2017-12-01 08:16:30.576268: step 129760, loss = 0.31, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 8h:58m:41s remains)
INFO - root - 2017-12-01 08:16:32.154038: step 129770, loss = 0.32, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 8h:34m:29s remains)
INFO - root - 2017-12-01 08:16:33.713973: step 129780, loss = 0.30, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 8h:40m:26s remains)
INFO - root - 2017-12-01 08:16:35.288533: step 129790, loss = 0.24, batch loss = 0.14 (51.2 examples/sec; 0.156 sec/batch; 8h:47m:54s remains)
INFO - root - 2017-12-01 08:16:36.854149: step 129800, loss = 0.33, batch loss = 0.24 (48.7 examples/sec; 0.164 sec/batch; 9h:14m:58s remains)
INFO - root - 2017-12-01 08:16:38.472785: step 129810, loss = 0.33, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 8h:54m:21s remains)
INFO - root - 2017-12-01 08:16:40.026537: step 129820, loss = 0.27, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 8h:45m:50s remains)
INFO - root - 2017-12-01 08:16:41.593370: step 129830, loss = 0.28, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 8h:52m:35s remains)
INFO - root - 2017-12-01 08:16:43.149922: step 129840, loss = 0.26, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 8h:54m:13s remains)
INFO - root - 2017-12-01 08:16:44.715009: step 129850, loss = 0.44, batch loss = 0.35 (50.9 examples/sec; 0.157 sec/batch; 8h:51m:00s remains)
INFO - root - 2017-12-01 08:16:46.299122: step 129860, loss = 0.24, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 8h:46m:14s remains)
INFO - root - 2017-12-01 08:16:47.859358: step 129870, loss = 0.42, batch loss = 0.32 (50.7 examples/sec; 0.158 sec/batch; 8h:52m:44s remains)
INFO - root - 2017-12-01 08:16:49.422749: step 129880, loss = 0.38, batch loss = 0.28 (50.4 examples/sec; 0.159 sec/batch; 8h:55m:47s remains)
INFO - root - 2017-12-01 08:16:50.981125: step 129890, loss = 0.37, batch loss = 0.27 (49.1 examples/sec; 0.163 sec/batch; 9h:10m:43s remains)
INFO - root - 2017-12-01 08:16:52.538606: step 129900, loss = 0.29, batch loss = 0.20 (53.4 examples/sec; 0.150 sec/batch; 8h:26m:17s remains)
INFO - root - 2017-12-01 08:16:54.180766: step 129910, loss = 0.28, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 8h:48m:37s remains)
INFO - root - 2017-12-01 08:16:55.818065: step 129920, loss = 0.32, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 8h:56m:36s remains)
INFO - root - 2017-12-01 08:16:57.400728: step 129930, loss = 0.40, batch loss = 0.30 (51.4 examples/sec; 0.156 sec/batch; 8h:45m:38s remains)
INFO - root - 2017-12-01 08:16:58.963980: step 129940, loss = 0.25, batch loss = 0.15 (49.8 examples/sec; 0.161 sec/batch; 9h:02m:24s remains)
INFO - root - 2017-12-01 08:17:00.510569: step 129950, loss = 0.30, batch loss = 0.21 (52.7 examples/sec; 0.152 sec/batch; 8h:32m:46s remains)
INFO - root - 2017-12-01 08:17:02.082506: step 129960, loss = 0.35, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 8h:47m:46s remains)
INFO - root - 2017-12-01 08:17:03.676722: step 129970, loss = 0.32, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 8h:50m:13s remains)
INFO - root - 2017-12-01 08:17:05.238231: step 129980, loss = 0.37, batch loss = 0.28 (50.5 examples/sec; 0.158 sec/batch; 8h:54m:28s remains)
INFO - root - 2017-12-01 08:17:06.791932: step 129990, loss = 0.30, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 8h:44m:01s remains)
INFO - root - 2017-12-01 08:17:08.352333: step 130000, loss = 0.27, batch loss = 0.17 (52.7 examples/sec; 0.152 sec/batch; 8h:32m:44s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-130000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-130000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-01 08:17:10.385461: step 130010, loss = 0.27, batch loss = 0.18 (51.1 examples/sec; 0.156 sec/batch; 8h:47m:53s remains)
INFO - root - 2017-12-01 08:17:11.939670: step 130020, loss = 0.31, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 8h:44m:38s remains)
INFO - root - 2017-12-01 08:17:13.562511: step 130030, loss = 0.29, batch loss = 0.19 (49.4 examples/sec; 0.162 sec/batch; 9h:06m:03s remains)
INFO - root - 2017-12-01 08:17:15.119013: step 130040, loss = 0.58, batch loss = 0.48 (51.4 examples/sec; 0.156 sec/batch; 8h:44m:46s remains)
INFO - root - 2017-12-01 08:17:16.695739: step 130050, loss = 0.36, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 8h:39m:09s remains)
INFO - root - 2017-12-01 08:17:18.254046: step 130060, loss = 0.46, batch loss = 0.36 (52.2 examples/sec; 0.153 sec/batch; 8h:37m:06s remains)
INFO - root - 2017-12-01 08:17:19.804725: step 130070, loss = 0.47, batch loss = 0.38 (51.9 examples/sec; 0.154 sec/batch; 8h:40m:07s remains)
INFO - root - 2017-12-01 08:17:21.380396: step 130080, loss = 0.25, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 8h:50m:23s remains)
INFO - root - 2017-12-01 08:17:22.945340: step 130090, loss = 0.33, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 8h:43m:30s remains)
INFO - root - 2017-12-01 08:17:24.502765: step 130100, loss = 0.28, batch loss = 0.18 (52.6 examples/sec; 0.152 sec/batch; 8h:33m:03s remains)
INFO - root - 2017-12-01 08:17:26.184805: step 130110, loss = 0.24, batch loss = 0.15 (47.7 examples/sec; 0.168 sec/batch; 9h:25m:54s remains)
INFO - root - 2017-12-01 08:17:27.755448: step 130120, loss = 0.53, batch loss = 0.43 (51.5 examples/sec; 0.155 sec/batch; 8h:43m:38s remains)
INFO - root - 2017-12-01 08:17:29.315812: step 130130, loss = 0.33, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 8h:42m:41s remains)
INFO - root - 2017-12-01 08:17:30.884435: step 130140, loss = 0.36, batch loss = 0.26 (51.2 examples/sec; 0.156 sec/batch; 8h:47m:28s remains)
INFO - root - 2017-12-01 08:17:32.446386: step 130150, loss = 0.42, batch loss = 0.32 (50.3 examples/sec; 0.159 sec/batch; 8h:56m:52s remains)
INFO - root - 2017-12-01 08:17:34.009378: step 130160, loss = 0.32, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 8h:41m:39s remains)
INFO - root - 2017-12-01 08:17:35.587818: step 130170, loss = 0.32, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 8h:35m:10s remains)
INFO - root - 2017-12-01 08:17:37.158519: step 130180, loss = 0.35, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 8h:40m:22s remains)
INFO - root - 2017-12-01 08:17:38.719962: step 130190, loss = 0.32, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 8h:47m:06s remains)
INFO - root - 2017-12-01 08:17:40.284941: step 130200, loss = 0.29, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 8h:44m:09s remains)
INFO - root - 2017-12-01 08:17:41.922797: step 130210, loss = 0.28, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 8h:48m:43s remains)
INFO - root - 2017-12-01 08:17:43.496443: step 130220, loss = 0.31, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 8h:43m:13s remains)
INFO - root - 2017-12-01 08:17:45.054828: step 130230, loss = 0.52, batch loss = 0.43 (52.9 examples/sec; 0.151 sec/batch; 8h:29m:24s remains)
INFO - root - 2017-12-01 08:17:46.622808: step 130240, loss = 0.27, batch loss = 0.17 (53.2 examples/sec; 0.150 sec/batch; 8h:26m:30s remains)
INFO - root - 2017-12-01 08:17:48.215694: step 130250, loss = 0.40, batch loss = 0.30 (51.5 examples/sec; 0.155 sec/batch; 8h:43m:28s remains)
INFO - root - 2017-12-01 08:17:49.770358: step 130260, loss = 0.24, batch loss = 0.14 (50.2 examples/sec; 0.159 sec/batch; 8h:56m:48s remains)
INFO - root - 2017-12-01 08:17:51.332309: step 130270, loss = 0.31, batch loss = 0.22 (49.6 examples/sec; 0.161 sec/batch; 9h:03m:55s remains)
INFO - root - 2017-12-01 08:17:52.902254: step 130280, loss = 0.27, batch loss = 0.17 (52.5 examples/sec; 0.152 sec/batch; 8h:33m:11s remains)
INFO - root - 2017-12-01 08:17:54.465045: step 130290, loss = 0.33, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 8h:54m:32s remains)
INFO - root - 2017-12-01 08:17:56.080604: step 130300, loss = 0.23, batch loss = 0.13 (50.1 examples/sec; 0.160 sec/batch; 8h:58m:01s remains)
INFO - root - 2017-12-01 08:17:57.744145: step 130310, loss = 0.26, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 8h:48m:04s remains)
INFO - root - 2017-12-01 08:17:59.311234: step 130320, loss = 0.37, batch loss = 0.27 (49.0 examples/sec; 0.163 sec/batch; 9h:10m:24s remains)
INFO - root - 2017-12-01 08:18:00.872404: step 130330, loss = 0.46, batch loss = 0.36 (50.9 examples/sec; 0.157 sec/batch; 8h:50m:00s remains)
INFO - root - 2017-12-01 08:18:02.445748: step 130340, loss = 0.29, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 8h:41m:36s remains)
INFO - root - 2017-12-01 08:18:04.025787: step 130350, loss = 0.27, batch loss = 0.18 (47.9 examples/sec; 0.167 sec/batch; 9h:22m:54s remains)
INFO - root - 2017-12-01 08:18:05.607491: step 130360, loss = 0.32, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 8h:59m:12s remains)
INFO - root - 2017-12-01 08:18:07.166200: step 130370, loss = 0.27, batch loss = 0.17 (54.1 examples/sec; 0.148 sec/batch; 8h:18m:12s remains)
INFO - root - 2017-12-01 08:18:08.747486: step 130380, loss = 0.37, batch loss = 0.27 (51.9 examples/sec; 0.154 sec/batch; 8h:39m:15s remains)
INFO - root - 2017-12-01 08:18:10.315310: step 130390, loss = 0.33, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 8h:47m:14s remains)
INFO - root - 2017-12-01 08:18:11.890263: step 130400, loss = 0.29, batch loss = 0.20 (49.7 examples/sec; 0.161 sec/batch; 9h:02m:37s remains)
INFO - root - 2017-12-01 08:18:13.518366: step 130410, loss = 0.27, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 8h:41m:08s remains)
INFO - root - 2017-12-01 08:18:15.084591: step 130420, loss = 0.36, batch loss = 0.26 (49.2 examples/sec; 0.162 sec/batch; 9h:07m:11s remains)
INFO - root - 2017-12-01 08:18:16.644454: step 130430, loss = 0.28, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 8h:49m:12s remains)
INFO - root - 2017-12-01 08:18:18.217312: step 130440, loss = 0.27, batch loss = 0.17 (49.3 examples/sec; 0.162 sec/batch; 9h:06m:35s remains)
INFO - root - 2017-12-01 08:18:19.785275: step 130450, loss = 0.32, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 8h:42m:09s remains)
INFO - root - 2017-12-01 08:18:21.365372: step 130460, loss = 0.27, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 8h:55m:16s remains)
INFO - root - 2017-12-01 08:18:22.940207: step 130470, loss = 0.25, batch loss = 0.15 (49.8 examples/sec; 0.161 sec/batch; 9h:00m:30s remains)
INFO - root - 2017-12-01 08:18:24.501318: step 130480, loss = 0.27, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 8h:50m:12s remains)
INFO - root - 2017-12-01 08:18:26.069129: step 130490, loss = 0.33, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 8h:35m:39s remains)
INFO - root - 2017-12-01 08:18:27.642675: step 130500, loss = 0.28, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 8h:49m:27s remains)
INFO - root - 2017-12-01 08:18:29.341063: step 130510, loss = 0.31, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 8h:38m:17s remains)
INFO - root - 2017-12-01 08:18:30.922799: step 130520, loss = 0.27, batch loss = 0.17 (49.4 examples/sec; 0.162 sec/batch; 9h:05m:10s remains)
INFO - root - 2017-12-01 08:18:32.484962: step 130530, loss = 0.42, batch loss = 0.32 (51.3 examples/sec; 0.156 sec/batch; 8h:44m:43s remains)
INFO - root - 2017-12-01 08:18:34.034551: step 130540, loss = 0.28, batch loss = 0.18 (52.6 examples/sec; 0.152 sec/batch; 8h:32m:04s remains)
INFO - root - 2017-12-01 08:18:35.597182: step 130550, loss = 0.27, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 8h:36m:06s remains)
INFO - root - 2017-12-01 08:18:37.165267: step 130560, loss = 0.33, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 8h:38m:50s remains)
INFO - root - 2017-12-01 08:18:38.737750: step 130570, loss = 0.24, batch loss = 0.15 (50.4 examples/sec; 0.159 sec/batch; 8h:53m:41s remains)
INFO - root - 2017-12-01 08:18:40.303620: step 130580, loss = 0.32, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 8h:38m:31s remains)
INFO - root - 2017-12-01 08:18:41.877539: step 130590, loss = 0.49, batch loss = 0.39 (51.8 examples/sec; 0.155 sec/batch; 8h:40m:01s remains)
INFO - root - 2017-12-01 08:18:43.448472: step 130600, loss = 0.47, batch loss = 0.38 (51.1 examples/sec; 0.157 sec/batch; 8h:47m:06s remains)
INFO - root - 2017-12-01 08:18:45.071204: step 130610, loss = 0.29, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 8h:55m:39s remains)
INFO - root - 2017-12-01 08:18:46.639328: step 130620, loss = 0.30, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 8h:42m:32s remains)
INFO - root - 2017-12-01 08:18:48.192279: step 130630, loss = 0.27, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 8h:47m:23s remains)
INFO - root - 2017-12-01 08:18:49.751564: step 130640, loss = 0.29, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 8h:49m:53s remains)
INFO - root - 2017-12-01 08:18:51.306164: step 130650, loss = 0.32, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 8h:54m:16s remains)
INFO - root - 2017-12-01 08:18:52.871341: step 130660, loss = 0.30, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 8h:32m:27s remains)
INFO - root - 2017-12-01 08:18:54.425615: step 130670, loss = 0.26, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 8h:37m:48s remains)
INFO - root - 2017-12-01 08:18:56.026084: step 130680, loss = 0.28, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 8h:44m:12s remains)
INFO - root - 2017-12-01 08:18:57.621228: step 130690, loss = 0.32, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 8h:34m:49s remains)
INFO - root - 2017-12-01 08:18:59.170217: step 130700, loss = 0.32, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 8h:46m:41s remains)
INFO - root - 2017-12-01 08:19:00.820204: step 130710, loss = 0.43, batch loss = 0.33 (51.0 examples/sec; 0.157 sec/batch; 8h:47m:40s remains)
INFO - root - 2017-12-01 08:19:02.387050: step 130720, loss = 0.27, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 8h:41m:11s remains)
INFO - root - 2017-12-01 08:19:03.946780: step 130730, loss = 0.35, batch loss = 0.26 (51.1 examples/sec; 0.157 sec/batch; 8h:46m:44s remains)
INFO - root - 2017-12-01 08:19:05.529987: step 130740, loss = 0.35, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 8h:42m:40s remains)
INFO - root - 2017-12-01 08:19:07.082586: step 130750, loss = 0.34, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 8h:47m:26s remains)
INFO - root - 2017-12-01 08:19:08.645023: step 130760, loss = 0.36, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 8h:50m:03s remains)
INFO - root - 2017-12-01 08:19:10.239968: step 130770, loss = 0.36, batch loss = 0.26 (50.1 examples/sec; 0.160 sec/batch; 8h:57m:07s remains)
INFO - root - 2017-12-01 08:19:11.842990: step 130780, loss = 0.27, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 8h:53m:45s remains)
INFO - root - 2017-12-01 08:19:13.402321: step 130790, loss = 0.34, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 8h:47m:46s remains)
INFO - root - 2017-12-01 08:19:14.961624: step 130800, loss = 0.36, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 8h:54m:05s remains)
INFO - root - 2017-12-01 08:19:16.583786: step 130810, loss = 0.60, batch loss = 0.50 (51.1 examples/sec; 0.157 sec/batch; 8h:46m:40s remains)
INFO - root - 2017-12-01 08:19:18.174468: step 130820, loss = 0.28, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 8h:45m:34s remains)
INFO - root - 2017-12-01 08:19:19.726144: step 130830, loss = 0.26, batch loss = 0.17 (51.8 examples/sec; 0.155 sec/batch; 8h:39m:35s remains)
INFO - root - 2017-12-01 08:19:21.283272: step 130840, loss = 0.34, batch loss = 0.24 (52.8 examples/sec; 0.152 sec/batch; 8h:29m:21s remains)
INFO - root - 2017-12-01 08:19:22.848354: step 130850, loss = 0.28, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 8h:39m:50s remains)
INFO - root - 2017-12-01 08:19:24.420190: step 130860, loss = 0.29, batch loss = 0.19 (49.6 examples/sec; 0.161 sec/batch; 9h:01m:57s remains)
INFO - root - 2017-12-01 08:19:25.990661: step 130870, loss = 0.29, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 8h:40m:13s remains)
INFO - root - 2017-12-01 08:19:27.564937: step 130880, loss = 0.28, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 8h:38m:50s remains)
INFO - root - 2017-12-01 08:19:29.124742: step 130890, loss = 0.29, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 8h:32m:58s remains)
INFO - root - 2017-12-01 08:19:30.699906: step 130900, loss = 0.31, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 8h:37m:58s remains)
INFO - root - 2017-12-01 08:19:32.312624: step 130910, loss = 0.39, batch loss = 0.30 (51.9 examples/sec; 0.154 sec/batch; 8h:37m:46s remains)
INFO - root - 2017-12-01 08:19:33.882442: step 130920, loss = 0.30, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 8h:41m:16s remains)
INFO - root - 2017-12-01 08:19:35.434401: step 130930, loss = 0.33, batch loss = 0.23 (53.3 examples/sec; 0.150 sec/batch; 8h:24m:35s remains)
INFO - root - 2017-12-01 08:19:36.988606: step 130940, loss = 0.33, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 8h:52m:48s remains)
INFO - root - 2017-12-01 08:19:38.579768: step 130950, loss = 0.27, batch loss = 0.17 (49.7 examples/sec; 0.161 sec/batch; 9h:00m:48s remains)
INFO - root - 2017-12-01 08:19:40.142560: step 130960, loss = 0.26, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 8h:37m:15s remains)
INFO - root - 2017-12-01 08:19:41.703393: step 130970, loss = 0.31, batch loss = 0.21 (53.0 examples/sec; 0.151 sec/batch; 8h:27m:11s remains)
INFO - root - 2017-12-01 08:19:43.293340: step 130980, loss = 0.65, batch loss = 0.56 (48.9 examples/sec; 0.164 sec/batch; 9h:09m:33s remains)
INFO - root - 2017-12-01 08:19:44.856811: step 130990, loss = 0.29, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 8h:49m:22s remains)
INFO - root - 2017-12-01 08:19:46.430405: step 131000, loss = 0.25, batch loss = 0.16 (50.8 examples/sec; 0.157 sec/batch; 8h:48m:42s remains)
INFO - root - 2017-12-01 08:19:48.073245: step 131010, loss = 0.39, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 8h:48m:14s remains)
INFO - root - 2017-12-01 08:19:49.633908: step 131020, loss = 0.28, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 8h:45m:52s remains)
INFO - root - 2017-12-01 08:19:51.205377: step 131030, loss = 0.34, batch loss = 0.25 (52.1 examples/sec; 0.154 sec/batch; 8h:36m:01s remains)
INFO - root - 2017-12-01 08:19:52.775718: step 131040, loss = 0.34, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 8h:40m:45s remains)
INFO - root - 2017-12-01 08:19:54.339831: step 131050, loss = 0.25, batch loss = 0.16 (52.5 examples/sec; 0.152 sec/batch; 8h:31m:19s remains)
INFO - root - 2017-12-01 08:19:55.899567: step 131060, loss = 0.35, batch loss = 0.26 (52.4 examples/sec; 0.153 sec/batch; 8h:32m:31s remains)
INFO - root - 2017-12-01 08:19:57.471545: step 131070, loss = 0.26, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 8h:39m:50s remains)
INFO - root - 2017-12-01 08:19:59.034960: step 131080, loss = 0.25, batch loss = 0.16 (52.5 examples/sec; 0.152 sec/batch; 8h:31m:18s remains)
INFO - root - 2017-12-01 08:20:00.600822: step 131090, loss = 0.28, batch loss = 0.18 (52.4 examples/sec; 0.153 sec/batch; 8h:32m:11s remains)
INFO - root - 2017-12-01 08:20:02.187075: step 131100, loss = 0.25, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 8h:43m:52s remains)
INFO - root - 2017-12-01 08:20:03.831903: step 131110, loss = 0.25, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 8h:40m:27s remains)
INFO - root - 2017-12-01 08:20:05.398507: step 131120, loss = 0.26, batch loss = 0.17 (51.1 examples/sec; 0.156 sec/batch; 8h:45m:01s remains)
INFO - root - 2017-12-01 08:20:06.959211: step 131130, loss = 0.30, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 8h:55m:10s remains)
INFO - root - 2017-12-01 08:20:08.512268: step 131140, loss = 0.24, batch loss = 0.14 (51.0 examples/sec; 0.157 sec/batch; 8h:46m:16s remains)
INFO - root - 2017-12-01 08:20:10.108971: step 131150, loss = 0.27, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 8h:42m:50s remains)
INFO - root - 2017-12-01 08:20:11.684183: step 131160, loss = 0.32, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 8h:47m:01s remains)
INFO - root - 2017-12-01 08:20:13.223898: step 131170, loss = 0.38, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 8h:42m:57s remains)
INFO - root - 2017-12-01 08:20:14.788328: step 131180, loss = 0.25, batch loss = 0.16 (52.4 examples/sec; 0.153 sec/batch; 8h:32m:40s remains)
INFO - root - 2017-12-01 08:20:16.367326: step 131190, loss = 0.31, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 8h:37m:21s remains)
INFO - root - 2017-12-01 08:20:17.966700: step 131200, loss = 0.32, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 8h:56m:51s remains)
INFO - root - 2017-12-01 08:20:19.634945: step 131210, loss = 0.31, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 8h:50m:57s remains)
INFO - root - 2017-12-01 08:20:21.213381: step 131220, loss = 0.28, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 8h:42m:51s remains)
INFO - root - 2017-12-01 08:20:22.770070: step 131230, loss = 0.40, batch loss = 0.31 (50.5 examples/sec; 0.158 sec/batch; 8h:51m:19s remains)
INFO - root - 2017-12-01 08:20:24.332529: step 131240, loss = 0.36, batch loss = 0.26 (53.1 examples/sec; 0.151 sec/batch; 8h:25m:10s remains)
INFO - root - 2017-12-01 08:20:25.888486: step 131250, loss = 0.30, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 8h:35m:41s remains)
INFO - root - 2017-12-01 08:20:27.453346: step 131260, loss = 0.33, batch loss = 0.23 (50.5 examples/sec; 0.158 sec/batch; 8h:50m:53s remains)
INFO - root - 2017-12-01 08:20:29.050206: step 131270, loss = 0.37, batch loss = 0.28 (51.4 examples/sec; 0.156 sec/batch; 8h:41m:39s remains)
INFO - root - 2017-12-01 08:20:30.617195: step 131280, loss = 0.28, batch loss = 0.19 (48.2 examples/sec; 0.166 sec/batch; 9h:16m:37s remains)
INFO - root - 2017-12-01 08:20:32.185531: step 131290, loss = 0.30, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 8h:35m:37s remains)
INFO - root - 2017-12-01 08:20:33.804810: step 131300, loss = 0.27, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 8h:50m:18s remains)
INFO - root - 2017-12-01 08:20:35.437969: step 131310, loss = 0.32, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 8h:45m:13s remains)
INFO - root - 2017-12-01 08:20:36.994932: step 131320, loss = 0.42, batch loss = 0.33 (51.7 examples/sec; 0.155 sec/batch; 8h:38m:40s remains)
INFO - root - 2017-12-01 08:20:38.557852: step 131330, loss = 0.28, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 8h:45m:45s remains)
INFO - root - 2017-12-01 08:20:40.091152: step 131340, loss = 0.30, batch loss = 0.21 (53.5 examples/sec; 0.150 sec/batch; 8h:21m:39s remains)
INFO - root - 2017-12-01 08:20:41.673412: step 131350, loss = 0.32, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 8h:42m:34s remains)
INFO - root - 2017-12-01 08:20:43.229716: step 131360, loss = 0.42, batch loss = 0.32 (51.4 examples/sec; 0.156 sec/batch; 8h:41m:54s remains)
INFO - root - 2017-12-01 08:20:44.795275: step 131370, loss = 0.27, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 8h:32m:28s remains)
INFO - root - 2017-12-01 08:20:46.369643: step 131380, loss = 0.36, batch loss = 0.27 (50.8 examples/sec; 0.157 sec/batch; 8h:47m:23s remains)
INFO - root - 2017-12-01 08:20:47.924739: step 131390, loss = 0.24, batch loss = 0.15 (51.6 examples/sec; 0.155 sec/batch; 8h:39m:46s remains)
INFO - root - 2017-12-01 08:20:49.496525: step 131400, loss = 0.52, batch loss = 0.43 (50.0 examples/sec; 0.160 sec/batch; 8h:56m:16s remains)
INFO - root - 2017-12-01 08:20:51.133846: step 131410, loss = 0.27, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 8h:48m:22s remains)
INFO - root - 2017-12-01 08:20:52.688635: step 131420, loss = 0.30, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 8h:38m:37s remains)
INFO - root - 2017-12-01 08:20:54.262921: step 131430, loss = 0.36, batch loss = 0.26 (48.5 examples/sec; 0.165 sec/batch; 9h:13m:04s remains)
INFO - root - 2017-12-01 08:20:55.852743: step 131440, loss = 0.39, batch loss = 0.30 (52.0 examples/sec; 0.154 sec/batch; 8h:35m:38s remains)
INFO - root - 2017-12-01 08:20:57.414798: step 131450, loss = 0.25, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 8h:46m:50s remains)
INFO - root - 2017-12-01 08:20:58.994807: step 131460, loss = 0.24, batch loss = 0.15 (48.8 examples/sec; 0.164 sec/batch; 9h:08m:54s remains)
INFO - root - 2017-12-01 08:21:00.561362: step 131470, loss = 0.29, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 8h:32m:00s remains)
INFO - root - 2017-12-01 08:21:02.123242: step 131480, loss = 0.30, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 8h:36m:28s remains)
INFO - root - 2017-12-01 08:21:03.696241: step 131490, loss = 0.28, batch loss = 0.19 (49.7 examples/sec; 0.161 sec/batch; 8h:59m:41s remains)
INFO - root - 2017-12-01 08:21:05.256946: step 131500, loss = 0.30, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 8h:45m:55s remains)
INFO - root - 2017-12-01 08:21:06.913804: step 131510, loss = 0.32, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 8h:52m:40s remains)
INFO - root - 2017-12-01 08:21:08.469151: step 131520, loss = 0.32, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 8h:35m:01s remains)
INFO - root - 2017-12-01 08:21:10.029490: step 131530, loss = 0.29, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 8h:49m:13s remains)
INFO - root - 2017-12-01 08:21:11.608456: step 131540, loss = 0.30, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 8h:30m:58s remains)
INFO - root - 2017-12-01 08:21:13.177510: step 131550, loss = 0.42, batch loss = 0.33 (52.1 examples/sec; 0.154 sec/batch; 8h:34m:45s remains)
INFO - root - 2017-12-01 08:21:14.742310: step 131560, loss = 0.27, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 8h:45m:01s remains)
INFO - root - 2017-12-01 08:21:16.314624: step 131570, loss = 0.29, batch loss = 0.19 (49.6 examples/sec; 0.161 sec/batch; 8h:59m:55s remains)
INFO - root - 2017-12-01 08:21:17.864165: step 131580, loss = 0.32, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 8h:37m:50s remains)
INFO - root - 2017-12-01 08:21:19.443131: step 131590, loss = 0.25, batch loss = 0.15 (51.6 examples/sec; 0.155 sec/batch; 8h:39m:33s remains)
INFO - root - 2017-12-01 08:21:21.012648: step 131600, loss = 0.35, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 8h:36m:05s remains)
INFO - root - 2017-12-01 08:21:22.630025: step 131610, loss = 0.33, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 8h:33m:04s remains)
INFO - root - 2017-12-01 08:21:24.196193: step 131620, loss = 0.34, batch loss = 0.24 (50.8 examples/sec; 0.158 sec/batch; 8h:47m:22s remains)
INFO - root - 2017-12-01 08:21:25.758005: step 131630, loss = 0.35, batch loss = 0.26 (50.2 examples/sec; 0.159 sec/batch; 8h:53m:24s remains)
INFO - root - 2017-12-01 08:21:27.327033: step 131640, loss = 0.33, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 8h:38m:51s remains)
INFO - root - 2017-12-01 08:21:28.898591: step 131650, loss = 0.34, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 8h:51m:07s remains)
INFO - root - 2017-12-01 08:21:30.445871: step 131660, loss = 0.26, batch loss = 0.16 (52.1 examples/sec; 0.154 sec/batch; 8h:34m:00s remains)
INFO - root - 2017-12-01 08:21:32.029102: step 131670, loss = 0.25, batch loss = 0.16 (53.0 examples/sec; 0.151 sec/batch; 8h:25m:36s remains)
INFO - root - 2017-12-01 08:21:33.592657: step 131680, loss = 0.25, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 8h:36m:37s remains)
INFO - root - 2017-12-01 08:21:35.145079: step 131690, loss = 0.24, batch loss = 0.14 (52.1 examples/sec; 0.153 sec/batch; 8h:33m:37s remains)
INFO - root - 2017-12-01 08:21:36.724498: step 131700, loss = 0.37, batch loss = 0.28 (49.5 examples/sec; 0.162 sec/batch; 9h:00m:42s remains)
INFO - root - 2017-12-01 08:21:38.329521: step 131710, loss = 0.35, batch loss = 0.25 (50.0 examples/sec; 0.160 sec/batch; 8h:55m:34s remains)
INFO - root - 2017-12-01 08:21:39.890984: step 131720, loss = 0.27, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 8h:45m:14s remains)
INFO - root - 2017-12-01 08:21:41.460497: step 131730, loss = 0.32, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 8h:44m:26s remains)
INFO - root - 2017-12-01 08:21:43.031197: step 131740, loss = 0.25, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 8h:42m:57s remains)
INFO - root - 2017-12-01 08:21:44.624672: step 131750, loss = 0.28, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 8h:35m:46s remains)
INFO - root - 2017-12-01 08:21:46.179219: step 131760, loss = 0.40, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 8h:47m:45s remains)
INFO - root - 2017-12-01 08:21:47.743399: step 131770, loss = 0.32, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 8h:46m:35s remains)
INFO - root - 2017-12-01 08:21:49.302009: step 131780, loss = 0.28, batch loss = 0.19 (51.1 examples/sec; 0.156 sec/batch; 8h:43m:17s remains)
INFO - root - 2017-12-01 08:21:50.875310: step 131790, loss = 0.36, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 8h:39m:07s remains)
INFO - root - 2017-12-01 08:21:52.445346: step 131800, loss = 0.26, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 8h:35m:43s remains)
INFO - root - 2017-12-01 08:21:54.095685: step 131810, loss = 0.24, batch loss = 0.15 (51.8 examples/sec; 0.154 sec/batch; 8h:36m:44s remains)
INFO - root - 2017-12-01 08:21:55.664196: step 131820, loss = 0.34, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 8h:31m:58s remains)
INFO - root - 2017-12-01 08:21:57.221417: step 131830, loss = 0.25, batch loss = 0.15 (51.5 examples/sec; 0.155 sec/batch; 8h:39m:39s remains)
INFO - root - 2017-12-01 08:21:58.797704: step 131840, loss = 0.33, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 8h:51m:59s remains)
INFO - root - 2017-12-01 08:22:00.358584: step 131850, loss = 0.35, batch loss = 0.26 (49.6 examples/sec; 0.161 sec/batch; 8h:58m:50s remains)
INFO - root - 2017-12-01 08:22:01.927525: step 131860, loss = 0.37, batch loss = 0.28 (52.4 examples/sec; 0.153 sec/batch; 8h:30m:09s remains)
INFO - root - 2017-12-01 08:22:03.478970: step 131870, loss = 0.28, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 8h:31m:36s remains)
INFO - root - 2017-12-01 08:22:05.029933: step 131880, loss = 0.33, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 8h:34m:10s remains)
INFO - root - 2017-12-01 08:22:06.586887: step 131890, loss = 0.29, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 8h:54m:18s remains)
INFO - root - 2017-12-01 08:22:08.142782: step 131900, loss = 0.37, batch loss = 0.28 (52.4 examples/sec; 0.153 sec/batch; 8h:30m:15s remains)
INFO - root - 2017-12-01 08:22:09.788706: step 131910, loss = 0.38, batch loss = 0.28 (51.9 examples/sec; 0.154 sec/batch; 8h:35m:21s remains)
INFO - root - 2017-12-01 08:22:11.346366: step 131920, loss = 0.27, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 8h:49m:36s remains)
INFO - root - 2017-12-01 08:22:12.900192: step 131930, loss = 0.39, batch loss = 0.30 (51.6 examples/sec; 0.155 sec/batch; 8h:38m:35s remains)
INFO - root - 2017-12-01 08:22:14.470650: step 131940, loss = 0.27, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 8h:34m:46s remains)
INFO - root - 2017-12-01 08:22:16.036137: step 131950, loss = 0.33, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 8h:45m:47s remains)
INFO - root - 2017-12-01 08:22:17.604221: step 131960, loss = 0.24, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 8h:41m:31s remains)
INFO - root - 2017-12-01 08:22:19.173977: step 131970, loss = 0.40, batch loss = 0.31 (50.7 examples/sec; 0.158 sec/batch; 8h:47m:49s remains)
INFO - root - 2017-12-01 08:22:20.738177: step 131980, loss = 0.29, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 8h:37m:56s remains)
INFO - root - 2017-12-01 08:22:22.304008: step 131990, loss = 0.30, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 8h:53m:41s remains)
INFO - root - 2017-12-01 08:22:23.880281: step 132000, loss = 0.30, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 8h:33m:14s remains)
INFO - root - 2017-12-01 08:22:25.484706: step 132010, loss = 0.25, batch loss = 0.15 (52.6 examples/sec; 0.152 sec/batch; 8h:28m:29s remains)
INFO - root - 2017-12-01 08:22:27.044558: step 132020, loss = 0.30, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 8h:44m:08s remains)
INFO - root - 2017-12-01 08:22:28.593203: step 132030, loss = 0.31, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 8h:45m:20s remains)
INFO - root - 2017-12-01 08:22:30.157980: step 132040, loss = 0.36, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 8h:50m:07s remains)
INFO - root - 2017-12-01 08:22:31.745174: step 132050, loss = 0.34, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 8h:39m:32s remains)
INFO - root - 2017-12-01 08:22:33.295045: step 132060, loss = 0.34, batch loss = 0.25 (50.1 examples/sec; 0.160 sec/batch; 8h:53m:21s remains)
INFO - root - 2017-12-01 08:22:34.861600: step 132070, loss = 0.34, batch loss = 0.24 (48.9 examples/sec; 0.164 sec/batch; 9h:07m:02s remains)
INFO - root - 2017-12-01 08:22:36.423748: step 132080, loss = 0.31, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 8h:29m:55s remains)
INFO - root - 2017-12-01 08:22:37.989538: step 132090, loss = 0.46, batch loss = 0.37 (52.3 examples/sec; 0.153 sec/batch; 8h:30m:43s remains)
INFO - root - 2017-12-01 08:22:39.573960: step 132100, loss = 0.33, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 8h:51m:05s remains)
INFO - root - 2017-12-01 08:22:41.207031: step 132110, loss = 0.27, batch loss = 0.17 (53.0 examples/sec; 0.151 sec/batch; 8h:24m:06s remains)
INFO - root - 2017-12-01 08:22:42.779884: step 132120, loss = 0.23, batch loss = 0.14 (50.4 examples/sec; 0.159 sec/batch; 8h:50m:13s remains)
INFO - root - 2017-12-01 08:22:44.354925: step 132130, loss = 0.29, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 8h:49m:55s remains)
INFO - root - 2017-12-01 08:22:45.904312: step 132140, loss = 0.26, batch loss = 0.17 (52.3 examples/sec; 0.153 sec/batch; 8h:30m:56s remains)
INFO - root - 2017-12-01 08:22:47.467192: step 132150, loss = 0.29, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 8h:33m:31s remains)
INFO - root - 2017-12-01 08:22:49.075494: step 132160, loss = 0.30, batch loss = 0.21 (45.8 examples/sec; 0.175 sec/batch; 9h:43m:11s remains)
INFO - root - 2017-12-01 08:22:50.637413: step 132170, loss = 0.36, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 8h:38m:47s remains)
INFO - root - 2017-12-01 08:22:52.202685: step 132180, loss = 0.32, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 8h:37m:43s remains)
INFO - root - 2017-12-01 08:22:53.765321: step 132190, loss = 0.35, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 8h:42m:55s remains)
INFO - root - 2017-12-01 08:22:55.350218: step 132200, loss = 0.28, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 8h:47m:30s remains)
INFO - root - 2017-12-01 08:22:56.960222: step 132210, loss = 0.31, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 8h:43m:25s remains)
INFO - root - 2017-12-01 08:22:58.515810: step 132220, loss = 0.51, batch loss = 0.41 (51.6 examples/sec; 0.155 sec/batch; 8h:37m:20s remains)
INFO - root - 2017-12-01 08:23:00.086115: step 132230, loss = 0.26, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 8h:38m:37s remains)
INFO - root - 2017-12-01 08:23:01.706597: step 132240, loss = 0.43, batch loss = 0.33 (43.0 examples/sec; 0.186 sec/batch; 10h:21m:36s remains)
INFO - root - 2017-12-01 08:23:03.262935: step 132250, loss = 0.25, batch loss = 0.16 (50.8 examples/sec; 0.158 sec/batch; 8h:45m:56s remains)
INFO - root - 2017-12-01 08:23:04.838523: step 132260, loss = 0.26, batch loss = 0.17 (52.1 examples/sec; 0.154 sec/batch; 8h:32m:19s remains)
INFO - root - 2017-12-01 08:23:06.391235: step 132270, loss = 0.33, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 8h:52m:11s remains)
INFO - root - 2017-12-01 08:23:07.938991: step 132280, loss = 0.34, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 8h:41m:59s remains)
INFO - root - 2017-12-01 08:23:09.518210: step 132290, loss = 0.30, batch loss = 0.20 (49.3 examples/sec; 0.162 sec/batch; 9h:01m:15s remains)
INFO - root - 2017-12-01 08:23:11.112714: step 132300, loss = 0.28, batch loss = 0.19 (52.7 examples/sec; 0.152 sec/batch; 8h:26m:31s remains)
INFO - root - 2017-12-01 08:23:12.755261: step 132310, loss = 0.28, batch loss = 0.18 (49.2 examples/sec; 0.162 sec/batch; 9h:02m:03s remains)
INFO - root - 2017-12-01 08:23:14.322264: step 132320, loss = 0.33, batch loss = 0.23 (53.0 examples/sec; 0.151 sec/batch; 8h:23m:45s remains)
INFO - root - 2017-12-01 08:23:15.891698: step 132330, loss = 0.38, batch loss = 0.28 (52.2 examples/sec; 0.153 sec/batch; 8h:31m:19s remains)
INFO - root - 2017-12-01 08:23:17.457871: step 132340, loss = 0.34, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 8h:34m:50s remains)
INFO - root - 2017-12-01 08:23:19.008620: step 132350, loss = 0.32, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 8h:41m:03s remains)
INFO - root - 2017-12-01 08:23:20.590595: step 132360, loss = 0.25, batch loss = 0.16 (49.6 examples/sec; 0.161 sec/batch; 8h:57m:31s remains)
INFO - root - 2017-12-01 08:23:22.181286: step 132370, loss = 0.35, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 8h:34m:32s remains)
INFO - root - 2017-12-01 08:23:23.741363: step 132380, loss = 0.28, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 8h:44m:50s remains)
INFO - root - 2017-12-01 08:23:25.294825: step 132390, loss = 0.28, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 8h:44m:50s remains)
INFO - root - 2017-12-01 08:23:26.867382: step 132400, loss = 0.36, batch loss = 0.26 (49.2 examples/sec; 0.163 sec/batch; 9h:02m:46s remains)
INFO - root - 2017-12-01 08:23:28.493121: step 132410, loss = 0.28, batch loss = 0.19 (49.8 examples/sec; 0.161 sec/batch; 8h:55m:34s remains)
INFO - root - 2017-12-01 08:23:30.044182: step 132420, loss = 0.24, batch loss = 0.15 (51.7 examples/sec; 0.155 sec/batch; 8h:36m:09s remains)
INFO - root - 2017-12-01 08:23:31.603615: step 132430, loss = 0.34, batch loss = 0.25 (49.8 examples/sec; 0.161 sec/batch; 8h:55m:26s remains)
INFO - root - 2017-12-01 08:23:33.157952: step 132440, loss = 0.30, batch loss = 0.21 (52.6 examples/sec; 0.152 sec/batch; 8h:27m:17s remains)
INFO - root - 2017-12-01 08:23:34.727535: step 132450, loss = 0.32, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 8h:30m:00s remains)
INFO - root - 2017-12-01 08:23:36.296811: step 132460, loss = 0.36, batch loss = 0.27 (52.2 examples/sec; 0.153 sec/batch; 8h:31m:23s remains)
INFO - root - 2017-12-01 08:23:37.867264: step 132470, loss = 0.32, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 8h:43m:18s remains)
INFO - root - 2017-12-01 08:23:39.428550: step 132480, loss = 0.33, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 8h:46m:08s remains)
INFO - root - 2017-12-01 08:23:41.026915: step 132490, loss = 0.31, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 8h:34m:04s remains)
INFO - root - 2017-12-01 08:23:42.588358: step 132500, loss = 0.25, batch loss = 0.16 (52.2 examples/sec; 0.153 sec/batch; 8h:30m:38s remains)
INFO - root - 2017-12-01 08:23:44.206729: step 132510, loss = 0.22, batch loss = 0.13 (51.4 examples/sec; 0.156 sec/batch; 8h:39m:10s remains)
INFO - root - 2017-12-01 08:23:45.763082: step 132520, loss = 0.23, batch loss = 0.13 (50.0 examples/sec; 0.160 sec/batch; 8h:53m:45s remains)
INFO - root - 2017-12-01 08:23:47.335452: step 132530, loss = 0.32, batch loss = 0.23 (51.8 examples/sec; 0.155 sec/batch; 8h:35m:11s remains)
INFO - root - 2017-12-01 08:23:48.899883: step 132540, loss = 0.24, batch loss = 0.15 (51.0 examples/sec; 0.157 sec/batch; 8h:42m:24s remains)
INFO - root - 2017-12-01 08:23:50.457872: step 132550, loss = 0.22, batch loss = 0.13 (50.7 examples/sec; 0.158 sec/batch; 8h:46m:19s remains)
INFO - root - 2017-12-01 08:23:52.025674: step 132560, loss = 0.33, batch loss = 0.23 (49.3 examples/sec; 0.162 sec/batch; 9h:00m:42s remains)
INFO - root - 2017-12-01 08:23:53.604427: step 132570, loss = 0.24, batch loss = 0.15 (51.9 examples/sec; 0.154 sec/batch; 8h:33m:20s remains)
INFO - root - 2017-12-01 08:23:55.164426: step 132580, loss = 0.28, batch loss = 0.18 (52.5 examples/sec; 0.152 sec/batch; 8h:28m:01s remains)
INFO - root - 2017-12-01 08:23:56.761982: step 132590, loss = 0.28, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 8h:42m:00s remains)
INFO - root - 2017-12-01 08:23:58.306538: step 132600, loss = 0.31, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 8h:41m:48s remains)
INFO - root - 2017-12-01 08:23:59.929290: step 132610, loss = 0.39, batch loss = 0.30 (51.6 examples/sec; 0.155 sec/batch; 8h:36m:01s remains)
INFO - root - 2017-12-01 08:24:01.506083: step 132620, loss = 0.29, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 8h:52m:44s remains)
INFO - root - 2017-12-01 08:24:03.058634: step 132630, loss = 0.38, batch loss = 0.28 (52.7 examples/sec; 0.152 sec/batch; 8h:25m:49s remains)
INFO - root - 2017-12-01 08:24:04.636812: step 132640, loss = 0.32, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 8h:38m:07s remains)
INFO - root - 2017-12-01 08:24:06.224923: step 132650, loss = 0.25, batch loss = 0.16 (52.1 examples/sec; 0.153 sec/batch; 8h:30m:58s remains)
INFO - root - 2017-12-01 08:24:07.785741: step 132660, loss = 0.22, batch loss = 0.13 (51.0 examples/sec; 0.157 sec/batch; 8h:42m:57s remains)
INFO - root - 2017-12-01 08:24:09.359009: step 132670, loss = 0.28, batch loss = 0.18 (49.2 examples/sec; 0.163 sec/batch; 9h:02m:00s remains)
INFO - root - 2017-12-01 08:24:10.950117: step 132680, loss = 0.40, batch loss = 0.31 (48.9 examples/sec; 0.164 sec/batch; 9h:04m:40s remains)
INFO - root - 2017-12-01 08:24:12.529105: step 132690, loss = 0.24, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 8h:39m:21s remains)
INFO - root - 2017-12-01 08:24:14.064013: step 132700, loss = 0.35, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 8h:35m:58s remains)
INFO - root - 2017-12-01 08:24:15.727627: step 132710, loss = 0.29, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 8h:44m:23s remains)
INFO - root - 2017-12-01 08:24:17.321407: step 132720, loss = 0.29, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 8h:46m:45s remains)
INFO - root - 2017-12-01 08:24:18.884128: step 132730, loss = 0.32, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 8h:41m:34s remains)
INFO - root - 2017-12-01 08:24:20.436778: step 132740, loss = 0.30, batch loss = 0.21 (52.8 examples/sec; 0.151 sec/batch; 8h:23m:59s remains)
INFO - root - 2017-12-01 08:24:21.994698: step 132750, loss = 0.26, batch loss = 0.16 (52.1 examples/sec; 0.154 sec/batch; 8h:31m:16s remains)
INFO - root - 2017-12-01 08:24:23.560432: step 132760, loss = 0.25, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 8h:33m:56s remains)
INFO - root - 2017-12-01 08:24:25.142562: step 132770, loss = 0.30, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 8h:51m:37s remains)
INFO - root - 2017-12-01 08:24:26.712194: step 132780, loss = 0.28, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 8h:39m:29s remains)
INFO - root - 2017-12-01 08:24:28.257683: step 132790, loss = 0.25, batch loss = 0.16 (51.0 examples/sec; 0.157 sec/batch; 8h:41m:41s remains)
INFO - root - 2017-12-01 08:24:29.809651: step 132800, loss = 0.29, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 8h:26m:02s remains)
INFO - root - 2017-12-01 08:24:31.432122: step 132810, loss = 0.29, batch loss = 0.20 (49.6 examples/sec; 0.161 sec/batch; 8h:56m:24s remains)
INFO - root - 2017-12-01 08:24:32.997024: step 132820, loss = 0.21, batch loss = 0.11 (51.3 examples/sec; 0.156 sec/batch; 8h:39m:25s remains)
INFO - root - 2017-12-01 08:24:34.543447: step 132830, loss = 0.31, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 8h:29m:34s remains)
INFO - root - 2017-12-01 08:24:36.098278: step 132840, loss = 0.28, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 8h:40m:01s remains)
INFO - root - 2017-12-01 08:24:37.652365: step 132850, loss = 0.26, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 8h:42m:14s remains)
INFO - root - 2017-12-01 08:24:39.227484: step 132860, loss = 0.33, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 8h:41m:56s remains)
INFO - root - 2017-12-01 08:24:40.790817: step 132870, loss = 0.30, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 8h:41m:57s remains)
INFO - root - 2017-12-01 08:24:42.346139: step 132880, loss = 0.29, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 8h:27m:49s remains)
INFO - root - 2017-12-01 08:24:43.934975: step 132890, loss = 0.36, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 8h:45m:08s remains)
INFO - root - 2017-12-01 08:24:45.496637: step 132900, loss = 0.29, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 8h:47m:45s remains)
INFO - root - 2017-12-01 08:24:47.133695: step 132910, loss = 0.29, batch loss = 0.19 (50.1 examples/sec; 0.160 sec/batch; 8h:50m:40s remains)
INFO - root - 2017-12-01 08:24:48.691896: step 132920, loss = 0.32, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 8h:37m:37s remains)
INFO - root - 2017-12-01 08:24:50.271372: step 132930, loss = 0.33, batch loss = 0.24 (50.1 examples/sec; 0.160 sec/batch; 8h:51m:17s remains)
INFO - root - 2017-12-01 08:24:51.825617: step 132940, loss = 0.33, batch loss = 0.24 (50.8 examples/sec; 0.157 sec/batch; 8h:43m:34s remains)
INFO - root - 2017-12-01 08:24:53.389839: step 132950, loss = 0.29, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 8h:52m:51s remains)
INFO - root - 2017-12-01 08:24:54.957818: step 132960, loss = 0.30, batch loss = 0.21 (53.5 examples/sec; 0.149 sec/batch; 8h:16m:55s remains)
INFO - root - 2017-12-01 08:24:56.560326: step 132970, loss = 0.35, batch loss = 0.25 (49.9 examples/sec; 0.160 sec/batch; 8h:53m:09s remains)
INFO - root - 2017-12-01 08:24:58.147384: step 132980, loss = 0.32, batch loss = 0.22 (48.4 examples/sec; 0.165 sec/batch; 9h:09m:58s remains)
INFO - root - 2017-12-01 08:24:59.712743: step 132990, loss = 0.41, batch loss = 0.31 (52.8 examples/sec; 0.151 sec/batch; 8h:23m:20s remains)
INFO - root - 2017-12-01 08:25:01.267143: step 133000, loss = 0.33, batch loss = 0.24 (49.4 examples/sec; 0.162 sec/batch; 8h:57m:55s remains)
INFO - root - 2017-12-01 08:25:02.903990: step 133010, loss = 0.41, batch loss = 0.32 (49.5 examples/sec; 0.162 sec/batch; 8h:57m:24s remains)
INFO - root - 2017-12-01 08:25:04.478188: step 133020, loss = 0.30, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 8h:32m:21s remains)
INFO - root - 2017-12-01 08:25:06.055384: step 133030, loss = 0.28, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 8h:42m:04s remains)
INFO - root - 2017-12-01 08:25:07.625077: step 133040, loss = 0.43, batch loss = 0.34 (50.7 examples/sec; 0.158 sec/batch; 8h:45m:00s remains)
INFO - root - 2017-12-01 08:25:09.175199: step 133050, loss = 0.39, batch loss = 0.30 (52.0 examples/sec; 0.154 sec/batch; 8h:31m:51s remains)
INFO - root - 2017-12-01 08:25:10.745206: step 133060, loss = 0.29, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 8h:48m:34s remains)
INFO - root - 2017-12-01 08:25:12.288989: step 133070, loss = 0.24, batch loss = 0.15 (52.8 examples/sec; 0.152 sec/batch; 8h:23m:55s remains)
INFO - root - 2017-12-01 08:25:13.855979: step 133080, loss = 0.30, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 8h:38m:28s remains)
INFO - root - 2017-12-01 08:25:15.423572: step 133090, loss = 0.33, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 8h:40m:46s remains)
INFO - root - 2017-12-01 08:25:16.991124: step 133100, loss = 0.31, batch loss = 0.22 (49.8 examples/sec; 0.160 sec/batch; 8h:53m:23s remains)
INFO - root - 2017-12-01 08:25:18.628853: step 133110, loss = 0.28, batch loss = 0.18 (52.7 examples/sec; 0.152 sec/batch; 8h:24m:37s remains)
INFO - root - 2017-12-01 08:25:20.200520: step 133120, loss = 0.32, batch loss = 0.23 (50.1 examples/sec; 0.160 sec/batch; 8h:50m:11s remains)
INFO - root - 2017-12-01 08:25:21.755288: step 133130, loss = 0.37, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 8h:42m:22s remains)
INFO - root - 2017-12-01 08:25:23.323252: step 133140, loss = 0.30, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 8h:42m:54s remains)
INFO - root - 2017-12-01 08:25:24.898164: step 133150, loss = 0.44, batch loss = 0.34 (52.0 examples/sec; 0.154 sec/batch; 8h:30m:42s remains)
INFO - root - 2017-12-01 08:25:26.474735: step 133160, loss = 0.37, batch loss = 0.27 (50.4 examples/sec; 0.159 sec/batch; 8h:47m:23s remains)
INFO - root - 2017-12-01 08:25:28.026077: step 133170, loss = 0.33, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 8h:46m:52s remains)
INFO - root - 2017-12-01 08:25:29.592014: step 133180, loss = 0.25, batch loss = 0.16 (49.8 examples/sec; 0.161 sec/batch; 8h:53m:19s remains)
INFO - root - 2017-12-01 08:25:31.176704: step 133190, loss = 0.33, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 8h:44m:29s remains)
INFO - root - 2017-12-01 08:25:32.728177: step 133200, loss = 0.27, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 8h:31m:43s remains)
INFO - root - 2017-12-01 08:25:34.346676: step 133210, loss = 0.30, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 8h:33m:44s remains)
INFO - root - 2017-12-01 08:25:35.898780: step 133220, loss = 0.29, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 8h:33m:53s remains)
INFO - root - 2017-12-01 08:25:37.493071: step 133230, loss = 0.31, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 8h:34m:29s remains)
INFO - root - 2017-12-01 08:25:39.041301: step 133240, loss = 0.42, batch loss = 0.33 (51.7 examples/sec; 0.155 sec/batch; 8h:33m:29s remains)
INFO - root - 2017-12-01 08:25:40.580618: step 133250, loss = 0.27, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 8h:33m:50s remains)
INFO - root - 2017-12-01 08:25:42.144479: step 133260, loss = 0.25, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 8h:41m:43s remains)
INFO - root - 2017-12-01 08:25:43.708586: step 133270, loss = 0.32, batch loss = 0.23 (48.6 examples/sec; 0.165 sec/batch; 9h:06m:36s remains)
INFO - root - 2017-12-01 08:25:45.281606: step 133280, loss = 0.28, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 8h:31m:40s remains)
INFO - root - 2017-12-01 08:25:46.864686: step 133290, loss = 0.30, batch loss = 0.21 (48.3 examples/sec; 0.165 sec/batch; 9h:09m:22s remains)
INFO - root - 2017-12-01 08:25:48.425856: step 133300, loss = 0.30, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 8h:50m:14s remains)
INFO - root - 2017-12-01 08:25:50.120074: step 133310, loss = 0.25, batch loss = 0.16 (49.3 examples/sec; 0.162 sec/batch; 8h:59m:14s remains)
INFO - root - 2017-12-01 08:25:51.671965: step 133320, loss = 0.30, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 8h:38m:19s remains)
INFO - root - 2017-12-01 08:25:53.240371: step 133330, loss = 0.33, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 8h:42m:04s remains)
INFO - root - 2017-12-01 08:25:54.792675: step 133340, loss = 0.25, batch loss = 0.16 (53.5 examples/sec; 0.150 sec/batch; 8h:16m:15s remains)
INFO - root - 2017-12-01 08:25:56.409179: step 133350, loss = 0.31, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 8h:37m:40s remains)
INFO - root - 2017-12-01 08:25:57.975975: step 133360, loss = 0.33, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 8h:39m:20s remains)
INFO - root - 2017-12-01 08:25:59.548647: step 133370, loss = 0.27, batch loss = 0.17 (53.1 examples/sec; 0.151 sec/batch; 8h:19m:43s remains)
INFO - root - 2017-12-01 08:26:01.122419: step 133380, loss = 0.27, batch loss = 0.17 (52.1 examples/sec; 0.153 sec/batch; 8h:29m:14s remains)
INFO - root - 2017-12-01 08:26:02.691622: step 133390, loss = 0.27, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 8h:42m:40s remains)
INFO - root - 2017-12-01 08:26:04.252996: step 133400, loss = 0.26, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 8h:33m:45s remains)
INFO - root - 2017-12-01 08:26:05.901310: step 133410, loss = 0.41, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 8h:41m:36s remains)
INFO - root - 2017-12-01 08:26:07.460464: step 133420, loss = 0.34, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 8h:31m:47s remains)
INFO - root - 2017-12-01 08:26:09.019384: step 133430, loss = 0.37, batch loss = 0.28 (49.8 examples/sec; 0.161 sec/batch; 8h:53m:30s remains)
INFO - root - 2017-12-01 08:26:10.572119: step 133440, loss = 0.26, batch loss = 0.17 (53.7 examples/sec; 0.149 sec/batch; 8h:14m:26s remains)
INFO - root - 2017-12-01 08:26:12.154565: step 133450, loss = 0.25, batch loss = 0.15 (52.0 examples/sec; 0.154 sec/batch; 8h:30m:17s remains)
INFO - root - 2017-12-01 08:26:13.740472: step 133460, loss = 0.35, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 8h:33m:08s remains)
INFO - root - 2017-12-01 08:26:15.291145: step 133470, loss = 0.27, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 8h:34m:38s remains)
INFO - root - 2017-12-01 08:26:16.857496: step 133480, loss = 0.36, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 8h:37m:01s remains)
INFO - root - 2017-12-01 08:26:18.439576: step 133490, loss = 0.25, batch loss = 0.15 (51.4 examples/sec; 0.156 sec/batch; 8h:36m:21s remains)
INFO - root - 2017-12-01 08:26:19.995137: step 133500, loss = 0.40, batch loss = 0.31 (51.8 examples/sec; 0.155 sec/batch; 8h:32m:33s remains)
INFO - root - 2017-12-01 08:26:21.622067: step 133510, loss = 0.30, batch loss = 0.20 (52.1 examples/sec; 0.153 sec/batch; 8h:28m:49s remains)
INFO - root - 2017-12-01 08:26:23.195845: step 133520, loss = 0.35, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 8h:33m:02s remains)
INFO - root - 2017-12-01 08:26:24.785535: step 133530, loss = 0.31, batch loss = 0.22 (49.5 examples/sec; 0.162 sec/batch; 8h:56m:19s remains)
INFO - root - 2017-12-01 08:26:26.355271: step 133540, loss = 0.31, batch loss = 0.22 (48.8 examples/sec; 0.164 sec/batch; 9h:03m:43s remains)
INFO - root - 2017-12-01 08:26:27.924069: step 133550, loss = 0.33, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 8h:24m:39s remains)
INFO - root - 2017-12-01 08:26:29.477888: step 133560, loss = 0.28, batch loss = 0.19 (52.1 examples/sec; 0.154 sec/batch; 8h:29m:35s remains)
INFO - root - 2017-12-01 08:26:31.049733: step 133570, loss = 0.28, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 8h:37m:27s remains)
INFO - root - 2017-12-01 08:26:32.620164: step 133580, loss = 0.31, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 8h:44m:54s remains)
INFO - root - 2017-12-01 08:26:34.174056: step 133590, loss = 0.33, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 8h:40m:11s remains)
INFO - root - 2017-12-01 08:26:35.730977: step 133600, loss = 0.26, batch loss = 0.17 (52.8 examples/sec; 0.151 sec/batch; 8h:21m:53s remains)
INFO - root - 2017-12-01 08:26:37.339363: step 133610, loss = 0.32, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 8h:27m:43s remains)
INFO - root - 2017-12-01 08:26:38.888347: step 133620, loss = 0.32, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 8h:35m:12s remains)
INFO - root - 2017-12-01 08:26:40.455099: step 133630, loss = 0.31, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 8h:48m:09s remains)
INFO - root - 2017-12-01 08:26:42.011875: step 133640, loss = 0.45, batch loss = 0.36 (51.8 examples/sec; 0.154 sec/batch; 8h:31m:37s remains)
INFO - root - 2017-12-01 08:26:43.580581: step 133650, loss = 0.27, batch loss = 0.18 (52.1 examples/sec; 0.153 sec/batch; 8h:28m:34s remains)
INFO - root - 2017-12-01 08:26:45.149862: step 133660, loss = 0.28, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 8h:31m:32s remains)
INFO - root - 2017-12-01 08:26:46.705539: step 133670, loss = 0.30, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 8h:42m:31s remains)
INFO - root - 2017-12-01 08:26:48.257951: step 133680, loss = 0.32, batch loss = 0.23 (50.8 examples/sec; 0.157 sec/batch; 8h:41m:29s remains)
INFO - root - 2017-12-01 08:26:49.802835: step 133690, loss = 0.28, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 8h:50m:03s remains)
INFO - root - 2017-12-01 08:26:51.349252: step 133700, loss = 0.36, batch loss = 0.27 (50.4 examples/sec; 0.159 sec/batch; 8h:46m:00s remains)
INFO - root - 2017-12-01 08:26:52.976043: step 133710, loss = 0.26, batch loss = 0.16 (51.7 examples/sec; 0.155 sec/batch; 8h:33m:06s remains)
INFO - root - 2017-12-01 08:26:54.540578: step 133720, loss = 0.27, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 8h:37m:33s remains)
INFO - root - 2017-12-01 08:26:56.101888: step 133730, loss = 0.38, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 8h:40m:47s remains)
INFO - root - 2017-12-01 08:26:57.644153: step 133740, loss = 0.28, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 8h:25m:41s remains)
INFO - root - 2017-12-01 08:26:59.213751: step 133750, loss = 0.31, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 8h:49m:26s remains)
INFO - root - 2017-12-01 08:27:00.789774: step 133760, loss = 0.30, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 8h:30m:14s remains)
INFO - root - 2017-12-01 08:27:02.370137: step 133770, loss = 0.30, batch loss = 0.21 (47.5 examples/sec; 0.168 sec/batch; 9h:17m:17s remains)
INFO - root - 2017-12-01 08:27:03.944869: step 133780, loss = 0.28, batch loss = 0.19 (48.5 examples/sec; 0.165 sec/batch; 9h:06m:20s remains)
INFO - root - 2017-12-01 08:27:05.526315: step 133790, loss = 0.33, batch loss = 0.23 (52.1 examples/sec; 0.154 sec/batch; 8h:28m:39s remains)
INFO - root - 2017-12-01 08:27:07.095546: step 133800, loss = 0.36, batch loss = 0.27 (50.0 examples/sec; 0.160 sec/batch; 8h:49m:34s remains)
INFO - root - 2017-12-01 08:27:08.692944: step 133810, loss = 0.31, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 8h:34m:03s remains)
INFO - root - 2017-12-01 08:27:10.284802: step 133820, loss = 0.29, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 8h:45m:58s remains)
INFO - root - 2017-12-01 08:27:11.869005: step 133830, loss = 0.32, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 8h:35m:48s remains)
INFO - root - 2017-12-01 08:27:13.423372: step 133840, loss = 0.33, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 8h:37m:44s remains)
INFO - root - 2017-12-01 08:27:14.985516: step 133850, loss = 0.28, batch loss = 0.19 (49.0 examples/sec; 0.163 sec/batch; 9h:00m:25s remains)
INFO - root - 2017-12-01 08:27:16.565189: step 133860, loss = 0.29, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 8h:42m:21s remains)
INFO - root - 2017-12-01 08:27:18.148217: step 133870, loss = 0.34, batch loss = 0.25 (50.2 examples/sec; 0.159 sec/batch; 8h:47m:59s remains)
INFO - root - 2017-12-01 08:27:19.697489: step 133880, loss = 0.28, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 8h:33m:43s remains)
INFO - root - 2017-12-01 08:27:21.270777: step 133890, loss = 0.32, batch loss = 0.23 (48.8 examples/sec; 0.164 sec/batch; 9h:03m:11s remains)
INFO - root - 2017-12-01 08:27:22.856637: step 133900, loss = 0.34, batch loss = 0.24 (52.4 examples/sec; 0.153 sec/batch; 8h:25m:27s remains)
INFO - root - 2017-12-01 08:27:24.479216: step 133910, loss = 0.30, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 8h:31m:11s remains)
INFO - root - 2017-12-01 08:27:26.026081: step 133920, loss = 0.34, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 8h:32m:49s remains)
INFO - root - 2017-12-01 08:27:27.572746: step 133930, loss = 0.36, batch loss = 0.27 (53.0 examples/sec; 0.151 sec/batch; 8h:19m:18s remains)
INFO - root - 2017-12-01 08:27:29.137368: step 133940, loss = 0.29, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 8h:33m:02s remains)
INFO - root - 2017-12-01 08:27:30.725701: step 133950, loss = 0.27, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 8h:33m:30s remains)
INFO - root - 2017-12-01 08:27:32.278120: step 133960, loss = 0.32, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 8h:32m:51s remains)
INFO - root - 2017-12-01 08:27:33.836818: step 133970, loss = 0.31, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 8h:40m:45s remains)
INFO - root - 2017-12-01 08:27:35.397351: step 133980, loss = 0.25, batch loss = 0.15 (53.5 examples/sec; 0.150 sec/batch; 8h:15m:02s remains)
INFO - root - 2017-12-01 08:27:36.966776: step 133990, loss = 0.30, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 8h:29m:49s remains)
INFO - root - 2017-12-01 08:27:38.551218: step 134000, loss = 0.30, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 8h:35m:55s remains)
INFO - root - 2017-12-01 08:27:40.175840: step 134010, loss = 0.31, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 8h:37m:21s remains)
INFO - root - 2017-12-01 08:27:41.739635: step 134020, loss = 0.37, batch loss = 0.28 (51.0 examples/sec; 0.157 sec/batch; 8h:38m:43s remains)
INFO - root - 2017-12-01 08:27:43.298882: step 134030, loss = 0.32, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 8h:25m:52s remains)
INFO - root - 2017-12-01 08:27:44.870678: step 134040, loss = 0.35, batch loss = 0.26 (50.5 examples/sec; 0.159 sec/batch; 8h:44m:18s remains)
INFO - root - 2017-12-01 08:27:46.436612: step 134050, loss = 0.28, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 8h:40m:35s remains)
INFO - root - 2017-12-01 08:27:48.008548: step 134060, loss = 0.28, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 8h:30m:36s remains)
INFO - root - 2017-12-01 08:27:49.588303: step 134070, loss = 0.26, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 8h:33m:26s remains)
INFO - root - 2017-12-01 08:27:51.161527: step 134080, loss = 0.36, batch loss = 0.27 (50.7 examples/sec; 0.158 sec/batch; 8h:41m:23s remains)
INFO - root - 2017-12-01 08:27:52.730413: step 134090, loss = 0.37, batch loss = 0.28 (50.3 examples/sec; 0.159 sec/batch; 8h:45m:38s remains)
INFO - root - 2017-12-01 08:27:54.303727: step 134100, loss = 0.27, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 8h:36m:13s remains)
INFO - root - 2017-12-01 08:27:55.935441: step 134110, loss = 0.33, batch loss = 0.24 (51.8 examples/sec; 0.155 sec/batch; 8h:31m:02s remains)
INFO - root - 2017-12-01 08:27:57.509960: step 134120, loss = 0.24, batch loss = 0.15 (50.6 examples/sec; 0.158 sec/batch; 8h:42m:19s remains)
INFO - root - 2017-12-01 08:27:59.072962: step 134130, loss = 0.36, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 8h:35m:13s remains)
INFO - root - 2017-12-01 08:28:00.632932: step 134140, loss = 0.26, batch loss = 0.17 (51.8 examples/sec; 0.155 sec/batch; 8h:31m:02s remains)
INFO - root - 2017-12-01 08:28:02.197071: step 134150, loss = 0.25, batch loss = 0.15 (50.2 examples/sec; 0.159 sec/batch; 8h:46m:56s remains)
INFO - root - 2017-12-01 08:28:03.774853: step 134160, loss = 0.25, batch loss = 0.16 (48.5 examples/sec; 0.165 sec/batch; 9h:04m:48s remains)
INFO - root - 2017-12-01 08:28:05.342372: step 134170, loss = 0.34, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 8h:42m:36s remains)
INFO - root - 2017-12-01 08:28:06.900453: step 134180, loss = 0.35, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 8h:33m:43s remains)
INFO - root - 2017-12-01 08:28:08.480119: step 134190, loss = 0.27, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 8h:42m:53s remains)
INFO - root - 2017-12-01 08:28:10.061025: step 134200, loss = 0.40, batch loss = 0.31 (48.7 examples/sec; 0.164 sec/batch; 9h:02m:35s remains)
INFO - root - 2017-12-01 08:28:11.699718: step 134210, loss = 0.30, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 8h:32m:25s remains)
INFO - root - 2017-12-01 08:28:13.249783: step 134220, loss = 0.27, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 8h:34m:26s remains)
INFO - root - 2017-12-01 08:28:14.824882: step 134230, loss = 0.35, batch loss = 0.26 (47.9 examples/sec; 0.167 sec/batch; 9h:12m:01s remains)
INFO - root - 2017-12-01 08:28:16.411266: step 134240, loss = 0.23, batch loss = 0.14 (51.0 examples/sec; 0.157 sec/batch; 8h:38m:20s remains)
INFO - root - 2017-12-01 08:28:17.980830: step 134250, loss = 0.26, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 8h:32m:09s remains)
INFO - root - 2017-12-01 08:28:19.528679: step 134260, loss = 0.30, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 8h:40m:47s remains)
INFO - root - 2017-12-01 08:28:21.081455: step 134270, loss = 0.24, batch loss = 0.14 (50.6 examples/sec; 0.158 sec/batch; 8h:42m:29s remains)
INFO - root - 2017-12-01 08:28:22.654409: step 134280, loss = 0.29, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 8h:34m:14s remains)
INFO - root - 2017-12-01 08:28:24.229563: step 134290, loss = 0.33, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 8h:31m:25s remains)
INFO - root - 2017-12-01 08:28:25.809918: step 134300, loss = 0.25, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 8h:35m:18s remains)
INFO - root - 2017-12-01 08:28:27.406854: step 134310, loss = 0.36, batch loss = 0.27 (51.7 examples/sec; 0.155 sec/batch; 8h:30m:56s remains)
INFO - root - 2017-12-01 08:28:28.971390: step 134320, loss = 0.29, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 8h:24m:37s remains)
INFO - root - 2017-12-01 08:28:30.543459: step 134330, loss = 0.23, batch loss = 0.14 (52.4 examples/sec; 0.153 sec/batch; 8h:24m:08s remains)
INFO - root - 2017-12-01 08:28:32.126514: step 134340, loss = 0.27, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 8h:44m:51s remains)
INFO - root - 2017-12-01 08:28:33.688459: step 134350, loss = 0.26, batch loss = 0.16 (49.6 examples/sec; 0.161 sec/batch; 8h:53m:09s remains)
INFO - root - 2017-12-01 08:28:35.276212: step 134360, loss = 0.29, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 8h:42m:28s remains)
INFO - root - 2017-12-01 08:28:36.843890: step 134370, loss = 0.33, batch loss = 0.24 (51.8 examples/sec; 0.154 sec/batch; 8h:29m:39s remains)
INFO - root - 2017-12-01 08:28:38.400488: step 134380, loss = 0.34, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 8h:32m:23s remains)
INFO - root - 2017-12-01 08:28:39.959955: step 134390, loss = 0.27, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 8h:44m:34s remains)
INFO - root - 2017-12-01 08:28:41.523108: step 134400, loss = 0.40, batch loss = 0.30 (51.3 examples/sec; 0.156 sec/batch; 8h:35m:13s remains)
INFO - root - 2017-12-01 08:28:43.137406: step 134410, loss = 0.26, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 8h:28m:13s remains)
INFO - root - 2017-12-01 08:28:44.704176: step 134420, loss = 0.24, batch loss = 0.15 (50.5 examples/sec; 0.159 sec/batch; 8h:43m:27s remains)
INFO - root - 2017-12-01 08:28:46.256788: step 134430, loss = 0.35, batch loss = 0.26 (51.1 examples/sec; 0.157 sec/batch; 8h:37m:04s remains)
INFO - root - 2017-12-01 08:28:47.834760: step 134440, loss = 0.30, batch loss = 0.21 (50.0 examples/sec; 0.160 sec/batch; 8h:48m:12s remains)
INFO - root - 2017-12-01 08:28:49.403333: step 134450, loss = 0.31, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 8h:30m:55s remains)
INFO - root - 2017-12-01 08:28:50.972723: step 134460, loss = 0.25, batch loss = 0.16 (51.1 examples/sec; 0.156 sec/batch; 8h:36m:24s remains)
INFO - root - 2017-12-01 08:28:52.544196: step 134470, loss = 0.29, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 8h:33m:33s remains)
INFO - root - 2017-12-01 08:28:54.115982: step 134480, loss = 0.25, batch loss = 0.16 (52.2 examples/sec; 0.153 sec/batch; 8h:25m:48s remains)
INFO - root - 2017-12-01 08:28:55.728526: step 134490, loss = 0.30, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 8h:46m:49s remains)
INFO - root - 2017-12-01 08:28:57.282017: step 134500, loss = 0.28, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 8h:34m:53s remains)
INFO - root - 2017-12-01 08:28:58.901269: step 134510, loss = 0.30, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 8h:24m:25s remains)
INFO - root - 2017-12-01 08:29:00.474702: step 134520, loss = 0.26, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 8h:31m:34s remains)
INFO - root - 2017-12-01 08:29:02.039701: step 134530, loss = 0.27, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 8h:46m:02s remains)
INFO - root - 2017-12-01 08:29:03.601678: step 134540, loss = 0.25, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 8h:34m:37s remains)
INFO - root - 2017-12-01 08:29:05.165907: step 134550, loss = 0.24, batch loss = 0.15 (52.1 examples/sec; 0.154 sec/batch; 8h:26m:46s remains)
INFO - root - 2017-12-01 08:29:06.736075: step 134560, loss = 0.35, batch loss = 0.26 (50.1 examples/sec; 0.160 sec/batch; 8h:47m:12s remains)
INFO - root - 2017-12-01 08:29:08.296663: step 134570, loss = 0.29, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 8h:36m:24s remains)
INFO - root - 2017-12-01 08:29:09.865107: step 134580, loss = 0.31, batch loss = 0.21 (50.5 examples/sec; 0.159 sec/batch; 8h:43m:03s remains)
INFO - root - 2017-12-01 08:29:11.424232: step 134590, loss = 0.32, batch loss = 0.22 (52.7 examples/sec; 0.152 sec/batch; 8h:21m:09s remains)
INFO - root - 2017-12-01 08:29:13.004007: step 134600, loss = 0.26, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 8h:28m:03s remains)
INFO - root - 2017-12-01 08:29:14.621109: step 134610, loss = 0.31, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 8h:34m:29s remains)
INFO - root - 2017-12-01 08:29:16.170092: step 134620, loss = 0.32, batch loss = 0.23 (53.5 examples/sec; 0.150 sec/batch; 8h:13m:19s remains)
INFO - root - 2017-12-01 08:29:17.726400: step 134630, loss = 0.27, batch loss = 0.18 (49.5 examples/sec; 0.162 sec/batch; 8h:53m:02s remains)
INFO - root - 2017-12-01 08:29:19.319761: step 134640, loss = 0.25, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 8h:29m:13s remains)
INFO - root - 2017-12-01 08:29:20.881712: step 134650, loss = 0.29, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 8h:40m:34s remains)
INFO - root - 2017-12-01 08:29:22.430373: step 134660, loss = 0.25, batch loss = 0.15 (52.1 examples/sec; 0.154 sec/batch; 8h:26m:32s remains)
INFO - root - 2017-12-01 08:29:23.981509: step 134670, loss = 0.28, batch loss = 0.18 (50.1 examples/sec; 0.160 sec/batch; 8h:46m:50s remains)
INFO - root - 2017-12-01 08:29:25.555425: step 134680, loss = 0.33, batch loss = 0.24 (53.6 examples/sec; 0.149 sec/batch; 8h:12m:01s remains)
INFO - root - 2017-12-01 08:29:27.126103: step 134690, loss = 0.36, batch loss = 0.27 (50.2 examples/sec; 0.159 sec/batch; 8h:45m:42s remains)
INFO - root - 2017-12-01 08:29:28.692983: step 134700, loss = 0.30, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 8h:28m:02s remains)
INFO - root - 2017-12-01 08:29:30.301603: step 134710, loss = 0.24, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 8h:33m:42s remains)
INFO - root - 2017-12-01 08:29:31.851084: step 134720, loss = 0.28, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 8h:35m:31s remains)
INFO - root - 2017-12-01 08:29:33.414131: step 134730, loss = 0.27, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 8h:29m:50s remains)
INFO - root - 2017-12-01 08:29:34.993876: step 134740, loss = 0.29, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 8h:43m:54s remains)
INFO - root - 2017-12-01 08:29:36.556083: step 134750, loss = 0.27, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 8h:43m:33s remains)
INFO - root - 2017-12-01 08:29:38.117938: step 134760, loss = 0.35, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 8h:28m:11s remains)
INFO - root - 2017-12-01 08:29:39.745175: step 134770, loss = 0.33, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 8h:37m:11s remains)
INFO - root - 2017-12-01 08:29:41.310353: step 134780, loss = 0.23, batch loss = 0.14 (49.5 examples/sec; 0.162 sec/batch; 8h:52m:59s remains)
INFO - root - 2017-12-01 08:29:42.874917: step 134790, loss = 0.39, batch loss = 0.29 (50.9 examples/sec; 0.157 sec/batch; 8h:37m:57s remains)
INFO - root - 2017-12-01 08:29:44.447725: step 134800, loss = 0.36, batch loss = 0.27 (51.9 examples/sec; 0.154 sec/batch; 8h:27m:40s remains)
INFO - root - 2017-12-01 08:29:46.065649: step 134810, loss = 0.29, batch loss = 0.20 (48.8 examples/sec; 0.164 sec/batch; 9h:00m:28s remains)
INFO - root - 2017-12-01 08:29:47.628651: step 134820, loss = 0.29, batch loss = 0.20 (53.3 examples/sec; 0.150 sec/batch; 8h:14m:36s remains)
INFO - root - 2017-12-01 08:29:49.175634: step 134830, loss = 0.25, batch loss = 0.16 (51.0 examples/sec; 0.157 sec/batch; 8h:37m:13s remains)
INFO - root - 2017-12-01 08:29:50.758120: step 134840, loss = 0.29, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 8h:29m:59s remains)
INFO - root - 2017-12-01 08:29:52.345223: step 134850, loss = 0.33, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 8h:41m:06s remains)
INFO - root - 2017-12-01 08:29:53.916767: step 134860, loss = 0.33, batch loss = 0.24 (48.3 examples/sec; 0.166 sec/batch; 9h:05m:44s remains)
INFO - root - 2017-12-01 08:29:55.482608: step 134870, loss = 0.27, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 8h:31m:05s remains)
INFO - root - 2017-12-01 08:29:57.048486: step 134880, loss = 0.25, batch loss = 0.16 (53.5 examples/sec; 0.150 sec/batch; 8h:12m:36s remains)
INFO - root - 2017-12-01 08:29:58.578610: step 134890, loss = 0.26, batch loss = 0.17 (53.2 examples/sec; 0.150 sec/batch; 8h:14m:51s remains)
INFO - root - 2017-12-01 08:30:00.149420: step 134900, loss = 0.30, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 8h:45m:01s remains)
INFO - root - 2017-12-01 08:30:01.787197: step 134910, loss = 0.35, batch loss = 0.26 (52.2 examples/sec; 0.153 sec/batch; 8h:24m:48s remains)
INFO - root - 2017-12-01 08:30:03.370587: step 134920, loss = 0.25, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 8h:39m:17s remains)
INFO - root - 2017-12-01 08:30:04.928923: step 134930, loss = 0.27, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 8h:31m:03s remains)
INFO - root - 2017-12-01 08:30:06.494541: step 134940, loss = 0.33, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 8h:41m:27s remains)
INFO - root - 2017-12-01 08:30:08.052849: step 134950, loss = 0.44, batch loss = 0.35 (52.6 examples/sec; 0.152 sec/batch; 8h:20m:24s remains)
INFO - root - 2017-12-01 08:30:09.616540: step 134960, loss = 0.27, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 8h:40m:00s remains)
INFO - root - 2017-12-01 08:30:11.177617: step 134970, loss = 0.31, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 8h:38m:08s remains)
INFO - root - 2017-12-01 08:30:12.744924: step 134980, loss = 0.23, batch loss = 0.14 (49.5 examples/sec; 0.162 sec/batch; 8h:52m:05s remains)
INFO - root - 2017-12-01 08:30:14.313151: step 134990, loss = 0.30, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 8h:31m:02s remains)
INFO - root - 2017-12-01 08:30:15.876514: step 135000, loss = 0.30, batch loss = 0.20 (52.5 examples/sec; 0.152 sec/batch; 8h:21m:41s remains)
INFO - root - 2017-12-01 08:30:17.535018: step 135010, loss = 0.28, batch loss = 0.18 (52.1 examples/sec; 0.154 sec/batch; 8h:25m:47s remains)
INFO - root - 2017-12-01 08:30:19.112511: step 135020, loss = 0.48, batch loss = 0.39 (50.4 examples/sec; 0.159 sec/batch; 8h:42m:49s remains)
INFO - root - 2017-12-01 08:30:20.714306: step 135030, loss = 0.26, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 8h:27m:54s remains)
INFO - root - 2017-12-01 08:30:22.305572: step 135040, loss = 0.39, batch loss = 0.30 (48.0 examples/sec; 0.167 sec/batch; 9h:08m:39s remains)
INFO - root - 2017-12-01 08:30:23.875985: step 135050, loss = 0.24, batch loss = 0.15 (52.1 examples/sec; 0.154 sec/batch; 8h:25m:42s remains)
INFO - root - 2017-12-01 08:30:25.431989: step 135060, loss = 0.25, batch loss = 0.16 (50.8 examples/sec; 0.158 sec/batch; 8h:38m:37s remains)
INFO - root - 2017-12-01 08:30:27.035502: step 135070, loss = 0.27, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 8h:40m:13s remains)
INFO - root - 2017-12-01 08:30:28.598949: step 135080, loss = 0.36, batch loss = 0.27 (52.1 examples/sec; 0.154 sec/batch; 8h:25m:31s remains)
INFO - root - 2017-12-01 08:30:30.162402: step 135090, loss = 0.28, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 8h:23m:09s remains)
INFO - root - 2017-12-01 08:30:31.729936: step 135100, loss = 0.27, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 8h:28m:48s remains)
INFO - root - 2017-12-01 08:30:33.357618: step 135110, loss = 0.25, batch loss = 0.15 (52.1 examples/sec; 0.154 sec/batch; 8h:25m:06s remains)
INFO - root - 2017-12-01 08:30:34.941485: step 135120, loss = 0.35, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 8h:27m:47s remains)
INFO - root - 2017-12-01 08:30:36.498802: step 135130, loss = 0.30, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 8h:36m:16s remains)
INFO - root - 2017-12-01 08:30:38.065456: step 135140, loss = 0.27, batch loss = 0.18 (49.9 examples/sec; 0.160 sec/batch; 8h:47m:19s remains)
INFO - root - 2017-12-01 08:30:39.626723: step 135150, loss = 0.30, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 8h:40m:15s remains)
INFO - root - 2017-12-01 08:30:41.173446: step 135160, loss = 0.35, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 8h:31m:02s remains)
INFO - root - 2017-12-01 08:30:42.721586: step 135170, loss = 0.37, batch loss = 0.28 (52.0 examples/sec; 0.154 sec/batch; 8h:26m:08s remains)
INFO - root - 2017-12-01 08:30:44.293993: step 135180, loss = 0.29, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 8h:23m:56s remains)
INFO - root - 2017-12-01 08:30:45.838048: step 135190, loss = 0.34, batch loss = 0.25 (52.0 examples/sec; 0.154 sec/batch; 8h:25m:54s remains)
INFO - root - 2017-12-01 08:30:47.415238: step 135200, loss = 0.31, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 8h:27m:29s remains)
INFO - root - 2017-12-01 08:30:49.099625: step 135210, loss = 0.33, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 8h:28m:23s remains)
INFO - root - 2017-12-01 08:30:50.662590: step 135220, loss = 0.28, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 8h:39m:46s remains)
INFO - root - 2017-12-01 08:30:52.220286: step 135230, loss = 0.25, batch loss = 0.15 (51.7 examples/sec; 0.155 sec/batch; 8h:28m:50s remains)
INFO - root - 2017-12-01 08:30:53.775021: step 135240, loss = 0.24, batch loss = 0.15 (53.2 examples/sec; 0.150 sec/batch; 8h:13m:57s remains)
INFO - root - 2017-12-01 08:30:55.335562: step 135250, loss = 0.33, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 8h:23m:15s remains)
INFO - root - 2017-12-01 08:30:56.949194: step 135260, loss = 0.31, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 8h:35m:24s remains)
INFO - root - 2017-12-01 08:30:58.510161: step 135270, loss = 0.34, batch loss = 0.25 (48.9 examples/sec; 0.164 sec/batch; 8h:58m:15s remains)
INFO - root - 2017-12-01 08:31:00.070832: step 135280, loss = 0.27, batch loss = 0.18 (52.6 examples/sec; 0.152 sec/batch; 8h:19m:47s remains)
INFO - root - 2017-12-01 08:31:01.640543: step 135290, loss = 0.27, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 8h:35m:46s remains)
INFO - root - 2017-12-01 08:31:03.213439: step 135300, loss = 0.38, batch loss = 0.29 (51.0 examples/sec; 0.157 sec/batch; 8h:35m:21s remains)
INFO - root - 2017-12-01 08:31:04.817840: step 135310, loss = 0.23, batch loss = 0.14 (52.5 examples/sec; 0.152 sec/batch; 8h:20m:20s remains)
INFO - root - 2017-12-01 08:31:06.367322: step 135320, loss = 0.33, batch loss = 0.24 (52.8 examples/sec; 0.151 sec/batch; 8h:17m:47s remains)
INFO - root - 2017-12-01 08:31:07.944598: step 135330, loss = 0.32, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 8h:25m:23s remains)
INFO - root - 2017-12-01 08:31:09.522938: step 135340, loss = 0.26, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 8h:39m:49s remains)
INFO - root - 2017-12-01 08:31:11.107701: step 135350, loss = 0.27, batch loss = 0.18 (48.3 examples/sec; 0.166 sec/batch; 9h:03m:56s remains)
INFO - root - 2017-12-01 08:31:12.682624: step 135360, loss = 0.31, batch loss = 0.22 (52.8 examples/sec; 0.152 sec/batch; 8h:18m:13s remains)
INFO - root - 2017-12-01 08:31:14.263227: step 135370, loss = 0.29, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 8h:32m:55s remains)
INFO - root - 2017-12-01 08:31:15.848039: step 135380, loss = 0.31, batch loss = 0.22 (48.9 examples/sec; 0.163 sec/batch; 8h:57m:00s remains)
INFO - root - 2017-12-01 08:31:17.433406: step 135390, loss = 0.29, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 8h:28m:25s remains)
INFO - root - 2017-12-01 08:31:18.984225: step 135400, loss = 0.36, batch loss = 0.26 (52.0 examples/sec; 0.154 sec/batch; 8h:25m:00s remains)
INFO - root - 2017-12-01 08:31:20.611149: step 135410, loss = 0.33, batch loss = 0.24 (50.1 examples/sec; 0.160 sec/batch; 8h:44m:01s remains)
INFO - root - 2017-12-01 08:31:22.193527: step 135420, loss = 0.34, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 8h:36m:30s remains)
INFO - root - 2017-12-01 08:31:23.770006: step 135430, loss = 0.28, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 8h:38m:39s remains)
INFO - root - 2017-12-01 08:31:25.338131: step 135440, loss = 0.27, batch loss = 0.18 (48.9 examples/sec; 0.164 sec/batch; 8h:57m:15s remains)
INFO - root - 2017-12-01 08:31:26.913360: step 135450, loss = 0.33, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 8h:35m:33s remains)
INFO - root - 2017-12-01 08:31:28.473576: step 135460, loss = 0.23, batch loss = 0.14 (51.9 examples/sec; 0.154 sec/batch; 8h:26m:35s remains)
INFO - root - 2017-12-01 08:31:30.036843: step 135470, loss = 0.34, batch loss = 0.24 (52.7 examples/sec; 0.152 sec/batch; 8h:18m:37s remains)
INFO - root - 2017-12-01 08:31:31.616275: step 135480, loss = 0.28, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 8h:32m:50s remains)
INFO - root - 2017-12-01 08:31:33.174970: step 135490, loss = 0.30, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 8h:35m:13s remains)
INFO - root - 2017-12-01 08:31:34.762753: step 135500, loss = 0.34, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 8h:29m:42s remains)
INFO - root - 2017-12-01 08:31:36.368438: step 135510, loss = 0.26, batch loss = 0.17 (50.8 examples/sec; 0.157 sec/batch; 8h:36m:55s remains)
INFO - root - 2017-12-01 08:31:37.938770: step 135520, loss = 0.36, batch loss = 0.27 (49.2 examples/sec; 0.163 sec/batch; 8h:54m:10s remains)
INFO - root - 2017-12-01 08:31:39.507264: step 135530, loss = 0.30, batch loss = 0.21 (52.7 examples/sec; 0.152 sec/batch; 8h:18m:07s remains)
INFO - root - 2017-12-01 08:31:41.075136: step 135540, loss = 0.28, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 8h:33m:22s remains)
INFO - root - 2017-12-01 08:31:42.655750: step 135550, loss = 0.33, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 8h:31m:50s remains)
INFO - root - 2017-12-01 08:31:44.220304: step 135560, loss = 0.24, batch loss = 0.15 (49.7 examples/sec; 0.161 sec/batch; 8h:48m:14s remains)
INFO - root - 2017-12-01 08:31:45.773940: step 135570, loss = 0.30, batch loss = 0.21 (52.8 examples/sec; 0.152 sec/batch; 8h:17m:34s remains)
INFO - root - 2017-12-01 08:31:47.343798: step 135580, loss = 0.22, batch loss = 0.13 (51.0 examples/sec; 0.157 sec/batch; 8h:34m:33s remains)
INFO - root - 2017-12-01 08:31:48.909784: step 135590, loss = 0.26, batch loss = 0.17 (52.1 examples/sec; 0.154 sec/batch; 8h:24m:09s remains)
INFO - root - 2017-12-01 08:31:50.482210: step 135600, loss = 0.36, batch loss = 0.26 (50.5 examples/sec; 0.159 sec/batch; 8h:40m:09s remains)
INFO - root - 2017-12-01 08:31:52.117136: step 135610, loss = 0.24, batch loss = 0.15 (50.9 examples/sec; 0.157 sec/batch; 8h:35m:39s remains)
INFO - root - 2017-12-01 08:31:53.654456: step 135620, loss = 0.37, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 8h:35m:51s remains)
INFO - root - 2017-12-01 08:31:55.225846: step 135630, loss = 0.28, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 8h:34m:20s remains)
INFO - root - 2017-12-01 08:31:56.788402: step 135640, loss = 0.28, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 8h:37m:15s remains)
INFO - root - 2017-12-01 08:31:58.355575: step 135650, loss = 0.27, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 8h:28m:24s remains)
INFO - root - 2017-12-01 08:31:59.914214: step 135660, loss = 0.30, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 8h:25m:07s remains)
INFO - root - 2017-12-01 08:32:01.490995: step 135670, loss = 0.43, batch loss = 0.33 (51.6 examples/sec; 0.155 sec/batch; 8h:28m:31s remains)
INFO - root - 2017-12-01 08:32:03.056003: step 135680, loss = 0.29, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 8h:38m:02s remains)
INFO - root - 2017-12-01 08:32:04.611539: step 135690, loss = 0.25, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 8h:30m:49s remains)
INFO - root - 2017-12-01 08:32:06.158416: step 135700, loss = 0.23, batch loss = 0.14 (50.7 examples/sec; 0.158 sec/batch; 8h:37m:24s remains)
INFO - root - 2017-12-01 08:32:07.778961: step 135710, loss = 0.35, batch loss = 0.26 (52.5 examples/sec; 0.152 sec/batch; 8h:20m:03s remains)
INFO - root - 2017-12-01 08:32:09.317352: step 135720, loss = 0.23, batch loss = 0.14 (52.1 examples/sec; 0.154 sec/batch; 8h:24m:01s remains)
INFO - root - 2017-12-01 08:32:10.897907: step 135730, loss = 0.32, batch loss = 0.22 (45.1 examples/sec; 0.177 sec/batch; 9h:41m:08s remains)
INFO - root - 2017-12-01 08:32:12.459182: step 135740, loss = 0.33, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 8h:22m:20s remains)
INFO - root - 2017-12-01 08:32:14.215358: step 135750, loss = 0.31, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 8h:26m:55s remains)
INFO - root - 2017-12-01 08:32:15.844693: step 135760, loss = 0.41, batch loss = 0.32 (50.4 examples/sec; 0.159 sec/batch; 8h:40m:53s remains)
INFO - root - 2017-12-01 08:32:17.404599: step 135770, loss = 0.31, batch loss = 0.22 (52.7 examples/sec; 0.152 sec/batch; 8h:17m:47s remains)
INFO - root - 2017-12-01 08:32:18.966792: step 135780, loss = 0.24, batch loss = 0.15 (53.1 examples/sec; 0.151 sec/batch; 8h:13m:35s remains)
INFO - root - 2017-12-01 08:32:20.535611: step 135790, loss = 0.28, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 8h:38m:09s remains)
INFO - root - 2017-12-01 08:32:22.098502: step 135800, loss = 0.26, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 8h:37m:58s remains)
INFO - root - 2017-12-01 08:32:23.751865: step 135810, loss = 0.27, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 8h:28m:27s remains)
INFO - root - 2017-12-01 08:32:25.327642: step 135820, loss = 0.26, batch loss = 0.16 (49.6 examples/sec; 0.161 sec/batch; 8h:49m:08s remains)
INFO - root - 2017-12-01 08:32:26.881933: step 135830, loss = 0.34, batch loss = 0.25 (47.4 examples/sec; 0.169 sec/batch; 9h:12m:55s remains)
INFO - root - 2017-12-01 08:32:28.443430: step 135840, loss = 0.34, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 8h:24m:52s remains)
INFO - root - 2017-12-01 08:32:30.026327: step 135850, loss = 0.32, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 8h:17m:52s remains)
INFO - root - 2017-12-01 08:32:31.601140: step 135860, loss = 0.37, batch loss = 0.28 (50.0 examples/sec; 0.160 sec/batch; 8h:44m:00s remains)
INFO - root - 2017-12-01 08:32:33.164193: step 135870, loss = 0.29, batch loss = 0.20 (53.1 examples/sec; 0.151 sec/batch; 8h:14m:01s remains)
INFO - root - 2017-12-01 08:32:34.716951: step 135880, loss = 0.34, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 8h:31m:45s remains)
INFO - root - 2017-12-01 08:32:36.309943: step 135890, loss = 0.28, batch loss = 0.19 (44.4 examples/sec; 0.180 sec/batch; 9h:51m:02s remains)
INFO - root - 2017-12-01 08:32:37.870600: step 135900, loss = 0.26, batch loss = 0.17 (50.5 examples/sec; 0.159 sec/batch; 8h:39m:33s remains)
INFO - root - 2017-12-01 08:32:39.490002: step 135910, loss = 0.28, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 8h:28m:23s remains)
INFO - root - 2017-12-01 08:32:41.078857: step 135920, loss = 0.30, batch loss = 0.20 (45.5 examples/sec; 0.176 sec/batch; 9h:35m:43s remains)
INFO - root - 2017-12-01 08:32:42.651462: step 135930, loss = 0.28, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 8h:26m:00s remains)
INFO - root - 2017-12-01 08:32:44.209082: step 135940, loss = 0.28, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 8h:28m:55s remains)
INFO - root - 2017-12-01 08:32:45.755649: step 135950, loss = 0.31, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 8h:27m:23s remains)
INFO - root - 2017-12-01 08:32:47.339665: step 135960, loss = 0.46, batch loss = 0.36 (51.3 examples/sec; 0.156 sec/batch; 8h:30m:27s remains)
INFO - root - 2017-12-01 08:32:48.892100: step 135970, loss = 0.28, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 8h:38m:29s remains)
INFO - root - 2017-12-01 08:32:50.462122: step 135980, loss = 0.27, batch loss = 0.18 (49.8 examples/sec; 0.161 sec/batch; 8h:46m:20s remains)
INFO - root - 2017-12-01 08:32:52.045010: step 135990, loss = 0.30, batch loss = 0.20 (49.3 examples/sec; 0.162 sec/batch; 8h:50m:59s remains)
INFO - root - 2017-12-01 08:32:53.605855: step 136000, loss = 0.23, batch loss = 0.14 (51.3 examples/sec; 0.156 sec/batch; 8h:30m:39s remains)
INFO - root - 2017-12-01 08:32:55.228972: step 136010, loss = 0.26, batch loss = 0.17 (49.9 examples/sec; 0.160 sec/batch; 8h:45m:25s remains)
INFO - root - 2017-12-01 08:32:56.817155: step 136020, loss = 0.36, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 8h:29m:06s remains)
INFO - root - 2017-12-01 08:32:58.403846: step 136030, loss = 0.26, batch loss = 0.16 (50.5 examples/sec; 0.158 sec/batch; 8h:38m:55s remains)
INFO - root - 2017-12-01 08:32:59.971347: step 136040, loss = 0.35, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 8h:25m:09s remains)
INFO - root - 2017-12-01 08:33:01.539727: step 136050, loss = 0.35, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 8h:36m:09s remains)
INFO - root - 2017-12-01 08:33:03.098425: step 136060, loss = 0.31, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 8h:39m:26s remains)
INFO - root - 2017-12-01 08:33:04.649912: step 136070, loss = 0.26, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 8h:24m:50s remains)
INFO - root - 2017-12-01 08:33:06.213211: step 136080, loss = 0.29, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 8h:20m:40s remains)
INFO - root - 2017-12-01 08:33:07.792154: step 136090, loss = 0.45, batch loss = 0.36 (50.7 examples/sec; 0.158 sec/batch; 8h:37m:01s remains)
INFO - root - 2017-12-01 08:33:09.354007: step 136100, loss = 0.29, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 8h:37m:42s remains)
INFO - root - 2017-12-01 08:33:11.058251: step 136110, loss = 0.30, batch loss = 0.21 (49.2 examples/sec; 0.163 sec/batch; 8h:52m:21s remains)
INFO - root - 2017-12-01 08:33:12.645498: step 136120, loss = 0.38, batch loss = 0.29 (52.6 examples/sec; 0.152 sec/batch; 8h:17m:22s remains)
INFO - root - 2017-12-01 08:33:14.209767: step 136130, loss = 0.45, batch loss = 0.35 (50.8 examples/sec; 0.157 sec/batch; 8h:35m:07s remains)
INFO - root - 2017-12-01 08:33:15.817967: step 136140, loss = 0.30, batch loss = 0.21 (53.2 examples/sec; 0.150 sec/batch; 8h:12m:07s remains)
INFO - root - 2017-12-01 08:33:17.384337: step 136150, loss = 0.30, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 8h:29m:46s remains)
INFO - root - 2017-12-01 08:33:18.974252: step 136160, loss = 0.42, batch loss = 0.33 (50.8 examples/sec; 0.157 sec/batch; 8h:34m:49s remains)
INFO - root - 2017-12-01 08:33:20.546328: step 136170, loss = 0.27, batch loss = 0.17 (50.8 examples/sec; 0.157 sec/batch; 8h:35m:08s remains)
INFO - root - 2017-12-01 08:33:22.110020: step 136180, loss = 0.31, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 8h:30m:48s remains)
INFO - root - 2017-12-01 08:33:23.682971: step 136190, loss = 0.28, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 8h:33m:55s remains)
INFO - root - 2017-12-01 08:33:25.260602: step 136200, loss = 0.45, batch loss = 0.35 (51.2 examples/sec; 0.156 sec/batch; 8h:31m:26s remains)
INFO - root - 2017-12-01 08:33:26.892921: step 136210, loss = 0.35, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 8h:26m:50s remains)
INFO - root - 2017-12-01 08:33:28.464412: step 136220, loss = 0.23, batch loss = 0.14 (50.3 examples/sec; 0.159 sec/batch; 8h:39m:51s remains)
INFO - root - 2017-12-01 08:33:30.024263: step 136230, loss = 0.29, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 8h:23m:52s remains)
INFO - root - 2017-12-01 08:33:31.587289: step 136240, loss = 0.28, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 8h:34m:50s remains)
INFO - root - 2017-12-01 08:33:33.174312: step 136250, loss = 0.34, batch loss = 0.25 (49.7 examples/sec; 0.161 sec/batch; 8h:46m:23s remains)
INFO - root - 2017-12-01 08:33:34.745653: step 136260, loss = 0.44, batch loss = 0.35 (48.6 examples/sec; 0.165 sec/batch; 8h:58m:44s remains)
INFO - root - 2017-12-01 08:33:36.323107: step 136270, loss = 0.34, batch loss = 0.25 (52.1 examples/sec; 0.154 sec/batch; 8h:22m:10s remains)
INFO - root - 2017-12-01 08:33:37.918630: step 136280, loss = 0.30, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 8h:32m:32s remains)
INFO - root - 2017-12-01 08:33:39.478562: step 136290, loss = 0.26, batch loss = 0.17 (48.2 examples/sec; 0.166 sec/batch; 9h:02m:36s remains)
INFO - root - 2017-12-01 08:33:41.063242: step 136300, loss = 0.26, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 8h:26m:56s remains)
INFO - root - 2017-12-01 08:33:42.675137: step 136310, loss = 0.26, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 8h:27m:46s remains)
INFO - root - 2017-12-01 08:33:44.239838: step 136320, loss = 0.40, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 8h:26m:38s remains)
INFO - root - 2017-12-01 08:33:45.789877: step 136330, loss = 0.22, batch loss = 0.13 (51.0 examples/sec; 0.157 sec/batch; 8h:33m:15s remains)
INFO - root - 2017-12-01 08:33:47.386639: step 136340, loss = 0.34, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 8h:25m:35s remains)
INFO - root - 2017-12-01 08:33:48.967214: step 136350, loss = 0.26, batch loss = 0.17 (50.2 examples/sec; 0.159 sec/batch; 8h:40m:56s remains)
INFO - root - 2017-12-01 08:33:50.531984: step 136360, loss = 0.38, batch loss = 0.29 (53.0 examples/sec; 0.151 sec/batch; 8h:13m:08s remains)
INFO - root - 2017-12-01 08:33:52.107730: step 136370, loss = 0.32, batch loss = 0.23 (52.5 examples/sec; 0.152 sec/batch; 8h:18m:04s remains)
INFO - root - 2017-12-01 08:33:53.685660: step 136380, loss = 0.25, batch loss = 0.16 (50.8 examples/sec; 0.158 sec/batch; 8h:34m:51s remains)
INFO - root - 2017-12-01 08:33:55.237465: step 136390, loss = 0.32, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 8h:22m:47s remains)
INFO - root - 2017-12-01 08:33:56.797206: step 136400, loss = 0.37, batch loss = 0.28 (50.6 examples/sec; 0.158 sec/batch; 8h:37m:06s remains)
INFO - root - 2017-12-01 08:33:58.431967: step 136410, loss = 0.27, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 8h:25m:45s remains)
INFO - root - 2017-12-01 08:34:00.018643: step 136420, loss = 0.35, batch loss = 0.26 (49.6 examples/sec; 0.161 sec/batch; 8h:46m:49s remains)
INFO - root - 2017-12-01 08:34:01.596899: step 136430, loss = 0.31, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 8h:27m:48s remains)
INFO - root - 2017-12-01 08:34:03.167601: step 136440, loss = 0.24, batch loss = 0.15 (52.6 examples/sec; 0.152 sec/batch; 8h:17m:00s remains)
INFO - root - 2017-12-01 08:34:04.738772: step 136450, loss = 0.33, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 8h:32m:35s remains)
INFO - root - 2017-12-01 08:34:06.296220: step 136460, loss = 0.38, batch loss = 0.29 (50.1 examples/sec; 0.160 sec/batch; 8h:42m:13s remains)
INFO - root - 2017-12-01 08:34:07.872627: step 136470, loss = 0.24, batch loss = 0.14 (50.5 examples/sec; 0.159 sec/batch; 8h:37m:57s remains)
INFO - root - 2017-12-01 08:34:09.430613: step 136480, loss = 0.26, batch loss = 0.16 (52.6 examples/sec; 0.152 sec/batch; 8h:16m:34s remains)
INFO - root - 2017-12-01 08:34:11.006123: step 136490, loss = 0.23, batch loss = 0.14 (50.7 examples/sec; 0.158 sec/batch; 8h:35m:56s remains)
INFO - root - 2017-12-01 08:34:12.577870: step 136500, loss = 0.31, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 8h:29m:15s remains)
INFO - root - 2017-12-01 08:34:14.207683: step 136510, loss = 0.45, batch loss = 0.35 (48.4 examples/sec; 0.165 sec/batch; 9h:00m:13s remains)
INFO - root - 2017-12-01 08:34:15.761868: step 136520, loss = 0.27, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 8h:29m:22s remains)
INFO - root - 2017-12-01 08:34:17.339135: step 136530, loss = 0.28, batch loss = 0.19 (49.8 examples/sec; 0.161 sec/batch; 8h:44m:58s remains)
INFO - root - 2017-12-01 08:34:18.894667: step 136540, loss = 0.30, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 8h:32m:00s remains)
INFO - root - 2017-12-01 08:34:20.444426: step 136550, loss = 0.33, batch loss = 0.24 (49.6 examples/sec; 0.161 sec/batch; 8h:46m:19s remains)
INFO - root - 2017-12-01 08:34:22.040245: step 136560, loss = 0.34, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 8h:33m:38s remains)
INFO - root - 2017-12-01 08:34:23.592835: step 136570, loss = 0.31, batch loss = 0.22 (49.9 examples/sec; 0.160 sec/batch; 8h:43m:49s remains)
INFO - root - 2017-12-01 08:34:25.161495: step 136580, loss = 0.37, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 8h:35m:21s remains)
INFO - root - 2017-12-01 08:34:26.718117: step 136590, loss = 0.26, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 8h:26m:26s remains)
INFO - root - 2017-12-01 08:34:28.285447: step 136600, loss = 0.27, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 8h:23m:43s remains)
INFO - root - 2017-12-01 08:34:29.888672: step 136610, loss = 0.24, batch loss = 0.15 (51.9 examples/sec; 0.154 sec/batch; 8h:23m:39s remains)
INFO - root - 2017-12-01 08:34:31.444325: step 136620, loss = 0.27, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 8h:35m:36s remains)
INFO - root - 2017-12-01 08:34:33.033606: step 136630, loss = 0.29, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 8h:20m:12s remains)
INFO - root - 2017-12-01 08:34:34.594022: step 136640, loss = 0.29, batch loss = 0.20 (53.0 examples/sec; 0.151 sec/batch; 8h:12m:44s remains)
INFO - root - 2017-12-01 08:34:36.151397: step 136650, loss = 0.38, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 8h:22m:55s remains)
INFO - root - 2017-12-01 08:34:37.719726: step 136660, loss = 0.30, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 8h:31m:40s remains)
INFO - root - 2017-12-01 08:34:39.279355: step 136670, loss = 0.37, batch loss = 0.28 (51.8 examples/sec; 0.154 sec/batch; 8h:23m:39s remains)
INFO - root - 2017-12-01 08:34:40.841453: step 136680, loss = 0.53, batch loss = 0.44 (52.4 examples/sec; 0.153 sec/batch; 8h:18m:16s remains)
INFO - root - 2017-12-01 08:34:42.419016: step 136690, loss = 0.29, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 8h:36m:11s remains)
INFO - root - 2017-12-01 08:34:43.975746: step 136700, loss = 0.37, batch loss = 0.28 (51.8 examples/sec; 0.155 sec/batch; 8h:24m:18s remains)
INFO - root - 2017-12-01 08:34:45.586643: step 136710, loss = 0.29, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 8h:19m:47s remains)
INFO - root - 2017-12-01 08:34:47.148272: step 136720, loss = 0.29, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 8h:26m:18s remains)
INFO - root - 2017-12-01 08:34:48.729882: step 136730, loss = 0.31, batch loss = 0.21 (51.8 examples/sec; 0.154 sec/batch; 8h:23m:52s remains)
INFO - root - 2017-12-01 08:34:50.281210: step 136740, loss = 0.30, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 8h:32m:14s remains)
INFO - root - 2017-12-01 08:34:51.838775: step 136750, loss = 0.31, batch loss = 0.22 (49.7 examples/sec; 0.161 sec/batch; 8h:45m:16s remains)
INFO - root - 2017-12-01 08:34:53.408783: step 136760, loss = 0.30, batch loss = 0.21 (51.1 examples/sec; 0.156 sec/batch; 8h:30m:28s remains)
INFO - root - 2017-12-01 08:34:54.989455: step 136770, loss = 0.35, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 8h:27m:51s remains)
INFO - root - 2017-12-01 08:34:56.549454: step 136780, loss = 0.25, batch loss = 0.16 (52.6 examples/sec; 0.152 sec/batch; 8h:16m:09s remains)
INFO - root - 2017-12-01 08:34:58.117991: step 136790, loss = 0.43, batch loss = 0.34 (50.7 examples/sec; 0.158 sec/batch; 8h:35m:07s remains)
INFO - root - 2017-12-01 08:34:59.693805: step 136800, loss = 0.32, batch loss = 0.23 (44.4 examples/sec; 0.180 sec/batch; 9h:47m:21s remains)
INFO - root - 2017-12-01 08:35:01.329602: step 136810, loss = 0.31, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 8h:35m:44s remains)
INFO - root - 2017-12-01 08:35:02.893216: step 136820, loss = 0.23, batch loss = 0.14 (49.2 examples/sec; 0.163 sec/batch; 8h:50m:22s remains)
INFO - root - 2017-12-01 08:35:04.447067: step 136830, loss = 0.27, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 8h:22m:41s remains)
INFO - root - 2017-12-01 08:35:06.012002: step 136840, loss = 0.41, batch loss = 0.32 (49.4 examples/sec; 0.162 sec/batch; 8h:48m:25s remains)
INFO - root - 2017-12-01 08:35:07.603772: step 136850, loss = 0.41, batch loss = 0.31 (51.8 examples/sec; 0.154 sec/batch; 8h:23m:34s remains)
INFO - root - 2017-12-01 08:35:09.182515: step 136860, loss = 0.26, batch loss = 0.17 (49.9 examples/sec; 0.160 sec/batch; 8h:42m:13s remains)
INFO - root - 2017-12-01 08:35:10.776331: step 136870, loss = 0.36, batch loss = 0.27 (45.9 examples/sec; 0.174 sec/batch; 9h:28m:47s remains)
INFO - root - 2017-12-01 08:35:12.381761: step 136880, loss = 0.29, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 8h:22m:20s remains)
INFO - root - 2017-12-01 08:35:13.940805: step 136890, loss = 0.29, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 8h:33m:39s remains)
INFO - root - 2017-12-01 08:35:15.511362: step 136900, loss = 0.26, batch loss = 0.17 (49.0 examples/sec; 0.163 sec/batch; 8h:52m:21s remains)
INFO - root - 2017-12-01 08:35:17.161204: step 136910, loss = 0.33, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 8h:28m:22s remains)
INFO - root - 2017-12-01 08:35:18.723924: step 136920, loss = 0.31, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 8h:32m:23s remains)
INFO - root - 2017-12-01 08:35:20.288384: step 136930, loss = 0.44, batch loss = 0.35 (50.8 examples/sec; 0.157 sec/batch; 8h:33m:04s remains)
INFO - root - 2017-12-01 08:35:21.844534: step 136940, loss = 0.34, batch loss = 0.25 (52.6 examples/sec; 0.152 sec/batch; 8h:16m:00s remains)
INFO - root - 2017-12-01 08:35:23.427930: step 136950, loss = 0.34, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 8h:24m:10s remains)
INFO - root - 2017-12-01 08:35:24.983504: step 136960, loss = 0.31, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 8h:20m:35s remains)
INFO - root - 2017-12-01 08:35:26.571425: step 136970, loss = 0.30, batch loss = 0.21 (49.3 examples/sec; 0.162 sec/batch; 8h:48m:49s remains)
INFO - root - 2017-12-01 08:35:28.151608: step 136980, loss = 0.43, batch loss = 0.34 (52.3 examples/sec; 0.153 sec/batch; 8h:18m:08s remains)
INFO - root - 2017-12-01 08:35:29.736574: step 136990, loss = 0.33, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 8h:34m:25s remains)
INFO - root - 2017-12-01 08:35:31.294295: step 137000, loss = 0.36, batch loss = 0.27 (50.5 examples/sec; 0.159 sec/batch; 8h:36m:28s remains)
INFO - root - 2017-12-01 08:35:32.931717: step 137010, loss = 0.34, batch loss = 0.25 (51.5 examples/sec; 0.155 sec/batch; 8h:25m:47s remains)
INFO - root - 2017-12-01 08:35:34.498936: step 137020, loss = 0.30, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 8h:25m:37s remains)
INFO - root - 2017-12-01 08:35:36.049394: step 137030, loss = 0.29, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 8h:35m:48s remains)
INFO - root - 2017-12-01 08:35:37.621903: step 137040, loss = 0.29, batch loss = 0.20 (48.4 examples/sec; 0.165 sec/batch; 8h:57m:57s remains)
INFO - root - 2017-12-01 08:35:39.201157: step 137050, loss = 0.37, batch loss = 0.27 (52.5 examples/sec; 0.152 sec/batch; 8h:16m:25s remains)
INFO - root - 2017-12-01 08:35:40.747841: step 137060, loss = 0.28, batch loss = 0.19 (51.8 examples/sec; 0.155 sec/batch; 8h:23m:28s remains)
INFO - root - 2017-12-01 08:35:42.314033: step 137070, loss = 0.32, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 8h:34m:08s remains)
INFO - root - 2017-12-01 08:35:43.897549: step 137080, loss = 0.25, batch loss = 0.16 (48.4 examples/sec; 0.165 sec/batch; 8h:58m:51s remains)
INFO - root - 2017-12-01 08:35:45.458773: step 137090, loss = 0.34, batch loss = 0.25 (53.2 examples/sec; 0.150 sec/batch; 8h:10m:05s remains)
INFO - root - 2017-12-01 08:35:47.010362: step 137100, loss = 0.29, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 8h:19m:25s remains)
INFO - root - 2017-12-01 08:35:48.645791: step 137110, loss = 0.28, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 8h:30m:31s remains)
INFO - root - 2017-12-01 08:35:50.203586: step 137120, loss = 0.29, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 8h:24m:28s remains)
INFO - root - 2017-12-01 08:35:51.761559: step 137130, loss = 0.31, batch loss = 0.22 (53.4 examples/sec; 0.150 sec/batch; 8h:07m:52s remains)
INFO - root - 2017-12-01 08:35:53.336159: step 137140, loss = 0.26, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 8h:18m:54s remains)
INFO - root - 2017-12-01 08:35:54.896223: step 137150, loss = 0.30, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 8h:30m:58s remains)
INFO - root - 2017-12-01 08:35:56.468375: step 137160, loss = 0.23, batch loss = 0.14 (50.6 examples/sec; 0.158 sec/batch; 8h:34m:53s remains)
INFO - root - 2017-12-01 08:35:58.017425: step 137170, loss = 0.27, batch loss = 0.17 (50.8 examples/sec; 0.158 sec/batch; 8h:32m:57s remains)
INFO - root - 2017-12-01 08:35:59.588495: step 137180, loss = 0.33, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 8h:14m:57s remains)
INFO - root - 2017-12-01 08:36:01.150029: step 137190, loss = 0.27, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 8h:25m:00s remains)
INFO - root - 2017-12-01 08:36:02.707793: step 137200, loss = 0.35, batch loss = 0.25 (52.1 examples/sec; 0.154 sec/batch; 8h:19m:45s remains)
INFO - root - 2017-12-01 08:36:04.362033: step 137210, loss = 0.30, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 8h:25m:10s remains)
INFO - root - 2017-12-01 08:36:05.914202: step 137220, loss = 0.37, batch loss = 0.28 (52.1 examples/sec; 0.154 sec/batch; 8h:20m:11s remains)
INFO - root - 2017-12-01 08:36:07.488780: step 137230, loss = 0.29, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 8h:27m:22s remains)
INFO - root - 2017-12-01 08:36:09.042252: step 137240, loss = 0.24, batch loss = 0.15 (52.6 examples/sec; 0.152 sec/batch; 8h:15m:06s remains)
INFO - root - 2017-12-01 08:36:10.598644: step 137250, loss = 0.27, batch loss = 0.18 (50.1 examples/sec; 0.160 sec/batch; 8h:39m:57s remains)
INFO - root - 2017-12-01 08:36:12.182899: step 137260, loss = 0.29, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 8h:33m:44s remains)
INFO - root - 2017-12-01 08:36:13.740461: step 137270, loss = 0.30, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 8h:15m:54s remains)
INFO - root - 2017-12-01 08:36:15.278494: step 137280, loss = 0.33, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 8h:23m:07s remains)
INFO - root - 2017-12-01 08:36:16.846709: step 137290, loss = 0.31, batch loss = 0.22 (48.7 examples/sec; 0.164 sec/batch; 8h:54m:09s remains)
INFO - root - 2017-12-01 08:36:18.405680: step 137300, loss = 0.28, batch loss = 0.19 (52.7 examples/sec; 0.152 sec/batch; 8h:13m:26s remains)
INFO - root - 2017-12-01 08:36:20.064950: step 137310, loss = 0.31, batch loss = 0.22 (48.0 examples/sec; 0.167 sec/batch; 9h:01m:50s remains)
INFO - root - 2017-12-01 08:36:21.647155: step 137320, loss = 0.32, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 8h:14m:36s remains)
INFO - root - 2017-12-01 08:36:23.218305: step 137330, loss = 0.31, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 8h:24m:50s remains)
INFO - root - 2017-12-01 08:36:24.777531: step 137340, loss = 0.23, batch loss = 0.14 (50.9 examples/sec; 0.157 sec/batch; 8h:30m:57s remains)
INFO - root - 2017-12-01 08:36:26.338971: step 137350, loss = 0.22, batch loss = 0.13 (51.5 examples/sec; 0.155 sec/batch; 8h:24m:55s remains)
INFO - root - 2017-12-01 08:36:27.907587: step 137360, loss = 0.51, batch loss = 0.42 (49.5 examples/sec; 0.162 sec/batch; 8h:45m:42s remains)
INFO - root - 2017-12-01 08:36:29.478961: step 137370, loss = 0.29, batch loss = 0.20 (48.5 examples/sec; 0.165 sec/batch; 8h:56m:00s remains)
INFO - root - 2017-12-01 08:36:31.073913: step 137380, loss = 0.27, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 8h:22m:46s remains)
INFO - root - 2017-12-01 08:36:32.640076: step 137390, loss = 0.29, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 8h:31m:56s remains)
INFO - root - 2017-12-01 08:36:34.199490: step 137400, loss = 0.28, batch loss = 0.19 (48.6 examples/sec; 0.164 sec/batch; 8h:54m:48s remains)
INFO - root - 2017-12-01 08:36:35.849833: step 137410, loss = 0.34, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 8h:34m:07s remains)
INFO - root - 2017-12-01 08:36:37.408990: step 137420, loss = 0.33, batch loss = 0.24 (50.2 examples/sec; 0.160 sec/batch; 8h:38m:37s remains)
INFO - root - 2017-12-01 08:36:38.969137: step 137430, loss = 0.40, batch loss = 0.30 (51.6 examples/sec; 0.155 sec/batch; 8h:24m:23s remains)
INFO - root - 2017-12-01 08:36:40.539225: step 137440, loss = 0.23, batch loss = 0.14 (50.7 examples/sec; 0.158 sec/batch; 8h:32m:55s remains)
INFO - root - 2017-12-01 08:36:42.100097: step 137450, loss = 0.29, batch loss = 0.19 (51.1 examples/sec; 0.156 sec/batch; 8h:28m:42s remains)
INFO - root - 2017-12-01 08:36:43.679109: step 137460, loss = 0.33, batch loss = 0.24 (50.5 examples/sec; 0.159 sec/batch; 8h:35m:22s remains)
INFO - root - 2017-12-01 08:36:45.255617: step 137470, loss = 0.30, batch loss = 0.21 (48.8 examples/sec; 0.164 sec/batch; 8h:52m:51s remains)
INFO - root - 2017-12-01 08:36:46.807252: step 137480, loss = 0.27, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 8h:23m:47s remains)
INFO - root - 2017-12-01 08:36:48.375662: step 137490, loss = 0.33, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 8h:14m:31s remains)
INFO - root - 2017-12-01 08:36:49.932357: step 137500, loss = 0.39, batch loss = 0.30 (53.0 examples/sec; 0.151 sec/batch; 8h:11m:00s remains)
INFO - root - 2017-12-01 08:36:51.570464: step 137510, loss = 0.31, batch loss = 0.22 (48.8 examples/sec; 0.164 sec/batch; 8h:53m:00s remains)
INFO - root - 2017-12-01 08:36:53.141666: step 137520, loss = 0.31, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 8h:19m:14s remains)
INFO - root - 2017-12-01 08:36:54.702104: step 137530, loss = 0.37, batch loss = 0.28 (52.7 examples/sec; 0.152 sec/batch; 8h:13m:06s remains)
INFO - root - 2017-12-01 08:36:56.283362: step 137540, loss = 0.28, batch loss = 0.19 (49.0 examples/sec; 0.163 sec/batch; 8h:50m:02s remains)
INFO - root - 2017-12-01 08:36:57.832557: step 137550, loss = 0.28, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 8h:39m:38s remains)
INFO - root - 2017-12-01 08:36:59.395508: step 137560, loss = 0.27, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 8h:32m:15s remains)
INFO - root - 2017-12-01 08:37:00.996604: step 137570, loss = 0.28, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 8h:26m:14s remains)
INFO - root - 2017-12-01 08:37:02.554233: step 137580, loss = 0.28, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 8h:40m:21s remains)
INFO - root - 2017-12-01 08:37:04.109310: step 137590, loss = 0.28, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 8h:32m:23s remains)
INFO - root - 2017-12-01 08:37:05.667138: step 137600, loss = 0.24, batch loss = 0.15 (50.3 examples/sec; 0.159 sec/batch; 8h:36m:41s remains)
INFO - root - 2017-12-01 08:37:07.328565: step 137610, loss = 0.26, batch loss = 0.17 (49.2 examples/sec; 0.162 sec/batch; 8h:47m:45s remains)
INFO - root - 2017-12-01 08:37:08.888254: step 137620, loss = 0.26, batch loss = 0.17 (50.6 examples/sec; 0.158 sec/batch; 8h:33m:07s remains)
INFO - root - 2017-12-01 08:37:10.446957: step 137630, loss = 0.42, batch loss = 0.33 (52.7 examples/sec; 0.152 sec/batch; 8h:12m:34s remains)
INFO - root - 2017-12-01 08:37:12.008326: step 137640, loss = 0.24, batch loss = 0.15 (51.0 examples/sec; 0.157 sec/batch; 8h:29m:26s remains)
INFO - root - 2017-12-01 08:37:13.586150: step 137650, loss = 0.27, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 8h:21m:09s remains)
INFO - root - 2017-12-01 08:37:15.165691: step 137660, loss = 0.27, batch loss = 0.18 (49.5 examples/sec; 0.162 sec/batch; 8h:45m:03s remains)
INFO - root - 2017-12-01 08:37:16.720278: step 137670, loss = 0.31, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 8h:29m:52s remains)
INFO - root - 2017-12-01 08:37:18.264933: step 137680, loss = 0.25, batch loss = 0.16 (51.1 examples/sec; 0.157 sec/batch; 8h:28m:24s remains)
INFO - root - 2017-12-01 08:37:19.833483: step 137690, loss = 0.29, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 8h:25m:51s remains)
INFO - root - 2017-12-01 08:37:21.382490: step 137700, loss = 0.30, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 8h:19m:07s remains)
INFO - root - 2017-12-01 08:37:22.990531: step 137710, loss = 0.28, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 8h:33m:50s remains)
INFO - root - 2017-12-01 08:37:24.541438: step 137720, loss = 0.31, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 8h:19m:53s remains)
INFO - root - 2017-12-01 08:37:26.099616: step 137730, loss = 0.49, batch loss = 0.40 (52.1 examples/sec; 0.154 sec/batch; 8h:18m:45s remains)
INFO - root - 2017-12-01 08:37:27.658465: step 137740, loss = 0.23, batch loss = 0.14 (52.7 examples/sec; 0.152 sec/batch; 8h:12m:48s remains)
INFO - root - 2017-12-01 08:37:29.226925: step 137750, loss = 0.24, batch loss = 0.15 (52.3 examples/sec; 0.153 sec/batch; 8h:16m:29s remains)
INFO - root - 2017-12-01 08:37:30.801728: step 137760, loss = 0.34, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 8h:30m:21s remains)
INFO - root - 2017-12-01 08:37:32.359551: step 137770, loss = 0.33, batch loss = 0.24 (50.5 examples/sec; 0.159 sec/batch; 8h:34m:27s remains)
INFO - root - 2017-12-01 08:37:33.911991: step 137780, loss = 0.29, batch loss = 0.20 (52.7 examples/sec; 0.152 sec/batch; 8h:12m:24s remains)
INFO - root - 2017-12-01 08:37:35.485811: step 137790, loss = 0.31, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 8h:25m:02s remains)
INFO - root - 2017-12-01 08:37:37.053128: step 137800, loss = 0.32, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 8h:27m:28s remains)
INFO - root - 2017-12-01 08:37:38.672398: step 137810, loss = 0.32, batch loss = 0.23 (52.8 examples/sec; 0.152 sec/batch; 8h:12m:02s remains)
INFO - root - 2017-12-01 08:37:40.268342: step 137820, loss = 0.31, batch loss = 0.22 (51.4 examples/sec; 0.155 sec/batch; 8h:24m:32s remains)
INFO - root - 2017-12-01 08:37:41.842215: step 137830, loss = 0.32, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 8h:26m:05s remains)
INFO - root - 2017-12-01 08:37:43.399692: step 137840, loss = 0.28, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 8h:16m:26s remains)
INFO - root - 2017-12-01 08:37:44.969041: step 137850, loss = 0.27, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 8h:23m:03s remains)
INFO - root - 2017-12-01 08:37:46.543308: step 137860, loss = 0.33, batch loss = 0.24 (52.1 examples/sec; 0.154 sec/batch; 8h:18m:29s remains)
INFO - root - 2017-12-01 08:37:48.102471: step 137870, loss = 0.22, batch loss = 0.13 (51.5 examples/sec; 0.155 sec/batch; 8h:24m:09s remains)
INFO - root - 2017-12-01 08:37:49.681224: step 137880, loss = 0.29, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 8h:22m:06s remains)
INFO - root - 2017-12-01 08:37:51.238586: step 137890, loss = 0.29, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 8h:19m:17s remains)
INFO - root - 2017-12-01 08:37:52.780071: step 137900, loss = 0.32, batch loss = 0.23 (53.5 examples/sec; 0.150 sec/batch; 8h:05m:06s remains)
INFO - root - 2017-12-01 08:37:54.389808: step 137910, loss = 0.42, batch loss = 0.33 (52.4 examples/sec; 0.153 sec/batch; 8h:14m:44s remains)
INFO - root - 2017-12-01 08:37:55.965056: step 137920, loss = 0.26, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 8h:23m:51s remains)
INFO - root - 2017-12-01 08:37:57.515676: step 137930, loss = 0.25, batch loss = 0.16 (52.6 examples/sec; 0.152 sec/batch; 8h:13m:27s remains)
INFO - root - 2017-12-01 08:37:59.082449: step 137940, loss = 0.30, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 8h:36m:50s remains)
INFO - root - 2017-12-01 08:38:00.645613: step 137950, loss = 0.32, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 8h:26m:25s remains)
INFO - root - 2017-12-01 08:38:02.210607: step 137960, loss = 0.30, batch loss = 0.21 (51.8 examples/sec; 0.155 sec/batch; 8h:21m:10s remains)
INFO - root - 2017-12-01 08:38:03.793215: step 137970, loss = 0.31, batch loss = 0.22 (50.0 examples/sec; 0.160 sec/batch; 8h:39m:02s remains)
INFO - root - 2017-12-01 08:38:05.356563: step 137980, loss = 0.32, batch loss = 0.23 (49.3 examples/sec; 0.162 sec/batch; 8h:46m:04s remains)
INFO - root - 2017-12-01 08:38:06.907661: step 137990, loss = 0.29, batch loss = 0.20 (52.5 examples/sec; 0.152 sec/batch; 8h:13m:43s remains)
INFO - root - 2017-12-01 08:38:08.475501: step 138000, loss = 0.25, batch loss = 0.16 (50.8 examples/sec; 0.158 sec/batch; 8h:30m:37s remains)
INFO - root - 2017-12-01 08:38:10.076799: step 138010, loss = 0.35, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 8h:19m:17s remains)
INFO - root - 2017-12-01 08:38:11.625886: step 138020, loss = 0.25, batch loss = 0.16 (52.1 examples/sec; 0.154 sec/batch; 8h:17m:43s remains)
INFO - root - 2017-12-01 08:38:13.178181: step 138030, loss = 0.26, batch loss = 0.17 (51.8 examples/sec; 0.155 sec/batch; 8h:20m:59s remains)
INFO - root - 2017-12-01 08:38:14.741480: step 138040, loss = 0.31, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 8h:12m:35s remains)
INFO - root - 2017-12-01 08:38:16.300820: step 138050, loss = 0.37, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 8h:22m:13s remains)
INFO - root - 2017-12-01 08:38:17.846048: step 138060, loss = 0.29, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 8h:19m:02s remains)
INFO - root - 2017-12-01 08:38:19.426322: step 138070, loss = 0.31, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 8h:33m:18s remains)
INFO - root - 2017-12-01 08:38:20.983179: step 138080, loss = 0.30, batch loss = 0.21 (51.8 examples/sec; 0.155 sec/batch; 8h:20m:39s remains)
INFO - root - 2017-12-01 08:38:22.535927: step 138090, loss = 0.29, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 8h:21m:30s remains)
INFO - root - 2017-12-01 08:38:24.110483: step 138100, loss = 0.36, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 8h:28m:38s remains)
INFO - root - 2017-12-01 08:38:25.720802: step 138110, loss = 0.26, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 8h:22m:25s remains)
INFO - root - 2017-12-01 08:38:27.269648: step 138120, loss = 0.29, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 8h:24m:18s remains)
INFO - root - 2017-12-01 08:38:28.816508: step 138130, loss = 0.36, batch loss = 0.27 (52.8 examples/sec; 0.152 sec/batch; 8h:10m:54s remains)
INFO - root - 2017-12-01 08:38:30.402215: step 138140, loss = 0.26, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 8h:16m:52s remains)
INFO - root - 2017-12-01 08:38:31.966519: step 138150, loss = 0.30, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 8h:30m:44s remains)
INFO - root - 2017-12-01 08:38:33.541538: step 138160, loss = 0.28, batch loss = 0.19 (49.4 examples/sec; 0.162 sec/batch; 8h:45m:00s remains)
INFO - root - 2017-12-01 08:38:35.094524: step 138170, loss = 0.36, batch loss = 0.27 (49.7 examples/sec; 0.161 sec/batch; 8h:41m:09s remains)
INFO - root - 2017-12-01 08:38:36.660092: step 138180, loss = 0.40, batch loss = 0.31 (52.1 examples/sec; 0.154 sec/batch; 8h:17m:45s remains)
INFO - root - 2017-12-01 08:38:38.229614: step 138190, loss = 0.32, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 8h:22m:29s remains)
INFO - root - 2017-12-01 08:38:39.805230: step 138200, loss = 0.30, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 8h:23m:30s remains)
INFO - root - 2017-12-01 08:38:41.414508: step 138210, loss = 0.24, batch loss = 0.15 (52.3 examples/sec; 0.153 sec/batch; 8h:15m:25s remains)
INFO - root - 2017-12-01 08:38:42.984622: step 138220, loss = 0.25, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 8h:20m:06s remains)
INFO - root - 2017-12-01 08:38:44.546910: step 138230, loss = 0.29, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 8h:28m:28s remains)
INFO - root - 2017-12-01 08:38:46.099619: step 138240, loss = 0.35, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 8h:19m:48s remains)
INFO - root - 2017-12-01 08:38:47.648000: step 138250, loss = 0.31, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 8h:34m:16s remains)
INFO - root - 2017-12-01 08:38:49.211705: step 138260, loss = 0.23, batch loss = 0.14 (51.6 examples/sec; 0.155 sec/batch; 8h:22m:14s remains)
INFO - root - 2017-12-01 08:38:50.759818: step 138270, loss = 0.40, batch loss = 0.31 (51.3 examples/sec; 0.156 sec/batch; 8h:24m:58s remains)
INFO - root - 2017-12-01 08:38:52.325702: step 138280, loss = 0.31, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 8h:26m:11s remains)
INFO - root - 2017-12-01 08:38:53.883714: step 138290, loss = 0.34, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 8h:31m:31s remains)
INFO - root - 2017-12-01 08:38:55.435148: step 138300, loss = 0.28, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 8h:28m:31s remains)
INFO - root - 2017-12-01 08:38:57.056951: step 138310, loss = 0.29, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 8h:24m:23s remains)
INFO - root - 2017-12-01 08:38:58.615470: step 138320, loss = 0.30, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 8h:26m:02s remains)
INFO - root - 2017-12-01 08:39:00.228587: step 138330, loss = 0.24, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 8h:24m:44s remains)
INFO - root - 2017-12-01 08:39:01.788455: step 138340, loss = 0.24, batch loss = 0.15 (50.9 examples/sec; 0.157 sec/batch; 8h:29m:00s remains)
INFO - root - 2017-12-01 08:39:03.371762: step 138350, loss = 0.26, batch loss = 0.17 (52.5 examples/sec; 0.152 sec/batch; 8h:13m:16s remains)
INFO - root - 2017-12-01 08:39:04.958197: step 138360, loss = 0.29, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 8h:29m:30s remains)
INFO - root - 2017-12-01 08:39:06.523538: step 138370, loss = 0.27, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 8h:23m:26s remains)
INFO - root - 2017-12-01 08:39:08.088840: step 138380, loss = 0.28, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 8h:18m:31s remains)
INFO - root - 2017-12-01 08:39:09.667700: step 138390, loss = 0.27, batch loss = 0.18 (49.2 examples/sec; 0.163 sec/batch; 8h:46m:06s remains)
INFO - root - 2017-12-01 08:39:11.259022: step 138400, loss = 0.30, batch loss = 0.21 (50.0 examples/sec; 0.160 sec/batch; 8h:38m:01s remains)
INFO - root - 2017-12-01 08:39:12.919274: step 138410, loss = 0.32, batch loss = 0.23 (49.5 examples/sec; 0.162 sec/batch; 8h:42m:59s remains)
INFO - root - 2017-12-01 08:39:14.481446: step 138420, loss = 0.37, batch loss = 0.28 (50.2 examples/sec; 0.159 sec/batch; 8h:35m:20s remains)
INFO - root - 2017-12-01 08:39:16.035829: step 138430, loss = 0.40, batch loss = 0.31 (52.0 examples/sec; 0.154 sec/batch; 8h:17m:37s remains)
INFO - root - 2017-12-01 08:39:17.603140: step 138440, loss = 0.31, batch loss = 0.22 (53.0 examples/sec; 0.151 sec/batch; 8h:08m:00s remains)
INFO - root - 2017-12-01 08:39:19.252563: step 138450, loss = 0.29, batch loss = 0.20 (49.3 examples/sec; 0.162 sec/batch; 8h:44m:54s remains)
INFO - root - 2017-12-01 08:39:20.833954: step 138460, loss = 0.32, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 8h:29m:43s remains)
INFO - root - 2017-12-01 08:39:22.422036: step 138470, loss = 0.29, batch loss = 0.20 (49.8 examples/sec; 0.161 sec/batch; 8h:39m:06s remains)
INFO - root - 2017-12-01 08:39:23.977317: step 138480, loss = 0.34, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 8h:19m:56s remains)
INFO - root - 2017-12-01 08:39:25.536051: step 138490, loss = 0.31, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 8h:33m:43s remains)
INFO - root - 2017-12-01 08:39:27.107434: step 138500, loss = 0.39, batch loss = 0.30 (48.7 examples/sec; 0.164 sec/batch; 8h:51m:38s remains)
INFO - root - 2017-12-01 08:39:28.728577: step 138510, loss = 0.26, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 8h:20m:38s remains)
INFO - root - 2017-12-01 08:39:30.309250: step 138520, loss = 0.27, batch loss = 0.18 (49.8 examples/sec; 0.161 sec/batch; 8h:39m:26s remains)
INFO - root - 2017-12-01 08:39:31.876570: step 138530, loss = 0.26, batch loss = 0.17 (53.0 examples/sec; 0.151 sec/batch; 8h:07m:31s remains)
INFO - root - 2017-12-01 08:39:33.458584: step 138540, loss = 0.34, batch loss = 0.25 (50.5 examples/sec; 0.159 sec/batch; 8h:32m:26s remains)
INFO - root - 2017-12-01 08:39:35.004159: step 138550, loss = 0.29, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 8h:18m:14s remains)
INFO - root - 2017-12-01 08:39:36.589054: step 138560, loss = 0.35, batch loss = 0.26 (48.5 examples/sec; 0.165 sec/batch; 8h:53m:00s remains)
INFO - root - 2017-12-01 08:39:38.151835: step 138570, loss = 0.29, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 8h:23m:02s remains)
INFO - root - 2017-12-01 08:39:39.719285: step 138580, loss = 0.34, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 8h:12m:16s remains)
INFO - root - 2017-12-01 08:39:41.268442: step 138590, loss = 0.31, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 8h:35m:11s remains)
INFO - root - 2017-12-01 08:39:42.832637: step 138600, loss = 0.27, batch loss = 0.18 (50.5 examples/sec; 0.159 sec/batch; 8h:32m:24s remains)
INFO - root - 2017-12-01 08:39:44.451358: step 138610, loss = 0.28, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 8h:19m:46s remains)
INFO - root - 2017-12-01 08:39:46.042882: step 138620, loss = 0.32, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 8h:20m:12s remains)
INFO - root - 2017-12-01 08:39:47.602821: step 138630, loss = 0.24, batch loss = 0.15 (50.5 examples/sec; 0.158 sec/batch; 8h:31m:42s remains)
INFO - root - 2017-12-01 08:39:49.157371: step 138640, loss = 0.40, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 8h:26m:33s remains)
INFO - root - 2017-12-01 08:39:50.729642: step 138650, loss = 0.28, batch loss = 0.19 (51.8 examples/sec; 0.155 sec/batch; 8h:19m:26s remains)
INFO - root - 2017-12-01 08:39:52.281032: step 138660, loss = 0.31, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 8h:18m:01s remains)
INFO - root - 2017-12-01 08:39:53.859648: step 138670, loss = 0.24, batch loss = 0.15 (50.8 examples/sec; 0.157 sec/batch; 8h:28m:25s remains)
INFO - root - 2017-12-01 08:39:55.428940: step 138680, loss = 0.45, batch loss = 0.36 (50.4 examples/sec; 0.159 sec/batch; 8h:33m:07s remains)
INFO - root - 2017-12-01 08:39:56.998537: step 138690, loss = 0.25, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 8h:32m:39s remains)
INFO - root - 2017-12-01 08:39:58.549172: step 138700, loss = 0.25, batch loss = 0.16 (50.8 examples/sec; 0.157 sec/batch; 8h:28m:18s remains)
INFO - root - 2017-12-01 08:40:00.185916: step 138710, loss = 0.33, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 8h:23m:31s remains)
INFO - root - 2017-12-01 08:40:01.771686: step 138720, loss = 0.48, batch loss = 0.39 (48.6 examples/sec; 0.165 sec/batch; 8h:51m:30s remains)
INFO - root - 2017-12-01 08:40:03.328787: step 138730, loss = 0.30, batch loss = 0.21 (53.0 examples/sec; 0.151 sec/batch; 8h:07m:02s remains)
INFO - root - 2017-12-01 08:40:04.897213: step 138740, loss = 0.34, batch loss = 0.25 (52.8 examples/sec; 0.151 sec/batch; 8h:08m:55s remains)
INFO - root - 2017-12-01 08:40:06.455738: step 138750, loss = 0.27, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 8h:14m:23s remains)
INFO - root - 2017-12-01 08:40:07.992969: step 138760, loss = 0.27, batch loss = 0.18 (52.4 examples/sec; 0.153 sec/batch; 8h:13m:07s remains)
INFO - root - 2017-12-01 08:40:09.552903: step 138770, loss = 0.41, batch loss = 0.32 (51.2 examples/sec; 0.156 sec/batch; 8h:24m:45s remains)
INFO - root - 2017-12-01 08:40:11.123864: step 138780, loss = 0.33, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 8h:17m:09s remains)
INFO - root - 2017-12-01 08:40:12.688050: step 138790, loss = 0.24, batch loss = 0.15 (52.9 examples/sec; 0.151 sec/batch; 8h:08m:01s remains)
INFO - root - 2017-12-01 08:40:14.278623: step 138800, loss = 0.31, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 8h:26m:45s remains)
INFO - root - 2017-12-01 08:40:15.917792: step 138810, loss = 0.31, batch loss = 0.22 (52.5 examples/sec; 0.152 sec/batch; 8h:11m:38s remains)
INFO - root - 2017-12-01 08:40:17.497754: step 138820, loss = 0.29, batch loss = 0.20 (49.7 examples/sec; 0.161 sec/batch; 8h:39m:43s remains)
INFO - root - 2017-12-01 08:40:19.043607: step 138830, loss = 0.36, batch loss = 0.27 (51.2 examples/sec; 0.156 sec/batch; 8h:23m:57s remains)
INFO - root - 2017-12-01 08:40:20.612642: step 138840, loss = 0.33, batch loss = 0.24 (50.8 examples/sec; 0.157 sec/batch; 8h:28m:14s remains)
INFO - root - 2017-12-01 08:40:22.193965: step 138850, loss = 0.33, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 8h:17m:19s remains)
INFO - root - 2017-12-01 08:40:23.774146: step 138860, loss = 0.31, batch loss = 0.22 (53.3 examples/sec; 0.150 sec/batch; 8h:04m:07s remains)
INFO - root - 2017-12-01 08:40:25.339911: step 138870, loss = 0.25, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 8h:28m:51s remains)
INFO - root - 2017-12-01 08:40:26.907424: step 138880, loss = 0.29, batch loss = 0.20 (49.4 examples/sec; 0.162 sec/batch; 8h:42m:20s remains)
INFO - root - 2017-12-01 08:40:28.468561: step 138890, loss = 0.37, batch loss = 0.28 (49.4 examples/sec; 0.162 sec/batch; 8h:42m:15s remains)
INFO - root - 2017-12-01 08:40:30.034217: step 138900, loss = 0.29, batch loss = 0.20 (53.0 examples/sec; 0.151 sec/batch; 8h:06m:58s remains)
INFO - root - 2017-12-01 08:40:31.654032: step 138910, loss = 0.26, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 8h:23m:12s remains)
INFO - root - 2017-12-01 08:40:33.212687: step 138920, loss = 0.31, batch loss = 0.22 (48.5 examples/sec; 0.165 sec/batch; 8h:51m:53s remains)
INFO - root - 2017-12-01 08:40:34.777357: step 138930, loss = 0.32, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 8h:16m:06s remains)
INFO - root - 2017-12-01 08:40:36.333271: step 138940, loss = 0.26, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 8h:14m:12s remains)
INFO - root - 2017-12-01 08:40:37.906766: step 138950, loss = 0.26, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 8h:22m:02s remains)
INFO - root - 2017-12-01 08:40:39.475776: step 138960, loss = 0.43, batch loss = 0.35 (51.2 examples/sec; 0.156 sec/batch; 8h:24m:00s remains)
INFO - root - 2017-12-01 08:40:41.064581: step 138970, loss = 0.25, batch loss = 0.17 (50.5 examples/sec; 0.159 sec/batch; 8h:31m:15s remains)
INFO - root - 2017-12-01 08:40:42.648392: step 138980, loss = 0.32, batch loss = 0.23 (52.0 examples/sec; 0.154 sec/batch; 8h:15m:49s remains)
INFO - root - 2017-12-01 08:40:44.220858: step 138990, loss = 0.37, batch loss = 0.28 (50.0 examples/sec; 0.160 sec/batch; 8h:35m:36s remains)
INFO - root - 2017-12-01 08:40:45.769552: step 139000, loss = 0.27, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 8h:25m:01s remains)
INFO - root - 2017-12-01 08:40:47.401224: step 139010, loss = 0.25, batch loss = 0.16 (49.8 examples/sec; 0.161 sec/batch; 8h:37m:43s remains)
INFO - root - 2017-12-01 08:40:48.961902: step 139020, loss = 0.26, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 8h:20m:36s remains)
INFO - root - 2017-12-01 08:40:50.527440: step 139030, loss = 0.30, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 8h:16m:02s remains)
INFO - root - 2017-12-01 08:40:52.071104: step 139040, loss = 0.28, batch loss = 0.19 (53.2 examples/sec; 0.150 sec/batch; 8h:05m:13s remains)
INFO - root - 2017-12-01 08:40:53.649511: step 139050, loss = 0.24, batch loss = 0.15 (52.1 examples/sec; 0.154 sec/batch; 8h:15m:14s remains)
INFO - root - 2017-12-01 08:40:55.225943: step 139060, loss = 0.35, batch loss = 0.26 (52.1 examples/sec; 0.154 sec/batch; 8h:15m:15s remains)
INFO - root - 2017-12-01 08:40:56.779996: step 139070, loss = 0.37, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 8h:22m:56s remains)
INFO - root - 2017-12-01 08:40:58.336304: step 139080, loss = 0.30, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 8h:25m:04s remains)
INFO - root - 2017-12-01 08:40:59.907205: step 139090, loss = 0.31, batch loss = 0.22 (49.4 examples/sec; 0.162 sec/batch; 8h:41m:46s remains)
INFO - root - 2017-12-01 08:41:01.470303: step 139100, loss = 0.35, batch loss = 0.26 (53.1 examples/sec; 0.151 sec/batch; 8h:05m:41s remains)
INFO - root - 2017-12-01 08:41:03.118248: step 139110, loss = 0.32, batch loss = 0.23 (50.0 examples/sec; 0.160 sec/batch; 8h:35m:59s remains)
INFO - root - 2017-12-01 08:41:04.684597: step 139120, loss = 0.33, batch loss = 0.24 (50.8 examples/sec; 0.157 sec/batch; 8h:27m:30s remains)
INFO - root - 2017-12-01 08:41:06.264942: step 139130, loss = 0.27, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 8h:12m:46s remains)
INFO - root - 2017-12-01 08:41:07.823311: step 139140, loss = 0.36, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 8h:26m:30s remains)
INFO - root - 2017-12-01 08:41:09.374485: step 139150, loss = 0.38, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 8h:23m:01s remains)
INFO - root - 2017-12-01 08:41:10.936427: step 139160, loss = 0.32, batch loss = 0.23 (50.8 examples/sec; 0.157 sec/batch; 8h:27m:01s remains)
INFO - root - 2017-12-01 08:41:12.510051: step 139170, loss = 0.25, batch loss = 0.16 (51.1 examples/sec; 0.156 sec/batch; 8h:24m:11s remains)
INFO - root - 2017-12-01 08:41:14.072890: step 139180, loss = 0.27, batch loss = 0.19 (52.1 examples/sec; 0.154 sec/batch; 8h:14m:53s remains)
INFO - root - 2017-12-01 08:41:15.653948: step 139190, loss = 0.22, batch loss = 0.13 (49.4 examples/sec; 0.162 sec/batch; 8h:42m:16s remains)
INFO - root - 2017-12-01 08:41:17.218492: step 139200, loss = 0.30, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 8h:29m:40s remains)
INFO - root - 2017-12-01 08:41:18.854306: step 139210, loss = 0.27, batch loss = 0.18 (52.4 examples/sec; 0.153 sec/batch; 8h:12m:16s remains)
INFO - root - 2017-12-01 08:41:20.429869: step 139220, loss = 0.32, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 8h:26m:09s remains)
INFO - root - 2017-12-01 08:41:21.992753: step 139230, loss = 0.28, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 8h:26m:42s remains)
INFO - root - 2017-12-01 08:41:23.541802: step 139240, loss = 0.27, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 8h:26m:10s remains)
INFO - root - 2017-12-01 08:41:25.111935: step 139250, loss = 0.25, batch loss = 0.16 (52.2 examples/sec; 0.153 sec/batch; 8h:13m:21s remains)
INFO - root - 2017-12-01 08:41:26.668801: step 139260, loss = 0.44, batch loss = 0.35 (52.4 examples/sec; 0.153 sec/batch; 8h:11m:58s remains)
INFO - root - 2017-12-01 08:41:28.230183: step 139270, loss = 0.29, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 8h:27m:45s remains)
INFO - root - 2017-12-01 08:41:29.780372: step 139280, loss = 0.49, batch loss = 0.40 (49.8 examples/sec; 0.161 sec/batch; 8h:37m:04s remains)
INFO - root - 2017-12-01 08:41:31.353489: step 139290, loss = 0.23, batch loss = 0.14 (50.9 examples/sec; 0.157 sec/batch; 8h:25m:49s remains)
INFO - root - 2017-12-01 08:41:32.926605: step 139300, loss = 0.26, batch loss = 0.17 (47.9 examples/sec; 0.167 sec/batch; 8h:58m:09s remains)
INFO - root - 2017-12-01 08:41:34.537922: step 139310, loss = 0.37, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 8h:19m:13s remains)
INFO - root - 2017-12-01 08:41:36.096257: step 139320, loss = 0.33, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 8h:31m:51s remains)
INFO - root - 2017-12-01 08:41:37.664628: step 139330, loss = 0.54, batch loss = 0.45 (51.3 examples/sec; 0.156 sec/batch; 8h:22m:08s remains)
INFO - root - 2017-12-01 08:41:39.242280: step 139340, loss = 0.33, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 8h:28m:07s remains)
INFO - root - 2017-12-01 08:41:40.798386: step 139350, loss = 0.29, batch loss = 0.20 (51.8 examples/sec; 0.155 sec/batch; 8h:17m:37s remains)
INFO - root - 2017-12-01 08:41:42.382910: step 139360, loss = 0.26, batch loss = 0.17 (50.0 examples/sec; 0.160 sec/batch; 8h:34m:59s remains)
INFO - root - 2017-12-01 08:41:43.947887: step 139370, loss = 0.30, batch loss = 0.21 (52.1 examples/sec; 0.153 sec/batch; 8h:13m:57s remains)
INFO - root - 2017-12-01 08:41:45.501799: step 139380, loss = 0.27, batch loss = 0.19 (51.8 examples/sec; 0.155 sec/batch; 8h:17m:18s remains)
INFO - root - 2017-12-01 08:41:47.085031: step 139390, loss = 0.44, batch loss = 0.35 (51.8 examples/sec; 0.154 sec/batch; 8h:16m:59s remains)
INFO - root - 2017-12-01 08:41:48.661169: step 139400, loss = 0.30, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 8h:29m:38s remains)
INFO - root - 2017-12-01 08:41:50.265250: step 139410, loss = 0.33, batch loss = 0.24 (49.1 examples/sec; 0.163 sec/batch; 8h:44m:02s remains)
INFO - root - 2017-12-01 08:41:51.820517: step 139420, loss = 0.34, batch loss = 0.25 (52.7 examples/sec; 0.152 sec/batch; 8h:08m:20s remains)
INFO - root - 2017-12-01 08:41:53.374506: step 139430, loss = 0.34, batch loss = 0.25 (51.9 examples/sec; 0.154 sec/batch; 8h:15m:54s remains)
INFO - root - 2017-12-01 08:41:54.951045: step 139440, loss = 0.29, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 8h:35m:40s remains)
INFO - root - 2017-12-01 08:41:56.501113: step 139450, loss = 0.30, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 8h:11m:32s remains)
INFO - root - 2017-12-01 08:41:58.056004: step 139460, loss = 0.29, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 8h:16m:33s remains)
INFO - root - 2017-12-01 08:41:59.616019: step 139470, loss = 0.29, batch loss = 0.20 (53.5 examples/sec; 0.150 sec/batch; 8h:01m:21s remains)
INFO - root - 2017-12-01 08:42:01.211205: step 139480, loss = 0.27, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 8h:10m:34s remains)
INFO - root - 2017-12-01 08:42:02.768104: step 139490, loss = 0.31, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 8h:29m:19s remains)
INFO - root - 2017-12-01 08:42:04.323310: step 139500, loss = 0.43, batch loss = 0.34 (51.1 examples/sec; 0.157 sec/batch; 8h:23m:57s remains)
INFO - root - 2017-12-01 08:42:06.016575: step 139510, loss = 0.34, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 8h:27m:57s remains)
INFO - root - 2017-12-01 08:42:07.575447: step 139520, loss = 0.42, batch loss = 0.34 (51.2 examples/sec; 0.156 sec/batch; 8h:23m:02s remains)
INFO - root - 2017-12-01 08:42:09.140239: step 139530, loss = 0.36, batch loss = 0.27 (50.6 examples/sec; 0.158 sec/batch; 8h:28m:14s remains)
INFO - root - 2017-12-01 08:42:10.748450: step 139540, loss = 0.36, batch loss = 0.28 (49.6 examples/sec; 0.161 sec/batch; 8h:38m:38s remains)
INFO - root - 2017-12-01 08:42:12.343718: step 139550, loss = 0.28, batch loss = 0.19 (47.8 examples/sec; 0.167 sec/batch; 8h:58m:21s remains)
INFO - root - 2017-12-01 08:42:13.989288: step 139560, loss = 0.29, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 8h:26m:53s remains)
INFO - root - 2017-12-01 08:42:15.541161: step 139570, loss = 0.26, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 8h:20m:54s remains)
INFO - root - 2017-12-01 08:42:17.099615: step 139580, loss = 0.27, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 8h:21m:01s remains)
INFO - root - 2017-12-01 08:42:18.662301: step 139590, loss = 0.27, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 8h:14m:20s remains)
INFO - root - 2017-12-01 08:42:20.235265: step 139600, loss = 0.29, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 8h:32m:16s remains)
INFO - root - 2017-12-01 08:42:21.884811: step 139610, loss = 0.43, batch loss = 0.34 (51.5 examples/sec; 0.155 sec/batch; 8h:19m:07s remains)
INFO - root - 2017-12-01 08:42:23.458130: step 139620, loss = 0.28, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 8h:23m:00s remains)
INFO - root - 2017-12-01 08:42:25.015984: step 139630, loss = 0.33, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 8h:30m:11s remains)
INFO - root - 2017-12-01 08:42:26.567363: step 139640, loss = 0.30, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 8h:13m:56s remains)
INFO - root - 2017-12-01 08:42:28.154405: step 139650, loss = 0.30, batch loss = 0.21 (48.9 examples/sec; 0.164 sec/batch; 8h:45m:46s remains)
INFO - root - 2017-12-01 08:42:29.802675: step 139660, loss = 0.25, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 8h:21m:41s remains)
INFO - root - 2017-12-01 08:42:31.356466: step 139670, loss = 0.34, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 8h:27m:11s remains)
INFO - root - 2017-12-01 08:42:32.913260: step 139680, loss = 0.33, batch loss = 0.25 (52.0 examples/sec; 0.154 sec/batch; 8h:14m:36s remains)
INFO - root - 2017-12-01 08:42:34.488857: step 139690, loss = 0.33, batch loss = 0.24 (50.5 examples/sec; 0.159 sec/batch; 8h:29m:22s remains)
INFO - root - 2017-12-01 08:42:36.053649: step 139700, loss = 0.31, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 8h:29m:49s remains)
INFO - root - 2017-12-01 08:42:37.713501: step 139710, loss = 0.36, batch loss = 0.27 (51.7 examples/sec; 0.155 sec/batch; 8h:17m:20s remains)
INFO - root - 2017-12-01 08:42:39.261238: step 139720, loss = 0.25, batch loss = 0.16 (50.8 examples/sec; 0.158 sec/batch; 8h:26m:26s remains)
INFO - root - 2017-12-01 08:42:40.832964: step 139730, loss = 0.25, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 8h:20m:35s remains)
INFO - root - 2017-12-01 08:42:42.407359: step 139740, loss = 0.27, batch loss = 0.18 (47.9 examples/sec; 0.167 sec/batch; 8h:56m:41s remains)
INFO - root - 2017-12-01 08:42:43.978539: step 139750, loss = 0.46, batch loss = 0.37 (52.6 examples/sec; 0.152 sec/batch; 8h:08m:24s remains)
INFO - root - 2017-12-01 08:42:45.535544: step 139760, loss = 0.31, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 8h:20m:36s remains)
INFO - root - 2017-12-01 08:42:47.109327: step 139770, loss = 0.34, batch loss = 0.25 (50.8 examples/sec; 0.157 sec/batch; 8h:25m:34s remains)
INFO - root - 2017-12-01 08:42:48.668312: step 139780, loss = 0.34, batch loss = 0.25 (51.6 examples/sec; 0.155 sec/batch; 8h:17m:43s remains)
INFO - root - 2017-12-01 08:42:50.226800: step 139790, loss = 0.34, batch loss = 0.25 (49.6 examples/sec; 0.161 sec/batch; 8h:38m:16s remains)
INFO - root - 2017-12-01 08:42:51.805476: step 139800, loss = 0.32, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 8h:24m:56s remains)
INFO - root - 2017-12-01 08:42:53.428269: step 139810, loss = 0.25, batch loss = 0.16 (50.5 examples/sec; 0.158 sec/batch; 8h:28m:37s remains)
INFO - root - 2017-12-01 08:42:54.998872: step 139820, loss = 0.33, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 8h:17m:34s remains)
INFO - root - 2017-12-01 08:42:56.581721: step 139830, loss = 0.36, batch loss = 0.27 (51.8 examples/sec; 0.154 sec/batch; 8h:15m:58s remains)
INFO - root - 2017-12-01 08:42:58.161586: step 139840, loss = 0.24, batch loss = 0.15 (51.0 examples/sec; 0.157 sec/batch; 8h:23m:17s remains)
INFO - root - 2017-12-01 08:42:59.739598: step 139850, loss = 0.27, batch loss = 0.18 (47.5 examples/sec; 0.168 sec/batch; 9h:00m:34s remains)
INFO - root - 2017-12-01 08:43:01.288267: step 139860, loss = 0.38, batch loss = 0.29 (51.1 examples/sec; 0.156 sec/batch; 8h:22m:27s remains)
INFO - root - 2017-12-01 08:43:02.871539: step 139870, loss = 0.24, batch loss = 0.15 (51.8 examples/sec; 0.155 sec/batch; 8h:16m:01s remains)
INFO - root - 2017-12-01 08:43:04.445830: step 139880, loss = 0.33, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 8h:20m:29s remains)
INFO - root - 2017-12-01 08:43:06.001680: step 139890, loss = 0.43, batch loss = 0.34 (50.9 examples/sec; 0.157 sec/batch; 8h:24m:32s remains)
INFO - root - 2017-12-01 08:43:07.558342: step 139900, loss = 0.29, batch loss = 0.20 (48.2 examples/sec; 0.166 sec/batch; 8h:52m:45s remains)
INFO - root - 2017-12-01 08:43:09.175477: step 139910, loss = 0.28, batch loss = 0.19 (50.8 examples/sec; 0.158 sec/batch; 8h:25m:53s remains)
INFO - root - 2017-12-01 08:43:10.747493: step 139920, loss = 0.33, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 8h:14m:45s remains)
INFO - root - 2017-12-01 08:43:12.293400: step 139930, loss = 0.26, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 8h:23m:49s remains)
INFO - root - 2017-12-01 08:43:13.856226: step 139940, loss = 0.36, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 8h:18m:42s remains)
INFO - root - 2017-12-01 08:43:15.416438: step 139950, loss = 0.28, batch loss = 0.19 (53.2 examples/sec; 0.150 sec/batch; 8h:02m:11s remains)
INFO - root - 2017-12-01 08:43:16.986381: step 139960, loss = 0.34, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 8h:15m:22s remains)
INFO - root - 2017-12-01 08:43:18.554055: step 139970, loss = 0.31, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 8h:23m:26s remains)
INFO - root - 2017-12-01 08:43:20.131907: step 139980, loss = 0.38, batch loss = 0.29 (50.8 examples/sec; 0.157 sec/batch; 8h:24m:57s remains)
INFO - root - 2017-12-01 08:43:21.692253: step 139990, loss = 0.41, batch loss = 0.32 (50.4 examples/sec; 0.159 sec/batch; 8h:28m:55s remains)
INFO - root - 2017-12-01 08:43:23.332358: step 140000, loss = 0.36, batch loss = 0.27 (52.1 examples/sec; 0.154 sec/batch; 8h:12m:41s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-140000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-140000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-01 08:43:25.243742: step 140010, loss = 0.28, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 8h:24m:36s remains)
INFO - root - 2017-12-01 08:43:26.783212: step 140020, loss = 0.30, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 8h:13m:36s remains)
INFO - root - 2017-12-01 08:43:28.353417: step 140030, loss = 0.27, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 8h:30m:57s remains)
INFO - root - 2017-12-01 08:43:29.947067: step 140040, loss = 0.42, batch loss = 0.34 (49.9 examples/sec; 0.160 sec/batch; 8h:34m:14s remains)
INFO - root - 2017-12-01 08:43:31.505469: step 140050, loss = 0.33, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 8h:27m:09s remains)
INFO - root - 2017-12-01 08:43:33.064187: step 140060, loss = 0.20, batch loss = 0.11 (49.1 examples/sec; 0.163 sec/batch; 8h:43m:00s remains)
INFO - root - 2017-12-01 08:43:34.641710: step 140070, loss = 0.24, batch loss = 0.15 (47.1 examples/sec; 0.170 sec/batch; 9h:04m:58s remains)
INFO - root - 2017-12-01 08:43:36.206502: step 140080, loss = 0.24, batch loss = 0.15 (52.3 examples/sec; 0.153 sec/batch; 8h:10m:21s remains)
INFO - root - 2017-12-01 08:43:37.771691: step 140090, loss = 0.23, batch loss = 0.14 (51.2 examples/sec; 0.156 sec/batch; 8h:20m:44s remains)
INFO - root - 2017-12-01 08:43:39.325003: step 140100, loss = 0.25, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 8h:24m:09s remains)
INFO - root - 2017-12-01 08:43:40.969131: step 140110, loss = 0.30, batch loss = 0.21 (53.0 examples/sec; 0.151 sec/batch; 8h:04m:03s remains)
INFO - root - 2017-12-01 08:43:42.559883: step 140120, loss = 0.27, batch loss = 0.19 (49.2 examples/sec; 0.163 sec/batch; 8h:41m:19s remains)
INFO - root - 2017-12-01 08:43:44.114627: step 140130, loss = 0.33, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 8h:23m:57s remains)
INFO - root - 2017-12-01 08:43:45.683769: step 140140, loss = 0.25, batch loss = 0.16 (52.7 examples/sec; 0.152 sec/batch; 8h:06m:18s remains)
INFO - root - 2017-12-01 08:43:47.245745: step 140150, loss = 0.30, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 8h:24m:51s remains)
INFO - root - 2017-12-01 08:43:48.805511: step 140160, loss = 0.29, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 8h:20m:21s remains)
INFO - root - 2017-12-01 08:43:50.388743: step 140170, loss = 0.36, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 8h:23m:40s remains)
INFO - root - 2017-12-01 08:43:51.956594: step 140180, loss = 0.25, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 8h:13m:35s remains)
INFO - root - 2017-12-01 08:43:53.521466: step 140190, loss = 0.24, batch loss = 0.15 (52.7 examples/sec; 0.152 sec/batch; 8h:06m:18s remains)
INFO - root - 2017-12-01 08:43:55.110347: step 140200, loss = 0.29, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 8h:28m:24s remains)
INFO - root - 2017-12-01 08:43:56.717013: step 140210, loss = 0.58, batch loss = 0.49 (51.8 examples/sec; 0.154 sec/batch; 8h:14m:38s remains)
INFO - root - 2017-12-01 08:43:58.277653: step 140220, loss = 0.29, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 8h:14m:09s remains)
INFO - root - 2017-12-01 08:43:59.852068: step 140230, loss = 0.29, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 8h:18m:19s remains)
INFO - root - 2017-12-01 08:44:01.416375: step 140240, loss = 0.26, batch loss = 0.17 (51.8 examples/sec; 0.154 sec/batch; 8h:14m:35s remains)
INFO - root - 2017-12-01 08:44:02.963576: step 140250, loss = 0.39, batch loss = 0.30 (49.9 examples/sec; 0.160 sec/batch; 8h:33m:25s remains)
INFO - root - 2017-12-01 08:44:04.540604: step 140260, loss = 0.30, batch loss = 0.21 (52.6 examples/sec; 0.152 sec/batch; 8h:07m:08s remains)
INFO - root - 2017-12-01 08:44:06.110868: step 140270, loss = 0.24, batch loss = 0.15 (52.1 examples/sec; 0.153 sec/batch; 8h:11m:38s remains)
INFO - root - 2017-12-01 08:44:07.682823: step 140280, loss = 0.22, batch loss = 0.13 (51.1 examples/sec; 0.156 sec/batch; 8h:21m:16s remains)
INFO - root - 2017-12-01 08:44:09.255194: step 140290, loss = 0.28, batch loss = 0.19 (48.8 examples/sec; 0.164 sec/batch; 8h:45m:25s remains)
INFO - root - 2017-12-01 08:44:10.805790: step 140300, loss = 0.27, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 8h:18m:28s remains)
INFO - root - 2017-12-01 08:44:12.414856: step 140310, loss = 0.47, batch loss = 0.39 (53.4 examples/sec; 0.150 sec/batch; 8h:00m:15s remains)
INFO - root - 2017-12-01 08:44:14.005438: step 140320, loss = 0.28, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 8h:13m:43s remains)
INFO - root - 2017-12-01 08:44:15.552484: step 140330, loss = 0.30, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 8h:23m:43s remains)
INFO - root - 2017-12-01 08:44:17.120780: step 140340, loss = 0.27, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 8h:19m:00s remains)
INFO - root - 2017-12-01 08:44:18.698359: step 140350, loss = 0.34, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 8h:14m:16s remains)
INFO - root - 2017-12-01 08:44:20.257654: step 140360, loss = 0.25, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 8h:28m:09s remains)
INFO - root - 2017-12-01 08:44:21.822496: step 140370, loss = 0.31, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 8h:21m:27s remains)
INFO - root - 2017-12-01 08:44:23.404009: step 140380, loss = 0.26, batch loss = 0.17 (50.7 examples/sec; 0.158 sec/batch; 8h:25m:12s remains)
INFO - root - 2017-12-01 08:44:24.962963: step 140390, loss = 0.23, batch loss = 0.14 (51.0 examples/sec; 0.157 sec/batch; 8h:22m:28s remains)
INFO - root - 2017-12-01 08:44:26.529900: step 140400, loss = 0.33, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 8h:27m:05s remains)
INFO - root - 2017-12-01 08:44:28.157783: step 140410, loss = 0.34, batch loss = 0.25 (47.8 examples/sec; 0.167 sec/batch; 8h:55m:25s remains)
INFO - root - 2017-12-01 08:44:29.719870: step 140420, loss = 0.35, batch loss = 0.26 (52.1 examples/sec; 0.153 sec/batch; 8h:11m:05s remains)
INFO - root - 2017-12-01 08:44:31.279762: step 140430, loss = 0.30, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 8h:24m:24s remains)
INFO - root - 2017-12-01 08:44:32.855395: step 140440, loss = 0.25, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 8h:19m:16s remains)
INFO - root - 2017-12-01 08:44:34.416596: step 140450, loss = 0.26, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 8h:16m:22s remains)
INFO - root - 2017-12-01 08:44:35.961355: step 140460, loss = 0.33, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 8h:10m:27s remains)
INFO - root - 2017-12-01 08:44:37.522855: step 140470, loss = 0.33, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 8h:19m:16s remains)
INFO - root - 2017-12-01 08:44:39.091183: step 140480, loss = 0.33, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 8h:28m:05s remains)
INFO - root - 2017-12-01 08:44:40.657501: step 140490, loss = 0.27, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 8h:18m:12s remains)
INFO - root - 2017-12-01 08:44:42.216460: step 140500, loss = 0.38, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 8h:19m:05s remains)
INFO - root - 2017-12-01 08:44:43.832628: step 140510, loss = 0.22, batch loss = 0.13 (53.1 examples/sec; 0.151 sec/batch; 8h:01m:42s remains)
INFO - root - 2017-12-01 08:44:45.387795: step 140520, loss = 0.27, batch loss = 0.18 (52.1 examples/sec; 0.154 sec/batch; 8h:11m:29s remains)
INFO - root - 2017-12-01 08:44:46.952619: step 140530, loss = 0.29, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 8h:21m:24s remains)
INFO - root - 2017-12-01 08:44:48.512200: step 140540, loss = 0.26, batch loss = 0.17 (49.9 examples/sec; 0.160 sec/batch; 8h:32m:27s remains)
INFO - root - 2017-12-01 08:44:50.074342: step 140550, loss = 0.36, batch loss = 0.27 (49.5 examples/sec; 0.162 sec/batch; 8h:36m:54s remains)
INFO - root - 2017-12-01 08:44:51.651978: step 140560, loss = 0.31, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 8h:18m:07s remains)
INFO - root - 2017-12-01 08:44:53.213306: step 140570, loss = 0.30, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 8h:09m:12s remains)
INFO - root - 2017-12-01 08:44:54.776844: step 140580, loss = 0.33, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 8h:18m:08s remains)
INFO - root - 2017-12-01 08:44:56.359865: step 140590, loss = 0.44, batch loss = 0.35 (50.5 examples/sec; 0.159 sec/batch; 8h:27m:01s remains)
INFO - root - 2017-12-01 08:44:57.921596: step 140600, loss = 0.33, batch loss = 0.24 (53.2 examples/sec; 0.150 sec/batch; 8h:00m:54s remains)
INFO - root - 2017-12-01 08:44:59.558161: step 140610, loss = 0.23, batch loss = 0.14 (50.6 examples/sec; 0.158 sec/batch; 8h:25m:26s remains)
INFO - root - 2017-12-01 08:45:01.123857: step 140620, loss = 0.33, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 8h:28m:26s remains)
INFO - root - 2017-12-01 08:45:02.706539: step 140630, loss = 0.27, batch loss = 0.18 (49.8 examples/sec; 0.161 sec/batch; 8h:33m:38s remains)
INFO - root - 2017-12-01 08:45:04.258658: step 140640, loss = 0.40, batch loss = 0.31 (52.2 examples/sec; 0.153 sec/batch; 8h:09m:38s remains)
INFO - root - 2017-12-01 08:45:05.822644: step 140650, loss = 0.26, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 8h:12m:22s remains)
INFO - root - 2017-12-01 08:45:07.395799: step 140660, loss = 0.30, batch loss = 0.21 (49.9 examples/sec; 0.160 sec/batch; 8h:32m:15s remains)
INFO - root - 2017-12-01 08:45:08.959804: step 140670, loss = 0.47, batch loss = 0.39 (49.8 examples/sec; 0.160 sec/batch; 8h:33m:07s remains)
INFO - root - 2017-12-01 08:45:10.523726: step 140680, loss = 0.29, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 8h:18m:18s remains)
INFO - root - 2017-12-01 08:45:12.141403: step 140690, loss = 0.29, batch loss = 0.20 (47.7 examples/sec; 0.168 sec/batch; 8h:56m:01s remains)
INFO - root - 2017-12-01 08:45:13.689708: step 140700, loss = 0.28, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 8h:11m:26s remains)
INFO - root - 2017-12-01 08:45:15.329512: step 140710, loss = 0.33, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 8h:20m:39s remains)
INFO - root - 2017-12-01 08:45:16.894817: step 140720, loss = 0.37, batch loss = 0.29 (50.2 examples/sec; 0.159 sec/batch; 8h:29m:27s remains)
INFO - root - 2017-12-01 08:45:18.457373: step 140730, loss = 0.24, batch loss = 0.15 (52.0 examples/sec; 0.154 sec/batch; 8h:11m:34s remains)
INFO - root - 2017-12-01 08:45:20.028385: step 140740, loss = 0.32, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 8h:05m:27s remains)
INFO - root - 2017-12-01 08:45:21.619277: step 140750, loss = 0.32, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 8h:12m:35s remains)
INFO - root - 2017-12-01 08:45:23.179604: step 140760, loss = 0.30, batch loss = 0.22 (49.5 examples/sec; 0.162 sec/batch; 8h:36m:44s remains)
INFO - root - 2017-12-01 08:45:24.732256: step 140770, loss = 0.32, batch loss = 0.23 (49.7 examples/sec; 0.161 sec/batch; 8h:34m:41s remains)
INFO - root - 2017-12-01 08:45:26.303191: step 140780, loss = 0.25, batch loss = 0.16 (54.1 examples/sec; 0.148 sec/batch; 7h:52m:25s remains)
INFO - root - 2017-12-01 08:45:27.870442: step 140790, loss = 0.33, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 8h:22m:20s remains)
INFO - root - 2017-12-01 08:45:29.448079: step 140800, loss = 0.28, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 8h:18m:47s remains)
INFO - root - 2017-12-01 08:45:31.070198: step 140810, loss = 0.42, batch loss = 0.33 (52.5 examples/sec; 0.152 sec/batch; 8h:06m:51s remains)
INFO - root - 2017-12-01 08:45:32.639226: step 140820, loss = 0.31, batch loss = 0.23 (49.9 examples/sec; 0.160 sec/batch; 8h:32m:16s remains)
INFO - root - 2017-12-01 08:45:34.212819: step 140830, loss = 0.27, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 8h:21m:18s remains)
INFO - root - 2017-12-01 08:45:35.769326: step 140840, loss = 0.27, batch loss = 0.18 (50.0 examples/sec; 0.160 sec/batch; 8h:31m:33s remains)
INFO - root - 2017-12-01 08:45:37.325798: step 140850, loss = 0.26, batch loss = 0.17 (50.8 examples/sec; 0.157 sec/batch; 8h:22m:54s remains)
INFO - root - 2017-12-01 08:45:38.880987: step 140860, loss = 0.36, batch loss = 0.27 (52.5 examples/sec; 0.152 sec/batch; 8h:06m:54s remains)
INFO - root - 2017-12-01 08:45:40.420917: step 140870, loss = 0.26, batch loss = 0.17 (52.8 examples/sec; 0.152 sec/batch; 8h:03m:57s remains)
INFO - root - 2017-12-01 08:45:41.988606: step 140880, loss = 0.37, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 8h:22m:05s remains)
INFO - root - 2017-12-01 08:45:43.555024: step 140890, loss = 0.31, batch loss = 0.22 (51.1 examples/sec; 0.156 sec/batch; 8h:19m:40s remains)
INFO - root - 2017-12-01 08:45:45.131980: step 140900, loss = 0.34, batch loss = 0.25 (50.0 examples/sec; 0.160 sec/batch; 8h:30m:47s remains)
INFO - root - 2017-12-01 08:45:46.761690: step 140910, loss = 0.26, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 8h:20m:11s remains)
INFO - root - 2017-12-01 08:45:48.322832: step 140920, loss = 0.28, batch loss = 0.19 (50.3 examples/sec; 0.159 sec/batch; 8h:28m:04s remains)
INFO - root - 2017-12-01 08:45:49.886299: step 140930, loss = 0.34, batch loss = 0.26 (51.4 examples/sec; 0.156 sec/batch; 8h:16m:33s remains)
INFO - root - 2017-12-01 08:45:51.434266: step 140940, loss = 0.33, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 8h:11m:14s remains)
INFO - root - 2017-12-01 08:45:52.992019: step 140950, loss = 0.24, batch loss = 0.15 (52.8 examples/sec; 0.152 sec/batch; 8h:04m:08s remains)
INFO - root - 2017-12-01 08:45:54.558714: step 140960, loss = 0.26, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 8h:28m:11s remains)
INFO - root - 2017-12-01 08:45:56.141260: step 140970, loss = 0.29, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 8h:25m:30s remains)
INFO - root - 2017-12-01 08:45:57.699262: step 140980, loss = 0.29, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 8h:16m:43s remains)
INFO - root - 2017-12-01 08:45:59.256121: step 140990, loss = 0.27, batch loss = 0.18 (50.4 examples/sec; 0.159 sec/batch; 8h:26m:38s remains)
INFO - root - 2017-12-01 08:46:00.830529: step 141000, loss = 0.35, batch loss = 0.26 (50.7 examples/sec; 0.158 sec/batch; 8h:24m:05s remains)
INFO - root - 2017-12-01 08:46:02.490849: step 141010, loss = 0.26, batch loss = 0.17 (50.8 examples/sec; 0.157 sec/batch; 8h:22m:16s remains)
INFO - root - 2017-12-01 08:46:04.068811: step 141020, loss = 0.24, batch loss = 0.15 (51.0 examples/sec; 0.157 sec/batch; 8h:20m:06s remains)
INFO - root - 2017-12-01 08:46:05.632360: step 141030, loss = 0.28, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 8h:16m:17s remains)
INFO - root - 2017-12-01 08:46:07.181703: step 141040, loss = 0.29, batch loss = 0.20 (50.8 examples/sec; 0.158 sec/batch; 8h:22m:49s remains)
INFO - root - 2017-12-01 08:46:08.732343: step 141050, loss = 0.26, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 8h:15m:55s remains)
INFO - root - 2017-12-01 08:46:10.278397: step 141060, loss = 0.43, batch loss = 0.34 (50.3 examples/sec; 0.159 sec/batch; 8h:27m:17s remains)
INFO - root - 2017-12-01 08:46:11.845476: step 141070, loss = 0.29, batch loss = 0.21 (52.8 examples/sec; 0.151 sec/batch; 8h:03m:06s remains)
INFO - root - 2017-12-01 08:46:13.427426: step 141080, loss = 0.28, batch loss = 0.19 (50.2 examples/sec; 0.159 sec/batch; 8h:28m:14s remains)
INFO - root - 2017-12-01 08:46:15.026956: step 141090, loss = 0.22, batch loss = 0.13 (50.4 examples/sec; 0.159 sec/batch; 8h:26m:07s remains)
INFO - root - 2017-12-01 08:46:16.581763: step 141100, loss = 0.24, batch loss = 0.15 (51.6 examples/sec; 0.155 sec/batch; 8h:14m:05s remains)
INFO - root - 2017-12-01 08:46:18.191407: step 141110, loss = 0.27, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 8h:11m:31s remains)
INFO - root - 2017-12-01 08:46:19.747906: step 141120, loss = 0.31, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 8h:19m:48s remains)
INFO - root - 2017-12-01 08:46:21.314663: step 141130, loss = 0.32, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 8h:23m:46s remains)
INFO - root - 2017-12-01 08:46:22.879510: step 141140, loss = 0.41, batch loss = 0.33 (51.7 examples/sec; 0.155 sec/batch; 8h:13m:57s remains)
INFO - root - 2017-12-01 08:46:24.443882: step 141150, loss = 0.27, batch loss = 0.18 (52.4 examples/sec; 0.153 sec/batch; 8h:06m:42s remains)
INFO - root - 2017-12-01 08:46:26.003811: step 141160, loss = 0.35, batch loss = 0.26 (50.1 examples/sec; 0.160 sec/batch; 8h:28m:50s remains)
INFO - root - 2017-12-01 08:46:27.585538: step 141170, loss = 0.29, batch loss = 0.20 (48.9 examples/sec; 0.164 sec/batch; 8h:41m:51s remains)
INFO - root - 2017-12-01 08:46:29.151787: step 141180, loss = 0.27, batch loss = 0.18 (49.8 examples/sec; 0.161 sec/batch; 8h:32m:18s remains)
INFO - root - 2017-12-01 08:46:30.712554: step 141190, loss = 0.33, batch loss = 0.25 (52.0 examples/sec; 0.154 sec/batch; 8h:10m:16s remains)
INFO - root - 2017-12-01 08:46:32.265796: step 141200, loss = 0.30, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 8h:18m:19s remains)
INFO - root - 2017-12-01 08:46:33.899636: step 141210, loss = 0.35, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 8h:14m:01s remains)
INFO - root - 2017-12-01 08:46:35.451247: step 141220, loss = 0.25, batch loss = 0.16 (51.8 examples/sec; 0.155 sec/batch; 8h:12m:41s remains)
INFO - root - 2017-12-01 08:46:37.004578: step 141230, loss = 0.24, batch loss = 0.15 (51.5 examples/sec; 0.155 sec/batch; 8h:14m:50s remains)
INFO - root - 2017-12-01 08:46:38.582589: step 141240, loss = 0.31, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 8h:10m:48s remains)
INFO - root - 2017-12-01 08:46:40.156142: step 141250, loss = 0.28, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 8h:24m:50s remains)
INFO - root - 2017-12-01 08:46:41.735662: step 141260, loss = 0.29, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 8h:26m:22s remains)
INFO - root - 2017-12-01 08:46:43.289870: step 141270, loss = 0.30, batch loss = 0.21 (52.5 examples/sec; 0.153 sec/batch; 8h:06m:04s remains)
INFO - root - 2017-12-01 08:46:44.849937: step 141280, loss = 0.35, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 8h:10m:49s remains)
INFO - root - 2017-12-01 08:46:46.424768: step 141290, loss = 0.36, batch loss = 0.27 (50.8 examples/sec; 0.157 sec/batch; 8h:21m:48s remains)
INFO - root - 2017-12-01 08:46:47.986696: step 141300, loss = 0.28, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 8h:24m:48s remains)
INFO - root - 2017-12-01 08:46:49.582326: step 141310, loss = 0.28, batch loss = 0.19 (53.3 examples/sec; 0.150 sec/batch; 7h:58m:25s remains)
INFO - root - 2017-12-01 08:46:51.152716: step 141320, loss = 0.29, batch loss = 0.20 (52.5 examples/sec; 0.152 sec/batch; 8h:05m:29s remains)
INFO - root - 2017-12-01 08:46:52.735931: step 141330, loss = 0.25, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 8h:17m:50s remains)
INFO - root - 2017-12-01 08:46:54.298003: step 141340, loss = 0.30, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 8h:18m:59s remains)
INFO - root - 2017-12-01 08:46:55.886000: step 141350, loss = 0.26, batch loss = 0.17 (50.1 examples/sec; 0.160 sec/batch; 8h:28m:13s remains)
INFO - root - 2017-12-01 08:46:57.462126: step 141360, loss = 0.31, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 8h:16m:10s remains)
INFO - root - 2017-12-01 08:46:59.032740: step 141370, loss = 0.27, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 8h:17m:03s remains)
INFO - root - 2017-12-01 08:47:00.597989: step 141380, loss = 0.31, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 8h:25m:41s remains)
INFO - root - 2017-12-01 08:47:02.157386: step 141390, loss = 0.28, batch loss = 0.19 (53.1 examples/sec; 0.151 sec/batch; 7h:59m:54s remains)
INFO - root - 2017-12-01 08:47:03.729392: step 141400, loss = 0.27, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 8h:12m:40s remains)
INFO - root - 2017-12-01 08:47:05.350279: step 141410, loss = 0.25, batch loss = 0.17 (50.2 examples/sec; 0.159 sec/batch; 8h:27m:34s remains)
INFO - root - 2017-12-01 08:47:06.917070: step 141420, loss = 0.25, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 8h:11m:25s remains)
INFO - root - 2017-12-01 08:47:08.514911: step 141430, loss = 0.30, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 8h:19m:53s remains)
INFO - root - 2017-12-01 08:47:10.064260: step 141440, loss = 0.30, batch loss = 0.21 (51.1 examples/sec; 0.156 sec/batch; 8h:18m:18s remains)
INFO - root - 2017-12-01 08:47:11.631474: step 141450, loss = 0.23, batch loss = 0.14 (51.6 examples/sec; 0.155 sec/batch; 8h:13m:50s remains)
INFO - root - 2017-12-01 08:47:13.204189: step 141460, loss = 0.26, batch loss = 0.17 (47.0 examples/sec; 0.170 sec/batch; 9h:01m:25s remains)
INFO - root - 2017-12-01 08:47:14.839529: step 141470, loss = 0.30, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 8h:16m:29s remains)
INFO - root - 2017-12-01 08:47:16.390377: step 141480, loss = 0.26, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 8h:11m:10s remains)
INFO - root - 2017-12-01 08:47:17.957772: step 141490, loss = 0.29, batch loss = 0.20 (49.8 examples/sec; 0.161 sec/batch; 8h:31m:52s remains)
INFO - root - 2017-12-01 08:47:19.541329: step 141500, loss = 0.32, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 8h:16m:08s remains)
INFO - root - 2017-12-01 08:47:21.152977: step 141510, loss = 0.32, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 8h:16m:38s remains)
INFO - root - 2017-12-01 08:47:22.713452: step 141520, loss = 0.32, batch loss = 0.23 (48.2 examples/sec; 0.166 sec/batch; 8h:47m:45s remains)
INFO - root - 2017-12-01 08:47:24.279615: step 141530, loss = 0.29, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 8h:17m:18s remains)
INFO - root - 2017-12-01 08:47:25.853854: step 141540, loss = 0.28, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 8h:20m:08s remains)
INFO - root - 2017-12-01 08:47:27.412348: step 141550, loss = 0.28, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 8h:22m:32s remains)
INFO - root - 2017-12-01 08:47:28.973314: step 141560, loss = 0.39, batch loss = 0.30 (53.3 examples/sec; 0.150 sec/batch; 7h:57m:29s remains)
INFO - root - 2017-12-01 08:47:30.527175: step 141570, loss = 0.33, batch loss = 0.24 (49.3 examples/sec; 0.162 sec/batch; 8h:36m:14s remains)
INFO - root - 2017-12-01 08:47:32.117343: step 141580, loss = 0.36, batch loss = 0.28 (52.6 examples/sec; 0.152 sec/batch; 8h:04m:20s remains)
INFO - root - 2017-12-01 08:47:33.671366: step 141590, loss = 0.25, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 8h:10m:31s remains)
INFO - root - 2017-12-01 08:47:35.253225: step 141600, loss = 0.34, batch loss = 0.25 (50.1 examples/sec; 0.160 sec/batch; 8h:27m:47s remains)
INFO - root - 2017-12-01 08:47:36.910138: step 141610, loss = 0.23, batch loss = 0.14 (50.8 examples/sec; 0.157 sec/batch; 8h:20m:37s remains)
INFO - root - 2017-12-01 08:47:38.460991: step 141620, loss = 0.42, batch loss = 0.34 (52.7 examples/sec; 0.152 sec/batch; 8h:03m:15s remains)
INFO - root - 2017-12-01 08:47:40.028103: step 141630, loss = 0.31, batch loss = 0.23 (48.9 examples/sec; 0.164 sec/batch; 8h:40m:57s remains)
INFO - root - 2017-12-01 08:47:41.602336: step 141640, loss = 0.31, batch loss = 0.22 (48.4 examples/sec; 0.165 sec/batch; 8h:46m:19s remains)
INFO - root - 2017-12-01 08:47:43.166036: step 141650, loss = 0.31, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 8h:21m:29s remains)
INFO - root - 2017-12-01 08:47:44.716655: step 141660, loss = 0.25, batch loss = 0.16 (52.5 examples/sec; 0.152 sec/batch; 8h:04m:29s remains)
INFO - root - 2017-12-01 08:47:46.260045: step 141670, loss = 0.24, batch loss = 0.15 (50.9 examples/sec; 0.157 sec/batch; 8h:19m:50s remains)
INFO - root - 2017-12-01 08:47:47.816432: step 141680, loss = 0.26, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 8h:25m:39s remains)
INFO - root - 2017-12-01 08:47:49.364259: step 141690, loss = 0.38, batch loss = 0.30 (50.5 examples/sec; 0.158 sec/batch; 8h:23m:29s remains)
INFO - root - 2017-12-01 08:47:50.931092: step 141700, loss = 0.27, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 8h:16m:07s remains)
INFO - root - 2017-12-01 08:47:52.543207: step 141710, loss = 0.31, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 8h:15m:28s remains)
INFO - root - 2017-12-01 08:47:54.095547: step 141720, loss = 0.31, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 8h:27m:30s remains)
INFO - root - 2017-12-01 08:47:55.691387: step 141730, loss = 0.34, batch loss = 0.25 (45.9 examples/sec; 0.174 sec/batch; 9h:14m:23s remains)
INFO - root - 2017-12-01 08:47:57.267609: step 141740, loss = 0.23, batch loss = 0.14 (51.8 examples/sec; 0.155 sec/batch; 8h:11m:17s remains)
INFO - root - 2017-12-01 08:47:58.877807: step 141750, loss = 0.33, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 8h:16m:18s remains)
INFO - root - 2017-12-01 08:48:00.421313: step 141760, loss = 0.27, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 8h:13m:56s remains)
INFO - root - 2017-12-01 08:48:02.001602: step 141770, loss = 0.25, batch loss = 0.16 (49.1 examples/sec; 0.163 sec/batch; 8h:37m:28s remains)
INFO - root - 2017-12-01 08:48:03.576212: step 141780, loss = 0.27, batch loss = 0.18 (52.1 examples/sec; 0.153 sec/batch; 8h:07m:55s remains)
INFO - root - 2017-12-01 08:48:05.141477: step 141790, loss = 0.29, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 8h:18m:40s remains)
INFO - root - 2017-12-01 08:48:06.696461: step 141800, loss = 0.34, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 8h:15m:45s remains)
INFO - root - 2017-12-01 08:48:08.353628: step 141810, loss = 0.26, batch loss = 0.17 (50.0 examples/sec; 0.160 sec/batch; 8h:28m:40s remains)
INFO - root - 2017-12-01 08:48:09.922780: step 141820, loss = 0.26, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 8h:23m:21s remains)
INFO - root - 2017-12-01 08:48:11.468459: step 141830, loss = 0.32, batch loss = 0.23 (52.7 examples/sec; 0.152 sec/batch; 8h:02m:25s remains)
INFO - root - 2017-12-01 08:48:13.030846: step 141840, loss = 0.24, batch loss = 0.15 (52.5 examples/sec; 0.152 sec/batch; 8h:04m:16s remains)
INFO - root - 2017-12-01 08:48:14.611058: step 141850, loss = 0.24, batch loss = 0.15 (51.7 examples/sec; 0.155 sec/batch; 8h:11m:57s remains)
INFO - root - 2017-12-01 08:48:16.168178: step 141860, loss = 0.22, batch loss = 0.13 (50.7 examples/sec; 0.158 sec/batch; 8h:21m:06s remains)
INFO - root - 2017-12-01 08:48:17.733345: step 141870, loss = 0.24, batch loss = 0.15 (49.1 examples/sec; 0.163 sec/batch; 8h:38m:01s remains)
INFO - root - 2017-12-01 08:48:19.292860: step 141880, loss = 0.26, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 8h:18m:11s remains)
INFO - root - 2017-12-01 08:48:20.865489: step 141890, loss = 0.26, batch loss = 0.18 (49.2 examples/sec; 0.163 sec/batch; 8h:36m:14s remains)
INFO - root - 2017-12-01 08:48:22.425953: step 141900, loss = 0.28, batch loss = 0.19 (52.1 examples/sec; 0.154 sec/batch; 8h:07m:59s remains)
INFO - root - 2017-12-01 08:48:24.075500: step 141910, loss = 0.36, batch loss = 0.27 (53.0 examples/sec; 0.151 sec/batch; 7h:59m:07s remains)
INFO - root - 2017-12-01 08:48:25.627496: step 141920, loss = 0.34, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 8h:04m:04s remains)
INFO - root - 2017-12-01 08:48:27.214069: step 141930, loss = 0.28, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 8h:20m:09s remains)
INFO - root - 2017-12-01 08:48:28.773576: step 141940, loss = 0.28, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 8h:17m:14s remains)
INFO - root - 2017-12-01 08:48:30.337058: step 141950, loss = 0.35, batch loss = 0.26 (50.1 examples/sec; 0.160 sec/batch; 8h:27m:25s remains)
INFO - root - 2017-12-01 08:48:31.901755: step 141960, loss = 0.26, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 8h:11m:37s remains)
INFO - root - 2017-12-01 08:48:33.461300: step 141970, loss = 0.39, batch loss = 0.30 (52.2 examples/sec; 0.153 sec/batch; 8h:06m:56s remains)
INFO - root - 2017-12-01 08:48:35.038483: step 141980, loss = 0.29, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 8h:18m:57s remains)
INFO - root - 2017-12-01 08:48:36.616798: step 141990, loss = 0.35, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 8h:18m:23s remains)
INFO - root - 2017-12-01 08:48:38.193556: step 142000, loss = 0.32, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 8h:09m:55s remains)
INFO - root - 2017-12-01 08:48:39.831049: step 142010, loss = 0.26, batch loss = 0.17 (49.7 examples/sec; 0.161 sec/batch; 8h:30m:43s remains)
INFO - root - 2017-12-01 08:48:41.384432: step 142020, loss = 0.27, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 8h:16m:23s remains)
INFO - root - 2017-12-01 08:48:42.937452: step 142030, loss = 0.27, batch loss = 0.18 (52.6 examples/sec; 0.152 sec/batch; 8h:02m:28s remains)
INFO - root - 2017-12-01 08:48:44.513995: step 142040, loss = 0.51, batch loss = 0.42 (51.6 examples/sec; 0.155 sec/batch; 8h:12m:08s remains)
INFO - root - 2017-12-01 08:48:46.086413: step 142050, loss = 0.33, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 8h:19m:19s remains)
INFO - root - 2017-12-01 08:48:47.649587: step 142060, loss = 0.28, batch loss = 0.19 (50.1 examples/sec; 0.160 sec/batch; 8h:26m:38s remains)
INFO - root - 2017-12-01 08:48:49.210358: step 142070, loss = 0.26, batch loss = 0.17 (49.4 examples/sec; 0.162 sec/batch; 8h:33m:39s remains)
INFO - root - 2017-12-01 08:48:50.775860: step 142080, loss = 0.31, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 8h:23m:21s remains)
INFO - root - 2017-12-01 08:48:52.373846: step 142090, loss = 0.38, batch loss = 0.29 (51.0 examples/sec; 0.157 sec/batch; 8h:17m:47s remains)
INFO - root - 2017-12-01 08:48:53.929430: step 142100, loss = 0.33, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 8h:16m:04s remains)
INFO - root - 2017-12-01 08:48:55.539665: step 142110, loss = 0.30, batch loss = 0.22 (52.4 examples/sec; 0.153 sec/batch; 8h:04m:14s remains)
INFO - root - 2017-12-01 08:48:57.102361: step 142120, loss = 0.27, batch loss = 0.18 (51.9 examples/sec; 0.154 sec/batch; 8h:09m:10s remains)
INFO - root - 2017-12-01 08:48:58.669586: step 142130, loss = 0.25, batch loss = 0.16 (50.8 examples/sec; 0.157 sec/batch; 8h:19m:35s remains)
INFO - root - 2017-12-01 08:49:00.217536: step 142140, loss = 0.33, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 8h:21m:01s remains)
INFO - root - 2017-12-01 08:49:01.798126: step 142150, loss = 0.30, batch loss = 0.21 (48.3 examples/sec; 0.166 sec/batch; 8h:45m:06s remains)
INFO - root - 2017-12-01 08:49:03.384382: step 142160, loss = 0.24, batch loss = 0.15 (52.3 examples/sec; 0.153 sec/batch; 8h:05m:25s remains)
INFO - root - 2017-12-01 08:49:04.931602: step 142170, loss = 0.38, batch loss = 0.29 (52.6 examples/sec; 0.152 sec/batch; 8h:02m:14s remains)
INFO - root - 2017-12-01 08:49:06.495289: step 142180, loss = 0.27, batch loss = 0.18 (49.1 examples/sec; 0.163 sec/batch; 8h:36m:39s remains)
INFO - root - 2017-12-01 08:49:08.062229: step 142190, loss = 0.30, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 8h:24m:17s remains)
INFO - root - 2017-12-01 08:49:09.634017: step 142200, loss = 0.34, batch loss = 0.25 (50.4 examples/sec; 0.159 sec/batch; 8h:23m:21s remains)
INFO - root - 2017-12-01 08:49:11.260941: step 142210, loss = 0.25, batch loss = 0.16 (50.6 examples/sec; 0.158 sec/batch; 8h:21m:24s remains)
INFO - root - 2017-12-01 08:49:12.833897: step 142220, loss = 0.29, batch loss = 0.21 (49.4 examples/sec; 0.162 sec/batch; 8h:33m:41s remains)
INFO - root - 2017-12-01 08:49:14.390007: step 142230, loss = 0.30, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 8h:18m:37s remains)
INFO - root - 2017-12-01 08:49:15.975662: step 142240, loss = 0.29, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 8h:05m:16s remains)
INFO - root - 2017-12-01 08:49:17.540048: step 142250, loss = 0.29, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 8h:18m:44s remains)
INFO - root - 2017-12-01 08:49:19.096692: step 142260, loss = 0.23, batch loss = 0.14 (50.8 examples/sec; 0.158 sec/batch; 8h:19m:43s remains)
INFO - root - 2017-12-01 08:49:20.652344: step 142270, loss = 0.33, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 8h:18m:04s remains)
INFO - root - 2017-12-01 08:49:22.215713: step 142280, loss = 0.30, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 8h:17m:47s remains)
INFO - root - 2017-12-01 08:49:23.775606: step 142290, loss = 0.30, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 8h:13m:38s remains)
INFO - root - 2017-12-01 08:49:25.351356: step 142300, loss = 0.38, batch loss = 0.29 (50.5 examples/sec; 0.159 sec/batch; 8h:22m:29s remains)
INFO - root - 2017-12-01 08:49:26.957502: step 142310, loss = 0.43, batch loss = 0.34 (51.4 examples/sec; 0.156 sec/batch; 8h:12m:55s remains)
INFO - root - 2017-12-01 08:49:28.519416: step 142320, loss = 0.25, batch loss = 0.17 (52.7 examples/sec; 0.152 sec/batch; 8h:01m:30s remains)
INFO - root - 2017-12-01 08:49:30.078499: step 142330, loss = 0.25, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 8h:08m:08s remains)
INFO - root - 2017-12-01 08:49:31.656360: step 142340, loss = 0.23, batch loss = 0.14 (51.1 examples/sec; 0.156 sec/batch; 8h:15m:54s remains)
INFO - root - 2017-12-01 08:49:33.224090: step 142350, loss = 0.26, batch loss = 0.17 (50.7 examples/sec; 0.158 sec/batch; 8h:20m:20s remains)
INFO - root - 2017-12-01 08:49:34.789168: step 142360, loss = 0.26, batch loss = 0.17 (52.5 examples/sec; 0.152 sec/batch; 8h:02m:45s remains)
INFO - root - 2017-12-01 08:49:36.343059: step 142370, loss = 0.28, batch loss = 0.19 (52.8 examples/sec; 0.152 sec/batch; 8h:00m:10s remains)
INFO - root - 2017-12-01 08:49:37.889473: step 142380, loss = 0.34, batch loss = 0.25 (54.0 examples/sec; 0.148 sec/batch; 7h:49m:08s remains)
INFO - root - 2017-12-01 08:49:39.449278: step 142390, loss = 0.29, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 8h:11m:43s remains)
INFO - root - 2017-12-01 08:49:41.019875: step 142400, loss = 0.24, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 8h:13m:32s remains)
INFO - root - 2017-12-01 08:49:42.672098: step 142410, loss = 0.21, batch loss = 0.12 (51.7 examples/sec; 0.155 sec/batch; 8h:10m:11s remains)
INFO - root - 2017-12-01 08:49:44.248021: step 142420, loss = 0.31, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 8h:21m:37s remains)
INFO - root - 2017-12-01 08:49:45.800946: step 142430, loss = 0.21, batch loss = 0.13 (51.1 examples/sec; 0.156 sec/batch; 8h:15m:45s remains)
INFO - root - 2017-12-01 08:49:47.352668: step 142440, loss = 0.33, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 8h:07m:58s remains)
INFO - root - 2017-12-01 08:49:48.923227: step 142450, loss = 0.47, batch loss = 0.38 (52.3 examples/sec; 0.153 sec/batch; 8h:04m:21s remains)
INFO - root - 2017-12-01 08:49:50.507679: step 142460, loss = 0.26, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 8h:07m:22s remains)
INFO - root - 2017-12-01 08:49:52.065981: step 142470, loss = 0.33, batch loss = 0.24 (50.7 examples/sec; 0.158 sec/batch; 8h:20m:13s remains)
INFO - root - 2017-12-01 08:49:53.626036: step 142480, loss = 0.29, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 8h:19m:52s remains)
INFO - root - 2017-12-01 08:49:55.195547: step 142490, loss = 0.28, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 8h:14m:33s remains)
INFO - root - 2017-12-01 08:49:56.762570: step 142500, loss = 0.25, batch loss = 0.16 (50.0 examples/sec; 0.160 sec/batch; 8h:26m:35s remains)
INFO - root - 2017-12-01 08:49:58.375201: step 142510, loss = 0.31, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 8h:10m:17s remains)
INFO - root - 2017-12-01 08:49:59.938888: step 142520, loss = 0.24, batch loss = 0.15 (53.0 examples/sec; 0.151 sec/batch; 7h:57m:32s remains)
INFO - root - 2017-12-01 08:50:01.520127: step 142530, loss = 0.32, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 8h:16m:17s remains)
INFO - root - 2017-12-01 08:50:03.089027: step 142540, loss = 0.23, batch loss = 0.15 (50.9 examples/sec; 0.157 sec/batch; 8h:17m:19s remains)
INFO - root - 2017-12-01 08:50:04.646749: step 142550, loss = 0.24, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 8h:18m:00s remains)
INFO - root - 2017-12-01 08:50:06.210009: step 142560, loss = 0.25, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 8h:08m:19s remains)
INFO - root - 2017-12-01 08:50:07.773290: step 142570, loss = 0.31, batch loss = 0.22 (49.9 examples/sec; 0.160 sec/batch; 8h:27m:31s remains)
INFO - root - 2017-12-01 08:50:09.343789: step 142580, loss = 0.26, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 8h:19m:43s remains)
INFO - root - 2017-12-01 08:50:10.904455: step 142590, loss = 0.28, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 8h:12m:58s remains)
INFO - root - 2017-12-01 08:50:12.480529: step 142600, loss = 0.34, batch loss = 0.26 (49.8 examples/sec; 0.161 sec/batch; 8h:28m:47s remains)
INFO - root - 2017-12-01 08:50:14.111497: step 142610, loss = 0.33, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 8h:01m:15s remains)
INFO - root - 2017-12-01 08:50:15.669354: step 142620, loss = 0.24, batch loss = 0.15 (49.4 examples/sec; 0.162 sec/batch; 8h:32m:28s remains)
INFO - root - 2017-12-01 08:50:17.224113: step 142630, loss = 0.27, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 8h:18m:59s remains)
INFO - root - 2017-12-01 08:50:18.782461: step 142640, loss = 0.30, batch loss = 0.21 (50.3 examples/sec; 0.159 sec/batch; 8h:22m:47s remains)
INFO - root - 2017-12-01 08:50:20.332277: step 142650, loss = 0.27, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 8h:16m:37s remains)
INFO - root - 2017-12-01 08:50:21.882831: step 142660, loss = 0.28, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 8h:09m:17s remains)
INFO - root - 2017-12-01 08:50:23.463835: step 142670, loss = 0.27, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 8h:14m:35s remains)
INFO - root - 2017-12-01 08:50:25.032397: step 142680, loss = 0.35, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 8h:16m:54s remains)
INFO - root - 2017-12-01 08:50:26.587699: step 142690, loss = 0.25, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 8h:21m:55s remains)
INFO - root - 2017-12-01 08:50:28.145150: step 142700, loss = 0.34, batch loss = 0.25 (52.0 examples/sec; 0.154 sec/batch; 8h:06m:30s remains)
INFO - root - 2017-12-01 08:50:29.785643: step 142710, loss = 0.43, batch loss = 0.34 (52.0 examples/sec; 0.154 sec/batch; 8h:06m:25s remains)
INFO - root - 2017-12-01 08:50:31.339723: step 142720, loss = 0.28, batch loss = 0.19 (50.5 examples/sec; 0.159 sec/batch; 8h:21m:23s remains)
INFO - root - 2017-12-01 08:50:32.908670: step 142730, loss = 0.33, batch loss = 0.24 (47.6 examples/sec; 0.168 sec/batch; 8h:51m:05s remains)
INFO - root - 2017-12-01 08:50:34.496206: step 142740, loss = 0.30, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 8h:12m:30s remains)
INFO - root - 2017-12-01 08:50:36.091113: step 142750, loss = 0.34, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 8h:15m:10s remains)
INFO - root - 2017-12-01 08:50:37.653514: step 142760, loss = 0.28, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 8h:19m:24s remains)
INFO - root - 2017-12-01 08:50:39.215493: step 142770, loss = 0.33, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 8h:16m:46s remains)
INFO - root - 2017-12-01 08:50:40.791584: step 142780, loss = 0.39, batch loss = 0.31 (50.4 examples/sec; 0.159 sec/batch; 8h:22m:08s remains)
INFO - root - 2017-12-01 08:50:42.342683: step 142790, loss = 0.38, batch loss = 0.30 (52.9 examples/sec; 0.151 sec/batch; 7h:58m:10s remains)
INFO - root - 2017-12-01 08:50:43.924824: step 142800, loss = 0.45, batch loss = 0.37 (49.4 examples/sec; 0.162 sec/batch; 8h:31m:41s remains)
INFO - root - 2017-12-01 08:50:45.581925: step 142810, loss = 0.30, batch loss = 0.21 (51.1 examples/sec; 0.157 sec/batch; 8h:15m:20s remains)
INFO - root - 2017-12-01 08:50:47.143826: step 142820, loss = 0.34, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 8h:14m:25s remains)
INFO - root - 2017-12-01 08:50:48.702020: step 142830, loss = 0.25, batch loss = 0.16 (49.5 examples/sec; 0.162 sec/batch; 8h:30m:55s remains)
INFO - root - 2017-12-01 08:50:50.265237: step 142840, loss = 0.27, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 8h:19m:00s remains)
INFO - root - 2017-12-01 08:50:51.836906: step 142850, loss = 0.27, batch loss = 0.18 (52.6 examples/sec; 0.152 sec/batch; 8h:00m:35s remains)
INFO - root - 2017-12-01 08:50:53.399369: step 142860, loss = 0.27, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 8h:15m:20s remains)
INFO - root - 2017-12-01 08:50:54.953980: step 142870, loss = 0.21, batch loss = 0.13 (51.4 examples/sec; 0.156 sec/batch; 8h:11m:35s remains)
INFO - root - 2017-12-01 08:50:56.569978: step 142880, loss = 0.28, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 8h:14m:08s remains)
INFO - root - 2017-12-01 08:50:58.133518: step 142890, loss = 0.26, batch loss = 0.17 (52.1 examples/sec; 0.154 sec/batch; 8h:05m:09s remains)
INFO - root - 2017-12-01 08:50:59.690804: step 142900, loss = 0.25, batch loss = 0.16 (52.4 examples/sec; 0.153 sec/batch; 8h:02m:38s remains)
INFO - root - 2017-12-01 08:51:01.301603: step 142910, loss = 0.45, batch loss = 0.36 (50.9 examples/sec; 0.157 sec/batch; 8h:16m:44s remains)
INFO - root - 2017-12-01 08:51:02.855771: step 142920, loss = 0.26, batch loss = 0.18 (52.1 examples/sec; 0.154 sec/batch; 8h:05m:14s remains)
INFO - root - 2017-12-01 08:51:04.425111: step 142930, loss = 0.32, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 8h:16m:13s remains)
INFO - root - 2017-12-01 08:51:05.996718: step 142940, loss = 0.32, batch loss = 0.24 (50.8 examples/sec; 0.157 sec/batch; 8h:17m:24s remains)
INFO - root - 2017-12-01 08:51:07.570888: step 142950, loss = 0.26, batch loss = 0.17 (48.7 examples/sec; 0.164 sec/batch; 8h:38m:52s remains)
INFO - root - 2017-12-01 08:51:09.135342: step 142960, loss = 0.36, batch loss = 0.27 (51.5 examples/sec; 0.155 sec/batch; 8h:10m:41s remains)
INFO - root - 2017-12-01 08:51:10.718487: step 142970, loss = 0.32, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 8h:13m:57s remains)
INFO - root - 2017-12-01 08:51:12.280681: step 142980, loss = 0.25, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 8h:16m:13s remains)
INFO - root - 2017-12-01 08:51:13.845745: step 142990, loss = 0.36, batch loss = 0.28 (51.1 examples/sec; 0.156 sec/batch; 8h:14m:12s remains)
INFO - root - 2017-12-01 08:51:15.408459: step 143000, loss = 0.50, batch loss = 0.41 (51.7 examples/sec; 0.155 sec/batch; 8h:08m:58s remains)
INFO - root - 2017-12-01 08:51:17.052560: step 143010, loss = 0.28, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 8h:15m:29s remains)
INFO - root - 2017-12-01 08:51:18.615763: step 143020, loss = 0.23, batch loss = 0.14 (49.6 examples/sec; 0.161 sec/batch; 8h:29m:19s remains)
INFO - root - 2017-12-01 08:51:20.197306: step 143030, loss = 0.39, batch loss = 0.31 (51.3 examples/sec; 0.156 sec/batch; 8h:12m:14s remains)
INFO - root - 2017-12-01 08:51:21.752596: step 143040, loss = 0.26, batch loss = 0.17 (52.5 examples/sec; 0.152 sec/batch; 8h:01m:10s remains)
INFO - root - 2017-12-01 08:51:23.338939: step 143050, loss = 0.26, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 8h:18m:23s remains)
INFO - root - 2017-12-01 08:51:24.904967: step 143060, loss = 0.41, batch loss = 0.33 (50.9 examples/sec; 0.157 sec/batch; 8h:16m:02s remains)
INFO - root - 2017-12-01 08:51:26.469649: step 143070, loss = 0.22, batch loss = 0.14 (50.6 examples/sec; 0.158 sec/batch; 8h:18m:53s remains)
INFO - root - 2017-12-01 08:51:28.042224: step 143080, loss = 0.24, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 8h:15m:45s remains)
INFO - root - 2017-12-01 08:51:29.596704: step 143090, loss = 0.28, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 8h:10m:15s remains)
INFO - root - 2017-12-01 08:51:31.160616: step 143100, loss = 0.27, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 8h:10m:42s remains)
INFO - root - 2017-12-01 08:51:32.762995: step 143110, loss = 0.24, batch loss = 0.15 (52.3 examples/sec; 0.153 sec/batch; 8h:03m:11s remains)
INFO - root - 2017-12-01 08:51:34.329599: step 143120, loss = 0.23, batch loss = 0.14 (50.9 examples/sec; 0.157 sec/batch; 8h:16m:25s remains)
INFO - root - 2017-12-01 08:51:35.885591: step 143130, loss = 0.54, batch loss = 0.45 (52.1 examples/sec; 0.153 sec/batch; 8h:04m:20s remains)
INFO - root - 2017-12-01 08:51:37.475603: step 143140, loss = 0.34, batch loss = 0.25 (47.2 examples/sec; 0.169 sec/batch; 8h:54m:28s remains)
INFO - root - 2017-12-01 08:51:39.018845: step 143150, loss = 0.26, batch loss = 0.17 (52.3 examples/sec; 0.153 sec/batch; 8h:02m:35s remains)
INFO - root - 2017-12-01 08:51:40.590654: step 143160, loss = 0.26, batch loss = 0.17 (50.2 examples/sec; 0.159 sec/batch; 8h:22m:51s remains)
INFO - root - 2017-12-01 08:51:42.158365: step 143170, loss = 0.33, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 8h:12m:48s remains)
INFO - root - 2017-12-01 08:51:43.722830: step 143180, loss = 0.25, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 8h:15m:52s remains)
INFO - root - 2017-12-01 08:51:45.289410: step 143190, loss = 0.28, batch loss = 0.19 (49.7 examples/sec; 0.161 sec/batch; 8h:28m:17s remains)
INFO - root - 2017-12-01 08:51:46.849312: step 143200, loss = 0.31, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 8h:10m:13s remains)
INFO - root - 2017-12-01 08:51:48.468058: step 143210, loss = 0.24, batch loss = 0.15 (50.8 examples/sec; 0.157 sec/batch; 8h:16m:21s remains)
INFO - root - 2017-12-01 08:51:50.017612: step 143220, loss = 0.24, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 8h:12m:20s remains)
INFO - root - 2017-12-01 08:51:51.579204: step 143230, loss = 0.44, batch loss = 0.35 (51.0 examples/sec; 0.157 sec/batch; 8h:14m:46s remains)
INFO - root - 2017-12-01 08:51:53.145201: step 143240, loss = 0.27, batch loss = 0.18 (52.1 examples/sec; 0.153 sec/batch; 8h:03m:56s remains)
INFO - root - 2017-12-01 08:51:54.731978: step 143250, loss = 0.30, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 8h:05m:52s remains)
INFO - root - 2017-12-01 08:51:56.283247: step 143260, loss = 0.29, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 8h:13m:19s remains)
INFO - root - 2017-12-01 08:51:57.855465: step 143270, loss = 0.28, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 8h:11m:51s remains)
INFO - root - 2017-12-01 08:51:59.429692: step 143280, loss = 0.29, batch loss = 0.20 (47.2 examples/sec; 0.170 sec/batch; 8h:54m:56s remains)
INFO - root - 2017-12-01 08:52:00.990171: step 143290, loss = 0.28, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 8h:09m:29s remains)
INFO - root - 2017-12-01 08:52:02.550170: step 143300, loss = 0.29, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 8h:13m:32s remains)
INFO - root - 2017-12-01 08:52:04.158487: step 143310, loss = 0.31, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 8h:17m:04s remains)
INFO - root - 2017-12-01 08:52:05.720572: step 143320, loss = 0.32, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 8h:08m:33s remains)
INFO - root - 2017-12-01 08:52:07.266026: step 143330, loss = 0.22, batch loss = 0.13 (51.8 examples/sec; 0.154 sec/batch; 8h:06m:52s remains)
INFO - root - 2017-12-01 08:52:08.845947: step 143340, loss = 0.37, batch loss = 0.29 (51.6 examples/sec; 0.155 sec/batch; 8h:08m:50s remains)
INFO - root - 2017-12-01 08:52:10.420417: step 143350, loss = 0.31, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 8h:12m:31s remains)
INFO - root - 2017-12-01 08:52:11.984639: step 143360, loss = 0.24, batch loss = 0.15 (48.9 examples/sec; 0.164 sec/batch; 8h:35m:47s remains)
INFO - root - 2017-12-01 08:52:13.549788: step 143370, loss = 0.27, batch loss = 0.18 (52.8 examples/sec; 0.152 sec/batch; 7h:57m:56s remains)
INFO - root - 2017-12-01 08:52:15.092005: step 143380, loss = 0.26, batch loss = 0.17 (52.9 examples/sec; 0.151 sec/batch; 7h:56m:20s remains)
INFO - root - 2017-12-01 08:52:16.691814: step 143390, loss = 0.25, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 8h:04m:57s remains)
INFO - root - 2017-12-01 08:52:18.245586: step 143400, loss = 0.27, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 8h:16m:29s remains)
INFO - root - 2017-12-01 08:52:19.878699: step 143410, loss = 0.33, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 8h:17m:47s remains)
INFO - root - 2017-12-01 08:52:21.432586: step 143420, loss = 0.28, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 8h:05m:15s remains)
INFO - root - 2017-12-01 08:52:22.999399: step 143430, loss = 0.44, batch loss = 0.35 (49.8 examples/sec; 0.161 sec/batch; 8h:25m:47s remains)
INFO - root - 2017-12-01 08:52:24.577672: step 143440, loss = 0.30, batch loss = 0.21 (48.3 examples/sec; 0.166 sec/batch; 8h:41m:54s remains)
INFO - root - 2017-12-01 08:52:26.142202: step 143450, loss = 0.22, batch loss = 0.13 (52.0 examples/sec; 0.154 sec/batch; 8h:04m:27s remains)
INFO - root - 2017-12-01 08:52:27.689724: step 143460, loss = 0.31, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 8h:09m:03s remains)
INFO - root - 2017-12-01 08:52:29.260745: step 143470, loss = 0.25, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 8h:04m:40s remains)
INFO - root - 2017-12-01 08:52:30.832237: step 143480, loss = 0.35, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 8h:20m:19s remains)
INFO - root - 2017-12-01 08:52:32.397170: step 143490, loss = 0.30, batch loss = 0.22 (49.1 examples/sec; 0.163 sec/batch; 8h:32m:52s remains)
INFO - root - 2017-12-01 08:52:33.976738: step 143500, loss = 0.37, batch loss = 0.28 (51.3 examples/sec; 0.156 sec/batch; 8h:11m:13s remains)
INFO - root - 2017-12-01 08:52:35.621831: step 143510, loss = 0.26, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 8h:08m:42s remains)
INFO - root - 2017-12-01 08:52:37.173057: step 143520, loss = 0.45, batch loss = 0.37 (51.0 examples/sec; 0.157 sec/batch; 8h:13m:56s remains)
INFO - root - 2017-12-01 08:52:38.740554: step 143530, loss = 0.24, batch loss = 0.16 (52.1 examples/sec; 0.154 sec/batch; 8h:03m:59s remains)
INFO - root - 2017-12-01 08:52:40.300716: step 143540, loss = 0.32, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 8h:01m:56s remains)
INFO - root - 2017-12-01 08:52:41.857741: step 143550, loss = 0.27, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 8h:10m:44s remains)
INFO - root - 2017-12-01 08:52:43.422834: step 143560, loss = 0.33, batch loss = 0.24 (50.8 examples/sec; 0.157 sec/batch; 8h:15m:43s remains)
INFO - root - 2017-12-01 08:52:44.989283: step 143570, loss = 0.24, batch loss = 0.15 (51.4 examples/sec; 0.156 sec/batch; 8h:09m:48s remains)
INFO - root - 2017-12-01 08:52:46.569315: step 143580, loss = 0.25, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 8h:08m:13s remains)
INFO - root - 2017-12-01 08:52:48.164860: step 143590, loss = 0.27, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 8h:16m:49s remains)
INFO - root - 2017-12-01 08:52:49.710646: step 143600, loss = 0.28, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 8h:11m:56s remains)
INFO - root - 2017-12-01 08:52:51.335798: step 143610, loss = 0.32, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 8h:04m:55s remains)
INFO - root - 2017-12-01 08:52:52.897102: step 143620, loss = 0.37, batch loss = 0.29 (51.3 examples/sec; 0.156 sec/batch; 8h:11m:23s remains)
INFO - root - 2017-12-01 08:52:54.475002: step 143630, loss = 0.30, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 8h:10m:17s remains)
INFO - root - 2017-12-01 08:52:56.034489: step 143640, loss = 0.24, batch loss = 0.16 (51.8 examples/sec; 0.155 sec/batch; 8h:06m:21s remains)
INFO - root - 2017-12-01 08:52:57.592632: step 143650, loss = 0.26, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 8h:17m:17s remains)
INFO - root - 2017-12-01 08:52:59.177256: step 143660, loss = 0.30, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 8h:05m:09s remains)
INFO - root - 2017-12-01 08:53:00.763942: step 143670, loss = 0.29, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 8h:13m:40s remains)
INFO - root - 2017-12-01 08:53:02.340501: step 143680, loss = 0.27, batch loss = 0.18 (53.0 examples/sec; 0.151 sec/batch; 7h:54m:54s remains)
INFO - root - 2017-12-01 08:53:03.985120: step 143690, loss = 0.32, batch loss = 0.24 (50.8 examples/sec; 0.158 sec/batch; 8h:15m:43s remains)
INFO - root - 2017-12-01 08:53:05.555634: step 143700, loss = 0.25, batch loss = 0.17 (49.7 examples/sec; 0.161 sec/batch; 8h:26m:06s remains)
INFO - root - 2017-12-01 08:53:07.197444: step 143710, loss = 0.41, batch loss = 0.33 (52.4 examples/sec; 0.153 sec/batch; 8h:00m:36s remains)
INFO - root - 2017-12-01 08:53:08.740623: step 143720, loss = 0.34, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 8h:10m:52s remains)
INFO - root - 2017-12-01 08:53:10.301173: step 143730, loss = 0.27, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 8h:19m:53s remains)
INFO - root - 2017-12-01 08:53:11.854823: step 143740, loss = 0.44, batch loss = 0.35 (50.9 examples/sec; 0.157 sec/batch; 8h:14m:46s remains)
INFO - root - 2017-12-01 08:53:13.405127: step 143750, loss = 0.33, batch loss = 0.24 (52.4 examples/sec; 0.153 sec/batch; 8h:00m:01s remains)
INFO - root - 2017-12-01 08:53:14.975448: step 143760, loss = 0.38, batch loss = 0.29 (51.9 examples/sec; 0.154 sec/batch; 8h:04m:46s remains)
INFO - root - 2017-12-01 08:53:16.637030: step 143770, loss = 0.35, batch loss = 0.26 (44.8 examples/sec; 0.179 sec/batch; 9h:21m:35s remains)
INFO - root - 2017-12-01 08:53:18.211808: step 143780, loss = 0.23, batch loss = 0.15 (51.1 examples/sec; 0.156 sec/batch; 8h:12m:12s remains)
INFO - root - 2017-12-01 08:53:19.771347: step 143790, loss = 0.27, batch loss = 0.18 (50.5 examples/sec; 0.158 sec/batch; 8h:17m:49s remains)
INFO - root - 2017-12-01 08:53:21.326446: step 143800, loss = 0.40, batch loss = 0.32 (50.4 examples/sec; 0.159 sec/batch; 8h:19m:27s remains)
INFO - root - 2017-12-01 08:53:22.969634: step 143810, loss = 0.27, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 8h:06m:31s remains)
INFO - root - 2017-12-01 08:53:24.530957: step 143820, loss = 0.34, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 8h:14m:30s remains)
INFO - root - 2017-12-01 08:53:26.094476: step 143830, loss = 0.28, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 8h:09m:19s remains)
INFO - root - 2017-12-01 08:53:27.678669: step 143840, loss = 0.34, batch loss = 0.26 (52.4 examples/sec; 0.153 sec/batch; 7h:59m:36s remains)
INFO - root - 2017-12-01 08:53:29.239158: step 143850, loss = 0.28, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 7h:58m:31s remains)
INFO - root - 2017-12-01 08:53:30.806118: step 143860, loss = 0.27, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 8h:12m:55s remains)
INFO - root - 2017-12-01 08:53:32.363538: step 143870, loss = 0.33, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 8h:10m:07s remains)
INFO - root - 2017-12-01 08:53:33.921608: step 143880, loss = 0.27, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 8h:10m:17s remains)
INFO - root - 2017-12-01 08:53:35.460145: step 143890, loss = 0.25, batch loss = 0.16 (52.6 examples/sec; 0.152 sec/batch; 7h:58m:03s remains)
INFO - root - 2017-12-01 08:53:37.025017: step 143900, loss = 0.24, batch loss = 0.15 (53.2 examples/sec; 0.150 sec/batch; 7h:52m:14s remains)
INFO - root - 2017-12-01 08:53:38.644212: step 143910, loss = 0.33, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 8h:13m:38s remains)
INFO - root - 2017-12-01 08:53:40.216452: step 143920, loss = 0.28, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 8h:07m:45s remains)
INFO - root - 2017-12-01 08:53:41.759769: step 143930, loss = 0.26, batch loss = 0.18 (52.2 examples/sec; 0.153 sec/batch; 8h:01m:29s remains)
INFO - root - 2017-12-01 08:53:43.340898: step 143940, loss = 0.28, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 8h:10m:06s remains)
INFO - root - 2017-12-01 08:53:44.893942: step 143950, loss = 0.26, batch loss = 0.17 (53.1 examples/sec; 0.151 sec/batch; 7h:53m:21s remains)
INFO - root - 2017-12-01 08:53:46.440115: step 143960, loss = 0.28, batch loss = 0.19 (51.7 examples/sec; 0.155 sec/batch; 8h:06m:28s remains)
INFO - root - 2017-12-01 08:53:47.998920: step 143970, loss = 0.30, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 8h:15m:37s remains)
INFO - root - 2017-12-01 08:53:49.559320: step 143980, loss = 0.35, batch loss = 0.26 (50.4 examples/sec; 0.159 sec/batch; 8h:18m:46s remains)
INFO - root - 2017-12-01 08:53:51.133848: step 143990, loss = 0.32, batch loss = 0.23 (50.0 examples/sec; 0.160 sec/batch; 8h:22m:45s remains)
INFO - root - 2017-12-01 08:53:52.700822: step 144000, loss = 0.24, batch loss = 0.16 (50.8 examples/sec; 0.157 sec/batch; 8h:14m:32s remains)
INFO - root - 2017-12-01 08:53:54.316252: step 144010, loss = 0.27, batch loss = 0.18 (48.5 examples/sec; 0.165 sec/batch; 8h:38m:36s remains)
INFO - root - 2017-12-01 08:53:55.884703: step 144020, loss = 0.33, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 8h:16m:11s remains)
INFO - root - 2017-12-01 08:53:57.455005: step 144030, loss = 0.29, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 8h:12m:42s remains)
INFO - root - 2017-12-01 08:53:59.012527: step 144040, loss = 0.31, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 8h:01m:39s remains)
INFO - root - 2017-12-01 08:54:00.596018: step 144050, loss = 0.29, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 8h:15m:18s remains)
INFO - root - 2017-12-01 08:54:02.154106: step 144060, loss = 0.42, batch loss = 0.33 (51.0 examples/sec; 0.157 sec/batch; 8h:12m:56s remains)
INFO - root - 2017-12-01 08:54:03.713779: step 144070, loss = 0.32, batch loss = 0.23 (52.6 examples/sec; 0.152 sec/batch; 7h:57m:23s remains)
INFO - root - 2017-12-01 08:54:05.298957: step 144080, loss = 0.31, batch loss = 0.23 (48.5 examples/sec; 0.165 sec/batch; 8h:37m:59s remains)
INFO - root - 2017-12-01 08:54:06.867506: step 144090, loss = 0.27, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 8h:17m:38s remains)
INFO - root - 2017-12-01 08:54:08.428227: step 144100, loss = 0.21, batch loss = 0.13 (49.3 examples/sec; 0.162 sec/batch; 8h:29m:57s remains)
INFO - root - 2017-12-01 08:54:10.103377: step 144110, loss = 0.33, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 8h:19m:18s remains)
INFO - root - 2017-12-01 08:54:11.671257: step 144120, loss = 0.25, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 8h:04m:55s remains)
INFO - root - 2017-12-01 08:54:13.238180: step 144130, loss = 0.23, batch loss = 0.14 (50.7 examples/sec; 0.158 sec/batch; 8h:15m:30s remains)
INFO - root - 2017-12-01 08:54:14.790006: step 144140, loss = 0.24, batch loss = 0.15 (50.8 examples/sec; 0.157 sec/batch; 8h:13m:55s remains)
INFO - root - 2017-12-01 08:54:16.376197: step 144150, loss = 0.27, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 8h:12m:32s remains)
INFO - root - 2017-12-01 08:54:17.919649: step 144160, loss = 0.36, batch loss = 0.27 (52.1 examples/sec; 0.154 sec/batch; 8h:01m:55s remains)
INFO - root - 2017-12-01 08:54:19.475945: step 144170, loss = 0.30, batch loss = 0.22 (49.6 examples/sec; 0.161 sec/batch; 8h:25m:57s remains)
INFO - root - 2017-12-01 08:54:21.055413: step 144180, loss = 0.24, batch loss = 0.15 (47.3 examples/sec; 0.169 sec/batch; 8h:51m:01s remains)
INFO - root - 2017-12-01 08:54:22.659879: step 144190, loss = 0.22, batch loss = 0.13 (50.5 examples/sec; 0.159 sec/batch; 8h:17m:40s remains)
INFO - root - 2017-12-01 08:54:24.228266: step 144200, loss = 0.34, batch loss = 0.25 (49.4 examples/sec; 0.162 sec/batch; 8h:28m:11s remains)
INFO - root - 2017-12-01 08:54:25.872547: step 144210, loss = 0.37, batch loss = 0.28 (51.6 examples/sec; 0.155 sec/batch; 8h:06m:32s remains)
INFO - root - 2017-12-01 08:54:27.475312: step 144220, loss = 0.26, batch loss = 0.17 (48.8 examples/sec; 0.164 sec/batch; 8h:34m:15s remains)
INFO - root - 2017-12-01 08:54:29.032977: step 144230, loss = 0.42, batch loss = 0.33 (51.4 examples/sec; 0.156 sec/batch; 8h:07m:56s remains)
INFO - root - 2017-12-01 08:54:30.603194: step 144240, loss = 0.27, batch loss = 0.19 (50.3 examples/sec; 0.159 sec/batch; 8h:19m:22s remains)
INFO - root - 2017-12-01 08:54:32.166761: step 144250, loss = 0.32, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 8h:11m:58s remains)
INFO - root - 2017-12-01 08:54:33.739916: step 144260, loss = 0.28, batch loss = 0.19 (50.5 examples/sec; 0.158 sec/batch; 8h:17m:02s remains)
INFO - root - 2017-12-01 08:54:35.289700: step 144270, loss = 0.33, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 7h:57m:31s remains)
INFO - root - 2017-12-01 08:54:36.854731: step 144280, loss = 0.33, batch loss = 0.25 (50.5 examples/sec; 0.158 sec/batch; 8h:17m:04s remains)
INFO - root - 2017-12-01 08:54:38.428979: step 144290, loss = 0.25, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 8h:12m:45s remains)
INFO - root - 2017-12-01 08:54:39.992713: step 144300, loss = 0.28, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 8h:18m:20s remains)
INFO - root - 2017-12-01 08:54:41.647469: step 144310, loss = 0.27, batch loss = 0.18 (52.5 examples/sec; 0.152 sec/batch; 7h:57m:32s remains)
INFO - root - 2017-12-01 08:54:43.214396: step 144320, loss = 0.29, batch loss = 0.21 (50.2 examples/sec; 0.159 sec/batch; 8h:19m:35s remains)
INFO - root - 2017-12-01 08:54:44.769170: step 144330, loss = 0.28, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 8h:09m:10s remains)
INFO - root - 2017-12-01 08:54:46.344546: step 144340, loss = 0.29, batch loss = 0.20 (48.7 examples/sec; 0.164 sec/batch; 8h:35m:22s remains)
INFO - root - 2017-12-01 08:54:47.904559: step 144350, loss = 0.31, batch loss = 0.22 (52.8 examples/sec; 0.151 sec/batch; 7h:54m:44s remains)
INFO - root - 2017-12-01 08:54:49.454141: step 144360, loss = 0.43, batch loss = 0.34 (52.8 examples/sec; 0.151 sec/batch; 7h:54m:52s remains)
INFO - root - 2017-12-01 08:54:51.041717: step 144370, loss = 0.39, batch loss = 0.31 (51.4 examples/sec; 0.156 sec/batch; 8h:08m:06s remains)
INFO - root - 2017-12-01 08:54:52.601485: step 144380, loss = 0.29, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 8h:12m:28s remains)
INFO - root - 2017-12-01 08:54:54.152847: step 144390, loss = 0.30, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 8h:09m:50s remains)
INFO - root - 2017-12-01 08:54:55.722585: step 144400, loss = 0.24, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 8h:09m:04s remains)
INFO - root - 2017-12-01 08:54:57.375473: step 144410, loss = 0.25, batch loss = 0.16 (49.6 examples/sec; 0.161 sec/batch; 8h:25m:56s remains)
INFO - root - 2017-12-01 08:54:58.950781: step 144420, loss = 0.29, batch loss = 0.20 (53.1 examples/sec; 0.151 sec/batch; 7h:52m:25s remains)
INFO - root - 2017-12-01 08:55:00.506551: step 144430, loss = 0.33, batch loss = 0.24 (52.2 examples/sec; 0.153 sec/batch; 8h:00m:00s remains)
INFO - root - 2017-12-01 08:55:02.080948: step 144440, loss = 0.31, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 8h:14m:03s remains)
INFO - root - 2017-12-01 08:55:03.642866: step 144450, loss = 0.27, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 8h:12m:55s remains)
INFO - root - 2017-12-01 08:55:05.204810: step 144460, loss = 0.24, batch loss = 0.16 (51.0 examples/sec; 0.157 sec/batch; 8h:11m:29s remains)
INFO - root - 2017-12-01 08:55:06.768619: step 144470, loss = 0.33, batch loss = 0.25 (51.7 examples/sec; 0.155 sec/batch; 8h:05m:21s remains)
INFO - root - 2017-12-01 08:55:08.338716: step 144480, loss = 0.25, batch loss = 0.16 (53.0 examples/sec; 0.151 sec/batch; 7h:53m:05s remains)
INFO - root - 2017-12-01 08:55:09.898662: step 144490, loss = 0.34, batch loss = 0.26 (51.9 examples/sec; 0.154 sec/batch; 8h:03m:25s remains)
INFO - root - 2017-12-01 08:55:11.476624: step 144500, loss = 0.29, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 8h:18m:18s remains)
INFO - root - 2017-12-01 08:55:13.124308: step 144510, loss = 0.30, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 8h:05m:01s remains)
INFO - root - 2017-12-01 08:55:14.716265: step 144520, loss = 0.28, batch loss = 0.20 (48.9 examples/sec; 0.163 sec/batch; 8h:32m:10s remains)
INFO - root - 2017-12-01 08:55:16.264026: step 144530, loss = 0.31, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 8h:12m:11s remains)
INFO - root - 2017-12-01 08:55:17.829618: step 144540, loss = 0.24, batch loss = 0.15 (50.1 examples/sec; 0.160 sec/batch; 8h:20m:34s remains)
INFO - root - 2017-12-01 08:55:19.404731: step 144550, loss = 0.28, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 8h:12m:32s remains)
INFO - root - 2017-12-01 08:55:20.963122: step 144560, loss = 0.28, batch loss = 0.19 (52.5 examples/sec; 0.152 sec/batch; 7h:56m:54s remains)
INFO - root - 2017-12-01 08:55:22.536591: step 144570, loss = 0.26, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 8h:06m:49s remains)
INFO - root - 2017-12-01 08:55:24.093913: step 144580, loss = 0.25, batch loss = 0.17 (50.1 examples/sec; 0.160 sec/batch; 8h:20m:06s remains)
INFO - root - 2017-12-01 08:55:25.671163: step 144590, loss = 0.21, batch loss = 0.12 (50.5 examples/sec; 0.158 sec/batch; 8h:16m:07s remains)
INFO - root - 2017-12-01 08:55:27.234327: step 144600, loss = 0.34, batch loss = 0.25 (51.2 examples/sec; 0.156 sec/batch; 8h:09m:09s remains)
INFO - root - 2017-12-01 08:55:28.861647: step 144610, loss = 0.26, batch loss = 0.18 (51.8 examples/sec; 0.155 sec/batch; 8h:03m:51s remains)
INFO - root - 2017-12-01 08:55:30.439147: step 144620, loss = 0.29, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 8h:05m:19s remains)
INFO - root - 2017-12-01 08:55:32.002096: step 144630, loss = 0.31, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 8h:11m:53s remains)
INFO - root - 2017-12-01 08:55:33.577600: step 144640, loss = 0.25, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 8h:12m:21s remains)
INFO - root - 2017-12-01 08:55:35.137116: step 144650, loss = 0.33, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 8h:04m:01s remains)
INFO - root - 2017-12-01 08:55:36.694652: step 144660, loss = 0.26, batch loss = 0.17 (51.1 examples/sec; 0.156 sec/batch; 8h:09m:56s remains)
INFO - root - 2017-12-01 08:55:38.273082: step 144670, loss = 0.28, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 8h:20m:55s remains)
INFO - root - 2017-12-01 08:55:39.848437: step 144680, loss = 0.23, batch loss = 0.14 (51.8 examples/sec; 0.154 sec/batch; 8h:03m:02s remains)
INFO - root - 2017-12-01 08:55:41.406512: step 144690, loss = 0.29, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 8h:07m:12s remains)
INFO - root - 2017-12-01 08:55:42.969364: step 144700, loss = 0.37, batch loss = 0.28 (53.1 examples/sec; 0.151 sec/batch; 7h:51m:24s remains)
INFO - root - 2017-12-01 08:55:44.581499: step 144710, loss = 0.24, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 8h:14m:13s remains)
INFO - root - 2017-12-01 08:55:46.142444: step 144720, loss = 0.51, batch loss = 0.42 (50.8 examples/sec; 0.158 sec/batch; 8h:13m:06s remains)
INFO - root - 2017-12-01 08:55:47.704174: step 144730, loss = 0.24, batch loss = 0.16 (49.8 examples/sec; 0.160 sec/batch; 8h:22m:16s remains)
INFO - root - 2017-12-01 08:55:49.278430: step 144740, loss = 0.29, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 7h:58m:40s remains)
INFO - root - 2017-12-01 08:55:50.833586: step 144750, loss = 0.32, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 8h:12m:11s remains)
INFO - root - 2017-12-01 08:55:52.399666: step 144760, loss = 0.25, batch loss = 0.16 (51.1 examples/sec; 0.156 sec/batch; 8h:09m:40s remains)
INFO - root - 2017-12-01 08:55:53.963711: step 144770, loss = 0.30, batch loss = 0.21 (50.1 examples/sec; 0.160 sec/batch; 8h:19m:38s remains)
INFO - root - 2017-12-01 08:55:55.537777: step 144780, loss = 0.27, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 8h:09m:13s remains)
INFO - root - 2017-12-01 08:55:57.098165: step 144790, loss = 0.29, batch loss = 0.21 (53.0 examples/sec; 0.151 sec/batch; 7h:52m:20s remains)
INFO - root - 2017-12-01 08:55:58.670868: step 144800, loss = 0.31, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 8h:00m:48s remains)
INFO - root - 2017-12-01 08:56:00.274244: step 144810, loss = 0.30, batch loss = 0.21 (52.9 examples/sec; 0.151 sec/batch; 7h:53m:30s remains)
INFO - root - 2017-12-01 08:56:01.832896: step 144820, loss = 0.28, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 8h:05m:08s remains)
INFO - root - 2017-12-01 08:56:03.411808: step 144830, loss = 0.26, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 8h:17m:19s remains)
INFO - root - 2017-12-01 08:56:04.974499: step 144840, loss = 0.34, batch loss = 0.26 (51.0 examples/sec; 0.157 sec/batch; 8h:10m:33s remains)
INFO - root - 2017-12-01 08:56:06.537283: step 144850, loss = 0.26, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 8h:01m:06s remains)
INFO - root - 2017-12-01 08:56:08.095226: step 144860, loss = 0.26, batch loss = 0.17 (49.7 examples/sec; 0.161 sec/batch; 8h:23m:04s remains)
INFO - root - 2017-12-01 08:56:09.659018: step 144870, loss = 0.26, batch loss = 0.17 (51.8 examples/sec; 0.154 sec/batch; 8h:03m:01s remains)
INFO - root - 2017-12-01 08:56:11.233474: step 144880, loss = 0.30, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 8h:04m:22s remains)
INFO - root - 2017-12-01 08:56:12.801015: step 144890, loss = 0.31, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 8h:11m:07s remains)
INFO - root - 2017-12-01 08:56:14.376770: step 144900, loss = 0.56, batch loss = 0.48 (50.6 examples/sec; 0.158 sec/batch; 8h:14m:36s remains)
INFO - root - 2017-12-01 08:56:15.986575: step 144910, loss = 0.42, batch loss = 0.33 (50.9 examples/sec; 0.157 sec/batch; 8h:10m:58s remains)
INFO - root - 2017-12-01 08:56:17.542825: step 144920, loss = 0.29, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 7h:57m:16s remains)
INFO - root - 2017-12-01 08:56:19.096226: step 144930, loss = 0.27, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 8h:04m:49s remains)
INFO - root - 2017-12-01 08:56:20.665637: step 144940, loss = 0.26, batch loss = 0.18 (49.8 examples/sec; 0.161 sec/batch; 8h:21m:55s remains)
INFO - root - 2017-12-01 08:56:22.227776: step 144950, loss = 0.41, batch loss = 0.32 (48.4 examples/sec; 0.165 sec/batch; 8h:36m:22s remains)
INFO - root - 2017-12-01 08:56:23.807927: step 144960, loss = 0.30, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 8h:04m:29s remains)
INFO - root - 2017-12-01 08:56:25.364601: step 144970, loss = 0.36, batch loss = 0.27 (49.9 examples/sec; 0.160 sec/batch; 8h:21m:04s remains)
INFO - root - 2017-12-01 08:56:26.939657: step 144980, loss = 0.26, batch loss = 0.17 (50.7 examples/sec; 0.158 sec/batch; 8h:13m:26s remains)
INFO - root - 2017-12-01 08:56:28.498872: step 144990, loss = 0.29, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 7h:59m:59s remains)
INFO - root - 2017-12-01 08:56:30.062245: step 145000, loss = 0.30, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 8h:02m:17s remains)
INFO - root - 2017-12-01 08:56:31.682498: step 145010, loss = 0.28, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 8h:13m:52s remains)
INFO - root - 2017-12-01 08:56:33.248327: step 145020, loss = 0.33, batch loss = 0.25 (49.4 examples/sec; 0.162 sec/batch; 8h:26m:11s remains)
INFO - root - 2017-12-01 08:56:34.808510: step 145030, loss = 0.31, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 8h:02m:11s remains)
INFO - root - 2017-12-01 08:56:36.369484: step 145040, loss = 0.41, batch loss = 0.32 (49.1 examples/sec; 0.163 sec/batch; 8h:28m:42s remains)
INFO - root - 2017-12-01 08:56:37.946724: step 145050, loss = 0.29, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 8h:05m:09s remains)
INFO - root - 2017-12-01 08:56:39.533316: step 145060, loss = 0.31, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 8h:17m:01s remains)
INFO - root - 2017-12-01 08:56:41.115047: step 145070, loss = 0.36, batch loss = 0.27 (49.0 examples/sec; 0.163 sec/batch; 8h:30m:29s remains)
INFO - root - 2017-12-01 08:56:42.683902: step 145080, loss = 0.28, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 8h:04m:53s remains)
INFO - root - 2017-12-01 08:56:44.258253: step 145090, loss = 0.36, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 8h:08m:25s remains)
INFO - root - 2017-12-01 08:56:45.816645: step 145100, loss = 0.29, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 8h:14m:15s remains)
INFO - root - 2017-12-01 08:56:47.459102: step 145110, loss = 0.35, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 8h:03m:17s remains)
INFO - root - 2017-12-01 08:56:49.032569: step 145120, loss = 0.22, batch loss = 0.14 (51.2 examples/sec; 0.156 sec/batch; 8h:07m:34s remains)
INFO - root - 2017-12-01 08:56:50.604670: step 145130, loss = 0.26, batch loss = 0.17 (49.8 examples/sec; 0.161 sec/batch; 8h:21m:40s remains)
INFO - root - 2017-12-01 08:56:52.159338: step 145140, loss = 0.31, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 8h:01m:50s remains)
INFO - root - 2017-12-01 08:56:53.730284: step 145150, loss = 0.37, batch loss = 0.29 (50.3 examples/sec; 0.159 sec/batch; 8h:17m:04s remains)
INFO - root - 2017-12-01 08:56:55.300390: step 145160, loss = 0.27, batch loss = 0.18 (52.4 examples/sec; 0.153 sec/batch; 7h:57m:07s remains)
INFO - root - 2017-12-01 08:56:56.865012: step 145170, loss = 0.28, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 8h:13m:49s remains)
INFO - root - 2017-12-01 08:56:58.412277: step 145180, loss = 0.26, batch loss = 0.17 (50.1 examples/sec; 0.160 sec/batch; 8h:18m:44s remains)
INFO - root - 2017-12-01 08:56:59.982250: step 145190, loss = 0.33, batch loss = 0.25 (51.8 examples/sec; 0.154 sec/batch; 8h:01m:51s remains)
INFO - root - 2017-12-01 08:57:01.567791: step 145200, loss = 0.24, batch loss = 0.15 (51.6 examples/sec; 0.155 sec/batch; 8h:03m:38s remains)
INFO - root - 2017-12-01 08:57:03.165994: step 145210, loss = 0.51, batch loss = 0.42 (52.2 examples/sec; 0.153 sec/batch; 7h:57m:57s remains)
INFO - root - 2017-12-01 08:57:04.723395: step 145220, loss = 0.32, batch loss = 0.24 (53.3 examples/sec; 0.150 sec/batch; 7h:48m:15s remains)
INFO - root - 2017-12-01 08:57:06.305884: step 145230, loss = 0.29, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 8h:00m:32s remains)
INFO - root - 2017-12-01 08:57:07.882126: step 145240, loss = 0.31, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 8h:08m:57s remains)
INFO - root - 2017-12-01 08:57:09.445749: step 145250, loss = 0.25, batch loss = 0.16 (50.6 examples/sec; 0.158 sec/batch; 8h:13m:04s remains)
INFO - root - 2017-12-01 08:57:11.018879: step 145260, loss = 0.26, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 8h:13m:58s remains)
INFO - root - 2017-12-01 08:57:12.592469: step 145270, loss = 0.23, batch loss = 0.14 (52.0 examples/sec; 0.154 sec/batch; 8h:00m:18s remains)
INFO - root - 2017-12-01 08:57:14.236749: step 145280, loss = 0.29, batch loss = 0.20 (48.7 examples/sec; 0.164 sec/batch; 8h:33m:06s remains)
INFO - root - 2017-12-01 08:57:15.797043: step 145290, loss = 0.35, batch loss = 0.26 (52.5 examples/sec; 0.153 sec/batch; 7h:55m:49s remains)
INFO - root - 2017-12-01 08:57:17.400644: step 145300, loss = 0.35, batch loss = 0.26 (49.4 examples/sec; 0.162 sec/batch; 8h:24m:59s remains)
INFO - root - 2017-12-01 08:57:19.082701: step 145310, loss = 0.38, batch loss = 0.30 (52.3 examples/sec; 0.153 sec/batch; 7h:57m:27s remains)
INFO - root - 2017-12-01 08:57:20.658458: step 145320, loss = 0.24, batch loss = 0.15 (50.0 examples/sec; 0.160 sec/batch; 8h:19m:29s remains)
INFO - root - 2017-12-01 08:57:22.205230: step 145330, loss = 0.44, batch loss = 0.35 (49.8 examples/sec; 0.161 sec/batch; 8h:21m:20s remains)
INFO - root - 2017-12-01 08:57:23.763380: step 145340, loss = 0.23, batch loss = 0.15 (52.3 examples/sec; 0.153 sec/batch; 7h:56m:51s remains)
INFO - root - 2017-12-01 08:57:25.343088: step 145350, loss = 0.27, batch loss = 0.18 (50.1 examples/sec; 0.160 sec/batch; 8h:17m:52s remains)
INFO - root - 2017-12-01 08:57:26.903754: step 145360, loss = 0.27, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 8h:02m:41s remains)
INFO - root - 2017-12-01 08:57:28.458514: step 145370, loss = 0.28, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 8h:07m:43s remains)
INFO - root - 2017-12-01 08:57:30.010851: step 145380, loss = 0.30, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 8h:09m:14s remains)
INFO - root - 2017-12-01 08:57:31.563857: step 145390, loss = 0.28, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 8h:03m:57s remains)
INFO - root - 2017-12-01 08:57:33.148811: step 145400, loss = 0.31, batch loss = 0.23 (52.5 examples/sec; 0.152 sec/batch; 7h:54m:44s remains)
INFO - root - 2017-12-01 08:57:34.763056: step 145410, loss = 0.23, batch loss = 0.15 (50.8 examples/sec; 0.158 sec/batch; 8h:11m:24s remains)
INFO - root - 2017-12-01 08:57:36.311861: step 145420, loss = 0.26, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 8h:00m:04s remains)
INFO - root - 2017-12-01 08:57:37.877450: step 145430, loss = 0.32, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 8h:09m:41s remains)
INFO - root - 2017-12-01 08:57:39.448282: step 145440, loss = 0.23, batch loss = 0.14 (50.7 examples/sec; 0.158 sec/batch; 8h:12m:04s remains)
INFO - root - 2017-12-01 08:57:41.008475: step 145450, loss = 0.25, batch loss = 0.17 (52.4 examples/sec; 0.153 sec/batch; 7h:56m:01s remains)
INFO - root - 2017-12-01 08:57:42.569820: step 145460, loss = 0.31, batch loss = 0.22 (50.4 examples/sec; 0.159 sec/batch; 8h:14m:36s remains)
INFO - root - 2017-12-01 08:57:44.134361: step 145470, loss = 0.26, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 8h:10m:20s remains)
INFO - root - 2017-12-01 08:57:45.687666: step 145480, loss = 0.34, batch loss = 0.26 (49.9 examples/sec; 0.160 sec/batch; 8h:19m:22s remains)
INFO - root - 2017-12-01 08:57:47.250743: step 145490, loss = 0.27, batch loss = 0.19 (53.1 examples/sec; 0.151 sec/batch; 7h:49m:45s remains)
INFO - root - 2017-12-01 08:57:48.828005: step 145500, loss = 0.31, batch loss = 0.23 (52.5 examples/sec; 0.152 sec/batch; 7h:54m:36s remains)
INFO - root - 2017-12-01 08:57:50.439788: step 145510, loss = 0.26, batch loss = 0.17 (50.0 examples/sec; 0.160 sec/batch; 8h:18m:12s remains)
INFO - root - 2017-12-01 08:57:52.003447: step 145520, loss = 0.23, batch loss = 0.14 (49.3 examples/sec; 0.162 sec/batch; 8h:25m:53s remains)
INFO - root - 2017-12-01 08:57:53.568993: step 145530, loss = 0.36, batch loss = 0.27 (53.0 examples/sec; 0.151 sec/batch; 7h:49m:57s remains)
INFO - root - 2017-12-01 08:57:55.134080: step 145540, loss = 0.26, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 8h:09m:39s remains)
INFO - root - 2017-12-01 08:57:56.721680: step 145550, loss = 0.33, batch loss = 0.25 (49.1 examples/sec; 0.163 sec/batch; 8h:27m:40s remains)
INFO - root - 2017-12-01 08:57:58.285058: step 145560, loss = 0.35, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 8h:09m:37s remains)
INFO - root - 2017-12-01 08:57:59.827155: step 145570, loss = 0.35, batch loss = 0.27 (50.2 examples/sec; 0.159 sec/batch; 8h:16m:18s remains)
INFO - root - 2017-12-01 08:58:01.395644: step 145580, loss = 0.40, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 8h:09m:23s remains)
INFO - root - 2017-12-01 08:58:02.967598: step 145590, loss = 0.24, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 8h:06m:48s remains)
INFO - root - 2017-12-01 08:58:04.532238: step 145600, loss = 0.27, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 8h:04m:02s remains)
INFO - root - 2017-12-01 08:58:06.163912: step 145610, loss = 0.25, batch loss = 0.16 (52.0 examples/sec; 0.154 sec/batch; 7h:59m:23s remains)
INFO - root - 2017-12-01 08:58:07.725869: step 145620, loss = 0.23, batch loss = 0.14 (50.6 examples/sec; 0.158 sec/batch; 8h:12m:28s remains)
INFO - root - 2017-12-01 08:58:09.288052: step 145630, loss = 0.23, batch loss = 0.14 (50.5 examples/sec; 0.158 sec/batch; 8h:13m:33s remains)
INFO - root - 2017-12-01 08:58:10.832178: step 145640, loss = 0.30, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 8h:08m:31s remains)
INFO - root - 2017-12-01 08:58:12.384417: step 145650, loss = 0.29, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 8h:02m:30s remains)
INFO - root - 2017-12-01 08:58:13.948072: step 145660, loss = 0.29, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 8h:11m:32s remains)
INFO - root - 2017-12-01 08:58:15.517627: step 145670, loss = 0.35, batch loss = 0.26 (49.9 examples/sec; 0.160 sec/batch; 8h:19m:36s remains)
INFO - root - 2017-12-01 08:58:17.069430: step 145680, loss = 0.31, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 8h:07m:23s remains)
INFO - root - 2017-12-01 08:58:18.632094: step 145690, loss = 0.25, batch loss = 0.17 (49.6 examples/sec; 0.161 sec/batch; 8h:22m:26s remains)
INFO - root - 2017-12-01 08:58:20.186362: step 145700, loss = 0.31, batch loss = 0.22 (50.8 examples/sec; 0.157 sec/batch; 8h:10m:12s remains)
INFO - root - 2017-12-01 08:58:21.836886: step 145710, loss = 0.25, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 8h:09m:08s remains)
INFO - root - 2017-12-01 08:58:23.404980: step 145720, loss = 0.27, batch loss = 0.18 (50.1 examples/sec; 0.160 sec/batch; 8h:17m:05s remains)
INFO - root - 2017-12-01 08:58:24.976895: step 145730, loss = 0.31, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 8h:03m:58s remains)
INFO - root - 2017-12-01 08:58:26.550958: step 145740, loss = 0.24, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 8h:04m:09s remains)
INFO - root - 2017-12-01 08:58:28.136424: step 145750, loss = 0.27, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 8h:05m:17s remains)
INFO - root - 2017-12-01 08:58:29.698039: step 145760, loss = 0.22, batch loss = 0.14 (51.8 examples/sec; 0.154 sec/batch; 8h:00m:26s remains)
INFO - root - 2017-12-01 08:58:31.249275: step 145770, loss = 0.27, batch loss = 0.18 (52.3 examples/sec; 0.153 sec/batch; 7h:56m:27s remains)
INFO - root - 2017-12-01 08:58:32.823281: step 145780, loss = 0.27, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 8h:04m:58s remains)
INFO - root - 2017-12-01 08:58:34.376430: step 145790, loss = 0.29, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 8h:00m:02s remains)
INFO - root - 2017-12-01 08:58:35.929400: step 145800, loss = 0.31, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 8h:12m:09s remains)
INFO - root - 2017-12-01 08:58:37.542423: step 145810, loss = 0.36, batch loss = 0.27 (51.9 examples/sec; 0.154 sec/batch; 7h:59m:46s remains)
INFO - root - 2017-12-01 08:58:39.092306: step 145820, loss = 0.29, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 7h:57m:02s remains)
INFO - root - 2017-12-01 08:58:40.674509: step 145830, loss = 0.31, batch loss = 0.22 (50.5 examples/sec; 0.158 sec/batch; 8h:12m:33s remains)
INFO - root - 2017-12-01 08:58:42.234353: step 145840, loss = 0.23, batch loss = 0.15 (50.8 examples/sec; 0.157 sec/batch; 8h:09m:43s remains)
INFO - root - 2017-12-01 08:58:43.796464: step 145850, loss = 0.29, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 8h:06m:16s remains)
INFO - root - 2017-12-01 08:58:45.368762: step 145860, loss = 0.27, batch loss = 0.19 (47.1 examples/sec; 0.170 sec/batch; 8h:48m:18s remains)
INFO - root - 2017-12-01 08:58:46.938841: step 145870, loss = 0.26, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 8h:04m:01s remains)
INFO - root - 2017-12-01 08:58:48.496288: step 145880, loss = 0.33, batch loss = 0.25 (52.1 examples/sec; 0.154 sec/batch; 7h:57m:49s remains)
INFO - root - 2017-12-01 08:58:50.068379: step 145890, loss = 0.25, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 8h:06m:17s remains)
INFO - root - 2017-12-01 08:58:51.628994: step 145900, loss = 0.33, batch loss = 0.24 (49.2 examples/sec; 0.162 sec/batch; 8h:25m:22s remains)
INFO - root - 2017-12-01 08:58:53.275497: step 145910, loss = 0.26, batch loss = 0.17 (50.8 examples/sec; 0.158 sec/batch; 8h:10m:10s remains)
INFO - root - 2017-12-01 08:58:54.836356: step 145920, loss = 0.26, batch loss = 0.17 (49.5 examples/sec; 0.161 sec/batch; 8h:22m:10s remains)
INFO - root - 2017-12-01 08:58:56.398567: step 145930, loss = 0.37, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 8h:05m:38s remains)
INFO - root - 2017-12-01 08:58:57.957009: step 145940, loss = 0.23, batch loss = 0.14 (53.5 examples/sec; 0.150 sec/batch; 7h:45m:22s remains)
INFO - root - 2017-12-01 08:58:59.535083: step 145950, loss = 0.25, batch loss = 0.17 (52.3 examples/sec; 0.153 sec/batch; 7h:55m:53s remains)
INFO - root - 2017-12-01 08:59:01.112732: step 145960, loss = 0.50, batch loss = 0.41 (51.2 examples/sec; 0.156 sec/batch; 8h:05m:38s remains)
INFO - root - 2017-12-01 08:59:02.672108: step 145970, loss = 0.39, batch loss = 0.31 (51.0 examples/sec; 0.157 sec/batch; 8h:07m:15s remains)
INFO - root - 2017-12-01 08:59:04.240235: step 145980, loss = 0.40, batch loss = 0.32 (51.4 examples/sec; 0.156 sec/batch; 8h:04m:04s remains)
INFO - root - 2017-12-01 08:59:05.838658: step 145990, loss = 0.34, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 8h:02m:10s remains)
INFO - root - 2017-12-01 08:59:07.390430: step 146000, loss = 0.24, batch loss = 0.15 (49.3 examples/sec; 0.162 sec/batch; 8h:24m:17s remains)
INFO - root - 2017-12-01 08:59:09.045623: step 146010, loss = 0.29, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 8h:10m:57s remains)
INFO - root - 2017-12-01 08:59:10.624056: step 146020, loss = 0.30, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 8h:10m:21s remains)
INFO - root - 2017-12-01 08:59:12.185023: step 146030, loss = 0.24, batch loss = 0.15 (52.7 examples/sec; 0.152 sec/batch; 7h:51m:49s remains)
INFO - root - 2017-12-01 08:59:13.741385: step 146040, loss = 0.34, batch loss = 0.25 (51.1 examples/sec; 0.156 sec/batch; 8h:06m:10s remains)
INFO - root - 2017-12-01 08:59:15.331028: step 146050, loss = 0.26, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 8h:10m:07s remains)
INFO - root - 2017-12-01 08:59:16.901162: step 146060, loss = 0.30, batch loss = 0.21 (50.8 examples/sec; 0.158 sec/batch; 8h:09m:48s remains)
INFO - root - 2017-12-01 08:59:18.459407: step 146070, loss = 0.29, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 8h:02m:09s remains)
INFO - root - 2017-12-01 08:59:20.016072: step 146080, loss = 0.28, batch loss = 0.19 (49.7 examples/sec; 0.161 sec/batch; 8h:19m:45s remains)
INFO - root - 2017-12-01 08:59:21.597666: step 146090, loss = 0.30, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 8h:10m:47s remains)
INFO - root - 2017-12-01 08:59:23.141174: step 146100, loss = 0.24, batch loss = 0.15 (51.8 examples/sec; 0.155 sec/batch; 8h:00m:03s remains)
INFO - root - 2017-12-01 08:59:24.779052: step 146110, loss = 0.24, batch loss = 0.16 (49.6 examples/sec; 0.161 sec/batch; 8h:20m:36s remains)
INFO - root - 2017-12-01 08:59:26.368677: step 146120, loss = 0.28, batch loss = 0.20 (50.6 examples/sec; 0.158 sec/batch; 8h:10m:59s remains)
INFO - root - 2017-12-01 08:59:27.924185: step 146130, loss = 0.47, batch loss = 0.38 (49.5 examples/sec; 0.161 sec/batch; 8h:21m:32s remains)
INFO - root - 2017-12-01 08:59:29.493607: step 146140, loss = 0.27, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 8h:08m:37s remains)
INFO - root - 2017-12-01 08:59:31.050101: step 146150, loss = 0.27, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 7h:58m:16s remains)
INFO - root - 2017-12-01 08:59:32.605657: step 146160, loss = 0.41, batch loss = 0.32 (51.8 examples/sec; 0.154 sec/batch; 7h:59m:11s remains)
INFO - root - 2017-12-01 08:59:34.172648: step 146170, loss = 0.27, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 8h:04m:14s remains)
INFO - root - 2017-12-01 08:59:35.741462: step 146180, loss = 0.46, batch loss = 0.37 (52.5 examples/sec; 0.152 sec/batch; 7h:53m:03s remains)
INFO - root - 2017-12-01 08:59:37.333394: step 146190, loss = 0.28, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 8h:17m:24s remains)
INFO - root - 2017-12-01 08:59:38.889924: step 146200, loss = 0.30, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 8h:11m:26s remains)
INFO - root - 2017-12-01 08:59:40.553512: step 146210, loss = 0.46, batch loss = 0.37 (51.3 examples/sec; 0.156 sec/batch; 8h:03m:48s remains)
INFO - root - 2017-12-01 08:59:42.114204: step 146220, loss = 0.32, batch loss = 0.23 (51.2 examples/sec; 0.156 sec/batch; 8h:04m:49s remains)
INFO - root - 2017-12-01 08:59:43.678668: step 146230, loss = 0.42, batch loss = 0.33 (48.8 examples/sec; 0.164 sec/batch; 8h:29m:17s remains)
INFO - root - 2017-12-01 08:59:45.241013: step 146240, loss = 0.27, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 8h:08m:32s remains)
INFO - root - 2017-12-01 08:59:46.816215: step 146250, loss = 0.24, batch loss = 0.15 (50.7 examples/sec; 0.158 sec/batch; 8h:09m:22s remains)
INFO - root - 2017-12-01 08:59:48.379049: step 146260, loss = 0.29, batch loss = 0.20 (49.8 examples/sec; 0.161 sec/batch; 8h:18m:39s remains)
INFO - root - 2017-12-01 08:59:49.939457: step 146270, loss = 0.31, batch loss = 0.22 (51.3 examples/sec; 0.156 sec/batch; 8h:04m:09s remains)
INFO - root - 2017-12-01 08:59:51.493841: step 146280, loss = 0.33, batch loss = 0.25 (52.9 examples/sec; 0.151 sec/batch; 7h:49m:46s remains)
INFO - root - 2017-12-01 08:59:53.066081: step 146290, loss = 0.35, batch loss = 0.26 (50.8 examples/sec; 0.158 sec/batch; 8h:08m:57s remains)
INFO - root - 2017-12-01 08:59:54.613401: step 146300, loss = 0.27, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 7h:53m:56s remains)
INFO - root - 2017-12-01 08:59:56.277145: step 146310, loss = 0.25, batch loss = 0.16 (52.2 examples/sec; 0.153 sec/batch; 7h:55m:24s remains)
INFO - root - 2017-12-01 08:59:57.834222: step 146320, loss = 0.28, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 7h:54m:53s remains)
INFO - root - 2017-12-01 08:59:59.389402: step 146330, loss = 0.26, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 8h:04m:52s remains)
INFO - root - 2017-12-01 09:00:00.960892: step 146340, loss = 0.31, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 8h:14m:08s remains)
INFO - root - 2017-12-01 09:00:02.525294: step 146350, loss = 0.29, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 8h:03m:53s remains)
INFO - root - 2017-12-01 09:00:04.099401: step 146360, loss = 0.27, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 8h:09m:22s remains)
INFO - root - 2017-12-01 09:00:05.670898: step 146370, loss = 0.24, batch loss = 0.16 (47.2 examples/sec; 0.169 sec/batch; 8h:45m:30s remains)
INFO - root - 2017-12-01 09:00:07.226959: step 146380, loss = 0.26, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 8h:02m:19s remains)
INFO - root - 2017-12-01 09:00:08.781515: step 146390, loss = 0.27, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 7h:59m:13s remains)
INFO - root - 2017-12-01 09:00:10.349639: step 146400, loss = 0.27, batch loss = 0.18 (51.8 examples/sec; 0.155 sec/batch; 7h:59m:23s remains)
INFO - root - 2017-12-01 09:00:11.974428: step 146410, loss = 0.26, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 8h:07m:26s remains)
INFO - root - 2017-12-01 09:00:13.539948: step 146420, loss = 0.27, batch loss = 0.19 (50.3 examples/sec; 0.159 sec/batch; 8h:13m:13s remains)
INFO - root - 2017-12-01 09:00:15.105472: step 146430, loss = 0.29, batch loss = 0.21 (52.5 examples/sec; 0.152 sec/batch; 7h:52m:36s remains)
INFO - root - 2017-12-01 09:00:16.679821: step 146440, loss = 0.29, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 8h:02m:43s remains)
INFO - root - 2017-12-01 09:00:18.255826: step 146450, loss = 0.32, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 8h:06m:52s remains)
INFO - root - 2017-12-01 09:00:19.837317: step 146460, loss = 0.22, batch loss = 0.14 (51.2 examples/sec; 0.156 sec/batch; 8h:04m:25s remains)
INFO - root - 2017-12-01 09:00:21.418318: step 146470, loss = 0.24, batch loss = 0.16 (52.4 examples/sec; 0.153 sec/batch; 7h:53m:42s remains)
INFO - root - 2017-12-01 09:00:22.999332: step 146480, loss = 0.33, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 7h:53m:47s remains)
INFO - root - 2017-12-01 09:00:24.573650: step 146490, loss = 0.35, batch loss = 0.27 (51.0 examples/sec; 0.157 sec/batch; 8h:06m:12s remains)
INFO - root - 2017-12-01 09:00:26.162307: step 146500, loss = 0.29, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 7h:53m:44s remains)
INFO - root - 2017-12-01 09:00:27.810925: step 146510, loss = 0.26, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 8h:11m:10s remains)
INFO - root - 2017-12-01 09:00:29.380604: step 146520, loss = 0.26, batch loss = 0.18 (49.2 examples/sec; 0.163 sec/batch; 8h:24m:14s remains)
INFO - root - 2017-12-01 09:00:30.937174: step 146530, loss = 0.32, batch loss = 0.24 (52.6 examples/sec; 0.152 sec/batch; 7h:51m:27s remains)
INFO - root - 2017-12-01 09:00:32.503587: step 146540, loss = 0.28, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 7h:56m:44s remains)
INFO - root - 2017-12-01 09:00:34.063793: step 146550, loss = 0.29, batch loss = 0.20 (51.8 examples/sec; 0.155 sec/batch; 7h:58m:55s remains)
INFO - root - 2017-12-01 09:00:35.633097: step 146560, loss = 0.27, batch loss = 0.19 (52.6 examples/sec; 0.152 sec/batch; 7h:50m:55s remains)
INFO - root - 2017-12-01 09:00:37.179881: step 146570, loss = 0.36, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 8h:02m:42s remains)
INFO - root - 2017-12-01 09:00:38.729360: step 146580, loss = 0.35, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 8h:02m:52s remains)
INFO - root - 2017-12-01 09:00:40.293167: step 146590, loss = 0.43, batch loss = 0.34 (52.1 examples/sec; 0.153 sec/batch; 7h:55m:26s remains)
INFO - root - 2017-12-01 09:00:41.858860: step 146600, loss = 0.27, batch loss = 0.19 (52.1 examples/sec; 0.154 sec/batch; 7h:55m:42s remains)
INFO - root - 2017-12-01 09:00:43.490903: step 146610, loss = 0.32, batch loss = 0.23 (51.1 examples/sec; 0.156 sec/batch; 8h:04m:40s remains)
INFO - root - 2017-12-01 09:00:45.065135: step 146620, loss = 0.35, batch loss = 0.27 (53.1 examples/sec; 0.151 sec/batch; 7h:47m:02s remains)
INFO - root - 2017-12-01 09:00:46.624029: step 146630, loss = 0.23, batch loss = 0.14 (52.2 examples/sec; 0.153 sec/batch; 7h:55m:06s remains)
INFO - root - 2017-12-01 09:00:48.183983: step 146640, loss = 0.27, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 8h:04m:09s remains)
INFO - root - 2017-12-01 09:00:49.743575: step 146650, loss = 0.24, batch loss = 0.15 (52.2 examples/sec; 0.153 sec/batch; 7h:54m:52s remains)
INFO - root - 2017-12-01 09:00:51.296913: step 146660, loss = 0.28, batch loss = 0.20 (49.5 examples/sec; 0.161 sec/batch; 8h:20m:08s remains)
INFO - root - 2017-12-01 09:00:52.862185: step 146670, loss = 0.30, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 8h:00m:07s remains)
INFO - root - 2017-12-01 09:00:54.436025: step 146680, loss = 0.26, batch loss = 0.18 (50.1 examples/sec; 0.160 sec/batch; 8h:14m:26s remains)
INFO - root - 2017-12-01 09:00:55.988646: step 146690, loss = 0.20, batch loss = 0.12 (51.7 examples/sec; 0.155 sec/batch; 7h:59m:37s remains)
INFO - root - 2017-12-01 09:00:57.545637: step 146700, loss = 0.22, batch loss = 0.14 (50.3 examples/sec; 0.159 sec/batch; 8h:12m:14s remains)
INFO - root - 2017-12-01 09:00:59.171920: step 146710, loss = 0.44, batch loss = 0.35 (50.8 examples/sec; 0.158 sec/batch; 8h:07m:53s remains)
INFO - root - 2017-12-01 09:01:00.725542: step 146720, loss = 0.23, batch loss = 0.15 (51.7 examples/sec; 0.155 sec/batch; 7h:58m:52s remains)
INFO - root - 2017-12-01 09:01:02.307559: step 146730, loss = 0.26, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 8h:13m:43s remains)
INFO - root - 2017-12-01 09:01:03.878275: step 146740, loss = 0.35, batch loss = 0.26 (48.7 examples/sec; 0.164 sec/batch; 8h:28m:31s remains)
INFO - root - 2017-12-01 09:01:05.446063: step 146750, loss = 0.26, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 8h:00m:43s remains)
INFO - root - 2017-12-01 09:01:06.999489: step 146760, loss = 0.41, batch loss = 0.33 (51.0 examples/sec; 0.157 sec/batch; 8h:05m:41s remains)
INFO - root - 2017-12-01 09:01:08.566447: step 146770, loss = 0.24, batch loss = 0.15 (51.6 examples/sec; 0.155 sec/batch; 7h:59m:37s remains)
INFO - root - 2017-12-01 09:01:10.139348: step 146780, loss = 0.29, batch loss = 0.21 (48.1 examples/sec; 0.166 sec/batch; 8h:34m:24s remains)
INFO - root - 2017-12-01 09:01:11.688199: step 146790, loss = 0.31, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 8h:08m:44s remains)
INFO - root - 2017-12-01 09:01:13.246623: step 146800, loss = 0.29, batch loss = 0.21 (52.1 examples/sec; 0.153 sec/batch; 7h:55m:03s remains)
INFO - root - 2017-12-01 09:01:14.869951: step 146810, loss = 0.35, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 8h:02m:43s remains)
INFO - root - 2017-12-01 09:01:16.429263: step 146820, loss = 0.30, batch loss = 0.22 (49.0 examples/sec; 0.163 sec/batch; 8h:25m:02s remains)
INFO - root - 2017-12-01 09:01:17.997600: step 146830, loss = 0.26, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 8h:04m:52s remains)
INFO - root - 2017-12-01 09:01:19.550372: step 146840, loss = 0.25, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 8h:03m:31s remains)
INFO - root - 2017-12-01 09:01:21.121485: step 146850, loss = 0.24, batch loss = 0.15 (53.2 examples/sec; 0.150 sec/batch; 7h:45m:36s remains)
INFO - root - 2017-12-01 09:01:22.695966: step 146860, loss = 0.25, batch loss = 0.17 (51.1 examples/sec; 0.157 sec/batch; 8h:04m:34s remains)
INFO - root - 2017-12-01 09:01:24.259353: step 146870, loss = 0.28, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 8h:10m:12s remains)
INFO - root - 2017-12-01 09:01:25.875964: step 146880, loss = 0.29, batch loss = 0.20 (45.9 examples/sec; 0.174 sec/batch; 8h:58m:38s remains)
INFO - root - 2017-12-01 09:01:27.476494: step 146890, loss = 0.28, batch loss = 0.20 (51.1 examples/sec; 0.156 sec/batch; 8h:04m:00s remains)
INFO - root - 2017-12-01 09:01:29.039903: step 146900, loss = 0.36, batch loss = 0.28 (52.0 examples/sec; 0.154 sec/batch; 7h:56m:00s remains)
INFO - root - 2017-12-01 09:01:30.652389: step 146910, loss = 0.27, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 8h:09m:22s remains)
INFO - root - 2017-12-01 09:01:32.205515: step 146920, loss = 0.30, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 8h:07m:58s remains)
INFO - root - 2017-12-01 09:01:33.769221: step 146930, loss = 0.36, batch loss = 0.27 (50.1 examples/sec; 0.160 sec/batch; 8h:13m:23s remains)
INFO - root - 2017-12-01 09:01:35.324652: step 146940, loss = 0.26, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 7h:59m:08s remains)
INFO - root - 2017-12-01 09:01:36.906518: step 146950, loss = 0.35, batch loss = 0.26 (52.7 examples/sec; 0.152 sec/batch; 7h:49m:14s remains)
INFO - root - 2017-12-01 09:01:38.451947: step 146960, loss = 0.32, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 8h:04m:36s remains)
INFO - root - 2017-12-01 09:01:40.022204: step 146970, loss = 0.30, batch loss = 0.21 (50.4 examples/sec; 0.159 sec/batch; 8h:10m:40s remains)
INFO - root - 2017-12-01 09:01:41.608981: step 146980, loss = 0.29, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 8h:13m:09s remains)
INFO - root - 2017-12-01 09:01:43.180623: step 146990, loss = 0.30, batch loss = 0.21 (53.1 examples/sec; 0.151 sec/batch; 7h:45m:39s remains)
INFO - root - 2017-12-01 09:01:44.752677: step 147000, loss = 0.24, batch loss = 0.16 (52.8 examples/sec; 0.152 sec/batch; 7h:48m:40s remains)
INFO - root - 2017-12-01 09:01:46.366911: step 147010, loss = 0.22, batch loss = 0.14 (48.8 examples/sec; 0.164 sec/batch; 8h:27m:15s remains)
INFO - root - 2017-12-01 09:01:47.937908: step 147020, loss = 0.27, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 7h:52m:34s remains)
INFO - root - 2017-12-01 09:01:49.499197: step 147030, loss = 0.32, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 7h:59m:37s remains)
INFO - root - 2017-12-01 09:01:51.058727: step 147040, loss = 0.56, batch loss = 0.47 (51.0 examples/sec; 0.157 sec/batch; 8h:04m:44s remains)
INFO - root - 2017-12-01 09:01:52.615513: step 147050, loss = 0.22, batch loss = 0.14 (51.7 examples/sec; 0.155 sec/batch; 7h:58m:07s remains)
INFO - root - 2017-12-01 09:01:54.173710: step 147060, loss = 0.25, batch loss = 0.16 (51.1 examples/sec; 0.157 sec/batch; 8h:03m:52s remains)
INFO - root - 2017-12-01 09:01:55.729027: step 147070, loss = 0.39, batch loss = 0.30 (50.7 examples/sec; 0.158 sec/batch; 8h:07m:22s remains)
INFO - root - 2017-12-01 09:01:57.305249: step 147080, loss = 0.29, batch loss = 0.21 (51.9 examples/sec; 0.154 sec/batch; 7h:56m:47s remains)
INFO - root - 2017-12-01 09:01:58.865103: step 147090, loss = 0.31, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 7h:58m:09s remains)
INFO - root - 2017-12-01 09:02:00.425596: step 147100, loss = 0.24, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 8h:07m:47s remains)
INFO - root - 2017-12-01 09:02:02.040937: step 147110, loss = 0.25, batch loss = 0.17 (52.0 examples/sec; 0.154 sec/batch; 7h:54m:58s remains)
INFO - root - 2017-12-01 09:02:03.610933: step 147120, loss = 0.27, batch loss = 0.18 (50.8 examples/sec; 0.157 sec/batch; 8h:06m:05s remains)
INFO - root - 2017-12-01 09:02:05.164989: step 147130, loss = 0.25, batch loss = 0.17 (50.8 examples/sec; 0.158 sec/batch; 8h:06m:42s remains)
INFO - root - 2017-12-01 09:02:06.723188: step 147140, loss = 0.28, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 8h:19m:44s remains)
INFO - root - 2017-12-01 09:02:08.285337: step 147150, loss = 0.30, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 7h:53m:08s remains)
INFO - root - 2017-12-01 09:02:09.854689: step 147160, loss = 0.34, batch loss = 0.26 (53.4 examples/sec; 0.150 sec/batch; 7h:42m:45s remains)
INFO - root - 2017-12-01 09:02:11.431780: step 147170, loss = 0.31, batch loss = 0.22 (52.2 examples/sec; 0.153 sec/batch; 7h:53m:47s remains)
INFO - root - 2017-12-01 09:02:12.987467: step 147180, loss = 0.40, batch loss = 0.32 (51.1 examples/sec; 0.157 sec/batch; 8h:03m:39s remains)
INFO - root - 2017-12-01 09:02:14.594558: step 147190, loss = 0.33, batch loss = 0.24 (48.7 examples/sec; 0.164 sec/batch; 8h:27m:11s remains)
INFO - root - 2017-12-01 09:02:16.164065: step 147200, loss = 0.34, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 7h:56m:42s remains)
INFO - root - 2017-12-01 09:02:17.807679: step 147210, loss = 0.40, batch loss = 0.32 (49.8 examples/sec; 0.161 sec/batch; 8h:15m:55s remains)
INFO - root - 2017-12-01 09:02:19.375338: step 147220, loss = 0.37, batch loss = 0.29 (52.7 examples/sec; 0.152 sec/batch; 7h:48m:53s remains)
INFO - root - 2017-12-01 09:02:20.935431: step 147230, loss = 0.26, batch loss = 0.17 (52.1 examples/sec; 0.154 sec/batch; 7h:54m:16s remains)
INFO - root - 2017-12-01 09:02:22.487006: step 147240, loss = 0.34, batch loss = 0.26 (52.3 examples/sec; 0.153 sec/batch; 7h:52m:27s remains)
INFO - root - 2017-12-01 09:02:24.045824: step 147250, loss = 0.25, batch loss = 0.16 (51.6 examples/sec; 0.155 sec/batch; 7h:58m:58s remains)
INFO - root - 2017-12-01 09:02:25.603936: step 147260, loss = 0.37, batch loss = 0.28 (50.7 examples/sec; 0.158 sec/batch; 8h:06m:41s remains)
INFO - root - 2017-12-01 09:02:27.171425: step 147270, loss = 0.32, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 7h:51m:12s remains)
INFO - root - 2017-12-01 09:02:28.742758: step 147280, loss = 0.41, batch loss = 0.32 (52.4 examples/sec; 0.153 sec/batch; 7h:51m:00s remains)
INFO - root - 2017-12-01 09:02:30.312315: step 147290, loss = 0.25, batch loss = 0.17 (51.1 examples/sec; 0.156 sec/batch; 8h:02m:58s remains)
INFO - root - 2017-12-01 09:02:31.882869: step 147300, loss = 0.28, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 8h:08m:15s remains)
INFO - root - 2017-12-01 09:02:33.512024: step 147310, loss = 0.26, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 7h:59m:32s remains)
INFO - root - 2017-12-01 09:02:35.082358: step 147320, loss = 0.26, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 8h:07m:42s remains)
INFO - root - 2017-12-01 09:02:36.650791: step 147330, loss = 0.39, batch loss = 0.31 (50.9 examples/sec; 0.157 sec/batch; 8h:05m:11s remains)
INFO - root - 2017-12-01 09:02:38.220875: step 147340, loss = 0.33, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 7h:58m:47s remains)
INFO - root - 2017-12-01 09:02:39.786708: step 147350, loss = 0.34, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 7h:59m:01s remains)
INFO - root - 2017-12-01 09:02:41.348837: step 147360, loss = 0.32, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 7h:58m:31s remains)
INFO - root - 2017-12-01 09:02:42.900786: step 147370, loss = 0.27, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 7h:58m:01s remains)
INFO - root - 2017-12-01 09:02:44.468457: step 147380, loss = 0.29, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 8h:08m:12s remains)
INFO - root - 2017-12-01 09:02:46.030257: step 147390, loss = 0.31, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 7h:58m:58s remains)
INFO - root - 2017-12-01 09:02:47.585825: step 147400, loss = 0.21, batch loss = 0.12 (52.4 examples/sec; 0.153 sec/batch; 7h:50m:44s remains)
INFO - root - 2017-12-01 09:02:49.203476: step 147410, loss = 0.32, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 8h:07m:55s remains)
INFO - root - 2017-12-01 09:02:50.758869: step 147420, loss = 0.33, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 8h:01m:26s remains)
INFO - root - 2017-12-01 09:02:52.329619: step 147430, loss = 0.42, batch loss = 0.34 (51.1 examples/sec; 0.157 sec/batch; 8h:03m:03s remains)
INFO - root - 2017-12-01 09:02:53.907958: step 147440, loss = 0.27, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 8h:05m:04s remains)
INFO - root - 2017-12-01 09:02:55.527417: step 147450, loss = 0.28, batch loss = 0.19 (49.6 examples/sec; 0.161 sec/batch; 8h:17m:06s remains)
INFO - root - 2017-12-01 09:02:57.110021: step 147460, loss = 0.29, batch loss = 0.20 (52.3 examples/sec; 0.153 sec/batch; 7h:51m:24s remains)
INFO - root - 2017-12-01 09:02:58.693472: step 147470, loss = 0.23, batch loss = 0.15 (51.2 examples/sec; 0.156 sec/batch; 8h:02m:10s remains)
INFO - root - 2017-12-01 09:03:00.257980: step 147480, loss = 0.39, batch loss = 0.30 (48.0 examples/sec; 0.167 sec/batch; 8h:33m:57s remains)
INFO - root - 2017-12-01 09:03:01.818024: step 147490, loss = 0.34, batch loss = 0.26 (51.1 examples/sec; 0.157 sec/batch; 8h:02m:43s remains)
INFO - root - 2017-12-01 09:03:03.372083: step 147500, loss = 0.25, batch loss = 0.16 (52.9 examples/sec; 0.151 sec/batch; 7h:45m:59s remains)
INFO - root - 2017-12-01 09:03:05.071795: step 147510, loss = 0.29, batch loss = 0.21 (48.4 examples/sec; 0.165 sec/batch; 8h:29m:58s remains)
INFO - root - 2017-12-01 09:03:06.636718: step 147520, loss = 0.27, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 8h:14m:24s remains)
INFO - root - 2017-12-01 09:03:08.196899: step 147530, loss = 0.29, batch loss = 0.20 (52.9 examples/sec; 0.151 sec/batch; 7h:46m:15s remains)
INFO - root - 2017-12-01 09:03:09.770264: step 147540, loss = 0.39, batch loss = 0.30 (50.5 examples/sec; 0.158 sec/batch; 8h:08m:02s remains)
INFO - root - 2017-12-01 09:03:11.353782: step 147550, loss = 0.35, batch loss = 0.26 (49.5 examples/sec; 0.162 sec/batch; 8h:18m:05s remains)
INFO - root - 2017-12-01 09:03:12.926082: step 147560, loss = 0.43, batch loss = 0.35 (52.0 examples/sec; 0.154 sec/batch; 7h:53m:45s remains)
INFO - root - 2017-12-01 09:03:14.506375: step 147570, loss = 0.26, batch loss = 0.18 (52.1 examples/sec; 0.154 sec/batch; 7h:53m:34s remains)
INFO - root - 2017-12-01 09:03:16.080048: step 147580, loss = 0.25, batch loss = 0.17 (50.0 examples/sec; 0.160 sec/batch; 8h:12m:59s remains)
INFO - root - 2017-12-01 09:03:17.634074: step 147590, loss = 0.27, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 7h:59m:49s remains)
INFO - root - 2017-12-01 09:03:19.203681: step 147600, loss = 0.30, batch loss = 0.21 (53.0 examples/sec; 0.151 sec/batch; 7h:45m:11s remains)
INFO - root - 2017-12-01 09:03:20.859316: step 147610, loss = 0.35, batch loss = 0.27 (50.5 examples/sec; 0.158 sec/batch; 8h:07m:57s remains)
INFO - root - 2017-12-01 09:03:22.427517: step 147620, loss = 0.25, batch loss = 0.17 (52.5 examples/sec; 0.152 sec/batch; 7h:49m:20s remains)
INFO - root - 2017-12-01 09:03:23.991865: step 147630, loss = 0.37, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 8h:01m:53s remains)
INFO - root - 2017-12-01 09:03:25.554127: step 147640, loss = 0.24, batch loss = 0.16 (51.7 examples/sec; 0.155 sec/batch; 7h:56m:21s remains)
INFO - root - 2017-12-01 09:03:27.142780: step 147650, loss = 0.25, batch loss = 0.17 (49.6 examples/sec; 0.161 sec/batch; 8h:17m:21s remains)
INFO - root - 2017-12-01 09:03:28.712491: step 147660, loss = 0.37, batch loss = 0.28 (49.6 examples/sec; 0.161 sec/batch; 8h:16m:31s remains)
INFO - root - 2017-12-01 09:03:30.299586: step 147670, loss = 0.20, batch loss = 0.12 (52.2 examples/sec; 0.153 sec/batch; 7h:52m:19s remains)
INFO - root - 2017-12-01 09:03:31.860440: step 147680, loss = 0.30, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 7h:57m:29s remains)
INFO - root - 2017-12-01 09:03:33.413681: step 147690, loss = 0.26, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 8h:02m:21s remains)
INFO - root - 2017-12-01 09:03:34.973854: step 147700, loss = 0.26, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 7h:59m:12s remains)
INFO - root - 2017-12-01 09:03:36.641332: step 147710, loss = 0.29, batch loss = 0.21 (51.8 examples/sec; 0.155 sec/batch; 7h:55m:53s remains)
INFO - root - 2017-12-01 09:03:38.205008: step 147720, loss = 0.31, batch loss = 0.23 (50.1 examples/sec; 0.160 sec/batch; 8h:11m:43s remains)
INFO - root - 2017-12-01 09:03:39.752740: step 147730, loss = 0.25, batch loss = 0.16 (52.8 examples/sec; 0.151 sec/batch; 7h:46m:31s remains)
INFO - root - 2017-12-01 09:03:41.306597: step 147740, loss = 0.23, batch loss = 0.14 (52.3 examples/sec; 0.153 sec/batch; 7h:50m:35s remains)
INFO - root - 2017-12-01 09:03:42.865575: step 147750, loss = 0.25, batch loss = 0.17 (50.8 examples/sec; 0.157 sec/batch; 8h:04m:51s remains)
INFO - root - 2017-12-01 09:03:44.481162: step 147760, loss = 0.49, batch loss = 0.41 (50.0 examples/sec; 0.160 sec/batch; 8h:12m:31s remains)
INFO - root - 2017-12-01 09:03:46.034617: step 147770, loss = 0.35, batch loss = 0.27 (52.0 examples/sec; 0.154 sec/batch; 7h:53m:15s remains)
INFO - root - 2017-12-01 09:03:47.603343: step 147780, loss = 0.29, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 7h:50m:51s remains)
INFO - root - 2017-12-01 09:03:49.164317: step 147790, loss = 0.24, batch loss = 0.16 (50.6 examples/sec; 0.158 sec/batch; 8h:06m:21s remains)
INFO - root - 2017-12-01 09:03:50.719717: step 147800, loss = 0.25, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 7h:54m:22s remains)
INFO - root - 2017-12-01 09:03:52.325400: step 147810, loss = 0.25, batch loss = 0.16 (53.0 examples/sec; 0.151 sec/batch; 7h:44m:16s remains)
INFO - root - 2017-12-01 09:03:53.904732: step 147820, loss = 0.33, batch loss = 0.25 (52.1 examples/sec; 0.154 sec/batch; 7h:52m:53s remains)
INFO - root - 2017-12-01 09:03:55.459425: step 147830, loss = 0.31, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 8h:05m:04s remains)
INFO - root - 2017-12-01 09:03:57.015812: step 147840, loss = 0.25, batch loss = 0.16 (51.1 examples/sec; 0.157 sec/batch; 8h:01m:52s remains)
INFO - root - 2017-12-01 09:03:58.559066: step 147850, loss = 0.30, batch loss = 0.21 (51.8 examples/sec; 0.155 sec/batch; 7h:55m:36s remains)
INFO - root - 2017-12-01 09:04:00.119564: step 147860, loss = 0.35, batch loss = 0.27 (50.1 examples/sec; 0.160 sec/batch; 8h:11m:38s remains)
INFO - root - 2017-12-01 09:04:01.679267: step 147870, loss = 0.26, batch loss = 0.18 (49.5 examples/sec; 0.162 sec/batch; 8h:17m:45s remains)
INFO - root - 2017-12-01 09:04:03.254530: step 147880, loss = 0.35, batch loss = 0.27 (51.4 examples/sec; 0.156 sec/batch; 7h:58m:37s remains)
INFO - root - 2017-12-01 09:04:04.803786: step 147890, loss = 0.28, batch loss = 0.20 (52.0 examples/sec; 0.154 sec/batch; 7h:53m:23s remains)
INFO - root - 2017-12-01 09:04:06.357048: step 147900, loss = 0.28, batch loss = 0.19 (52.1 examples/sec; 0.153 sec/batch; 7h:52m:10s remains)
INFO - root - 2017-12-01 09:04:07.953619: step 147910, loss = 0.31, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 8h:02m:53s remains)
INFO - root - 2017-12-01 09:04:09.509703: step 147920, loss = 0.26, batch loss = 0.18 (50.8 examples/sec; 0.158 sec/batch; 8h:04m:48s remains)
INFO - root - 2017-12-01 09:04:11.078341: step 147930, loss = 0.28, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 8h:07m:00s remains)
INFO - root - 2017-12-01 09:04:12.637812: step 147940, loss = 0.31, batch loss = 0.23 (52.3 examples/sec; 0.153 sec/batch; 7h:50m:54s remains)
INFO - root - 2017-12-01 09:04:14.211256: step 147950, loss = 0.24, batch loss = 0.15 (51.2 examples/sec; 0.156 sec/batch; 8h:00m:16s remains)
INFO - root - 2017-12-01 09:04:15.763267: step 147960, loss = 0.35, batch loss = 0.26 (51.8 examples/sec; 0.155 sec/batch; 7h:55m:17s remains)
INFO - root - 2017-12-01 09:04:17.316672: step 147970, loss = 0.27, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 7h:59m:46s remains)
INFO - root - 2017-12-01 09:04:18.906025: step 147980, loss = 0.27, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 7h:49m:55s remains)
INFO - root - 2017-12-01 09:04:20.468191: step 147990, loss = 0.23, batch loss = 0.15 (50.9 examples/sec; 0.157 sec/batch; 8h:03m:22s remains)
INFO - root - 2017-12-01 09:04:22.029938: step 148000, loss = 0.23, batch loss = 0.14 (50.8 examples/sec; 0.157 sec/batch; 8h:03m:54s remains)
INFO - root - 2017-12-01 09:04:23.695827: step 148010, loss = 0.28, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 8h:13m:10s remains)
INFO - root - 2017-12-01 09:04:25.254548: step 148020, loss = 0.29, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 8h:09m:03s remains)
INFO - root - 2017-12-01 09:04:26.815153: step 148030, loss = 0.26, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 7h:53m:44s remains)
INFO - root - 2017-12-01 09:04:28.375686: step 148040, loss = 0.24, batch loss = 0.15 (51.0 examples/sec; 0.157 sec/batch; 8h:01m:51s remains)
INFO - root - 2017-12-01 09:04:29.929924: step 148050, loss = 0.26, batch loss = 0.18 (52.5 examples/sec; 0.152 sec/batch; 7h:48m:22s remains)
INFO - root - 2017-12-01 09:04:31.487026: step 148060, loss = 0.31, batch loss = 0.23 (51.3 examples/sec; 0.156 sec/batch; 7h:58m:55s remains)
INFO - root - 2017-12-01 09:04:33.034155: step 148070, loss = 0.36, batch loss = 0.28 (52.1 examples/sec; 0.153 sec/batch; 7h:51m:47s remains)
INFO - root - 2017-12-01 09:04:34.597998: step 148080, loss = 0.25, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 8h:03m:17s remains)
INFO - root - 2017-12-01 09:04:36.159206: step 148090, loss = 0.24, batch loss = 0.16 (50.6 examples/sec; 0.158 sec/batch; 8h:06m:00s remains)
INFO - root - 2017-12-01 09:04:37.715014: step 148100, loss = 0.39, batch loss = 0.31 (51.4 examples/sec; 0.156 sec/batch; 7h:58m:18s remains)
INFO - root - 2017-12-01 09:04:39.347976: step 148110, loss = 0.32, batch loss = 0.24 (52.1 examples/sec; 0.153 sec/batch; 7h:51m:41s remains)
INFO - root - 2017-12-01 09:04:40.903048: step 148120, loss = 0.29, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 8h:04m:51s remains)
INFO - root - 2017-12-01 09:04:42.467696: step 148130, loss = 0.27, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 7h:54m:14s remains)
INFO - root - 2017-12-01 09:04:44.036514: step 148140, loss = 0.36, batch loss = 0.28 (52.1 examples/sec; 0.153 sec/batch; 7h:51m:29s remains)
INFO - root - 2017-12-01 09:04:45.595702: step 148150, loss = 0.28, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 7h:50m:54s remains)
INFO - root - 2017-12-01 09:04:47.169326: step 148160, loss = 0.25, batch loss = 0.16 (51.2 examples/sec; 0.156 sec/batch; 8h:00m:17s remains)
INFO - root - 2017-12-01 09:04:48.735381: step 148170, loss = 0.26, batch loss = 0.18 (48.5 examples/sec; 0.165 sec/batch; 8h:26m:38s remains)
INFO - root - 2017-12-01 09:04:50.299343: step 148180, loss = 0.27, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 8h:02m:47s remains)
INFO - root - 2017-12-01 09:04:51.857557: step 148190, loss = 0.28, batch loss = 0.20 (52.8 examples/sec; 0.151 sec/batch; 7h:45m:21s remains)
INFO - root - 2017-12-01 09:04:53.425893: step 148200, loss = 0.28, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 7h:53m:23s remains)
INFO - root - 2017-12-01 09:04:55.031762: step 148210, loss = 0.26, batch loss = 0.18 (51.4 examples/sec; 0.156 sec/batch; 7h:58m:03s remains)
INFO - root - 2017-12-01 09:04:56.603332: step 148220, loss = 0.25, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 7h:50m:41s remains)
INFO - root - 2017-12-01 09:04:58.164881: step 148230, loss = 0.33, batch loss = 0.24 (51.4 examples/sec; 0.156 sec/batch; 7h:57m:37s remains)
INFO - root - 2017-12-01 09:04:59.739787: step 148240, loss = 0.24, batch loss = 0.16 (50.1 examples/sec; 0.160 sec/batch; 8h:10m:52s remains)
INFO - root - 2017-12-01 09:05:01.308422: step 148250, loss = 0.35, batch loss = 0.26 (50.5 examples/sec; 0.158 sec/batch; 8h:06m:03s remains)
INFO - root - 2017-12-01 09:05:02.879060: step 148260, loss = 0.31, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 7h:53m:39s remains)
INFO - root - 2017-12-01 09:05:04.458361: step 148270, loss = 0.34, batch loss = 0.26 (50.8 examples/sec; 0.158 sec/batch; 8h:03m:52s remains)
INFO - root - 2017-12-01 09:05:06.062005: step 148280, loss = 0.26, batch loss = 0.18 (50.6 examples/sec; 0.158 sec/batch; 8h:05m:08s remains)
INFO - root - 2017-12-01 09:05:07.621275: step 148290, loss = 0.27, batch loss = 0.19 (50.4 examples/sec; 0.159 sec/batch; 8h:07m:20s remains)
INFO - root - 2017-12-01 09:05:09.183166: step 148300, loss = 0.26, batch loss = 0.18 (52.7 examples/sec; 0.152 sec/batch; 7h:46m:07s remains)
INFO - root - 2017-12-01 09:05:10.805224: step 148310, loss = 0.27, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 7h:58m:19s remains)
INFO - root - 2017-12-01 09:05:12.349049: step 148320, loss = 0.33, batch loss = 0.25 (52.4 examples/sec; 0.153 sec/batch; 7h:48m:26s remains)
INFO - root - 2017-12-01 09:05:13.921579: step 148330, loss = 0.44, batch loss = 0.35 (47.8 examples/sec; 0.167 sec/batch; 8h:33m:54s remains)
INFO - root - 2017-12-01 09:05:15.504184: step 148340, loss = 0.25, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 8h:02m:24s remains)
INFO - root - 2017-12-01 09:05:17.055353: step 148350, loss = 0.27, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 7h:53m:28s remains)
INFO - root - 2017-12-01 09:05:18.622055: step 148360, loss = 0.29, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 8h:08m:34s remains)
INFO - root - 2017-12-01 09:05:20.204718: step 148370, loss = 0.28, batch loss = 0.20 (48.9 examples/sec; 0.164 sec/batch; 8h:22m:01s remains)
INFO - root - 2017-12-01 09:05:21.796509: step 148380, loss = 0.32, batch loss = 0.24 (52.4 examples/sec; 0.153 sec/batch; 7h:48m:49s remains)
INFO - root - 2017-12-01 09:05:23.341304: step 148390, loss = 0.31, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 7h:50m:14s remains)
INFO - root - 2017-12-01 09:05:24.919046: step 148400, loss = 0.31, batch loss = 0.22 (49.0 examples/sec; 0.163 sec/batch; 8h:20m:28s remains)
INFO - root - 2017-12-01 09:05:26.557092: step 148410, loss = 0.29, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 7h:48m:38s remains)
INFO - root - 2017-12-01 09:05:28.158365: step 148420, loss = 0.29, batch loss = 0.20 (47.2 examples/sec; 0.170 sec/batch; 8h:40m:17s remains)
INFO - root - 2017-12-01 09:05:29.728518: step 148430, loss = 0.28, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 7h:50m:03s remains)
INFO - root - 2017-12-01 09:05:31.318695: step 148440, loss = 0.30, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 7h:52m:13s remains)
INFO - root - 2017-12-01 09:05:32.884437: step 148450, loss = 0.29, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 7h:54m:33s remains)
INFO - root - 2017-12-01 09:05:34.430349: step 148460, loss = 0.25, batch loss = 0.17 (50.7 examples/sec; 0.158 sec/batch; 8h:03m:59s remains)
INFO - root - 2017-12-01 09:05:36.001925: step 148470, loss = 0.49, batch loss = 0.41 (48.0 examples/sec; 0.167 sec/batch; 8h:31m:17s remains)
INFO - root - 2017-12-01 09:05:37.577843: step 148480, loss = 0.26, batch loss = 0.17 (51.3 examples/sec; 0.156 sec/batch; 7h:58m:19s remains)
INFO - root - 2017-12-01 09:05:39.141995: step 148490, loss = 0.25, batch loss = 0.17 (52.2 examples/sec; 0.153 sec/batch; 7h:50m:19s remains)
INFO - root - 2017-12-01 09:05:40.734460: step 148500, loss = 0.29, batch loss = 0.21 (47.7 examples/sec; 0.168 sec/batch; 8h:34m:16s remains)
INFO - root - 2017-12-01 09:05:42.362818: step 148510, loss = 0.25, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 7h:54m:13s remains)
INFO - root - 2017-12-01 09:05:43.957173: step 148520, loss = 0.27, batch loss = 0.19 (49.9 examples/sec; 0.160 sec/batch; 8h:11m:36s remains)
INFO - root - 2017-12-01 09:05:45.516205: step 148530, loss = 0.24, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 8h:01m:32s remains)
INFO - root - 2017-12-01 09:05:47.071335: step 148540, loss = 0.38, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 7h:58m:43s remains)
INFO - root - 2017-12-01 09:05:48.628277: step 148550, loss = 0.37, batch loss = 0.29 (53.6 examples/sec; 0.149 sec/batch; 7h:37m:17s remains)
INFO - root - 2017-12-01 09:05:50.209887: step 148560, loss = 0.26, batch loss = 0.17 (50.4 examples/sec; 0.159 sec/batch; 8h:07m:05s remains)
INFO - root - 2017-12-01 09:05:51.779599: step 148570, loss = 0.38, batch loss = 0.30 (50.4 examples/sec; 0.159 sec/batch; 8h:07m:03s remains)
INFO - root - 2017-12-01 09:05:53.354523: step 148580, loss = 0.38, batch loss = 0.30 (50.0 examples/sec; 0.160 sec/batch; 8h:10m:16s remains)
INFO - root - 2017-12-01 09:05:54.938674: step 148590, loss = 0.25, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 7h:52m:02s remains)
INFO - root - 2017-12-01 09:05:56.521338: step 148600, loss = 0.25, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 7h:56m:02s remains)
INFO - root - 2017-12-01 09:05:58.198834: step 148610, loss = 0.27, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 8h:10m:29s remains)
INFO - root - 2017-12-01 09:05:59.755987: step 148620, loss = 0.27, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 8h:02m:19s remains)
INFO - root - 2017-12-01 09:06:01.316949: step 148630, loss = 0.23, batch loss = 0.15 (52.3 examples/sec; 0.153 sec/batch; 7h:49m:09s remains)
INFO - root - 2017-12-01 09:06:02.889144: step 148640, loss = 0.25, batch loss = 0.17 (49.5 examples/sec; 0.162 sec/batch; 8h:15m:09s remains)
INFO - root - 2017-12-01 09:06:04.466591: step 148650, loss = 0.31, batch loss = 0.23 (51.5 examples/sec; 0.155 sec/batch; 7h:56m:22s remains)
INFO - root - 2017-12-01 09:06:06.010943: step 148660, loss = 0.39, batch loss = 0.30 (51.7 examples/sec; 0.155 sec/batch; 7h:54m:26s remains)
INFO - root - 2017-12-01 09:06:07.590261: step 148670, loss = 0.26, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 8h:01m:58s remains)
INFO - root - 2017-12-01 09:06:09.147454: step 148680, loss = 0.31, batch loss = 0.23 (49.0 examples/sec; 0.163 sec/batch; 8h:20m:27s remains)
INFO - root - 2017-12-01 09:06:10.711628: step 148690, loss = 0.30, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 8h:02m:56s remains)
INFO - root - 2017-12-01 09:06:12.289287: step 148700, loss = 0.32, batch loss = 0.24 (50.4 examples/sec; 0.159 sec/batch; 8h:05m:52s remains)
INFO - root - 2017-12-01 09:06:13.929743: step 148710, loss = 0.27, batch loss = 0.19 (50.8 examples/sec; 0.157 sec/batch; 8h:02m:22s remains)
INFO - root - 2017-12-01 09:06:15.507105: step 148720, loss = 0.27, batch loss = 0.19 (51.4 examples/sec; 0.156 sec/batch; 7h:56m:55s remains)
INFO - root - 2017-12-01 09:06:17.070044: step 148730, loss = 0.33, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 7h:59m:20s remains)
INFO - root - 2017-12-01 09:06:18.629931: step 148740, loss = 0.22, batch loss = 0.13 (50.2 examples/sec; 0.159 sec/batch; 8h:08m:16s remains)
INFO - root - 2017-12-01 09:06:20.198401: step 148750, loss = 0.32, batch loss = 0.24 (48.8 examples/sec; 0.164 sec/batch; 8h:21m:47s remains)
INFO - root - 2017-12-01 09:06:21.782450: step 148760, loss = 0.42, batch loss = 0.33 (48.1 examples/sec; 0.166 sec/batch; 8h:29m:37s remains)
INFO - root - 2017-12-01 09:06:23.359454: step 148770, loss = 0.24, batch loss = 0.16 (50.2 examples/sec; 0.159 sec/batch; 8h:07m:49s remains)
INFO - root - 2017-12-01 09:06:24.928906: step 148780, loss = 0.28, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 8h:01m:33s remains)
INFO - root - 2017-12-01 09:06:26.506834: step 148790, loss = 0.27, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 8h:04m:23s remains)
INFO - root - 2017-12-01 09:06:28.108685: step 148800, loss = 0.24, batch loss = 0.15 (51.6 examples/sec; 0.155 sec/batch; 7h:54m:37s remains)
INFO - root - 2017-12-01 09:06:29.714087: step 148810, loss = 0.25, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 8h:00m:03s remains)
INFO - root - 2017-12-01 09:06:31.278651: step 148820, loss = 0.38, batch loss = 0.29 (49.3 examples/sec; 0.162 sec/batch; 8h:16m:57s remains)
INFO - root - 2017-12-01 09:06:32.865899: step 148830, loss = 0.28, batch loss = 0.20 (51.0 examples/sec; 0.157 sec/batch; 8h:00m:20s remains)
INFO - root - 2017-12-01 09:06:34.433530: step 148840, loss = 0.27, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 8h:00m:27s remains)
INFO - root - 2017-12-01 09:06:35.980543: step 148850, loss = 0.22, batch loss = 0.14 (51.8 examples/sec; 0.154 sec/batch; 7h:52m:48s remains)
INFO - root - 2017-12-01 09:06:37.547678: step 148860, loss = 0.28, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 7h:48m:49s remains)
INFO - root - 2017-12-01 09:06:39.100504: step 148870, loss = 0.25, batch loss = 0.17 (52.4 examples/sec; 0.153 sec/batch; 7h:47m:07s remains)
INFO - root - 2017-12-01 09:06:40.653410: step 148880, loss = 0.28, batch loss = 0.20 (52.1 examples/sec; 0.154 sec/batch; 7h:50m:18s remains)
INFO - root - 2017-12-01 09:06:42.226871: step 148890, loss = 0.28, batch loss = 0.20 (52.6 examples/sec; 0.152 sec/batch; 7h:45m:19s remains)
INFO - root - 2017-12-01 09:06:43.783954: step 148900, loss = 0.36, batch loss = 0.28 (50.5 examples/sec; 0.159 sec/batch; 8h:05m:05s remains)
INFO - root - 2017-12-01 09:06:45.414834: step 148910, loss = 0.31, batch loss = 0.22 (53.0 examples/sec; 0.151 sec/batch; 7h:41m:59s remains)
INFO - root - 2017-12-01 09:06:47.000974: step 148920, loss = 0.31, batch loss = 0.22 (51.8 examples/sec; 0.155 sec/batch; 7h:52m:49s remains)
INFO - root - 2017-12-01 09:06:48.558332: step 148930, loss = 0.26, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 8h:07m:29s remains)
INFO - root - 2017-12-01 09:06:50.112772: step 148940, loss = 0.28, batch loss = 0.20 (52.4 examples/sec; 0.153 sec/batch; 7h:47m:17s remains)
INFO - root - 2017-12-01 09:06:51.691509: step 148950, loss = 0.33, batch loss = 0.25 (48.7 examples/sec; 0.164 sec/batch; 8h:22m:26s remains)
INFO - root - 2017-12-01 09:06:53.269417: step 148960, loss = 0.23, batch loss = 0.14 (51.8 examples/sec; 0.154 sec/batch; 7h:52m:28s remains)
INFO - root - 2017-12-01 09:06:54.823536: step 148970, loss = 0.24, batch loss = 0.16 (51.1 examples/sec; 0.157 sec/batch; 7h:58m:43s remains)
INFO - root - 2017-12-01 09:06:56.368746: step 148980, loss = 0.54, batch loss = 0.46 (53.5 examples/sec; 0.150 sec/batch; 7h:37m:16s remains)
INFO - root - 2017-12-01 09:06:57.920880: step 148990, loss = 0.25, batch loss = 0.16 (50.4 examples/sec; 0.159 sec/batch; 8h:05m:10s remains)
INFO - root - 2017-12-01 09:06:59.490877: step 149000, loss = 0.38, batch loss = 0.30 (52.6 examples/sec; 0.152 sec/batch; 7h:45m:02s remains)
INFO - root - 2017-12-01 09:07:01.099112: step 149010, loss = 0.24, batch loss = 0.16 (52.2 examples/sec; 0.153 sec/batch; 7h:49m:03s remains)
INFO - root - 2017-12-01 09:07:02.652394: step 149020, loss = 0.35, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 8h:00m:12s remains)
INFO - root - 2017-12-01 09:07:04.206509: step 149030, loss = 0.25, batch loss = 0.17 (52.7 examples/sec; 0.152 sec/batch; 7h:44m:30s remains)
INFO - root - 2017-12-01 09:07:05.774499: step 149040, loss = 0.33, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 8h:02m:50s remains)
INFO - root - 2017-12-01 09:07:07.328058: step 149050, loss = 0.29, batch loss = 0.20 (53.0 examples/sec; 0.151 sec/batch; 7h:41m:23s remains)
INFO - root - 2017-12-01 09:07:08.938494: step 149060, loss = 0.40, batch loss = 0.32 (49.0 examples/sec; 0.163 sec/batch; 8h:19m:19s remains)
INFO - root - 2017-12-01 09:07:10.515544: step 149070, loss = 0.30, batch loss = 0.21 (47.7 examples/sec; 0.168 sec/batch; 8h:32m:28s remains)
INFO - root - 2017-12-01 09:07:12.142676: step 149080, loss = 0.29, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 8h:03m:48s remains)
INFO - root - 2017-12-01 09:07:13.712045: step 149090, loss = 0.29, batch loss = 0.21 (47.5 examples/sec; 0.168 sec/batch; 8h:34m:53s remains)
INFO - root - 2017-12-01 09:07:15.363884: step 149100, loss = 0.32, batch loss = 0.23 (50.0 examples/sec; 0.160 sec/batch; 8h:08m:44s remains)
INFO - root - 2017-12-01 09:07:17.020526: step 149110, loss = 0.32, batch loss = 0.24 (52.3 examples/sec; 0.153 sec/batch; 7h:47m:24s remains)
INFO - root - 2017-12-01 09:07:18.614258: step 149120, loss = 0.29, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 8h:00m:49s remains)
INFO - root - 2017-12-01 09:07:20.197404: step 149130, loss = 0.27, batch loss = 0.19 (47.8 examples/sec; 0.167 sec/batch; 8h:31m:41s remains)
INFO - root - 2017-12-01 09:07:21.778701: step 149140, loss = 0.29, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 8h:06m:20s remains)
INFO - root - 2017-12-01 09:07:23.320181: step 149150, loss = 0.27, batch loss = 0.18 (53.0 examples/sec; 0.151 sec/batch; 7h:41m:04s remains)
INFO - root - 2017-12-01 09:07:24.903070: step 149160, loss = 0.38, batch loss = 0.30 (49.6 examples/sec; 0.161 sec/batch; 8h:12m:27s remains)
INFO - root - 2017-12-01 09:07:26.465105: step 149170, loss = 0.26, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 7h:56m:26s remains)
INFO - root - 2017-12-01 09:07:28.027529: step 149180, loss = 0.23, batch loss = 0.14 (48.8 examples/sec; 0.164 sec/batch; 8h:20m:51s remains)
INFO - root - 2017-12-01 09:07:29.591422: step 149190, loss = 0.32, batch loss = 0.23 (52.1 examples/sec; 0.153 sec/batch; 7h:48m:53s remains)
INFO - root - 2017-12-01 09:07:31.151542: step 149200, loss = 0.32, batch loss = 0.24 (51.7 examples/sec; 0.155 sec/batch; 7h:53m:08s remains)
INFO - root - 2017-12-01 09:07:32.754636: step 149210, loss = 0.36, batch loss = 0.28 (51.2 examples/sec; 0.156 sec/batch; 7h:56m:58s remains)
INFO - root - 2017-12-01 09:07:34.331852: step 149220, loss = 0.28, batch loss = 0.20 (52.7 examples/sec; 0.152 sec/batch; 7h:44m:01s remains)
INFO - root - 2017-12-01 09:07:35.902317: step 149230, loss = 0.30, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 7h:54m:59s remains)
INFO - root - 2017-12-01 09:07:37.477924: step 149240, loss = 0.33, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 7h:59m:17s remains)
INFO - root - 2017-12-01 09:07:39.028627: step 149250, loss = 0.25, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 7h:59m:29s remains)
INFO - root - 2017-12-01 09:07:40.605817: step 149260, loss = 0.31, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 7h:57m:09s remains)
INFO - root - 2017-12-01 09:07:42.165809: step 149270, loss = 0.34, batch loss = 0.25 (52.5 examples/sec; 0.152 sec/batch; 7h:45m:31s remains)
INFO - root - 2017-12-01 09:07:43.726348: step 149280, loss = 0.29, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 7h:48m:25s remains)
INFO - root - 2017-12-01 09:07:45.308746: step 149290, loss = 0.30, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 8h:01m:21s remains)
INFO - root - 2017-12-01 09:07:46.888605: step 149300, loss = 0.38, batch loss = 0.29 (47.5 examples/sec; 0.168 sec/batch; 8h:34m:11s remains)
INFO - root - 2017-12-01 09:07:48.544928: step 149310, loss = 0.34, batch loss = 0.25 (50.2 examples/sec; 0.159 sec/batch; 8h:06m:24s remains)
INFO - root - 2017-12-01 09:07:50.106343: step 149320, loss = 0.24, batch loss = 0.16 (52.2 examples/sec; 0.153 sec/batch; 7h:47m:55s remains)
INFO - root - 2017-12-01 09:07:51.665275: step 149330, loss = 0.32, batch loss = 0.23 (52.2 examples/sec; 0.153 sec/batch; 7h:47m:27s remains)
INFO - root - 2017-12-01 09:07:53.237473: step 149340, loss = 0.35, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 7h:59m:57s remains)
INFO - root - 2017-12-01 09:07:54.826381: step 149350, loss = 0.40, batch loss = 0.31 (50.1 examples/sec; 0.160 sec/batch; 8h:07m:41s remains)
INFO - root - 2017-12-01 09:07:56.404235: step 149360, loss = 0.22, batch loss = 0.14 (48.5 examples/sec; 0.165 sec/batch; 8h:23m:33s remains)
INFO - root - 2017-12-01 09:07:57.999407: step 149370, loss = 0.27, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 7h:53m:45s remains)
INFO - root - 2017-12-01 09:07:59.560514: step 149380, loss = 0.40, batch loss = 0.32 (48.4 examples/sec; 0.165 sec/batch; 8h:24m:45s remains)
INFO - root - 2017-12-01 09:08:01.115427: step 149390, loss = 0.28, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 8h:04m:18s remains)
INFO - root - 2017-12-01 09:08:02.696455: step 149400, loss = 0.27, batch loss = 0.19 (48.7 examples/sec; 0.164 sec/batch; 8h:21m:19s remains)
INFO - root - 2017-12-01 09:08:04.373559: step 149410, loss = 0.27, batch loss = 0.18 (47.3 examples/sec; 0.169 sec/batch; 8h:36m:30s remains)
INFO - root - 2017-12-01 09:08:05.929265: step 149420, loss = 0.23, batch loss = 0.15 (52.0 examples/sec; 0.154 sec/batch; 7h:49m:43s remains)
INFO - root - 2017-12-01 09:08:07.494052: step 149430, loss = 0.25, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 7h:54m:13s remains)
INFO - root - 2017-12-01 09:08:09.064785: step 149440, loss = 0.22, batch loss = 0.13 (51.3 examples/sec; 0.156 sec/batch; 7h:55m:38s remains)
INFO - root - 2017-12-01 09:08:10.624705: step 149450, loss = 0.26, batch loss = 0.18 (49.9 examples/sec; 0.160 sec/batch; 8h:09m:08s remains)
INFO - root - 2017-12-01 09:08:12.194940: step 149460, loss = 0.35, batch loss = 0.26 (49.5 examples/sec; 0.162 sec/batch; 8h:12m:41s remains)
INFO - root - 2017-12-01 09:08:13.775581: step 149470, loss = 0.28, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 7h:56m:21s remains)
INFO - root - 2017-12-01 09:08:15.330372: step 149480, loss = 0.22, batch loss = 0.14 (51.9 examples/sec; 0.154 sec/batch; 7h:49m:56s remains)
INFO - root - 2017-12-01 09:08:16.913117: step 149490, loss = 0.31, batch loss = 0.22 (50.9 examples/sec; 0.157 sec/batch; 7h:59m:11s remains)
INFO - root - 2017-12-01 09:08:18.468598: step 149500, loss = 0.26, batch loss = 0.17 (49.8 examples/sec; 0.161 sec/batch; 8h:10m:09s remains)
INFO - root - 2017-12-01 09:08:20.077459: step 149510, loss = 0.24, batch loss = 0.15 (51.1 examples/sec; 0.157 sec/batch; 7h:57m:29s remains)
INFO - root - 2017-12-01 09:08:21.646713: step 149520, loss = 0.22, batch loss = 0.14 (51.2 examples/sec; 0.156 sec/batch; 7h:56m:48s remains)
INFO - root - 2017-12-01 09:08:23.218261: step 149530, loss = 0.26, batch loss = 0.17 (53.0 examples/sec; 0.151 sec/batch; 7h:40m:14s remains)
INFO - root - 2017-12-01 09:08:24.766942: step 149540, loss = 0.39, batch loss = 0.31 (51.7 examples/sec; 0.155 sec/batch; 7h:51m:34s remains)
INFO - root - 2017-12-01 09:08:26.335961: step 149550, loss = 0.24, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 7h:53m:55s remains)
INFO - root - 2017-12-01 09:08:27.923610: step 149560, loss = 0.44, batch loss = 0.36 (48.9 examples/sec; 0.164 sec/batch; 8h:18m:56s remains)
INFO - root - 2017-12-01 09:08:29.477352: step 149570, loss = 0.29, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 8h:03m:44s remains)
INFO - root - 2017-12-01 09:08:31.045661: step 149580, loss = 0.28, batch loss = 0.20 (50.2 examples/sec; 0.159 sec/batch; 8h:05m:31s remains)
INFO - root - 2017-12-01 09:08:32.593419: step 149590, loss = 0.37, batch loss = 0.28 (51.1 examples/sec; 0.157 sec/batch; 7h:57m:41s remains)
INFO - root - 2017-12-01 09:08:34.158774: step 149600, loss = 0.42, batch loss = 0.33 (52.0 examples/sec; 0.154 sec/batch; 7h:48m:37s remains)
INFO - root - 2017-12-01 09:08:35.778514: step 149610, loss = 0.27, batch loss = 0.19 (50.6 examples/sec; 0.158 sec/batch; 8h:01m:59s remains)
INFO - root - 2017-12-01 09:08:37.333186: step 149620, loss = 0.33, batch loss = 0.25 (50.3 examples/sec; 0.159 sec/batch; 8h:04m:47s remains)
INFO - root - 2017-12-01 09:08:38.889964: step 149630, loss = 0.30, batch loss = 0.21 (48.9 examples/sec; 0.164 sec/batch; 8h:19m:03s remains)
INFO - root - 2017-12-01 09:08:40.473374: step 149640, loss = 0.34, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 7h:58m:09s remains)
INFO - root - 2017-12-01 09:08:42.077010: step 149650, loss = 0.27, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 7h:53m:39s remains)
INFO - root - 2017-12-01 09:08:43.630768: step 149660, loss = 0.25, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 7h:51m:33s remains)
INFO - root - 2017-12-01 09:08:45.202221: step 149670, loss = 0.30, batch loss = 0.22 (51.6 examples/sec; 0.155 sec/batch; 7h:52m:49s remains)
INFO - root - 2017-12-01 09:08:46.771377: step 149680, loss = 0.28, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 7h:52m:31s remains)
INFO - root - 2017-12-01 09:08:48.326820: step 149690, loss = 0.33, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 7h:49m:48s remains)
INFO - root - 2017-12-01 09:08:49.894921: step 149700, loss = 0.47, batch loss = 0.38 (51.2 examples/sec; 0.156 sec/batch; 7h:56m:22s remains)
INFO - root - 2017-12-01 09:08:51.540784: step 149710, loss = 0.27, batch loss = 0.19 (52.2 examples/sec; 0.153 sec/batch; 7h:47m:20s remains)
INFO - root - 2017-12-01 09:08:53.097815: step 149720, loss = 0.29, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 8h:00m:14s remains)
INFO - root - 2017-12-01 09:08:54.666521: step 149730, loss = 0.25, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 7h:58m:57s remains)
INFO - root - 2017-12-01 09:08:56.222971: step 149740, loss = 0.23, batch loss = 0.15 (51.9 examples/sec; 0.154 sec/batch; 7h:49m:39s remains)
INFO - root - 2017-12-01 09:08:57.767771: step 149750, loss = 0.25, batch loss = 0.17 (53.5 examples/sec; 0.149 sec/batch; 7h:35m:07s remains)
INFO - root - 2017-12-01 09:08:59.354183: step 149760, loss = 0.25, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 7h:51m:03s remains)
INFO - root - 2017-12-01 09:09:00.915995: step 149770, loss = 0.27, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 7h:58m:33s remains)
INFO - root - 2017-12-01 09:09:02.483883: step 149780, loss = 0.27, batch loss = 0.19 (49.5 examples/sec; 0.162 sec/batch; 8h:11m:56s remains)
INFO - root - 2017-12-01 09:09:04.074241: step 149790, loss = 0.30, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 7h:48m:17s remains)
INFO - root - 2017-12-01 09:09:05.652038: step 149800, loss = 0.27, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 7h:48m:15s remains)
INFO - root - 2017-12-01 09:09:07.263352: step 149810, loss = 0.31, batch loss = 0.23 (50.1 examples/sec; 0.160 sec/batch; 8h:06m:26s remains)
INFO - root - 2017-12-01 09:09:08.819910: step 149820, loss = 0.29, batch loss = 0.21 (52.4 examples/sec; 0.153 sec/batch; 7h:44m:43s remains)
INFO - root - 2017-12-01 09:09:10.429889: step 149830, loss = 0.27, batch loss = 0.19 (51.0 examples/sec; 0.157 sec/batch; 7h:57m:15s remains)
INFO - root - 2017-12-01 09:09:12.021782: step 149840, loss = 0.28, batch loss = 0.20 (48.8 examples/sec; 0.164 sec/batch; 8h:19m:34s remains)
INFO - root - 2017-12-01 09:09:13.576787: step 149850, loss = 0.26, batch loss = 0.17 (51.0 examples/sec; 0.157 sec/batch; 7h:57m:11s remains)
INFO - root - 2017-12-01 09:09:15.152120: step 149860, loss = 0.34, batch loss = 0.26 (49.9 examples/sec; 0.160 sec/batch; 8h:07m:45s remains)
INFO - root - 2017-12-01 09:09:16.716078: step 149870, loss = 0.26, batch loss = 0.18 (50.3 examples/sec; 0.159 sec/batch; 8h:04m:29s remains)
INFO - root - 2017-12-01 09:09:18.281346: step 149880, loss = 0.30, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 8h:05m:22s remains)
INFO - root - 2017-12-01 09:09:19.847466: step 149890, loss = 0.21, batch loss = 0.13 (51.8 examples/sec; 0.154 sec/batch; 7h:50m:06s remains)
INFO - root - 2017-12-01 09:09:21.417171: step 149900, loss = 0.45, batch loss = 0.37 (51.4 examples/sec; 0.156 sec/batch; 7h:54m:01s remains)
INFO - root - 2017-12-01 09:09:23.050608: step 149910, loss = 0.27, batch loss = 0.19 (50.2 examples/sec; 0.159 sec/batch; 8h:05m:12s remains)
INFO - root - 2017-12-01 09:09:24.601804: step 149920, loss = 0.29, batch loss = 0.21 (49.2 examples/sec; 0.163 sec/batch; 8h:14m:55s remains)
INFO - root - 2017-12-01 09:09:26.166281: step 149930, loss = 0.25, batch loss = 0.16 (50.5 examples/sec; 0.158 sec/batch; 8h:01m:53s remains)
INFO - root - 2017-12-01 09:09:27.739302: step 149940, loss = 0.33, batch loss = 0.25 (51.1 examples/sec; 0.157 sec/batch; 7h:56m:11s remains)
INFO - root - 2017-12-01 09:09:29.305877: step 149950, loss = 0.33, batch loss = 0.25 (50.9 examples/sec; 0.157 sec/batch; 7h:57m:44s remains)
INFO - root - 2017-12-01 09:09:30.867583: step 149960, loss = 0.29, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 7h:53m:35s remains)
INFO - root - 2017-12-01 09:09:32.441602: step 149970, loss = 0.32, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 7h:56m:03s remains)
INFO - root - 2017-12-01 09:09:34.006598: step 149980, loss = 0.33, batch loss = 0.24 (49.6 examples/sec; 0.161 sec/batch; 8h:10m:45s remains)
INFO - root - 2017-12-01 09:09:35.590071: step 149990, loss = 0.28, batch loss = 0.20 (51.9 examples/sec; 0.154 sec/batch; 7h:49m:09s remains)
INFO - root - 2017-12-01 09:09:37.154100: step 150000, loss = 0.30, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 7h:53m:23s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-150000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC/model.ckpt-150000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-01 09:09:39.218524: step 150010, loss = 0.28, batch loss = 0.20 (48.5 examples/sec; 0.165 sec/batch; 8h:21m:46s remains)
INFO - root - 2017-12-01 09:09:40.798323: step 150020, loss = 0.25, batch loss = 0.16 (50.3 examples/sec; 0.159 sec/batch; 8h:03m:51s remains)
INFO - root - 2017-12-01 09:09:42.379273: step 150030, loss = 0.28, batch loss = 0.20 (50.7 examples/sec; 0.158 sec/batch; 8h:00m:03s remains)
INFO - root - 2017-12-01 09:09:43.960796: step 150040, loss = 0.27, batch loss = 0.18 (45.4 examples/sec; 0.176 sec/batch; 8h:55m:22s remains)
INFO - root - 2017-12-01 09:09:45.525964: step 150050, loss = 0.35, batch loss = 0.27 (53.1 examples/sec; 0.151 sec/batch; 7h:38m:14s remains)
INFO - root - 2017-12-01 09:09:47.081626: step 150060, loss = 0.40, batch loss = 0.31 (51.8 examples/sec; 0.155 sec/batch; 7h:49m:59s remains)
INFO - root - 2017-12-01 09:09:48.643877: step 150070, loss = 0.24, batch loss = 0.16 (52.5 examples/sec; 0.152 sec/batch; 7h:43m:00s remains)
INFO - root - 2017-12-01 09:09:50.212776: step 150080, loss = 0.30, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 8h:00m:38s remains)
INFO - root - 2017-12-01 09:09:51.777849: step 150090, loss = 0.34, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 7h:54m:14s remains)
INFO - root - 2017-12-01 09:09:53.325797: step 150100, loss = 0.26, batch loss = 0.18 (51.7 examples/sec; 0.155 sec/batch; 7h:50m:29s remains)
INFO - root - 2017-12-01 09:09:54.950844: step 150110, loss = 0.26, batch loss = 0.18 (50.5 examples/sec; 0.159 sec/batch; 8h:01m:49s remains)
INFO - root - 2017-12-01 09:09:56.512438: step 150120, loss = 0.28, batch loss = 0.20 (50.3 examples/sec; 0.159 sec/batch; 8h:03m:19s remains)
INFO - root - 2017-12-01 09:09:58.058975: step 150130, loss = 0.23, batch loss = 0.14 (52.5 examples/sec; 0.152 sec/batch; 7h:43m:06s remains)
INFO - root - 2017-12-01 09:09:59.612907: step 150140, loss = 0.33, batch loss = 0.25 (50.8 examples/sec; 0.158 sec/batch; 7h:58m:59s remains)
INFO - root - 2017-12-01 09:10:01.183213: step 150150, loss = 0.26, batch loss = 0.17 (51.9 examples/sec; 0.154 sec/batch; 7h:48m:08s remains)
INFO - root - 2017-12-01 09:10:02.753333: step 150160, loss = 0.26, batch loss = 0.17 (50.8 examples/sec; 0.158 sec/batch; 7h:58m:46s remains)
INFO - root - 2017-12-01 09:10:04.358892: step 150170, loss = 0.33, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 7h:52m:27s remains)
INFO - root - 2017-12-01 09:10:05.916489: step 150180, loss = 0.22, batch loss = 0.14 (51.4 examples/sec; 0.156 sec/batch; 7h:52m:45s remains)
INFO - root - 2017-12-01 09:10:07.471940: step 150190, loss = 0.29, batch loss = 0.21 (52.0 examples/sec; 0.154 sec/batch; 7h:47m:37s remains)
INFO - root - 2017-12-01 09:10:09.042191: step 150200, loss = 0.30, batch loss = 0.22 (50.1 examples/sec; 0.160 sec/batch; 8h:05m:33s remains)
INFO - root - 2017-12-01 09:10:10.674177: step 150210, loss = 0.28, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 7h:55m:02s remains)
INFO - root - 2017-12-01 09:10:12.254859: step 150220, loss = 0.30, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 8h:03m:25s remains)
INFO - root - 2017-12-01 09:10:13.826987: step 150230, loss = 0.23, batch loss = 0.15 (52.1 examples/sec; 0.153 sec/batch; 7h:46m:15s remains)
INFO - root - 2017-12-01 09:10:15.383865: step 150240, loss = 0.32, batch loss = 0.23 (50.2 examples/sec; 0.159 sec/batch; 8h:03m:45s remains)
INFO - root - 2017-12-01 09:10:16.934556: step 150250, loss = 0.48, batch loss = 0.40 (51.6 examples/sec; 0.155 sec/batch; 7h:51m:05s remains)
INFO - root - 2017-12-01 09:10:18.488186: step 150260, loss = 0.26, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 7h:51m:58s remains)
INFO - root - 2017-12-01 09:10:20.052103: step 150270, loss = 0.23, batch loss = 0.15 (49.3 examples/sec; 0.162 sec/batch; 8h:12m:37s remains)
INFO - root - 2017-12-01 09:10:21.615382: step 150280, loss = 0.26, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 7h:55m:18s remains)
INFO - root - 2017-12-01 09:10:23.180697: step 150290, loss = 0.30, batch loss = 0.22 (50.2 examples/sec; 0.159 sec/batch; 8h:04m:12s remains)
INFO - root - 2017-12-01 09:10:24.779283: step 150300, loss = 0.28, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 8h:00m:56s remains)
INFO - root - 2017-12-01 09:10:26.423967: step 150310, loss = 0.28, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 7h:57m:38s remains)
INFO - root - 2017-12-01 09:10:27.981497: step 150320, loss = 0.27, batch loss = 0.19 (51.6 examples/sec; 0.155 sec/batch; 7h:50m:58s remains)
INFO - root - 2017-12-01 09:10:29.537950: step 150330, loss = 0.24, batch loss = 0.16 (51.1 examples/sec; 0.157 sec/batch; 7h:55m:15s remains)
INFO - root - 2017-12-01 09:10:31.111550: step 150340, loss = 0.60, batch loss = 0.52 (51.3 examples/sec; 0.156 sec/batch; 7h:53m:19s remains)
INFO - root - 2017-12-01 09:10:32.676963: step 150350, loss = 0.34, batch loss = 0.26 (51.1 examples/sec; 0.157 sec/batch; 7h:55m:38s remains)
INFO - root - 2017-12-01 09:10:34.236812: step 150360, loss = 0.30, batch loss = 0.22 (52.0 examples/sec; 0.154 sec/batch; 7h:46m:45s remains)
INFO - root - 2017-12-01 09:10:35.795228: step 150370, loss = 0.32, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 7h:56m:16s remains)
INFO - root - 2017-12-01 09:10:37.351888: step 150380, loss = 0.33, batch loss = 0.24 (51.2 examples/sec; 0.156 sec/batch; 7h:53m:48s remains)
INFO - root - 2017-12-01 09:10:38.941513: step 150390, loss = 0.29, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 7h:57m:27s remains)
INFO - root - 2017-12-01 09:10:40.505961: step 150400, loss = 0.24, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 7h:52m:33s remains)
INFO - root - 2017-12-01 09:10:42.176853: step 150410, loss = 0.25, batch loss = 0.17 (53.3 examples/sec; 0.150 sec/batch; 7h:35m:54s remains)
INFO - root - 2017-12-01 09:10:43.746734: step 150420, loss = 0.27, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 7h:53m:46s remains)
INFO - root - 2017-12-01 09:10:45.331389: step 150430, loss = 0.30, batch loss = 0.21 (48.6 examples/sec; 0.165 sec/batch; 8h:19m:33s remains)
INFO - root - 2017-12-01 09:10:46.889740: step 150440, loss = 0.30, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 7h:50m:29s remains)
INFO - root - 2017-12-01 09:10:48.463783: step 150450, loss = 0.29, batch loss = 0.21 (50.6 examples/sec; 0.158 sec/batch; 7h:59m:20s remains)
INFO - root - 2017-12-01 09:10:50.023325: step 150460, loss = 0.26, batch loss = 0.17 (51.6 examples/sec; 0.155 sec/batch; 7h:50m:31s remains)
INFO - root - 2017-12-01 09:10:51.590693: step 150470, loss = 0.23, batch loss = 0.15 (51.3 examples/sec; 0.156 sec/batch; 7h:52m:42s remains)
INFO - root - 2017-12-01 09:10:53.145535: step 150480, loss = 0.29, batch loss = 0.21 (52.5 examples/sec; 0.153 sec/batch; 7h:42m:42s remains)
INFO - root - 2017-12-01 09:10:54.711854: step 150490, loss = 0.34, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 7h:48m:05s remains)
INFO - root - 2017-12-01 09:10:56.271771: step 150500, loss = 0.24, batch loss = 0.16 (52.1 examples/sec; 0.154 sec/batch; 7h:46m:05s remains)
INFO - root - 2017-12-01 09:10:57.904907: step 150510, loss = 0.27, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 7h:53m:58s remains)
INFO - root - 2017-12-01 09:10:59.465162: step 150520, loss = 0.27, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 7h:51m:08s remains)
INFO - root - 2017-12-01 09:11:01.034102: step 150530, loss = 0.44, batch loss = 0.36 (52.3 examples/sec; 0.153 sec/batch; 7h:43m:52s remains)
INFO - root - 2017-12-01 09:11:02.609032: step 150540, loss = 0.28, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 7h:53m:09s remains)
INFO - root - 2017-12-01 09:11:04.176514: step 150550, loss = 0.32, batch loss = 0.24 (50.6 examples/sec; 0.158 sec/batch; 7h:59m:08s remains)
INFO - root - 2017-12-01 09:11:05.733027: step 150560, loss = 0.39, batch loss = 0.31 (49.9 examples/sec; 0.160 sec/batch; 8h:05m:56s remains)
INFO - root - 2017-12-01 09:11:07.296361: step 150570, loss = 0.29, batch loss = 0.21 (51.6 examples/sec; 0.155 sec/batch; 7h:50m:03s remains)
INFO - root - 2017-12-01 09:11:08.868790: step 150580, loss = 0.32, batch loss = 0.24 (49.3 examples/sec; 0.162 sec/batch; 8h:12m:07s remains)
INFO - root - 2017-12-01 09:11:10.431875: step 150590, loss = 0.52, batch loss = 0.44 (51.1 examples/sec; 0.157 sec/batch; 7h:55m:01s remains)
INFO - root - 2017-12-01 09:11:12.010610: step 150600, loss = 0.44, batch loss = 0.36 (50.0 examples/sec; 0.160 sec/batch; 8h:05m:08s remains)
INFO - root - 2017-12-01 09:11:13.688681: step 150610, loss = 0.26, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 7h:56m:24s remains)
INFO - root - 2017-12-01 09:11:15.274577: step 150620, loss = 0.29, batch loss = 0.20 (49.1 examples/sec; 0.163 sec/batch; 8h:13m:39s remains)
INFO - root - 2017-12-01 09:11:16.856122: step 150630, loss = 0.39, batch loss = 0.31 (51.6 examples/sec; 0.155 sec/batch; 7h:50m:10s remains)
INFO - root - 2017-12-01 09:11:18.425705: step 150640, loss = 0.27, batch loss = 0.19 (50.3 examples/sec; 0.159 sec/batch; 8h:02m:01s remains)
INFO - root - 2017-12-01 09:11:19.984322: step 150650, loss = 0.30, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 8h:01m:48s remains)
INFO - root - 2017-12-01 09:11:21.551783: step 150660, loss = 0.25, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 8h:01m:39s remains)
INFO - root - 2017-12-01 09:11:23.115851: step 150670, loss = 0.31, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 7h:49m:20s remains)
INFO - root - 2017-12-01 09:11:24.686300: step 150680, loss = 0.32, batch loss = 0.23 (51.1 examples/sec; 0.156 sec/batch; 7h:54m:08s remains)
INFO - root - 2017-12-01 09:11:26.257382: step 150690, loss = 0.26, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 8h:01m:38s remains)
INFO - root - 2017-12-01 09:11:27.809729: step 150700, loss = 0.28, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 7h:53m:21s remains)
INFO - root - 2017-12-01 09:11:29.429279: step 150710, loss = 0.26, batch loss = 0.17 (50.8 examples/sec; 0.158 sec/batch; 7h:57m:11s remains)
INFO - root - 2017-12-01 09:11:30.998452: step 150720, loss = 0.30, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 7h:53m:37s remains)
INFO - root - 2017-12-01 09:11:32.564532: step 150730, loss = 0.26, batch loss = 0.18 (51.2 examples/sec; 0.156 sec/batch; 7h:53m:02s remains)
INFO - root - 2017-12-01 09:11:34.117453: step 150740, loss = 0.31, batch loss = 0.23 (50.7 examples/sec; 0.158 sec/batch; 7h:58m:01s remains)
INFO - root - 2017-12-01 09:11:35.669596: step 150750, loss = 0.28, batch loss = 0.19 (52.3 examples/sec; 0.153 sec/batch; 7h:43m:14s remains)
INFO - root - 2017-12-01 09:11:37.240283: step 150760, loss = 0.24, batch loss = 0.16 (51.9 examples/sec; 0.154 sec/batch; 7h:46m:40s remains)
INFO - root - 2017-12-01 09:11:38.793683: step 150770, loss = 0.33, batch loss = 0.25 (50.6 examples/sec; 0.158 sec/batch; 7h:58m:47s remains)
INFO - root - 2017-12-01 09:11:40.376522: step 150780, loss = 0.31, batch loss = 0.23 (50.6 examples/sec; 0.158 sec/batch; 7h:58m:39s remains)
INFO - root - 2017-12-01 09:11:41.953759: step 150790, loss = 0.31, batch loss = 0.23 (48.9 examples/sec; 0.163 sec/batch; 8h:15m:03s remains)
INFO - root - 2017-12-01 09:11:43.538114: step 150800, loss = 0.34, batch loss = 0.26 (51.3 examples/sec; 0.156 sec/batch; 7h:52m:08s remains)
INFO - root - 2017-12-01 09:11:45.153633: step 150810, loss = 0.35, batch loss = 0.27 (51.3 examples/sec; 0.156 sec/batch; 7h:52m:11s remains)
INFO - root - 2017-12-01 09:11:46.693727: step 150820, loss = 0.31, batch loss = 0.23 (51.8 examples/sec; 0.154 sec/batch; 7h:47m:35s remains)
INFO - root - 2017-12-01 09:11:48.251413: step 150830, loss = 0.31, batch loss = 0.23 (51.0 examples/sec; 0.157 sec/batch; 7h:54m:49s remains)
INFO - root - 2017-12-01 09:11:49.834843: step 150840, loss = 0.32, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 7h:52m:20s remains)
INFO - root - 2017-12-01 09:11:51.398631: step 150850, loss = 0.34, batch loss = 0.26 (47.9 examples/sec; 0.167 sec/batch; 8h:25m:50s remains)
INFO - root - 2017-12-01 09:11:52.960787: step 150860, loss = 0.31, batch loss = 0.23 (49.0 examples/sec; 0.163 sec/batch; 8h:14m:41s remains)
INFO - root - 2017-12-01 09:11:54.524989: step 150870, loss = 0.29, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 7h:56m:36s remains)
INFO - root - 2017-12-01 09:11:56.117951: step 150880, loss = 0.36, batch loss = 0.28 (49.6 examples/sec; 0.161 sec/batch; 8h:07m:53s remains)
INFO - root - 2017-12-01 09:11:57.683329: step 150890, loss = 0.28, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 8h:04m:47s remains)
INFO - root - 2017-12-01 09:11:59.249136: step 150900, loss = 0.29, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 7h:57m:17s remains)
INFO - root - 2017-12-01 09:12:00.894426: step 150910, loss = 0.25, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 7h:48m:08s remains)
INFO - root - 2017-12-01 09:12:02.485944: step 150920, loss = 0.25, batch loss = 0.17 (49.9 examples/sec; 0.160 sec/batch; 8h:04m:48s remains)
INFO - root - 2017-12-01 09:12:04.046613: step 150930, loss = 0.31, batch loss = 0.22 (50.6 examples/sec; 0.158 sec/batch; 7h:58m:26s remains)
INFO - root - 2017-12-01 09:12:05.615958: step 150940, loss = 0.28, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 7h:50m:52s remains)
INFO - root - 2017-12-01 09:12:07.178667: step 150950, loss = 0.24, batch loss = 0.16 (52.5 examples/sec; 0.152 sec/batch; 7h:41m:24s remains)
INFO - root - 2017-12-01 09:12:08.743773: step 150960, loss = 0.29, batch loss = 0.21 (50.7 examples/sec; 0.158 sec/batch; 7h:57m:11s remains)
INFO - root - 2017-12-01 09:12:10.309978: step 150970, loss = 0.26, batch loss = 0.18 (49.4 examples/sec; 0.162 sec/batch; 8h:09m:28s remains)
INFO - root - 2017-12-01 09:12:11.892559: step 150980, loss = 0.42, batch loss = 0.34 (51.1 examples/sec; 0.157 sec/batch; 7h:54m:03s remains)
INFO - root - 2017-12-01 09:12:13.483154: step 150990, loss = 0.33, batch loss = 0.25 (52.3 examples/sec; 0.153 sec/batch; 7h:43m:08s remains)
INFO - root - 2017-12-01 09:12:15.036464: step 151000, loss = 0.29, batch loss = 0.20 (50.5 examples/sec; 0.158 sec/batch; 7h:59m:20s remains)
INFO - root - 2017-12-01 09:12:16.683006: step 151010, loss = 0.29, batch loss = 0.21 (51.3 examples/sec; 0.156 sec/batch; 7h:51m:20s remains)
INFO - root - 2017-12-01 09:12:18.268542: step 151020, loss = 0.31, batch loss = 0.23 (51.8 examples/sec; 0.155 sec/batch; 7h:47m:23s remains)
INFO - root - 2017-12-01 09:12:19.848784: step 151030, loss = 0.30, batch loss = 0.22 (48.8 examples/sec; 0.164 sec/batch; 8h:16m:15s remains)
INFO - root - 2017-12-01 09:12:21.436180: step 151040, loss = 0.21, batch loss = 0.13 (50.8 examples/sec; 0.158 sec/batch; 7h:56m:26s remains)
INFO - root - 2017-12-01 09:12:23.016931: step 151050, loss = 0.27, batch loss = 0.19 (50.0 examples/sec; 0.160 sec/batch; 8h:03m:59s remains)
INFO - root - 2017-12-01 09:12:24.578614: step 151060, loss = 0.33, batch loss = 0.24 (49.7 examples/sec; 0.161 sec/batch; 8h:07m:11s remains)
INFO - root - 2017-12-01 09:12:26.141727: step 151070, loss = 0.32, batch loss = 0.24 (50.9 examples/sec; 0.157 sec/batch; 7h:55m:04s remains)
INFO - root - 2017-12-01 09:12:27.698914: step 151080, loss = 0.26, batch loss = 0.18 (52.7 examples/sec; 0.152 sec/batch; 7h:39m:03s remains)
INFO - root - 2017-12-01 09:12:29.291199: step 151090, loss = 0.32, batch loss = 0.24 (50.1 examples/sec; 0.160 sec/batch; 8h:03m:08s remains)
INFO - root - 2017-12-01 09:12:30.862952: step 151100, loss = 0.24, batch loss = 0.16 (49.9 examples/sec; 0.160 sec/batch; 8h:05m:04s remains)
INFO - root - 2017-12-01 09:12:32.501532: step 151110, loss = 0.31, batch loss = 0.22 (51.8 examples/sec; 0.154 sec/batch; 7h:46m:28s remains)
INFO - root - 2017-12-01 09:12:34.089889: step 151120, loss = 0.56, batch loss = 0.48 (48.8 examples/sec; 0.164 sec/batch; 8h:15m:41s remains)
INFO - root - 2017-12-01 09:12:35.650945: step 151130, loss = 0.29, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 7h:49m:43s remains)
INFO - root - 2017-12-01 09:12:37.204626: step 151140, loss = 0.38, batch loss = 0.30 (51.1 examples/sec; 0.157 sec/batch; 7h:53m:32s remains)
INFO - root - 2017-12-01 09:12:38.773094: step 151150, loss = 0.35, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 7h:55m:09s remains)
INFO - root - 2017-12-01 09:12:40.346423: step 151160, loss = 0.29, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 7h:54m:44s remains)
INFO - root - 2017-12-01 09:12:41.942118: step 151170, loss = 0.28, batch loss = 0.20 (48.8 examples/sec; 0.164 sec/batch; 8h:14m:55s remains)
INFO - root - 2017-12-01 09:12:43.506814: step 151180, loss = 0.34, batch loss = 0.26 (52.6 examples/sec; 0.152 sec/batch; 7h:39m:16s remains)
INFO - root - 2017-12-01 09:12:45.072984: step 151190, loss = 0.31, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 7h:55m:15s remains)
INFO - root - 2017-12-01 09:12:46.636161: step 151200, loss = 0.24, batch loss = 0.16 (51.4 examples/sec; 0.156 sec/batch; 7h:50m:15s remains)
INFO - root - 2017-12-01 09:12:48.234996: step 151210, loss = 0.31, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 7h:56m:03s remains)
INFO - root - 2017-12-01 09:12:49.806314: step 151220, loss = 0.27, batch loss = 0.19 (51.9 examples/sec; 0.154 sec/batch; 7h:45m:24s remains)
INFO - root - 2017-12-01 09:12:51.374480: step 151230, loss = 0.54, batch loss = 0.46 (51.7 examples/sec; 0.155 sec/batch; 7h:47m:10s remains)
INFO - root - 2017-12-01 09:12:52.942766: step 151240, loss = 0.27, batch loss = 0.19 (50.7 examples/sec; 0.158 sec/batch; 7h:56m:28s remains)
INFO - root - 2017-12-01 09:12:54.514152: step 151250, loss = 0.27, batch loss = 0.18 (49.8 examples/sec; 0.161 sec/batch; 8h:05m:00s remains)
INFO - root - 2017-12-01 09:12:56.093473: step 151260, loss = 0.24, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 7h:50m:42s remains)
INFO - root - 2017-12-01 09:12:57.661776: step 151270, loss = 0.32, batch loss = 0.24 (51.8 examples/sec; 0.155 sec/batch; 7h:46m:49s remains)
INFO - root - 2017-12-01 09:12:59.247325: step 151280, loss = 0.32, batch loss = 0.24 (51.0 examples/sec; 0.157 sec/batch; 7h:54m:05s remains)
INFO - root - 2017-12-01 09:13:00.794413: step 151290, loss = 0.35, batch loss = 0.26 (51.8 examples/sec; 0.154 sec/batch; 7h:46m:13s remains)
INFO - root - 2017-12-01 09:13:02.358828: step 151300, loss = 0.38, batch loss = 0.30 (52.9 examples/sec; 0.151 sec/batch; 7h:36m:54s remains)
INFO - root - 2017-12-01 09:13:03.993022: step 151310, loss = 0.33, batch loss = 0.24 (51.1 examples/sec; 0.157 sec/batch; 7h:53m:03s remains)
INFO - root - 2017-12-01 09:13:05.576775: step 151320, loss = 0.29, batch loss = 0.21 (49.2 examples/sec; 0.163 sec/batch; 8h:11m:26s remains)
INFO - root - 2017-12-01 09:13:07.154397: step 151330, loss = 0.28, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 7h:55m:06s remains)
INFO - root - 2017-12-01 09:13:08.720142: step 151340, loss = 0.26, batch loss = 0.18 (51.6 examples/sec; 0.155 sec/batch; 7h:48m:26s remains)
INFO - root - 2017-12-01 09:13:10.283622: step 151350, loss = 0.30, batch loss = 0.22 (51.5 examples/sec; 0.155 sec/batch; 7h:48m:44s remains)
INFO - root - 2017-12-01 09:13:11.839310: step 151360, loss = 0.30, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 7h:42m:05s remains)
INFO - root - 2017-12-01 09:13:13.405920: step 151370, loss = 0.28, batch loss = 0.20 (51.1 examples/sec; 0.157 sec/batch; 7h:52m:59s remains)
INFO - root - 2017-12-01 09:13:14.982759: step 151380, loss = 0.28, batch loss = 0.20 (52.5 examples/sec; 0.153 sec/batch; 7h:40m:21s remains)
INFO - root - 2017-12-01 09:13:16.544051: step 151390, loss = 0.29, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 7h:58m:19s remains)
INFO - root - 2017-12-01 09:13:18.102332: step 151400, loss = 0.21, batch loss = 0.13 (50.9 examples/sec; 0.157 sec/batch; 7h:54m:22s remains)
INFO - root - 2017-12-01 09:13:19.694529: step 151410, loss = 0.31, batch loss = 0.22 (51.9 examples/sec; 0.154 sec/batch; 7h:45m:11s remains)
INFO - root - 2017-12-01 09:13:21.265155: step 151420, loss = 0.30, batch loss = 0.22 (49.3 examples/sec; 0.162 sec/batch; 8h:09m:20s remains)
INFO - root - 2017-12-01 09:13:22.840473: step 151430, loss = 0.25, batch loss = 0.17 (50.1 examples/sec; 0.160 sec/batch; 8h:01m:53s remains)
INFO - root - 2017-12-01 09:13:24.419164: step 151440, loss = 0.37, batch loss = 0.29 (50.4 examples/sec; 0.159 sec/batch; 7h:59m:08s remains)
INFO - root - 2017-12-01 09:13:25.984206: step 151450, loss = 0.28, batch loss = 0.20 (52.8 examples/sec; 0.152 sec/batch; 7h:37m:20s remains)
INFO - root - 2017-12-01 09:13:27.555107: step 151460, loss = 0.28, batch loss = 0.20 (49.8 examples/sec; 0.161 sec/batch; 8h:05m:08s remains)
INFO - root - 2017-12-01 09:13:29.103524: step 151470, loss = 0.25, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 7h:48m:25s remains)
INFO - root - 2017-12-01 09:13:30.682787: step 151480, loss = 0.35, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 7h:54m:32s remains)
INFO - root - 2017-12-01 09:13:32.240686: step 151490, loss = 0.20, batch loss = 0.12 (51.3 examples/sec; 0.156 sec/batch; 7h:50m:10s remains)
INFO - root - 2017-12-01 09:13:33.793269: step 151500, loss = 0.27, batch loss = 0.19 (51.5 examples/sec; 0.155 sec/batch; 7h:48m:57s remains)
INFO - root - 2017-12-01 09:13:35.415561: step 151510, loss = 0.26, batch loss = 0.18 (51.1 examples/sec; 0.157 sec/batch; 7h:52m:13s remains)
INFO - root - 2017-12-01 09:13:36.975567: step 151520, loss = 0.24, batch loss = 0.15 (50.4 examples/sec; 0.159 sec/batch; 7h:58m:29s remains)
INFO - root - 2017-12-01 09:13:38.534958: step 151530, loss = 0.26, batch loss = 0.18 (49.4 examples/sec; 0.162 sec/batch; 8h:08m:22s remains)
INFO - root - 2017-12-01 09:13:40.089561: step 151540, loss = 0.32, batch loss = 0.23 (52.1 examples/sec; 0.154 sec/batch; 7h:42m:57s remains)
INFO - root - 2017-12-01 09:13:41.670898: step 151550, loss = 0.25, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 7h:49m:16s remains)
INFO - root - 2017-12-01 09:13:43.239175: step 151560, loss = 0.25, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 7h:51m:21s remains)
INFO - root - 2017-12-01 09:13:44.827427: step 151570, loss = 0.30, batch loss = 0.21 (48.6 examples/sec; 0.165 sec/batch; 8h:16m:38s remains)
INFO - root - 2017-12-01 09:13:46.380737: step 151580, loss = 0.29, batch loss = 0.21 (53.2 examples/sec; 0.150 sec/batch; 7h:33m:28s remains)
INFO - root - 2017-12-01 09:13:47.942965: step 151590, loss = 0.30, batch loss = 0.21 (52.1 examples/sec; 0.154 sec/batch; 7h:43m:07s remains)
INFO - root - 2017-12-01 09:13:49.523741: step 151600, loss = 0.26, batch loss = 0.18 (51.8 examples/sec; 0.155 sec/batch; 7h:45m:56s remains)
INFO - root - 2017-12-01 09:13:51.127948: step 151610, loss = 0.37, batch loss = 0.29 (52.4 examples/sec; 0.153 sec/batch; 7h:40m:42s remains)
INFO - root - 2017-12-01 09:13:52.675726: step 151620, loss = 0.38, batch loss = 0.30 (53.3 examples/sec; 0.150 sec/batch; 7h:32m:31s remains)
INFO - root - 2017-12-01 09:13:54.243931: step 151630, loss = 0.23, batch loss = 0.15 (51.6 examples/sec; 0.155 sec/batch; 7h:46m:55s remains)
INFO - root - 2017-12-01 09:13:55.815670: step 151640, loss = 0.26, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 7h:59m:25s remains)
INFO - root - 2017-12-01 09:13:57.375482: step 151650, loss = 0.31, batch loss = 0.23 (49.3 examples/sec; 0.162 sec/batch; 8h:08m:57s remains)
INFO - root - 2017-12-01 09:13:58.926908: step 151660, loss = 0.33, batch loss = 0.24 (51.3 examples/sec; 0.156 sec/batch; 7h:49m:42s remains)
INFO - root - 2017-12-01 09:14:00.497246: step 151670, loss = 0.29, batch loss = 0.21 (50.8 examples/sec; 0.157 sec/batch; 7h:54m:20s remains)
INFO - root - 2017-12-01 09:14:02.077919: step 151680, loss = 0.28, batch loss = 0.20 (51.4 examples/sec; 0.156 sec/batch; 7h:49m:25s remains)
INFO - root - 2017-12-01 09:14:03.641198: step 151690, loss = 0.33, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 7h:52m:48s remains)
INFO - root - 2017-12-01 09:14:05.230405: step 151700, loss = 0.29, batch loss = 0.21 (48.9 examples/sec; 0.164 sec/batch; 8h:12m:49s remains)
INFO - root - 2017-12-01 09:14:06.857149: step 151710, loss = 0.27, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 7h:51m:59s remains)
INFO - root - 2017-12-01 09:14:08.404796: step 151720, loss = 0.47, batch loss = 0.39 (51.4 examples/sec; 0.156 sec/batch; 7h:48m:56s remains)
INFO - root - 2017-12-01 09:14:09.978399: step 151730, loss = 0.28, batch loss = 0.20 (50.1 examples/sec; 0.160 sec/batch; 8h:01m:11s remains)
INFO - root - 2017-12-01 09:14:11.533571: step 151740, loss = 0.34, batch loss = 0.26 (53.5 examples/sec; 0.150 sec/batch; 7h:30m:42s remains)
INFO - root - 2017-12-01 09:14:13.121402: step 151750, loss = 0.37, batch loss = 0.29 (52.4 examples/sec; 0.153 sec/batch; 7h:39m:42s remains)
INFO - root - 2017-12-01 09:14:14.686238: step 151760, loss = 0.36, batch loss = 0.27 (51.1 examples/sec; 0.157 sec/batch; 7h:51m:52s remains)
INFO - root - 2017-12-01 09:14:16.238451: step 151770, loss = 0.28, batch loss = 0.19 (50.9 examples/sec; 0.157 sec/batch; 7h:53m:29s remains)
INFO - root - 2017-12-01 09:14:17.814547: step 151780, loss = 0.22, batch loss = 0.13 (48.7 examples/sec; 0.164 sec/batch; 8h:14m:46s remains)
INFO - root - 2017-12-01 09:14:19.389304: step 151790, loss = 0.25, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 7h:50m:24s remains)
INFO - root - 2017-12-01 09:14:20.952783: step 151800, loss = 0.44, batch loss = 0.36 (52.2 examples/sec; 0.153 sec/batch; 7h:41m:12s remains)
INFO - root - 2017-12-01 09:14:22.551043: step 151810, loss = 0.27, batch loss = 0.19 (53.2 examples/sec; 0.150 sec/batch; 7h:32m:44s remains)
INFO - root - 2017-12-01 09:14:24.120122: step 151820, loss = 0.33, batch loss = 0.24 (49.6 examples/sec; 0.161 sec/batch; 8h:06m:00s remains)
INFO - root - 2017-12-01 09:14:25.690603: step 151830, loss = 0.25, batch loss = 0.17 (50.1 examples/sec; 0.160 sec/batch; 8h:00m:51s remains)
INFO - root - 2017-12-01 09:14:27.254240: step 151840, loss = 0.34, batch loss = 0.26 (50.9 examples/sec; 0.157 sec/batch; 7h:52m:58s remains)
INFO - root - 2017-12-01 09:14:28.808427: step 151850, loss = 0.24, batch loss = 0.15 (49.7 examples/sec; 0.161 sec/batch; 8h:04m:16s remains)
INFO - root - 2017-12-01 09:14:30.368670: step 151860, loss = 0.29, batch loss = 0.21 (51.7 examples/sec; 0.155 sec/batch; 7h:45m:52s remains)
INFO - root - 2017-12-01 09:14:31.930123: step 151870, loss = 0.35, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 7h:47m:07s remains)
INFO - root - 2017-12-01 09:14:33.495355: step 151880, loss = 0.29, batch loss = 0.21 (52.1 examples/sec; 0.153 sec/batch; 7h:41m:52s remains)
INFO - root - 2017-12-01 09:14:35.079519: step 151890, loss = 0.35, batch loss = 0.27 (50.9 examples/sec; 0.157 sec/batch; 7h:53m:21s remains)
INFO - root - 2017-12-01 09:14:36.636333: step 151900, loss = 0.34, batch loss = 0.26 (50.1 examples/sec; 0.160 sec/batch; 8h:00m:49s remains)
INFO - root - 2017-12-01 09:14:38.286409: step 151910, loss = 0.31, batch loss = 0.23 (51.9 examples/sec; 0.154 sec/batch; 7h:44m:11s remains)
INFO - root - 2017-12-01 09:14:39.850856: step 151920, loss = 0.21, batch loss = 0.13 (51.9 examples/sec; 0.154 sec/batch; 7h:43m:46s remains)
INFO - root - 2017-12-01 09:14:41.413782: step 151930, loss = 0.25, batch loss = 0.16 (50.9 examples/sec; 0.157 sec/batch; 7h:52m:32s remains)
INFO - root - 2017-12-01 09:14:42.964362: step 151940, loss = 0.30, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 7h:49m:50s remains)
INFO - root - 2017-12-01 09:14:44.510079: step 151950, loss = 0.26, batch loss = 0.18 (53.3 examples/sec; 0.150 sec/batch; 7h:31m:56s remains)
INFO - root - 2017-12-01 09:14:46.079897: step 151960, loss = 0.26, batch loss = 0.18 (51.3 examples/sec; 0.156 sec/batch; 7h:49m:28s remains)
INFO - root - 2017-12-01 09:14:47.636634: step 151970, loss = 0.29, batch loss = 0.21 (51.5 examples/sec; 0.155 sec/batch; 7h:47m:29s remains)
INFO - root - 2017-12-01 09:14:49.213997: step 151980, loss = 0.50, batch loss = 0.42 (49.2 examples/sec; 0.163 sec/batch; 8h:09m:26s remains)
INFO - root - 2017-12-01 09:14:50.770970: step 151990, loss = 0.26, batch loss = 0.18 (49.2 examples/sec; 0.163 sec/batch; 8h:09m:18s remains)
INFO - root - 2017-12-01 09:14:52.354747: step 152000, loss = 0.32, batch loss = 0.24 (49.6 examples/sec; 0.161 sec/batch; 8h:05m:35s remains)
INFO - root - 2017-12-01 09:14:53.979973: step 152010, loss = 0.26, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 7h:59m:32s remains)
INFO - root - 2017-12-01 09:14:55.545994: step 152020, loss = 0.46, batch loss = 0.38 (51.4 examples/sec; 0.156 sec/batch; 7h:48m:05s remains)
INFO - root - 2017-12-01 09:14:57.125330: step 152030, loss = 0.35, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 7h:46m:34s remains)
INFO - root - 2017-12-01 09:14:58.675058: step 152040, loss = 0.34, batch loss = 0.26 (52.1 examples/sec; 0.154 sec/batch; 7h:41m:44s remains)
INFO - root - 2017-12-01 09:15:00.245970: step 152050, loss = 0.35, batch loss = 0.27 (49.6 examples/sec; 0.161 sec/batch; 8h:05m:06s remains)
INFO - root - 2017-12-01 09:15:01.835177: step 152060, loss = 0.27, batch loss = 0.19 (49.1 examples/sec; 0.163 sec/batch; 8h:10m:26s remains)
INFO - root - 2017-12-01 09:15:03.397767: step 152070, loss = 0.32, batch loss = 0.24 (53.4 examples/sec; 0.150 sec/batch; 7h:30m:09s remains)
INFO - root - 2017-12-01 09:15:04.986734: step 152080, loss = 0.23, batch loss = 0.15 (51.4 examples/sec; 0.156 sec/batch; 7h:47m:58s remains)
INFO - root - 2017-12-01 09:15:06.562604: step 152090, loss = 0.26, batch loss = 0.18 (49.3 examples/sec; 0.162 sec/batch; 8h:07m:52s remains)
INFO - root - 2017-12-01 09:15:08.118864: step 152100, loss = 0.28, batch loss = 0.19 (52.1 examples/sec; 0.154 sec/batch; 7h:41m:41s remains)
INFO - root - 2017-12-01 09:15:09.757182: step 152110, loss = 0.34, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 7h:46m:55s remains)
INFO - root - 2017-12-01 09:15:11.313509: step 152120, loss = 0.36, batch loss = 0.28 (49.9 examples/sec; 0.160 sec/batch; 8h:01m:41s remains)
INFO - root - 2017-12-01 09:15:12.886454: step 152130, loss = 0.27, batch loss = 0.19 (53.4 examples/sec; 0.150 sec/batch; 7h:30m:12s remains)
INFO - root - 2017-12-01 09:15:14.452904: step 152140, loss = 0.28, batch loss = 0.20 (51.7 examples/sec; 0.155 sec/batch; 7h:45m:10s remains)
INFO - root - 2017-12-01 09:15:16.019848: step 152150, loss = 0.28, batch loss = 0.20 (51.2 examples/sec; 0.156 sec/batch; 7h:50m:01s remains)
INFO - root - 2017-12-01 09:15:17.589936: step 152160, loss = 0.30, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 7h:47m:55s remains)
INFO - root - 2017-12-01 09:15:19.143511: step 152170, loss = 0.27, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 7h:42m:12s remains)
INFO - root - 2017-12-01 09:15:20.727127: step 152180, loss = 0.24, batch loss = 0.16 (51.5 examples/sec; 0.155 sec/batch; 7h:46m:46s remains)
INFO - root - 2017-12-01 09:15:22.286425: step 152190, loss = 0.22, batch loss = 0.13 (50.7 examples/sec; 0.158 sec/batch; 7h:53m:59s remains)
INFO - root - 2017-12-01 09:15:23.858339: step 152200, loss = 0.30, batch loss = 0.22 (51.0 examples/sec; 0.157 sec/batch; 7h:51m:09s remains)
INFO - root - 2017-12-01 09:15:25.570182: step 152210, loss = 0.41, batch loss = 0.33 (49.5 examples/sec; 0.162 sec/batch; 8h:05m:17s remains)
INFO - root - 2017-12-01 09:15:27.164876: step 152220, loss = 0.25, batch loss = 0.17 (53.0 examples/sec; 0.151 sec/batch; 7h:33m:55s remains)
INFO - root - 2017-12-01 09:15:28.740947: step 152230, loss = 0.28, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 7h:48m:46s remains)
INFO - root - 2017-12-01 09:15:30.301720: step 152240, loss = 0.32, batch loss = 0.24 (51.9 examples/sec; 0.154 sec/batch; 7h:43m:31s remains)
INFO - root - 2017-12-01 09:15:31.856464: step 152250, loss = 0.32, batch loss = 0.24 (52.4 examples/sec; 0.153 sec/batch; 7h:38m:30s remains)
INFO - root - 2017-12-01 09:15:33.414110: step 152260, loss = 0.22, batch loss = 0.14 (51.7 examples/sec; 0.155 sec/batch; 7h:44m:53s remains)
INFO - root - 2017-12-01 09:15:34.992488: step 152270, loss = 0.29, batch loss = 0.21 (52.3 examples/sec; 0.153 sec/batch; 7h:39m:22s remains)
INFO - root - 2017-12-01 09:15:36.589451: step 152280, loss = 0.27, batch loss = 0.19 (50.2 examples/sec; 0.159 sec/batch; 7h:58m:36s remains)
INFO - root - 2017-12-01 09:15:38.141974: step 152290, loss = 0.30, batch loss = 0.22 (51.2 examples/sec; 0.156 sec/batch; 7h:49m:05s remains)
INFO - root - 2017-12-01 09:15:39.695262: step 152300, loss = 0.27, batch loss = 0.19 (49.8 examples/sec; 0.161 sec/batch; 8h:02m:17s remains)
INFO - root - 2017-12-01 09:15:41.374183: step 152310, loss = 0.31, batch loss = 0.23 (50.8 examples/sec; 0.158 sec/batch; 7h:53m:24s remains)
INFO - root - 2017-12-01 09:15:42.916913: step 152320, loss = 0.23, batch loss = 0.15 (50.8 examples/sec; 0.157 sec/batch; 7h:52m:28s remains)
INFO - root - 2017-12-01 09:15:44.467449: step 152330, loss = 0.25, batch loss = 0.17 (51.7 examples/sec; 0.155 sec/batch; 7h:44m:24s remains)
INFO - root - 2017-12-01 09:15:46.036857: step 152340, loss = 0.37, batch loss = 0.29 (50.8 examples/sec; 0.158 sec/batch; 7h:53m:12s remains)
INFO - root - 2017-12-01 09:15:47.609361: step 152350, loss = 0.41, batch loss = 0.33 (50.1 examples/sec; 0.160 sec/batch; 7h:59m:20s remains)
INFO - root - 2017-12-01 09:15:49.163874: step 152360, loss = 0.41, batch loss = 0.33 (52.7 examples/sec; 0.152 sec/batch; 7h:35m:23s remains)
INFO - root - 2017-12-01 09:15:50.751318: step 152370, loss = 0.28, batch loss = 0.20 (51.5 examples/sec; 0.155 sec/batch; 7h:46m:30s remains)
INFO - root - 2017-12-01 09:15:52.306549: step 152380, loss = 0.28, batch loss = 0.20 (50.8 examples/sec; 0.157 sec/batch; 7h:52m:29s remains)
INFO - root - 2017-12-01 09:15:53.883249: step 152390, loss = 0.22, batch loss = 0.14 (50.8 examples/sec; 0.158 sec/batch; 7h:53m:01s remains)
INFO - root - 2017-12-01 09:15:55.435874: step 152400, loss = 0.30, batch loss = 0.22 (52.8 examples/sec; 0.151 sec/batch; 7h:34m:35s remains)
INFO - root - 2017-12-01 09:15:57.053856: step 152410, loss = 0.28, batch loss = 0.20 (51.8 examples/sec; 0.154 sec/batch; 7h:43m:09s remains)
INFO - root - 2017-12-01 09:15:58.628248: step 152420, loss = 0.29, batch loss = 0.21 (50.9 examples/sec; 0.157 sec/batch; 7h:51m:23s remains)
INFO - root - 2017-12-01 09:16:00.193085: step 152430, loss = 0.26, batch loss = 0.18 (52.8 examples/sec; 0.152 sec/batch; 7h:34m:55s remains)
INFO - root - 2017-12-01 09:16:01.768768: step 152440, loss = 0.28, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 8h:00m:48s remains)
INFO - root - 2017-12-01 09:16:03.322933: step 152450, loss = 0.28, batch loss = 0.19 (51.8 examples/sec; 0.154 sec/batch; 7h:43m:18s remains)
INFO - root - 2017-12-01 09:16:04.882230: step 152460, loss = 0.21, batch loss = 0.13 (51.4 examples/sec; 0.156 sec/batch; 7h:46m:49s remains)
INFO - root - 2017-12-01 09:16:06.441647: step 152470, loss = 0.22, batch loss = 0.14 (49.7 examples/sec; 0.161 sec/batch; 8h:03m:21s remains)
INFO - root - 2017-12-01 09:16:08.012151: step 152480, loss = 0.26, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 7h:50m:12s remains)
INFO - root - 2017-12-01 09:16:09.580521: step 152490, loss = 0.27, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 7h:47m:31s remains)
INFO - root - 2017-12-01 09:16:11.139528: step 152500, loss = 0.28, batch loss = 0.20 (51.3 examples/sec; 0.156 sec/batch; 7h:47m:58s remains)
INFO - root - 2017-12-01 09:16:12.803651: step 152510, loss = 0.33, batch loss = 0.25 (51.3 examples/sec; 0.156 sec/batch; 7h:47m:38s remains)
INFO - root - 2017-12-01 09:16:14.360170: step 152520, loss = 0.24, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 7h:47m:56s remains)
INFO - root - 2017-12-01 09:16:15.922613: step 152530, loss = 0.23, batch loss = 0.15 (50.7 examples/sec; 0.158 sec/batch; 7h:52m:50s remains)
INFO - root - 2017-12-01 09:16:17.489116: step 152540, loss = 0.25, batch loss = 0.17 (48.9 examples/sec; 0.164 sec/batch; 8h:10m:40s remains)
INFO - root - 2017-12-01 09:16:19.066037: step 152550, loss = 0.24, batch loss = 0.16 (52.1 examples/sec; 0.153 sec/batch; 7h:40m:11s remains)
INFO - root - 2017-12-01 09:16:20.628561: step 152560, loss = 0.26, batch loss = 0.18 (51.0 examples/sec; 0.157 sec/batch; 7h:50m:29s remains)
INFO - root - 2017-12-01 09:16:22.179892: step 152570, loss = 0.24, batch loss = 0.15 (49.8 examples/sec; 0.161 sec/batch; 8h:01m:35s remains)
INFO - root - 2017-12-01 09:16:23.754909: step 152580, loss = 0.26, batch loss = 0.18 (48.9 examples/sec; 0.164 sec/batch; 8h:10m:40s remains)
INFO - root - 2017-12-01 09:16:25.317986: step 152590, loss = 0.21, batch loss = 0.13 (49.8 examples/sec; 0.161 sec/batch; 8h:02m:02s remains)
INFO - root - 2017-12-01 09:16:26.879268: step 152600, loss = 0.26, batch loss = 0.18 (51.8 examples/sec; 0.154 sec/batch; 7h:43m:10s remains)
INFO - root - 2017-12-01 09:16:28.486897: step 152610, loss = 0.31, batch loss = 0.23 (51.4 examples/sec; 0.156 sec/batch; 7h:46m:25s remains)
INFO - root - 2017-12-01 09:16:30.043907: step 152620, loss = 0.36, batch loss = 0.28 (52.0 examples/sec; 0.154 sec/batch; 7h:41m:01s remains)
INFO - root - 2017-12-01 09:16:31.606439: step 152630, loss = 0.36, batch loss = 0.27 (49.0 examples/sec; 0.163 sec/batch; 8h:09m:47s remains)
INFO - root - 2017-12-01 09:16:33.191372: step 152640, loss = 0.25, batch loss = 0.17 (50.9 examples/sec; 0.157 sec/batch; 7h:50m:58s remains)
INFO - root - 2017-12-01 09:16:34.743591: step 152650, loss = 0.31, batch loss = 0.23 (51.7 examples/sec; 0.155 sec/batch; 7h:43m:59s remains)
INFO - root - 2017-12-01 09:16:36.314831: step 152660, loss = 0.28, batch loss = 0.20 (49.6 examples/sec; 0.161 sec/batch; 8h:03m:38s remains)
INFO - root - 2017-12-01 09:16:37.870223: step 152670, loss = 0.27, batch loss = 0.19 (52.4 examples/sec; 0.153 sec/batch; 7h:37m:43s remains)
INFO - root - 2017-12-01 09:16:39.442230: step 152680, loss = 0.34, batch loss = 0.26 (51.7 examples/sec; 0.155 sec/batch; 7h:43m:58s remains)
INFO - root - 2017-12-01 09:16:41.007901: step 152690, loss = 0.28, batch loss = 0.20 (52.2 examples/sec; 0.153 sec/batch; 7h:39m:42s remains)
INFO - root - 2017-12-01 09:16:42.562473: step 152700, loss = 0.37, batch loss = 0.29 (51.5 examples/sec; 0.155 sec/batch; 7h:45m:17s remains)
INFO - root - 2017-12-01 09:16:44.229192: step 152710, loss = 0.25, batch loss = 0.16 (51.3 examples/sec; 0.156 sec/batch; 7h:47m:38s remains)
INFO - root - 2017-12-01 09:16:45.785189: step 152720, loss = 0.31, batch loss = 0.22 (49.8 examples/sec; 0.161 sec/batch; 8h:01m:37s remains)
INFO - root - 2017-12-01 09:16:47.352336: step 152730, loss = 0.33, batch loss = 0.25 (49.9 examples/sec; 0.160 sec/batch; 8h:00m:11s remains)
INFO - root - 2017-12-01 09:16:48.910927: step 152740, loss = 0.33, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 7h:45m:56s remains)
INFO - root - 2017-12-01 09:16:50.485285: step 152750, loss = 0.32, batch loss = 0.24 (51.6 examples/sec; 0.155 sec/batch; 7h:44m:11s remains)
INFO - root - 2017-12-01 09:16:52.049941: step 152760, loss = 0.40, batch loss = 0.32 (52.1 examples/sec; 0.154 sec/batch; 7h:39m:56s remains)
INFO - root - 2017-12-01 09:16:53.605511: step 152770, loss = 0.29, batch loss = 0.20 (50.9 examples/sec; 0.157 sec/batch; 7h:50m:49s remains)
INFO - root - 2017-12-01 09:16:55.174281: step 152780, loss = 0.23, batch loss = 0.15 (51.0 examples/sec; 0.157 sec/batch; 7h:49m:24s remains)
INFO - root - 2017-12-01 09:16:56.729485: step 152790, loss = 0.26, batch loss = 0.18 (51.5 examples/sec; 0.155 sec/batch; 7h:45m:27s remains)
INFO - root - 2017-12-01 09:16:58.287734: step 152800, loss = 0.34, batch loss = 0.26 (52.4 examples/sec; 0.153 sec/batch; 7h:37m:07s remains)
INFO - root - 2017-12-01 09:16:59.894962: step 152810, loss = 0.31, batch loss = 0.23 (50.9 examples/sec; 0.157 sec/batch; 7h:50m:19s remains)
INFO - root - 2017-12-01 09:17:01.458933: step 152820, loss = 0.35, batch loss = 0.26 (50.6 examples/sec; 0.158 sec/batch; 7h:53m:09s remains)
INFO - root - 2017-12-01 09:17:03.003173: step 152830, loss = 0.25, batch loss = 0.17 (51.2 examples/sec; 0.156 sec/batch; 7h:48m:01s remains)
INFO - root - 2017-12-01 09:17:04.563915: step 152840, loss = 0.25, batch loss = 0.17 (52.5 examples/sec; 0.152 sec/batch; 7h:36m:25s remains)
INFO - root - 2017-12-01 09:17:06.120649: step 152850, loss = 0.25, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 7h:54m:21s remains)
INFO - root - 2017-12-01 09:17:07.701971: step 152860, loss = 0.20, batch loss = 0.12 (51.5 examples/sec; 0.155 sec/batch; 7h:45m:27s remains)
INFO - root - 2017-12-01 09:17:09.261832: step 152870, loss = 0.37, batch loss = 0.29 (50.6 examples/sec; 0.158 sec/batch; 7h:53m:39s remains)
INFO - root - 2017-12-01 09:17:10.826406: step 152880, loss = 0.26, batch loss = 0.18 (50.5 examples/sec; 0.159 sec/batch; 7h:54m:37s remains)
INFO - root - 2017-12-01 09:17:12.405021: step 152890, loss = 0.29, batch loss = 0.21 (49.7 examples/sec; 0.161 sec/batch; 8h:02m:02s remains)
INFO - root - 2017-12-01 09:17:13.991736: step 152900, loss = 0.24, batch loss = 0.16 (50.2 examples/sec; 0.159 sec/batch; 7h:56m:37s remains)
INFO - root - 2017-12-01 09:17:15.624233: step 152910, loss = 0.33, batch loss = 0.25 (52.7 examples/sec; 0.152 sec/batch; 7h:34m:15s remains)
INFO - root - 2017-12-01 09:17:17.192229: step 152920, loss = 0.30, batch loss = 0.22 (52.3 examples/sec; 0.153 sec/batch; 7h:38m:12s remains)
INFO - root - 2017-12-01 09:17:18.761243: step 152930, loss = 0.24, batch loss = 0.16 (50.7 examples/sec; 0.158 sec/batch; 7h:51m:55s remains)
INFO - root - 2017-12-01 09:17:20.324679: step 152940, loss = 0.30, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 7h:39m:39s remains)
INFO - root - 2017-12-01 09:17:21.892112: step 152950, loss = 0.36, batch loss = 0.28 (50.2 examples/sec; 0.159 sec/batch; 7h:56m:41s remains)
INFO - root - 2017-12-01 09:17:23.479343: step 152960, loss = 0.24, batch loss = 0.16 (50.5 examples/sec; 0.158 sec/batch; 7h:53m:56s remains)
INFO - root - 2017-12-01 09:17:25.036409: step 152970, loss = 0.25, batch loss = 0.17 (53.0 examples/sec; 0.151 sec/batch; 7h:31m:44s remains)
INFO - root - 2017-12-01 09:17:26.609276: step 152980, loss = 0.21, batch loss = 0.13 (50.8 examples/sec; 0.158 sec/batch; 7h:51m:17s remains)
INFO - root - 2017-12-01 09:17:28.179423: step 152990, loss = 0.33, batch loss = 0.25 (51.1 examples/sec; 0.156 sec/batch; 7h:48m:04s remains)
INFO - root - 2017-12-01 09:17:29.748894: step 153000, loss = 0.30, batch loss = 0.22 (50.3 examples/sec; 0.159 sec/batch; 7h:55m:50s remains)
INFO - root - 2017-12-01 09:17:31.397049: step 153010, loss = 0.28, batch loss = 0.20 (49.2 examples/sec; 0.163 sec/batch; 8h:06m:17s remains)
INFO - root - 2017-12-01 09:17:32.950259: step 153020, loss = 0.41, batch loss = 0.33 (51.9 examples/sec; 0.154 sec/batch; 7h:41m:07s remains)
INFO - root - 2017-12-01 09:17:34.517940: step 153030, loss = 0.44, batch loss = 0.36 (52.5 examples/sec; 0.153 sec/batch; 7h:36m:09s remains)
INFO - root - 2017-12-01 09:17:36.074359: step 153040, loss = 0.30, batch loss = 0.22 (52.6 examples/sec; 0.152 sec/batch; 7h:34m:46s remains)
INFO - root - 2017-12-01 09:17:37.661451: step 153050, loss = 0.30, batch loss = 0.22 (50.7 examples/sec; 0.158 sec/batch; 7h:52m:16s remains)
INFO - root - 2017-12-01 09:17:39.205241: step 153060, loss = 0.23, batch loss = 0.15 (51.5 examples/sec; 0.155 sec/batch; 7h:44m:48s remains)
INFO - root - 2017-12-01 09:17:40.791918: step 153070, loss = 0.30, batch loss = 0.22 (47.2 examples/sec; 0.169 sec/batch; 8h:26m:27s remains)
INFO - root - 2017-12-01 09:17:42.380242: step 153080, loss = 0.33, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 7h:45m:49s remains)
INFO - root - 2017-12-01 09:17:43.925998: step 153090, loss = 0.35, batch loss = 0.27 (51.6 examples/sec; 0.155 sec/batch; 7h:43m:58s remains)
INFO - root - 2017-12-01 09:17:45.484041: step 153100, loss = 0.20, batch loss = 0.12 (51.1 examples/sec; 0.156 sec/batch; 7h:47m:51s remains)
INFO - root - 2017-12-01 09:17:47.124508: step 153110, loss = 0.20, batch loss = 0.12 (52.2 examples/sec; 0.153 sec/batch; 7h:38m:11s remains)
INFO - root - 2017-12-01 09:17:48.690855: step 153120, loss = 0.29, batch loss = 0.21 (51.2 examples/sec; 0.156 sec/batch; 7h:46m:59s remains)
INFO - root - 2017-12-01 09:17:50.257486: step 153130, loss = 0.37, batch loss = 0.29 (49.8 examples/sec; 0.161 sec/batch; 8h:00m:21s remains)
INFO - root - 2017-12-01 09:17:51.822087: step 153140, loss = 0.33, batch loss = 0.25 (53.9 examples/sec; 0.148 sec/batch; 7h:23m:26s remains)
INFO - root - 2017-12-01 09:17:53.400471: step 153150, loss = 0.39, batch loss = 0.31 (50.8 examples/sec; 0.158 sec/batch; 7h:50m:49s remains)
INFO - root - 2017-12-01 09:17:54.968724: step 153160, loss = 0.25, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 7h:53m:21s remains)
INFO - root - 2017-12-01 09:17:56.539376: step 153170, loss = 0.37, batch loss = 0.29 (51.2 examples/sec; 0.156 sec/batch; 7h:46m:52s remains)
INFO - root - 2017-12-01 09:17:58.086149: step 153180, loss = 0.22, batch loss = 0.14 (50.8 examples/sec; 0.158 sec/batch; 7h:50m:45s remains)
INFO - root - 2017-12-01 09:17:59.659277: step 153190, loss = 0.28, batch loss = 0.19 (53.0 examples/sec; 0.151 sec/batch; 7h:31m:25s remains)
INFO - root - 2017-12-01 09:18:01.231124: step 153200, loss = 0.23, batch loss = 0.14 (47.5 examples/sec; 0.168 sec/batch; 8h:23m:23s remains)
INFO - root - 2017-12-01 09:18:02.872751: step 153210, loss = 0.23, batch loss = 0.15 (51.0 examples/sec; 0.157 sec/batch; 7h:48m:52s remains)
INFO - root - 2017-12-01 09:18:04.442826: step 153220, loss = 0.23, batch loss = 0.15 (52.2 examples/sec; 0.153 sec/batch; 7h:38m:03s remains)
INFO - root - 2017-12-01 09:18:06.008437: step 153230, loss = 0.29, batch loss = 0.21 (52.2 examples/sec; 0.153 sec/batch; 7h:38m:02s remains)
INFO - root - 2017-12-01 09:18:07.571883: step 153240, loss = 0.24, batch loss = 0.16 (50.2 examples/sec; 0.159 sec/batch; 7h:55m:56s remains)
INFO - root - 2017-12-01 09:18:09.131949: step 153250, loss = 0.25, batch loss = 0.17 (51.5 examples/sec; 0.155 sec/batch; 7h:43m:49s remains)
INFO - root - 2017-12-01 09:18:10.704810: step 153260, loss = 0.33, batch loss = 0.25 (51.4 examples/sec; 0.156 sec/batch; 7h:44m:46s remains)
INFO - root - 2017-12-01 09:18:12.281728: step 153270, loss = 0.31, batch loss = 0.23 (50.3 examples/sec; 0.159 sec/batch; 7h:55m:29s remains)
INFO - root - 2017-12-01 09:18:13.872377: step 153280, loss = 0.25, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 7h:53m:13s remains)
INFO - root - 2017-12-01 09:18:15.435522: step 153290, loss = 0.24, batch loss = 0.15 (50.8 examples/sec; 0.157 sec/batch; 7h:50m:16s remains)
INFO - root - 2017-12-01 09:18:17.005767: step 153300, loss = 0.26, batch loss = 0.18 (52.1 examples/sec; 0.154 sec/batch; 7h:38m:56s remains)
INFO - root - 2017-12-01 09:18:18.663624: step 153310, loss = 0.30, batch loss = 0.22 (49.9 examples/sec; 0.160 sec/batch; 7h:58m:38s remains)
INFO - root - 2017-12-01 09:18:20.241157: step 153320, loss = 0.34, batch loss = 0.26 (52.6 examples/sec; 0.152 sec/batch; 7h:34m:26s remains)
INFO - root - 2017-12-01 09:18:21.827713: step 153330, loss = 0.28, batch loss = 0.20 (49.9 examples/sec; 0.160 sec/batch; 7h:58m:59s remains)
INFO - root - 2017-12-01 09:18:23.390755: step 153340, loss = 0.25, batch loss = 0.17 (51.4 examples/sec; 0.156 sec/batch; 7h:44m:33s remains)
INFO - root - 2017-12-01 09:18:24.956753: step 153350, loss = 0.30, batch loss = 0.22 (49.2 examples/sec; 0.163 sec/batch; 8h:05m:52s remains)
INFO - root - 2017-12-01 09:18:26.528672: step 153360, loss = 0.30, batch loss = 0.22 (51.1 examples/sec; 0.157 sec/batch; 7h:47m:48s remains)
INFO - root - 2017-12-01 09:18:28.082699: step 153370, loss = 0.26, batch loss = 0.18 (52.7 examples/sec; 0.152 sec/batch; 7h:32m:50s remains)
INFO - root - 2017-12-01 09:18:29.657174: step 153380, loss = 0.29, batch loss = 0.21 (51.0 examples/sec; 0.157 sec/batch; 7h:48m:37s remains)
INFO - root - 2017-12-01 09:18:31.214482: step 153390, loss = 0.26, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 7h:51m:24s remains)
INFO - root - 2017-12-01 09:18:32.778517: step 153400, loss = 0.34, batch loss = 0.26 (51.5 examples/sec; 0.155 sec/batch; 7h:43m:17s remains)
INFO - root - 2017-12-01 09:18:34.429072: step 153410, loss = 0.26, batch loss = 0.18 (50.9 examples/sec; 0.157 sec/batch; 7h:49m:32s remains)
INFO - root - 2017-12-01 09:18:35.983960: step 153420, loss = 0.41, batch loss = 0.33 (50.7 examples/sec; 0.158 sec/batch; 7h:51m:00s remains)
INFO - root - 2017-12-01 09:18:37.543837: step 153430, loss = 0.36, batch loss = 0.28 (50.9 examples/sec; 0.157 sec/batch; 7h:49m:14s remains)
INFO - root - 2017-12-01 09:18:39.108615: step 153440, loss = 0.26, batch loss = 0.18 (53.0 examples/sec; 0.151 sec/batch; 7h:30m:29s remains)
INFO - root - 2017-12-01 09:18:40.701675: step 153450, loss = 0.30, batch loss = 0.22 (49.1 examples/sec; 0.163 sec/batch; 8h:06m:07s remains)
INFO - root - 2017-12-01 09:18:42.286515: step 153460, loss = 0.25, batch loss = 0.17 (49.4 examples/sec; 0.162 sec/batch; 8h:03m:39s remains)
INFO - root - 2017-12-01 09:18:43.854610: step 153470, loss = 0.33, batch loss = 0.24 (52.5 examples/sec; 0.152 sec/batch; 7h:34m:32s remains)
INFO - root - 2017-12-01 09:18:45.421917: step 153480, loss = 0.33, batch loss = 0.25 (51.0 examples/sec; 0.157 sec/batch; 7h:48m:12s remains)
INFO - root - 2017-12-01 09:18:46.992557: step 153490, loss = 0.25, batch loss = 0.17 (50.3 examples/sec; 0.159 sec/batch; 7h:54m:45s remains)
INFO - root - 2017-12-01 09:18:48.563741: step 153500, loss = 0.26, batch loss = 0.18 (50.2 examples/sec; 0.159 sec/batch; 7h:55m:25s remains)
INFO - root - 2017-12-01 09:18:50.204318: step 153510, loss = 0.28, batch loss = 0.20 (51.6 examples/sec; 0.155 sec/batch; 7h:42m:14s remains)
INFO - root - 2017-12-01 09:18:51.777499: step 153520, loss = 0.23, batch loss = 0.15 (50.8 examples/sec; 0.157 sec/batch; 7h:49m:29s remains)
INFO - root - 2017-12-01 09:18:53.331054: step 153530, loss = 0.22, batch loss = 0.14 (49.9 examples/sec; 0.160 sec/batch; 7h:58m:12s remains)
INFO - root - 2017-12-01 09:18:54.911257: step 153540, loss = 0.31, batch loss = 0.23 (52.4 examples/sec; 0.153 sec/batch; 7h:35m:08s remains)
INFO - root - 2017-12-01 09:18:56.474246: step 153550, loss = 0.32, batch loss = 0.24 (51.5 examples/sec; 0.155 sec/batch; 7h:42m:59s remains)
INFO - root - 2017-12-01 09:18:58.060904: step 153560, loss = 0.24, batch loss = 0.16 (50.3 examples/sec; 0.159 sec/batch; 7h:54m:20s remains)
INFO - root - 2017-12-01 09:18:59.615599: step 153570, loss = 0.27, batch loss = 0.19 (51.2 examples/sec; 0.156 sec/batch; 7h:46m:00s remains)
INFO - root - 2017-12-01 09:19:01.192025: step 153580, loss = 0.34, batch loss = 0.26 (49.4 examples/sec; 0.162 sec/batch; 8h:03m:14s remains)
INFO - root - 2017-12-01 09:19:02.760932: step 153590, loss = 0.32, batch loss = 0.24 (52.1 examples/sec; 0.154 sec/batch; 7h:38m:17s remains)
INFO - root - 2017-12-01 09:19:04.319152: step 153600, loss = 0.24, batch loss = 0.16 (50.8 examples/sec; 0.158 sec/batch; 7h:49m:42s remains)
INFO - root - 2017-12-01 09:19:05.927158: step 153610, loss = 0.26, batch loss = 0.18 (52.0 examples/sec; 0.154 sec/batch; 7h:38m:47s remains)
INFO - root - 2017-12-01 09:19:07.482058: step 153620, loss = 0.31, batch loss = 0.23 (51.6 examples/sec; 0.155 sec/batch; 7h:42m:04s remains)
INFO - root - 2017-12-01 09:19:09.033693: step 153630, loss = 0.27, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 7h:38m:33s remains)
INFO - root - 2017-12-01 09:19:10.603696: step 153640, loss = 0.27, batch loss = 0.19 (52.9 examples/sec; 0.151 sec/batch; 7h:30m:57s remains)
INFO - root - 2017-12-01 09:19:12.184319: step 153650, loss = 0.28, batch loss = 0.19 (51.3 examples/sec; 0.156 sec/batch; 7h:45m:16s remains)
INFO - root - 2017-12-01 09:19:13.732859: step 153660, loss = 0.32, batch loss = 0.24 (52.0 examples/sec; 0.154 sec/batch; 7h:38m:18s remains)
INFO - root - 2017-12-01 09:19:15.299825: step 153670, loss = 0.32, batch loss = 0.24 (50.5 examples/sec; 0.158 sec/batch; 7h:52m:01s remains)
INFO - root - 2017-12-01 09:19:16.859960: step 153680, loss = 0.30, batch loss = 0.22 (52.1 examples/sec; 0.154 sec/batch; 7h:37m:52s remains)
INFO - root - 2017-12-01 09:19:18.437520: step 153690, loss = 0.27, batch loss = 0.19 (52.0 examples/sec; 0.154 sec/batch; 7h:38m:46s remains)
INFO - root - 2017-12-01 09:19:19.993683: step 153700, loss = 0.27, batch loss = 0.19 (51.1 examples/sec; 0.157 sec/batch; 7h:46m:37s remains)
INFO - root - 2017-12-01 09:19:21.645680: step 153710, loss = 0.36, batch loss = 0.28 (52.8 examples/sec; 0.151 sec/batch; 7h:31m:08s remains)
INFO - root - 2017-12-01 09:19:23.229425: step 153720, loss = 0.30, batch loss = 0.22 (51.7 examples/sec; 0.155 sec/batch; 7h:41m:05s remains)
INFO - root - 2017-12-01 09:19:24.779945: step 153730, loss = 0.25, batch loss = 0.17 (50.5 examples/sec; 0.158 sec/batch; 7h:51m:55s remains)
INFO - root - 2017-12-01 09:19:26.348808: step 153740, loss = 0.34, batch loss = 0.26 (51.6 examples/sec; 0.155 sec/batch; 7h:42m:06s remains)
INFO - root - 2017-12-01 09:19:27.921964: step 153750, loss = 0.24, batch loss = 0.16 (51.8 examples/sec; 0.154 sec/batch; 7h:40m:07s remains)
INFO - root - 2017-12-01 09:19:29.501548: step 153760, loss = 0.25, batch loss = 0.17 (50.8 examples/sec; 0.158 sec/batch; 7h:49m:33s remains)
INFO - root - 2017-12-01 09:19:31.060305: step 153770, loss = 0.29, batch loss = 0.21 (50.5 examples/sec; 0.158 sec/batch; 7h:51m:41s remains)
INFO - root - 2017-12-01 09:19:32.617255: step 153780, loss = 0.20, batch loss = 0.12 (48.4 examples/sec; 0.165 sec/batch; 8h:12m:13s remains)
INFO - root - 2017-12-01 09:19:34.197959: step 153790, loss = 0.22, batch loss = 0.14 (51.3 examples/sec; 0.156 sec/batch; 7h:44m:37s remains)
INFO - root - 2017-12-01 09:19:35.752751: step 153800, loss = 0.29, batch loss = 0.21 (51.4 examples/sec; 0.156 sec/batch; 7h:43m:09s remains)
INFO - root - 2017-12-01 09:19:37.352916: step 153810, loss = 0.32, batch loss = 0.24 (50.3 examples/sec; 0.159 sec/batch; 7h:53m:35s remains)
INFO - root - 2017-12-01 09:19:38.914171: step 153820, loss = 0.24, batch loss = 0.16 (48.8 examples/sec; 0.164 sec/batch; 8h:08m:10s remains)
INFO - root - 2017-12-01 09:19:40.499259: step 153830, loss = 0.26, batch loss = 0.18 (50.7 examples/sec; 0.158 sec/batch; 7h:49m:36s remains)
INFO - root - 2017-12-01 09:19:42.069729: step 153840, loss = 0.24, batch loss = 0.15 (50.5 examples/sec; 0.158 sec/batch; 7h:51m:53s remains)
INFO - root - 2017-12-01 09:19:43.623915: step 153850, loss = 0.33, batch loss = 0.25 (50.7 examples/sec; 0.158 sec/batch; 7h:49m:57s remains)
INFO - root - 2017-12-01 09:19:45.195877: step 153860, loss = 0.24, batch loss = 0.16 (48.6 examples/sec; 0.164 sec/batch; 8h:09m:42s remains)
INFO - root - 2017-12-01 09:19:46.775728: step 153870, loss = 0.23, batch loss = 0.15 (51.0 examples/sec; 0.157 sec/batch; 7h:47m:23s remains)
INFO - root - 2017-12-01 09:19:48.331825: step 153880, loss = 0.30, batch loss = 0.22 (51.4 examples/sec; 0.156 sec/batch; 7h:43m:34s remains)
INFO - root - 2017-12-01 09:19:49.899095: step 153890, loss = 0.32, batch loss = 0.24 (51.1 examples/sec; 0.156 sec/batch; 7h:45m:39s remains)
INFO - root - 2017-12-01 09:19:51.464756: step 153900, loss = 0.28, batch loss = 0.20 (50.4 examples/sec; 0.159 sec/batch; 7h:52m:13s remains)
INFO - root - 2017-12-01 09:19:53.098635: step 153910, loss = 0.41, batch loss = 0.33 (51.5 examples/sec; 0.155 sec/batch; 7h:42m:12s remains)
INFO - root - 2017-12-01 09:19:54.688732: step 153920, loss = 0.37, batch loss = 0.29 (50.7 examples/sec; 0.158 sec/batch; 7h:49m:47s remains)
INFO - root - 2017-12-01 09:19:56.256050: step 153930, loss = 0.41, batch loss = 0.33 (50.9 examples/sec; 0.157 sec/batch; 7h:48m:08s remains)
