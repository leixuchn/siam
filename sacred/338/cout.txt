INFO - Siam-FC - Running command 'main'
INFO - Siam-FC - Started run with ID "338"
INFO - root - preproces -- siamese_fc_color
WARNING - root - root is not explicitly specified, using default value: None
INFO - root - For training, we use instance size 255 - 2 * 8 ...
WARNING - root - init_method is not explicitly specified, using default value: None
INFO - root - preproces -- None
WARNING - root - root is not explicitly specified, using default value: None
INFO - root - For training, we use instance size 255 - 2 * 8 ...
WARNING - root - init_method is not explicitly specified, using default value: None
/home/v-chaoqw/MYSFC-ORI/workspace/train_imdb.pickle
inputs Tensor("train/batch:0", shape=(8, 127, 127, 3), dtype=float32, device=/device:CPU:0)
conv1 Tensor("train/siamese_fc/pool1/MaxPool:0", shape=(8, 29, 29, 96), dtype=float32)
net Tensor("train/siamese_fc/conv4/concat:0", shape=(8, 8, 8, 384), dtype=float32)
Tensor("train/siamese_fc/conv5/def/transpose:0", shape=(8, 384, 8, 8), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(256, 384, 3, 3) dtype=float32_ref> Tensor("train/siamese_fc/conv5/def/transpose_1:0", shape=(8, 18, 8, 8), dtype=float32)
inputs Tensor("train/batch:1", shape=(8, 239, 239, 3), dtype=float32, device=/device:CPU:0)
conv1 Tensor("train/siamese_fc_1/pool1/MaxPool:0", shape=(8, 57, 57, 96), dtype=float32)
net Tensor("train/siamese_fc_1/conv4/concat:0", shape=(8, 22, 22, 384), dtype=float32)
Tensor("train/siamese_fc_1/conv5/def/transpose:0", shape=(8, 384, 22, 22), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(256, 384, 3, 3) dtype=float32_ref> Tensor("train/siamese_fc_1/conv5/def/transpose_1:0", shape=(8, 18, 22, 22), dtype=float32)
/home/v-chaoqw/MYSFC-ORI/workspace/val_imdb.pickle
inputs Tensor("val/batch:0", shape=(8, 127, 127, 3), dtype=float32, device=/device:CPU:0)
conv1 Tensor("val/siamese_fc/pool1/MaxPool:0", shape=(8, 29, 29, 96), dtype=float32)
net Tensor("val/siamese_fc/conv4/concat:0", shape=(8, 8, 8, 384), dtype=float32)
Tensor("val/siamese_fc/conv5/def/transpose:0", shape=(8, 384, 8, 8), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(256, 384, 3, 3) dtype=float32_ref> Tensor("val/siamese_fc/conv5/def/transpose_1:0", shape=(8, 18, 8, 8), dtype=float32)
inputs Tensor("val/batch:1", shape=(8, 239, 239, 3), dtype=float32, device=/device:CPU:0)
conv1 Tensor("val/siamese_fc_1/pool1/MaxPool:0", shape=(8, 57, 57, 96), dtype=float32)
net Tensor("val/siamese_fc_1/conv4/concat:0", shape=(8, 22, 22, 384), dtype=float32)
Tensor("val/siamese_fc_1/conv5/def/transpose:0", shape=(8, 384, 22, 22), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(256, 384, 3, 3) dtype=float32_ref> Tensor("val/siamese_fc_1/conv5/def/transpose_1:0", shape=(8, 18, 22, 22), dtype=float32)
2017-12-17 02:46:48.168498: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 02:46:48.168540: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 02:46:48.168547: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 02:46:48.168551: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 02:46:48.168555: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-17 02:46:48.515858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 6bee:00:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2017-12-17 02:46:48.515897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-12-17 02:46:48.515904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-12-17 02:46:48.515911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 6bee:00:00.0)
INFO - root - Restore from last checkpoint: /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO:tensorflow:Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO - tensorflow - Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO - root - Starting threads 0 ...

INFO - root - Starting threads 0 ...

INFO - root - training for 332500 steps
INFO - root - 2017-12-17 02:46:51.660673: step 0, loss = 2.28, batch loss = 2.23 (3.4 examples/sec; 2.349 sec/batch; 216h:58m:20s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 02:46:54.672459: step 10, loss = 1.58, batch loss = 1.52 (37.5 examples/sec; 0.213 sec/batch; 19h:41m:54s remains)
INFO - root - 2017-12-17 02:46:56.810506: step 20, loss = 1.45, batch loss = 1.36 (37.6 examples/sec; 0.213 sec/batch; 19h:37m:37s remains)
INFO - root - 2017-12-17 02:46:58.982860: step 30, loss = 1.89, batch loss = 1.77 (35.6 examples/sec; 0.225 sec/batch; 20h:44m:42s remains)
INFO - root - 2017-12-17 02:47:01.135273: step 40, loss = 0.96, batch loss = 0.82 (36.9 examples/sec; 0.217 sec/batch; 20h:02m:03s remains)
INFO - root - 2017-12-17 02:47:03.278917: step 50, loss = 0.90, batch loss = 0.75 (37.5 examples/sec; 0.214 sec/batch; 19h:43m:25s remains)
INFO - root - 2017-12-17 02:47:05.454450: step 60, loss = 0.75, batch loss = 0.60 (37.7 examples/sec; 0.212 sec/batch; 19h:36m:41s remains)
INFO - root - 2017-12-17 02:47:07.622529: step 70, loss = 0.72, batch loss = 0.56 (34.7 examples/sec; 0.231 sec/batch; 21h:17m:37s remains)
INFO - root - 2017-12-17 02:47:09.781786: step 80, loss = 0.78, batch loss = 0.63 (37.8 examples/sec; 0.212 sec/batch; 19h:32m:18s remains)
INFO - root - 2017-12-17 02:47:11.958633: step 90, loss = 0.65, batch loss = 0.49 (37.0 examples/sec; 0.216 sec/batch; 19h:57m:37s remains)
INFO - root - 2017-12-17 02:47:14.127290: step 100, loss = 0.68, batch loss = 0.52 (37.4 examples/sec; 0.214 sec/batch; 19h:45m:25s remains)
INFO - root - 2017-12-17 02:47:16.423622: step 110, loss = 0.67, batch loss = 0.51 (36.9 examples/sec; 0.217 sec/batch; 20h:00m:54s remains)
INFO - root - 2017-12-17 02:47:18.575706: step 120, loss = 0.64, batch loss = 0.48 (37.3 examples/sec; 0.214 sec/batch; 19h:47m:17s remains)
INFO - root - 2017-12-17 02:47:20.745748: step 130, loss = 0.70, batch loss = 0.54 (36.3 examples/sec; 0.221 sec/batch; 20h:22m:07s remains)
INFO - root - 2017-12-17 02:47:22.910458: step 140, loss = 0.66, batch loss = 0.50 (36.7 examples/sec; 0.218 sec/batch; 20h:07m:22s remains)
INFO - root - 2017-12-17 02:47:25.115647: step 150, loss = 0.81, batch loss = 0.65 (35.7 examples/sec; 0.224 sec/batch; 20h:39m:54s remains)
INFO - root - 2017-12-17 02:47:27.287392: step 160, loss = 0.69, batch loss = 0.54 (36.9 examples/sec; 0.217 sec/batch; 19h:59m:32s remains)
INFO - root - 2017-12-17 02:47:29.485779: step 170, loss = 0.70, batch loss = 0.54 (37.6 examples/sec; 0.213 sec/batch; 19h:39m:17s remains)
INFO - root - 2017-12-17 02:47:31.663458: step 180, loss = 0.77, batch loss = 0.61 (37.7 examples/sec; 0.212 sec/batch; 19h:36m:09s remains)
INFO - root - 2017-12-17 02:47:33.840783: step 190, loss = 0.71, batch loss = 0.55 (36.1 examples/sec; 0.221 sec/batch; 20h:26m:06s remains)
INFO - root - 2017-12-17 02:47:36.023009: step 200, loss = 0.66, batch loss = 0.50 (37.0 examples/sec; 0.216 sec/batch; 19h:56m:02s remains)
INFO - root - 2017-12-17 02:47:38.347071: step 210, loss = 0.59, batch loss = 0.44 (35.9 examples/sec; 0.223 sec/batch; 20h:35m:44s remains)
INFO - root - 2017-12-17 02:47:40.589829: step 220, loss = 0.72, batch loss = 0.56 (36.9 examples/sec; 0.217 sec/batch; 20h:01m:45s remains)
INFO - root - 2017-12-17 02:47:42.802386: step 230, loss = 0.66, batch loss = 0.51 (37.6 examples/sec; 0.213 sec/batch; 19h:39m:42s remains)
INFO - root - 2017-12-17 02:47:44.988905: step 240, loss = 0.65, batch loss = 0.49 (37.3 examples/sec; 0.215 sec/batch; 19h:49m:15s remains)
INFO - root - 2017-12-17 02:47:47.221059: step 250, loss = 0.79, batch loss = 0.63 (36.7 examples/sec; 0.218 sec/batch; 20h:08m:43s remains)
INFO - root - 2017-12-17 02:47:49.439164: step 260, loss = 0.66, batch loss = 0.50 (36.7 examples/sec; 0.218 sec/batch; 20h:08m:32s remains)
INFO - root - 2017-12-17 02:47:51.685280: step 270, loss = 0.71, batch loss = 0.56 (35.8 examples/sec; 0.224 sec/batch; 20h:37m:36s remains)
INFO - root - 2017-12-17 02:47:53.891037: step 280, loss = 0.68, batch loss = 0.52 (36.7 examples/sec; 0.218 sec/batch; 20h:06m:25s remains)
INFO - root - 2017-12-17 02:47:56.097640: step 290, loss = 0.94, batch loss = 0.78 (37.3 examples/sec; 0.214 sec/batch; 19h:46m:10s remains)
INFO - root - 2017-12-17 02:47:58.313244: step 300, loss = 0.76, batch loss = 0.60 (36.1 examples/sec; 0.222 sec/batch; 20h:26m:34s remains)
INFO - root - 2017-12-17 02:48:00.665465: step 310, loss = 0.73, batch loss = 0.58 (36.5 examples/sec; 0.219 sec/batch; 20h:12m:49s remains)
INFO - root - 2017-12-17 02:48:02.899118: step 320, loss = 0.86, batch loss = 0.71 (35.4 examples/sec; 0.226 sec/batch; 20h:52m:10s remains)
INFO - root - 2017-12-17 02:48:05.113894: step 330, loss = 0.81, batch loss = 0.66 (36.8 examples/sec; 0.218 sec/batch; 20h:04m:17s remains)
INFO - root - 2017-12-17 02:48:07.350154: step 340, loss = 0.74, batch loss = 0.59 (35.5 examples/sec; 0.225 sec/batch; 20h:47m:06s remains)
INFO - root - 2017-12-17 02:48:09.543363: step 350, loss = 0.67, batch loss = 0.52 (36.7 examples/sec; 0.218 sec/batch; 20h:06m:35s remains)
INFO - root - 2017-12-17 02:48:11.775168: step 360, loss = 0.68, batch loss = 0.52 (35.2 examples/sec; 0.227 sec/batch; 20h:56m:24s remains)
INFO - root - 2017-12-17 02:48:14.005369: step 370, loss = 0.72, batch loss = 0.57 (35.0 examples/sec; 0.229 sec/batch; 21h:06m:02s remains)
INFO - root - 2017-12-17 02:48:16.236598: step 380, loss = 0.73, batch loss = 0.58 (34.9 examples/sec; 0.229 sec/batch; 21h:09m:39s remains)
INFO - root - 2017-12-17 02:48:18.452177: step 390, loss = 0.73, batch loss = 0.57 (35.6 examples/sec; 0.225 sec/batch; 20h:42m:47s remains)
INFO - root - 2017-12-17 02:48:20.642472: step 400, loss = 0.78, batch loss = 0.62 (36.5 examples/sec; 0.219 sec/batch; 20h:12m:02s remains)
INFO - root - 2017-12-17 02:48:22.996513: step 410, loss = 0.83, batch loss = 0.68 (36.6 examples/sec; 0.218 sec/batch; 20h:08m:49s remains)
INFO - root - 2017-12-17 02:48:25.249634: step 420, loss = 0.72, batch loss = 0.57 (33.6 examples/sec; 0.238 sec/batch; 21h:57m:26s remains)
INFO - root - 2017-12-17 02:48:27.487116: step 430, loss = 0.77, batch loss = 0.62 (34.8 examples/sec; 0.230 sec/batch; 21h:13m:44s remains)
INFO - root - 2017-12-17 02:48:29.707883: step 440, loss = 0.74, batch loss = 0.58 (36.6 examples/sec; 0.218 sec/batch; 20h:08m:11s remains)
INFO - root - 2017-12-17 02:48:31.941576: step 450, loss = 0.75, batch loss = 0.60 (37.1 examples/sec; 0.216 sec/batch; 19h:54m:04s remains)
INFO - root - 2017-12-17 02:48:34.168907: step 460, loss = 0.65, batch loss = 0.49 (37.1 examples/sec; 0.216 sec/batch; 19h:53m:42s remains)
INFO - root - 2017-12-17 02:48:36.375204: step 470, loss = 0.80, batch loss = 0.65 (36.5 examples/sec; 0.219 sec/batch; 20h:13m:01s remains)
INFO - root - 2017-12-17 02:48:38.619349: step 480, loss = 0.80, batch loss = 0.64 (34.3 examples/sec; 0.233 sec/batch; 21h:29m:02s remains)
INFO - root - 2017-12-17 02:48:40.841582: step 490, loss = 0.69, batch loss = 0.54 (36.9 examples/sec; 0.217 sec/batch; 19h:59m:12s remains)
INFO - root - 2017-12-17 02:48:43.079241: step 500, loss = 0.68, batch loss = 0.53 (35.7 examples/sec; 0.224 sec/batch; 20h:39m:15s remains)
INFO - root - 2017-12-17 02:48:45.446218: step 510, loss = 0.64, batch loss = 0.49 (37.1 examples/sec; 0.215 sec/batch; 19h:52m:17s remains)
INFO - root - 2017-12-17 02:48:47.658026: step 520, loss = 0.78, batch loss = 0.63 (36.1 examples/sec; 0.221 sec/batch; 20h:25m:29s remains)
INFO - root - 2017-12-17 02:48:49.929694: step 530, loss = 0.74, batch loss = 0.59 (37.4 examples/sec; 0.214 sec/batch; 19h:44m:59s remains)
INFO - root - 2017-12-17 02:48:52.168165: step 540, loss = 0.64, batch loss = 0.49 (34.3 examples/sec; 0.233 sec/batch; 21h:31m:34s remains)
INFO - root - 2017-12-17 02:48:54.392791: step 550, loss = 0.76, batch loss = 0.61 (36.7 examples/sec; 0.218 sec/batch; 20h:06m:42s remains)
INFO - root - 2017-12-17 02:48:56.621644: step 560, loss = 0.66, batch loss = 0.51 (36.4 examples/sec; 0.220 sec/batch; 20h:14m:22s remains)
INFO - root - 2017-12-17 02:48:58.857526: step 570, loss = 0.65, batch loss = 0.50 (36.7 examples/sec; 0.218 sec/batch; 20h:05m:58s remains)
INFO - root - 2017-12-17 02:49:01.074629: step 580, loss = 0.77, batch loss = 0.62 (37.0 examples/sec; 0.216 sec/batch; 19h:57m:18s remains)
INFO - root - 2017-12-17 02:49:03.312456: step 590, loss = 0.58, batch loss = 0.43 (35.7 examples/sec; 0.224 sec/batch; 20h:38m:20s remains)
INFO - root - 2017-12-17 02:49:05.538422: step 600, loss = 0.68, batch loss = 0.53 (35.3 examples/sec; 0.227 sec/batch; 20h:54m:27s remains)
INFO - root - 2017-12-17 02:49:07.946540: step 610, loss = 0.75, batch loss = 0.59 (34.7 examples/sec; 0.230 sec/batch; 21h:14m:17s remains)
INFO - root - 2017-12-17 02:49:10.160123: step 620, loss = 0.84, batch loss = 0.67 (36.7 examples/sec; 0.218 sec/batch; 20h:06m:02s remains)
INFO - root - 2017-12-17 02:49:12.386940: step 630, loss = 0.76, batch loss = 0.58 (35.5 examples/sec; 0.225 sec/batch; 20h:45m:44s remains)
INFO - root - 2017-12-17 02:49:14.611612: step 640, loss = 0.74, batch loss = 0.56 (34.9 examples/sec; 0.230 sec/batch; 21h:09m:27s remains)
INFO - root - 2017-12-17 02:49:16.804683: step 650, loss = 0.78, batch loss = 0.58 (36.9 examples/sec; 0.217 sec/batch; 19h:59m:51s remains)
INFO - root - 2017-12-17 02:49:19.017509: step 660, loss = 0.70, batch loss = 0.50 (35.5 examples/sec; 0.225 sec/batch; 20h:44m:53s remains)
INFO - root - 2017-12-17 02:49:21.248012: step 670, loss = 0.82, batch loss = 0.62 (35.0 examples/sec; 0.228 sec/batch; 21h:02m:18s remains)
INFO - root - 2017-12-17 02:49:23.522799: step 680, loss = 0.84, batch loss = 0.64 (35.4 examples/sec; 0.226 sec/batch; 20h:51m:09s remains)
INFO - root - 2017-12-17 02:49:25.737158: step 690, loss = 0.71, batch loss = 0.51 (36.1 examples/sec; 0.221 sec/batch; 20h:24m:21s remains)
INFO - root - 2017-12-17 02:49:27.958788: step 700, loss = 0.72, batch loss = 0.52 (36.5 examples/sec; 0.219 sec/batch; 20h:12m:44s remains)
INFO - root - 2017-12-17 02:49:30.315863: step 710, loss = 0.70, batch loss = 0.50 (37.4 examples/sec; 0.214 sec/batch; 19h:43m:44s remains)
INFO - root - 2017-12-17 02:49:32.571310: step 720, loss = 0.72, batch loss = 0.52 (34.6 examples/sec; 0.231 sec/batch; 21h:18m:56s remains)
INFO - root - 2017-12-17 02:49:34.778381: step 730, loss = 0.74, batch loss = 0.54 (36.6 examples/sec; 0.219 sec/batch; 20h:09m:21s remains)
INFO - root - 2017-12-17 02:49:37.008651: step 740, loss = 0.75, batch loss = 0.55 (36.0 examples/sec; 0.222 sec/batch; 20h:27m:47s remains)
INFO - root - 2017-12-17 02:49:39.229808: step 750, loss = 0.67, batch loss = 0.47 (36.6 examples/sec; 0.218 sec/batch; 20h:07m:47s remains)
INFO - root - 2017-12-17 02:49:41.438048: step 760, loss = 0.72, batch loss = 0.52 (36.5 examples/sec; 0.219 sec/batch; 20h:13m:04s remains)
INFO - root - 2017-12-17 02:49:43.667804: step 770, loss = 0.83, batch loss = 0.63 (34.5 examples/sec; 0.232 sec/batch; 21h:21m:45s remains)
INFO - root - 2017-12-17 02:49:45.904560: step 780, loss = 0.66, batch loss = 0.46 (35.9 examples/sec; 0.223 sec/batch; 20h:32m:11s remains)
INFO - root - 2017-12-17 02:49:48.130595: step 790, loss = 0.65, batch loss = 0.45 (33.8 examples/sec; 0.237 sec/batch; 21h:50m:20s remains)
INFO - root - 2017-12-17 02:49:50.387534: step 800, loss = 0.68, batch loss = 0.48 (34.7 examples/sec; 0.231 sec/batch; 21h:16m:10s remains)
INFO - root - 2017-12-17 02:49:52.743325: step 810, loss = 0.78, batch loss = 0.58 (36.0 examples/sec; 0.222 sec/batch; 20h:29m:01s remains)
INFO - root - 2017-12-17 02:49:54.966964: step 820, loss = 0.65, batch loss = 0.45 (37.0 examples/sec; 0.216 sec/batch; 19h:55m:05s remains)
INFO - root - 2017-12-17 02:49:57.211693: step 830, loss = 0.68, batch loss = 0.48 (36.0 examples/sec; 0.222 sec/batch; 20h:27m:55s remains)
INFO - root - 2017-12-17 02:49:59.439546: step 840, loss = 0.69, batch loss = 0.50 (36.1 examples/sec; 0.221 sec/batch; 20h:24m:03s remains)
INFO - root - 2017-12-17 02:50:01.667151: step 850, loss = 0.71, batch loss = 0.51 (36.3 examples/sec; 0.220 sec/batch; 20h:17m:08s remains)
INFO - root - 2017-12-17 02:50:03.910707: step 860, loss = 0.63, batch loss = 0.43 (35.0 examples/sec; 0.229 sec/batch; 21h:04m:03s remains)
INFO - root - 2017-12-17 02:50:06.144888: step 870, loss = 0.67, batch loss = 0.47 (35.7 examples/sec; 0.224 sec/batch; 20h:39m:58s remains)
INFO - root - 2017-12-17 02:50:08.371222: step 880, loss = 0.67, batch loss = 0.47 (35.1 examples/sec; 0.228 sec/batch; 20h:58m:21s remains)
INFO - root - 2017-12-17 02:50:10.590304: step 890, loss = 0.64, batch loss = 0.44 (34.8 examples/sec; 0.230 sec/batch; 21h:12m:06s remains)
INFO - root - 2017-12-17 02:50:12.822879: step 900, loss = 0.63, batch loss = 0.43 (34.7 examples/sec; 0.230 sec/batch; 21h:12m:57s remains)
INFO - root - 2017-12-17 02:50:15.174943: step 910, loss = 0.67, batch loss = 0.47 (35.3 examples/sec; 0.227 sec/batch; 20h:53m:46s remains)
INFO - root - 2017-12-17 02:50:17.411180: step 920, loss = 0.66, batch loss = 0.46 (34.9 examples/sec; 0.229 sec/batch; 21h:06m:35s remains)
INFO - root - 2017-12-17 02:50:19.642086: step 930, loss = 0.67, batch loss = 0.47 (35.8 examples/sec; 0.224 sec/batch; 20h:36m:08s remains)
INFO - root - 2017-12-17 02:50:21.933575: step 940, loss = 0.67, batch loss = 0.48 (34.9 examples/sec; 0.229 sec/batch; 21h:06m:48s remains)
INFO - root - 2017-12-17 02:50:24.150377: step 950, loss = 0.65, batch loss = 0.46 (36.6 examples/sec; 0.219 sec/batch; 20h:08m:20s remains)
INFO - root - 2017-12-17 02:50:26.391007: step 960, loss = 0.78, batch loss = 0.59 (36.1 examples/sec; 0.222 sec/batch; 20h:26m:08s remains)
INFO - root - 2017-12-17 02:50:28.619482: step 970, loss = 0.63, batch loss = 0.43 (34.4 examples/sec; 0.233 sec/batch; 21h:26m:12s remains)
INFO - root - 2017-12-17 02:50:30.861991: step 980, loss = 0.59, batch loss = 0.39 (34.8 examples/sec; 0.230 sec/batch; 21h:10m:08s remains)
INFO - root - 2017-12-17 02:50:33.083199: step 990, loss = 0.61, batch loss = 0.42 (36.4 examples/sec; 0.220 sec/batch; 20h:14m:14s remains)
INFO - root - 2017-12-17 02:50:35.315419: step 1000, loss = 0.68, batch loss = 0.48 (37.1 examples/sec; 0.215 sec/batch; 19h:50m:24s remains)
INFO - root - 2017-12-17 02:50:37.679483: step 1010, loss = 0.63, batch loss = 0.43 (34.6 examples/sec; 0.231 sec/batch; 21h:15m:52s remains)
INFO - root - 2017-12-17 02:50:39.899099: step 1020, loss = 0.63, batch loss = 0.43 (36.6 examples/sec; 0.218 sec/batch; 20h:06m:47s remains)
INFO - root - 2017-12-17 02:50:42.125864: step 1030, loss = 0.66, batch loss = 0.47 (37.6 examples/sec; 0.213 sec/batch; 19h:34m:43s remains)
INFO - root - 2017-12-17 02:50:44.360398: step 1040, loss = 0.65, batch loss = 0.45 (35.8 examples/sec; 0.223 sec/batch; 20h:34m:32s remains)
INFO - root - 2017-12-17 02:50:46.596879: step 1050, loss = 0.71, batch loss = 0.52 (36.2 examples/sec; 0.221 sec/batch; 20h:19m:13s remains)
INFO - root - 2017-12-17 02:50:48.853516: step 1060, loss = 0.64, batch loss = 0.44 (36.3 examples/sec; 0.221 sec/batch; 20h:18m:10s remains)
INFO - root - 2017-12-17 02:50:51.077435: step 1070, loss = 0.66, batch loss = 0.47 (35.2 examples/sec; 0.227 sec/batch; 20h:55m:58s remains)
INFO - root - 2017-12-17 02:50:53.328917: step 1080, loss = 0.60, batch loss = 0.40 (34.8 examples/sec; 0.230 sec/batch; 21h:08m:52s remains)
INFO - root - 2017-12-17 02:50:55.545469: step 1090, loss = 0.57, batch loss = 0.38 (35.6 examples/sec; 0.225 sec/batch; 20h:41m:49s remains)
INFO - root - 2017-12-17 02:50:57.781655: step 1100, loss = 0.57, batch loss = 0.38 (36.2 examples/sec; 0.221 sec/batch; 20h:22m:01s remains)
INFO - root - 2017-12-17 02:51:00.131194: step 1110, loss = 0.58, batch loss = 0.39 (36.1 examples/sec; 0.222 sec/batch; 20h:24m:58s remains)
INFO - root - 2017-12-17 02:51:02.384395: step 1120, loss = 0.66, batch loss = 0.46 (36.2 examples/sec; 0.221 sec/batch; 20h:21m:18s remains)
INFO - root - 2017-12-17 02:51:04.614351: step 1130, loss = 0.64, batch loss = 0.44 (35.5 examples/sec; 0.225 sec/batch; 20h:42m:54s remains)
INFO - root - 2017-12-17 02:51:06.842371: step 1140, loss = 0.64, batch loss = 0.44 (36.3 examples/sec; 0.220 sec/batch; 20h:17m:25s remains)
INFO - root - 2017-12-17 02:51:09.070740: step 1150, loss = 0.63, batch loss = 0.44 (36.4 examples/sec; 0.220 sec/batch; 20h:14m:32s remains)
INFO - root - 2017-12-17 02:51:11.303484: step 1160, loss = 0.60, batch loss = 0.41 (35.0 examples/sec; 0.229 sec/batch; 21h:02m:35s remains)
INFO - root - 2017-12-17 02:51:13.528804: step 1170, loss = 0.60, batch loss = 0.41 (35.9 examples/sec; 0.223 sec/batch; 20h:31m:11s remains)
INFO - root - 2017-12-17 02:51:15.802883: step 1180, loss = 0.60, batch loss = 0.41 (34.9 examples/sec; 0.229 sec/batch; 21h:04m:54s remains)
INFO - root - 2017-12-17 02:51:18.024960: step 1190, loss = 0.62, batch loss = 0.43 (34.4 examples/sec; 0.233 sec/batch; 21h:25m:43s remains)
INFO - root - 2017-12-17 02:51:20.261239: step 1200, loss = 0.65, batch loss = 0.45 (36.3 examples/sec; 0.220 sec/batch; 20h:16m:19s remains)
INFO - root - 2017-12-17 02:51:22.636555: step 1210, loss = 0.68, batch loss = 0.49 (36.9 examples/sec; 0.217 sec/batch; 19h:57m:14s remains)
INFO - root - 2017-12-17 02:51:24.875074: step 1220, loss = 0.63, batch loss = 0.44 (36.1 examples/sec; 0.222 sec/batch; 20h:23m:01s remains)
INFO - root - 2017-12-17 02:51:27.096949: step 1230, loss = 0.67, batch loss = 0.47 (36.7 examples/sec; 0.218 sec/batch; 20h:02m:56s remains)
INFO - root - 2017-12-17 02:51:29.330113: step 1240, loss = 0.61, batch loss = 0.42 (36.0 examples/sec; 0.222 sec/batch; 20h:25m:25s remains)
INFO - root - 2017-12-17 02:51:31.565270: step 1250, loss = 0.65, batch loss = 0.46 (35.0 examples/sec; 0.228 sec/batch; 21h:01m:11s remains)
INFO - root - 2017-12-17 02:51:33.792196: step 1260, loss = 0.67, batch loss = 0.48 (35.4 examples/sec; 0.226 sec/batch; 20h:47m:59s remains)
INFO - root - 2017-12-17 02:51:36.015077: step 1270, loss = 0.63, batch loss = 0.44 (35.0 examples/sec; 0.228 sec/batch; 21h:01m:05s remains)
INFO - root - 2017-12-17 02:51:38.315498: step 1280, loss = 0.57, batch loss = 0.38 (35.3 examples/sec; 0.227 sec/batch; 20h:52m:39s remains)
INFO - root - 2017-12-17 02:51:40.537822: step 1290, loss = 0.63, batch loss = 0.44 (36.4 examples/sec; 0.220 sec/batch; 20h:14m:39s remains)
INFO - root - 2017-12-17 02:51:42.769271: step 1300, loss = 0.55, batch loss = 0.36 (36.1 examples/sec; 0.222 sec/batch; 20h:24m:12s remains)
INFO - root - 2017-12-17 02:51:45.153358: step 1310, loss = 0.66, batch loss = 0.47 (36.8 examples/sec; 0.217 sec/batch; 20h:00m:10s remains)
INFO - root - 2017-12-17 02:51:47.388800: step 1320, loss = 0.58, batch loss = 0.39 (34.8 examples/sec; 0.230 sec/batch; 21h:07m:35s remains)
INFO - root - 2017-12-17 02:51:49.616786: step 1330, loss = 0.60, batch loss = 0.42 (35.4 examples/sec; 0.226 sec/batch; 20h:46m:23s remains)
INFO - root - 2017-12-17 02:51:51.853231: step 1340, loss = 0.58, batch loss = 0.39 (35.6 examples/sec; 0.225 sec/batch; 20h:39m:20s remains)
INFO - root - 2017-12-17 02:51:54.140215: step 1350, loss = 0.68, batch loss = 0.49 (35.5 examples/sec; 0.225 sec/batch; 20h:43m:34s remains)
INFO - root - 2017-12-17 02:51:56.376234: step 1360, loss = 0.58, batch loss = 0.39 (35.3 examples/sec; 0.226 sec/batch; 20h:49m:02s remains)
INFO - root - 2017-12-17 02:51:58.636514: step 1370, loss = 0.67, batch loss = 0.48 (35.5 examples/sec; 0.225 sec/batch; 20h:43m:18s remains)
INFO - root - 2017-12-17 02:52:00.905090: step 1380, loss = 0.58, batch loss = 0.39 (36.3 examples/sec; 0.220 sec/batch; 20h:16m:42s remains)
INFO - root - 2017-12-17 02:52:03.159646: step 1390, loss = 0.63, batch loss = 0.44 (36.3 examples/sec; 0.220 sec/batch; 20h:15m:36s remains)
INFO - root - 2017-12-17 02:52:05.381623: step 1400, loss = 0.60, batch loss = 0.42 (36.0 examples/sec; 0.222 sec/batch; 20h:26m:31s remains)
INFO - root - 2017-12-17 02:52:07.809207: step 1410, loss = 0.60, batch loss = 0.41 (35.3 examples/sec; 0.227 sec/batch; 20h:49m:57s remains)
INFO - root - 2017-12-17 02:52:10.072448: step 1420, loss = 0.55, batch loss = 0.36 (34.8 examples/sec; 0.230 sec/batch; 21h:07m:09s remains)
INFO - root - 2017-12-17 02:52:12.342578: step 1430, loss = 0.61, batch loss = 0.42 (36.4 examples/sec; 0.220 sec/batch; 20h:13m:21s remains)
INFO - root - 2017-12-17 02:52:14.572618: step 1440, loss = 0.49, batch loss = 0.31 (35.6 examples/sec; 0.225 sec/batch; 20h:39m:21s remains)
INFO - root - 2017-12-17 02:52:16.850114: step 1450, loss = 0.62, batch loss = 0.43 (35.7 examples/sec; 0.224 sec/batch; 20h:36m:40s remains)
INFO - root - 2017-12-17 02:52:19.082570: step 1460, loss = 0.61, batch loss = 0.42 (35.4 examples/sec; 0.226 sec/batch; 20h:46m:03s remains)
INFO - root - 2017-12-17 02:52:21.328102: step 1470, loss = 0.55, batch loss = 0.37 (36.2 examples/sec; 0.221 sec/batch; 20h:18m:49s remains)
INFO - root - 2017-12-17 02:52:23.599312: step 1480, loss = 0.61, batch loss = 0.43 (34.2 examples/sec; 0.234 sec/batch; 21h:29m:21s remains)
INFO - root - 2017-12-17 02:52:25.837589: step 1490, loss = 0.71, batch loss = 0.53 (36.2 examples/sec; 0.221 sec/batch; 20h:20m:23s remains)
INFO - root - 2017-12-17 02:52:28.073613: step 1500, loss = 0.60, batch loss = 0.41 (35.8 examples/sec; 0.223 sec/batch; 20h:32m:21s remains)
INFO - root - 2017-12-17 02:52:30.434478: step 1510, loss = 0.54, batch loss = 0.35 (35.3 examples/sec; 0.226 sec/batch; 20h:49m:22s remains)
INFO - root - 2017-12-17 02:52:32.693737: step 1520, loss = 0.60, batch loss = 0.42 (35.0 examples/sec; 0.229 sec/batch; 21h:01m:45s remains)
INFO - root - 2017-12-17 02:52:34.946982: step 1530, loss = 0.50, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 20h:53m:41s remains)
INFO - root - 2017-12-17 02:52:37.176868: step 1540, loss = 0.62, batch loss = 0.44 (37.2 examples/sec; 0.215 sec/batch; 19h:46m:58s remains)
INFO - root - 2017-12-17 02:52:39.432337: step 1550, loss = 0.53, batch loss = 0.34 (36.3 examples/sec; 0.221 sec/batch; 20h:16m:33s remains)
INFO - root - 2017-12-17 02:52:41.674952: step 1560, loss = 0.56, batch loss = 0.37 (34.9 examples/sec; 0.229 sec/batch; 21h:05m:31s remains)
INFO - root - 2017-12-17 02:52:43.904945: step 1570, loss = 0.59, batch loss = 0.40 (36.3 examples/sec; 0.221 sec/batch; 20h:16m:42s remains)
INFO - root - 2017-12-17 02:52:46.146040: step 1580, loss = 0.56, batch loss = 0.37 (34.8 examples/sec; 0.230 sec/batch; 21h:06m:46s remains)
INFO - root - 2017-12-17 02:52:48.413939: step 1590, loss = 0.48, batch loss = 0.29 (35.7 examples/sec; 0.224 sec/batch; 20h:37m:04s remains)
INFO - root - 2017-12-17 02:52:50.651721: step 1600, loss = 0.55, batch loss = 0.37 (36.1 examples/sec; 0.222 sec/batch; 20h:22m:20s remains)
INFO - root - 2017-12-17 02:52:53.033609: step 1610, loss = 0.57, batch loss = 0.39 (34.8 examples/sec; 0.230 sec/batch; 21h:07m:31s remains)
INFO - root - 2017-12-17 02:52:55.269967: step 1620, loss = 0.61, batch loss = 0.43 (36.0 examples/sec; 0.222 sec/batch; 20h:26m:53s remains)
INFO - root - 2017-12-17 02:52:57.503288: step 1630, loss = 0.53, batch loss = 0.35 (36.0 examples/sec; 0.223 sec/batch; 20h:27m:06s remains)
INFO - root - 2017-12-17 02:52:59.729453: step 1640, loss = 0.56, batch loss = 0.37 (35.9 examples/sec; 0.223 sec/batch; 20h:28m:12s remains)
INFO - root - 2017-12-17 02:53:01.966016: step 1650, loss = 0.56, batch loss = 0.38 (35.3 examples/sec; 0.226 sec/batch; 20h:48m:56s remains)
INFO - root - 2017-12-17 02:53:04.229521: step 1660, loss = 0.65, batch loss = 0.47 (34.9 examples/sec; 0.229 sec/batch; 21h:02m:55s remains)
INFO - root - 2017-12-17 02:53:06.490762: step 1670, loss = 0.67, batch loss = 0.49 (35.1 examples/sec; 0.228 sec/batch; 20h:55m:49s remains)
INFO - root - 2017-12-17 02:53:08.745060: step 1680, loss = 0.61, batch loss = 0.43 (36.0 examples/sec; 0.222 sec/batch; 20h:25m:08s remains)
INFO - root - 2017-12-17 02:53:11.007860: step 1690, loss = 0.56, batch loss = 0.37 (35.6 examples/sec; 0.225 sec/batch; 20h:39m:21s remains)
INFO - root - 2017-12-17 02:53:13.237430: step 1700, loss = 0.60, batch loss = 0.42 (35.8 examples/sec; 0.224 sec/batch; 20h:32m:32s remains)
INFO - root - 2017-12-17 02:53:15.599748: step 1710, loss = 0.66, batch loss = 0.47 (35.8 examples/sec; 0.224 sec/batch; 20h:33m:05s remains)
INFO - root - 2017-12-17 02:53:17.824366: step 1720, loss = 0.60, batch loss = 0.41 (35.5 examples/sec; 0.225 sec/batch; 20h:42m:26s remains)
INFO - root - 2017-12-17 02:53:20.047708: step 1730, loss = 0.58, batch loss = 0.39 (35.9 examples/sec; 0.223 sec/batch; 20h:30m:00s remains)
INFO - root - 2017-12-17 02:53:22.279294: step 1740, loss = 0.57, batch loss = 0.39 (36.5 examples/sec; 0.219 sec/batch; 20h:07m:43s remains)
INFO - root - 2017-12-17 02:53:24.547915: step 1750, loss = 0.64, batch loss = 0.46 (35.5 examples/sec; 0.225 sec/batch; 20h:40m:43s remains)
INFO - root - 2017-12-17 02:53:26.813208: step 1760, loss = 0.58, batch loss = 0.40 (35.4 examples/sec; 0.226 sec/batch; 20h:47m:01s remains)
INFO - root - 2017-12-17 02:53:29.074429: step 1770, loss = 0.64, batch loss = 0.46 (35.2 examples/sec; 0.227 sec/batch; 20h:51m:03s remains)
INFO - root - 2017-12-17 02:53:31.348865: step 1780, loss = 0.56, batch loss = 0.38 (34.5 examples/sec; 0.232 sec/batch; 21h:18m:23s remains)
INFO - root - 2017-12-17 02:53:33.591640: step 1790, loss = 0.77, batch loss = 0.59 (35.3 examples/sec; 0.227 sec/batch; 20h:50m:46s remains)
INFO - root - 2017-12-17 02:53:35.815297: step 1800, loss = 0.61, batch loss = 0.43 (35.7 examples/sec; 0.224 sec/batch; 20h:36m:44s remains)
INFO - root - 2017-12-17 02:53:38.220724: step 1810, loss = 0.53, batch loss = 0.35 (34.7 examples/sec; 0.230 sec/batch; 21h:09m:13s remains)
INFO - root - 2017-12-17 02:53:40.461613: step 1820, loss = 0.46, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 20h:40m:19s remains)
INFO - root - 2017-12-17 02:53:42.696300: step 1830, loss = 0.56, batch loss = 0.38 (34.2 examples/sec; 0.234 sec/batch; 21h:27m:59s remains)
INFO - root - 2017-12-17 02:53:44.947438: step 1840, loss = 0.55, batch loss = 0.37 (35.9 examples/sec; 0.223 sec/batch; 20h:26m:41s remains)
INFO - root - 2017-12-17 02:53:47.184953: step 1850, loss = 0.56, batch loss = 0.38 (35.8 examples/sec; 0.224 sec/batch; 20h:31m:49s remains)
INFO - root - 2017-12-17 02:53:49.442515: step 1860, loss = 0.52, batch loss = 0.34 (35.7 examples/sec; 0.224 sec/batch; 20h:33m:48s remains)
INFO - root - 2017-12-17 02:53:51.672649: step 1870, loss = 0.51, batch loss = 0.34 (36.6 examples/sec; 0.219 sec/batch; 20h:04m:18s remains)
INFO - root - 2017-12-17 02:53:53.949306: step 1880, loss = 0.53, batch loss = 0.35 (35.2 examples/sec; 0.227 sec/batch; 20h:52m:47s remains)
INFO - root - 2017-12-17 02:53:56.186905: step 1890, loss = 0.53, batch loss = 0.36 (36.1 examples/sec; 0.221 sec/batch; 20h:20m:26s remains)
INFO - root - 2017-12-17 02:53:58.410354: step 1900, loss = 0.45, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 20h:31m:29s remains)
INFO - root - 2017-12-17 02:54:00.763442: step 1910, loss = 0.59, batch loss = 0.41 (36.0 examples/sec; 0.222 sec/batch; 20h:24m:50s remains)
INFO - root - 2017-12-17 02:54:03.016376: step 1920, loss = 0.58, batch loss = 0.40 (34.6 examples/sec; 0.231 sec/batch; 21h:14m:53s remains)
INFO - root - 2017-12-17 02:54:05.261971: step 1930, loss = 0.54, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 20h:12m:32s remains)
INFO - root - 2017-12-17 02:54:07.491130: step 1940, loss = 0.60, batch loss = 0.42 (34.9 examples/sec; 0.229 sec/batch; 21h:01m:18s remains)
INFO - root - 2017-12-17 02:54:09.739397: step 1950, loss = 0.50, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 20h:27m:59s remains)
INFO - root - 2017-12-17 02:54:11.979606: step 1960, loss = 0.53, batch loss = 0.35 (34.6 examples/sec; 0.231 sec/batch; 21h:12m:00s remains)
INFO - root - 2017-12-17 02:54:14.230978: step 1970, loss = 0.53, batch loss = 0.35 (34.4 examples/sec; 0.232 sec/batch; 21h:19m:18s remains)
INFO - root - 2017-12-17 02:54:16.473522: step 1980, loss = 0.47, batch loss = 0.29 (35.0 examples/sec; 0.228 sec/batch; 20h:58m:25s remains)
INFO - root - 2017-12-17 02:54:18.719584: step 1990, loss = 0.58, batch loss = 0.40 (34.8 examples/sec; 0.230 sec/batch; 21h:05m:05s remains)
INFO - root - 2017-12-17 02:54:20.992353: step 2000, loss = 0.52, batch loss = 0.35 (36.9 examples/sec; 0.217 sec/batch; 19h:52m:49s remains)
INFO - root - 2017-12-17 02:54:23.381733: step 2010, loss = 0.46, batch loss = 0.29 (36.6 examples/sec; 0.218 sec/batch; 20h:02m:24s remains)
INFO - root - 2017-12-17 02:54:25.626026: step 2020, loss = 0.48, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 20h:25m:47s remains)
INFO - root - 2017-12-17 02:54:27.905232: step 2030, loss = 0.51, batch loss = 0.33 (35.6 examples/sec; 0.225 sec/batch; 20h:37m:51s remains)
INFO - root - 2017-12-17 02:54:30.137433: step 2040, loss = 0.45, batch loss = 0.27 (35.0 examples/sec; 0.229 sec/batch; 20h:58m:49s remains)
INFO - root - 2017-12-17 02:54:32.364283: step 2050, loss = 0.51, batch loss = 0.33 (35.1 examples/sec; 0.228 sec/batch; 20h:55m:02s remains)
INFO - root - 2017-12-17 02:54:34.622364: step 2060, loss = 0.49, batch loss = 0.32 (33.9 examples/sec; 0.236 sec/batch; 21h:40m:55s remains)
INFO - root - 2017-12-17 02:54:36.896546: step 2070, loss = 0.50, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 20h:20m:24s remains)
INFO - root - 2017-12-17 02:54:39.179513: step 2080, loss = 0.55, batch loss = 0.37 (35.3 examples/sec; 0.227 sec/batch; 20h:47m:57s remains)
INFO - root - 2017-12-17 02:54:41.452504: step 2090, loss = 0.52, batch loss = 0.34 (36.1 examples/sec; 0.221 sec/batch; 20h:19m:24s remains)
INFO - root - 2017-12-17 02:54:43.690656: step 2100, loss = 0.61, batch loss = 0.44 (36.8 examples/sec; 0.218 sec/batch; 19h:57m:47s remains)
INFO - root - 2017-12-17 02:54:46.077652: step 2110, loss = 0.50, batch loss = 0.33 (35.9 examples/sec; 0.223 sec/batch; 20h:26m:49s remains)
INFO - root - 2017-12-17 02:54:48.334156: step 2120, loss = 0.57, batch loss = 0.40 (34.4 examples/sec; 0.232 sec/batch; 21h:19m:43s remains)
INFO - root - 2017-12-17 02:54:50.608322: step 2130, loss = 0.58, batch loss = 0.41 (35.2 examples/sec; 0.227 sec/batch; 20h:49m:49s remains)
INFO - root - 2017-12-17 02:54:52.861056: step 2140, loss = 0.48, batch loss = 0.31 (31.6 examples/sec; 0.253 sec/batch; 23h:12m:40s remains)
INFO - root - 2017-12-17 02:54:55.112874: step 2150, loss = 0.59, batch loss = 0.42 (36.1 examples/sec; 0.221 sec/batch; 20h:18m:30s remains)
INFO - root - 2017-12-17 02:54:57.397814: step 2160, loss = 0.44, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 20h:11m:44s remains)
INFO - root - 2017-12-17 02:54:59.652989: step 2170, loss = 0.60, batch loss = 0.42 (35.8 examples/sec; 0.223 sec/batch; 20h:29m:59s remains)
INFO - root - 2017-12-17 02:55:01.929006: step 2180, loss = 0.55, batch loss = 0.38 (35.6 examples/sec; 0.225 sec/batch; 20h:38m:43s remains)
INFO - root - 2017-12-17 02:55:04.223009: step 2190, loss = 0.47, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 20h:53m:51s remains)
INFO - root - 2017-12-17 02:55:06.505544: step 2200, loss = 0.55, batch loss = 0.37 (35.3 examples/sec; 0.227 sec/batch; 20h:48m:39s remains)
INFO - root - 2017-12-17 02:55:08.953590: step 2210, loss = 0.55, batch loss = 0.38 (34.1 examples/sec; 0.235 sec/batch; 21h:31m:20s remains)
INFO - root - 2017-12-17 02:55:11.212868: step 2220, loss = 0.52, batch loss = 0.35 (35.6 examples/sec; 0.225 sec/batch; 20h:38m:44s remains)
INFO - root - 2017-12-17 02:55:13.524617: step 2230, loss = 0.54, batch loss = 0.37 (34.6 examples/sec; 0.231 sec/batch; 21h:11m:36s remains)
INFO - root - 2017-12-17 02:55:15.844470: step 2240, loss = 0.52, batch loss = 0.34 (35.6 examples/sec; 0.225 sec/batch; 20h:38m:00s remains)
INFO - root - 2017-12-17 02:55:18.079204: step 2250, loss = 0.50, batch loss = 0.33 (35.6 examples/sec; 0.224 sec/batch; 20h:35m:23s remains)
INFO - root - 2017-12-17 02:55:20.357039: step 2260, loss = 0.49, batch loss = 0.32 (35.5 examples/sec; 0.225 sec/batch; 20h:40m:14s remains)
INFO - root - 2017-12-17 02:55:22.640717: step 2270, loss = 0.48, batch loss = 0.30 (34.7 examples/sec; 0.230 sec/batch; 21h:07m:14s remains)
INFO - root - 2017-12-17 02:55:24.918411: step 2280, loss = 0.43, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 20h:53m:39s remains)
INFO - root - 2017-12-17 02:55:27.194854: step 2290, loss = 0.48, batch loss = 0.30 (35.3 examples/sec; 0.227 sec/batch; 20h:47m:53s remains)
INFO - root - 2017-12-17 02:55:29.497600: step 2300, loss = 0.53, batch loss = 0.35 (34.1 examples/sec; 0.234 sec/batch; 21h:29m:34s remains)
INFO - root - 2017-12-17 02:55:31.927075: step 2310, loss = 0.56, batch loss = 0.39 (33.4 examples/sec; 0.240 sec/batch; 21h:59m:03s remains)
INFO - root - 2017-12-17 02:55:34.206966: step 2320, loss = 0.47, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 20h:36m:44s remains)
INFO - root - 2017-12-17 02:55:36.469092: step 2330, loss = 0.43, batch loss = 0.26 (36.3 examples/sec; 0.220 sec/batch; 20h:12m:32s remains)
INFO - root - 2017-12-17 02:55:38.722543: step 2340, loss = 0.48, batch loss = 0.31 (34.4 examples/sec; 0.233 sec/batch; 21h:20m:17s remains)
INFO - root - 2017-12-17 02:55:40.989158: step 2350, loss = 0.51, batch loss = 0.34 (35.5 examples/sec; 0.225 sec/batch; 20h:39m:21s remains)
INFO - root - 2017-12-17 02:55:43.273656: step 2360, loss = 0.49, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 20h:46m:19s remains)
INFO - root - 2017-12-17 02:55:45.597061: step 2370, loss = 0.54, batch loss = 0.37 (33.3 examples/sec; 0.240 sec/batch; 22h:03m:15s remains)
INFO - root - 2017-12-17 02:55:47.895969: step 2380, loss = 0.46, batch loss = 0.29 (34.2 examples/sec; 0.234 sec/batch; 21h:27m:54s remains)
INFO - root - 2017-12-17 02:55:50.147869: step 2390, loss = 0.50, batch loss = 0.33 (35.8 examples/sec; 0.224 sec/batch; 20h:30m:55s remains)
INFO - root - 2017-12-17 02:55:52.470240: step 2400, loss = 0.45, batch loss = 0.28 (34.8 examples/sec; 0.230 sec/batch; 21h:02m:59s remains)
INFO - root - 2017-12-17 02:55:54.893172: step 2410, loss = 0.46, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 21h:01m:37s remains)
INFO - root - 2017-12-17 02:55:57.152243: step 2420, loss = 0.52, batch loss = 0.35 (36.4 examples/sec; 0.220 sec/batch; 20h:09m:26s remains)
INFO - root - 2017-12-17 02:55:59.419137: step 2430, loss = 0.45, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 20h:43m:01s remains)
INFO - root - 2017-12-17 02:56:01.753550: step 2440, loss = 0.48, batch loss = 0.31 (32.6 examples/sec; 0.245 sec/batch; 22h:28m:58s remains)
INFO - root - 2017-12-17 02:56:04.019385: step 2450, loss = 0.52, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 20h:20m:38s remains)
INFO - root - 2017-12-17 02:56:06.305595: step 2460, loss = 0.43, batch loss = 0.26 (35.2 examples/sec; 0.228 sec/batch; 20h:51m:46s remains)
INFO - root - 2017-12-17 02:56:08.632279: step 2470, loss = 0.56, batch loss = 0.39 (34.5 examples/sec; 0.232 sec/batch; 21h:15m:35s remains)
INFO - root - 2017-12-17 02:56:10.890156: step 2480, loss = 0.47, batch loss = 0.30 (36.8 examples/sec; 0.218 sec/batch; 19h:56m:54s remains)
INFO - root - 2017-12-17 02:56:13.147666: step 2490, loss = 0.53, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 20h:26m:36s remains)
INFO - root - 2017-12-17 02:56:15.460126: step 2500, loss = 0.40, batch loss = 0.23 (33.7 examples/sec; 0.238 sec/batch; 21h:46m:27s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-2500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-2500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 02:56:18.309824: step 2510, loss = 0.42, batch loss = 0.25 (34.9 examples/sec; 0.229 sec/batch; 20h:59m:02s remains)
INFO - root - 2017-12-17 02:56:20.575178: step 2520, loss = 0.53, batch loss = 0.37 (34.6 examples/sec; 0.232 sec/batch; 21h:13m:16s remains)
INFO - root - 2017-12-17 02:56:22.835343: step 2530, loss = 0.54, batch loss = 0.37 (34.1 examples/sec; 0.234 sec/batch; 21h:28m:48s remains)
INFO - root - 2017-12-17 02:56:25.121894: step 2540, loss = 0.56, batch loss = 0.39 (35.8 examples/sec; 0.223 sec/batch; 20h:28m:42s remains)
INFO - root - 2017-12-17 02:56:27.384580: step 2550, loss = 0.51, batch loss = 0.34 (35.1 examples/sec; 0.228 sec/batch; 20h:53m:56s remains)
INFO - root - 2017-12-17 02:56:29.670766: step 2560, loss = 0.48, batch loss = 0.32 (35.0 examples/sec; 0.229 sec/batch; 20h:57m:51s remains)
INFO - root - 2017-12-17 02:56:31.928121: step 2570, loss = 0.46, batch loss = 0.30 (36.7 examples/sec; 0.218 sec/batch; 19h:59m:28s remains)
INFO - root - 2017-12-17 02:56:34.201159: step 2580, loss = 0.44, batch loss = 0.27 (34.7 examples/sec; 0.231 sec/batch; 21h:08m:04s remains)
INFO - root - 2017-12-17 02:56:36.478197: step 2590, loss = 0.41, batch loss = 0.24 (33.9 examples/sec; 0.236 sec/batch; 21h:37m:59s remains)
INFO - root - 2017-12-17 02:56:38.778326: step 2600, loss = 0.42, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 20h:49m:10s remains)
INFO - root - 2017-12-17 02:56:41.207771: step 2610, loss = 0.54, batch loss = 0.38 (35.1 examples/sec; 0.228 sec/batch; 20h:51m:28s remains)
INFO - root - 2017-12-17 02:56:43.476223: step 2620, loss = 0.47, batch loss = 0.30 (33.9 examples/sec; 0.236 sec/batch; 21h:37m:59s remains)
INFO - root - 2017-12-17 02:56:45.775152: step 2630, loss = 0.41, batch loss = 0.25 (34.4 examples/sec; 0.232 sec/batch; 21h:17m:15s remains)
INFO - root - 2017-12-17 02:56:48.033742: step 2640, loss = 0.45, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 20h:27m:55s remains)
INFO - root - 2017-12-17 02:56:50.305283: step 2650, loss = 0.53, batch loss = 0.37 (37.1 examples/sec; 0.216 sec/batch; 19h:46m:19s remains)
INFO - root - 2017-12-17 02:56:52.558976: step 2660, loss = 0.51, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 20h:19m:03s remains)
INFO - root - 2017-12-17 02:56:54.838995: step 2670, loss = 0.48, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 20h:41m:11s remains)
INFO - root - 2017-12-17 02:56:57.111014: step 2680, loss = 0.47, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 20h:52m:42s remains)
INFO - root - 2017-12-17 02:56:59.379814: step 2690, loss = 0.47, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 20h:06m:07s remains)
INFO - root - 2017-12-17 02:57:01.645540: step 2700, loss = 0.41, batch loss = 0.24 (33.8 examples/sec; 0.236 sec/batch; 21h:39m:20s remains)
INFO - root - 2017-12-17 02:57:04.029484: step 2710, loss = 0.55, batch loss = 0.38 (35.9 examples/sec; 0.223 sec/batch; 20h:23m:41s remains)
INFO - root - 2017-12-17 02:57:06.328531: step 2720, loss = 0.51, batch loss = 0.35 (34.8 examples/sec; 0.230 sec/batch; 21h:03m:00s remains)
INFO - root - 2017-12-17 02:57:08.650716: step 2730, loss = 0.57, batch loss = 0.41 (35.4 examples/sec; 0.226 sec/batch; 20h:43m:23s remains)
INFO - root - 2017-12-17 02:57:10.898856: step 2740, loss = 0.48, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 20h:45m:20s remains)
INFO - root - 2017-12-17 02:57:13.200903: step 2750, loss = 0.54, batch loss = 0.38 (35.2 examples/sec; 0.227 sec/batch; 20h:50m:15s remains)
INFO - root - 2017-12-17 02:57:15.459667: step 2760, loss = 0.53, batch loss = 0.36 (34.9 examples/sec; 0.229 sec/batch; 21h:00m:33s remains)
INFO - root - 2017-12-17 02:57:17.711332: step 2770, loss = 0.50, batch loss = 0.34 (35.6 examples/sec; 0.224 sec/batch; 20h:33m:44s remains)
INFO - root - 2017-12-17 02:57:20.023505: step 2780, loss = 0.59, batch loss = 0.42 (33.8 examples/sec; 0.236 sec/batch; 21h:38m:58s remains)
INFO - root - 2017-12-17 02:57:22.273631: step 2790, loss = 0.47, batch loss = 0.31 (33.3 examples/sec; 0.240 sec/batch; 22h:00m:23s remains)
INFO - root - 2017-12-17 02:57:24.604616: step 2800, loss = 0.46, batch loss = 0.29 (34.7 examples/sec; 0.230 sec/batch; 21h:05m:02s remains)
INFO - root - 2017-12-17 02:57:26.990515: step 2810, loss = 0.41, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 20h:46m:14s remains)
INFO - root - 2017-12-17 02:57:29.250737: step 2820, loss = 0.46, batch loss = 0.30 (33.7 examples/sec; 0.237 sec/batch; 21h:44m:58s remains)
INFO - root - 2017-12-17 02:57:31.509239: step 2830, loss = 0.45, batch loss = 0.29 (35.8 examples/sec; 0.224 sec/batch; 20h:28m:26s remains)
INFO - root - 2017-12-17 02:57:33.760750: step 2840, loss = 0.41, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 20h:41m:36s remains)
INFO - root - 2017-12-17 02:57:36.066636: step 2850, loss = 0.46, batch loss = 0.29 (33.8 examples/sec; 0.237 sec/batch; 21h:41m:32s remains)
INFO - root - 2017-12-17 02:57:38.340853: step 2860, loss = 0.42, batch loss = 0.25 (34.8 examples/sec; 0.230 sec/batch; 21h:03m:18s remains)
INFO - root - 2017-12-17 02:57:40.593219: step 2870, loss = 0.46, batch loss = 0.30 (34.3 examples/sec; 0.233 sec/batch; 21h:19m:31s remains)
INFO - root - 2017-12-17 02:57:42.831151: step 2880, loss = 0.42, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 20h:34m:46s remains)
INFO - root - 2017-12-17 02:57:45.085463: step 2890, loss = 0.54, batch loss = 0.38 (35.4 examples/sec; 0.226 sec/batch; 20h:40m:59s remains)
INFO - root - 2017-12-17 02:57:47.397130: step 2900, loss = 0.52, batch loss = 0.36 (36.2 examples/sec; 0.221 sec/batch; 20h:15m:36s remains)
INFO - root - 2017-12-17 02:57:49.796140: step 2910, loss = 0.41, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 20h:46m:26s remains)
INFO - root - 2017-12-17 02:57:52.047772: step 2920, loss = 0.48, batch loss = 0.32 (36.8 examples/sec; 0.217 sec/batch; 19h:52m:48s remains)
INFO - root - 2017-12-17 02:57:54.297360: step 2930, loss = 0.53, batch loss = 0.37 (36.4 examples/sec; 0.220 sec/batch; 20h:08m:35s remains)
INFO - root - 2017-12-17 02:57:56.546071: step 2940, loss = 0.60, batch loss = 0.43 (35.3 examples/sec; 0.227 sec/batch; 20h:46m:06s remains)
INFO - root - 2017-12-17 02:57:58.820150: step 2950, loss = 0.43, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 20h:22m:17s remains)
INFO - root - 2017-12-17 02:58:01.097501: step 2960, loss = 0.51, batch loss = 0.35 (35.7 examples/sec; 0.224 sec/batch; 20h:29m:28s remains)
INFO - root - 2017-12-17 02:58:03.407050: step 2970, loss = 0.44, batch loss = 0.28 (33.6 examples/sec; 0.238 sec/batch; 21h:45m:45s remains)
INFO - root - 2017-12-17 02:58:05.685332: step 2980, loss = 0.42, batch loss = 0.26 (36.9 examples/sec; 0.217 sec/batch; 19h:51m:32s remains)
INFO - root - 2017-12-17 02:58:08.004990: step 2990, loss = 0.51, batch loss = 0.35 (35.8 examples/sec; 0.224 sec/batch; 20h:28m:12s remains)
INFO - root - 2017-12-17 02:58:10.259321: step 3000, loss = 0.45, batch loss = 0.29 (33.8 examples/sec; 0.237 sec/batch; 21h:39m:19s remains)
INFO - root - 2017-12-17 02:58:12.670455: step 3010, loss = 0.42, batch loss = 0.26 (34.4 examples/sec; 0.232 sec/batch; 21h:16m:04s remains)
INFO - root - 2017-12-17 02:58:14.948984: step 3020, loss = 0.48, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 20h:23m:18s remains)
INFO - root - 2017-12-17 02:58:17.198692: step 3030, loss = 0.47, batch loss = 0.31 (36.0 examples/sec; 0.222 sec/batch; 20h:20m:43s remains)
INFO - root - 2017-12-17 02:58:19.456050: step 3040, loss = 0.48, batch loss = 0.32 (34.0 examples/sec; 0.235 sec/batch; 21h:31m:44s remains)
INFO - root - 2017-12-17 02:58:21.705614: step 3050, loss = 0.48, batch loss = 0.32 (36.6 examples/sec; 0.219 sec/batch; 20h:00m:07s remains)
INFO - root - 2017-12-17 02:58:24.041906: step 3060, loss = 0.39, batch loss = 0.23 (35.8 examples/sec; 0.224 sec/batch; 20h:28m:02s remains)
INFO - root - 2017-12-17 02:58:26.276516: step 3070, loss = 0.49, batch loss = 0.33 (35.8 examples/sec; 0.223 sec/batch; 20h:27m:03s remains)
INFO - root - 2017-12-17 02:58:28.528368: step 3080, loss = 0.48, batch loss = 0.32 (35.5 examples/sec; 0.226 sec/batch; 20h:38m:29s remains)
INFO - root - 2017-12-17 02:58:30.822896: step 3090, loss = 0.46, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 20h:46m:11s remains)
INFO - root - 2017-12-17 02:58:33.079913: step 3100, loss = 0.54, batch loss = 0.38 (35.8 examples/sec; 0.223 sec/batch; 20h:26m:01s remains)
INFO - root - 2017-12-17 02:58:35.480455: step 3110, loss = 0.44, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 20h:45m:18s remains)
INFO - root - 2017-12-17 02:58:37.749358: step 3120, loss = 0.40, batch loss = 0.24 (36.1 examples/sec; 0.221 sec/batch; 20h:14m:56s remains)
INFO - root - 2017-12-17 02:58:39.995893: step 3130, loss = 0.43, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 20h:41m:55s remains)
INFO - root - 2017-12-17 02:58:42.244198: step 3140, loss = 0.43, batch loss = 0.27 (34.3 examples/sec; 0.233 sec/batch; 21h:20m:55s remains)
INFO - root - 2017-12-17 02:58:44.482329: step 3150, loss = 0.49, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 20h:39m:07s remains)
INFO - root - 2017-12-17 02:58:46.768318: step 3160, loss = 0.47, batch loss = 0.32 (33.8 examples/sec; 0.237 sec/batch; 21h:39m:07s remains)
INFO - root - 2017-12-17 02:58:49.054260: step 3170, loss = 0.42, batch loss = 0.27 (35.2 examples/sec; 0.227 sec/batch; 20h:47m:56s remains)
INFO - root - 2017-12-17 02:58:51.351093: step 3180, loss = 0.37, batch loss = 0.21 (34.2 examples/sec; 0.234 sec/batch; 21h:25m:29s remains)
INFO - root - 2017-12-17 02:58:53.636718: step 3190, loss = 0.50, batch loss = 0.34 (35.4 examples/sec; 0.226 sec/batch; 20h:40m:18s remains)
INFO - root - 2017-12-17 02:58:55.868800: step 3200, loss = 0.46, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 20h:23m:05s remains)
INFO - root - 2017-12-17 02:58:58.315142: step 3210, loss = 0.51, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 20h:20m:16s remains)
INFO - root - 2017-12-17 02:59:00.584549: step 3220, loss = 0.37, batch loss = 0.21 (36.3 examples/sec; 0.220 sec/batch; 20h:09m:01s remains)
INFO - root - 2017-12-17 02:59:02.848423: step 3230, loss = 0.41, batch loss = 0.25 (33.8 examples/sec; 0.237 sec/batch; 21h:37m:56s remains)
INFO - root - 2017-12-17 02:59:05.112781: step 3240, loss = 0.38, batch loss = 0.22 (36.3 examples/sec; 0.220 sec/batch; 20h:07m:52s remains)
INFO - root - 2017-12-17 02:59:07.360386: step 3250, loss = 0.41, batch loss = 0.25 (34.9 examples/sec; 0.229 sec/batch; 20h:56m:47s remains)
INFO - root - 2017-12-17 02:59:09.627310: step 3260, loss = 0.46, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 20h:33m:01s remains)
INFO - root - 2017-12-17 02:59:11.882057: step 3270, loss = 0.46, batch loss = 0.31 (35.0 examples/sec; 0.228 sec/batch; 20h:53m:10s remains)
INFO - root - 2017-12-17 02:59:14.162384: step 3280, loss = 0.44, batch loss = 0.28 (35.3 examples/sec; 0.227 sec/batch; 20h:44m:09s remains)
INFO - root - 2017-12-17 02:59:16.434252: step 3290, loss = 0.49, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 20h:29m:33s remains)
INFO - root - 2017-12-17 02:59:18.696058: step 3300, loss = 0.43, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 20h:47m:37s remains)
INFO - root - 2017-12-17 02:59:21.081166: step 3310, loss = 0.45, batch loss = 0.29 (36.7 examples/sec; 0.218 sec/batch; 19h:54m:44s remains)
INFO - root - 2017-12-17 02:59:23.380178: step 3320, loss = 0.48, batch loss = 0.32 (34.2 examples/sec; 0.234 sec/batch; 21h:24m:40s remains)
INFO - root - 2017-12-17 02:59:25.641014: step 3330, loss = 0.61, batch loss = 0.46 (36.8 examples/sec; 0.217 sec/batch; 19h:51m:12s remains)
INFO - root - 2017-12-17 02:59:27.912856: step 3340, loss = 0.49, batch loss = 0.34 (36.1 examples/sec; 0.222 sec/batch; 20h:17m:18s remains)
INFO - root - 2017-12-17 02:59:30.154825: step 3350, loss = 0.55, batch loss = 0.40 (35.0 examples/sec; 0.228 sec/batch; 20h:52m:42s remains)
INFO - root - 2017-12-17 02:59:32.450930: step 3360, loss = 0.47, batch loss = 0.31 (35.2 examples/sec; 0.227 sec/batch; 20h:46m:14s remains)
INFO - root - 2017-12-17 02:59:34.725188: step 3370, loss = 0.42, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 20h:19m:23s remains)
INFO - root - 2017-12-17 02:59:36.973442: step 3380, loss = 0.44, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 20h:57m:46s remains)
INFO - root - 2017-12-17 02:59:39.243872: step 3390, loss = 0.45, batch loss = 0.30 (35.2 examples/sec; 0.228 sec/batch; 20h:48m:15s remains)
INFO - root - 2017-12-17 02:59:41.477899: step 3400, loss = 0.46, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 20h:02m:17s remains)
INFO - root - 2017-12-17 02:59:43.863880: step 3410, loss = 0.50, batch loss = 0.35 (34.6 examples/sec; 0.231 sec/batch; 21h:08m:57s remains)
INFO - root - 2017-12-17 02:59:46.128735: step 3420, loss = 0.47, batch loss = 0.32 (34.8 examples/sec; 0.230 sec/batch; 21h:00m:01s remains)
INFO - root - 2017-12-17 02:59:48.375790: step 3430, loss = 0.39, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 20h:27m:39s remains)
INFO - root - 2017-12-17 02:59:50.617947: step 3440, loss = 0.37, batch loss = 0.22 (35.5 examples/sec; 0.226 sec/batch; 20h:37m:25s remains)
INFO - root - 2017-12-17 02:59:52.912740: step 3450, loss = 0.50, batch loss = 0.34 (34.4 examples/sec; 0.233 sec/batch; 21h:16m:53s remains)
INFO - root - 2017-12-17 02:59:55.208323: step 3460, loss = 0.39, batch loss = 0.23 (34.6 examples/sec; 0.231 sec/batch; 21h:06m:30s remains)
INFO - root - 2017-12-17 02:59:57.483700: step 3470, loss = 0.42, batch loss = 0.27 (35.1 examples/sec; 0.228 sec/batch; 20h:50m:51s remains)
INFO - root - 2017-12-17 02:59:59.725276: step 3480, loss = 0.42, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 20h:20m:42s remains)
INFO - root - 2017-12-17 03:00:01.976301: step 3490, loss = 0.39, batch loss = 0.24 (34.2 examples/sec; 0.234 sec/batch; 21h:22m:35s remains)
INFO - root - 2017-12-17 03:00:04.273195: step 3500, loss = 0.43, batch loss = 0.28 (34.5 examples/sec; 0.232 sec/batch; 21h:10m:13s remains)
INFO - root - 2017-12-17 03:00:06.655070: step 3510, loss = 0.41, batch loss = 0.26 (31.4 examples/sec; 0.255 sec/batch; 23h:18m:46s remains)
INFO - root - 2017-12-17 03:00:08.986623: step 3520, loss = 0.38, batch loss = 0.22 (34.4 examples/sec; 0.233 sec/batch; 21h:16m:32s remains)
INFO - root - 2017-12-17 03:00:11.267877: step 3530, loss = 0.41, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 20h:33m:17s remains)
INFO - root - 2017-12-17 03:00:13.584119: step 3540, loss = 0.48, batch loss = 0.32 (35.2 examples/sec; 0.227 sec/batch; 20h:46m:54s remains)
INFO - root - 2017-12-17 03:00:15.829322: step 3550, loss = 0.40, batch loss = 0.24 (34.7 examples/sec; 0.231 sec/batch; 21h:03m:48s remains)
INFO - root - 2017-12-17 03:00:18.098599: step 3560, loss = 0.41, batch loss = 0.26 (35.8 examples/sec; 0.223 sec/batch; 20h:25m:14s remains)
INFO - root - 2017-12-17 03:00:20.349204: step 3570, loss = 0.43, batch loss = 0.28 (36.6 examples/sec; 0.218 sec/batch; 19h:56m:44s remains)
INFO - root - 2017-12-17 03:00:22.616843: step 3580, loss = 0.44, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 20h:44m:23s remains)
INFO - root - 2017-12-17 03:00:24.902346: step 3590, loss = 0.39, batch loss = 0.24 (35.8 examples/sec; 0.223 sec/batch; 20h:24m:27s remains)
INFO - root - 2017-12-17 03:00:27.179962: step 3600, loss = 0.37, batch loss = 0.22 (35.3 examples/sec; 0.226 sec/batch; 20h:41m:35s remains)
INFO - root - 2017-12-17 03:00:29.604840: step 3610, loss = 0.40, batch loss = 0.25 (34.9 examples/sec; 0.229 sec/batch; 20h:57m:16s remains)
INFO - root - 2017-12-17 03:00:31.893156: step 3620, loss = 0.41, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 20h:23m:00s remains)
INFO - root - 2017-12-17 03:00:34.134542: step 3630, loss = 0.43, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 20h:32m:35s remains)
INFO - root - 2017-12-17 03:00:36.422619: step 3640, loss = 0.41, batch loss = 0.26 (35.7 examples/sec; 0.224 sec/batch; 20h:29m:04s remains)
INFO - root - 2017-12-17 03:00:38.693803: step 3650, loss = 0.47, batch loss = 0.32 (36.5 examples/sec; 0.219 sec/batch; 20h:01m:46s remains)
INFO - root - 2017-12-17 03:00:40.993376: step 3660, loss = 0.44, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 20h:45m:21s remains)
INFO - root - 2017-12-17 03:00:43.257932: step 3670, loss = 0.45, batch loss = 0.30 (36.3 examples/sec; 0.220 sec/batch; 20h:08m:22s remains)
INFO - root - 2017-12-17 03:00:45.562684: step 3680, loss = 0.52, batch loss = 0.37 (36.6 examples/sec; 0.219 sec/batch; 19h:58m:40s remains)
INFO - root - 2017-12-17 03:00:47.805238: step 3690, loss = 0.50, batch loss = 0.35 (35.4 examples/sec; 0.226 sec/batch; 20h:38m:13s remains)
INFO - root - 2017-12-17 03:00:50.063024: step 3700, loss = 0.43, batch loss = 0.28 (36.4 examples/sec; 0.220 sec/batch; 20h:04m:27s remains)
INFO - root - 2017-12-17 03:00:52.457139: step 3710, loss = 0.42, batch loss = 0.27 (35.6 examples/sec; 0.224 sec/batch; 20h:29m:53s remains)
INFO - root - 2017-12-17 03:00:54.712596: step 3720, loss = 0.43, batch loss = 0.28 (36.1 examples/sec; 0.221 sec/batch; 20h:13m:04s remains)
INFO - root - 2017-12-17 03:00:56.962351: step 3730, loss = 0.45, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 21h:10m:18s remains)
INFO - root - 2017-12-17 03:00:59.229352: step 3740, loss = 0.43, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 20h:29m:31s remains)
INFO - root - 2017-12-17 03:01:01.485939: step 3750, loss = 0.47, batch loss = 0.32 (36.7 examples/sec; 0.218 sec/batch; 19h:53m:54s remains)
INFO - root - 2017-12-17 03:01:03.781496: step 3760, loss = 0.40, batch loss = 0.25 (34.9 examples/sec; 0.229 sec/batch; 20h:56m:00s remains)
INFO - root - 2017-12-17 03:01:06.040719: step 3770, loss = 0.39, batch loss = 0.24 (34.6 examples/sec; 0.231 sec/batch; 21h:06m:05s remains)
INFO - root - 2017-12-17 03:01:08.309598: step 3780, loss = 0.50, batch loss = 0.35 (36.0 examples/sec; 0.222 sec/batch; 20h:18m:47s remains)
INFO - root - 2017-12-17 03:01:10.576078: step 3790, loss = 0.45, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 20h:20m:49s remains)
INFO - root - 2017-12-17 03:01:12.843326: step 3800, loss = 0.37, batch loss = 0.22 (35.2 examples/sec; 0.227 sec/batch; 20h:45m:29s remains)
INFO - root - 2017-12-17 03:01:15.235806: step 3810, loss = 0.39, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 20h:29m:03s remains)
INFO - root - 2017-12-17 03:01:17.534220: step 3820, loss = 0.39, batch loss = 0.24 (36.2 examples/sec; 0.221 sec/batch; 20h:09m:50s remains)
INFO - root - 2017-12-17 03:01:19.816436: step 3830, loss = 0.44, batch loss = 0.29 (35.3 examples/sec; 0.226 sec/batch; 20h:40m:12s remains)
INFO - root - 2017-12-17 03:01:22.063176: step 3840, loss = 0.41, batch loss = 0.26 (36.7 examples/sec; 0.218 sec/batch; 19h:55m:32s remains)
INFO - root - 2017-12-17 03:01:24.320500: step 3850, loss = 0.48, batch loss = 0.33 (35.2 examples/sec; 0.227 sec/batch; 20h:45m:36s remains)
INFO - root - 2017-12-17 03:01:26.572609: step 3860, loss = 0.54, batch loss = 0.39 (37.1 examples/sec; 0.216 sec/batch; 19h:40m:49s remains)
INFO - root - 2017-12-17 03:01:28.857642: step 3870, loss = 0.48, batch loss = 0.33 (34.7 examples/sec; 0.231 sec/batch; 21h:03m:58s remains)
INFO - root - 2017-12-17 03:01:31.092475: step 3880, loss = 0.44, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 20h:42m:42s remains)
INFO - root - 2017-12-17 03:01:33.369393: step 3890, loss = 0.48, batch loss = 0.33 (34.7 examples/sec; 0.230 sec/batch; 21h:01m:12s remains)
INFO - root - 2017-12-17 03:01:35.639536: step 3900, loss = 0.45, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 20h:14m:41s remains)
INFO - root - 2017-12-17 03:01:38.073283: step 3910, loss = 0.45, batch loss = 0.31 (33.2 examples/sec; 0.241 sec/batch; 22h:00m:02s remains)
INFO - root - 2017-12-17 03:01:40.365784: step 3920, loss = 0.43, batch loss = 0.29 (35.3 examples/sec; 0.227 sec/batch; 20h:41m:01s remains)
INFO - root - 2017-12-17 03:01:42.632237: step 3930, loss = 0.47, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 20h:53m:32s remains)
INFO - root - 2017-12-17 03:01:44.888713: step 3940, loss = 0.48, batch loss = 0.33 (35.7 examples/sec; 0.224 sec/batch; 20h:25m:30s remains)
INFO - root - 2017-12-17 03:01:47.134947: step 3950, loss = 0.44, batch loss = 0.30 (35.2 examples/sec; 0.227 sec/batch; 20h:44m:32s remains)
INFO - root - 2017-12-17 03:01:49.393023: step 3960, loss = 0.45, batch loss = 0.31 (34.5 examples/sec; 0.232 sec/batch; 21h:11m:13s remains)
INFO - root - 2017-12-17 03:01:51.655631: step 3970, loss = 0.37, batch loss = 0.23 (35.2 examples/sec; 0.227 sec/batch; 20h:42m:58s remains)
INFO - root - 2017-12-17 03:01:53.885567: step 3980, loss = 0.39, batch loss = 0.24 (36.3 examples/sec; 0.221 sec/batch; 20h:07m:21s remains)
INFO - root - 2017-12-17 03:01:56.158484: step 3990, loss = 0.39, batch loss = 0.24 (35.5 examples/sec; 0.225 sec/batch; 20h:32m:23s remains)
INFO - root - 2017-12-17 03:01:58.392089: step 4000, loss = 0.50, batch loss = 0.36 (35.0 examples/sec; 0.229 sec/batch; 20h:52m:41s remains)
INFO - root - 2017-12-17 03:02:00.771971: step 4010, loss = 0.47, batch loss = 0.32 (36.0 examples/sec; 0.222 sec/batch; 20h:17m:26s remains)
INFO - root - 2017-12-17 03:02:03.037578: step 4020, loss = 0.64, batch loss = 0.49 (36.1 examples/sec; 0.222 sec/batch; 20h:12m:47s remains)
INFO - root - 2017-12-17 03:02:05.321889: step 4030, loss = 0.45, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 20h:26m:57s remains)
INFO - root - 2017-12-17 03:02:07.589023: step 4040, loss = 0.36, batch loss = 0.21 (35.7 examples/sec; 0.224 sec/batch; 20h:26m:06s remains)
INFO - root - 2017-12-17 03:02:09.828183: step 4050, loss = 0.38, batch loss = 0.23 (36.3 examples/sec; 0.220 sec/batch; 20h:05m:02s remains)
INFO - root - 2017-12-17 03:02:12.057478: step 4060, loss = 0.41, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 20h:32m:39s remains)
INFO - root - 2017-12-17 03:02:14.293982: step 4070, loss = 0.42, batch loss = 0.28 (35.7 examples/sec; 0.224 sec/batch; 20h:28m:11s remains)
INFO - root - 2017-12-17 03:02:16.547086: step 4080, loss = 0.44, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 19h:58m:22s remains)
INFO - root - 2017-12-17 03:02:18.790549: step 4090, loss = 0.45, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 20h:22m:32s remains)
INFO - root - 2017-12-17 03:02:21.012770: step 4100, loss = 0.44, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 20h:35m:52s remains)
INFO - root - 2017-12-17 03:02:23.431377: step 4110, loss = 0.41, batch loss = 0.27 (35.6 examples/sec; 0.224 sec/batch; 20h:28m:22s remains)
INFO - root - 2017-12-17 03:02:25.677449: step 4120, loss = 0.43, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 20h:55m:11s remains)
INFO - root - 2017-12-17 03:02:27.908942: step 4130, loss = 0.39, batch loss = 0.25 (35.8 examples/sec; 0.224 sec/batch; 20h:23m:40s remains)
INFO - root - 2017-12-17 03:02:30.156068: step 4140, loss = 0.43, batch loss = 0.29 (36.5 examples/sec; 0.219 sec/batch; 19h:58m:30s remains)
INFO - root - 2017-12-17 03:02:32.380349: step 4150, loss = 0.41, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 20h:06m:51s remains)
INFO - root - 2017-12-17 03:02:34.652375: step 4160, loss = 0.35, batch loss = 0.20 (33.5 examples/sec; 0.239 sec/batch; 21h:45m:43s remains)
INFO - root - 2017-12-17 03:02:36.911171: step 4170, loss = 0.51, batch loss = 0.36 (35.9 examples/sec; 0.223 sec/batch; 20h:19m:50s remains)
INFO - root - 2017-12-17 03:02:39.152473: step 4180, loss = 0.45, batch loss = 0.31 (36.2 examples/sec; 0.221 sec/batch; 20h:09m:45s remains)
INFO - root - 2017-12-17 03:02:41.425699: step 4190, loss = 0.52, batch loss = 0.37 (33.9 examples/sec; 0.236 sec/batch; 21h:31m:41s remains)
INFO - root - 2017-12-17 03:02:43.693379: step 4200, loss = 0.46, batch loss = 0.32 (34.7 examples/sec; 0.230 sec/batch; 21h:00m:12s remains)
INFO - root - 2017-12-17 03:02:46.094668: step 4210, loss = 0.44, batch loss = 0.30 (35.8 examples/sec; 0.223 sec/batch; 20h:21m:24s remains)
INFO - root - 2017-12-17 03:02:48.366036: step 4220, loss = 0.42, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 20h:33m:02s remains)
INFO - root - 2017-12-17 03:02:50.589971: step 4230, loss = 0.40, batch loss = 0.25 (36.5 examples/sec; 0.219 sec/batch; 19h:59m:02s remains)
INFO - root - 2017-12-17 03:02:52.876201: step 4240, loss = 0.37, batch loss = 0.22 (34.7 examples/sec; 0.230 sec/batch; 20h:59m:31s remains)
INFO - root - 2017-12-17 03:02:55.134366: step 4250, loss = 0.43, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 20h:18m:35s remains)
INFO - root - 2017-12-17 03:02:57.441879: step 4260, loss = 0.39, batch loss = 0.25 (34.4 examples/sec; 0.233 sec/batch; 21h:12m:59s remains)
INFO - root - 2017-12-17 03:02:59.707077: step 4270, loss = 0.47, batch loss = 0.33 (32.9 examples/sec; 0.243 sec/batch; 22h:09m:46s remains)
INFO - root - 2017-12-17 03:03:01.971058: step 4280, loss = 0.40, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 20h:35m:52s remains)
INFO - root - 2017-12-17 03:03:04.217523: step 4290, loss = 0.45, batch loss = 0.31 (35.4 examples/sec; 0.226 sec/batch; 20h:37m:20s remains)
INFO - root - 2017-12-17 03:03:06.472853: step 4300, loss = 0.34, batch loss = 0.19 (36.1 examples/sec; 0.222 sec/batch; 20h:13m:17s remains)
INFO - root - 2017-12-17 03:03:08.831713: step 4310, loss = 0.43, batch loss = 0.29 (35.2 examples/sec; 0.228 sec/batch; 20h:44m:45s remains)
INFO - root - 2017-12-17 03:03:11.090574: step 4320, loss = 0.41, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 20h:37m:28s remains)
INFO - root - 2017-12-17 03:03:13.348221: step 4330, loss = 0.45, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 20h:17m:39s remains)
INFO - root - 2017-12-17 03:03:15.617932: step 4340, loss = 0.52, batch loss = 0.38 (36.2 examples/sec; 0.221 sec/batch; 20h:09m:08s remains)
INFO - root - 2017-12-17 03:03:17.874172: step 4350, loss = 0.42, batch loss = 0.28 (34.4 examples/sec; 0.232 sec/batch; 21h:11m:07s remains)
INFO - root - 2017-12-17 03:03:20.123049: step 4360, loss = 0.35, batch loss = 0.21 (35.2 examples/sec; 0.227 sec/batch; 20h:44m:08s remains)
INFO - root - 2017-12-17 03:03:22.356311: step 4370, loss = 0.40, batch loss = 0.26 (36.5 examples/sec; 0.219 sec/batch; 20h:00m:11s remains)
INFO - root - 2017-12-17 03:03:24.618970: step 4380, loss = 0.36, batch loss = 0.22 (35.3 examples/sec; 0.227 sec/batch; 20h:38m:49s remains)
INFO - root - 2017-12-17 03:03:26.880385: step 4390, loss = 0.40, batch loss = 0.26 (34.5 examples/sec; 0.232 sec/batch; 21h:08m:51s remains)
INFO - root - 2017-12-17 03:03:29.134907: step 4400, loss = 0.39, batch loss = 0.25 (34.8 examples/sec; 0.230 sec/batch; 20h:56m:07s remains)
INFO - root - 2017-12-17 03:03:31.503494: step 4410, loss = 0.45, batch loss = 0.31 (35.9 examples/sec; 0.223 sec/batch; 20h:17m:22s remains)
INFO - root - 2017-12-17 03:03:33.743156: step 4420, loss = 0.41, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 20h:28m:49s remains)
INFO - root - 2017-12-17 03:03:35.972710: step 4430, loss = 0.44, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 20h:12m:54s remains)
INFO - root - 2017-12-17 03:03:38.222115: step 4440, loss = 0.39, batch loss = 0.25 (35.2 examples/sec; 0.227 sec/batch; 20h:42m:54s remains)
INFO - root - 2017-12-17 03:03:40.504838: step 4450, loss = 0.36, batch loss = 0.22 (35.8 examples/sec; 0.223 sec/batch; 20h:20m:16s remains)
INFO - root - 2017-12-17 03:03:42.736145: step 4460, loss = 0.36, batch loss = 0.22 (36.4 examples/sec; 0.220 sec/batch; 20h:00m:05s remains)
INFO - root - 2017-12-17 03:03:44.978725: step 4470, loss = 0.52, batch loss = 0.38 (35.4 examples/sec; 0.226 sec/batch; 20h:35m:54s remains)
INFO - root - 2017-12-17 03:03:47.259813: step 4480, loss = 0.34, batch loss = 0.20 (34.7 examples/sec; 0.230 sec/batch; 20h:59m:21s remains)
INFO - root - 2017-12-17 03:03:49.501681: step 4490, loss = 0.38, batch loss = 0.24 (36.5 examples/sec; 0.219 sec/batch; 19h:57m:55s remains)
INFO - root - 2017-12-17 03:03:51.742510: step 4500, loss = 0.37, batch loss = 0.23 (35.6 examples/sec; 0.225 sec/batch; 20h:27m:19s remains)
INFO - root - 2017-12-17 03:03:54.139547: step 4510, loss = 0.36, batch loss = 0.22 (37.6 examples/sec; 0.213 sec/batch; 19h:23m:49s remains)
INFO - root - 2017-12-17 03:03:56.422115: step 4520, loss = 0.38, batch loss = 0.24 (35.9 examples/sec; 0.223 sec/batch; 20h:19m:16s remains)
INFO - root - 2017-12-17 03:03:58.669845: step 4530, loss = 0.33, batch loss = 0.19 (33.7 examples/sec; 0.238 sec/batch; 21h:39m:30s remains)
INFO - root - 2017-12-17 03:04:00.948482: step 4540, loss = 0.36, batch loss = 0.22 (34.3 examples/sec; 0.234 sec/batch; 21h:16m:20s remains)
INFO - root - 2017-12-17 03:04:03.225246: step 4550, loss = 0.42, batch loss = 0.28 (34.7 examples/sec; 0.231 sec/batch; 21h:01m:21s remains)
INFO - root - 2017-12-17 03:04:05.473734: step 4560, loss = 0.40, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 20h:27m:11s remains)
INFO - root - 2017-12-17 03:04:07.753225: step 4570, loss = 0.47, batch loss = 0.34 (34.5 examples/sec; 0.232 sec/batch; 21h:08m:10s remains)
INFO - root - 2017-12-17 03:04:10.019876: step 4580, loss = 0.43, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 20h:51m:31s remains)
INFO - root - 2017-12-17 03:04:12.268401: step 4590, loss = 0.47, batch loss = 0.33 (34.8 examples/sec; 0.230 sec/batch; 20h:55m:47s remains)
INFO - root - 2017-12-17 03:04:14.563538: step 4600, loss = 0.44, batch loss = 0.30 (32.0 examples/sec; 0.250 sec/batch; 22h:44m:19s remains)
INFO - root - 2017-12-17 03:04:16.967114: step 4610, loss = 0.43, batch loss = 0.29 (36.1 examples/sec; 0.221 sec/batch; 20h:09m:48s remains)
INFO - root - 2017-12-17 03:04:19.234416: step 4620, loss = 0.44, batch loss = 0.30 (35.7 examples/sec; 0.224 sec/batch; 20h:24m:39s remains)
INFO - root - 2017-12-17 03:04:21.494890: step 4630, loss = 0.51, batch loss = 0.37 (35.0 examples/sec; 0.229 sec/batch; 20h:49m:23s remains)
INFO - root - 2017-12-17 03:04:23.757283: step 4640, loss = 0.37, batch loss = 0.24 (36.0 examples/sec; 0.222 sec/batch; 20h:15m:02s remains)
INFO - root - 2017-12-17 03:04:26.000006: step 4650, loss = 0.41, batch loss = 0.27 (35.8 examples/sec; 0.223 sec/batch; 20h:20m:23s remains)
INFO - root - 2017-12-17 03:04:28.281646: step 4660, loss = 0.43, batch loss = 0.30 (36.0 examples/sec; 0.222 sec/batch; 20h:12m:34s remains)
INFO - root - 2017-12-17 03:04:30.526799: step 4670, loss = 0.36, batch loss = 0.22 (34.0 examples/sec; 0.235 sec/batch; 21h:23m:48s remains)
INFO - root - 2017-12-17 03:04:32.770225: step 4680, loss = 0.58, batch loss = 0.45 (35.7 examples/sec; 0.224 sec/batch; 20h:24m:21s remains)
INFO - root - 2017-12-17 03:04:35.023876: step 4690, loss = 0.47, batch loss = 0.33 (33.6 examples/sec; 0.238 sec/batch; 21h:39m:30s remains)
INFO - root - 2017-12-17 03:04:37.262661: step 4700, loss = 0.36, batch loss = 0.22 (34.7 examples/sec; 0.231 sec/batch; 21h:00m:41s remains)
INFO - root - 2017-12-17 03:04:39.642749: step 4710, loss = 0.41, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 20h:42m:18s remains)
INFO - root - 2017-12-17 03:04:41.895098: step 4720, loss = 0.33, batch loss = 0.19 (36.0 examples/sec; 0.222 sec/batch; 20h:13m:49s remains)
INFO - root - 2017-12-17 03:04:44.135063: step 4730, loss = 0.51, batch loss = 0.37 (35.3 examples/sec; 0.227 sec/batch; 20h:37m:49s remains)
INFO - root - 2017-12-17 03:04:46.369642: step 4740, loss = 0.33, batch loss = 0.20 (34.9 examples/sec; 0.229 sec/batch; 20h:53m:33s remains)
INFO - root - 2017-12-17 03:04:48.658240: step 4750, loss = 0.44, batch loss = 0.31 (35.7 examples/sec; 0.224 sec/batch; 20h:24m:55s remains)
INFO - root - 2017-12-17 03:04:50.909914: step 4760, loss = 0.40, batch loss = 0.27 (35.8 examples/sec; 0.224 sec/batch; 20h:21m:17s remains)
INFO - root - 2017-12-17 03:04:53.174161: step 4770, loss = 0.37, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 20h:22m:59s remains)
INFO - root - 2017-12-17 03:04:55.458111: step 4780, loss = 0.54, batch loss = 0.41 (34.7 examples/sec; 0.231 sec/batch; 21h:00m:34s remains)
INFO - root - 2017-12-17 03:04:57.726514: step 4790, loss = 0.42, batch loss = 0.28 (35.4 examples/sec; 0.226 sec/batch; 20h:34m:04s remains)
INFO - root - 2017-12-17 03:04:59.987058: step 4800, loss = 0.43, batch loss = 0.30 (34.2 examples/sec; 0.234 sec/batch; 21h:15m:43s remains)
INFO - root - 2017-12-17 03:05:02.383550: step 4810, loss = 0.36, batch loss = 0.23 (34.4 examples/sec; 0.233 sec/batch; 21h:11m:33s remains)
INFO - root - 2017-12-17 03:05:04.638304: step 4820, loss = 0.37, batch loss = 0.24 (34.7 examples/sec; 0.231 sec/batch; 21h:00m:15s remains)
INFO - root - 2017-12-17 03:05:06.942680: step 4830, loss = 0.37, batch loss = 0.23 (36.3 examples/sec; 0.220 sec/batch; 20h:02m:01s remains)
INFO - root - 2017-12-17 03:05:09.188518: step 4840, loss = 0.43, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 20h:46m:46s remains)
INFO - root - 2017-12-17 03:05:11.465392: step 4850, loss = 0.44, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 20h:35m:40s remains)
INFO - root - 2017-12-17 03:05:13.736337: step 4860, loss = 0.43, batch loss = 0.30 (33.8 examples/sec; 0.237 sec/batch; 21h:31m:34s remains)
INFO - root - 2017-12-17 03:05:15.998058: step 4870, loss = 0.44, batch loss = 0.31 (34.1 examples/sec; 0.235 sec/batch; 21h:20m:58s remains)
INFO - root - 2017-12-17 03:05:18.249845: step 4880, loss = 0.36, batch loss = 0.23 (36.0 examples/sec; 0.222 sec/batch; 20h:12m:27s remains)
INFO - root - 2017-12-17 03:05:20.501832: step 4890, loss = 0.43, batch loss = 0.30 (34.8 examples/sec; 0.230 sec/batch; 20h:53m:47s remains)
INFO - root - 2017-12-17 03:05:22.751291: step 4900, loss = 0.42, batch loss = 0.28 (34.5 examples/sec; 0.232 sec/batch; 21h:06m:21s remains)
INFO - root - 2017-12-17 03:05:25.226758: step 4910, loss = 0.47, batch loss = 0.34 (33.4 examples/sec; 0.240 sec/batch; 21h:49m:04s remains)
INFO - root - 2017-12-17 03:05:27.517565: step 4920, loss = 0.44, batch loss = 0.31 (34.7 examples/sec; 0.231 sec/batch; 20h:59m:07s remains)
INFO - root - 2017-12-17 03:05:29.794902: step 4930, loss = 0.35, batch loss = 0.21 (36.3 examples/sec; 0.220 sec/batch; 20h:02m:39s remains)
INFO - root - 2017-12-17 03:05:32.044799: step 4940, loss = 0.37, batch loss = 0.23 (35.1 examples/sec; 0.228 sec/batch; 20h:43m:08s remains)
INFO - root - 2017-12-17 03:05:34.335997: step 4950, loss = 0.38, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 20h:33m:38s remains)
INFO - root - 2017-12-17 03:05:36.622072: step 4960, loss = 0.36, batch loss = 0.22 (33.4 examples/sec; 0.239 sec/batch; 21h:46m:06s remains)
INFO - root - 2017-12-17 03:05:38.927339: step 4970, loss = 0.45, batch loss = 0.32 (34.6 examples/sec; 0.231 sec/batch; 21h:00m:46s remains)
INFO - root - 2017-12-17 03:05:41.196892: step 4980, loss = 0.42, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 20h:43m:35s remains)
INFO - root - 2017-12-17 03:05:43.448844: step 4990, loss = 0.37, batch loss = 0.23 (35.9 examples/sec; 0.223 sec/batch; 20h:15m:09s remains)
INFO - root - 2017-12-17 03:05:45.697155: step 5000, loss = 0.40, batch loss = 0.26 (35.5 examples/sec; 0.225 sec/batch; 20h:29m:54s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-5000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-5000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 03:05:48.798580: step 5010, loss = 0.45, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 20h:14m:57s remains)
INFO - root - 2017-12-17 03:05:51.072029: step 5020, loss = 0.44, batch loss = 0.30 (35.1 examples/sec; 0.228 sec/batch; 20h:43m:39s remains)
INFO - root - 2017-12-17 03:05:53.330718: step 5030, loss = 0.40, batch loss = 0.27 (34.0 examples/sec; 0.235 sec/batch; 21h:25m:13s remains)
INFO - root - 2017-12-17 03:05:55.576859: step 5040, loss = 0.41, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 20h:40m:08s remains)
INFO - root - 2017-12-17 03:05:57.828241: step 5050, loss = 0.39, batch loss = 0.26 (34.7 examples/sec; 0.230 sec/batch; 20h:56m:31s remains)
INFO - root - 2017-12-17 03:06:00.067055: step 5060, loss = 0.36, batch loss = 0.23 (36.2 examples/sec; 0.221 sec/batch; 20h:06m:54s remains)
INFO - root - 2017-12-17 03:06:02.319038: step 5070, loss = 0.43, batch loss = 0.30 (35.4 examples/sec; 0.226 sec/batch; 20h:33m:15s remains)
INFO - root - 2017-12-17 03:06:04.570351: step 5080, loss = 0.37, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 20h:23m:09s remains)
INFO - root - 2017-12-17 03:06:06.853115: step 5090, loss = 0.34, batch loss = 0.21 (34.2 examples/sec; 0.234 sec/batch; 21h:17m:00s remains)
INFO - root - 2017-12-17 03:06:09.135450: step 5100, loss = 0.41, batch loss = 0.28 (34.3 examples/sec; 0.233 sec/batch; 21h:11m:58s remains)
INFO - root - 2017-12-17 03:06:11.529856: step 5110, loss = 0.64, batch loss = 0.51 (35.2 examples/sec; 0.227 sec/batch; 20h:39m:41s remains)
INFO - root - 2017-12-17 03:06:13.771965: step 5120, loss = 0.36, batch loss = 0.23 (36.0 examples/sec; 0.222 sec/batch; 20h:12m:22s remains)
INFO - root - 2017-12-17 03:06:16.060572: step 5130, loss = 0.37, batch loss = 0.24 (35.2 examples/sec; 0.227 sec/batch; 20h:39m:49s remains)
INFO - root - 2017-12-17 03:06:18.321178: step 5140, loss = 0.39, batch loss = 0.26 (34.8 examples/sec; 0.230 sec/batch; 20h:52m:29s remains)
INFO - root - 2017-12-17 03:06:20.563995: step 5150, loss = 0.41, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 20h:11m:04s remains)
INFO - root - 2017-12-17 03:06:22.813616: step 5160, loss = 0.40, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 20h:26m:27s remains)
INFO - root - 2017-12-17 03:06:25.047906: step 5170, loss = 0.39, batch loss = 0.26 (36.2 examples/sec; 0.221 sec/batch; 20h:07m:06s remains)
INFO - root - 2017-12-17 03:06:27.329611: step 5180, loss = 0.38, batch loss = 0.25 (34.1 examples/sec; 0.235 sec/batch; 21h:19m:30s remains)
INFO - root - 2017-12-17 03:06:29.575936: step 5190, loss = 0.33, batch loss = 0.20 (35.9 examples/sec; 0.223 sec/batch; 20h:15m:15s remains)
INFO - root - 2017-12-17 03:06:31.837228: step 5200, loss = 0.48, batch loss = 0.35 (35.3 examples/sec; 0.227 sec/batch; 20h:35m:36s remains)
INFO - root - 2017-12-17 03:06:34.226060: step 5210, loss = 0.33, batch loss = 0.20 (34.6 examples/sec; 0.231 sec/batch; 21h:00m:58s remains)
INFO - root - 2017-12-17 03:06:36.509817: step 5220, loss = 0.35, batch loss = 0.22 (35.1 examples/sec; 0.228 sec/batch; 20h:44m:18s remains)
INFO - root - 2017-12-17 03:06:38.821319: step 5230, loss = 0.36, batch loss = 0.23 (36.5 examples/sec; 0.219 sec/batch; 19h:56m:34s remains)
INFO - root - 2017-12-17 03:06:41.068791: step 5240, loss = 0.35, batch loss = 0.22 (36.5 examples/sec; 0.219 sec/batch; 19h:55m:13s remains)
INFO - root - 2017-12-17 03:06:43.336076: step 5250, loss = 0.42, batch loss = 0.29 (35.0 examples/sec; 0.229 sec/batch; 20h:46m:19s remains)
INFO - root - 2017-12-17 03:06:45.586380: step 5260, loss = 0.36, batch loss = 0.24 (34.5 examples/sec; 0.232 sec/batch; 21h:05m:42s remains)
INFO - root - 2017-12-17 03:06:47.862560: step 5270, loss = 0.41, batch loss = 0.28 (34.2 examples/sec; 0.234 sec/batch; 21h:17m:30s remains)
INFO - root - 2017-12-17 03:06:50.125773: step 5280, loss = 0.36, batch loss = 0.23 (36.2 examples/sec; 0.221 sec/batch; 20h:04m:11s remains)
INFO - root - 2017-12-17 03:06:52.400507: step 5290, loss = 0.34, batch loss = 0.21 (35.3 examples/sec; 0.227 sec/batch; 20h:35m:15s remains)
INFO - root - 2017-12-17 03:06:54.693668: step 5300, loss = 0.34, batch loss = 0.21 (36.6 examples/sec; 0.218 sec/batch; 19h:50m:25s remains)
INFO - root - 2017-12-17 03:06:57.086981: step 5310, loss = 0.30, batch loss = 0.17 (34.6 examples/sec; 0.231 sec/batch; 20h:59m:53s remains)
INFO - root - 2017-12-17 03:06:59.359241: step 5320, loss = 0.38, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 20h:33m:20s remains)
INFO - root - 2017-12-17 03:07:01.653846: step 5330, loss = 0.34, batch loss = 0.21 (34.1 examples/sec; 0.235 sec/batch; 21h:19m:29s remains)
INFO - root - 2017-12-17 03:07:03.934329: step 5340, loss = 0.43, batch loss = 0.30 (33.6 examples/sec; 0.238 sec/batch; 21h:37m:36s remains)
INFO - root - 2017-12-17 03:07:06.190385: step 5350, loss = 0.33, batch loss = 0.20 (35.2 examples/sec; 0.227 sec/batch; 20h:39m:43s remains)
INFO - root - 2017-12-17 03:07:08.462639: step 5360, loss = 0.36, batch loss = 0.23 (34.3 examples/sec; 0.233 sec/batch; 21h:10m:52s remains)
INFO - root - 2017-12-17 03:07:10.709959: step 5370, loss = 0.31, batch loss = 0.18 (36.2 examples/sec; 0.221 sec/batch; 20h:06m:30s remains)
INFO - root - 2017-12-17 03:07:12.996843: step 5380, loss = 0.32, batch loss = 0.20 (36.4 examples/sec; 0.220 sec/batch; 19h:58m:24s remains)
INFO - root - 2017-12-17 03:07:15.265924: step 5390, loss = 0.38, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 20h:32m:22s remains)
INFO - root - 2017-12-17 03:07:17.522013: step 5400, loss = 0.33, batch loss = 0.21 (34.8 examples/sec; 0.230 sec/batch; 20h:52m:26s remains)
INFO - root - 2017-12-17 03:07:19.899316: step 5410, loss = 0.36, batch loss = 0.24 (35.9 examples/sec; 0.223 sec/batch; 20h:14m:06s remains)
INFO - root - 2017-12-17 03:07:22.143457: step 5420, loss = 0.36, batch loss = 0.23 (36.2 examples/sec; 0.221 sec/batch; 20h:05m:11s remains)
INFO - root - 2017-12-17 03:07:24.412166: step 5430, loss = 0.36, batch loss = 0.24 (35.5 examples/sec; 0.225 sec/batch; 20h:28m:52s remains)
INFO - root - 2017-12-17 03:07:26.677862: step 5440, loss = 0.44, batch loss = 0.32 (35.9 examples/sec; 0.223 sec/batch; 20h:15m:59s remains)
INFO - root - 2017-12-17 03:07:28.936371: step 5450, loss = 0.35, batch loss = 0.22 (36.1 examples/sec; 0.222 sec/batch; 20h:08m:01s remains)
INFO - root - 2017-12-17 03:07:31.178534: step 5460, loss = 0.39, batch loss = 0.26 (35.0 examples/sec; 0.229 sec/batch; 20h:45m:45s remains)
INFO - root - 2017-12-17 03:07:33.419439: step 5470, loss = 0.39, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 20h:25m:37s remains)
INFO - root - 2017-12-17 03:07:35.678733: step 5480, loss = 0.42, batch loss = 0.29 (36.3 examples/sec; 0.221 sec/batch; 20h:01m:58s remains)
INFO - root - 2017-12-17 03:07:37.980759: step 5490, loss = 0.39, batch loss = 0.26 (32.3 examples/sec; 0.248 sec/batch; 22h:30m:38s remains)
INFO - root - 2017-12-17 03:07:40.270114: step 5500, loss = 0.38, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 20h:42m:30s remains)
INFO - root - 2017-12-17 03:07:42.638643: step 5510, loss = 0.42, batch loss = 0.29 (36.4 examples/sec; 0.220 sec/batch; 19h:56m:26s remains)
INFO - root - 2017-12-17 03:07:44.893138: step 5520, loss = 0.40, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 20h:23m:58s remains)
INFO - root - 2017-12-17 03:07:47.150313: step 5530, loss = 0.48, batch loss = 0.36 (34.4 examples/sec; 0.233 sec/batch; 21h:07m:48s remains)
INFO - root - 2017-12-17 03:07:49.408121: step 5540, loss = 0.53, batch loss = 0.40 (36.4 examples/sec; 0.220 sec/batch; 19h:58m:19s remains)
INFO - root - 2017-12-17 03:07:51.669282: step 5550, loss = 0.45, batch loss = 0.32 (35.8 examples/sec; 0.223 sec/batch; 20h:16m:04s remains)
INFO - root - 2017-12-17 03:07:53.919505: step 5560, loss = 0.38, batch loss = 0.25 (34.4 examples/sec; 0.233 sec/batch; 21h:06m:59s remains)
INFO - root - 2017-12-17 03:07:56.182869: step 5570, loss = 0.40, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 20h:30m:44s remains)
INFO - root - 2017-12-17 03:07:58.432041: step 5580, loss = 0.40, batch loss = 0.27 (35.4 examples/sec; 0.226 sec/batch; 20h:30m:03s remains)
INFO - root - 2017-12-17 03:08:00.666170: step 5590, loss = 0.35, batch loss = 0.23 (35.3 examples/sec; 0.227 sec/batch; 20h:35m:42s remains)
INFO - root - 2017-12-17 03:08:02.923485: step 5600, loss = 0.38, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 19h:50m:29s remains)
INFO - root - 2017-12-17 03:08:05.344677: step 5610, loss = 0.39, batch loss = 0.27 (35.5 examples/sec; 0.225 sec/batch; 20h:26m:46s remains)
INFO - root - 2017-12-17 03:08:07.606896: step 5620, loss = 0.39, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 20h:15m:33s remains)
INFO - root - 2017-12-17 03:08:09.882668: step 5630, loss = 0.35, batch loss = 0.23 (36.1 examples/sec; 0.221 sec/batch; 20h:06m:15s remains)
INFO - root - 2017-12-17 03:08:12.130347: step 5640, loss = 0.36, batch loss = 0.23 (35.6 examples/sec; 0.225 sec/batch; 20h:23m:00s remains)
INFO - root - 2017-12-17 03:08:14.390260: step 5650, loss = 0.32, batch loss = 0.20 (34.9 examples/sec; 0.229 sec/batch; 20h:47m:35s remains)
INFO - root - 2017-12-17 03:08:16.656422: step 5660, loss = 0.35, batch loss = 0.23 (36.3 examples/sec; 0.221 sec/batch; 20h:01m:28s remains)
INFO - root - 2017-12-17 03:08:18.974072: step 5670, loss = 0.36, batch loss = 0.23 (33.3 examples/sec; 0.240 sec/batch; 21h:47m:33s remains)
INFO - root - 2017-12-17 03:08:21.235381: step 5680, loss = 0.44, batch loss = 0.32 (34.9 examples/sec; 0.229 sec/batch; 20h:49m:22s remains)
INFO - root - 2017-12-17 03:08:23.524556: step 5690, loss = 0.32, batch loss = 0.19 (35.9 examples/sec; 0.223 sec/batch; 20h:15m:13s remains)
INFO - root - 2017-12-17 03:08:25.794713: step 5700, loss = 0.40, batch loss = 0.27 (35.6 examples/sec; 0.225 sec/batch; 20h:24m:40s remains)
INFO - root - 2017-12-17 03:08:28.170022: step 5710, loss = 0.42, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 20h:42m:58s remains)
INFO - root - 2017-12-17 03:08:30.440821: step 5720, loss = 0.40, batch loss = 0.28 (36.2 examples/sec; 0.221 sec/batch; 20h:03m:59s remains)
INFO - root - 2017-12-17 03:08:32.689635: step 5730, loss = 0.36, batch loss = 0.23 (33.4 examples/sec; 0.240 sec/batch; 21h:44m:28s remains)
INFO - root - 2017-12-17 03:08:34.973376: step 5740, loss = 0.42, batch loss = 0.29 (35.2 examples/sec; 0.227 sec/batch; 20h:36m:20s remains)
INFO - root - 2017-12-17 03:08:37.265475: step 5750, loss = 0.56, batch loss = 0.43 (34.3 examples/sec; 0.233 sec/batch; 21h:10m:05s remains)
INFO - root - 2017-12-17 03:08:39.577403: step 5760, loss = 0.34, batch loss = 0.22 (35.6 examples/sec; 0.225 sec/batch; 20h:24m:46s remains)
INFO - root - 2017-12-17 03:08:41.824748: step 5770, loss = 0.37, batch loss = 0.25 (35.0 examples/sec; 0.229 sec/batch; 20h:45m:39s remains)
INFO - root - 2017-12-17 03:08:44.072477: step 5780, loss = 0.40, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 20h:09m:49s remains)
INFO - root - 2017-12-17 03:08:46.320328: step 5790, loss = 0.31, batch loss = 0.19 (36.0 examples/sec; 0.222 sec/batch; 20h:10m:16s remains)
INFO - root - 2017-12-17 03:08:48.609039: step 5800, loss = 0.37, batch loss = 0.24 (35.3 examples/sec; 0.226 sec/batch; 20h:32m:41s remains)
INFO - root - 2017-12-17 03:08:51.001485: step 5810, loss = 0.36, batch loss = 0.24 (35.8 examples/sec; 0.223 sec/batch; 20h:16m:08s remains)
INFO - root - 2017-12-17 03:08:53.257596: step 5820, loss = 0.41, batch loss = 0.29 (34.9 examples/sec; 0.229 sec/batch; 20h:49m:02s remains)
INFO - root - 2017-12-17 03:08:55.569257: step 5830, loss = 0.49, batch loss = 0.37 (35.6 examples/sec; 0.224 sec/batch; 20h:22m:14s remains)
INFO - root - 2017-12-17 03:08:57.805379: step 5840, loss = 0.32, batch loss = 0.20 (35.4 examples/sec; 0.226 sec/batch; 20h:31m:12s remains)
INFO - root - 2017-12-17 03:09:00.040058: step 5850, loss = 0.42, batch loss = 0.30 (35.6 examples/sec; 0.225 sec/batch; 20h:24m:02s remains)
INFO - root - 2017-12-17 03:09:02.322054: step 5860, loss = 0.32, batch loss = 0.20 (36.0 examples/sec; 0.222 sec/batch; 20h:09m:10s remains)
INFO - root - 2017-12-17 03:09:04.600108: step 5870, loss = 0.43, batch loss = 0.31 (34.5 examples/sec; 0.232 sec/batch; 21h:04m:03s remains)
INFO - root - 2017-12-17 03:09:06.886962: step 5880, loss = 0.34, batch loss = 0.21 (34.4 examples/sec; 0.232 sec/batch; 21h:04m:36s remains)
INFO - root - 2017-12-17 03:09:09.221577: step 5890, loss = 0.35, batch loss = 0.23 (35.5 examples/sec; 0.225 sec/batch; 20h:25m:48s remains)
INFO - root - 2017-12-17 03:09:11.482367: step 5900, loss = 0.32, batch loss = 0.20 (36.9 examples/sec; 0.217 sec/batch; 19h:38m:37s remains)
INFO - root - 2017-12-17 03:09:13.874234: step 5910, loss = 0.31, batch loss = 0.19 (35.6 examples/sec; 0.225 sec/batch; 20h:24m:07s remains)
INFO - root - 2017-12-17 03:09:16.097497: step 5920, loss = 0.40, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 20h:15m:00s remains)
INFO - root - 2017-12-17 03:09:18.378302: step 5930, loss = 0.32, batch loss = 0.20 (35.0 examples/sec; 0.229 sec/batch; 20h:44m:54s remains)
INFO - root - 2017-12-17 03:09:20.648368: step 5940, loss = 0.38, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 20h:16m:56s remains)
INFO - root - 2017-12-17 03:09:22.885047: step 5950, loss = 0.40, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 20h:39m:23s remains)
INFO - root - 2017-12-17 03:09:25.176363: step 5960, loss = 0.37, batch loss = 0.25 (36.6 examples/sec; 0.219 sec/batch; 19h:49m:27s remains)
INFO - root - 2017-12-17 03:09:27.442715: step 5970, loss = 0.36, batch loss = 0.24 (35.6 examples/sec; 0.225 sec/batch; 20h:22m:31s remains)
INFO - root - 2017-12-17 03:09:29.687374: step 5980, loss = 0.40, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 20h:45m:07s remains)
INFO - root - 2017-12-17 03:09:31.978608: step 5990, loss = 0.39, batch loss = 0.27 (33.1 examples/sec; 0.242 sec/batch; 21h:54m:45s remains)
INFO - root - 2017-12-17 03:09:34.245268: step 6000, loss = 0.37, batch loss = 0.25 (35.2 examples/sec; 0.227 sec/batch; 20h:37m:05s remains)
INFO - root - 2017-12-17 03:09:36.624703: step 6010, loss = 0.42, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 20h:12m:37s remains)
INFO - root - 2017-12-17 03:09:38.865517: step 6020, loss = 0.32, batch loss = 0.20 (36.2 examples/sec; 0.221 sec/batch; 20h:03m:24s remains)
INFO - root - 2017-12-17 03:09:41.116981: step 6030, loss = 0.38, batch loss = 0.26 (36.3 examples/sec; 0.221 sec/batch; 20h:00m:25s remains)
INFO - root - 2017-12-17 03:09:43.366275: step 6040, loss = 0.32, batch loss = 0.20 (36.4 examples/sec; 0.220 sec/batch; 19h:54m:29s remains)
INFO - root - 2017-12-17 03:09:45.655976: step 6050, loss = 0.32, batch loss = 0.20 (34.1 examples/sec; 0.235 sec/batch; 21h:15m:56s remains)
INFO - root - 2017-12-17 03:09:47.937537: step 6060, loss = 0.36, batch loss = 0.24 (33.7 examples/sec; 0.237 sec/batch; 21h:31m:48s remains)
INFO - root - 2017-12-17 03:09:50.178930: step 6070, loss = 0.37, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 20h:17m:26s remains)
INFO - root - 2017-12-17 03:09:52.436269: step 6080, loss = 0.36, batch loss = 0.24 (36.4 examples/sec; 0.220 sec/batch; 19h:54m:14s remains)
INFO - root - 2017-12-17 03:09:54.728446: step 6090, loss = 0.37, batch loss = 0.25 (34.8 examples/sec; 0.230 sec/batch; 20h:51m:57s remains)
INFO - root - 2017-12-17 03:09:56.999665: step 6100, loss = 0.32, batch loss = 0.20 (35.8 examples/sec; 0.224 sec/batch; 20h:16m:21s remains)
INFO - root - 2017-12-17 03:09:59.357665: step 6110, loss = 0.31, batch loss = 0.19 (36.0 examples/sec; 0.222 sec/batch; 20h:08m:10s remains)
INFO - root - 2017-12-17 03:10:01.660913: step 6120, loss = 0.29, batch loss = 0.17 (34.9 examples/sec; 0.229 sec/batch; 20h:47m:56s remains)
INFO - root - 2017-12-17 03:10:03.957653: step 6130, loss = 0.41, batch loss = 0.29 (34.3 examples/sec; 0.233 sec/batch; 21h:07m:06s remains)
INFO - root - 2017-12-17 03:10:06.249554: step 6140, loss = 0.34, batch loss = 0.22 (35.6 examples/sec; 0.225 sec/batch; 20h:23m:09s remains)
INFO - root - 2017-12-17 03:10:08.513344: step 6150, loss = 0.32, batch loss = 0.20 (33.7 examples/sec; 0.238 sec/batch; 21h:32m:54s remains)
INFO - root - 2017-12-17 03:10:10.800161: step 6160, loss = 0.35, batch loss = 0.23 (35.8 examples/sec; 0.224 sec/batch; 20h:16m:07s remains)
INFO - root - 2017-12-17 03:10:13.052734: step 6170, loss = 0.40, batch loss = 0.28 (35.5 examples/sec; 0.225 sec/batch; 20h:24m:13s remains)
INFO - root - 2017-12-17 03:10:15.291054: step 6180, loss = 0.38, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 19h:53m:56s remains)
INFO - root - 2017-12-17 03:10:17.570511: step 6190, loss = 0.35, batch loss = 0.23 (35.0 examples/sec; 0.229 sec/batch; 20h:44m:34s remains)
INFO - root - 2017-12-17 03:10:19.857334: step 6200, loss = 0.32, batch loss = 0.20 (35.3 examples/sec; 0.226 sec/batch; 20h:31m:34s remains)
INFO - root - 2017-12-17 03:10:22.246688: step 6210, loss = 0.34, batch loss = 0.22 (35.2 examples/sec; 0.227 sec/batch; 20h:36m:45s remains)
INFO - root - 2017-12-17 03:10:24.524628: step 6220, loss = 0.34, batch loss = 0.22 (36.3 examples/sec; 0.220 sec/batch; 19h:58m:06s remains)
INFO - root - 2017-12-17 03:10:26.824658: step 6230, loss = 0.32, batch loss = 0.20 (35.5 examples/sec; 0.225 sec/batch; 20h:25m:08s remains)
INFO - root - 2017-12-17 03:10:29.102949: step 6240, loss = 0.39, batch loss = 0.27 (36.0 examples/sec; 0.222 sec/batch; 20h:06m:46s remains)
INFO - root - 2017-12-17 03:10:31.366445: step 6250, loss = 0.36, batch loss = 0.24 (37.0 examples/sec; 0.216 sec/batch; 19h:35m:35s remains)
INFO - root - 2017-12-17 03:10:33.644651: step 6260, loss = 0.31, batch loss = 0.19 (34.2 examples/sec; 0.234 sec/batch; 21h:11m:12s remains)
INFO - root - 2017-12-17 03:10:35.907980: step 6270, loss = 0.39, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 20h:32m:42s remains)
INFO - root - 2017-12-17 03:10:38.218961: step 6280, loss = 0.38, batch loss = 0.27 (33.9 examples/sec; 0.236 sec/batch; 21h:24m:55s remains)
INFO - root - 2017-12-17 03:10:40.464188: step 6290, loss = 0.48, batch loss = 0.36 (34.6 examples/sec; 0.231 sec/batch; 20h:58m:31s remains)
INFO - root - 2017-12-17 03:10:42.700603: step 6300, loss = 0.42, batch loss = 0.30 (35.0 examples/sec; 0.228 sec/batch; 20h:42m:02s remains)
INFO - root - 2017-12-17 03:10:45.094329: step 6310, loss = 0.42, batch loss = 0.31 (35.1 examples/sec; 0.228 sec/batch; 20h:38m:31s remains)
INFO - root - 2017-12-17 03:10:47.376279: step 6320, loss = 0.54, batch loss = 0.42 (33.0 examples/sec; 0.242 sec/batch; 21h:56m:32s remains)
INFO - root - 2017-12-17 03:10:49.654662: step 6330, loss = 0.41, batch loss = 0.29 (35.1 examples/sec; 0.228 sec/batch; 20h:39m:07s remains)
INFO - root - 2017-12-17 03:10:51.884735: step 6340, loss = 0.38, batch loss = 0.26 (35.3 examples/sec; 0.226 sec/batch; 20h:31m:10s remains)
INFO - root - 2017-12-17 03:10:54.152890: step 6350, loss = 0.35, batch loss = 0.24 (35.1 examples/sec; 0.228 sec/batch; 20h:38m:00s remains)
INFO - root - 2017-12-17 03:10:56.419288: step 6360, loss = 0.35, batch loss = 0.24 (36.4 examples/sec; 0.220 sec/batch; 19h:56m:05s remains)
INFO - root - 2017-12-17 03:10:58.682014: step 6370, loss = 0.34, batch loss = 0.23 (36.7 examples/sec; 0.218 sec/batch; 19h:44m:29s remains)
INFO - root - 2017-12-17 03:11:00.967840: step 6380, loss = 0.41, batch loss = 0.30 (34.7 examples/sec; 0.230 sec/batch; 20h:52m:46s remains)
INFO - root - 2017-12-17 03:11:03.245325: step 6390, loss = 0.43, batch loss = 0.31 (34.7 examples/sec; 0.230 sec/batch; 20h:51m:19s remains)
INFO - root - 2017-12-17 03:11:05.518056: step 6400, loss = 0.42, batch loss = 0.31 (35.3 examples/sec; 0.227 sec/batch; 20h:31m:08s remains)
INFO - root - 2017-12-17 03:11:07.931831: step 6410, loss = 0.32, batch loss = 0.20 (35.2 examples/sec; 0.227 sec/batch; 20h:34m:59s remains)
INFO - root - 2017-12-17 03:11:10.205031: step 6420, loss = 0.30, batch loss = 0.18 (35.2 examples/sec; 0.227 sec/batch; 20h:34m:43s remains)
INFO - root - 2017-12-17 03:11:12.453964: step 6430, loss = 0.34, batch loss = 0.22 (34.9 examples/sec; 0.229 sec/batch; 20h:45m:52s remains)
INFO - root - 2017-12-17 03:11:14.707740: step 6440, loss = 0.33, batch loss = 0.22 (34.7 examples/sec; 0.230 sec/batch; 20h:51m:40s remains)
INFO - root - 2017-12-17 03:11:16.971107: step 6450, loss = 0.38, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 20h:34m:05s remains)
INFO - root - 2017-12-17 03:11:19.215684: step 6460, loss = 0.30, batch loss = 0.19 (36.6 examples/sec; 0.218 sec/batch; 19h:46m:54s remains)
INFO - root - 2017-12-17 03:11:21.488016: step 6470, loss = 0.36, batch loss = 0.24 (32.4 examples/sec; 0.247 sec/batch; 22h:23m:12s remains)
INFO - root - 2017-12-17 03:11:23.745753: step 6480, loss = 0.42, batch loss = 0.30 (35.9 examples/sec; 0.223 sec/batch; 20h:10m:32s remains)
INFO - root - 2017-12-17 03:11:26.004652: step 6490, loss = 0.33, batch loss = 0.22 (36.7 examples/sec; 0.218 sec/batch; 19h:45m:47s remains)
INFO - root - 2017-12-17 03:11:28.288733: step 6500, loss = 0.39, batch loss = 0.28 (32.5 examples/sec; 0.246 sec/batch; 22h:18m:50s remains)
INFO - root - 2017-12-17 03:11:30.681759: step 6510, loss = 0.32, batch loss = 0.20 (35.1 examples/sec; 0.228 sec/batch; 20h:36m:36s remains)
INFO - root - 2017-12-17 03:11:32.936164: step 6520, loss = 0.38, batch loss = 0.26 (35.4 examples/sec; 0.226 sec/batch; 20h:27m:18s remains)
INFO - root - 2017-12-17 03:11:35.172988: step 6530, loss = 0.32, batch loss = 0.20 (36.0 examples/sec; 0.222 sec/batch; 20h:08m:14s remains)
INFO - root - 2017-12-17 03:11:37.465911: step 6540, loss = 0.38, batch loss = 0.26 (32.9 examples/sec; 0.243 sec/batch; 21h:59m:09s remains)
INFO - root - 2017-12-17 03:11:39.755590: step 6550, loss = 0.33, batch loss = 0.21 (34.7 examples/sec; 0.231 sec/batch; 20h:53m:30s remains)
INFO - root - 2017-12-17 03:11:41.995811: step 6560, loss = 0.36, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 20h:24m:06s remains)
INFO - root - 2017-12-17 03:11:44.266919: step 6570, loss = 0.31, batch loss = 0.19 (36.1 examples/sec; 0.221 sec/batch; 20h:03m:10s remains)
INFO - root - 2017-12-17 03:11:46.530266: step 6580, loss = 0.36, batch loss = 0.24 (35.4 examples/sec; 0.226 sec/batch; 20h:26m:51s remains)
INFO - root - 2017-12-17 03:11:48.783320: step 6590, loss = 0.38, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 20h:07m:42s remains)
INFO - root - 2017-12-17 03:11:51.088190: step 6600, loss = 0.38, batch loss = 0.27 (36.3 examples/sec; 0.220 sec/batch; 19h:57m:39s remains)
INFO - root - 2017-12-17 03:11:53.477576: step 6610, loss = 0.34, batch loss = 0.23 (35.8 examples/sec; 0.223 sec/batch; 20h:12m:30s remains)
INFO - root - 2017-12-17 03:11:55.753343: step 6620, loss = 0.44, batch loss = 0.32 (35.3 examples/sec; 0.227 sec/batch; 20h:31m:52s remains)
INFO - root - 2017-12-17 03:11:58.015042: step 6630, loss = 0.37, batch loss = 0.26 (35.9 examples/sec; 0.223 sec/batch; 20h:09m:44s remains)
INFO - root - 2017-12-17 03:12:00.303743: step 6640, loss = 0.34, batch loss = 0.22 (34.4 examples/sec; 0.232 sec/batch; 21h:01m:16s remains)
INFO - root - 2017-12-17 03:12:02.569147: step 6650, loss = 0.39, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 20h:42m:33s remains)
INFO - root - 2017-12-17 03:12:04.854170: step 6660, loss = 0.32, batch loss = 0.20 (35.0 examples/sec; 0.228 sec/batch; 20h:39m:44s remains)
INFO - root - 2017-12-17 03:12:07.112841: step 6670, loss = 0.37, batch loss = 0.25 (35.4 examples/sec; 0.226 sec/batch; 20h:28m:39s remains)
INFO - root - 2017-12-17 03:12:09.407440: step 6680, loss = 0.35, batch loss = 0.24 (36.1 examples/sec; 0.221 sec/batch; 20h:01m:58s remains)
INFO - root - 2017-12-17 03:12:11.653767: step 6690, loss = 0.41, batch loss = 0.30 (34.5 examples/sec; 0.232 sec/batch; 20h:57m:38s remains)
INFO - root - 2017-12-17 03:12:13.894252: step 6700, loss = 0.41, batch loss = 0.30 (36.5 examples/sec; 0.219 sec/batch; 19h:49m:22s remains)
INFO - root - 2017-12-17 03:12:16.304284: step 6710, loss = 0.30, batch loss = 0.19 (35.4 examples/sec; 0.226 sec/batch; 20h:27m:50s remains)
INFO - root - 2017-12-17 03:12:18.606421: step 6720, loss = 0.31, batch loss = 0.19 (35.0 examples/sec; 0.229 sec/batch; 20h:42m:38s remains)
INFO - root - 2017-12-17 03:12:20.868894: step 6730, loss = 0.32, batch loss = 0.21 (34.3 examples/sec; 0.233 sec/batch; 21h:04m:41s remains)
INFO - root - 2017-12-17 03:12:23.120913: step 6740, loss = 0.33, batch loss = 0.22 (35.8 examples/sec; 0.223 sec/batch; 20h:11m:35s remains)
INFO - root - 2017-12-17 03:12:25.373073: step 6750, loss = 0.33, batch loss = 0.22 (36.0 examples/sec; 0.222 sec/batch; 20h:05m:49s remains)
INFO - root - 2017-12-17 03:12:27.647940: step 6760, loss = 0.32, batch loss = 0.21 (35.1 examples/sec; 0.228 sec/batch; 20h:37m:26s remains)
INFO - root - 2017-12-17 03:12:29.886931: step 6770, loss = 0.29, batch loss = 0.18 (36.5 examples/sec; 0.219 sec/batch; 19h:49m:56s remains)
INFO - root - 2017-12-17 03:12:32.151562: step 6780, loss = 0.31, batch loss = 0.19 (35.7 examples/sec; 0.224 sec/batch; 20h:17m:44s remains)
INFO - root - 2017-12-17 03:12:34.418901: step 6790, loss = 0.31, batch loss = 0.20 (35.3 examples/sec; 0.227 sec/batch; 20h:29m:33s remains)
INFO - root - 2017-12-17 03:12:36.682858: step 6800, loss = 0.29, batch loss = 0.18 (33.9 examples/sec; 0.236 sec/batch; 21h:21m:38s remains)
INFO - root - 2017-12-17 03:12:39.094579: step 6810, loss = 0.36, batch loss = 0.25 (35.3 examples/sec; 0.227 sec/batch; 20h:31m:39s remains)
INFO - root - 2017-12-17 03:12:41.350381: step 6820, loss = 0.36, batch loss = 0.25 (35.3 examples/sec; 0.226 sec/batch; 20h:28m:46s remains)
INFO - root - 2017-12-17 03:12:43.621839: step 6830, loss = 0.50, batch loss = 0.39 (36.4 examples/sec; 0.220 sec/batch; 19h:52m:04s remains)
INFO - root - 2017-12-17 03:12:45.885086: step 6840, loss = 0.32, batch loss = 0.21 (35.8 examples/sec; 0.223 sec/batch; 20h:13m:03s remains)
INFO - root - 2017-12-17 03:12:48.155215: step 6850, loss = 0.35, batch loss = 0.24 (34.7 examples/sec; 0.231 sec/batch; 20h:51m:28s remains)
INFO - root - 2017-12-17 03:12:50.423882: step 6860, loss = 0.39, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 20h:19m:52s remains)
INFO - root - 2017-12-17 03:12:52.693471: step 6870, loss = 0.30, batch loss = 0.19 (34.7 examples/sec; 0.230 sec/batch; 20h:50m:34s remains)
INFO - root - 2017-12-17 03:12:55.006851: step 6880, loss = 0.38, batch loss = 0.27 (33.1 examples/sec; 0.242 sec/batch; 21h:52m:57s remains)
INFO - root - 2017-12-17 03:12:57.290122: step 6890, loss = 0.30, batch loss = 0.19 (34.7 examples/sec; 0.231 sec/batch; 20h:52m:30s remains)
INFO - root - 2017-12-17 03:12:59.518527: step 6900, loss = 0.33, batch loss = 0.22 (35.1 examples/sec; 0.228 sec/batch; 20h:37m:45s remains)
INFO - root - 2017-12-17 03:13:01.934799: step 6910, loss = 0.30, batch loss = 0.19 (35.3 examples/sec; 0.226 sec/batch; 20h:28m:31s remains)
INFO - root - 2017-12-17 03:13:04.201308: step 6920, loss = 0.34, batch loss = 0.23 (34.8 examples/sec; 0.230 sec/batch; 20h:47m:28s remains)
INFO - root - 2017-12-17 03:13:06.470673: step 6930, loss = 0.32, batch loss = 0.21 (35.0 examples/sec; 0.229 sec/batch; 20h:39m:55s remains)
INFO - root - 2017-12-17 03:13:08.791657: step 6940, loss = 0.43, batch loss = 0.32 (36.1 examples/sec; 0.222 sec/batch; 20h:04m:04s remains)
INFO - root - 2017-12-17 03:13:11.052904: step 6950, loss = 0.39, batch loss = 0.28 (35.6 examples/sec; 0.225 sec/batch; 20h:18m:12s remains)
INFO - root - 2017-12-17 03:13:13.296194: step 6960, loss = 0.38, batch loss = 0.27 (35.3 examples/sec; 0.227 sec/batch; 20h:29m:56s remains)
INFO - root - 2017-12-17 03:13:15.575453: step 6970, loss = 0.32, batch loss = 0.21 (33.6 examples/sec; 0.238 sec/batch; 21h:33m:34s remains)
INFO - root - 2017-12-17 03:13:17.827253: step 6980, loss = 0.30, batch loss = 0.19 (35.7 examples/sec; 0.224 sec/batch; 20h:14m:32s remains)
INFO - root - 2017-12-17 03:13:20.072510: step 6990, loss = 0.29, batch loss = 0.18 (34.5 examples/sec; 0.232 sec/batch; 20h:57m:40s remains)
INFO - root - 2017-12-17 03:13:22.376378: step 7000, loss = 0.36, batch loss = 0.26 (36.4 examples/sec; 0.220 sec/batch; 19h:52m:15s remains)
INFO - root - 2017-12-17 03:13:24.798199: step 7010, loss = 0.32, batch loss = 0.21 (35.8 examples/sec; 0.224 sec/batch; 20h:13m:16s remains)
INFO - root - 2017-12-17 03:13:27.047103: step 7020, loss = 0.40, batch loss = 0.29 (35.9 examples/sec; 0.223 sec/batch; 20h:07m:22s remains)
INFO - root - 2017-12-17 03:13:29.306877: step 7030, loss = 0.32, batch loss = 0.21 (34.9 examples/sec; 0.229 sec/batch; 20h:43m:51s remains)
INFO - root - 2017-12-17 03:13:31.562462: step 7040, loss = 0.29, batch loss = 0.18 (36.0 examples/sec; 0.223 sec/batch; 20h:06m:59s remains)
INFO - root - 2017-12-17 03:13:33.851206: step 7050, loss = 0.35, batch loss = 0.24 (36.1 examples/sec; 0.221 sec/batch; 20h:01m:13s remains)
INFO - root - 2017-12-17 03:13:36.122481: step 7060, loss = 0.37, batch loss = 0.27 (34.5 examples/sec; 0.232 sec/batch; 20h:56m:58s remains)
INFO - root - 2017-12-17 03:13:38.394874: step 7070, loss = 0.38, batch loss = 0.28 (36.0 examples/sec; 0.222 sec/batch; 20h:06m:01s remains)
INFO - root - 2017-12-17 03:13:40.643523: step 7080, loss = 0.35, batch loss = 0.25 (34.9 examples/sec; 0.230 sec/batch; 20h:44m:59s remains)
INFO - root - 2017-12-17 03:13:42.928003: step 7090, loss = 0.29, batch loss = 0.18 (35.6 examples/sec; 0.225 sec/batch; 20h:18m:58s remains)
INFO - root - 2017-12-17 03:13:45.174196: step 7100, loss = 0.30, batch loss = 0.20 (35.4 examples/sec; 0.226 sec/batch; 20h:26m:01s remains)
INFO - root - 2017-12-17 03:13:47.573927: step 7110, loss = 0.28, batch loss = 0.17 (36.1 examples/sec; 0.222 sec/batch; 20h:01m:39s remains)
INFO - root - 2017-12-17 03:13:49.810176: step 7120, loss = 0.37, batch loss = 0.26 (36.0 examples/sec; 0.222 sec/batch; 20h:05m:14s remains)
INFO - root - 2017-12-17 03:13:52.090337: step 7130, loss = 0.31, batch loss = 0.20 (36.8 examples/sec; 0.218 sec/batch; 19h:40m:26s remains)
INFO - root - 2017-12-17 03:13:54.403513: step 7140, loss = 0.29, batch loss = 0.18 (34.7 examples/sec; 0.231 sec/batch; 20h:50m:52s remains)
INFO - root - 2017-12-17 03:13:56.660363: step 7150, loss = 0.31, batch loss = 0.20 (35.6 examples/sec; 0.225 sec/batch; 20h:18m:36s remains)
INFO - root - 2017-12-17 03:13:58.966214: step 7160, loss = 0.35, batch loss = 0.24 (35.4 examples/sec; 0.226 sec/batch; 20h:26m:25s remains)
INFO - root - 2017-12-17 03:14:01.265088: step 7170, loss = 0.32, batch loss = 0.21 (34.8 examples/sec; 0.230 sec/batch; 20h:45m:31s remains)
INFO - root - 2017-12-17 03:14:03.542136: step 7180, loss = 0.31, batch loss = 0.20 (36.0 examples/sec; 0.222 sec/batch; 20h:05m:31s remains)
INFO - root - 2017-12-17 03:14:05.826165: step 7190, loss = 0.31, batch loss = 0.20 (34.7 examples/sec; 0.230 sec/batch; 20h:49m:22s remains)
INFO - root - 2017-12-17 03:14:08.123239: step 7200, loss = 0.29, batch loss = 0.18 (35.6 examples/sec; 0.225 sec/batch; 20h:17m:32s remains)
INFO - root - 2017-12-17 03:14:10.527072: step 7210, loss = 0.31, batch loss = 0.20 (33.0 examples/sec; 0.243 sec/batch; 21h:54m:50s remains)
INFO - root - 2017-12-17 03:14:12.804813: step 7220, loss = 0.31, batch loss = 0.21 (35.5 examples/sec; 0.226 sec/batch; 20h:23m:11s remains)
INFO - root - 2017-12-17 03:14:15.065330: step 7230, loss = 0.33, batch loss = 0.22 (34.9 examples/sec; 0.229 sec/batch; 20h:41m:16s remains)
INFO - root - 2017-12-17 03:14:17.306589: step 7240, loss = 0.30, batch loss = 0.19 (36.1 examples/sec; 0.222 sec/batch; 20h:01m:30s remains)
INFO - root - 2017-12-17 03:14:19.588350: step 7250, loss = 0.32, batch loss = 0.22 (35.3 examples/sec; 0.227 sec/batch; 20h:29m:10s remains)
INFO - root - 2017-12-17 03:14:21.851015: step 7260, loss = 0.26, batch loss = 0.16 (35.6 examples/sec; 0.225 sec/batch; 20h:18m:42s remains)
INFO - root - 2017-12-17 03:14:24.144819: step 7270, loss = 0.27, batch loss = 0.16 (34.2 examples/sec; 0.234 sec/batch; 21h:06m:56s remains)
INFO - root - 2017-12-17 03:14:26.410833: step 7280, loss = 0.32, batch loss = 0.21 (35.2 examples/sec; 0.227 sec/batch; 20h:30m:11s remains)
INFO - root - 2017-12-17 03:14:28.685656: step 7290, loss = 0.34, batch loss = 0.23 (34.9 examples/sec; 0.229 sec/batch; 20h:41m:28s remains)
INFO - root - 2017-12-17 03:14:30.998161: step 7300, loss = 0.28, batch loss = 0.17 (33.2 examples/sec; 0.241 sec/batch; 21h:45m:19s remains)
INFO - root - 2017-12-17 03:14:33.429682: step 7310, loss = 0.47, batch loss = 0.36 (36.1 examples/sec; 0.222 sec/batch; 20h:01m:58s remains)
INFO - root - 2017-12-17 03:14:35.684220: step 7320, loss = 0.28, batch loss = 0.18 (35.7 examples/sec; 0.224 sec/batch; 20h:14m:32s remains)
INFO - root - 2017-12-17 03:14:37.969269: step 7330, loss = 0.36, batch loss = 0.26 (34.9 examples/sec; 0.229 sec/batch; 20h:40m:35s remains)
INFO - root - 2017-12-17 03:14:40.257663: step 7340, loss = 0.39, batch loss = 0.29 (34.0 examples/sec; 0.235 sec/batch; 21h:15m:27s remains)
INFO - root - 2017-12-17 03:14:42.507333: step 7350, loss = 0.30, batch loss = 0.20 (36.4 examples/sec; 0.220 sec/batch; 19h:51m:43s remains)
INFO - root - 2017-12-17 03:14:44.757119: step 7360, loss = 0.28, batch loss = 0.18 (36.1 examples/sec; 0.222 sec/batch; 20h:01m:55s remains)
INFO - root - 2017-12-17 03:14:46.997102: step 7370, loss = 0.30, batch loss = 0.19 (36.3 examples/sec; 0.220 sec/batch; 19h:53m:53s remains)
INFO - root - 2017-12-17 03:14:49.271064: step 7380, loss = 0.38, batch loss = 0.28 (34.9 examples/sec; 0.229 sec/batch; 20h:43m:01s remains)
INFO - root - 2017-12-17 03:14:51.554056: step 7390, loss = 0.28, batch loss = 0.17 (36.2 examples/sec; 0.221 sec/batch; 19h:56m:31s remains)
INFO - root - 2017-12-17 03:14:53.850963: step 7400, loss = 0.32, batch loss = 0.21 (34.7 examples/sec; 0.231 sec/batch; 20h:50m:15s remains)
INFO - root - 2017-12-17 03:14:56.235093: step 7410, loss = 0.28, batch loss = 0.18 (36.1 examples/sec; 0.222 sec/batch; 20h:01m:58s remains)
INFO - root - 2017-12-17 03:14:58.490025: step 7420, loss = 0.34, batch loss = 0.23 (34.9 examples/sec; 0.230 sec/batch; 20h:43m:35s remains)
INFO - root - 2017-12-17 03:15:00.751512: step 7430, loss = 0.30, batch loss = 0.19 (34.8 examples/sec; 0.230 sec/batch; 20h:46m:19s remains)
INFO - root - 2017-12-17 03:15:03.023966: step 7440, loss = 0.32, batch loss = 0.22 (35.5 examples/sec; 0.225 sec/batch; 20h:19m:20s remains)
INFO - root - 2017-12-17 03:15:05.324329: step 7450, loss = 0.31, batch loss = 0.20 (34.8 examples/sec; 0.230 sec/batch; 20h:46m:07s remains)
INFO - root - 2017-12-17 03:15:07.606217: step 7460, loss = 0.35, batch loss = 0.24 (34.8 examples/sec; 0.230 sec/batch; 20h:44m:08s remains)
INFO - root - 2017-12-17 03:15:09.873092: step 7470, loss = 0.34, batch loss = 0.24 (36.0 examples/sec; 0.223 sec/batch; 20h:05m:25s remains)
INFO - root - 2017-12-17 03:15:12.130702: step 7480, loss = 0.34, batch loss = 0.24 (36.1 examples/sec; 0.222 sec/batch; 20h:00m:34s remains)
INFO - root - 2017-12-17 03:15:14.383285: step 7490, loss = 0.24, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 20h:07m:32s remains)
INFO - root - 2017-12-17 03:15:16.653643: step 7500, loss = 0.28, batch loss = 0.18 (35.0 examples/sec; 0.229 sec/batch; 20h:38m:00s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-7500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-7500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 03:15:19.412285: step 7510, loss = 0.39, batch loss = 0.28 (35.1 examples/sec; 0.228 sec/batch; 20h:35m:25s remains)
INFO - root - 2017-12-17 03:15:21.709070: step 7520, loss = 0.29, batch loss = 0.18 (34.1 examples/sec; 0.235 sec/batch; 21h:11m:45s remains)
INFO - root - 2017-12-17 03:15:23.961532: step 7530, loss = 0.35, batch loss = 0.25 (34.1 examples/sec; 0.234 sec/batch; 21h:09m:49s remains)
INFO - root - 2017-12-17 03:15:26.230288: step 7540, loss = 0.33, batch loss = 0.23 (36.3 examples/sec; 0.221 sec/batch; 19h:54m:36s remains)
INFO - root - 2017-12-17 03:15:28.508570: step 7550, loss = 0.34, batch loss = 0.23 (34.6 examples/sec; 0.231 sec/batch; 20h:52m:20s remains)
INFO - root - 2017-12-17 03:15:30.759797: step 7560, loss = 0.34, batch loss = 0.24 (34.8 examples/sec; 0.230 sec/batch; 20h:45m:18s remains)
INFO - root - 2017-12-17 03:15:33.055983: step 7570, loss = 0.27, batch loss = 0.17 (35.8 examples/sec; 0.223 sec/batch; 20h:09m:58s remains)
INFO - root - 2017-12-17 03:15:35.320846: step 7580, loss = 0.36, batch loss = 0.25 (36.2 examples/sec; 0.221 sec/batch; 19h:56m:56s remains)
INFO - root - 2017-12-17 03:15:37.590504: step 7590, loss = 0.33, batch loss = 0.23 (34.3 examples/sec; 0.233 sec/batch; 21h:01m:44s remains)
INFO - root - 2017-12-17 03:15:39.891547: step 7600, loss = 0.30, batch loss = 0.20 (36.0 examples/sec; 0.222 sec/batch; 20h:02m:15s remains)
INFO - root - 2017-12-17 03:15:42.284136: step 7610, loss = 0.34, batch loss = 0.24 (36.5 examples/sec; 0.219 sec/batch; 19h:46m:56s remains)
INFO - root - 2017-12-17 03:15:44.558481: step 7620, loss = 0.29, batch loss = 0.18 (33.6 examples/sec; 0.238 sec/batch; 21h:29m:34s remains)
INFO - root - 2017-12-17 03:15:46.863755: step 7630, loss = 0.30, batch loss = 0.20 (33.9 examples/sec; 0.236 sec/batch; 21h:18m:06s remains)
INFO - root - 2017-12-17 03:15:49.117949: step 7640, loss = 0.29, batch loss = 0.19 (36.0 examples/sec; 0.222 sec/batch; 20h:01m:33s remains)
INFO - root - 2017-12-17 03:15:51.345841: step 7650, loss = 0.29, batch loss = 0.19 (35.7 examples/sec; 0.224 sec/batch; 20h:13m:24s remains)
INFO - root - 2017-12-17 03:15:53.579683: step 7660, loss = 0.30, batch loss = 0.20 (36.0 examples/sec; 0.222 sec/batch; 20h:03m:33s remains)
INFO - root - 2017-12-17 03:15:55.858902: step 7670, loss = 0.27, batch loss = 0.17 (33.9 examples/sec; 0.236 sec/batch; 21h:17m:02s remains)
INFO - root - 2017-12-17 03:15:58.108045: step 7680, loss = 0.35, batch loss = 0.24 (33.3 examples/sec; 0.240 sec/batch; 21h:38m:49s remains)
INFO - root - 2017-12-17 03:16:00.410099: step 7690, loss = 0.31, batch loss = 0.20 (36.9 examples/sec; 0.217 sec/batch; 19h:32m:51s remains)
INFO - root - 2017-12-17 03:16:02.664632: step 7700, loss = 0.37, batch loss = 0.26 (35.2 examples/sec; 0.227 sec/batch; 20h:31m:06s remains)
INFO - root - 2017-12-17 03:16:05.071281: step 7710, loss = 0.30, batch loss = 0.20 (36.5 examples/sec; 0.219 sec/batch; 19h:46m:17s remains)
INFO - root - 2017-12-17 03:16:07.383694: step 7720, loss = 0.30, batch loss = 0.20 (33.0 examples/sec; 0.243 sec/batch; 21h:53m:12s remains)
INFO - root - 2017-12-17 03:16:09.725881: step 7730, loss = 0.35, batch loss = 0.25 (33.7 examples/sec; 0.238 sec/batch; 21h:26m:01s remains)
INFO - root - 2017-12-17 03:16:12.007745: step 7740, loss = 0.30, batch loss = 0.20 (35.1 examples/sec; 0.228 sec/batch; 20h:34m:17s remains)
INFO - root - 2017-12-17 03:16:14.261322: step 7750, loss = 0.27, batch loss = 0.17 (35.7 examples/sec; 0.224 sec/batch; 20h:12m:56s remains)
INFO - root - 2017-12-17 03:16:16.548640: step 7760, loss = 0.33, batch loss = 0.22 (35.3 examples/sec; 0.227 sec/batch; 20h:28m:03s remains)
INFO - root - 2017-12-17 03:16:18.824393: step 7770, loss = 0.28, batch loss = 0.18 (35.4 examples/sec; 0.226 sec/batch; 20h:22m:32s remains)
INFO - root - 2017-12-17 03:16:21.112020: step 7780, loss = 0.27, batch loss = 0.17 (36.7 examples/sec; 0.218 sec/batch; 19h:41m:00s remains)
INFO - root - 2017-12-17 03:16:23.372179: step 7790, loss = 0.33, batch loss = 0.23 (34.5 examples/sec; 0.232 sec/batch; 20h:54m:52s remains)
INFO - root - 2017-12-17 03:16:25.647398: step 7800, loss = 0.32, batch loss = 0.22 (34.6 examples/sec; 0.231 sec/batch; 20h:50m:46s remains)
INFO - root - 2017-12-17 03:16:28.021277: step 7810, loss = 0.26, batch loss = 0.16 (35.2 examples/sec; 0.227 sec/batch; 20h:30m:15s remains)
INFO - root - 2017-12-17 03:16:30.298019: step 7820, loss = 0.47, batch loss = 0.37 (36.6 examples/sec; 0.219 sec/batch; 19h:42m:49s remains)
INFO - root - 2017-12-17 03:16:32.542480: step 7830, loss = 0.33, batch loss = 0.23 (36.9 examples/sec; 0.217 sec/batch; 19h:32m:25s remains)
INFO - root - 2017-12-17 03:16:34.802899: step 7840, loss = 0.36, batch loss = 0.26 (35.1 examples/sec; 0.228 sec/batch; 20h:33m:54s remains)
INFO - root - 2017-12-17 03:16:37.090154: step 7850, loss = 0.30, batch loss = 0.20 (36.5 examples/sec; 0.219 sec/batch; 19h:45m:10s remains)
INFO - root - 2017-12-17 03:16:39.368877: step 7860, loss = 0.34, batch loss = 0.24 (35.2 examples/sec; 0.227 sec/batch; 20h:28m:14s remains)
INFO - root - 2017-12-17 03:16:41.613511: step 7870, loss = 0.30, batch loss = 0.20 (35.5 examples/sec; 0.226 sec/batch; 20h:20m:15s remains)
INFO - root - 2017-12-17 03:16:43.896210: step 7880, loss = 0.27, batch loss = 0.17 (34.4 examples/sec; 0.232 sec/batch; 20h:57m:26s remains)
INFO - root - 2017-12-17 03:16:46.142634: step 7890, loss = 0.45, batch loss = 0.35 (36.1 examples/sec; 0.222 sec/batch; 19h:58m:32s remains)
INFO - root - 2017-12-17 03:16:48.382463: step 7900, loss = 0.26, batch loss = 0.16 (36.3 examples/sec; 0.220 sec/batch; 19h:52m:17s remains)
INFO - root - 2017-12-17 03:16:50.832970: step 7910, loss = 0.29, batch loss = 0.19 (34.4 examples/sec; 0.233 sec/batch; 20h:59m:22s remains)
INFO - root - 2017-12-17 03:16:53.065750: step 7920, loss = 0.29, batch loss = 0.19 (36.4 examples/sec; 0.220 sec/batch; 19h:50m:12s remains)
INFO - root - 2017-12-17 03:16:55.325558: step 7930, loss = 0.34, batch loss = 0.24 (35.1 examples/sec; 0.228 sec/batch; 20h:33m:55s remains)
INFO - root - 2017-12-17 03:16:57.606849: step 7940, loss = 0.33, batch loss = 0.23 (36.0 examples/sec; 0.222 sec/batch; 20h:01m:53s remains)
INFO - root - 2017-12-17 03:16:59.853793: step 7950, loss = 0.32, batch loss = 0.22 (34.9 examples/sec; 0.229 sec/batch; 20h:39m:35s remains)
INFO - root - 2017-12-17 03:17:02.167558: step 7960, loss = 0.27, batch loss = 0.17 (34.8 examples/sec; 0.230 sec/batch; 20h:45m:06s remains)
INFO - root - 2017-12-17 03:17:04.419237: step 7970, loss = 0.28, batch loss = 0.18 (35.9 examples/sec; 0.223 sec/batch; 20h:04m:08s remains)
INFO - root - 2017-12-17 03:17:06.681338: step 7980, loss = 0.31, batch loss = 0.21 (36.7 examples/sec; 0.218 sec/batch; 19h:39m:31s remains)
INFO - root - 2017-12-17 03:17:08.950054: step 7990, loss = 0.33, batch loss = 0.23 (35.1 examples/sec; 0.228 sec/batch; 20h:33m:14s remains)
INFO - root - 2017-12-17 03:17:11.211088: step 8000, loss = 0.30, batch loss = 0.20 (33.7 examples/sec; 0.237 sec/batch; 21h:22m:26s remains)
INFO - root - 2017-12-17 03:17:13.629836: step 8010, loss = 0.35, batch loss = 0.25 (35.7 examples/sec; 0.224 sec/batch; 20h:11m:34s remains)
INFO - root - 2017-12-17 03:17:15.904963: step 8020, loss = 0.32, batch loss = 0.22 (34.7 examples/sec; 0.230 sec/batch; 20h:46m:23s remains)
INFO - root - 2017-12-17 03:17:18.194874: step 8030, loss = 0.29, batch loss = 0.19 (35.9 examples/sec; 0.223 sec/batch; 20h:04m:50s remains)
INFO - root - 2017-12-17 03:17:20.431380: step 8040, loss = 0.28, batch loss = 0.18 (36.0 examples/sec; 0.223 sec/batch; 20h:03m:15s remains)
INFO - root - 2017-12-17 03:17:22.682430: step 8050, loss = 0.27, batch loss = 0.17 (33.7 examples/sec; 0.237 sec/batch; 21h:22m:39s remains)
INFO - root - 2017-12-17 03:17:24.942488: step 8060, loss = 0.37, batch loss = 0.27 (35.9 examples/sec; 0.223 sec/batch; 20h:03m:29s remains)
INFO - root - 2017-12-17 03:17:27.200487: step 8070, loss = 0.32, batch loss = 0.22 (33.2 examples/sec; 0.241 sec/batch; 21h:43m:41s remains)
INFO - root - 2017-12-17 03:17:29.459249: step 8080, loss = 0.33, batch loss = 0.23 (35.5 examples/sec; 0.225 sec/batch; 20h:17m:19s remains)
INFO - root - 2017-12-17 03:17:31.773151: step 8090, loss = 0.37, batch loss = 0.27 (34.4 examples/sec; 0.233 sec/batch; 20h:58m:57s remains)
INFO - root - 2017-12-17 03:17:34.062167: step 8100, loss = 0.30, batch loss = 0.20 (34.8 examples/sec; 0.230 sec/batch; 20h:42m:24s remains)
INFO - root - 2017-12-17 03:17:36.485927: step 8110, loss = 0.25, batch loss = 0.15 (34.2 examples/sec; 0.234 sec/batch; 21h:04m:08s remains)
INFO - root - 2017-12-17 03:17:38.760121: step 8120, loss = 0.27, batch loss = 0.17 (36.1 examples/sec; 0.221 sec/batch; 19h:56m:40s remains)
INFO - root - 2017-12-17 03:17:41.028825: step 8130, loss = 0.35, batch loss = 0.25 (34.1 examples/sec; 0.235 sec/batch; 21h:09m:00s remains)
INFO - root - 2017-12-17 03:17:43.311972: step 8140, loss = 0.28, batch loss = 0.18 (36.1 examples/sec; 0.222 sec/batch; 19h:57m:31s remains)
INFO - root - 2017-12-17 03:17:45.582751: step 8150, loss = 0.26, batch loss = 0.17 (35.1 examples/sec; 0.228 sec/batch; 20h:33m:00s remains)
INFO - root - 2017-12-17 03:17:47.846719: step 8160, loss = 0.32, batch loss = 0.22 (34.8 examples/sec; 0.230 sec/batch; 20h:42m:55s remains)
INFO - root - 2017-12-17 03:17:50.086286: step 8170, loss = 0.29, batch loss = 0.20 (36.5 examples/sec; 0.219 sec/batch; 19h:46m:12s remains)
INFO - root - 2017-12-17 03:17:52.353834: step 8180, loss = 0.28, batch loss = 0.18 (34.8 examples/sec; 0.230 sec/batch; 20h:42m:28s remains)
INFO - root - 2017-12-17 03:17:54.671184: step 8190, loss = 0.28, batch loss = 0.18 (32.5 examples/sec; 0.246 sec/batch; 22h:09m:36s remains)
INFO - root - 2017-12-17 03:17:56.950525: step 8200, loss = 0.37, batch loss = 0.28 (35.0 examples/sec; 0.229 sec/batch; 20h:36m:11s remains)
INFO - root - 2017-12-17 03:17:59.351292: step 8210, loss = 0.32, batch loss = 0.22 (36.3 examples/sec; 0.220 sec/batch; 19h:51m:20s remains)
INFO - root - 2017-12-17 03:18:01.621483: step 8220, loss = 0.29, batch loss = 0.20 (33.9 examples/sec; 0.236 sec/batch; 21h:15m:44s remains)
INFO - root - 2017-12-17 03:18:03.913200: step 8230, loss = 0.30, batch loss = 0.20 (35.6 examples/sec; 0.225 sec/batch; 20h:15m:41s remains)
INFO - root - 2017-12-17 03:18:06.181644: step 8240, loss = 0.34, batch loss = 0.24 (34.0 examples/sec; 0.235 sec/batch; 21h:11m:34s remains)
INFO - root - 2017-12-17 03:18:08.449165: step 8250, loss = 0.33, batch loss = 0.23 (35.6 examples/sec; 0.224 sec/batch; 20h:12m:46s remains)
INFO - root - 2017-12-17 03:18:10.715776: step 8260, loss = 0.37, batch loss = 0.27 (36.5 examples/sec; 0.219 sec/batch; 19h:45m:49s remains)
INFO - root - 2017-12-17 03:18:13.009718: step 8270, loss = 0.31, batch loss = 0.22 (35.7 examples/sec; 0.224 sec/batch; 20h:12m:02s remains)
INFO - root - 2017-12-17 03:18:15.256857: step 8280, loss = 0.31, batch loss = 0.21 (35.1 examples/sec; 0.228 sec/batch; 20h:33m:17s remains)
INFO - root - 2017-12-17 03:18:17.533139: step 8290, loss = 0.31, batch loss = 0.21 (35.5 examples/sec; 0.225 sec/batch; 20h:17m:38s remains)
INFO - root - 2017-12-17 03:18:19.793045: step 8300, loss = 0.26, batch loss = 0.17 (35.7 examples/sec; 0.224 sec/batch; 20h:11m:42s remains)
INFO - root - 2017-12-17 03:18:22.200762: step 8310, loss = 0.29, batch loss = 0.20 (35.8 examples/sec; 0.223 sec/batch; 20h:07m:14s remains)
INFO - root - 2017-12-17 03:18:24.483066: step 8320, loss = 0.34, batch loss = 0.24 (34.8 examples/sec; 0.230 sec/batch; 20h:41m:24s remains)
INFO - root - 2017-12-17 03:18:26.808372: step 8330, loss = 0.31, batch loss = 0.22 (35.9 examples/sec; 0.223 sec/batch; 20h:03m:17s remains)
INFO - root - 2017-12-17 03:18:29.070793: step 8340, loss = 0.34, batch loss = 0.24 (35.9 examples/sec; 0.223 sec/batch; 20h:04m:19s remains)
INFO - root - 2017-12-17 03:18:31.359208: step 8350, loss = 0.26, batch loss = 0.17 (35.3 examples/sec; 0.227 sec/batch; 20h:23m:55s remains)
INFO - root - 2017-12-17 03:18:33.626447: step 8360, loss = 0.26, batch loss = 0.16 (35.8 examples/sec; 0.224 sec/batch; 20h:07m:56s remains)
INFO - root - 2017-12-17 03:18:35.870799: step 8370, loss = 0.31, batch loss = 0.21 (35.9 examples/sec; 0.223 sec/batch; 20h:05m:07s remains)
INFO - root - 2017-12-17 03:18:38.170006: step 8380, loss = 0.28, batch loss = 0.18 (33.7 examples/sec; 0.237 sec/batch; 21h:20m:42s remains)
INFO - root - 2017-12-17 03:18:40.441847: step 8390, loss = 0.31, batch loss = 0.21 (35.7 examples/sec; 0.224 sec/batch; 20h:10m:59s remains)
INFO - root - 2017-12-17 03:18:42.689041: step 8400, loss = 0.27, batch loss = 0.18 (35.4 examples/sec; 0.226 sec/batch; 20h:21m:48s remains)
INFO - root - 2017-12-17 03:18:45.069204: step 8410, loss = 0.36, batch loss = 0.27 (36.3 examples/sec; 0.221 sec/batch; 19h:51m:06s remains)
INFO - root - 2017-12-17 03:18:47.338819: step 8420, loss = 0.25, batch loss = 0.15 (35.6 examples/sec; 0.224 sec/batch; 20h:12m:06s remains)
INFO - root - 2017-12-17 03:18:49.577552: step 8430, loss = 0.30, batch loss = 0.21 (36.3 examples/sec; 0.221 sec/batch; 19h:51m:36s remains)
INFO - root - 2017-12-17 03:18:51.829562: step 8440, loss = 0.27, batch loss = 0.18 (36.1 examples/sec; 0.222 sec/batch; 19h:56m:54s remains)
INFO - root - 2017-12-17 03:18:54.142396: step 8450, loss = 0.32, batch loss = 0.22 (34.9 examples/sec; 0.229 sec/batch; 20h:38m:42s remains)
INFO - root - 2017-12-17 03:18:56.402546: step 8460, loss = 0.29, batch loss = 0.19 (35.0 examples/sec; 0.229 sec/batch; 20h:35m:22s remains)
INFO - root - 2017-12-17 03:18:58.669827: step 8470, loss = 0.28, batch loss = 0.19 (34.7 examples/sec; 0.231 sec/batch; 20h:45m:44s remains)
INFO - root - 2017-12-17 03:19:00.941865: step 8480, loss = 0.31, batch loss = 0.22 (35.6 examples/sec; 0.225 sec/batch; 20h:14m:37s remains)
INFO - root - 2017-12-17 03:19:03.247827: step 8490, loss = 0.30, batch loss = 0.21 (34.9 examples/sec; 0.230 sec/batch; 20h:39m:28s remains)
INFO - root - 2017-12-17 03:19:05.519651: step 8500, loss = 0.37, batch loss = 0.27 (36.4 examples/sec; 0.220 sec/batch; 19h:46m:27s remains)
INFO - root - 2017-12-17 03:19:07.937402: step 8510, loss = 0.30, batch loss = 0.20 (36.7 examples/sec; 0.218 sec/batch; 19h:38m:17s remains)
INFO - root - 2017-12-17 03:19:10.225488: step 8520, loss = 0.39, batch loss = 0.29 (33.4 examples/sec; 0.239 sec/batch; 21h:31m:43s remains)
INFO - root - 2017-12-17 03:19:12.482190: step 8530, loss = 0.26, batch loss = 0.17 (33.8 examples/sec; 0.237 sec/batch; 21h:19m:22s remains)
INFO - root - 2017-12-17 03:19:14.736417: step 8540, loss = 0.30, batch loss = 0.20 (34.4 examples/sec; 0.232 sec/batch; 20h:54m:09s remains)
INFO - root - 2017-12-17 03:19:16.997469: step 8550, loss = 0.22, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 20h:57m:35s remains)
INFO - root - 2017-12-17 03:19:19.234449: step 8560, loss = 0.28, batch loss = 0.19 (36.7 examples/sec; 0.218 sec/batch; 19h:35m:47s remains)
INFO - root - 2017-12-17 03:19:21.468847: step 8570, loss = 0.26, batch loss = 0.17 (34.8 examples/sec; 0.230 sec/batch; 20h:41m:56s remains)
INFO - root - 2017-12-17 03:19:23.718720: step 8580, loss = 0.28, batch loss = 0.19 (36.2 examples/sec; 0.221 sec/batch; 19h:51m:37s remains)
INFO - root - 2017-12-17 03:19:26.008496: step 8590, loss = 0.30, batch loss = 0.20 (35.1 examples/sec; 0.228 sec/batch; 20h:32m:05s remains)
INFO - root - 2017-12-17 03:19:28.314040: step 8600, loss = 0.33, batch loss = 0.24 (34.9 examples/sec; 0.229 sec/batch; 20h:36m:19s remains)
INFO - root - 2017-12-17 03:19:30.707612: step 8610, loss = 0.27, batch loss = 0.18 (35.9 examples/sec; 0.223 sec/batch; 20h:02m:42s remains)
INFO - root - 2017-12-17 03:19:32.988956: step 8620, loss = 0.27, batch loss = 0.17 (34.8 examples/sec; 0.230 sec/batch; 20h:40m:17s remains)
INFO - root - 2017-12-17 03:19:35.240631: step 8630, loss = 0.26, batch loss = 0.16 (33.6 examples/sec; 0.238 sec/batch; 21h:25m:22s remains)
INFO - root - 2017-12-17 03:19:37.515529: step 8640, loss = 0.31, batch loss = 0.22 (34.9 examples/sec; 0.229 sec/batch; 20h:38m:25s remains)
INFO - root - 2017-12-17 03:19:39.790392: step 8650, loss = 0.40, batch loss = 0.31 (34.6 examples/sec; 0.232 sec/batch; 20h:49m:38s remains)
INFO - root - 2017-12-17 03:19:42.095709: step 8660, loss = 0.29, batch loss = 0.19 (34.7 examples/sec; 0.231 sec/batch; 20h:44m:18s remains)
INFO - root - 2017-12-17 03:19:44.364002: step 8670, loss = 0.27, batch loss = 0.18 (35.1 examples/sec; 0.228 sec/batch; 20h:28m:50s remains)
INFO - root - 2017-12-17 03:19:46.592421: step 8680, loss = 0.31, batch loss = 0.21 (36.1 examples/sec; 0.221 sec/batch; 19h:55m:00s remains)
INFO - root - 2017-12-17 03:19:48.850942: step 8690, loss = 0.27, batch loss = 0.17 (32.8 examples/sec; 0.244 sec/batch; 21h:56m:09s remains)
INFO - root - 2017-12-17 03:19:51.116160: step 8700, loss = 0.29, batch loss = 0.19 (35.6 examples/sec; 0.225 sec/batch; 20h:14m:19s remains)
INFO - root - 2017-12-17 03:19:53.486919: step 8710, loss = 0.30, batch loss = 0.21 (36.2 examples/sec; 0.221 sec/batch; 19h:53m:02s remains)
INFO - root - 2017-12-17 03:19:55.755203: step 8720, loss = 0.35, batch loss = 0.25 (36.0 examples/sec; 0.222 sec/batch; 19h:57m:54s remains)
INFO - root - 2017-12-17 03:19:58.038420: step 8730, loss = 0.27, batch loss = 0.18 (35.3 examples/sec; 0.227 sec/batch; 20h:22m:47s remains)
INFO - root - 2017-12-17 03:20:00.335977: step 8740, loss = 0.27, batch loss = 0.18 (34.7 examples/sec; 0.231 sec/batch; 20h:44m:11s remains)
INFO - root - 2017-12-17 03:20:02.595922: step 8750, loss = 0.30, batch loss = 0.21 (35.4 examples/sec; 0.226 sec/batch; 20h:17m:42s remains)
INFO - root - 2017-12-17 03:20:04.881381: step 8760, loss = 0.25, batch loss = 0.16 (34.9 examples/sec; 0.229 sec/batch; 20h:35m:13s remains)
INFO - root - 2017-12-17 03:20:07.168909: step 8770, loss = 0.30, batch loss = 0.21 (35.5 examples/sec; 0.226 sec/batch; 20h:17m:02s remains)
INFO - root - 2017-12-17 03:20:09.436516: step 8780, loss = 0.26, batch loss = 0.17 (34.8 examples/sec; 0.230 sec/batch; 20h:41m:25s remains)
INFO - root - 2017-12-17 03:20:11.693999: step 8790, loss = 0.22, batch loss = 0.13 (35.8 examples/sec; 0.224 sec/batch; 20h:07m:15s remains)
INFO - root - 2017-12-17 03:20:13.973405: step 8800, loss = 0.43, batch loss = 0.34 (35.2 examples/sec; 0.227 sec/batch; 20h:25m:33s remains)
INFO - root - 2017-12-17 03:20:16.373866: step 8810, loss = 0.23, batch loss = 0.14 (34.0 examples/sec; 0.235 sec/batch; 21h:07m:58s remains)
INFO - root - 2017-12-17 03:20:18.616136: step 8820, loss = 0.27, batch loss = 0.18 (36.1 examples/sec; 0.222 sec/batch; 19h:55m:10s remains)
INFO - root - 2017-12-17 03:20:20.891130: step 8830, loss = 0.23, batch loss = 0.14 (36.4 examples/sec; 0.220 sec/batch; 19h:44m:19s remains)
INFO - root - 2017-12-17 03:20:23.157339: step 8840, loss = 0.28, batch loss = 0.19 (33.8 examples/sec; 0.237 sec/batch; 21h:16m:29s remains)
INFO - root - 2017-12-17 03:20:25.416431: step 8850, loss = 0.30, batch loss = 0.21 (35.8 examples/sec; 0.223 sec/batch; 20h:05m:28s remains)
INFO - root - 2017-12-17 03:20:27.675140: step 8860, loss = 0.26, batch loss = 0.17 (35.1 examples/sec; 0.228 sec/batch; 20h:28m:55s remains)
INFO - root - 2017-12-17 03:20:29.953509: step 8870, loss = 0.27, batch loss = 0.18 (36.2 examples/sec; 0.221 sec/batch; 19h:53m:23s remains)
INFO - root - 2017-12-17 03:20:32.203946: step 8880, loss = 0.24, batch loss = 0.15 (34.8 examples/sec; 0.230 sec/batch; 20h:39m:08s remains)
INFO - root - 2017-12-17 03:20:34.450057: step 8890, loss = 0.29, batch loss = 0.20 (35.7 examples/sec; 0.224 sec/batch; 20h:07m:55s remains)
INFO - root - 2017-12-17 03:20:36.757978: step 8900, loss = 0.32, batch loss = 0.23 (34.6 examples/sec; 0.231 sec/batch; 20h:45m:37s remains)
INFO - root - 2017-12-17 03:20:39.165958: step 8910, loss = 0.36, batch loss = 0.27 (34.3 examples/sec; 0.233 sec/batch; 20h:57m:18s remains)
INFO - root - 2017-12-17 03:20:41.438966: step 8920, loss = 0.28, batch loss = 0.18 (34.9 examples/sec; 0.229 sec/batch; 20h:35m:43s remains)
INFO - root - 2017-12-17 03:20:43.698921: step 8930, loss = 0.26, batch loss = 0.17 (34.9 examples/sec; 0.230 sec/batch; 20h:37m:51s remains)
INFO - root - 2017-12-17 03:20:45.941525: step 8940, loss = 0.29, batch loss = 0.20 (35.7 examples/sec; 0.224 sec/batch; 20h:07m:27s remains)
INFO - root - 2017-12-17 03:20:48.177406: step 8950, loss = 0.25, batch loss = 0.16 (36.4 examples/sec; 0.220 sec/batch; 19h:45m:23s remains)
INFO - root - 2017-12-17 03:20:50.437558: step 8960, loss = 0.28, batch loss = 0.19 (35.7 examples/sec; 0.224 sec/batch; 20h:08m:22s remains)
INFO - root - 2017-12-17 03:20:52.705283: step 8970, loss = 0.25, batch loss = 0.16 (34.8 examples/sec; 0.230 sec/batch; 20h:40m:17s remains)
INFO - root - 2017-12-17 03:20:55.014997: step 8980, loss = 0.29, batch loss = 0.20 (35.7 examples/sec; 0.224 sec/batch; 20h:07m:04s remains)
INFO - root - 2017-12-17 03:20:57.258922: step 8990, loss = 0.22, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 20h:28m:03s remains)
INFO - root - 2017-12-17 03:20:59.517499: step 9000, loss = 0.23, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 20h:07m:07s remains)
INFO - root - 2017-12-17 03:21:01.917027: step 9010, loss = 0.26, batch loss = 0.17 (36.0 examples/sec; 0.222 sec/batch; 19h:56m:54s remains)
INFO - root - 2017-12-17 03:21:04.194327: step 9020, loss = 0.25, batch loss = 0.16 (36.0 examples/sec; 0.223 sec/batch; 19h:59m:37s remains)
INFO - root - 2017-12-17 03:21:06.440113: step 9030, loss = 0.29, batch loss = 0.20 (35.5 examples/sec; 0.225 sec/batch; 20h:14m:16s remains)
INFO - root - 2017-12-17 03:21:08.741561: step 9040, loss = 0.22, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 20h:08m:04s remains)
INFO - root - 2017-12-17 03:21:10.969502: step 9050, loss = 0.24, batch loss = 0.15 (36.9 examples/sec; 0.217 sec/batch; 19h:28m:30s remains)
INFO - root - 2017-12-17 03:21:13.234542: step 9060, loss = 0.28, batch loss = 0.19 (36.6 examples/sec; 0.219 sec/batch; 19h:39m:27s remains)
INFO - root - 2017-12-17 03:21:15.530210: step 9070, loss = 0.30, batch loss = 0.21 (36.0 examples/sec; 0.222 sec/batch; 19h:57m:57s remains)
INFO - root - 2017-12-17 03:21:17.771689: step 9080, loss = 0.30, batch loss = 0.21 (35.3 examples/sec; 0.226 sec/batch; 20h:20m:29s remains)
INFO - root - 2017-12-17 03:21:20.019847: step 9090, loss = 0.30, batch loss = 0.21 (35.1 examples/sec; 0.228 sec/batch; 20h:27m:35s remains)
INFO - root - 2017-12-17 03:21:22.258925: step 9100, loss = 0.28, batch loss = 0.19 (36.1 examples/sec; 0.221 sec/batch; 19h:53m:13s remains)
INFO - root - 2017-12-17 03:21:24.615136: step 9110, loss = 0.32, batch loss = 0.23 (36.1 examples/sec; 0.222 sec/batch; 19h:54m:21s remains)
INFO - root - 2017-12-17 03:21:26.877513: step 9120, loss = 0.27, batch loss = 0.18 (34.9 examples/sec; 0.229 sec/batch; 20h:36m:51s remains)
INFO - root - 2017-12-17 03:21:29.172235: step 9130, loss = 0.25, batch loss = 0.16 (36.1 examples/sec; 0.222 sec/batch; 19h:55m:28s remains)
INFO - root - 2017-12-17 03:21:31.435076: step 9140, loss = 0.22, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 20h:48m:33s remains)
INFO - root - 2017-12-17 03:21:33.688510: step 9150, loss = 0.28, batch loss = 0.19 (35.4 examples/sec; 0.226 sec/batch; 20h:17m:05s remains)
INFO - root - 2017-12-17 03:21:35.967388: step 9160, loss = 0.24, batch loss = 0.15 (34.6 examples/sec; 0.231 sec/batch; 20h:46m:03s remains)
INFO - root - 2017-12-17 03:21:38.226905: step 9170, loss = 0.28, batch loss = 0.19 (35.6 examples/sec; 0.225 sec/batch; 20h:11m:33s remains)
INFO - root - 2017-12-17 03:21:40.484408: step 9180, loss = 0.27, batch loss = 0.18 (34.9 examples/sec; 0.229 sec/batch; 20h:33m:46s remains)
INFO - root - 2017-12-17 03:21:42.756606: step 9190, loss = 0.34, batch loss = 0.25 (35.0 examples/sec; 0.229 sec/batch; 20h:31m:57s remains)
INFO - root - 2017-12-17 03:21:45.042248: step 9200, loss = 0.28, batch loss = 0.19 (33.3 examples/sec; 0.240 sec/batch; 21h:32m:55s remains)
INFO - root - 2017-12-17 03:21:47.467775: step 9210, loss = 0.30, batch loss = 0.21 (33.3 examples/sec; 0.240 sec/batch; 21h:32m:54s remains)
INFO - root - 2017-12-17 03:21:49.740036: step 9220, loss = 0.23, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 19h:57m:35s remains)
INFO - root - 2017-12-17 03:21:52.007407: step 9230, loss = 0.26, batch loss = 0.17 (35.6 examples/sec; 0.225 sec/batch; 20h:10m:57s remains)
INFO - root - 2017-12-17 03:21:54.302552: step 9240, loss = 0.28, batch loss = 0.19 (35.1 examples/sec; 0.228 sec/batch; 20h:26m:48s remains)
INFO - root - 2017-12-17 03:21:56.580980: step 9250, loss = 0.29, batch loss = 0.20 (33.3 examples/sec; 0.240 sec/batch; 21h:33m:42s remains)
INFO - root - 2017-12-17 03:21:58.840481: step 9260, loss = 0.28, batch loss = 0.20 (34.9 examples/sec; 0.229 sec/batch; 20h:35m:38s remains)
INFO - root - 2017-12-17 03:22:01.168438: step 9270, loss = 0.24, batch loss = 0.15 (33.5 examples/sec; 0.238 sec/batch; 21h:24m:39s remains)
INFO - root - 2017-12-17 03:22:03.444756: step 9280, loss = 0.26, batch loss = 0.17 (35.6 examples/sec; 0.225 sec/batch; 20h:11m:30s remains)
INFO - root - 2017-12-17 03:22:05.702168: step 9290, loss = 0.31, batch loss = 0.22 (34.1 examples/sec; 0.234 sec/batch; 21h:02m:29s remains)
INFO - root - 2017-12-17 03:22:07.961987: step 9300, loss = 0.24, batch loss = 0.16 (37.2 examples/sec; 0.215 sec/batch; 19h:19m:55s remains)
INFO - root - 2017-12-17 03:22:10.338709: step 9310, loss = 0.23, batch loss = 0.14 (35.3 examples/sec; 0.226 sec/batch; 20h:19m:05s remains)
INFO - root - 2017-12-17 03:22:12.606514: step 9320, loss = 0.32, batch loss = 0.23 (34.9 examples/sec; 0.229 sec/batch; 20h:35m:33s remains)
INFO - root - 2017-12-17 03:22:14.870135: step 9330, loss = 0.26, batch loss = 0.17 (34.1 examples/sec; 0.235 sec/batch; 21h:03m:07s remains)
INFO - root - 2017-12-17 03:22:17.144026: step 9340, loss = 0.25, batch loss = 0.16 (35.1 examples/sec; 0.228 sec/batch; 20h:26m:16s remains)
INFO - root - 2017-12-17 03:22:19.393829: step 9350, loss = 0.30, batch loss = 0.22 (35.8 examples/sec; 0.223 sec/batch; 20h:02m:06s remains)
INFO - root - 2017-12-17 03:22:21.699964: step 9360, loss = 0.34, batch loss = 0.26 (33.9 examples/sec; 0.236 sec/batch; 21h:12m:23s remains)
INFO - root - 2017-12-17 03:22:23.988480: step 9370, loss = 0.24, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 20h:22m:29s remains)
INFO - root - 2017-12-17 03:22:26.298776: step 9380, loss = 0.29, batch loss = 0.20 (35.9 examples/sec; 0.223 sec/batch; 19h:58m:42s remains)
INFO - root - 2017-12-17 03:22:28.552013: step 9390, loss = 0.22, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 20h:35m:48s remains)
INFO - root - 2017-12-17 03:22:30.853004: step 9400, loss = 0.23, batch loss = 0.15 (36.3 examples/sec; 0.221 sec/batch; 19h:48m:19s remains)
INFO - root - 2017-12-17 03:22:33.247787: step 9410, loss = 0.32, batch loss = 0.23 (33.2 examples/sec; 0.241 sec/batch; 21h:36m:37s remains)
INFO - root - 2017-12-17 03:22:35.528101: step 9420, loss = 0.28, batch loss = 0.20 (35.7 examples/sec; 0.224 sec/batch; 20h:05m:20s remains)
INFO - root - 2017-12-17 03:22:37.829090: step 9430, loss = 0.24, batch loss = 0.15 (34.4 examples/sec; 0.233 sec/batch; 20h:52m:23s remains)
INFO - root - 2017-12-17 03:22:40.116526: step 9440, loss = 0.26, batch loss = 0.17 (35.8 examples/sec; 0.224 sec/batch; 20h:03m:27s remains)
INFO - root - 2017-12-17 03:22:42.409948: step 9450, loss = 0.25, batch loss = 0.17 (35.2 examples/sec; 0.227 sec/batch; 20h:21m:57s remains)
INFO - root - 2017-12-17 03:22:44.706915: step 9460, loss = 0.25, batch loss = 0.16 (35.5 examples/sec; 0.225 sec/batch; 20h:13m:21s remains)
INFO - root - 2017-12-17 03:22:46.962027: step 9470, loss = 0.28, batch loss = 0.19 (35.1 examples/sec; 0.228 sec/batch; 20h:27m:28s remains)
INFO - root - 2017-12-17 03:22:49.207148: step 9480, loss = 0.24, batch loss = 0.16 (35.2 examples/sec; 0.227 sec/batch; 20h:24m:12s remains)
INFO - root - 2017-12-17 03:22:51.514378: step 9490, loss = 0.22, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 20h:04m:51s remains)
INFO - root - 2017-12-17 03:22:53.759483: step 9500, loss = 0.27, batch loss = 0.18 (35.8 examples/sec; 0.224 sec/batch; 20h:03m:47s remains)
INFO - root - 2017-12-17 03:22:56.115011: step 9510, loss = 0.26, batch loss = 0.17 (36.8 examples/sec; 0.217 sec/batch; 19h:30m:21s remains)
INFO - root - 2017-12-17 03:22:58.337637: step 9520, loss = 0.29, batch loss = 0.21 (36.3 examples/sec; 0.220 sec/batch; 19h:44m:43s remains)
INFO - root - 2017-12-17 03:23:00.628881: step 9530, loss = 0.24, batch loss = 0.16 (36.0 examples/sec; 0.222 sec/batch; 19h:55m:17s remains)
INFO - root - 2017-12-17 03:23:02.896748: step 9540, loss = 0.33, batch loss = 0.25 (35.6 examples/sec; 0.225 sec/batch; 20h:09m:17s remains)
INFO - root - 2017-12-17 03:23:05.134696: step 9550, loss = 0.46, batch loss = 0.37 (35.7 examples/sec; 0.224 sec/batch; 20h:04m:39s remains)
INFO - root - 2017-12-17 03:23:07.406513: step 9560, loss = 0.23, batch loss = 0.15 (34.6 examples/sec; 0.231 sec/batch; 20h:43m:18s remains)
INFO - root - 2017-12-17 03:23:09.690842: step 9570, loss = 0.37, batch loss = 0.28 (35.2 examples/sec; 0.227 sec/batch; 20h:22m:48s remains)
INFO - root - 2017-12-17 03:23:11.998217: step 9580, loss = 0.28, batch loss = 0.19 (35.3 examples/sec; 0.226 sec/batch; 20h:18m:45s remains)
INFO - root - 2017-12-17 03:23:14.234865: step 9590, loss = 0.30, batch loss = 0.21 (35.5 examples/sec; 0.225 sec/batch; 20h:12m:42s remains)
INFO - root - 2017-12-17 03:23:16.494194: step 9600, loss = 0.22, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 20h:10m:26s remains)
INFO - root - 2017-12-17 03:23:18.897476: step 9610, loss = 0.27, batch loss = 0.18 (36.2 examples/sec; 0.221 sec/batch; 19h:49m:15s remains)
INFO - root - 2017-12-17 03:23:21.170156: step 9620, loss = 0.25, batch loss = 0.17 (36.0 examples/sec; 0.222 sec/batch; 19h:55m:20s remains)
INFO - root - 2017-12-17 03:23:23.472770: step 9630, loss = 0.24, batch loss = 0.16 (34.4 examples/sec; 0.233 sec/batch; 20h:53m:02s remains)
INFO - root - 2017-12-17 03:23:25.738596: step 9640, loss = 0.30, batch loss = 0.22 (34.9 examples/sec; 0.229 sec/batch; 20h:33m:11s remains)
INFO - root - 2017-12-17 03:23:27.990439: step 9650, loss = 0.39, batch loss = 0.30 (35.2 examples/sec; 0.228 sec/batch; 20h:24m:10s remains)
INFO - root - 2017-12-17 03:23:30.274380: step 9660, loss = 0.26, batch loss = 0.18 (34.6 examples/sec; 0.231 sec/batch; 20h:44m:38s remains)
INFO - root - 2017-12-17 03:23:32.546301: step 9670, loss = 0.34, batch loss = 0.26 (35.8 examples/sec; 0.224 sec/batch; 20h:03m:42s remains)
INFO - root - 2017-12-17 03:23:34.788802: step 9680, loss = 0.22, batch loss = 0.14 (36.1 examples/sec; 0.221 sec/batch; 19h:50m:42s remains)
INFO - root - 2017-12-17 03:23:37.078545: step 9690, loss = 0.25, batch loss = 0.17 (33.9 examples/sec; 0.236 sec/batch; 21h:09m:02s remains)
INFO - root - 2017-12-17 03:23:39.411456: step 9700, loss = 0.27, batch loss = 0.18 (33.1 examples/sec; 0.241 sec/batch; 21h:38m:30s remains)
INFO - root - 2017-12-17 03:23:41.824928: step 9710, loss = 0.23, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 20h:36m:53s remains)
INFO - root - 2017-12-17 03:23:44.120322: step 9720, loss = 0.32, batch loss = 0.24 (35.3 examples/sec; 0.227 sec/batch; 20h:20m:44s remains)
INFO - root - 2017-12-17 03:23:46.424270: step 9730, loss = 0.26, batch loss = 0.18 (34.1 examples/sec; 0.234 sec/batch; 21h:00m:31s remains)
INFO - root - 2017-12-17 03:23:48.699257: step 9740, loss = 0.22, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 20h:01m:51s remains)
INFO - root - 2017-12-17 03:23:50.974085: step 9750, loss = 0.26, batch loss = 0.18 (36.1 examples/sec; 0.221 sec/batch; 19h:50m:43s remains)
INFO - root - 2017-12-17 03:23:53.249621: step 9760, loss = 0.26, batch loss = 0.18 (34.0 examples/sec; 0.235 sec/batch; 21h:04m:59s remains)
INFO - root - 2017-12-17 03:23:55.530048: step 9770, loss = 0.22, batch loss = 0.13 (33.3 examples/sec; 0.240 sec/batch; 21h:31m:01s remains)
INFO - root - 2017-12-17 03:23:57.792924: step 9780, loss = 0.20, batch loss = 0.11 (36.4 examples/sec; 0.219 sec/batch; 19h:40m:34s remains)
INFO - root - 2017-12-17 03:24:00.040285: step 9790, loss = 0.27, batch loss = 0.18 (35.6 examples/sec; 0.225 sec/batch; 20h:09m:00s remains)
INFO - root - 2017-12-17 03:24:02.289103: step 9800, loss = 0.24, batch loss = 0.15 (35.8 examples/sec; 0.223 sec/batch; 20h:01m:00s remains)
INFO - root - 2017-12-17 03:24:04.675570: step 9810, loss = 0.24, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 19h:48m:13s remains)
INFO - root - 2017-12-17 03:24:06.946726: step 9820, loss = 0.29, batch loss = 0.21 (36.7 examples/sec; 0.218 sec/batch; 19h:33m:04s remains)
INFO - root - 2017-12-17 03:24:09.179609: step 9830, loss = 0.26, batch loss = 0.17 (34.8 examples/sec; 0.230 sec/batch; 20h:35m:41s remains)
INFO - root - 2017-12-17 03:24:11.452122: step 9840, loss = 0.24, batch loss = 0.15 (35.6 examples/sec; 0.225 sec/batch; 20h:07m:32s remains)
INFO - root - 2017-12-17 03:24:13.709278: step 9850, loss = 0.29, batch loss = 0.21 (36.0 examples/sec; 0.222 sec/batch; 19h:55m:19s remains)
INFO - root - 2017-12-17 03:24:15.988466: step 9860, loss = 0.38, batch loss = 0.30 (36.1 examples/sec; 0.222 sec/batch; 19h:51m:18s remains)
INFO - root - 2017-12-17 03:24:18.300666: step 9870, loss = 0.21, batch loss = 0.13 (33.9 examples/sec; 0.236 sec/batch; 21h:09m:14s remains)
INFO - root - 2017-12-17 03:24:20.592658: step 9880, loss = 0.27, batch loss = 0.18 (36.7 examples/sec; 0.218 sec/batch; 19h:31m:56s remains)
INFO - root - 2017-12-17 03:24:22.846561: step 9890, loss = 0.22, batch loss = 0.14 (36.1 examples/sec; 0.222 sec/batch; 19h:52m:45s remains)
INFO - root - 2017-12-17 03:24:25.140413: step 9900, loss = 0.24, batch loss = 0.16 (34.1 examples/sec; 0.235 sec/batch; 21h:02m:18s remains)
INFO - root - 2017-12-17 03:24:27.575607: step 9910, loss = 0.21, batch loss = 0.13 (36.5 examples/sec; 0.219 sec/batch; 19h:38m:40s remains)
INFO - root - 2017-12-17 03:24:29.824777: step 9920, loss = 0.25, batch loss = 0.17 (35.5 examples/sec; 0.226 sec/batch; 20h:12m:27s remains)
INFO - root - 2017-12-17 03:24:32.102299: step 9930, loss = 0.20, batch loss = 0.12 (33.3 examples/sec; 0.240 sec/batch; 21h:30m:36s remains)
INFO - root - 2017-12-17 03:24:34.361999: step 9940, loss = 0.26, batch loss = 0.17 (35.7 examples/sec; 0.224 sec/batch; 20h:04m:05s remains)
INFO - root - 2017-12-17 03:24:36.627820: step 9950, loss = 0.30, batch loss = 0.21 (35.4 examples/sec; 0.226 sec/batch; 20h:14m:59s remains)
INFO - root - 2017-12-17 03:24:38.897434: step 9960, loss = 0.28, batch loss = 0.19 (33.6 examples/sec; 0.238 sec/batch; 21h:19m:34s remains)
INFO - root - 2017-12-17 03:24:41.162581: step 9970, loss = 0.30, batch loss = 0.22 (36.3 examples/sec; 0.220 sec/batch; 19h:44m:24s remains)
INFO - root - 2017-12-17 03:24:43.436332: step 9980, loss = 0.28, batch loss = 0.20 (35.7 examples/sec; 0.224 sec/batch; 20h:03m:10s remains)
INFO - root - 2017-12-17 03:24:45.685354: step 9990, loss = 0.25, batch loss = 0.16 (35.4 examples/sec; 0.226 sec/batch; 20h:14m:01s remains)
INFO - root - 2017-12-17 03:24:47.970606: step 10000, loss = 0.31, batch loss = 0.23 (35.1 examples/sec; 0.228 sec/batch; 20h:26m:09s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-10000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-10000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 03:24:50.830552: step 10010, loss = 0.25, batch loss = 0.16 (36.1 examples/sec; 0.222 sec/batch; 19h:52m:30s remains)
INFO - root - 2017-12-17 03:24:53.112263: step 10020, loss = 0.22, batch loss = 0.14 (35.3 examples/sec; 0.227 sec/batch; 20h:19m:32s remains)
INFO - root - 2017-12-17 03:24:55.364507: step 10030, loss = 0.22, batch loss = 0.14 (34.0 examples/sec; 0.235 sec/batch; 21h:05m:33s remains)
INFO - root - 2017-12-17 03:24:57.639057: step 10040, loss = 0.27, batch loss = 0.19 (35.8 examples/sec; 0.223 sec/batch; 20h:00m:01s remains)
INFO - root - 2017-12-17 03:24:59.877807: step 10050, loss = 0.24, batch loss = 0.16 (35.6 examples/sec; 0.225 sec/batch; 20h:08m:47s remains)
INFO - root - 2017-12-17 03:25:02.114254: step 10060, loss = 0.27, batch loss = 0.19 (35.6 examples/sec; 0.225 sec/batch; 20h:06m:46s remains)
INFO - root - 2017-12-17 03:25:04.358068: step 10070, loss = 0.27, batch loss = 0.19 (36.2 examples/sec; 0.221 sec/batch; 19h:46m:04s remains)
INFO - root - 2017-12-17 03:25:06.600281: step 10080, loss = 0.23, batch loss = 0.15 (35.0 examples/sec; 0.229 sec/batch; 20h:28m:13s remains)
INFO - root - 2017-12-17 03:25:08.878605: step 10090, loss = 0.24, batch loss = 0.16 (35.3 examples/sec; 0.226 sec/batch; 20h:16m:29s remains)
INFO - root - 2017-12-17 03:25:11.117978: step 10100, loss = 0.26, batch loss = 0.18 (35.0 examples/sec; 0.229 sec/batch; 20h:28m:37s remains)
INFO - root - 2017-12-17 03:25:13.482859: step 10110, loss = 0.24, batch loss = 0.16 (36.8 examples/sec; 0.217 sec/batch; 19h:28m:32s remains)
INFO - root - 2017-12-17 03:25:15.752924: step 10120, loss = 0.27, batch loss = 0.19 (34.4 examples/sec; 0.233 sec/batch; 20h:49m:47s remains)
INFO - root - 2017-12-17 03:25:18.033403: step 10130, loss = 0.24, batch loss = 0.15 (37.3 examples/sec; 0.214 sec/batch; 19h:11m:56s remains)
INFO - root - 2017-12-17 03:25:20.298554: step 10140, loss = 0.35, batch loss = 0.27 (36.2 examples/sec; 0.221 sec/batch; 19h:48m:14s remains)
INFO - root - 2017-12-17 03:25:22.552243: step 10150, loss = 0.25, batch loss = 0.17 (35.7 examples/sec; 0.224 sec/batch; 20h:02m:48s remains)
INFO - root - 2017-12-17 03:25:24.813119: step 10160, loss = 0.28, batch loss = 0.20 (36.1 examples/sec; 0.221 sec/batch; 19h:48m:54s remains)
INFO - root - 2017-12-17 03:25:27.045532: step 10170, loss = 0.23, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 20h:20m:42s remains)
INFO - root - 2017-12-17 03:25:29.290891: step 10180, loss = 0.24, batch loss = 0.16 (34.4 examples/sec; 0.232 sec/batch; 20h:48m:15s remains)
INFO - root - 2017-12-17 03:25:31.514835: step 10190, loss = 0.23, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 19h:36m:29s remains)
INFO - root - 2017-12-17 03:25:33.758460: step 10200, loss = 0.19, batch loss = 0.10 (34.5 examples/sec; 0.232 sec/batch; 20h:44m:56s remains)
INFO - root - 2017-12-17 03:25:36.116657: step 10210, loss = 0.22, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 20h:30m:35s remains)
INFO - root - 2017-12-17 03:25:38.359616: step 10220, loss = 0.29, batch loss = 0.21 (35.2 examples/sec; 0.227 sec/batch; 20h:20m:09s remains)
INFO - root - 2017-12-17 03:25:40.589962: step 10230, loss = 0.31, batch loss = 0.23 (35.1 examples/sec; 0.228 sec/batch; 20h:22m:48s remains)
INFO - root - 2017-12-17 03:25:42.826064: step 10240, loss = 0.22, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 19h:38m:44s remains)
INFO - root - 2017-12-17 03:25:45.077648: step 10250, loss = 0.23, batch loss = 0.15 (36.1 examples/sec; 0.222 sec/batch; 19h:50m:03s remains)
INFO - root - 2017-12-17 03:25:47.327557: step 10260, loss = 0.26, batch loss = 0.18 (34.9 examples/sec; 0.229 sec/batch; 20h:29m:30s remains)
INFO - root - 2017-12-17 03:25:49.632589: step 10270, loss = 0.27, batch loss = 0.18 (35.9 examples/sec; 0.223 sec/batch; 19h:57m:22s remains)
INFO - root - 2017-12-17 03:25:51.866492: step 10280, loss = 0.27, batch loss = 0.19 (35.3 examples/sec; 0.227 sec/batch; 20h:16m:23s remains)
INFO - root - 2017-12-17 03:25:54.070911: step 10290, loss = 0.22, batch loss = 0.14 (36.6 examples/sec; 0.219 sec/batch; 19h:34m:29s remains)
INFO - root - 2017-12-17 03:25:56.308707: step 10300, loss = 0.24, batch loss = 0.16 (36.5 examples/sec; 0.219 sec/batch; 19h:37m:38s remains)
INFO - root - 2017-12-17 03:25:58.682727: step 10310, loss = 0.25, batch loss = 0.16 (35.4 examples/sec; 0.226 sec/batch; 20h:13m:05s remains)
INFO - root - 2017-12-17 03:26:00.937588: step 10320, loss = 0.23, batch loss = 0.15 (35.8 examples/sec; 0.224 sec/batch; 20h:00m:08s remains)
INFO - root - 2017-12-17 03:26:03.198247: step 10330, loss = 0.24, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 19h:55m:51s remains)
INFO - root - 2017-12-17 03:26:05.441078: step 10340, loss = 0.33, batch loss = 0.25 (35.8 examples/sec; 0.223 sec/batch; 19h:58m:12s remains)
INFO - root - 2017-12-17 03:26:07.685289: step 10350, loss = 0.31, batch loss = 0.23 (34.3 examples/sec; 0.233 sec/batch; 20h:52m:33s remains)
INFO - root - 2017-12-17 03:26:09.925511: step 10360, loss = 0.22, batch loss = 0.13 (35.8 examples/sec; 0.224 sec/batch; 20h:00m:24s remains)
INFO - root - 2017-12-17 03:26:12.162694: step 10370, loss = 0.22, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 20h:05m:21s remains)
INFO - root - 2017-12-17 03:26:14.446253: step 10380, loss = 0.21, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 19h:59m:20s remains)
INFO - root - 2017-12-17 03:26:16.678610: step 10390, loss = 0.22, batch loss = 0.14 (35.5 examples/sec; 0.225 sec/batch; 20h:09m:33s remains)
INFO - root - 2017-12-17 03:26:18.957147: step 10400, loss = 0.22, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 19h:45m:57s remains)
INFO - root - 2017-12-17 03:26:21.350309: step 10410, loss = 0.24, batch loss = 0.16 (36.3 examples/sec; 0.220 sec/batch; 19h:43m:14s remains)
INFO - root - 2017-12-17 03:26:23.587904: step 10420, loss = 0.22, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 20h:02m:22s remains)
INFO - root - 2017-12-17 03:26:25.849922: step 10430, loss = 0.20, batch loss = 0.11 (34.7 examples/sec; 0.230 sec/batch; 20h:36m:44s remains)
INFO - root - 2017-12-17 03:26:28.126951: step 10440, loss = 0.24, batch loss = 0.16 (33.1 examples/sec; 0.242 sec/batch; 21h:38m:13s remains)
INFO - root - 2017-12-17 03:26:30.377109: step 10450, loss = 0.21, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 20h:06m:56s remains)
INFO - root - 2017-12-17 03:26:32.637302: step 10460, loss = 0.22, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 19h:45m:18s remains)
INFO - root - 2017-12-17 03:26:34.895847: step 10470, loss = 0.21, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 20h:26m:30s remains)
INFO - root - 2017-12-17 03:26:37.165715: step 10480, loss = 0.32, batch loss = 0.24 (35.6 examples/sec; 0.225 sec/batch; 20h:05m:29s remains)
INFO - root - 2017-12-17 03:26:39.406262: step 10490, loss = 0.20, batch loss = 0.12 (33.8 examples/sec; 0.237 sec/batch; 21h:10m:04s remains)
INFO - root - 2017-12-17 03:26:41.669476: step 10500, loss = 0.26, batch loss = 0.18 (34.5 examples/sec; 0.232 sec/batch; 20h:44m:43s remains)
INFO - root - 2017-12-17 03:26:44.024276: step 10510, loss = 0.20, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 19h:52m:37s remains)
INFO - root - 2017-12-17 03:26:46.285087: step 10520, loss = 0.28, batch loss = 0.20 (35.1 examples/sec; 0.228 sec/batch; 20h:22m:01s remains)
INFO - root - 2017-12-17 03:26:48.517824: step 10530, loss = 0.22, batch loss = 0.14 (36.8 examples/sec; 0.218 sec/batch; 19h:28m:02s remains)
INFO - root - 2017-12-17 03:26:50.789639: step 10540, loss = 0.23, batch loss = 0.15 (34.2 examples/sec; 0.234 sec/batch; 20h:55m:11s remains)
INFO - root - 2017-12-17 03:26:53.060935: step 10550, loss = 0.21, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 19h:47m:00s remains)
INFO - root - 2017-12-17 03:26:55.295071: step 10560, loss = 0.22, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 19h:56m:49s remains)
INFO - root - 2017-12-17 03:26:57.561955: step 10570, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.224 sec/batch; 19h:59m:13s remains)
INFO - root - 2017-12-17 03:26:59.812146: step 10580, loss = 0.21, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 20h:15m:33s remains)
INFO - root - 2017-12-17 03:27:02.086374: step 10590, loss = 0.25, batch loss = 0.17 (35.4 examples/sec; 0.226 sec/batch; 20h:11m:45s remains)
INFO - root - 2017-12-17 03:27:04.381300: step 10600, loss = 0.27, batch loss = 0.19 (36.0 examples/sec; 0.222 sec/batch; 19h:53m:39s remains)
INFO - root - 2017-12-17 03:27:06.754739: step 10610, loss = 0.19, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 19h:45m:59s remains)
INFO - root - 2017-12-17 03:27:09.073282: step 10620, loss = 0.23, batch loss = 0.15 (33.3 examples/sec; 0.240 sec/batch; 21h:29m:16s remains)
INFO - root - 2017-12-17 03:27:11.333719: step 10630, loss = 0.22, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 19h:34m:56s remains)
INFO - root - 2017-12-17 03:27:13.607924: step 10640, loss = 0.23, batch loss = 0.15 (36.5 examples/sec; 0.219 sec/batch; 19h:36m:02s remains)
INFO - root - 2017-12-17 03:27:15.867610: step 10650, loss = 0.23, batch loss = 0.15 (35.0 examples/sec; 0.228 sec/batch; 20h:24m:27s remains)
INFO - root - 2017-12-17 03:27:18.120092: step 10660, loss = 0.18, batch loss = 0.10 (34.1 examples/sec; 0.235 sec/batch; 20h:59m:48s remains)
INFO - root - 2017-12-17 03:27:20.391839: step 10670, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 20h:12m:47s remains)
INFO - root - 2017-12-17 03:27:22.642622: step 10680, loss = 0.25, batch loss = 0.17 (36.0 examples/sec; 0.223 sec/batch; 19h:53m:28s remains)
INFO - root - 2017-12-17 03:27:24.890536: step 10690, loss = 0.22, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 19h:51m:15s remains)
INFO - root - 2017-12-17 03:27:27.141444: step 10700, loss = 0.20, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 19h:54m:41s remains)
INFO - root - 2017-12-17 03:27:29.566355: step 10710, loss = 0.23, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 20h:13m:02s remains)
INFO - root - 2017-12-17 03:27:31.834441: step 10720, loss = 0.22, batch loss = 0.14 (34.7 examples/sec; 0.231 sec/batch; 20h:36m:18s remains)
INFO - root - 2017-12-17 03:27:34.063561: step 10730, loss = 0.25, batch loss = 0.17 (36.0 examples/sec; 0.223 sec/batch; 19h:53m:15s remains)
INFO - root - 2017-12-17 03:27:36.327539: step 10740, loss = 0.26, batch loss = 0.18 (36.3 examples/sec; 0.220 sec/batch; 19h:41m:08s remains)
INFO - root - 2017-12-17 03:27:38.576084: step 10750, loss = 0.23, batch loss = 0.15 (34.8 examples/sec; 0.230 sec/batch; 20h:34m:03s remains)
INFO - root - 2017-12-17 03:27:40.831229: step 10760, loss = 0.20, batch loss = 0.12 (34.4 examples/sec; 0.233 sec/batch; 20h:47m:42s remains)
INFO - root - 2017-12-17 03:27:43.093479: step 10770, loss = 0.26, batch loss = 0.17 (35.5 examples/sec; 0.225 sec/batch; 20h:07m:38s remains)
INFO - root - 2017-12-17 03:27:45.329362: step 10780, loss = 0.21, batch loss = 0.13 (34.7 examples/sec; 0.231 sec/batch; 20h:37m:48s remains)
INFO - root - 2017-12-17 03:27:47.600592: step 10790, loss = 0.23, batch loss = 0.14 (36.4 examples/sec; 0.220 sec/batch; 19h:38m:13s remains)
INFO - root - 2017-12-17 03:27:49.895471: step 10800, loss = 0.22, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 20h:29m:24s remains)
INFO - root - 2017-12-17 03:27:52.293577: step 10810, loss = 0.24, batch loss = 0.16 (34.7 examples/sec; 0.230 sec/batch; 20h:34m:30s remains)
INFO - root - 2017-12-17 03:27:54.531020: step 10820, loss = 0.23, batch loss = 0.15 (35.7 examples/sec; 0.224 sec/batch; 20h:00m:11s remains)
INFO - root - 2017-12-17 03:27:56.803749: step 10830, loss = 0.27, batch loss = 0.19 (35.9 examples/sec; 0.223 sec/batch; 19h:55m:26s remains)
INFO - root - 2017-12-17 03:27:59.053705: step 10840, loss = 0.24, batch loss = 0.16 (37.0 examples/sec; 0.216 sec/batch; 19h:18m:54s remains)
INFO - root - 2017-12-17 03:28:01.324232: step 10850, loss = 0.20, batch loss = 0.12 (34.4 examples/sec; 0.232 sec/batch; 20h:45m:49s remains)
INFO - root - 2017-12-17 03:28:03.549685: step 10860, loss = 0.24, batch loss = 0.16 (34.5 examples/sec; 0.232 sec/batch; 20h:41m:56s remains)
INFO - root - 2017-12-17 03:28:05.822989: step 10870, loss = 0.26, batch loss = 0.18 (35.2 examples/sec; 0.227 sec/batch; 20h:16m:43s remains)
INFO - root - 2017-12-17 03:28:08.091829: step 10880, loss = 0.23, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 20h:22m:18s remains)
INFO - root - 2017-12-17 03:28:10.334663: step 10890, loss = 0.20, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 20h:27m:21s remains)
INFO - root - 2017-12-17 03:28:12.601267: step 10900, loss = 0.20, batch loss = 0.12 (34.2 examples/sec; 0.234 sec/batch; 20h:55m:26s remains)
INFO - root - 2017-12-17 03:28:15.002672: step 10910, loss = 0.20, batch loss = 0.12 (36.1 examples/sec; 0.221 sec/batch; 19h:46m:43s remains)
INFO - root - 2017-12-17 03:28:17.255786: step 10920, loss = 0.21, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 19h:57m:20s remains)
INFO - root - 2017-12-17 03:28:19.478640: step 10930, loss = 0.21, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 20h:33m:38s remains)
INFO - root - 2017-12-17 03:28:21.737498: step 10940, loss = 0.23, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 19h:43m:22s remains)
INFO - root - 2017-12-17 03:28:23.980208: step 10950, loss = 0.21, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 20h:15m:03s remains)
INFO - root - 2017-12-17 03:28:26.232905: step 10960, loss = 0.19, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 19h:33m:24s remains)
INFO - root - 2017-12-17 03:28:28.483441: step 10970, loss = 0.22, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 20h:40m:17s remains)
INFO - root - 2017-12-17 03:28:30.701220: step 10980, loss = 0.22, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 20h:07m:59s remains)
INFO - root - 2017-12-17 03:28:32.938887: step 10990, loss = 0.26, batch loss = 0.18 (35.6 examples/sec; 0.225 sec/batch; 20h:03m:18s remains)
INFO - root - 2017-12-17 03:28:35.163242: step 11000, loss = 0.22, batch loss = 0.13 (37.0 examples/sec; 0.216 sec/batch; 19h:17m:37s remains)
INFO - root - 2017-12-17 03:28:37.544268: step 11010, loss = 0.22, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 20h:39m:20s remains)
INFO - root - 2017-12-17 03:28:39.822110: step 11020, loss = 0.28, batch loss = 0.20 (35.7 examples/sec; 0.224 sec/batch; 20h:00m:56s remains)
INFO - root - 2017-12-17 03:28:42.072056: step 11030, loss = 0.23, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 20h:10m:34s remains)
INFO - root - 2017-12-17 03:28:44.327532: step 11040, loss = 0.25, batch loss = 0.17 (36.8 examples/sec; 0.217 sec/batch; 19h:24m:18s remains)
INFO - root - 2017-12-17 03:28:46.617546: step 11050, loss = 0.24, batch loss = 0.16 (35.7 examples/sec; 0.224 sec/batch; 20h:00m:32s remains)
INFO - root - 2017-12-17 03:28:48.858856: step 11060, loss = 0.21, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 19h:42m:46s remains)
INFO - root - 2017-12-17 03:28:51.129739: step 11070, loss = 0.23, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 20h:17m:10s remains)
INFO - root - 2017-12-17 03:28:53.400860: step 11080, loss = 0.24, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 19h:43m:36s remains)
INFO - root - 2017-12-17 03:28:55.673746: step 11090, loss = 0.22, batch loss = 0.14 (35.2 examples/sec; 0.227 sec/batch; 20h:18m:21s remains)
INFO - root - 2017-12-17 03:28:57.927888: step 11100, loss = 0.21, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 19h:50m:01s remains)
INFO - root - 2017-12-17 03:29:00.318763: step 11110, loss = 0.23, batch loss = 0.15 (34.8 examples/sec; 0.230 sec/batch; 20h:32m:09s remains)
INFO - root - 2017-12-17 03:29:02.574840: step 11120, loss = 0.19, batch loss = 0.11 (36.7 examples/sec; 0.218 sec/batch; 19h:28m:35s remains)
INFO - root - 2017-12-17 03:29:04.853276: step 11130, loss = 0.25, batch loss = 0.17 (34.6 examples/sec; 0.232 sec/batch; 20h:39m:58s remains)
INFO - root - 2017-12-17 03:29:07.143635: step 11140, loss = 0.25, batch loss = 0.17 (36.1 examples/sec; 0.221 sec/batch; 19h:45m:26s remains)
INFO - root - 2017-12-17 03:29:09.403052: step 11150, loss = 0.23, batch loss = 0.15 (34.9 examples/sec; 0.229 sec/batch; 20h:27m:36s remains)
INFO - root - 2017-12-17 03:29:11.637921: step 11160, loss = 0.19, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 19h:48m:39s remains)
INFO - root - 2017-12-17 03:29:13.897578: step 11170, loss = 0.19, batch loss = 0.11 (36.9 examples/sec; 0.217 sec/batch; 19h:19m:36s remains)
INFO - root - 2017-12-17 03:29:16.134338: step 11180, loss = 0.21, batch loss = 0.13 (36.9 examples/sec; 0.217 sec/batch; 19h:20m:59s remains)
INFO - root - 2017-12-17 03:29:18.416098: step 11190, loss = 0.26, batch loss = 0.18 (33.7 examples/sec; 0.238 sec/batch; 21h:12m:30s remains)
INFO - root - 2017-12-17 03:29:20.662496: step 11200, loss = 0.21, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 20h:04m:49s remains)
INFO - root - 2017-12-17 03:29:23.059813: step 11210, loss = 0.24, batch loss = 0.15 (34.8 examples/sec; 0.230 sec/batch; 20h:29m:43s remains)
INFO - root - 2017-12-17 03:29:25.304377: step 11220, loss = 0.23, batch loss = 0.14 (34.3 examples/sec; 0.233 sec/batch; 20h:50m:02s remains)
INFO - root - 2017-12-17 03:29:27.571471: step 11230, loss = 0.23, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 19h:53m:12s remains)
INFO - root - 2017-12-17 03:29:29.838584: step 11240, loss = 0.21, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 19h:39m:59s remains)
INFO - root - 2017-12-17 03:29:32.102662: step 11250, loss = 0.23, batch loss = 0.15 (35.0 examples/sec; 0.229 sec/batch; 20h:25m:14s remains)
INFO - root - 2017-12-17 03:29:34.354378: step 11260, loss = 0.23, batch loss = 0.15 (34.6 examples/sec; 0.231 sec/batch; 20h:37m:58s remains)
INFO - root - 2017-12-17 03:29:36.600113: step 11270, loss = 0.22, batch loss = 0.14 (36.6 examples/sec; 0.218 sec/batch; 19h:29m:28s remains)
INFO - root - 2017-12-17 03:29:38.867581: step 11280, loss = 0.18, batch loss = 0.10 (33.8 examples/sec; 0.237 sec/batch; 21h:07m:26s remains)
INFO - root - 2017-12-17 03:29:41.152957: step 11290, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 20h:27m:09s remains)
INFO - root - 2017-12-17 03:29:43.395694: step 11300, loss = 0.22, batch loss = 0.14 (34.7 examples/sec; 0.231 sec/batch; 20h:34m:55s remains)
INFO - root - 2017-12-17 03:29:45.833678: step 11310, loss = 0.24, batch loss = 0.16 (35.3 examples/sec; 0.226 sec/batch; 20h:12m:29s remains)
INFO - root - 2017-12-17 03:29:48.077521: step 11320, loss = 0.20, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 20h:04m:03s remains)
INFO - root - 2017-12-17 03:29:50.350360: step 11330, loss = 0.22, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 20h:02m:54s remains)
INFO - root - 2017-12-17 03:29:52.653238: step 11340, loss = 0.19, batch loss = 0.11 (33.9 examples/sec; 0.236 sec/batch; 21h:04m:49s remains)
INFO - root - 2017-12-17 03:29:54.941815: step 11350, loss = 0.20, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 20h:36m:23s remains)
INFO - root - 2017-12-17 03:29:57.212708: step 11360, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.223 sec/batch; 19h:54m:29s remains)
INFO - root - 2017-12-17 03:29:59.435053: step 11370, loss = 0.26, batch loss = 0.17 (34.6 examples/sec; 0.231 sec/batch; 20h:37m:21s remains)
INFO - root - 2017-12-17 03:30:01.697777: step 11380, loss = 0.26, batch loss = 0.18 (34.7 examples/sec; 0.230 sec/batch; 20h:32m:50s remains)
INFO - root - 2017-12-17 03:30:03.965516: step 11390, loss = 0.23, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 20h:19m:40s remains)
INFO - root - 2017-12-17 03:30:06.209362: step 11400, loss = 0.23, batch loss = 0.15 (34.4 examples/sec; 0.232 sec/batch; 20h:42m:57s remains)
INFO - root - 2017-12-17 03:30:08.610096: step 11410, loss = 0.28, batch loss = 0.20 (36.1 examples/sec; 0.222 sec/batch; 19h:46m:07s remains)
INFO - root - 2017-12-17 03:30:10.857460: step 11420, loss = 0.24, batch loss = 0.16 (35.6 examples/sec; 0.225 sec/batch; 20h:03m:12s remains)
INFO - root - 2017-12-17 03:30:13.117618: step 11430, loss = 0.23, batch loss = 0.15 (34.6 examples/sec; 0.231 sec/batch; 20h:38m:34s remains)
INFO - root - 2017-12-17 03:30:15.386605: step 11440, loss = 0.25, batch loss = 0.17 (35.8 examples/sec; 0.223 sec/batch; 19h:54m:53s remains)
INFO - root - 2017-12-17 03:30:17.678019: step 11450, loss = 0.29, batch loss = 0.20 (34.4 examples/sec; 0.233 sec/batch; 20h:45m:15s remains)
INFO - root - 2017-12-17 03:30:19.916575: step 11460, loss = 0.20, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 19h:42m:26s remains)
INFO - root - 2017-12-17 03:30:22.188890: step 11470, loss = 0.21, batch loss = 0.12 (34.1 examples/sec; 0.235 sec/batch; 20h:54m:50s remains)
INFO - root - 2017-12-17 03:30:24.445789: step 11480, loss = 0.21, batch loss = 0.13 (35.0 examples/sec; 0.228 sec/batch; 20h:22m:09s remains)
INFO - root - 2017-12-17 03:30:26.665408: step 11490, loss = 0.21, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 19h:43m:15s remains)
INFO - root - 2017-12-17 03:30:28.925148: step 11500, loss = 0.22, batch loss = 0.14 (35.0 examples/sec; 0.229 sec/batch; 20h:22m:37s remains)
INFO - root - 2017-12-17 03:30:31.308084: step 11510, loss = 0.22, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 19h:58m:32s remains)
INFO - root - 2017-12-17 03:30:33.562434: step 11520, loss = 0.28, batch loss = 0.20 (35.6 examples/sec; 0.225 sec/batch; 20h:01m:22s remains)
INFO - root - 2017-12-17 03:30:35.831433: step 11530, loss = 0.18, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 19h:33m:53s remains)
INFO - root - 2017-12-17 03:30:38.078803: step 11540, loss = 0.24, batch loss = 0.16 (36.4 examples/sec; 0.220 sec/batch; 19h:35m:35s remains)
INFO - root - 2017-12-17 03:30:40.326268: step 11550, loss = 0.22, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 19h:47m:03s remains)
INFO - root - 2017-12-17 03:30:42.591380: step 11560, loss = 0.19, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 20h:20m:22s remains)
INFO - root - 2017-12-17 03:30:44.830657: step 11570, loss = 0.22, batch loss = 0.14 (35.5 examples/sec; 0.225 sec/batch; 20h:03m:56s remains)
INFO - root - 2017-12-17 03:30:47.077485: step 11580, loss = 0.21, batch loss = 0.13 (36.3 examples/sec; 0.221 sec/batch; 19h:40m:20s remains)
INFO - root - 2017-12-17 03:30:49.322219: step 11590, loss = 0.29, batch loss = 0.21 (35.5 examples/sec; 0.225 sec/batch; 20h:04m:49s remains)
INFO - root - 2017-12-17 03:30:51.611081: step 11600, loss = 0.22, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 20h:12m:23s remains)
INFO - root - 2017-12-17 03:30:54.011497: step 11610, loss = 0.19, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 20h:10m:09s remains)
INFO - root - 2017-12-17 03:30:56.230462: step 11620, loss = 0.23, batch loss = 0.15 (35.8 examples/sec; 0.224 sec/batch; 19h:56m:31s remains)
INFO - root - 2017-12-17 03:30:58.507790: step 11630, loss = 0.18, batch loss = 0.10 (34.7 examples/sec; 0.230 sec/batch; 20h:32m:16s remains)
INFO - root - 2017-12-17 03:31:00.780960: step 11640, loss = 0.21, batch loss = 0.13 (35.2 examples/sec; 0.228 sec/batch; 20h:16m:37s remains)
INFO - root - 2017-12-17 03:31:03.038813: step 11650, loss = 0.22, batch loss = 0.14 (37.0 examples/sec; 0.216 sec/batch; 19h:17m:06s remains)
INFO - root - 2017-12-17 03:31:05.305540: step 11660, loss = 0.20, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 19h:38m:58s remains)
INFO - root - 2017-12-17 03:31:07.602067: step 11670, loss = 0.20, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 20h:25m:50s remains)
INFO - root - 2017-12-17 03:31:09.859281: step 11680, loss = 0.26, batch loss = 0.18 (35.3 examples/sec; 0.226 sec/batch; 20h:11m:03s remains)
INFO - root - 2017-12-17 03:31:12.110944: step 11690, loss = 0.25, batch loss = 0.17 (35.9 examples/sec; 0.223 sec/batch; 19h:50m:20s remains)
INFO - root - 2017-12-17 03:31:14.387494: step 11700, loss = 0.19, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 19h:57m:10s remains)
INFO - root - 2017-12-17 03:31:16.778432: step 11710, loss = 0.21, batch loss = 0.13 (35.0 examples/sec; 0.228 sec/batch; 20h:20m:54s remains)
INFO - root - 2017-12-17 03:31:19.057348: step 11720, loss = 0.21, batch loss = 0.13 (32.9 examples/sec; 0.243 sec/batch; 21h:38m:49s remains)
INFO - root - 2017-12-17 03:31:21.316779: step 11730, loss = 0.25, batch loss = 0.17 (34.8 examples/sec; 0.230 sec/batch; 20h:28m:46s remains)
INFO - root - 2017-12-17 03:31:23.575667: step 11740, loss = 0.23, batch loss = 0.15 (35.5 examples/sec; 0.225 sec/batch; 20h:04m:32s remains)
INFO - root - 2017-12-17 03:31:25.830275: step 11750, loss = 0.24, batch loss = 0.16 (34.7 examples/sec; 0.231 sec/batch; 20h:32m:20s remains)
INFO - root - 2017-12-17 03:31:28.128620: step 11760, loss = 0.21, batch loss = 0.13 (35.0 examples/sec; 0.228 sec/batch; 20h:20m:55s remains)
INFO - root - 2017-12-17 03:31:30.375472: step 11770, loss = 0.25, batch loss = 0.17 (36.6 examples/sec; 0.219 sec/batch; 19h:29m:25s remains)
INFO - root - 2017-12-17 03:31:32.627978: step 11780, loss = 0.29, batch loss = 0.21 (35.1 examples/sec; 0.228 sec/batch; 20h:17m:44s remains)
INFO - root - 2017-12-17 03:31:34.876770: step 11790, loss = 0.21, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 19h:49m:41s remains)
INFO - root - 2017-12-17 03:31:37.161849: step 11800, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.223 sec/batch; 19h:52m:57s remains)
INFO - root - 2017-12-17 03:31:39.560046: step 11810, loss = 0.26, batch loss = 0.18 (35.9 examples/sec; 0.223 sec/batch; 19h:52m:13s remains)
INFO - root - 2017-12-17 03:31:41.844540: step 11820, loss = 0.24, batch loss = 0.16 (36.4 examples/sec; 0.220 sec/batch; 19h:35m:52s remains)
INFO - root - 2017-12-17 03:31:44.095613: step 11830, loss = 0.22, batch loss = 0.14 (35.3 examples/sec; 0.227 sec/batch; 20h:10m:51s remains)
INFO - root - 2017-12-17 03:31:46.374853: step 11840, loss = 0.23, batch loss = 0.15 (33.9 examples/sec; 0.236 sec/batch; 21h:02m:10s remains)
INFO - root - 2017-12-17 03:31:48.640744: step 11850, loss = 0.21, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 20h:27m:28s remains)
INFO - root - 2017-12-17 03:31:50.891976: step 11860, loss = 0.24, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 19h:41m:30s remains)
INFO - root - 2017-12-17 03:31:53.146488: step 11870, loss = 0.28, batch loss = 0.20 (35.7 examples/sec; 0.224 sec/batch; 19h:57m:27s remains)
INFO - root - 2017-12-17 03:31:55.433895: step 11880, loss = 0.29, batch loss = 0.21 (34.5 examples/sec; 0.232 sec/batch; 20h:38m:10s remains)
INFO - root - 2017-12-17 03:31:57.706301: step 11890, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 20h:24m:20s remains)
INFO - root - 2017-12-17 03:31:59.984253: step 11900, loss = 0.26, batch loss = 0.18 (35.0 examples/sec; 0.228 sec/batch; 20h:20m:09s remains)
INFO - root - 2017-12-17 03:32:02.426445: step 11910, loss = 0.21, batch loss = 0.13 (34.0 examples/sec; 0.235 sec/batch; 20h:57m:44s remains)
INFO - root - 2017-12-17 03:32:04.730170: step 11920, loss = 0.25, batch loss = 0.17 (35.0 examples/sec; 0.229 sec/batch; 20h:22m:49s remains)
INFO - root - 2017-12-17 03:32:06.973106: step 11930, loss = 0.21, batch loss = 0.13 (37.2 examples/sec; 0.215 sec/batch; 19h:09m:33s remains)
INFO - root - 2017-12-17 03:32:09.227011: step 11940, loss = 0.25, batch loss = 0.17 (34.5 examples/sec; 0.232 sec/batch; 20h:39m:08s remains)
INFO - root - 2017-12-17 03:32:11.522061: step 11950, loss = 0.27, batch loss = 0.19 (36.1 examples/sec; 0.222 sec/batch; 19h:44m:55s remains)
INFO - root - 2017-12-17 03:32:13.818117: step 11960, loss = 0.22, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 20h:25m:29s remains)
INFO - root - 2017-12-17 03:32:16.083190: step 11970, loss = 0.21, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 20h:45m:19s remains)
INFO - root - 2017-12-17 03:32:18.341741: step 11980, loss = 0.22, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 19h:47m:03s remains)
INFO - root - 2017-12-17 03:32:20.590664: step 11990, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 20h:07m:07s remains)
INFO - root - 2017-12-17 03:32:22.831401: step 12000, loss = 0.22, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 19h:51m:29s remains)
INFO - root - 2017-12-17 03:32:25.229100: step 12010, loss = 0.24, batch loss = 0.16 (35.4 examples/sec; 0.226 sec/batch; 20h:07m:39s remains)
INFO - root - 2017-12-17 03:32:27.514048: step 12020, loss = 0.19, batch loss = 0.11 (32.9 examples/sec; 0.243 sec/batch; 21h:37m:40s remains)
INFO - root - 2017-12-17 03:32:29.764177: step 12030, loss = 0.26, batch loss = 0.18 (35.7 examples/sec; 0.224 sec/batch; 19h:57m:57s remains)
INFO - root - 2017-12-17 03:32:32.023465: step 12040, loss = 0.23, batch loss = 0.15 (36.6 examples/sec; 0.218 sec/batch; 19h:26m:16s remains)
INFO - root - 2017-12-17 03:32:34.285622: step 12050, loss = 0.18, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 19h:59m:10s remains)
INFO - root - 2017-12-17 03:32:36.562396: step 12060, loss = 0.25, batch loss = 0.17 (36.3 examples/sec; 0.220 sec/batch; 19h:36m:24s remains)
INFO - root - 2017-12-17 03:32:38.841420: step 12070, loss = 0.19, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 20h:27m:47s remains)
INFO - root - 2017-12-17 03:32:41.093475: step 12080, loss = 0.36, batch loss = 0.28 (35.9 examples/sec; 0.223 sec/batch; 19h:49m:31s remains)
INFO - root - 2017-12-17 03:32:43.345035: step 12090, loss = 0.23, batch loss = 0.15 (34.7 examples/sec; 0.230 sec/batch; 20h:29m:37s remains)
INFO - root - 2017-12-17 03:32:45.613002: step 12100, loss = 0.23, batch loss = 0.15 (34.6 examples/sec; 0.231 sec/batch; 20h:35m:54s remains)
INFO - root - 2017-12-17 03:32:48.002751: step 12110, loss = 0.27, batch loss = 0.19 (35.9 examples/sec; 0.223 sec/batch; 19h:50m:00s remains)
INFO - root - 2017-12-17 03:32:50.263514: step 12120, loss = 0.23, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 20h:08m:19s remains)
INFO - root - 2017-12-17 03:32:52.555056: step 12130, loss = 0.23, batch loss = 0.15 (34.3 examples/sec; 0.233 sec/batch; 20h:45m:40s remains)
INFO - root - 2017-12-17 03:32:54.815941: step 12140, loss = 0.23, batch loss = 0.15 (36.1 examples/sec; 0.221 sec/batch; 19h:42m:17s remains)
INFO - root - 2017-12-17 03:32:57.076282: step 12150, loss = 0.20, batch loss = 0.12 (33.4 examples/sec; 0.239 sec/batch; 21h:18m:38s remains)
INFO - root - 2017-12-17 03:32:59.319843: step 12160, loss = 0.18, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 19h:42m:50s remains)
INFO - root - 2017-12-17 03:33:01.556431: step 12170, loss = 0.23, batch loss = 0.15 (36.3 examples/sec; 0.220 sec/batch; 19h:36m:33s remains)
INFO - root - 2017-12-17 03:33:03.812719: step 12180, loss = 0.24, batch loss = 0.16 (36.5 examples/sec; 0.219 sec/batch; 19h:28m:42s remains)
INFO - root - 2017-12-17 03:33:06.073462: step 12190, loss = 0.23, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 19h:40m:32s remains)
INFO - root - 2017-12-17 03:33:08.363847: step 12200, loss = 0.21, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 20h:02m:51s remains)
INFO - root - 2017-12-17 03:33:10.787183: step 12210, loss = 0.23, batch loss = 0.15 (34.0 examples/sec; 0.235 sec/batch; 20h:54m:18s remains)
INFO - root - 2017-12-17 03:33:13.023718: step 12220, loss = 0.22, batch loss = 0.14 (34.7 examples/sec; 0.230 sec/batch; 20h:30m:17s remains)
INFO - root - 2017-12-17 03:33:15.280439: step 12230, loss = 0.22, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 20h:23m:38s remains)
INFO - root - 2017-12-17 03:33:17.526763: step 12240, loss = 0.28, batch loss = 0.20 (34.4 examples/sec; 0.232 sec/batch; 20h:40m:59s remains)
INFO - root - 2017-12-17 03:33:19.814997: step 12250, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 20h:24m:27s remains)
INFO - root - 2017-12-17 03:33:22.059801: step 12260, loss = 0.23, batch loss = 0.15 (35.6 examples/sec; 0.225 sec/batch; 20h:00m:13s remains)
INFO - root - 2017-12-17 03:33:24.299708: step 12270, loss = 0.19, batch loss = 0.11 (37.7 examples/sec; 0.212 sec/batch; 18h:54m:02s remains)
INFO - root - 2017-12-17 03:33:26.553498: step 12280, loss = 0.24, batch loss = 0.16 (36.0 examples/sec; 0.222 sec/batch; 19h:47m:05s remains)
INFO - root - 2017-12-17 03:33:28.819232: step 12290, loss = 0.20, batch loss = 0.12 (34.2 examples/sec; 0.234 sec/batch; 20h:47m:15s remains)
INFO - root - 2017-12-17 03:33:31.056767: step 12300, loss = 0.22, batch loss = 0.14 (35.2 examples/sec; 0.227 sec/batch; 20h:11m:57s remains)
INFO - root - 2017-12-17 03:33:33.504260: step 12310, loss = 0.23, batch loss = 0.15 (36.5 examples/sec; 0.219 sec/batch; 19h:29m:40s remains)
INFO - root - 2017-12-17 03:33:35.756441: step 12320, loss = 0.21, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 19h:33m:17s remains)
INFO - root - 2017-12-17 03:33:38.058648: step 12330, loss = 0.23, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 19h:45m:12s remains)
INFO - root - 2017-12-17 03:33:40.317804: step 12340, loss = 0.20, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 20h:34m:01s remains)
INFO - root - 2017-12-17 03:33:42.554589: step 12350, loss = 0.24, batch loss = 0.16 (35.1 examples/sec; 0.228 sec/batch; 20h:15m:16s remains)
INFO - root - 2017-12-17 03:33:44.804554: step 12360, loss = 0.21, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 20h:09m:45s remains)
INFO - root - 2017-12-17 03:33:47.075357: step 12370, loss = 0.23, batch loss = 0.15 (35.7 examples/sec; 0.224 sec/batch; 19h:56m:31s remains)
INFO - root - 2017-12-17 03:33:49.321900: step 12380, loss = 0.21, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 20h:04m:31s remains)
INFO - root - 2017-12-17 03:33:51.571364: step 12390, loss = 0.21, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 20h:43m:08s remains)
INFO - root - 2017-12-17 03:33:53.832007: step 12400, loss = 0.19, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 20h:15m:05s remains)
INFO - root - 2017-12-17 03:33:56.260714: step 12410, loss = 0.28, batch loss = 0.20 (34.9 examples/sec; 0.229 sec/batch; 20h:21m:58s remains)
INFO - root - 2017-12-17 03:33:58.496356: step 12420, loss = 0.22, batch loss = 0.13 (37.2 examples/sec; 0.215 sec/batch; 19h:06m:40s remains)
INFO - root - 2017-12-17 03:34:00.768111: step 12430, loss = 0.18, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 20h:25m:44s remains)
INFO - root - 2017-12-17 03:34:03.053416: step 12440, loss = 0.19, batch loss = 0.11 (32.1 examples/sec; 0.249 sec/batch; 22h:08m:10s remains)
INFO - root - 2017-12-17 03:34:05.372736: step 12450, loss = 0.24, batch loss = 0.16 (36.3 examples/sec; 0.221 sec/batch; 19h:36m:51s remains)
INFO - root - 2017-12-17 03:34:07.647123: step 12460, loss = 0.19, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 20h:25m:22s remains)
INFO - root - 2017-12-17 03:34:09.948782: step 12470, loss = 0.24, batch loss = 0.16 (35.6 examples/sec; 0.225 sec/batch; 19h:57m:35s remains)
INFO - root - 2017-12-17 03:34:12.213495: step 12480, loss = 0.20, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 19h:54m:15s remains)
INFO - root - 2017-12-17 03:34:14.463347: step 12490, loss = 0.25, batch loss = 0.17 (34.8 examples/sec; 0.230 sec/batch; 20h:25m:30s remains)
INFO - root - 2017-12-17 03:34:16.751494: step 12500, loss = 0.20, batch loss = 0.12 (34.7 examples/sec; 0.230 sec/batch; 20h:29m:16s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-12500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-12500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 03:34:19.926033: step 12510, loss = 0.21, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 20h:00m:03s remains)
INFO - root - 2017-12-17 03:34:22.175865: step 12520, loss = 0.20, batch loss = 0.12 (34.0 examples/sec; 0.236 sec/batch; 20h:56m:12s remains)
INFO - root - 2017-12-17 03:34:24.431223: step 12530, loss = 0.21, batch loss = 0.13 (34.7 examples/sec; 0.230 sec/batch; 20h:29m:00s remains)
INFO - root - 2017-12-17 03:34:26.716672: step 12540, loss = 0.23, batch loss = 0.15 (34.1 examples/sec; 0.235 sec/batch; 20h:51m:24s remains)
INFO - root - 2017-12-17 03:34:28.970364: step 12550, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 20h:22m:43s remains)
INFO - root - 2017-12-17 03:34:31.231523: step 12560, loss = 0.20, batch loss = 0.12 (36.8 examples/sec; 0.217 sec/batch; 19h:19m:22s remains)
INFO - root - 2017-12-17 03:34:33.495463: step 12570, loss = 0.31, batch loss = 0.23 (35.9 examples/sec; 0.223 sec/batch; 19h:49m:32s remains)
INFO - root - 2017-12-17 03:34:35.758637: step 12580, loss = 0.28, batch loss = 0.20 (34.8 examples/sec; 0.230 sec/batch; 20h:25m:36s remains)
INFO - root - 2017-12-17 03:34:37.998955: step 12590, loss = 0.25, batch loss = 0.17 (35.4 examples/sec; 0.226 sec/batch; 20h:04m:35s remains)
INFO - root - 2017-12-17 03:34:40.295545: step 12600, loss = 0.22, batch loss = 0.14 (35.0 examples/sec; 0.228 sec/batch; 20h:17m:22s remains)
INFO - root - 2017-12-17 03:34:42.691967: step 12610, loss = 0.20, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 20h:15m:27s remains)
INFO - root - 2017-12-17 03:34:44.936520: step 12620, loss = 0.27, batch loss = 0.19 (34.6 examples/sec; 0.231 sec/batch; 20h:30m:56s remains)
INFO - root - 2017-12-17 03:34:47.178848: step 12630, loss = 0.20, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 19h:59m:15s remains)
INFO - root - 2017-12-17 03:34:49.461185: step 12640, loss = 0.24, batch loss = 0.16 (33.7 examples/sec; 0.238 sec/batch; 21h:06m:56s remains)
INFO - root - 2017-12-17 03:34:51.754569: step 12650, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 20h:22m:16s remains)
INFO - root - 2017-12-17 03:34:54.030276: step 12660, loss = 0.17, batch loss = 0.09 (36.8 examples/sec; 0.217 sec/batch; 19h:18m:07s remains)
INFO - root - 2017-12-17 03:34:56.288779: step 12670, loss = 0.46, batch loss = 0.38 (35.6 examples/sec; 0.225 sec/batch; 19h:58m:13s remains)
INFO - root - 2017-12-17 03:34:58.548375: step 12680, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.228 sec/batch; 20h:12m:56s remains)
INFO - root - 2017-12-17 03:35:00.799745: step 12690, loss = 0.19, batch loss = 0.11 (36.3 examples/sec; 0.221 sec/batch; 19h:35m:32s remains)
INFO - root - 2017-12-17 03:35:03.027543: step 12700, loss = 0.23, batch loss = 0.15 (37.1 examples/sec; 0.215 sec/batch; 19h:07m:55s remains)
INFO - root - 2017-12-17 03:35:05.412672: step 12710, loss = 0.20, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 19h:48m:06s remains)
INFO - root - 2017-12-17 03:35:07.697667: step 12720, loss = 0.27, batch loss = 0.19 (34.9 examples/sec; 0.229 sec/batch; 20h:20m:41s remains)
INFO - root - 2017-12-17 03:35:09.985098: step 12730, loss = 0.22, batch loss = 0.14 (34.4 examples/sec; 0.233 sec/batch; 20h:40m:37s remains)
INFO - root - 2017-12-17 03:35:12.260967: step 12740, loss = 0.20, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 20h:07m:43s remains)
INFO - root - 2017-12-17 03:35:14.564371: step 12750, loss = 0.25, batch loss = 0.17 (32.9 examples/sec; 0.243 sec/batch; 21h:36m:45s remains)
INFO - root - 2017-12-17 03:35:16.820630: step 12760, loss = 0.22, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 19h:33m:17s remains)
INFO - root - 2017-12-17 03:35:19.059815: step 12770, loss = 0.22, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 19h:53m:51s remains)
INFO - root - 2017-12-17 03:35:21.311823: step 12780, loss = 0.25, batch loss = 0.17 (35.1 examples/sec; 0.228 sec/batch; 20h:14m:35s remains)
INFO - root - 2017-12-17 03:35:23.548135: step 12790, loss = 0.25, batch loss = 0.17 (33.5 examples/sec; 0.238 sec/batch; 21h:10m:41s remains)
INFO - root - 2017-12-17 03:35:25.812619: step 12800, loss = 0.21, batch loss = 0.14 (35.3 examples/sec; 0.226 sec/batch; 20h:06m:22s remains)
INFO - root - 2017-12-17 03:35:28.201345: step 12810, loss = 0.23, batch loss = 0.15 (35.8 examples/sec; 0.223 sec/batch; 19h:49m:25s remains)
INFO - root - 2017-12-17 03:35:30.524643: step 12820, loss = 0.22, batch loss = 0.14 (32.5 examples/sec; 0.246 sec/batch; 21h:49m:57s remains)
INFO - root - 2017-12-17 03:35:32.771734: step 12830, loss = 0.22, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 20h:15m:07s remains)
INFO - root - 2017-12-17 03:35:35.024096: step 12840, loss = 0.23, batch loss = 0.15 (35.5 examples/sec; 0.225 sec/batch; 20h:00m:16s remains)
INFO - root - 2017-12-17 03:35:37.270049: step 12850, loss = 0.22, batch loss = 0.14 (36.4 examples/sec; 0.220 sec/batch; 19h:30m:04s remains)
INFO - root - 2017-12-17 03:35:39.596137: step 12860, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 20h:20m:51s remains)
INFO - root - 2017-12-17 03:35:41.858913: step 12870, loss = 0.20, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 19h:50m:42s remains)
INFO - root - 2017-12-17 03:35:44.109867: step 12880, loss = 0.20, batch loss = 0.12 (35.0 examples/sec; 0.229 sec/batch; 20h:18m:02s remains)
INFO - root - 2017-12-17 03:35:46.367992: step 12890, loss = 0.26, batch loss = 0.18 (37.2 examples/sec; 0.215 sec/batch; 19h:05m:09s remains)
INFO - root - 2017-12-17 03:35:48.597518: step 12900, loss = 0.19, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 19h:45m:01s remains)
INFO - root - 2017-12-17 03:35:50.949049: step 12910, loss = 0.25, batch loss = 0.17 (36.3 examples/sec; 0.220 sec/batch; 19h:33m:19s remains)
INFO - root - 2017-12-17 03:35:53.172197: step 12920, loss = 0.21, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 20h:07m:00s remains)
INFO - root - 2017-12-17 03:35:55.422626: step 12930, loss = 0.20, batch loss = 0.12 (36.8 examples/sec; 0.218 sec/batch; 19h:18m:43s remains)
INFO - root - 2017-12-17 03:35:57.687148: step 12940, loss = 0.27, batch loss = 0.19 (35.2 examples/sec; 0.227 sec/batch; 20h:10m:03s remains)
INFO - root - 2017-12-17 03:35:59.940285: step 12950, loss = 0.24, batch loss = 0.16 (35.6 examples/sec; 0.224 sec/batch; 19h:55m:35s remains)
INFO - root - 2017-12-17 03:36:02.212180: step 12960, loss = 0.26, batch loss = 0.18 (36.4 examples/sec; 0.220 sec/batch; 19h:30m:34s remains)
INFO - root - 2017-12-17 03:36:04.482440: step 12970, loss = 0.19, batch loss = 0.11 (35.6 examples/sec; 0.224 sec/batch; 19h:55m:27s remains)
INFO - root - 2017-12-17 03:36:06.763540: step 12980, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 20h:19m:45s remains)
INFO - root - 2017-12-17 03:36:09.049490: step 12990, loss = 0.21, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 19h:57m:25s remains)
INFO - root - 2017-12-17 03:36:11.340706: step 13000, loss = 0.24, batch loss = 0.16 (35.6 examples/sec; 0.225 sec/batch; 19h:57m:21s remains)
INFO - root - 2017-12-17 03:36:13.778547: step 13010, loss = 0.27, batch loss = 0.19 (35.4 examples/sec; 0.226 sec/batch; 20h:03m:39s remains)
INFO - root - 2017-12-17 03:36:16.091784: step 13020, loss = 0.19, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 20h:30m:38s remains)
INFO - root - 2017-12-17 03:36:18.395232: step 13030, loss = 0.32, batch loss = 0.24 (34.0 examples/sec; 0.235 sec/batch; 20h:51m:07s remains)
INFO - root - 2017-12-17 03:36:20.662370: step 13040, loss = 0.19, batch loss = 0.11 (34.3 examples/sec; 0.233 sec/batch; 20h:42m:43s remains)
INFO - root - 2017-12-17 03:36:22.974623: step 13050, loss = 0.22, batch loss = 0.14 (33.5 examples/sec; 0.239 sec/batch; 21h:10m:06s remains)
INFO - root - 2017-12-17 03:36:25.253357: step 13060, loss = 0.30, batch loss = 0.22 (35.7 examples/sec; 0.224 sec/batch; 19h:52m:31s remains)
INFO - root - 2017-12-17 03:36:27.555537: step 13070, loss = 0.21, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 20h:14m:14s remains)
INFO - root - 2017-12-17 03:36:29.822714: step 13080, loss = 0.22, batch loss = 0.14 (33.5 examples/sec; 0.239 sec/batch; 21h:12m:10s remains)
INFO - root - 2017-12-17 03:36:32.067500: step 13090, loss = 0.21, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 19h:53m:11s remains)
INFO - root - 2017-12-17 03:36:34.318134: step 13100, loss = 0.22, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 19h:32m:33s remains)
INFO - root - 2017-12-17 03:36:36.708304: step 13110, loss = 0.26, batch loss = 0.18 (35.6 examples/sec; 0.225 sec/batch; 19h:55m:17s remains)
INFO - root - 2017-12-17 03:36:38.969103: step 13120, loss = 0.21, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 19h:37m:38s remains)
INFO - root - 2017-12-17 03:36:41.209384: step 13130, loss = 0.21, batch loss = 0.13 (35.2 examples/sec; 0.228 sec/batch; 20h:11m:19s remains)
INFO - root - 2017-12-17 03:36:43.482424: step 13140, loss = 0.22, batch loss = 0.14 (33.3 examples/sec; 0.240 sec/batch; 21h:18m:53s remains)
INFO - root - 2017-12-17 03:36:45.781704: step 13150, loss = 0.20, batch loss = 0.12 (33.9 examples/sec; 0.236 sec/batch; 20h:56m:42s remains)
INFO - root - 2017-12-17 03:36:48.107362: step 13160, loss = 0.19, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 20h:06m:40s remains)
INFO - root - 2017-12-17 03:36:50.395667: step 13170, loss = 0.21, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 19h:40m:59s remains)
INFO - root - 2017-12-17 03:36:52.651897: step 13180, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.230 sec/batch; 20h:21m:32s remains)
INFO - root - 2017-12-17 03:36:54.919435: step 13190, loss = 0.25, batch loss = 0.17 (35.0 examples/sec; 0.228 sec/batch; 20h:15m:37s remains)
INFO - root - 2017-12-17 03:36:57.206463: step 13200, loss = 0.22, batch loss = 0.14 (34.5 examples/sec; 0.232 sec/batch; 20h:33m:42s remains)
INFO - root - 2017-12-17 03:36:59.589376: step 13210, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 20h:08m:25s remains)
INFO - root - 2017-12-17 03:37:01.864722: step 13220, loss = 0.17, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:41m:55s remains)
INFO - root - 2017-12-17 03:37:04.123685: step 13230, loss = 0.27, batch loss = 0.19 (35.4 examples/sec; 0.226 sec/batch; 20h:01m:02s remains)
INFO - root - 2017-12-17 03:37:06.387661: step 13240, loss = 0.19, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 20h:28m:00s remains)
INFO - root - 2017-12-17 03:37:08.719999: step 13250, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.224 sec/batch; 19h:49m:55s remains)
INFO - root - 2017-12-17 03:37:10.973891: step 13260, loss = 0.29, batch loss = 0.21 (37.1 examples/sec; 0.216 sec/batch; 19h:08m:40s remains)
INFO - root - 2017-12-17 03:37:13.265798: step 13270, loss = 0.21, batch loss = 0.13 (34.1 examples/sec; 0.235 sec/batch; 20h:47m:52s remains)
INFO - root - 2017-12-17 03:37:15.549695: step 13280, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.228 sec/batch; 20h:10m:39s remains)
INFO - root - 2017-12-17 03:37:17.795896: step 13290, loss = 0.19, batch loss = 0.11 (35.0 examples/sec; 0.228 sec/batch; 20h:14m:40s remains)
INFO - root - 2017-12-17 03:37:20.100300: step 13300, loss = 0.20, batch loss = 0.12 (34.4 examples/sec; 0.233 sec/batch; 20h:37m:40s remains)
INFO - root - 2017-12-17 03:37:22.544765: step 13310, loss = 0.24, batch loss = 0.16 (33.9 examples/sec; 0.236 sec/batch; 20h:54m:31s remains)
INFO - root - 2017-12-17 03:37:24.795211: step 13320, loss = 0.26, batch loss = 0.18 (34.6 examples/sec; 0.231 sec/batch; 20h:28m:17s remains)
INFO - root - 2017-12-17 03:37:27.080905: step 13330, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 20h:18m:14s remains)
INFO - root - 2017-12-17 03:37:29.349313: step 13340, loss = 0.20, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 20h:12m:08s remains)
INFO - root - 2017-12-17 03:37:31.634571: step 13350, loss = 0.20, batch loss = 0.12 (33.8 examples/sec; 0.237 sec/batch; 20h:58m:42s remains)
INFO - root - 2017-12-17 03:37:33.898913: step 13360, loss = 0.21, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 19h:54m:39s remains)
INFO - root - 2017-12-17 03:37:36.158984: step 13370, loss = 0.23, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 19h:44m:16s remains)
INFO - root - 2017-12-17 03:37:38.475307: step 13380, loss = 0.23, batch loss = 0.15 (33.3 examples/sec; 0.240 sec/batch; 21h:17m:05s remains)
INFO - root - 2017-12-17 03:37:40.769371: step 13390, loss = 0.22, batch loss = 0.14 (34.5 examples/sec; 0.232 sec/batch; 20h:34m:28s remains)
INFO - root - 2017-12-17 03:37:43.030209: step 13400, loss = 0.30, batch loss = 0.22 (36.3 examples/sec; 0.221 sec/batch; 19h:33m:20s remains)
INFO - root - 2017-12-17 03:37:45.466237: step 13410, loss = 0.19, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 20h:07m:11s remains)
INFO - root - 2017-12-17 03:37:47.746511: step 13420, loss = 0.21, batch loss = 0.13 (33.9 examples/sec; 0.236 sec/batch; 20h:55m:47s remains)
INFO - root - 2017-12-17 03:37:49.997760: step 13430, loss = 0.26, batch loss = 0.18 (35.9 examples/sec; 0.223 sec/batch; 19h:46m:14s remains)
INFO - root - 2017-12-17 03:37:52.283154: step 13440, loss = 0.18, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 19h:56m:13s remains)
INFO - root - 2017-12-17 03:37:54.636093: step 13450, loss = 0.21, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 19h:38m:44s remains)
INFO - root - 2017-12-17 03:37:56.876734: step 13460, loss = 0.20, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 19h:41m:32s remains)
INFO - root - 2017-12-17 03:37:59.111330: step 13470, loss = 0.22, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 20h:19m:14s remains)
INFO - root - 2017-12-17 03:38:01.335795: step 13480, loss = 0.27, batch loss = 0.19 (35.9 examples/sec; 0.223 sec/batch; 19h:46m:04s remains)
INFO - root - 2017-12-17 03:38:03.577856: step 13490, loss = 0.21, batch loss = 0.13 (37.2 examples/sec; 0.215 sec/batch; 19h:02m:40s remains)
INFO - root - 2017-12-17 03:38:05.840044: step 13500, loss = 0.21, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 19h:47m:26s remains)
INFO - root - 2017-12-17 03:38:08.269357: step 13510, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 19h:52m:54s remains)
INFO - root - 2017-12-17 03:38:10.569121: step 13520, loss = 0.29, batch loss = 0.21 (35.3 examples/sec; 0.226 sec/batch; 20h:03m:11s remains)
INFO - root - 2017-12-17 03:38:12.893163: step 13530, loss = 0.20, batch loss = 0.12 (33.5 examples/sec; 0.239 sec/batch; 21h:10m:27s remains)
INFO - root - 2017-12-17 03:38:15.178181: step 13540, loss = 0.23, batch loss = 0.15 (34.7 examples/sec; 0.231 sec/batch; 20h:26m:51s remains)
INFO - root - 2017-12-17 03:38:17.452871: step 13550, loss = 0.21, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 19h:36m:07s remains)
INFO - root - 2017-12-17 03:38:19.697407: step 13560, loss = 0.24, batch loss = 0.17 (36.2 examples/sec; 0.221 sec/batch; 19h:34m:48s remains)
INFO - root - 2017-12-17 03:38:21.983456: step 13570, loss = 0.21, batch loss = 0.13 (33.0 examples/sec; 0.243 sec/batch; 21h:29m:31s remains)
INFO - root - 2017-12-17 03:38:24.286958: step 13580, loss = 0.23, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 20h:11m:43s remains)
INFO - root - 2017-12-17 03:38:26.554722: step 13590, loss = 0.28, batch loss = 0.20 (32.0 examples/sec; 0.250 sec/batch; 22h:09m:20s remains)
INFO - root - 2017-12-17 03:38:28.834018: step 13600, loss = 0.23, batch loss = 0.15 (34.5 examples/sec; 0.232 sec/batch; 20h:33m:25s remains)
INFO - root - 2017-12-17 03:38:31.208295: step 13610, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 20h:02m:25s remains)
INFO - root - 2017-12-17 03:38:33.488855: step 13620, loss = 0.19, batch loss = 0.11 (34.0 examples/sec; 0.236 sec/batch; 20h:52m:18s remains)
INFO - root - 2017-12-17 03:38:35.760747: step 13630, loss = 0.20, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 20h:29m:17s remains)
INFO - root - 2017-12-17 03:38:38.032103: step 13640, loss = 0.20, batch loss = 0.13 (35.3 examples/sec; 0.226 sec/batch; 20h:03m:37s remains)
INFO - root - 2017-12-17 03:38:40.325975: step 13650, loss = 0.21, batch loss = 0.13 (33.7 examples/sec; 0.238 sec/batch; 21h:03m:17s remains)
INFO - root - 2017-12-17 03:38:42.572152: step 13660, loss = 0.22, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 19h:34m:51s remains)
INFO - root - 2017-12-17 03:38:44.811973: step 13670, loss = 0.24, batch loss = 0.16 (34.4 examples/sec; 0.233 sec/batch; 20h:35m:50s remains)
INFO - root - 2017-12-17 03:38:47.071219: step 13680, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 20h:00m:06s remains)
INFO - root - 2017-12-17 03:38:49.328284: step 13690, loss = 0.20, batch loss = 0.12 (34.1 examples/sec; 0.234 sec/batch; 20h:44m:53s remains)
INFO - root - 2017-12-17 03:38:51.570959: step 13700, loss = 0.22, batch loss = 0.14 (34.1 examples/sec; 0.235 sec/batch; 20h:48m:16s remains)
INFO - root - 2017-12-17 03:38:53.950407: step 13710, loss = 0.19, batch loss = 0.11 (35.0 examples/sec; 0.229 sec/batch; 20h:15m:50s remains)
INFO - root - 2017-12-17 03:38:56.205592: step 13720, loss = 0.20, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 19h:49m:27s remains)
INFO - root - 2017-12-17 03:38:58.454574: step 13730, loss = 0.28, batch loss = 0.20 (35.7 examples/sec; 0.224 sec/batch; 19h:51m:15s remains)
INFO - root - 2017-12-17 03:39:00.726246: step 13740, loss = 0.25, batch loss = 0.18 (35.5 examples/sec; 0.225 sec/batch; 19h:57m:20s remains)
INFO - root - 2017-12-17 03:39:03.019387: step 13750, loss = 0.30, batch loss = 0.22 (36.3 examples/sec; 0.220 sec/batch; 19h:30m:47s remains)
INFO - root - 2017-12-17 03:39:05.321822: step 13760, loss = 0.23, batch loss = 0.15 (35.5 examples/sec; 0.225 sec/batch; 19h:57m:07s remains)
INFO - root - 2017-12-17 03:39:07.603782: step 13770, loss = 0.24, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 19h:34m:35s remains)
INFO - root - 2017-12-17 03:39:09.866077: step 13780, loss = 0.22, batch loss = 0.14 (36.7 examples/sec; 0.218 sec/batch; 19h:18m:05s remains)
INFO - root - 2017-12-17 03:39:12.114987: step 13790, loss = 0.28, batch loss = 0.20 (35.0 examples/sec; 0.229 sec/batch; 20h:15m:05s remains)
INFO - root - 2017-12-17 03:39:14.384355: step 13800, loss = 0.24, batch loss = 0.16 (34.5 examples/sec; 0.232 sec/batch; 20h:32m:43s remains)
INFO - root - 2017-12-17 03:39:16.831698: step 13810, loss = 0.24, batch loss = 0.16 (35.5 examples/sec; 0.225 sec/batch; 19h:56m:12s remains)
INFO - root - 2017-12-17 03:39:19.104571: step 13820, loss = 0.22, batch loss = 0.15 (34.8 examples/sec; 0.230 sec/batch; 20h:20m:44s remains)
INFO - root - 2017-12-17 03:39:21.349928: step 13830, loss = 0.22, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 19h:34m:19s remains)
INFO - root - 2017-12-17 03:39:23.664800: step 13840, loss = 0.19, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 20h:30m:47s remains)
INFO - root - 2017-12-17 03:39:26.011570: step 13850, loss = 0.22, batch loss = 0.14 (35.0 examples/sec; 0.228 sec/batch; 20h:12m:57s remains)
INFO - root - 2017-12-17 03:39:28.251732: step 13860, loss = 0.21, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 20h:10m:42s remains)
INFO - root - 2017-12-17 03:39:30.532431: step 13870, loss = 0.25, batch loss = 0.17 (35.0 examples/sec; 0.228 sec/batch; 20h:12m:56s remains)
INFO - root - 2017-12-17 03:39:32.808213: step 13880, loss = 0.20, batch loss = 0.12 (33.2 examples/sec; 0.241 sec/batch; 21h:19m:06s remains)
INFO - root - 2017-12-17 03:39:35.101277: step 13890, loss = 0.23, batch loss = 0.15 (35.6 examples/sec; 0.225 sec/batch; 19h:52m:39s remains)
INFO - root - 2017-12-17 03:39:37.335842: step 13900, loss = 0.22, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 19h:44m:17s remains)
INFO - root - 2017-12-17 03:39:39.716515: step 13910, loss = 0.23, batch loss = 0.15 (36.6 examples/sec; 0.219 sec/batch; 19h:20m:59s remains)
INFO - root - 2017-12-17 03:39:42.060904: step 13920, loss = 0.29, batch loss = 0.21 (32.6 examples/sec; 0.246 sec/batch; 21h:43m:58s remains)
INFO - root - 2017-12-17 03:39:44.339309: step 13930, loss = 0.24, batch loss = 0.16 (35.8 examples/sec; 0.224 sec/batch; 19h:47m:00s remains)
INFO - root - 2017-12-17 03:39:46.639890: step 13940, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 19h:38m:18s remains)
INFO - root - 2017-12-17 03:39:48.873433: step 13950, loss = 0.21, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 19h:27m:35s remains)
INFO - root - 2017-12-17 03:39:51.146976: step 13960, loss = 0.19, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 19h:41m:07s remains)
INFO - root - 2017-12-17 03:39:53.407032: step 13970, loss = 0.19, batch loss = 0.12 (32.7 examples/sec; 0.244 sec/batch; 21h:37m:14s remains)
INFO - root - 2017-12-17 03:39:55.672674: step 13980, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.223 sec/batch; 19h:45m:22s remains)
INFO - root - 2017-12-17 03:39:57.951914: step 13990, loss = 0.25, batch loss = 0.17 (36.1 examples/sec; 0.222 sec/batch; 19h:36m:49s remains)
INFO - root - 2017-12-17 03:40:00.212639: step 14000, loss = 0.22, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 19h:32m:59s remains)
INFO - root - 2017-12-17 03:40:02.619778: step 14010, loss = 0.24, batch loss = 0.16 (36.9 examples/sec; 0.217 sec/batch; 19h:12m:12s remains)
INFO - root - 2017-12-17 03:40:04.851386: step 14020, loss = 0.20, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 19h:26m:50s remains)
INFO - root - 2017-12-17 03:40:07.139188: step 14030, loss = 0.24, batch loss = 0.16 (36.8 examples/sec; 0.218 sec/batch; 19h:14m:54s remains)
INFO - root - 2017-12-17 03:40:09.402264: step 14040, loss = 0.23, batch loss = 0.15 (35.3 examples/sec; 0.227 sec/batch; 20h:02m:20s remains)
INFO - root - 2017-12-17 03:40:11.634191: step 14050, loss = 0.19, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 19h:37m:16s remains)
INFO - root - 2017-12-17 03:40:13.900984: step 14060, loss = 0.27, batch loss = 0.19 (35.6 examples/sec; 0.225 sec/batch; 19h:53m:15s remains)
INFO - root - 2017-12-17 03:40:16.156405: step 14070, loss = 0.19, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 20h:02m:36s remains)
INFO - root - 2017-12-17 03:40:18.408319: step 14080, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.223 sec/batch; 19h:45m:37s remains)
INFO - root - 2017-12-17 03:40:20.643194: step 14090, loss = 0.17, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 20h:00m:22s remains)
INFO - root - 2017-12-17 03:40:22.908480: step 14100, loss = 0.24, batch loss = 0.16 (34.7 examples/sec; 0.230 sec/batch; 20h:22m:32s remains)
INFO - root - 2017-12-17 03:40:25.292475: step 14110, loss = 0.28, batch loss = 0.20 (33.6 examples/sec; 0.238 sec/batch; 21h:03m:04s remains)
INFO - root - 2017-12-17 03:40:27.601573: step 14120, loss = 0.22, batch loss = 0.14 (32.6 examples/sec; 0.245 sec/batch; 21h:41m:09s remains)
INFO - root - 2017-12-17 03:40:29.870187: step 14130, loss = 0.18, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 19h:41m:15s remains)
INFO - root - 2017-12-17 03:40:32.174589: step 14140, loss = 0.23, batch loss = 0.16 (33.3 examples/sec; 0.240 sec/batch; 21h:15m:23s remains)
INFO - root - 2017-12-17 03:40:34.434201: step 14150, loss = 0.23, batch loss = 0.15 (35.0 examples/sec; 0.229 sec/batch; 20h:14m:25s remains)
INFO - root - 2017-12-17 03:40:36.710364: step 14160, loss = 0.25, batch loss = 0.17 (35.0 examples/sec; 0.228 sec/batch; 20h:12m:13s remains)
INFO - root - 2017-12-17 03:40:39.035162: step 14170, loss = 0.25, batch loss = 0.17 (34.6 examples/sec; 0.231 sec/batch; 20h:26m:55s remains)
INFO - root - 2017-12-17 03:40:41.313317: step 14180, loss = 0.25, batch loss = 0.17 (35.4 examples/sec; 0.226 sec/batch; 19h:59m:54s remains)
INFO - root - 2017-12-17 03:40:43.590303: step 14190, loss = 0.21, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 19h:37m:43s remains)
INFO - root - 2017-12-17 03:40:45.852991: step 14200, loss = 0.27, batch loss = 0.19 (35.5 examples/sec; 0.225 sec/batch; 19h:54m:06s remains)
INFO - root - 2017-12-17 03:40:48.263206: step 14210, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 20h:15m:30s remains)
INFO - root - 2017-12-17 03:40:50.535188: step 14220, loss = 0.32, batch loss = 0.24 (35.7 examples/sec; 0.224 sec/batch; 19h:49m:20s remains)
INFO - root - 2017-12-17 03:40:52.854963: step 14230, loss = 0.27, batch loss = 0.19 (33.6 examples/sec; 0.238 sec/batch; 21h:02m:21s remains)
INFO - root - 2017-12-17 03:40:55.110214: step 14240, loss = 0.22, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 19h:57m:31s remains)
INFO - root - 2017-12-17 03:40:57.379421: step 14250, loss = 0.21, batch loss = 0.13 (35.0 examples/sec; 0.228 sec/batch; 20h:10m:56s remains)
INFO - root - 2017-12-17 03:40:59.633448: step 14260, loss = 0.21, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 20h:19m:41s remains)
INFO - root - 2017-12-17 03:41:01.881723: step 14270, loss = 0.21, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 20h:01m:57s remains)
INFO - root - 2017-12-17 03:41:04.155171: step 14280, loss = 0.22, batch loss = 0.15 (34.0 examples/sec; 0.235 sec/batch; 20h:47m:40s remains)
INFO - root - 2017-12-17 03:41:06.390728: step 14290, loss = 0.22, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 19h:48m:07s remains)
INFO - root - 2017-12-17 03:41:08.676412: step 14300, loss = 0.25, batch loss = 0.17 (34.6 examples/sec; 0.231 sec/batch; 20h:25m:03s remains)
INFO - root - 2017-12-17 03:41:11.098765: step 14310, loss = 0.21, batch loss = 0.13 (33.5 examples/sec; 0.239 sec/batch; 21h:06m:06s remains)
INFO - root - 2017-12-17 03:41:13.346826: step 14320, loss = 0.20, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 19h:32m:35s remains)
INFO - root - 2017-12-17 03:41:15.626911: step 14330, loss = 0.25, batch loss = 0.18 (35.2 examples/sec; 0.227 sec/batch; 20h:06m:05s remains)
INFO - root - 2017-12-17 03:41:17.916859: step 14340, loss = 0.24, batch loss = 0.16 (35.9 examples/sec; 0.223 sec/batch; 19h:42m:03s remains)
INFO - root - 2017-12-17 03:41:20.163484: step 14350, loss = 0.22, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 19h:47m:39s remains)
INFO - root - 2017-12-17 03:41:22.434495: step 14360, loss = 0.23, batch loss = 0.15 (34.7 examples/sec; 0.230 sec/batch; 20h:21m:00s remains)
INFO - root - 2017-12-17 03:41:24.674746: step 14370, loss = 0.25, batch loss = 0.17 (36.7 examples/sec; 0.218 sec/batch; 19h:14m:29s remains)
INFO - root - 2017-12-17 03:41:26.966835: step 14380, loss = 0.20, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 19h:53m:55s remains)
INFO - root - 2017-12-17 03:41:29.255343: step 14390, loss = 0.23, batch loss = 0.15 (35.0 examples/sec; 0.229 sec/batch; 20h:12m:06s remains)
INFO - root - 2017-12-17 03:41:31.538758: step 14400, loss = 0.26, batch loss = 0.18 (34.8 examples/sec; 0.230 sec/batch; 20h:19m:41s remains)
INFO - root - 2017-12-17 03:41:33.918900: step 14410, loss = 0.27, batch loss = 0.19 (36.7 examples/sec; 0.218 sec/batch; 19h:16m:07s remains)
INFO - root - 2017-12-17 03:41:36.206583: step 14420, loss = 0.22, batch loss = 0.14 (33.3 examples/sec; 0.240 sec/batch; 21h:14m:52s remains)
INFO - root - 2017-12-17 03:41:38.492278: step 14430, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 20h:13m:33s remains)
INFO - root - 2017-12-17 03:41:40.726053: step 14440, loss = 0.19, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 20h:03m:53s remains)
INFO - root - 2017-12-17 03:41:42.998532: step 14450, loss = 0.22, batch loss = 0.15 (33.2 examples/sec; 0.241 sec/batch; 21h:18m:41s remains)
INFO - root - 2017-12-17 03:41:45.299416: step 14460, loss = 0.20, batch loss = 0.12 (33.4 examples/sec; 0.240 sec/batch; 21h:11m:26s remains)
INFO - root - 2017-12-17 03:41:47.536712: step 14470, loss = 0.22, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 19h:37m:46s remains)
INFO - root - 2017-12-17 03:41:49.830646: step 14480, loss = 0.24, batch loss = 0.16 (35.8 examples/sec; 0.224 sec/batch; 19h:44m:58s remains)
INFO - root - 2017-12-17 03:41:52.083954: step 14490, loss = 0.23, batch loss = 0.15 (35.0 examples/sec; 0.229 sec/batch; 20h:11m:19s remains)
INFO - root - 2017-12-17 03:41:54.376968: step 14500, loss = 0.21, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 19h:37m:40s remains)
INFO - root - 2017-12-17 03:41:56.804809: step 14510, loss = 0.23, batch loss = 0.16 (35.9 examples/sec; 0.223 sec/batch; 19h:41m:58s remains)
INFO - root - 2017-12-17 03:41:59.056167: step 14520, loss = 0.24, batch loss = 0.16 (35.3 examples/sec; 0.227 sec/batch; 20h:02m:21s remains)
INFO - root - 2017-12-17 03:42:01.359318: step 14530, loss = 0.21, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 20h:34m:21s remains)
INFO - root - 2017-12-17 03:42:03.642837: step 14540, loss = 0.27, batch loss = 0.20 (35.9 examples/sec; 0.223 sec/batch; 19h:40m:07s remains)
INFO - root - 2017-12-17 03:42:05.899733: step 14550, loss = 0.24, batch loss = 0.16 (35.1 examples/sec; 0.228 sec/batch; 20h:07m:12s remains)
INFO - root - 2017-12-17 03:42:08.202651: step 14560, loss = 0.21, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 19h:52m:28s remains)
INFO - root - 2017-12-17 03:42:10.470153: step 14570, loss = 0.19, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 20h:17m:54s remains)
INFO - root - 2017-12-17 03:42:12.711914: step 14580, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.223 sec/batch; 19h:43m:36s remains)
INFO - root - 2017-12-17 03:42:14.995951: step 14590, loss = 0.25, batch loss = 0.17 (35.4 examples/sec; 0.226 sec/batch; 19h:58m:32s remains)
INFO - root - 2017-12-17 03:42:17.274084: step 14600, loss = 0.20, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 19h:36m:04s remains)
INFO - root - 2017-12-17 03:42:19.668520: step 14610, loss = 0.21, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 20h:26m:28s remains)
INFO - root - 2017-12-17 03:42:21.937493: step 14620, loss = 0.26, batch loss = 0.18 (34.4 examples/sec; 0.233 sec/batch; 20h:33m:32s remains)
INFO - root - 2017-12-17 03:42:24.287940: step 14630, loss = 0.21, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 19h:39m:58s remains)
INFO - root - 2017-12-17 03:42:26.514016: step 14640, loss = 0.27, batch loss = 0.19 (35.5 examples/sec; 0.226 sec/batch; 19h:55m:01s remains)
INFO - root - 2017-12-17 03:42:28.779943: step 14650, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.223 sec/batch; 19h:42m:31s remains)
INFO - root - 2017-12-17 03:42:31.026503: step 14660, loss = 0.24, batch loss = 0.16 (36.0 examples/sec; 0.223 sec/batch; 19h:38m:39s remains)
INFO - root - 2017-12-17 03:42:33.298898: step 14670, loss = 0.23, batch loss = 0.15 (34.6 examples/sec; 0.231 sec/batch; 20h:24m:39s remains)
INFO - root - 2017-12-17 03:42:35.536509: step 14680, loss = 0.21, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 19h:27m:29s remains)
INFO - root - 2017-12-17 03:42:37.821311: step 14690, loss = 0.26, batch loss = 0.18 (33.8 examples/sec; 0.237 sec/batch; 20h:54m:01s remains)
INFO - root - 2017-12-17 03:42:40.079955: step 14700, loss = 0.25, batch loss = 0.18 (35.6 examples/sec; 0.224 sec/batch; 19h:48m:44s remains)
INFO - root - 2017-12-17 03:42:42.454004: step 14710, loss = 0.21, batch loss = 0.13 (36.1 examples/sec; 0.221 sec/batch; 19h:32m:40s remains)
INFO - root - 2017-12-17 03:42:44.678722: step 14720, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.224 sec/batch; 19h:44m:32s remains)
INFO - root - 2017-12-17 03:42:46.956069: step 14730, loss = 0.24, batch loss = 0.17 (35.5 examples/sec; 0.226 sec/batch; 19h:54m:46s remains)
INFO - root - 2017-12-17 03:42:49.229549: step 14740, loss = 0.25, batch loss = 0.17 (35.0 examples/sec; 0.229 sec/batch; 20h:11m:31s remains)
INFO - root - 2017-12-17 03:42:51.472122: step 14750, loss = 0.22, batch loss = 0.15 (35.8 examples/sec; 0.224 sec/batch; 19h:44m:18s remains)
INFO - root - 2017-12-17 03:42:53.704037: step 14760, loss = 0.23, batch loss = 0.15 (36.6 examples/sec; 0.219 sec/batch; 19h:17m:37s remains)
INFO - root - 2017-12-17 03:42:55.927290: step 14770, loss = 0.21, batch loss = 0.13 (36.5 examples/sec; 0.219 sec/batch; 19h:19m:55s remains)
INFO - root - 2017-12-17 03:42:58.187039: step 14780, loss = 0.32, batch loss = 0.24 (35.0 examples/sec; 0.229 sec/batch; 20h:10m:09s remains)
INFO - root - 2017-12-17 03:43:00.448932: step 14790, loss = 0.27, batch loss = 0.19 (36.7 examples/sec; 0.218 sec/batch; 19h:13m:40s remains)
INFO - root - 2017-12-17 03:43:02.688888: step 14800, loss = 0.19, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 20h:08m:03s remains)
INFO - root - 2017-12-17 03:43:05.035425: step 14810, loss = 0.22, batch loss = 0.15 (36.7 examples/sec; 0.218 sec/batch; 19h:15m:40s remains)
INFO - root - 2017-12-17 03:43:07.310354: step 14820, loss = 0.18, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 20h:25m:03s remains)
INFO - root - 2017-12-17 03:43:09.550777: step 14830, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 19h:55m:36s remains)
INFO - root - 2017-12-17 03:43:11.798681: step 14840, loss = 0.23, batch loss = 0.15 (35.8 examples/sec; 0.223 sec/batch; 19h:41m:42s remains)
INFO - root - 2017-12-17 03:43:14.089507: step 14850, loss = 0.23, batch loss = 0.15 (33.8 examples/sec; 0.237 sec/batch; 20h:53m:33s remains)
INFO - root - 2017-12-17 03:43:16.362223: step 14860, loss = 0.17, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 19h:47m:13s remains)
INFO - root - 2017-12-17 03:43:18.646217: step 14870, loss = 0.23, batch loss = 0.15 (34.8 examples/sec; 0.230 sec/batch; 20h:15m:32s remains)
INFO - root - 2017-12-17 03:43:20.893464: step 14880, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.223 sec/batch; 19h:42m:35s remains)
INFO - root - 2017-12-17 03:43:23.211053: step 14890, loss = 0.22, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 19h:56m:48s remains)
INFO - root - 2017-12-17 03:43:25.460492: step 14900, loss = 0.19, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 19h:20m:21s remains)
INFO - root - 2017-12-17 03:43:27.874504: step 14910, loss = 0.23, batch loss = 0.15 (34.0 examples/sec; 0.235 sec/batch; 20h:46m:30s remains)
INFO - root - 2017-12-17 03:43:30.137922: step 14920, loss = 0.26, batch loss = 0.18 (34.8 examples/sec; 0.230 sec/batch; 20h:16m:28s remains)
INFO - root - 2017-12-17 03:43:32.371358: step 14930, loss = 0.20, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 19h:59m:59s remains)
INFO - root - 2017-12-17 03:43:34.611587: step 14940, loss = 0.18, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 19h:29m:14s remains)
INFO - root - 2017-12-17 03:43:36.888127: step 14950, loss = 0.24, batch loss = 0.16 (35.9 examples/sec; 0.223 sec/batch; 19h:39m:00s remains)
INFO - root - 2017-12-17 03:43:39.159248: step 14960, loss = 0.23, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 19h:40m:44s remains)
INFO - root - 2017-12-17 03:43:41.417025: step 14970, loss = 0.26, batch loss = 0.18 (35.3 examples/sec; 0.226 sec/batch; 19h:58m:03s remains)
INFO - root - 2017-12-17 03:43:43.690155: step 14980, loss = 0.29, batch loss = 0.21 (35.3 examples/sec; 0.226 sec/batch; 19h:58m:20s remains)
INFO - root - 2017-12-17 03:43:45.960820: step 14990, loss = 0.21, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 20h:06m:38s remains)
INFO - root - 2017-12-17 03:43:48.199231: step 15000, loss = 0.23, batch loss = 0.15 (35.7 examples/sec; 0.224 sec/batch; 19h:45m:01s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-15000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-15000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 03:43:51.045142: step 15010, loss = 0.24, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 19h:30m:35s remains)
INFO - root - 2017-12-17 03:43:53.314040: step 15020, loss = 0.25, batch loss = 0.17 (34.9 examples/sec; 0.229 sec/batch; 20h:11m:41s remains)
INFO - root - 2017-12-17 03:43:55.551454: step 15030, loss = 0.24, batch loss = 0.16 (36.0 examples/sec; 0.222 sec/batch; 19h:36m:33s remains)
INFO - root - 2017-12-17 03:43:57.797503: step 15040, loss = 0.20, batch loss = 0.12 (36.6 examples/sec; 0.218 sec/batch; 19h:15m:29s remains)
INFO - root - 2017-12-17 03:44:00.034333: step 15050, loss = 0.23, batch loss = 0.15 (34.5 examples/sec; 0.232 sec/batch; 20h:25m:24s remains)
INFO - root - 2017-12-17 03:44:02.319489: step 15060, loss = 0.27, batch loss = 0.19 (36.1 examples/sec; 0.222 sec/batch; 19h:33m:56s remains)
INFO - root - 2017-12-17 03:44:04.575155: step 15070, loss = 0.24, batch loss = 0.16 (35.3 examples/sec; 0.226 sec/batch; 19h:58m:09s remains)
INFO - root - 2017-12-17 03:44:06.843552: step 15080, loss = 0.21, batch loss = 0.14 (34.5 examples/sec; 0.232 sec/batch; 20h:25m:45s remains)
INFO - root - 2017-12-17 03:44:09.103721: step 15090, loss = 0.25, batch loss = 0.17 (36.2 examples/sec; 0.221 sec/batch; 19h:27m:45s remains)
INFO - root - 2017-12-17 03:44:11.356380: step 15100, loss = 0.25, batch loss = 0.17 (35.3 examples/sec; 0.227 sec/batch; 19h:58m:19s remains)
INFO - root - 2017-12-17 03:44:13.776656: step 15110, loss = 0.22, batch loss = 0.14 (35.2 examples/sec; 0.227 sec/batch; 20h:01m:15s remains)
INFO - root - 2017-12-17 03:44:15.997246: step 15120, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:56m:24s remains)
INFO - root - 2017-12-17 03:44:18.236114: step 15130, loss = 0.24, batch loss = 0.16 (35.6 examples/sec; 0.225 sec/batch; 19h:49m:56s remains)
INFO - root - 2017-12-17 03:44:20.476104: step 15140, loss = 0.25, batch loss = 0.17 (35.2 examples/sec; 0.227 sec/batch; 20h:01m:58s remains)
INFO - root - 2017-12-17 03:44:22.714933: step 15150, loss = 0.22, batch loss = 0.15 (35.3 examples/sec; 0.227 sec/batch; 19h:59m:15s remains)
INFO - root - 2017-12-17 03:44:24.937524: step 15160, loss = 0.20, batch loss = 0.12 (36.3 examples/sec; 0.221 sec/batch; 19h:26m:38s remains)
INFO - root - 2017-12-17 03:44:27.177213: step 15170, loss = 0.18, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 19h:30m:18s remains)
INFO - root - 2017-12-17 03:44:29.393478: step 15180, loss = 0.27, batch loss = 0.19 (35.3 examples/sec; 0.227 sec/batch; 19h:58m:15s remains)
INFO - root - 2017-12-17 03:44:31.709170: step 15190, loss = 0.23, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 19h:34m:29s remains)
INFO - root - 2017-12-17 03:44:33.975475: step 15200, loss = 0.19, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 19h:58m:16s remains)
INFO - root - 2017-12-17 03:44:36.350796: step 15210, loss = 0.21, batch loss = 0.13 (36.6 examples/sec; 0.218 sec/batch; 19h:15m:03s remains)
INFO - root - 2017-12-17 03:44:38.673579: step 15220, loss = 0.20, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 19h:49m:45s remains)
INFO - root - 2017-12-17 03:44:40.939833: step 15230, loss = 0.28, batch loss = 0.20 (33.5 examples/sec; 0.239 sec/batch; 21h:02m:34s remains)
INFO - root - 2017-12-17 03:44:43.204079: step 15240, loss = 0.19, batch loss = 0.11 (35.2 examples/sec; 0.227 sec/batch; 20h:00m:58s remains)
INFO - root - 2017-12-17 03:44:45.422482: step 15250, loss = 0.19, batch loss = 0.11 (36.6 examples/sec; 0.218 sec/batch; 19h:15m:07s remains)
INFO - root - 2017-12-17 03:44:47.712297: step 15260, loss = 0.25, batch loss = 0.18 (36.6 examples/sec; 0.218 sec/batch; 19h:15m:09s remains)
INFO - root - 2017-12-17 03:44:49.956181: step 15270, loss = 0.22, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 19h:27m:37s remains)
INFO - root - 2017-12-17 03:44:52.194189: step 15280, loss = 0.21, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 19h:28m:28s remains)
INFO - root - 2017-12-17 03:44:54.494329: step 15290, loss = 0.26, batch loss = 0.18 (35.7 examples/sec; 0.224 sec/batch; 19h:44m:15s remains)
INFO - root - 2017-12-17 03:44:56.745360: step 15300, loss = 0.24, batch loss = 0.16 (36.0 examples/sec; 0.222 sec/batch; 19h:33m:33s remains)
INFO - root - 2017-12-17 03:44:59.129883: step 15310, loss = 0.20, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 19h:20m:30s remains)
INFO - root - 2017-12-17 03:45:01.381448: step 15320, loss = 0.18, batch loss = 0.11 (33.5 examples/sec; 0.239 sec/batch; 21h:03m:41s remains)
INFO - root - 2017-12-17 03:45:03.639533: step 15330, loss = 0.21, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 19h:29m:18s remains)
INFO - root - 2017-12-17 03:45:05.881594: step 15340, loss = 0.24, batch loss = 0.16 (35.9 examples/sec; 0.223 sec/batch; 19h:39m:03s remains)
INFO - root - 2017-12-17 03:45:08.168725: step 15350, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 20h:07m:03s remains)
INFO - root - 2017-12-17 03:45:10.402794: step 15360, loss = 0.23, batch loss = 0.15 (35.0 examples/sec; 0.229 sec/batch; 20h:09m:38s remains)
INFO - root - 2017-12-17 03:45:12.693816: step 15370, loss = 0.20, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 19h:12m:11s remains)
INFO - root - 2017-12-17 03:45:14.916153: step 15380, loss = 0.17, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 19h:16m:01s remains)
INFO - root - 2017-12-17 03:45:17.142243: step 15390, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 20h:12m:45s remains)
INFO - root - 2017-12-17 03:45:19.379703: step 15400, loss = 0.25, batch loss = 0.18 (37.1 examples/sec; 0.216 sec/batch; 19h:01m:07s remains)
INFO - root - 2017-12-17 03:45:21.771067: step 15410, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 20h:03m:55s remains)
INFO - root - 2017-12-17 03:45:24.063992: step 15420, loss = 0.21, batch loss = 0.13 (36.6 examples/sec; 0.219 sec/batch; 19h:16m:37s remains)
INFO - root - 2017-12-17 03:45:26.306033: step 15430, loss = 0.30, batch loss = 0.22 (34.9 examples/sec; 0.229 sec/batch; 20h:11m:18s remains)
INFO - root - 2017-12-17 03:45:28.559154: step 15440, loss = 0.20, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 20h:07m:02s remains)
INFO - root - 2017-12-17 03:45:30.844422: step 15450, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 20h:09m:58s remains)
INFO - root - 2017-12-17 03:45:33.090813: step 15460, loss = 0.21, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 19h:52m:36s remains)
INFO - root - 2017-12-17 03:45:35.384843: step 15470, loss = 0.22, batch loss = 0.14 (35.3 examples/sec; 0.227 sec/batch; 19h:59m:03s remains)
INFO - root - 2017-12-17 03:45:37.638060: step 15480, loss = 0.22, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 19h:38m:50s remains)
INFO - root - 2017-12-17 03:45:39.906062: step 15490, loss = 0.18, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 19h:31m:34s remains)
INFO - root - 2017-12-17 03:45:42.189046: step 15500, loss = 0.17, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 19h:46m:23s remains)
INFO - root - 2017-12-17 03:45:44.567972: step 15510, loss = 0.23, batch loss = 0.15 (35.8 examples/sec; 0.223 sec/batch; 19h:39m:35s remains)
INFO - root - 2017-12-17 03:45:46.812585: step 15520, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:53m:37s remains)
INFO - root - 2017-12-17 03:45:49.074071: step 15530, loss = 0.25, batch loss = 0.17 (36.1 examples/sec; 0.221 sec/batch; 19h:29m:07s remains)
INFO - root - 2017-12-17 03:45:51.318402: step 15540, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:54m:32s remains)
INFO - root - 2017-12-17 03:45:53.549639: step 15550, loss = 0.22, batch loss = 0.15 (34.8 examples/sec; 0.230 sec/batch; 20h:12m:38s remains)
INFO - root - 2017-12-17 03:45:55.801111: step 15560, loss = 0.22, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 19h:34m:06s remains)
INFO - root - 2017-12-17 03:45:58.086359: step 15570, loss = 0.26, batch loss = 0.18 (34.7 examples/sec; 0.230 sec/batch; 20h:16m:02s remains)
INFO - root - 2017-12-17 03:46:00.313830: step 15580, loss = 0.19, batch loss = 0.11 (37.0 examples/sec; 0.216 sec/batch; 19h:02m:14s remains)
INFO - root - 2017-12-17 03:46:02.549932: step 15590, loss = 0.19, batch loss = 0.11 (35.2 examples/sec; 0.228 sec/batch; 20h:01m:43s remains)
INFO - root - 2017-12-17 03:46:04.812589: step 15600, loss = 0.20, batch loss = 0.12 (34.3 examples/sec; 0.234 sec/batch; 20h:33m:37s remains)
INFO - root - 2017-12-17 03:46:07.204864: step 15610, loss = 0.23, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 20h:02m:21s remains)
INFO - root - 2017-12-17 03:46:09.473590: step 15620, loss = 0.17, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 19h:36m:31s remains)
INFO - root - 2017-12-17 03:46:11.743711: step 15630, loss = 0.22, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 19h:16m:30s remains)
INFO - root - 2017-12-17 03:46:14.017589: step 15640, loss = 0.18, batch loss = 0.10 (33.2 examples/sec; 0.241 sec/batch; 21h:12m:18s remains)
INFO - root - 2017-12-17 03:46:16.269873: step 15650, loss = 0.21, batch loss = 0.13 (36.3 examples/sec; 0.221 sec/batch; 19h:25m:03s remains)
INFO - root - 2017-12-17 03:46:18.504420: step 15660, loss = 0.19, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 19h:16m:11s remains)
INFO - root - 2017-12-17 03:46:20.755726: step 15670, loss = 0.19, batch loss = 0.12 (36.6 examples/sec; 0.219 sec/batch; 19h:14m:50s remains)
INFO - root - 2017-12-17 03:46:22.999123: step 15680, loss = 0.20, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 20h:12m:43s remains)
INFO - root - 2017-12-17 03:46:25.263588: step 15690, loss = 0.32, batch loss = 0.24 (35.2 examples/sec; 0.227 sec/batch; 19h:59m:28s remains)
INFO - root - 2017-12-17 03:46:27.537818: step 15700, loss = 0.25, batch loss = 0.17 (36.0 examples/sec; 0.222 sec/batch; 19h:32m:05s remains)
INFO - root - 2017-12-17 03:46:29.898961: step 15710, loss = 0.24, batch loss = 0.16 (35.3 examples/sec; 0.227 sec/batch; 19h:56m:05s remains)
INFO - root - 2017-12-17 03:46:32.241463: step 15720, loss = 0.24, batch loss = 0.16 (33.1 examples/sec; 0.241 sec/batch; 21h:14m:24s remains)
INFO - root - 2017-12-17 03:46:34.505339: step 15730, loss = 0.22, batch loss = 0.14 (35.2 examples/sec; 0.227 sec/batch; 20h:00m:03s remains)
INFO - root - 2017-12-17 03:46:36.756666: step 15740, loss = 0.18, batch loss = 0.10 (35.8 examples/sec; 0.223 sec/batch; 19h:38m:10s remains)
INFO - root - 2017-12-17 03:46:39.007200: step 15750, loss = 0.21, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 19h:39m:35s remains)
INFO - root - 2017-12-17 03:46:41.260370: step 15760, loss = 0.23, batch loss = 0.15 (34.6 examples/sec; 0.231 sec/batch; 20h:20m:07s remains)
INFO - root - 2017-12-17 03:46:43.505323: step 15770, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.223 sec/batch; 19h:38m:02s remains)
INFO - root - 2017-12-17 03:46:45.744037: step 15780, loss = 0.20, batch loss = 0.12 (35.3 examples/sec; 0.226 sec/batch; 19h:55m:01s remains)
INFO - root - 2017-12-17 03:46:47.986035: step 15790, loss = 0.26, batch loss = 0.18 (36.8 examples/sec; 0.217 sec/batch; 19h:06m:16s remains)
INFO - root - 2017-12-17 03:46:50.249485: step 15800, loss = 0.26, batch loss = 0.18 (36.0 examples/sec; 0.222 sec/batch; 19h:31m:38s remains)
INFO - root - 2017-12-17 03:46:52.613594: step 15810, loss = 0.20, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 19h:45m:12s remains)
INFO - root - 2017-12-17 03:46:54.888588: step 15820, loss = 0.23, batch loss = 0.15 (36.3 examples/sec; 0.220 sec/batch; 19h:22m:43s remains)
INFO - root - 2017-12-17 03:46:57.160667: step 15830, loss = 0.20, batch loss = 0.13 (32.9 examples/sec; 0.243 sec/batch; 21h:22m:39s remains)
INFO - root - 2017-12-17 03:46:59.415379: step 15840, loss = 0.26, batch loss = 0.19 (36.5 examples/sec; 0.219 sec/batch; 19h:16m:57s remains)
INFO - root - 2017-12-17 03:47:01.644847: step 15850, loss = 0.19, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 19h:47m:12s remains)
INFO - root - 2017-12-17 03:47:03.922149: step 15860, loss = 0.21, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 19h:45m:52s remains)
INFO - root - 2017-12-17 03:47:06.164195: step 15870, loss = 0.19, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 19h:26m:12s remains)
INFO - root - 2017-12-17 03:47:08.420644: step 15880, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 19h:51m:08s remains)
INFO - root - 2017-12-17 03:47:10.705433: step 15890, loss = 0.28, batch loss = 0.20 (36.5 examples/sec; 0.219 sec/batch; 19h:15m:12s remains)
INFO - root - 2017-12-17 03:47:12.925349: step 15900, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 19h:42m:31s remains)
INFO - root - 2017-12-17 03:47:15.327721: step 15910, loss = 0.19, batch loss = 0.11 (34.3 examples/sec; 0.234 sec/batch; 20h:32m:22s remains)
INFO - root - 2017-12-17 03:47:17.589632: step 15920, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.224 sec/batch; 19h:39m:40s remains)
INFO - root - 2017-12-17 03:47:19.849241: step 15930, loss = 0.24, batch loss = 0.16 (35.7 examples/sec; 0.224 sec/batch; 19h:43m:35s remains)
INFO - root - 2017-12-17 03:47:22.122077: step 15940, loss = 0.18, batch loss = 0.10 (34.7 examples/sec; 0.231 sec/batch; 20h:16m:53s remains)
INFO - root - 2017-12-17 03:47:24.395317: step 15950, loss = 0.23, batch loss = 0.15 (34.6 examples/sec; 0.231 sec/batch; 20h:19m:31s remains)
INFO - root - 2017-12-17 03:47:26.652330: step 15960, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 19h:41m:17s remains)
INFO - root - 2017-12-17 03:47:28.917318: step 15970, loss = 0.26, batch loss = 0.18 (34.8 examples/sec; 0.230 sec/batch; 20h:13m:33s remains)
INFO - root - 2017-12-17 03:47:31.162684: step 15980, loss = 0.19, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 19h:56m:23s remains)
INFO - root - 2017-12-17 03:47:33.405769: step 15990, loss = 0.20, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 20h:10m:36s remains)
INFO - root - 2017-12-17 03:47:35.640398: step 16000, loss = 0.25, batch loss = 0.17 (35.2 examples/sec; 0.227 sec/batch; 19h:59m:35s remains)
INFO - root - 2017-12-17 03:47:38.027605: step 16010, loss = 0.22, batch loss = 0.14 (34.7 examples/sec; 0.231 sec/batch; 20h:15m:57s remains)
INFO - root - 2017-12-17 03:47:40.287214: step 16020, loss = 0.27, batch loss = 0.19 (36.1 examples/sec; 0.222 sec/batch; 19h:30m:19s remains)
INFO - root - 2017-12-17 03:47:42.547835: step 16030, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:50m:31s remains)
INFO - root - 2017-12-17 03:47:44.778328: step 16040, loss = 0.18, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:35m:16s remains)
INFO - root - 2017-12-17 03:47:47.065406: step 16050, loss = 0.23, batch loss = 0.15 (34.1 examples/sec; 0.234 sec/batch; 20h:35m:43s remains)
INFO - root - 2017-12-17 03:47:49.310984: step 16060, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.223 sec/batch; 19h:38m:28s remains)
INFO - root - 2017-12-17 03:47:51.557010: step 16070, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 19h:32m:14s remains)
INFO - root - 2017-12-17 03:47:53.793559: step 16080, loss = 0.25, batch loss = 0.17 (35.6 examples/sec; 0.225 sec/batch; 19h:44m:44s remains)
INFO - root - 2017-12-17 03:47:56.086256: step 16090, loss = 0.20, batch loss = 0.12 (34.4 examples/sec; 0.232 sec/batch; 20h:25m:18s remains)
INFO - root - 2017-12-17 03:47:58.374556: step 16100, loss = 0.27, batch loss = 0.20 (36.3 examples/sec; 0.220 sec/batch; 19h:21m:48s remains)
INFO - root - 2017-12-17 03:48:00.737907: step 16110, loss = 0.18, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 20h:15m:42s remains)
INFO - root - 2017-12-17 03:48:03.007056: step 16120, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 20h:08m:23s remains)
INFO - root - 2017-12-17 03:48:05.256619: step 16130, loss = 0.17, batch loss = 0.09 (35.8 examples/sec; 0.224 sec/batch; 19h:39m:06s remains)
INFO - root - 2017-12-17 03:48:07.492320: step 16140, loss = 0.19, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 19h:53m:02s remains)
INFO - root - 2017-12-17 03:48:09.795865: step 16150, loss = 0.24, batch loss = 0.16 (34.9 examples/sec; 0.229 sec/batch; 20h:09m:52s remains)
INFO - root - 2017-12-17 03:48:12.047048: step 16160, loss = 0.20, batch loss = 0.12 (35.8 examples/sec; 0.223 sec/batch; 19h:37m:41s remains)
INFO - root - 2017-12-17 03:48:14.291306: step 16170, loss = 0.17, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 19h:26m:39s remains)
INFO - root - 2017-12-17 03:48:16.555227: step 16180, loss = 0.21, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 19h:42m:03s remains)
INFO - root - 2017-12-17 03:48:18.826841: step 16190, loss = 0.22, batch loss = 0.14 (34.4 examples/sec; 0.232 sec/batch; 20h:24m:47s remains)
INFO - root - 2017-12-17 03:48:21.087195: step 16200, loss = 0.19, batch loss = 0.11 (36.7 examples/sec; 0.218 sec/batch; 19h:07m:41s remains)
INFO - root - 2017-12-17 03:48:23.467404: step 16210, loss = 0.20, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 19h:44m:01s remains)
INFO - root - 2017-12-17 03:48:25.724299: step 16220, loss = 0.18, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 19h:57m:06s remains)
INFO - root - 2017-12-17 03:48:27.985286: step 16230, loss = 0.24, batch loss = 0.16 (34.2 examples/sec; 0.234 sec/batch; 20h:33m:54s remains)
INFO - root - 2017-12-17 03:48:30.279857: step 16240, loss = 0.18, batch loss = 0.10 (34.1 examples/sec; 0.235 sec/batch; 20h:37m:33s remains)
INFO - root - 2017-12-17 03:48:32.535243: step 16250, loss = 0.19, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 19h:30m:57s remains)
INFO - root - 2017-12-17 03:48:34.797180: step 16260, loss = 0.29, batch loss = 0.21 (34.5 examples/sec; 0.232 sec/batch; 20h:23m:54s remains)
INFO - root - 2017-12-17 03:48:37.074391: step 16270, loss = 0.19, batch loss = 0.11 (34.0 examples/sec; 0.235 sec/batch; 20h:38m:23s remains)
INFO - root - 2017-12-17 03:48:39.375673: step 16280, loss = 0.20, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 20h:18m:19s remains)
INFO - root - 2017-12-17 03:48:41.620384: step 16290, loss = 0.19, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 19h:24m:09s remains)
INFO - root - 2017-12-17 03:48:43.915770: step 16300, loss = 0.19, batch loss = 0.11 (34.7 examples/sec; 0.230 sec/batch; 20h:14m:01s remains)
INFO - root - 2017-12-17 03:48:46.315782: step 16310, loss = 0.19, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 20h:16m:28s remains)
INFO - root - 2017-12-17 03:48:48.552062: step 16320, loss = 0.23, batch loss = 0.15 (35.5 examples/sec; 0.226 sec/batch; 19h:48m:19s remains)
INFO - root - 2017-12-17 03:48:50.801555: step 16330, loss = 0.21, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 19h:54m:15s remains)
INFO - root - 2017-12-17 03:48:53.063249: step 16340, loss = 0.22, batch loss = 0.14 (37.0 examples/sec; 0.216 sec/batch; 19h:00m:14s remains)
INFO - root - 2017-12-17 03:48:55.323736: step 16350, loss = 0.22, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 19h:31m:27s remains)
INFO - root - 2017-12-17 03:48:57.568637: step 16360, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 19h:53m:27s remains)
INFO - root - 2017-12-17 03:48:59.850003: step 16370, loss = 0.19, batch loss = 0.11 (37.0 examples/sec; 0.216 sec/batch; 18h:59m:07s remains)
INFO - root - 2017-12-17 03:49:02.077906: step 16380, loss = 0.21, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 19h:17m:20s remains)
INFO - root - 2017-12-17 03:49:04.325241: step 16390, loss = 0.19, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 20h:07m:49s remains)
INFO - root - 2017-12-17 03:49:06.576171: step 16400, loss = 0.23, batch loss = 0.15 (36.9 examples/sec; 0.217 sec/batch; 19h:03m:25s remains)
INFO - root - 2017-12-17 03:49:08.970191: step 16410, loss = 0.17, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 19h:15m:14s remains)
INFO - root - 2017-12-17 03:49:11.215377: step 16420, loss = 0.22, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 19h:30m:39s remains)
INFO - root - 2017-12-17 03:49:13.436879: step 16430, loss = 0.19, batch loss = 0.11 (36.8 examples/sec; 0.217 sec/batch; 19h:03m:55s remains)
INFO - root - 2017-12-17 03:49:15.712871: step 16440, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 19h:39m:22s remains)
INFO - root - 2017-12-17 03:49:17.948411: step 16450, loss = 0.21, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 19h:33m:11s remains)
INFO - root - 2017-12-17 03:49:20.216558: step 16460, loss = 0.18, batch loss = 0.10 (35.1 examples/sec; 0.228 sec/batch; 20h:01m:41s remains)
INFO - root - 2017-12-17 03:49:22.510675: step 16470, loss = 0.22, batch loss = 0.15 (36.4 examples/sec; 0.220 sec/batch; 19h:18m:31s remains)
INFO - root - 2017-12-17 03:49:24.796404: step 16480, loss = 0.25, batch loss = 0.18 (35.9 examples/sec; 0.223 sec/batch; 19h:34m:01s remains)
INFO - root - 2017-12-17 03:49:27.059486: step 16490, loss = 0.26, batch loss = 0.18 (36.3 examples/sec; 0.221 sec/batch; 19h:21m:47s remains)
INFO - root - 2017-12-17 03:49:29.315806: step 16500, loss = 0.20, batch loss = 0.12 (35.8 examples/sec; 0.223 sec/batch; 19h:35m:46s remains)
INFO - root - 2017-12-17 03:49:31.717579: step 16510, loss = 0.22, batch loss = 0.15 (36.3 examples/sec; 0.220 sec/batch; 19h:20m:49s remains)
INFO - root - 2017-12-17 03:49:33.970022: step 16520, loss = 0.18, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 19h:31m:22s remains)
INFO - root - 2017-12-17 03:49:36.243650: step 16530, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.224 sec/batch; 19h:38m:25s remains)
INFO - root - 2017-12-17 03:49:38.479531: step 16540, loss = 0.21, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 19h:24m:54s remains)
INFO - root - 2017-12-17 03:49:40.723355: step 16550, loss = 0.25, batch loss = 0.17 (35.9 examples/sec; 0.223 sec/batch; 19h:33m:15s remains)
INFO - root - 2017-12-17 03:49:42.972752: step 16560, loss = 0.23, batch loss = 0.15 (35.8 examples/sec; 0.223 sec/batch; 19h:36m:00s remains)
INFO - root - 2017-12-17 03:49:45.229640: step 16570, loss = 0.20, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 20h:05m:51s remains)
INFO - root - 2017-12-17 03:49:47.506782: step 16580, loss = 0.21, batch loss = 0.14 (34.7 examples/sec; 0.231 sec/batch; 20h:14m:06s remains)
INFO - root - 2017-12-17 03:49:49.805953: step 16590, loss = 0.22, batch loss = 0.14 (35.5 examples/sec; 0.225 sec/batch; 19h:46m:35s remains)
INFO - root - 2017-12-17 03:49:52.050577: step 16600, loss = 0.28, batch loss = 0.20 (36.1 examples/sec; 0.222 sec/batch; 19h:27m:06s remains)
INFO - root - 2017-12-17 03:49:54.412080: step 16610, loss = 0.23, batch loss = 0.15 (36.1 examples/sec; 0.222 sec/batch; 19h:27m:46s remains)
INFO - root - 2017-12-17 03:49:56.681650: step 16620, loss = 0.19, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 19h:43m:00s remains)
INFO - root - 2017-12-17 03:49:58.988271: step 16630, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 19h:56m:48s remains)
INFO - root - 2017-12-17 03:50:01.250822: step 16640, loss = 0.21, batch loss = 0.14 (35.3 examples/sec; 0.227 sec/batch; 19h:52m:35s remains)
INFO - root - 2017-12-17 03:50:03.522548: step 16650, loss = 0.20, batch loss = 0.13 (34.3 examples/sec; 0.234 sec/batch; 20h:29m:26s remains)
INFO - root - 2017-12-17 03:50:05.822328: step 16660, loss = 0.21, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 19h:31m:27s remains)
INFO - root - 2017-12-17 03:50:08.065355: step 16670, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 19h:39m:23s remains)
INFO - root - 2017-12-17 03:50:10.341016: step 16680, loss = 0.21, batch loss = 0.14 (37.1 examples/sec; 0.216 sec/batch; 18h:54m:41s remains)
INFO - root - 2017-12-17 03:50:12.642909: step 16690, loss = 0.25, batch loss = 0.17 (34.7 examples/sec; 0.230 sec/batch; 20h:12m:09s remains)
INFO - root - 2017-12-17 03:50:14.927965: step 16700, loss = 0.23, batch loss = 0.16 (35.5 examples/sec; 0.225 sec/batch; 19h:45m:36s remains)
INFO - root - 2017-12-17 03:50:17.300004: step 16710, loss = 0.22, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 19h:40m:57s remains)
INFO - root - 2017-12-17 03:50:19.580082: step 16720, loss = 0.21, batch loss = 0.14 (33.4 examples/sec; 0.240 sec/batch; 21h:01m:34s remains)
INFO - root - 2017-12-17 03:50:21.841430: step 16730, loss = 0.16, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 19h:24m:33s remains)
INFO - root - 2017-12-17 03:50:24.155399: step 16740, loss = 0.23, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 19h:56m:19s remains)
INFO - root - 2017-12-17 03:50:26.449814: step 16750, loss = 0.24, batch loss = 0.17 (34.8 examples/sec; 0.230 sec/batch; 20h:08m:58s remains)
INFO - root - 2017-12-17 03:50:28.685183: step 16760, loss = 0.19, batch loss = 0.11 (35.2 examples/sec; 0.227 sec/batch; 19h:55m:54s remains)
INFO - root - 2017-12-17 03:50:30.974055: step 16770, loss = 0.20, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 19h:14m:51s remains)
INFO - root - 2017-12-17 03:50:33.231182: step 16780, loss = 0.23, batch loss = 0.16 (34.6 examples/sec; 0.231 sec/batch; 20h:15m:11s remains)
INFO - root - 2017-12-17 03:50:35.507130: step 16790, loss = 0.23, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 19h:34m:00s remains)
INFO - root - 2017-12-17 03:50:37.776035: step 16800, loss = 0.21, batch loss = 0.13 (35.0 examples/sec; 0.228 sec/batch; 20h:01m:10s remains)
INFO - root - 2017-12-17 03:50:40.226376: step 16810, loss = 0.19, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 19h:46m:02s remains)
INFO - root - 2017-12-17 03:50:42.469107: step 16820, loss = 0.21, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 19h:17m:55s remains)
INFO - root - 2017-12-17 03:50:44.733062: step 16830, loss = 0.25, batch loss = 0.17 (36.2 examples/sec; 0.221 sec/batch; 19h:23m:44s remains)
INFO - root - 2017-12-17 03:50:47.008391: step 16840, loss = 0.18, batch loss = 0.10 (36.3 examples/sec; 0.221 sec/batch; 19h:20m:38s remains)
INFO - root - 2017-12-17 03:50:49.265704: step 16850, loss = 0.21, batch loss = 0.14 (34.7 examples/sec; 0.231 sec/batch; 20h:12m:38s remains)
INFO - root - 2017-12-17 03:50:51.522442: step 16860, loss = 0.18, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 19h:43m:40s remains)
INFO - root - 2017-12-17 03:50:53.780988: step 16870, loss = 0.20, batch loss = 0.12 (36.6 examples/sec; 0.218 sec/batch; 19h:08m:50s remains)
INFO - root - 2017-12-17 03:50:56.029495: step 16880, loss = 0.19, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 19h:37m:40s remains)
INFO - root - 2017-12-17 03:50:58.292808: step 16890, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 19h:39m:42s remains)
INFO - root - 2017-12-17 03:51:00.555099: step 16900, loss = 0.24, batch loss = 0.16 (36.3 examples/sec; 0.221 sec/batch; 19h:20m:41s remains)
INFO - root - 2017-12-17 03:51:02.919045: step 16910, loss = 0.22, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 19h:57m:24s remains)
INFO - root - 2017-12-17 03:51:05.186132: step 16920, loss = 0.22, batch loss = 0.14 (34.0 examples/sec; 0.235 sec/batch; 20h:37m:36s remains)
INFO - root - 2017-12-17 03:51:07.443117: step 16930, loss = 0.25, batch loss = 0.18 (34.7 examples/sec; 0.231 sec/batch; 20h:12m:35s remains)
INFO - root - 2017-12-17 03:51:09.705256: step 16940, loss = 0.23, batch loss = 0.15 (35.0 examples/sec; 0.229 sec/batch; 20h:02m:46s remains)
INFO - root - 2017-12-17 03:51:11.953665: step 16950, loss = 0.23, batch loss = 0.15 (35.7 examples/sec; 0.224 sec/batch; 19h:39m:09s remains)
INFO - root - 2017-12-17 03:51:14.225353: step 16960, loss = 0.22, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 19h:29m:13s remains)
INFO - root - 2017-12-17 03:51:16.465623: step 16970, loss = 0.33, batch loss = 0.26 (35.6 examples/sec; 0.225 sec/batch; 19h:42m:16s remains)
INFO - root - 2017-12-17 03:51:18.733831: step 16980, loss = 0.22, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 20h:04m:41s remains)
INFO - root - 2017-12-17 03:51:21.005475: step 16990, loss = 0.28, batch loss = 0.21 (33.6 examples/sec; 0.238 sec/batch; 20h:53m:05s remains)
INFO - root - 2017-12-17 03:51:23.342054: step 17000, loss = 0.19, batch loss = 0.11 (34.4 examples/sec; 0.233 sec/batch; 20h:23m:13s remains)
INFO - root - 2017-12-17 03:51:25.707090: step 17010, loss = 0.23, batch loss = 0.15 (35.5 examples/sec; 0.225 sec/batch; 19h:45m:41s remains)
INFO - root - 2017-12-17 03:51:27.972335: step 17020, loss = 0.23, batch loss = 0.16 (34.9 examples/sec; 0.229 sec/batch; 20h:05m:30s remains)
INFO - root - 2017-12-17 03:51:30.241302: step 17030, loss = 0.19, batch loss = 0.11 (35.6 examples/sec; 0.224 sec/batch; 19h:40m:18s remains)
INFO - root - 2017-12-17 03:51:32.466991: step 17040, loss = 0.21, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 19h:31m:46s remains)
INFO - root - 2017-12-17 03:51:34.753046: step 17050, loss = 0.18, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 19h:36m:29s remains)
INFO - root - 2017-12-17 03:51:37.013254: step 17060, loss = 0.17, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 19h:32m:25s remains)
INFO - root - 2017-12-17 03:51:39.293275: step 17070, loss = 0.20, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 19h:59m:59s remains)
INFO - root - 2017-12-17 03:51:41.600444: step 17080, loss = 0.21, batch loss = 0.13 (35.5 examples/sec; 0.226 sec/batch; 19h:45m:37s remains)
INFO - root - 2017-12-17 03:51:43.873535: step 17090, loss = 0.19, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 19h:33m:03s remains)
INFO - root - 2017-12-17 03:51:46.121837: step 17100, loss = 0.27, batch loss = 0.20 (35.6 examples/sec; 0.224 sec/batch; 19h:40m:00s remains)
INFO - root - 2017-12-17 03:51:48.500518: step 17110, loss = 0.22, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 19h:18m:16s remains)
INFO - root - 2017-12-17 03:51:50.774985: step 17120, loss = 0.21, batch loss = 0.14 (34.7 examples/sec; 0.230 sec/batch; 20h:10m:32s remains)
INFO - root - 2017-12-17 03:51:53.041366: step 17130, loss = 0.26, batch loss = 0.18 (35.8 examples/sec; 0.223 sec/batch; 19h:33m:36s remains)
INFO - root - 2017-12-17 03:51:55.310865: step 17140, loss = 0.22, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 20h:09m:05s remains)
INFO - root - 2017-12-17 03:51:57.553363: step 17150, loss = 0.24, batch loss = 0.17 (35.6 examples/sec; 0.225 sec/batch; 19h:41m:28s remains)
INFO - root - 2017-12-17 03:51:59.850623: step 17160, loss = 0.21, batch loss = 0.13 (33.4 examples/sec; 0.240 sec/batch; 21h:00m:21s remains)
INFO - root - 2017-12-17 03:52:02.106248: step 17170, loss = 0.20, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 19h:22m:29s remains)
INFO - root - 2017-12-17 03:52:04.351199: step 17180, loss = 0.27, batch loss = 0.19 (36.3 examples/sec; 0.220 sec/batch; 19h:17m:27s remains)
INFO - root - 2017-12-17 03:52:06.631802: step 17190, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 19h:22m:47s remains)
INFO - root - 2017-12-17 03:52:08.929801: step 17200, loss = 0.21, batch loss = 0.13 (36.5 examples/sec; 0.219 sec/batch; 19h:11m:51s remains)
INFO - root - 2017-12-17 03:52:11.322446: step 17210, loss = 0.22, batch loss = 0.14 (34.5 examples/sec; 0.232 sec/batch; 20h:17m:04s remains)
INFO - root - 2017-12-17 03:52:13.567909: step 17220, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.229 sec/batch; 20h:02m:05s remains)
INFO - root - 2017-12-17 03:52:15.828237: step 17230, loss = 0.22, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 19h:46m:33s remains)
INFO - root - 2017-12-17 03:52:18.105873: step 17240, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 19h:55m:17s remains)
INFO - root - 2017-12-17 03:52:20.379665: step 17250, loss = 0.18, batch loss = 0.10 (34.6 examples/sec; 0.231 sec/batch; 20h:15m:06s remains)
INFO - root - 2017-12-17 03:52:22.599295: step 17260, loss = 0.22, batch loss = 0.15 (35.6 examples/sec; 0.225 sec/batch; 19h:41m:03s remains)
INFO - root - 2017-12-17 03:52:24.845723: step 17270, loss = 0.24, batch loss = 0.17 (36.5 examples/sec; 0.219 sec/batch; 19h:11m:40s remains)
INFO - root - 2017-12-17 03:52:27.091371: step 17280, loss = 0.19, batch loss = 0.11 (33.7 examples/sec; 0.237 sec/batch; 20h:46m:13s remains)
INFO - root - 2017-12-17 03:52:29.333581: step 17290, loss = 0.19, batch loss = 0.11 (36.1 examples/sec; 0.221 sec/batch; 19h:23m:28s remains)
INFO - root - 2017-12-17 03:52:31.599108: step 17300, loss = 0.24, batch loss = 0.16 (36.1 examples/sec; 0.222 sec/batch; 19h:23m:52s remains)
INFO - root - 2017-12-17 03:52:34.030397: step 17310, loss = 0.21, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 19h:23m:45s remains)
INFO - root - 2017-12-17 03:52:36.259412: step 17320, loss = 0.21, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 19h:43m:57s remains)
INFO - root - 2017-12-17 03:52:38.521278: step 17330, loss = 0.20, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 20h:00m:20s remains)
INFO - root - 2017-12-17 03:52:40.774563: step 17340, loss = 0.24, batch loss = 0.16 (34.7 examples/sec; 0.231 sec/batch; 20h:12m:22s remains)
INFO - root - 2017-12-17 03:52:43.043509: step 17350, loss = 0.21, batch loss = 0.13 (33.5 examples/sec; 0.239 sec/batch; 20h:54m:16s remains)
INFO - root - 2017-12-17 03:52:45.273178: step 17360, loss = 0.26, batch loss = 0.18 (36.3 examples/sec; 0.220 sec/batch; 19h:17m:11s remains)
INFO - root - 2017-12-17 03:52:47.537212: step 17370, loss = 0.21, batch loss = 0.14 (36.8 examples/sec; 0.217 sec/batch; 19h:00m:24s remains)
INFO - root - 2017-12-17 03:52:49.743545: step 17380, loss = 0.28, batch loss = 0.20 (36.3 examples/sec; 0.221 sec/batch; 19h:18m:43s remains)
INFO - root - 2017-12-17 03:52:51.968831: step 17390, loss = 0.18, batch loss = 0.11 (34.7 examples/sec; 0.230 sec/batch; 20h:10m:25s remains)
INFO - root - 2017-12-17 03:52:54.212308: step 17400, loss = 0.21, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 19h:45m:34s remains)
INFO - root - 2017-12-17 03:52:56.700847: step 17410, loss = 0.21, batch loss = 0.14 (32.0 examples/sec; 0.250 sec/batch; 21h:51m:43s remains)
INFO - root - 2017-12-17 03:52:58.983454: step 17420, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 19h:43m:21s remains)
INFO - root - 2017-12-17 03:53:01.255440: step 17430, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 19h:34m:47s remains)
INFO - root - 2017-12-17 03:53:03.516970: step 17440, loss = 0.18, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 19h:44m:00s remains)
INFO - root - 2017-12-17 03:53:05.798727: step 17450, loss = 0.20, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 20h:12m:34s remains)
INFO - root - 2017-12-17 03:53:08.051732: step 17460, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:47m:29s remains)
INFO - root - 2017-12-17 03:53:10.306535: step 17470, loss = 0.20, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 19h:28m:58s remains)
INFO - root - 2017-12-17 03:53:12.576533: step 17480, loss = 0.25, batch loss = 0.17 (36.1 examples/sec; 0.222 sec/batch; 19h:23m:55s remains)
INFO - root - 2017-12-17 03:53:14.847838: step 17490, loss = 0.19, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 19h:19m:52s remains)
INFO - root - 2017-12-17 03:53:17.081812: step 17500, loss = 0.19, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 19h:35m:10s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-17500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-17500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 03:53:20.096811: step 17510, loss = 0.24, batch loss = 0.17 (34.1 examples/sec; 0.234 sec/batch; 20h:30m:03s remains)
INFO - root - 2017-12-17 03:53:22.363369: step 17520, loss = 0.16, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 19h:29m:53s remains)
INFO - root - 2017-12-17 03:53:24.623471: step 17530, loss = 0.19, batch loss = 0.11 (34.4 examples/sec; 0.233 sec/batch; 20h:21m:33s remains)
INFO - root - 2017-12-17 03:53:26.887532: step 17540, loss = 0.18, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 19h:23m:17s remains)
INFO - root - 2017-12-17 03:53:29.119709: step 17550, loss = 0.18, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 19h:10m:38s remains)
INFO - root - 2017-12-17 03:53:31.359940: step 17560, loss = 0.20, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 19h:40m:27s remains)
INFO - root - 2017-12-17 03:53:33.664077: step 17570, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 19h:36m:18s remains)
INFO - root - 2017-12-17 03:53:35.907046: step 17580, loss = 0.21, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 19h:39m:39s remains)
INFO - root - 2017-12-17 03:53:38.156376: step 17590, loss = 0.21, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 19h:39m:15s remains)
INFO - root - 2017-12-17 03:53:40.415069: step 17600, loss = 0.23, batch loss = 0.15 (35.6 examples/sec; 0.225 sec/batch; 19h:39m:53s remains)
INFO - root - 2017-12-17 03:53:42.788336: step 17610, loss = 0.20, batch loss = 0.12 (34.2 examples/sec; 0.234 sec/batch; 20h:27m:58s remains)
INFO - root - 2017-12-17 03:53:45.046898: step 17620, loss = 0.23, batch loss = 0.16 (35.8 examples/sec; 0.223 sec/batch; 19h:31m:40s remains)
INFO - root - 2017-12-17 03:53:47.279701: step 17630, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.223 sec/batch; 19h:31m:24s remains)
INFO - root - 2017-12-17 03:53:49.540857: step 17640, loss = 0.20, batch loss = 0.13 (35.0 examples/sec; 0.228 sec/batch; 19h:58m:08s remains)
INFO - root - 2017-12-17 03:53:51.835436: step 17650, loss = 0.22, batch loss = 0.14 (32.5 examples/sec; 0.246 sec/batch; 21h:33m:13s remains)
INFO - root - 2017-12-17 03:53:54.093671: step 17660, loss = 0.19, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 19h:22m:30s remains)
INFO - root - 2017-12-17 03:53:56.336427: step 17670, loss = 0.25, batch loss = 0.18 (35.0 examples/sec; 0.228 sec/batch; 19h:58m:50s remains)
INFO - root - 2017-12-17 03:53:58.576405: step 17680, loss = 0.21, batch loss = 0.14 (35.2 examples/sec; 0.227 sec/batch; 19h:53m:35s remains)
INFO - root - 2017-12-17 03:54:00.861825: step 17690, loss = 0.22, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 19h:44m:45s remains)
INFO - root - 2017-12-17 03:54:03.133508: step 17700, loss = 0.20, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 19h:31m:33s remains)
INFO - root - 2017-12-17 03:54:05.536029: step 17710, loss = 0.20, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 19h:27m:03s remains)
INFO - root - 2017-12-17 03:54:07.802322: step 17720, loss = 0.21, batch loss = 0.13 (35.3 examples/sec; 0.226 sec/batch; 19h:47m:25s remains)
INFO - root - 2017-12-17 03:54:10.091762: step 17730, loss = 0.24, batch loss = 0.17 (36.2 examples/sec; 0.221 sec/batch; 19h:19m:47s remains)
INFO - root - 2017-12-17 03:54:12.349549: step 17740, loss = 0.21, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 19h:28m:38s remains)
INFO - root - 2017-12-17 03:54:14.592738: step 17750, loss = 0.21, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 19h:30m:43s remains)
INFO - root - 2017-12-17 03:54:16.877158: step 17760, loss = 0.19, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 20h:05m:52s remains)
INFO - root - 2017-12-17 03:54:19.118605: step 17770, loss = 0.20, batch loss = 0.12 (34.7 examples/sec; 0.231 sec/batch; 20h:10m:08s remains)
INFO - root - 2017-12-17 03:54:21.408256: step 17780, loss = 0.21, batch loss = 0.14 (33.8 examples/sec; 0.237 sec/batch; 20h:40m:32s remains)
INFO - root - 2017-12-17 03:54:23.689720: step 17790, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 19h:36m:01s remains)
INFO - root - 2017-12-17 03:54:25.941290: step 17800, loss = 0.25, batch loss = 0.18 (36.1 examples/sec; 0.222 sec/batch; 19h:23m:29s remains)
INFO - root - 2017-12-17 03:54:28.301938: step 17810, loss = 0.24, batch loss = 0.16 (34.6 examples/sec; 0.231 sec/batch; 20h:14m:09s remains)
INFO - root - 2017-12-17 03:54:30.616063: step 17820, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 19h:26m:31s remains)
INFO - root - 2017-12-17 03:54:32.866651: step 17830, loss = 0.20, batch loss = 0.13 (35.8 examples/sec; 0.224 sec/batch; 19h:32m:33s remains)
INFO - root - 2017-12-17 03:54:35.116511: step 17840, loss = 0.20, batch loss = 0.12 (36.6 examples/sec; 0.219 sec/batch; 19h:06m:43s remains)
INFO - root - 2017-12-17 03:54:37.370994: step 17850, loss = 0.21, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 19h:39m:59s remains)
INFO - root - 2017-12-17 03:54:39.674307: step 17860, loss = 0.17, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 19h:45m:10s remains)
INFO - root - 2017-12-17 03:54:41.912105: step 17870, loss = 0.20, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 19h:35m:02s remains)
INFO - root - 2017-12-17 03:54:44.154540: step 17880, loss = 0.20, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 19h:13m:36s remains)
INFO - root - 2017-12-17 03:54:46.428536: step 17890, loss = 0.22, batch loss = 0.14 (35.5 examples/sec; 0.225 sec/batch; 19h:42m:04s remains)
INFO - root - 2017-12-17 03:54:48.671181: step 17900, loss = 0.21, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 19h:55m:28s remains)
INFO - root - 2017-12-17 03:54:51.081493: step 17910, loss = 0.24, batch loss = 0.16 (35.7 examples/sec; 0.224 sec/batch; 19h:33m:41s remains)
INFO - root - 2017-12-17 03:54:53.380208: step 17920, loss = 0.19, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 19h:40m:49s remains)
INFO - root - 2017-12-17 03:54:55.676410: step 17930, loss = 0.20, batch loss = 0.12 (34.5 examples/sec; 0.232 sec/batch; 20h:15m:17s remains)
INFO - root - 2017-12-17 03:54:57.975150: step 17940, loss = 0.20, batch loss = 0.13 (34.0 examples/sec; 0.235 sec/batch; 20h:32m:51s remains)
INFO - root - 2017-12-17 03:55:00.237554: step 17950, loss = 0.23, batch loss = 0.16 (36.3 examples/sec; 0.221 sec/batch; 19h:16m:00s remains)
INFO - root - 2017-12-17 03:55:02.525945: step 17960, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:43m:19s remains)
INFO - root - 2017-12-17 03:55:04.778749: step 17970, loss = 0.21, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 19h:33m:19s remains)
INFO - root - 2017-12-17 03:55:07.029379: step 17980, loss = 0.22, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 19h:27m:37s remains)
INFO - root - 2017-12-17 03:55:09.306138: step 17990, loss = 0.24, batch loss = 0.17 (34.8 examples/sec; 0.230 sec/batch; 20h:05m:36s remains)
INFO - root - 2017-12-17 03:55:11.548996: step 18000, loss = 0.22, batch loss = 0.15 (35.6 examples/sec; 0.225 sec/batch; 19h:38m:19s remains)
INFO - root - 2017-12-17 03:55:13.973774: step 18010, loss = 0.18, batch loss = 0.11 (32.2 examples/sec; 0.249 sec/batch; 21h:43m:59s remains)
INFO - root - 2017-12-17 03:55:16.244695: step 18020, loss = 0.20, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 19h:49m:04s remains)
INFO - root - 2017-12-17 03:55:18.505160: step 18030, loss = 0.21, batch loss = 0.14 (35.0 examples/sec; 0.229 sec/batch; 19h:58m:36s remains)
INFO - root - 2017-12-17 03:55:20.767092: step 18040, loss = 0.19, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 19h:48m:51s remains)
INFO - root - 2017-12-17 03:55:23.009763: step 18050, loss = 0.22, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 19h:28m:13s remains)
INFO - root - 2017-12-17 03:55:25.256116: step 18060, loss = 0.19, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 19h:10m:34s remains)
INFO - root - 2017-12-17 03:55:27.512687: step 18070, loss = 0.23, batch loss = 0.15 (36.1 examples/sec; 0.222 sec/batch; 19h:21m:39s remains)
INFO - root - 2017-12-17 03:55:29.733772: step 18080, loss = 0.21, batch loss = 0.13 (35.8 examples/sec; 0.224 sec/batch; 19h:32m:25s remains)
INFO - root - 2017-12-17 03:55:31.985801: step 18090, loss = 0.17, batch loss = 0.10 (34.5 examples/sec; 0.232 sec/batch; 20h:15m:30s remains)
INFO - root - 2017-12-17 03:55:34.328232: step 18100, loss = 0.20, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 19h:18m:35s remains)
INFO - root - 2017-12-17 03:55:36.735985: step 18110, loss = 0.20, batch loss = 0.12 (35.6 examples/sec; 0.224 sec/batch; 19h:36m:02s remains)
INFO - root - 2017-12-17 03:55:39.011402: step 18120, loss = 0.20, batch loss = 0.12 (37.2 examples/sec; 0.215 sec/batch; 18h:45m:35s remains)
INFO - root - 2017-12-17 03:55:41.257002: step 18130, loss = 0.24, batch loss = 0.17 (35.7 examples/sec; 0.224 sec/batch; 19h:34m:30s remains)
INFO - root - 2017-12-17 03:55:43.528859: step 18140, loss = 0.19, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 20h:10m:30s remains)
INFO - root - 2017-12-17 03:55:45.804233: step 18150, loss = 0.26, batch loss = 0.19 (35.5 examples/sec; 0.225 sec/batch; 19h:40m:04s remains)
INFO - root - 2017-12-17 03:55:48.065936: step 18160, loss = 0.26, batch loss = 0.19 (35.5 examples/sec; 0.225 sec/batch; 19h:38m:58s remains)
INFO - root - 2017-12-17 03:55:50.328123: step 18170, loss = 0.20, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 19h:20m:48s remains)
INFO - root - 2017-12-17 03:55:52.600997: step 18180, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 19h:59m:51s remains)
INFO - root - 2017-12-17 03:55:54.836037: step 18190, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 19h:16m:54s remains)
INFO - root - 2017-12-17 03:55:57.100723: step 18200, loss = 0.21, batch loss = 0.14 (34.1 examples/sec; 0.235 sec/batch; 20h:29m:59s remains)
INFO - root - 2017-12-17 03:55:59.501704: step 18210, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.228 sec/batch; 19h:51m:49s remains)
INFO - root - 2017-12-17 03:56:01.785018: step 18220, loss = 0.27, batch loss = 0.20 (36.2 examples/sec; 0.221 sec/batch; 19h:17m:29s remains)
INFO - root - 2017-12-17 03:56:04.055116: step 18230, loss = 0.20, batch loss = 0.12 (33.0 examples/sec; 0.242 sec/batch; 21h:08m:56s remains)
INFO - root - 2017-12-17 03:56:06.401014: step 18240, loss = 0.20, batch loss = 0.12 (34.1 examples/sec; 0.235 sec/batch; 20h:28m:56s remains)
INFO - root - 2017-12-17 03:56:08.660648: step 18250, loss = 0.21, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 19h:06m:55s remains)
INFO - root - 2017-12-17 03:56:10.924599: step 18260, loss = 0.21, batch loss = 0.13 (34.3 examples/sec; 0.234 sec/batch; 20h:23m:10s remains)
INFO - root - 2017-12-17 03:56:13.185589: step 18270, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 19h:58m:55s remains)
INFO - root - 2017-12-17 03:56:15.454330: step 18280, loss = 0.24, batch loss = 0.17 (36.1 examples/sec; 0.222 sec/batch; 19h:21m:33s remains)
INFO - root - 2017-12-17 03:56:17.688959: step 18290, loss = 0.21, batch loss = 0.14 (36.4 examples/sec; 0.220 sec/batch; 19h:11m:06s remains)
INFO - root - 2017-12-17 03:56:19.956674: step 18300, loss = 0.21, batch loss = 0.13 (36.6 examples/sec; 0.218 sec/batch; 19h:03m:53s remains)
INFO - root - 2017-12-17 03:56:22.379192: step 18310, loss = 0.20, batch loss = 0.13 (34.1 examples/sec; 0.235 sec/batch; 20h:29m:03s remains)
INFO - root - 2017-12-17 03:56:24.661272: step 18320, loss = 0.18, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 19h:34m:05s remains)
INFO - root - 2017-12-17 03:56:26.901486: step 18330, loss = 0.20, batch loss = 0.13 (34.7 examples/sec; 0.231 sec/batch; 20h:08m:16s remains)
INFO - root - 2017-12-17 03:56:29.167043: step 18340, loss = 0.26, batch loss = 0.18 (35.4 examples/sec; 0.226 sec/batch; 19h:44m:53s remains)
INFO - root - 2017-12-17 03:56:31.428457: step 18350, loss = 0.25, batch loss = 0.18 (34.1 examples/sec; 0.234 sec/batch; 20h:27m:22s remains)
INFO - root - 2017-12-17 03:56:33.694280: step 18360, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.224 sec/batch; 19h:30m:19s remains)
INFO - root - 2017-12-17 03:56:35.975049: step 18370, loss = 0.21, batch loss = 0.14 (35.2 examples/sec; 0.227 sec/batch; 19h:49m:32s remains)
INFO - root - 2017-12-17 03:56:38.224258: step 18380, loss = 0.19, batch loss = 0.12 (33.4 examples/sec; 0.239 sec/batch; 20h:53m:29s remains)
INFO - root - 2017-12-17 03:56:40.521134: step 18390, loss = 0.24, batch loss = 0.17 (36.0 examples/sec; 0.222 sec/batch; 19h:22m:46s remains)
INFO - root - 2017-12-17 03:56:42.804986: step 18400, loss = 0.19, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 19h:40m:26s remains)
INFO - root - 2017-12-17 03:56:45.195776: step 18410, loss = 0.20, batch loss = 0.12 (34.3 examples/sec; 0.233 sec/batch; 20h:21m:26s remains)
INFO - root - 2017-12-17 03:56:47.457167: step 18420, loss = 0.20, batch loss = 0.13 (33.3 examples/sec; 0.240 sec/batch; 20h:56m:53s remains)
INFO - root - 2017-12-17 03:56:49.721439: step 18430, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 19h:59m:57s remains)
INFO - root - 2017-12-17 03:56:52.007490: step 18440, loss = 0.20, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 19h:37m:12s remains)
INFO - root - 2017-12-17 03:56:54.236760: step 18450, loss = 0.18, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 19h:21m:26s remains)
INFO - root - 2017-12-17 03:56:56.515393: step 18460, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:41m:15s remains)
INFO - root - 2017-12-17 03:56:58.797417: step 18470, loss = 0.22, batch loss = 0.15 (34.7 examples/sec; 0.231 sec/batch; 20h:07m:10s remains)
INFO - root - 2017-12-17 03:57:01.073809: step 18480, loss = 0.19, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 20h:07m:32s remains)
INFO - root - 2017-12-17 03:57:03.341977: step 18490, loss = 0.17, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 19h:35m:05s remains)
INFO - root - 2017-12-17 03:57:05.603122: step 18500, loss = 0.19, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 20h:08m:51s remains)
INFO - root - 2017-12-17 03:57:08.051556: step 18510, loss = 0.18, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:27m:22s remains)
INFO - root - 2017-12-17 03:57:10.291699: step 18520, loss = 0.18, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 19h:46m:30s remains)
INFO - root - 2017-12-17 03:57:12.560690: step 18530, loss = 0.19, batch loss = 0.11 (36.0 examples/sec; 0.223 sec/batch; 19h:24m:26s remains)
INFO - root - 2017-12-17 03:57:14.831859: step 18540, loss = 0.19, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 19h:31m:42s remains)
INFO - root - 2017-12-17 03:57:17.131610: step 18550, loss = 0.22, batch loss = 0.15 (35.0 examples/sec; 0.229 sec/batch; 19h:57m:42s remains)
INFO - root - 2017-12-17 03:57:19.406569: step 18560, loss = 0.18, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 19h:20m:51s remains)
INFO - root - 2017-12-17 03:57:21.653938: step 18570, loss = 0.22, batch loss = 0.14 (34.4 examples/sec; 0.232 sec/batch; 20h:16m:17s remains)
INFO - root - 2017-12-17 03:57:23.910675: step 18580, loss = 0.24, batch loss = 0.16 (35.8 examples/sec; 0.224 sec/batch; 19h:30m:26s remains)
INFO - root - 2017-12-17 03:57:26.172366: step 18590, loss = 0.16, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 19h:36m:11s remains)
INFO - root - 2017-12-17 03:57:28.446742: step 18600, loss = 0.20, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 19h:32m:43s remains)
INFO - root - 2017-12-17 03:57:30.810959: step 18610, loss = 0.20, batch loss = 0.12 (36.8 examples/sec; 0.217 sec/batch; 18h:57m:38s remains)
INFO - root - 2017-12-17 03:57:33.068890: step 18620, loss = 0.19, batch loss = 0.12 (34.7 examples/sec; 0.230 sec/batch; 20h:04m:54s remains)
INFO - root - 2017-12-17 03:57:35.311315: step 18630, loss = 0.17, batch loss = 0.10 (35.2 examples/sec; 0.228 sec/batch; 19h:50m:31s remains)
INFO - root - 2017-12-17 03:57:37.574677: step 18640, loss = 0.20, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 19h:28m:22s remains)
INFO - root - 2017-12-17 03:57:39.846216: step 18650, loss = 0.16, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 19h:34m:30s remains)
INFO - root - 2017-12-17 03:57:42.128650: step 18660, loss = 0.22, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 19h:52m:07s remains)
INFO - root - 2017-12-17 03:57:44.406453: step 18670, loss = 0.24, batch loss = 0.17 (35.3 examples/sec; 0.227 sec/batch; 19h:46m:03s remains)
INFO - root - 2017-12-17 03:57:46.652386: step 18680, loss = 0.21, batch loss = 0.14 (36.6 examples/sec; 0.219 sec/batch; 19h:03m:00s remains)
INFO - root - 2017-12-17 03:57:48.912590: step 18690, loss = 0.29, batch loss = 0.22 (36.4 examples/sec; 0.220 sec/batch; 19h:08m:26s remains)
INFO - root - 2017-12-17 03:57:51.208055: step 18700, loss = 0.20, batch loss = 0.12 (33.9 examples/sec; 0.236 sec/batch; 20h:35m:13s remains)
INFO - root - 2017-12-17 03:57:53.627452: step 18710, loss = 0.24, batch loss = 0.17 (34.8 examples/sec; 0.230 sec/batch; 20h:02m:14s remains)
INFO - root - 2017-12-17 03:57:55.889877: step 18720, loss = 0.18, batch loss = 0.10 (35.0 examples/sec; 0.229 sec/batch; 19h:55m:06s remains)
INFO - root - 2017-12-17 03:57:58.143951: step 18730, loss = 0.21, batch loss = 0.14 (34.5 examples/sec; 0.232 sec/batch; 20h:11m:12s remains)
INFO - root - 2017-12-17 03:58:00.475795: step 18740, loss = 0.21, batch loss = 0.13 (33.5 examples/sec; 0.239 sec/batch; 20h:47m:19s remains)
INFO - root - 2017-12-17 03:58:02.725744: step 18750, loss = 0.20, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 19h:38m:06s remains)
INFO - root - 2017-12-17 03:58:04.991381: step 18760, loss = 0.20, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 19h:16m:23s remains)
INFO - root - 2017-12-17 03:58:07.314283: step 18770, loss = 0.19, batch loss = 0.12 (33.3 examples/sec; 0.241 sec/batch; 20h:57m:38s remains)
INFO - root - 2017-12-17 03:58:09.593405: step 18780, loss = 0.20, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 19h:19m:48s remains)
INFO - root - 2017-12-17 03:58:11.850475: step 18790, loss = 0.22, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 19h:21m:43s remains)
INFO - root - 2017-12-17 03:58:14.123337: step 18800, loss = 0.17, batch loss = 0.10 (33.4 examples/sec; 0.239 sec/batch; 20h:51m:46s remains)
INFO - root - 2017-12-17 03:58:16.508151: step 18810, loss = 0.19, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 19h:20m:55s remains)
INFO - root - 2017-12-17 03:58:18.773162: step 18820, loss = 0.19, batch loss = 0.11 (34.3 examples/sec; 0.233 sec/batch; 20h:19m:33s remains)
INFO - root - 2017-12-17 03:58:21.053823: step 18830, loss = 0.23, batch loss = 0.15 (35.3 examples/sec; 0.227 sec/batch; 19h:44m:27s remains)
INFO - root - 2017-12-17 03:58:23.299521: step 18840, loss = 0.24, batch loss = 0.17 (35.5 examples/sec; 0.225 sec/batch; 19h:36m:46s remains)
INFO - root - 2017-12-17 03:58:25.560802: step 18850, loss = 0.17, batch loss = 0.10 (35.0 examples/sec; 0.228 sec/batch; 19h:53m:55s remains)
INFO - root - 2017-12-17 03:58:27.817762: step 18860, loss = 0.18, batch loss = 0.11 (33.5 examples/sec; 0.239 sec/batch; 20h:47m:17s remains)
INFO - root - 2017-12-17 03:58:30.076630: step 18870, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:42m:32s remains)
INFO - root - 2017-12-17 03:58:32.345333: step 18880, loss = 0.17, batch loss = 0.09 (34.8 examples/sec; 0.230 sec/batch; 20h:02m:58s remains)
INFO - root - 2017-12-17 03:58:34.634792: step 18890, loss = 0.19, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 19h:47m:45s remains)
INFO - root - 2017-12-17 03:58:36.918278: step 18900, loss = 0.23, batch loss = 0.15 (36.3 examples/sec; 0.220 sec/batch; 19h:11m:52s remains)
INFO - root - 2017-12-17 03:58:39.372393: step 18910, loss = 0.26, batch loss = 0.19 (35.6 examples/sec; 0.224 sec/batch; 19h:33m:04s remains)
INFO - root - 2017-12-17 03:58:41.613281: step 18920, loss = 0.17, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 19h:24m:26s remains)
INFO - root - 2017-12-17 03:58:43.878362: step 18930, loss = 0.31, batch loss = 0.24 (36.8 examples/sec; 0.218 sec/batch; 18h:57m:28s remains)
INFO - root - 2017-12-17 03:58:46.158558: step 18940, loss = 0.20, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:50m:09s remains)
INFO - root - 2017-12-17 03:58:48.419511: step 18950, loss = 0.19, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 18h:58m:31s remains)
INFO - root - 2017-12-17 03:58:50.663986: step 18960, loss = 0.19, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 19h:36m:08s remains)
INFO - root - 2017-12-17 03:58:52.926800: step 18970, loss = 0.21, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 19h:34m:29s remains)
INFO - root - 2017-12-17 03:58:55.180322: step 18980, loss = 0.25, batch loss = 0.18 (34.9 examples/sec; 0.229 sec/batch; 19h:57m:44s remains)
INFO - root - 2017-12-17 03:58:57.420006: step 18990, loss = 0.23, batch loss = 0.16 (35.5 examples/sec; 0.226 sec/batch; 19h:38m:19s remains)
INFO - root - 2017-12-17 03:58:59.673305: step 19000, loss = 0.23, batch loss = 0.16 (34.5 examples/sec; 0.232 sec/batch; 20h:11m:29s remains)
INFO - root - 2017-12-17 03:59:02.071276: step 19010, loss = 0.21, batch loss = 0.14 (35.3 examples/sec; 0.226 sec/batch; 19h:43m:23s remains)
INFO - root - 2017-12-17 03:59:04.313686: step 19020, loss = 0.23, batch loss = 0.15 (35.6 examples/sec; 0.225 sec/batch; 19h:34m:26s remains)
INFO - root - 2017-12-17 03:59:06.557578: step 19030, loss = 0.20, batch loss = 0.12 (36.1 examples/sec; 0.222 sec/batch; 19h:17m:16s remains)
INFO - root - 2017-12-17 03:59:08.829207: step 19040, loss = 0.17, batch loss = 0.10 (34.0 examples/sec; 0.235 sec/batch; 20h:28m:23s remains)
INFO - root - 2017-12-17 03:59:11.095215: step 19050, loss = 0.23, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 19h:16m:05s remains)
INFO - root - 2017-12-17 03:59:13.341850: step 19060, loss = 0.22, batch loss = 0.15 (35.0 examples/sec; 0.228 sec/batch; 19h:53m:21s remains)
INFO - root - 2017-12-17 03:59:15.609026: step 19070, loss = 0.17, batch loss = 0.10 (34.2 examples/sec; 0.234 sec/batch; 20h:23m:30s remains)
INFO - root - 2017-12-17 03:59:17.862145: step 19080, loss = 0.20, batch loss = 0.12 (33.4 examples/sec; 0.240 sec/batch; 20h:51m:39s remains)
INFO - root - 2017-12-17 03:59:20.142193: step 19090, loss = 0.18, batch loss = 0.11 (33.9 examples/sec; 0.236 sec/batch; 20h:31m:44s remains)
INFO - root - 2017-12-17 03:59:22.416620: step 19100, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 19h:47m:58s remains)
INFO - root - 2017-12-17 03:59:24.848037: step 19110, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:40m:49s remains)
INFO - root - 2017-12-17 03:59:27.121567: step 19120, loss = 0.26, batch loss = 0.18 (35.0 examples/sec; 0.229 sec/batch; 19h:54m:05s remains)
INFO - root - 2017-12-17 03:59:29.361775: step 19130, loss = 0.22, batch loss = 0.14 (35.3 examples/sec; 0.227 sec/batch; 19h:43m:01s remains)
INFO - root - 2017-12-17 03:59:31.688835: step 19140, loss = 0.19, batch loss = 0.11 (34.0 examples/sec; 0.236 sec/batch; 20h:30m:02s remains)
INFO - root - 2017-12-17 03:59:34.001025: step 19150, loss = 0.19, batch loss = 0.12 (34.3 examples/sec; 0.234 sec/batch; 20h:19m:33s remains)
INFO - root - 2017-12-17 03:59:36.265425: step 19160, loss = 0.18, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 19h:27m:20s remains)
INFO - root - 2017-12-17 03:59:38.535942: step 19170, loss = 0.23, batch loss = 0.16 (33.1 examples/sec; 0.242 sec/batch; 21h:02m:03s remains)
INFO - root - 2017-12-17 03:59:40.841069: step 19180, loss = 0.20, batch loss = 0.13 (34.7 examples/sec; 0.230 sec/batch; 20h:02m:52s remains)
INFO - root - 2017-12-17 03:59:43.078726: step 19190, loss = 0.17, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:20m:09s remains)
INFO - root - 2017-12-17 03:59:45.346891: step 19200, loss = 0.23, batch loss = 0.16 (35.2 examples/sec; 0.227 sec/batch; 19h:47m:31s remains)
INFO - root - 2017-12-17 03:59:47.793273: step 19210, loss = 0.18, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 19h:27m:16s remains)
INFO - root - 2017-12-17 03:59:50.047055: step 19220, loss = 0.20, batch loss = 0.13 (35.3 examples/sec; 0.226 sec/batch; 19h:41m:58s remains)
INFO - root - 2017-12-17 03:59:52.320687: step 19230, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 19h:41m:12s remains)
INFO - root - 2017-12-17 03:59:54.583664: step 19240, loss = 0.19, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 20h:10m:51s remains)
INFO - root - 2017-12-17 03:59:56.874598: step 19250, loss = 0.21, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 19h:25m:38s remains)
INFO - root - 2017-12-17 03:59:59.156680: step 19260, loss = 0.18, batch loss = 0.11 (34.3 examples/sec; 0.233 sec/batch; 20h:17m:52s remains)
INFO - root - 2017-12-17 04:00:01.402345: step 19270, loss = 0.20, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 19h:09m:30s remains)
INFO - root - 2017-12-17 04:00:03.670929: step 19280, loss = 0.19, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 19h:14m:27s remains)
INFO - root - 2017-12-17 04:00:05.944494: step 19290, loss = 0.20, batch loss = 0.13 (33.5 examples/sec; 0.239 sec/batch; 20h:46m:42s remains)
INFO - root - 2017-12-17 04:00:08.220472: step 19300, loss = 0.31, batch loss = 0.23 (36.2 examples/sec; 0.221 sec/batch; 19h:14m:02s remains)
INFO - root - 2017-12-17 04:00:10.597258: step 19310, loss = 0.22, batch loss = 0.14 (35.0 examples/sec; 0.229 sec/batch; 19h:53m:06s remains)
INFO - root - 2017-12-17 04:00:12.870147: step 19320, loss = 0.18, batch loss = 0.11 (33.7 examples/sec; 0.237 sec/batch; 20h:38m:16s remains)
INFO - root - 2017-12-17 04:00:15.119270: step 19330, loss = 0.23, batch loss = 0.15 (36.3 examples/sec; 0.221 sec/batch; 19h:11m:23s remains)
INFO - root - 2017-12-17 04:00:17.400226: step 19340, loss = 0.22, batch loss = 0.15 (35.7 examples/sec; 0.224 sec/batch; 19h:29m:31s remains)
INFO - root - 2017-12-17 04:00:19.630421: step 19350, loss = 0.19, batch loss = 0.11 (36.7 examples/sec; 0.218 sec/batch; 18h:58m:25s remains)
INFO - root - 2017-12-17 04:00:21.937631: step 19360, loss = 0.21, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 19h:58m:57s remains)
INFO - root - 2017-12-17 04:00:24.259779: step 19370, loss = 0.22, batch loss = 0.14 (35.5 examples/sec; 0.225 sec/batch; 19h:34m:35s remains)
INFO - root - 2017-12-17 04:00:26.532318: step 19380, loss = 0.23, batch loss = 0.15 (34.3 examples/sec; 0.233 sec/batch; 20h:16m:51s remains)
INFO - root - 2017-12-17 04:00:28.799654: step 19390, loss = 0.18, batch loss = 0.10 (35.1 examples/sec; 0.228 sec/batch; 19h:50m:10s remains)
INFO - root - 2017-12-17 04:00:31.072357: step 19400, loss = 0.24, batch loss = 0.16 (35.2 examples/sec; 0.227 sec/batch; 19h:46m:59s remains)
INFO - root - 2017-12-17 04:00:33.462326: step 19410, loss = 0.20, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 19h:30m:32s remains)
INFO - root - 2017-12-17 04:00:35.725120: step 19420, loss = 0.24, batch loss = 0.17 (36.7 examples/sec; 0.218 sec/batch; 18h:57m:47s remains)
INFO - root - 2017-12-17 04:00:38.054331: step 19430, loss = 0.20, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 19h:55m:45s remains)
INFO - root - 2017-12-17 04:00:40.331108: step 19440, loss = 0.21, batch loss = 0.14 (33.1 examples/sec; 0.241 sec/batch; 20h:59m:24s remains)
INFO - root - 2017-12-17 04:00:42.585726: step 19450, loss = 0.19, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 18h:56m:16s remains)
INFO - root - 2017-12-17 04:00:44.886811: step 19460, loss = 0.19, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 19h:42m:48s remains)
INFO - root - 2017-12-17 04:00:47.157856: step 19470, loss = 0.21, batch loss = 0.14 (36.1 examples/sec; 0.222 sec/batch; 19h:16m:45s remains)
INFO - root - 2017-12-17 04:00:49.393297: step 19480, loss = 0.23, batch loss = 0.15 (34.9 examples/sec; 0.229 sec/batch; 19h:54m:39s remains)
INFO - root - 2017-12-17 04:00:51.626690: step 19490, loss = 0.19, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 19h:29m:56s remains)
INFO - root - 2017-12-17 04:00:53.928050: step 19500, loss = 0.21, batch loss = 0.13 (33.0 examples/sec; 0.242 sec/batch; 21h:03m:52s remains)
INFO - root - 2017-12-17 04:00:56.324354: step 19510, loss = 0.21, batch loss = 0.14 (36.8 examples/sec; 0.217 sec/batch; 18h:54m:11s remains)
INFO - root - 2017-12-17 04:00:58.607818: step 19520, loss = 0.23, batch loss = 0.16 (35.0 examples/sec; 0.228 sec/batch; 19h:51m:33s remains)
INFO - root - 2017-12-17 04:01:00.871026: step 19530, loss = 0.17, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 19h:16m:15s remains)
INFO - root - 2017-12-17 04:01:03.158948: step 19540, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 19h:11m:48s remains)
INFO - root - 2017-12-17 04:01:05.458446: step 19550, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.229 sec/batch; 19h:51m:58s remains)
INFO - root - 2017-12-17 04:01:07.735176: step 19560, loss = 0.22, batch loss = 0.15 (34.3 examples/sec; 0.233 sec/batch; 20h:15m:02s remains)
INFO - root - 2017-12-17 04:01:10.003774: step 19570, loss = 0.19, batch loss = 0.11 (33.9 examples/sec; 0.236 sec/batch; 20h:32m:12s remains)
INFO - root - 2017-12-17 04:01:12.296940: step 19580, loss = 0.21, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 19h:37m:33s remains)
INFO - root - 2017-12-17 04:01:14.524661: step 19590, loss = 0.24, batch loss = 0.17 (35.9 examples/sec; 0.223 sec/batch; 19h:20m:50s remains)
INFO - root - 2017-12-17 04:01:16.771679: step 19600, loss = 0.20, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 19h:54m:30s remains)
INFO - root - 2017-12-17 04:01:19.154001: step 19610, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 19h:35m:53s remains)
INFO - root - 2017-12-17 04:01:21.419012: step 19620, loss = 0.22, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 19h:18m:31s remains)
INFO - root - 2017-12-17 04:01:23.682161: step 19630, loss = 0.29, batch loss = 0.22 (35.0 examples/sec; 0.228 sec/batch; 19h:50m:49s remains)
INFO - root - 2017-12-17 04:01:25.942150: step 19640, loss = 0.23, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 19h:22m:40s remains)
INFO - root - 2017-12-17 04:01:28.219792: step 19650, loss = 0.18, batch loss = 0.10 (32.9 examples/sec; 0.243 sec/batch; 21h:07m:47s remains)
INFO - root - 2017-12-17 04:01:30.473409: step 19660, loss = 0.20, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 19h:59m:16s remains)
INFO - root - 2017-12-17 04:01:32.700913: step 19670, loss = 0.22, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 19h:08m:51s remains)
INFO - root - 2017-12-17 04:01:34.954403: step 19680, loss = 0.18, batch loss = 0.11 (33.8 examples/sec; 0.237 sec/batch; 20h:33m:11s remains)
INFO - root - 2017-12-17 04:01:37.264020: step 19690, loss = 0.16, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 19h:13m:31s remains)
INFO - root - 2017-12-17 04:01:39.578559: step 19700, loss = 0.27, batch loss = 0.19 (35.0 examples/sec; 0.229 sec/batch; 19h:52m:36s remains)
INFO - root - 2017-12-17 04:01:42.011900: step 19710, loss = 0.20, batch loss = 0.12 (34.7 examples/sec; 0.231 sec/batch; 20h:03m:17s remains)
INFO - root - 2017-12-17 04:01:44.272979: step 19720, loss = 0.20, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 19h:42m:32s remains)
INFO - root - 2017-12-17 04:01:46.516529: step 19730, loss = 0.17, batch loss = 0.10 (34.3 examples/sec; 0.234 sec/batch; 20h:17m:23s remains)
INFO - root - 2017-12-17 04:01:48.778577: step 19740, loss = 0.24, batch loss = 0.17 (35.5 examples/sec; 0.226 sec/batch; 19h:35m:39s remains)
INFO - root - 2017-12-17 04:01:51.036985: step 19750, loss = 0.20, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 19h:21m:52s remains)
INFO - root - 2017-12-17 04:01:53.293406: step 19760, loss = 0.22, batch loss = 0.14 (34.2 examples/sec; 0.234 sec/batch; 20h:20m:47s remains)
INFO - root - 2017-12-17 04:01:55.540191: step 19770, loss = 0.21, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 19h:59m:36s remains)
INFO - root - 2017-12-17 04:01:57.847088: step 19780, loss = 0.24, batch loss = 0.17 (34.2 examples/sec; 0.234 sec/batch; 20h:19m:28s remains)
INFO - root - 2017-12-17 04:02:00.079102: step 19790, loss = 0.19, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 19h:04m:12s remains)
INFO - root - 2017-12-17 04:02:02.355895: step 19800, loss = 0.17, batch loss = 0.09 (34.6 examples/sec; 0.231 sec/batch; 20h:05m:11s remains)
INFO - root - 2017-12-17 04:02:04.784122: step 19810, loss = 0.19, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 20h:07m:25s remains)
INFO - root - 2017-12-17 04:02:07.040151: step 19820, loss = 0.19, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 19h:41m:51s remains)
INFO - root - 2017-12-17 04:02:09.276186: step 19830, loss = 0.19, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 19h:02m:22s remains)
INFO - root - 2017-12-17 04:02:11.539503: step 19840, loss = 0.18, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:22m:03s remains)
INFO - root - 2017-12-17 04:02:13.855566: step 19850, loss = 0.21, batch loss = 0.14 (32.5 examples/sec; 0.246 sec/batch; 21h:21m:33s remains)
INFO - root - 2017-12-17 04:02:16.112735: step 19860, loss = 0.19, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 19h:47m:45s remains)
INFO - root - 2017-12-17 04:02:18.421380: step 19870, loss = 0.24, batch loss = 0.17 (35.0 examples/sec; 0.228 sec/batch; 19h:49m:44s remains)
INFO - root - 2017-12-17 04:02:20.674023: step 19880, loss = 0.21, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 20h:03m:47s remains)
INFO - root - 2017-12-17 04:02:23.006218: step 19890, loss = 0.20, batch loss = 0.13 (34.0 examples/sec; 0.235 sec/batch; 20h:24m:08s remains)
INFO - root - 2017-12-17 04:02:25.264774: step 19900, loss = 0.26, batch loss = 0.18 (36.7 examples/sec; 0.218 sec/batch; 18h:56m:53s remains)
INFO - root - 2017-12-17 04:02:27.687385: step 19910, loss = 0.19, batch loss = 0.12 (32.9 examples/sec; 0.243 sec/batch; 21h:06m:15s remains)
INFO - root - 2017-12-17 04:02:29.971181: step 19920, loss = 0.20, batch loss = 0.13 (33.1 examples/sec; 0.241 sec/batch; 20h:57m:21s remains)
INFO - root - 2017-12-17 04:02:32.219098: step 19930, loss = 0.22, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 19h:36m:37s remains)
INFO - root - 2017-12-17 04:02:34.477789: step 19940, loss = 0.18, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 19h:10m:25s remains)
INFO - root - 2017-12-17 04:02:36.801559: step 19950, loss = 0.19, batch loss = 0.11 (32.4 examples/sec; 0.247 sec/batch; 21h:25m:38s remains)
INFO - root - 2017-12-17 04:02:39.104935: step 19960, loss = 0.17, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:20m:27s remains)
INFO - root - 2017-12-17 04:02:41.363903: step 19970, loss = 0.25, batch loss = 0.17 (33.9 examples/sec; 0.236 sec/batch; 20h:29m:31s remains)
INFO - root - 2017-12-17 04:02:43.645311: step 19980, loss = 0.18, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 19h:18m:32s remains)
INFO - root - 2017-12-17 04:02:45.886476: step 19990, loss = 0.21, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 20h:03m:40s remains)
INFO - root - 2017-12-17 04:02:48.143056: step 20000, loss = 0.21, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 19h:48m:27s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-20000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-20000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 04:02:50.960807: step 20010, loss = 0.19, batch loss = 0.12 (34.5 examples/sec; 0.232 sec/batch; 20h:09m:08s remains)
INFO - root - 2017-12-17 04:02:53.248260: step 20020, loss = 0.18, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 19h:36m:24s remains)
INFO - root - 2017-12-17 04:02:55.496017: step 20030, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.229 sec/batch; 19h:50m:23s remains)
INFO - root - 2017-12-17 04:02:57.765913: step 20040, loss = 0.21, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 19h:01m:10s remains)
INFO - root - 2017-12-17 04:03:00.016183: step 20050, loss = 0.19, batch loss = 0.11 (36.3 examples/sec; 0.220 sec/batch; 19h:06m:48s remains)
INFO - root - 2017-12-17 04:03:02.278968: step 20060, loss = 0.18, batch loss = 0.10 (36.1 examples/sec; 0.221 sec/batch; 19h:12m:33s remains)
INFO - root - 2017-12-17 04:03:04.559864: step 20070, loss = 0.19, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 19h:55m:00s remains)
INFO - root - 2017-12-17 04:03:06.873466: step 20080, loss = 0.24, batch loss = 0.16 (35.4 examples/sec; 0.226 sec/batch; 19h:35m:23s remains)
INFO - root - 2017-12-17 04:03:09.142247: step 20090, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.229 sec/batch; 19h:51m:13s remains)
INFO - root - 2017-12-17 04:03:11.391300: step 20100, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.226 sec/batch; 19h:34m:53s remains)
INFO - root - 2017-12-17 04:03:13.764113: step 20110, loss = 0.20, batch loss = 0.13 (36.9 examples/sec; 0.217 sec/batch; 18h:48m:53s remains)
INFO - root - 2017-12-17 04:03:16.030208: step 20120, loss = 0.21, batch loss = 0.14 (35.0 examples/sec; 0.229 sec/batch; 19h:50m:34s remains)
INFO - root - 2017-12-17 04:03:18.319434: step 20130, loss = 0.23, batch loss = 0.16 (35.3 examples/sec; 0.226 sec/batch; 19h:39m:05s remains)
INFO - root - 2017-12-17 04:03:20.556770: step 20140, loss = 0.20, batch loss = 0.12 (36.1 examples/sec; 0.221 sec/batch; 19h:12m:58s remains)
INFO - root - 2017-12-17 04:03:22.848992: step 20150, loss = 0.20, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 19h:57m:53s remains)
INFO - root - 2017-12-17 04:03:25.155862: step 20160, loss = 0.22, batch loss = 0.14 (36.8 examples/sec; 0.217 sec/batch; 18h:51m:46s remains)
INFO - root - 2017-12-17 04:03:27.401031: step 20170, loss = 0.24, batch loss = 0.16 (34.7 examples/sec; 0.230 sec/batch; 19h:59m:29s remains)
INFO - root - 2017-12-17 04:03:29.654246: step 20180, loss = 0.27, batch loss = 0.20 (35.6 examples/sec; 0.225 sec/batch; 19h:30m:20s remains)
INFO - root - 2017-12-17 04:03:31.950176: step 20190, loss = 0.20, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 19h:21m:32s remains)
INFO - root - 2017-12-17 04:03:34.274663: step 20200, loss = 0.17, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 19h:03m:26s remains)
INFO - root - 2017-12-17 04:03:36.661515: step 20210, loss = 0.24, batch loss = 0.17 (35.9 examples/sec; 0.223 sec/batch; 19h:18m:22s remains)
INFO - root - 2017-12-17 04:03:38.928789: step 20220, loss = 0.18, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 19h:29m:00s remains)
INFO - root - 2017-12-17 04:03:41.212351: step 20230, loss = 0.26, batch loss = 0.18 (36.4 examples/sec; 0.220 sec/batch; 19h:03m:40s remains)
INFO - root - 2017-12-17 04:03:43.472217: step 20240, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 19h:54m:05s remains)
INFO - root - 2017-12-17 04:03:45.716843: step 20250, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.223 sec/batch; 19h:22m:33s remains)
INFO - root - 2017-12-17 04:03:47.949692: step 20260, loss = 0.19, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 19h:04m:55s remains)
INFO - root - 2017-12-17 04:03:50.234950: step 20270, loss = 0.27, batch loss = 0.20 (33.4 examples/sec; 0.240 sec/batch; 20h:48m:08s remains)
INFO - root - 2017-12-17 04:03:52.488086: step 20280, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 19h:52m:54s remains)
INFO - root - 2017-12-17 04:03:54.765776: step 20290, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 19h:18m:10s remains)
INFO - root - 2017-12-17 04:03:57.032019: step 20300, loss = 0.17, batch loss = 0.10 (34.6 examples/sec; 0.231 sec/batch; 20h:02m:45s remains)
INFO - root - 2017-12-17 04:03:59.452715: step 20310, loss = 0.20, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 20h:02m:39s remains)
INFO - root - 2017-12-17 04:04:01.680487: step 20320, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 19h:33m:00s remains)
INFO - root - 2017-12-17 04:04:03.922919: step 20330, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 19h:16m:44s remains)
INFO - root - 2017-12-17 04:04:06.190881: step 20340, loss = 0.17, batch loss = 0.10 (35.0 examples/sec; 0.228 sec/batch; 19h:47m:57s remains)
INFO - root - 2017-12-17 04:04:08.435294: step 20350, loss = 0.17, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:19m:53s remains)
INFO - root - 2017-12-17 04:04:10.679913: step 20360, loss = 0.18, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 19h:18m:25s remains)
INFO - root - 2017-12-17 04:04:12.919336: step 20370, loss = 0.24, batch loss = 0.17 (36.0 examples/sec; 0.222 sec/batch; 19h:15m:18s remains)
INFO - root - 2017-12-17 04:04:15.156500: step 20380, loss = 0.21, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 19h:20m:14s remains)
INFO - root - 2017-12-17 04:04:17.421758: step 20390, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:35m:50s remains)
INFO - root - 2017-12-17 04:04:19.670675: step 20400, loss = 0.27, batch loss = 0.19 (36.1 examples/sec; 0.222 sec/batch; 19h:13m:05s remains)
INFO - root - 2017-12-17 04:04:22.080566: step 20410, loss = 0.22, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 19h:24m:55s remains)
INFO - root - 2017-12-17 04:04:24.366265: step 20420, loss = 0.18, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 19h:15m:25s remains)
INFO - root - 2017-12-17 04:04:26.677567: step 20430, loss = 0.24, batch loss = 0.16 (34.7 examples/sec; 0.231 sec/batch; 20h:00m:03s remains)
INFO - root - 2017-12-17 04:04:28.976850: step 20440, loss = 0.20, batch loss = 0.12 (34.7 examples/sec; 0.230 sec/batch; 19h:58m:15s remains)
INFO - root - 2017-12-17 04:04:31.226782: step 20450, loss = 0.22, batch loss = 0.14 (35.5 examples/sec; 0.225 sec/batch; 19h:31m:18s remains)
INFO - root - 2017-12-17 04:04:33.471664: step 20460, loss = 0.19, batch loss = 0.12 (36.3 examples/sec; 0.221 sec/batch; 19h:06m:48s remains)
INFO - root - 2017-12-17 04:04:35.707714: step 20470, loss = 0.21, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 19h:15m:30s remains)
INFO - root - 2017-12-17 04:04:37.958617: step 20480, loss = 0.19, batch loss = 0.12 (36.8 examples/sec; 0.217 sec/batch; 18h:49m:25s remains)
INFO - root - 2017-12-17 04:04:40.217577: step 20490, loss = 0.23, batch loss = 0.16 (35.0 examples/sec; 0.229 sec/batch; 19h:49m:15s remains)
INFO - root - 2017-12-17 04:04:42.472568: step 20500, loss = 0.22, batch loss = 0.15 (35.6 examples/sec; 0.225 sec/batch; 19h:28m:06s remains)
INFO - root - 2017-12-17 04:04:44.861475: step 20510, loss = 0.23, batch loss = 0.16 (35.1 examples/sec; 0.228 sec/batch; 19h:43m:47s remains)
INFO - root - 2017-12-17 04:04:47.131546: step 20520, loss = 0.22, batch loss = 0.15 (35.8 examples/sec; 0.224 sec/batch; 19h:22m:08s remains)
INFO - root - 2017-12-17 04:04:49.388123: step 20530, loss = 0.21, batch loss = 0.14 (35.8 examples/sec; 0.223 sec/batch; 19h:21m:30s remains)
INFO - root - 2017-12-17 04:04:51.633904: step 20540, loss = 0.27, batch loss = 0.20 (35.3 examples/sec; 0.227 sec/batch; 19h:38m:24s remains)
INFO - root - 2017-12-17 04:04:53.932036: step 20550, loss = 0.21, batch loss = 0.14 (34.0 examples/sec; 0.235 sec/batch; 20h:23m:32s remains)
INFO - root - 2017-12-17 04:04:56.162314: step 20560, loss = 0.19, batch loss = 0.12 (37.0 examples/sec; 0.216 sec/batch; 18h:44m:37s remains)
INFO - root - 2017-12-17 04:04:58.437362: step 20570, loss = 0.19, batch loss = 0.12 (31.7 examples/sec; 0.252 sec/batch; 21h:51m:22s remains)
INFO - root - 2017-12-17 04:05:00.711047: step 20580, loss = 0.22, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 19h:45m:47s remains)
INFO - root - 2017-12-17 04:05:02.997165: step 20590, loss = 0.20, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 19h:13m:29s remains)
INFO - root - 2017-12-17 04:05:05.258404: step 20600, loss = 0.18, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 19h:45m:05s remains)
INFO - root - 2017-12-17 04:05:07.658084: step 20610, loss = 0.22, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 19h:33m:59s remains)
INFO - root - 2017-12-17 04:05:09.933775: step 20620, loss = 0.20, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 19h:54m:05s remains)
INFO - root - 2017-12-17 04:05:12.197993: step 20630, loss = 0.26, batch loss = 0.19 (36.3 examples/sec; 0.220 sec/batch; 19h:05m:50s remains)
INFO - root - 2017-12-17 04:05:14.487980: step 20640, loss = 0.20, batch loss = 0.13 (37.2 examples/sec; 0.215 sec/batch; 18h:37m:18s remains)
INFO - root - 2017-12-17 04:05:16.711926: step 20650, loss = 0.20, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 19h:02m:20s remains)
INFO - root - 2017-12-17 04:05:19.013883: step 20660, loss = 0.22, batch loss = 0.14 (35.3 examples/sec; 0.227 sec/batch; 19h:38m:00s remains)
INFO - root - 2017-12-17 04:05:21.329414: step 20670, loss = 0.23, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 19h:44m:49s remains)
INFO - root - 2017-12-17 04:05:23.623940: step 20680, loss = 0.25, batch loss = 0.18 (35.0 examples/sec; 0.229 sec/batch; 19h:48m:04s remains)
INFO - root - 2017-12-17 04:05:25.932527: step 20690, loss = 0.23, batch loss = 0.15 (33.9 examples/sec; 0.236 sec/batch; 20h:24m:41s remains)
INFO - root - 2017-12-17 04:05:28.197231: step 20700, loss = 0.20, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 19h:19m:58s remains)
INFO - root - 2017-12-17 04:05:30.574829: step 20710, loss = 0.22, batch loss = 0.15 (34.6 examples/sec; 0.231 sec/batch; 20h:02m:03s remains)
INFO - root - 2017-12-17 04:05:32.847489: step 20720, loss = 0.22, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 19h:34m:09s remains)
INFO - root - 2017-12-17 04:05:35.116092: step 20730, loss = 0.21, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 19h:47m:45s remains)
INFO - root - 2017-12-17 04:05:37.394054: step 20740, loss = 0.27, batch loss = 0.19 (35.2 examples/sec; 0.227 sec/batch; 19h:39m:34s remains)
INFO - root - 2017-12-17 04:05:39.643271: step 20750, loss = 0.18, batch loss = 0.11 (34.7 examples/sec; 0.230 sec/batch; 19h:56m:53s remains)
INFO - root - 2017-12-17 04:05:41.917312: step 20760, loss = 0.21, batch loss = 0.14 (34.2 examples/sec; 0.234 sec/batch; 20h:15m:56s remains)
INFO - root - 2017-12-17 04:05:44.187805: step 20770, loss = 0.18, batch loss = 0.11 (32.9 examples/sec; 0.244 sec/batch; 21h:05m:10s remains)
INFO - root - 2017-12-17 04:05:46.453738: step 20780, loss = 0.21, batch loss = 0.14 (36.4 examples/sec; 0.220 sec/batch; 19h:01m:28s remains)
INFO - root - 2017-12-17 04:05:48.695873: step 20790, loss = 0.21, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 19h:05m:19s remains)
INFO - root - 2017-12-17 04:05:51.014411: step 20800, loss = 0.25, batch loss = 0.17 (35.3 examples/sec; 0.227 sec/batch; 19h:38m:00s remains)
INFO - root - 2017-12-17 04:05:53.376114: step 20810, loss = 0.21, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 20h:00m:20s remains)
INFO - root - 2017-12-17 04:05:55.650317: step 20820, loss = 0.22, batch loss = 0.15 (34.8 examples/sec; 0.230 sec/batch; 19h:54m:44s remains)
INFO - root - 2017-12-17 04:05:57.904069: step 20830, loss = 0.24, batch loss = 0.17 (36.3 examples/sec; 0.221 sec/batch; 19h:05m:39s remains)
INFO - root - 2017-12-17 04:06:00.160930: step 20840, loss = 0.20, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 20h:02m:52s remains)
INFO - root - 2017-12-17 04:06:02.420698: step 20850, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.229 sec/batch; 19h:47m:25s remains)
INFO - root - 2017-12-17 04:06:04.721482: step 20860, loss = 0.22, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 19h:43m:26s remains)
INFO - root - 2017-12-17 04:06:06.954818: step 20870, loss = 0.21, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 19h:04m:56s remains)
INFO - root - 2017-12-17 04:06:09.228005: step 20880, loss = 0.19, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 19h:37m:27s remains)
INFO - root - 2017-12-17 04:06:11.512169: step 20890, loss = 0.21, batch loss = 0.14 (36.7 examples/sec; 0.218 sec/batch; 18h:52m:18s remains)
INFO - root - 2017-12-17 04:06:13.776279: step 20900, loss = 0.31, batch loss = 0.24 (34.7 examples/sec; 0.231 sec/batch; 19h:57m:48s remains)
INFO - root - 2017-12-17 04:06:16.194759: step 20910, loss = 0.20, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 20h:05m:15s remains)
INFO - root - 2017-12-17 04:06:18.497787: step 20920, loss = 0.25, batch loss = 0.18 (35.6 examples/sec; 0.225 sec/batch; 19h:27m:23s remains)
INFO - root - 2017-12-17 04:06:20.734328: step 20930, loss = 0.19, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 19h:39m:31s remains)
INFO - root - 2017-12-17 04:06:22.992055: step 20940, loss = 0.19, batch loss = 0.11 (36.7 examples/sec; 0.218 sec/batch; 18h:50m:23s remains)
INFO - root - 2017-12-17 04:06:25.244754: step 20950, loss = 0.20, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 19h:06m:03s remains)
INFO - root - 2017-12-17 04:06:27.530619: step 20960, loss = 0.21, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 20h:10m:29s remains)
INFO - root - 2017-12-17 04:06:29.794841: step 20970, loss = 0.23, batch loss = 0.16 (34.9 examples/sec; 0.229 sec/batch; 19h:49m:45s remains)
INFO - root - 2017-12-17 04:06:32.068492: step 20980, loss = 0.23, batch loss = 0.16 (36.3 examples/sec; 0.221 sec/batch; 19h:04m:54s remains)
INFO - root - 2017-12-17 04:06:34.310431: step 20990, loss = 0.20, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 19h:44m:01s remains)
INFO - root - 2017-12-17 04:06:36.561471: step 21000, loss = 0.19, batch loss = 0.12 (37.0 examples/sec; 0.216 sec/batch; 18h:41m:49s remains)
INFO - root - 2017-12-17 04:06:38.979447: step 21010, loss = 0.17, batch loss = 0.10 (34.9 examples/sec; 0.229 sec/batch; 19h:48m:34s remains)
INFO - root - 2017-12-17 04:06:41.209608: step 21020, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.224 sec/batch; 19h:25m:01s remains)
INFO - root - 2017-12-17 04:06:43.474736: step 21030, loss = 0.25, batch loss = 0.17 (34.8 examples/sec; 0.230 sec/batch; 19h:52m:29s remains)
INFO - root - 2017-12-17 04:06:45.754633: step 21040, loss = 0.21, batch loss = 0.14 (33.9 examples/sec; 0.236 sec/batch; 20h:24m:09s remains)
INFO - root - 2017-12-17 04:06:48.019091: step 21050, loss = 0.18, batch loss = 0.10 (34.7 examples/sec; 0.230 sec/batch; 19h:55m:07s remains)
INFO - root - 2017-12-17 04:06:50.282003: step 21060, loss = 0.29, batch loss = 0.21 (35.8 examples/sec; 0.223 sec/batch; 19h:19m:36s remains)
INFO - root - 2017-12-17 04:06:52.545104: step 21070, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 19h:05m:52s remains)
INFO - root - 2017-12-17 04:06:54.789551: step 21080, loss = 0.23, batch loss = 0.16 (35.0 examples/sec; 0.229 sec/batch; 19h:46m:40s remains)
INFO - root - 2017-12-17 04:06:57.056013: step 21090, loss = 0.21, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 19h:24m:41s remains)
INFO - root - 2017-12-17 04:06:59.332602: step 21100, loss = 0.23, batch loss = 0.16 (35.0 examples/sec; 0.229 sec/batch; 19h:47m:30s remains)
INFO - root - 2017-12-17 04:07:01.763908: step 21110, loss = 0.23, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 19h:06m:52s remains)
INFO - root - 2017-12-17 04:07:04.004084: step 21120, loss = 0.22, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 18h:57m:43s remains)
INFO - root - 2017-12-17 04:07:06.295865: step 21130, loss = 0.23, batch loss = 0.16 (33.0 examples/sec; 0.242 sec/batch; 20h:57m:49s remains)
INFO - root - 2017-12-17 04:07:08.600551: step 21140, loss = 0.20, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 19h:21m:35s remains)
INFO - root - 2017-12-17 04:07:10.867652: step 21150, loss = 0.21, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 19h:11m:12s remains)
INFO - root - 2017-12-17 04:07:13.125616: step 21160, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 19h:38m:34s remains)
INFO - root - 2017-12-17 04:07:15.386752: step 21170, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 19h:20m:52s remains)
INFO - root - 2017-12-17 04:07:17.660406: step 21180, loss = 0.21, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 19h:13m:36s remains)
INFO - root - 2017-12-17 04:07:19.940473: step 21190, loss = 0.18, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 19h:54m:01s remains)
INFO - root - 2017-12-17 04:07:22.225069: step 21200, loss = 0.21, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 19h:06m:53s remains)
INFO - root - 2017-12-17 04:07:24.632365: step 21210, loss = 0.20, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 19h:35m:29s remains)
INFO - root - 2017-12-17 04:07:26.882551: step 21220, loss = 0.23, batch loss = 0.16 (36.3 examples/sec; 0.220 sec/batch; 19h:01m:57s remains)
INFO - root - 2017-12-17 04:07:29.200544: step 21230, loss = 0.22, batch loss = 0.14 (33.5 examples/sec; 0.239 sec/batch; 20h:37m:26s remains)
INFO - root - 2017-12-17 04:07:31.499721: step 21240, loss = 0.20, batch loss = 0.12 (35.5 examples/sec; 0.226 sec/batch; 19h:29m:51s remains)
INFO - root - 2017-12-17 04:07:33.766818: step 21250, loss = 0.20, batch loss = 0.13 (33.7 examples/sec; 0.237 sec/batch; 20h:31m:06s remains)
INFO - root - 2017-12-17 04:07:36.029540: step 21260, loss = 0.21, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 19h:47m:48s remains)
INFO - root - 2017-12-17 04:07:38.303391: step 21270, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 19h:49m:49s remains)
INFO - root - 2017-12-17 04:07:40.568596: step 21280, loss = 0.25, batch loss = 0.17 (35.5 examples/sec; 0.225 sec/batch; 19h:28m:55s remains)
INFO - root - 2017-12-17 04:07:42.851282: step 21290, loss = 0.20, batch loss = 0.12 (34.3 examples/sec; 0.233 sec/batch; 20h:10m:02s remains)
INFO - root - 2017-12-17 04:07:45.120774: step 21300, loss = 0.21, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 19h:27m:36s remains)
INFO - root - 2017-12-17 04:07:47.579347: step 21310, loss = 0.16, batch loss = 0.09 (37.0 examples/sec; 0.216 sec/batch; 18h:41m:07s remains)
INFO - root - 2017-12-17 04:07:49.868146: step 21320, loss = 0.19, batch loss = 0.11 (35.0 examples/sec; 0.229 sec/batch; 19h:45m:49s remains)
INFO - root - 2017-12-17 04:07:52.181207: step 21330, loss = 0.19, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 19h:07m:12s remains)
INFO - root - 2017-12-17 04:07:54.459822: step 21340, loss = 0.24, batch loss = 0.17 (35.8 examples/sec; 0.223 sec/batch; 19h:17m:29s remains)
INFO - root - 2017-12-17 04:07:56.758657: step 21350, loss = 0.20, batch loss = 0.13 (36.8 examples/sec; 0.217 sec/batch; 18h:47m:10s remains)
INFO - root - 2017-12-17 04:07:59.011867: step 21360, loss = 0.22, batch loss = 0.15 (35.2 examples/sec; 0.228 sec/batch; 19h:40m:11s remains)
INFO - root - 2017-12-17 04:08:01.317884: step 21370, loss = 0.19, batch loss = 0.11 (36.7 examples/sec; 0.218 sec/batch; 18h:50m:59s remains)
INFO - root - 2017-12-17 04:08:03.613725: step 21380, loss = 0.19, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 19h:57m:26s remains)
INFO - root - 2017-12-17 04:08:05.889953: step 21390, loss = 0.22, batch loss = 0.15 (35.8 examples/sec; 0.223 sec/batch; 19h:17m:57s remains)
INFO - root - 2017-12-17 04:08:08.196318: step 21400, loss = 0.20, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 19h:23m:05s remains)
INFO - root - 2017-12-17 04:08:10.665534: step 21410, loss = 0.25, batch loss = 0.17 (33.5 examples/sec; 0.239 sec/batch; 20h:38m:45s remains)
INFO - root - 2017-12-17 04:08:12.975905: step 21420, loss = 0.19, batch loss = 0.12 (33.9 examples/sec; 0.236 sec/batch; 20h:23m:05s remains)
INFO - root - 2017-12-17 04:08:15.249049: step 21430, loss = 0.24, batch loss = 0.17 (37.2 examples/sec; 0.215 sec/batch; 18h:35m:18s remains)
INFO - root - 2017-12-17 04:08:17.525464: step 21440, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 19h:27m:10s remains)
INFO - root - 2017-12-17 04:08:19.805181: step 21450, loss = 0.18, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 19h:19m:06s remains)
INFO - root - 2017-12-17 04:08:22.069451: step 21460, loss = 0.19, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 20h:00m:04s remains)
INFO - root - 2017-12-17 04:08:24.349932: step 21470, loss = 0.17, batch loss = 0.10 (33.5 examples/sec; 0.239 sec/batch; 20h:37m:31s remains)
INFO - root - 2017-12-17 04:08:26.637800: step 21480, loss = 0.18, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 19h:38m:36s remains)
INFO - root - 2017-12-17 04:08:28.931689: step 21490, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:32m:14s remains)
INFO - root - 2017-12-17 04:08:31.240833: step 21500, loss = 0.25, batch loss = 0.17 (35.0 examples/sec; 0.229 sec/batch; 19h:45m:49s remains)
INFO - root - 2017-12-17 04:08:33.643988: step 21510, loss = 0.20, batch loss = 0.13 (35.3 examples/sec; 0.226 sec/batch; 19h:33m:58s remains)
INFO - root - 2017-12-17 04:08:35.925930: step 21520, loss = 0.17, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 19h:52m:06s remains)
INFO - root - 2017-12-17 04:08:38.193618: step 21530, loss = 0.18, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 19h:30m:38s remains)
INFO - root - 2017-12-17 04:08:40.466113: step 21540, loss = 0.23, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 19h:36m:46s remains)
INFO - root - 2017-12-17 04:08:42.737498: step 21550, loss = 0.23, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 19h:40m:22s remains)
INFO - root - 2017-12-17 04:08:45.006318: step 21560, loss = 0.22, batch loss = 0.14 (36.1 examples/sec; 0.222 sec/batch; 19h:09m:39s remains)
INFO - root - 2017-12-17 04:08:47.283681: step 21570, loss = 0.21, batch loss = 0.13 (35.6 examples/sec; 0.224 sec/batch; 19h:23m:04s remains)
INFO - root - 2017-12-17 04:08:49.523910: step 21580, loss = 0.24, batch loss = 0.17 (35.4 examples/sec; 0.226 sec/batch; 19h:31m:35s remains)
INFO - root - 2017-12-17 04:08:51.809844: step 21590, loss = 0.18, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 19h:02m:08s remains)
INFO - root - 2017-12-17 04:08:54.108011: step 21600, loss = 0.19, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 19h:35m:06s remains)
INFO - root - 2017-12-17 04:08:56.576324: step 21610, loss = 0.21, batch loss = 0.14 (33.4 examples/sec; 0.240 sec/batch; 20h:41m:31s remains)
INFO - root - 2017-12-17 04:08:58.868986: step 21620, loss = 0.23, batch loss = 0.15 (34.9 examples/sec; 0.229 sec/batch; 19h:46m:51s remains)
INFO - root - 2017-12-17 04:09:01.128920: step 21630, loss = 0.20, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 19h:20m:20s remains)
INFO - root - 2017-12-17 04:09:03.376757: step 21640, loss = 0.23, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 19h:14m:27s remains)
INFO - root - 2017-12-17 04:09:05.691415: step 21650, loss = 0.27, batch loss = 0.20 (33.2 examples/sec; 0.241 sec/batch; 20h:48m:36s remains)
INFO - root - 2017-12-17 04:09:07.973978: step 21660, loss = 0.17, batch loss = 0.09 (34.9 examples/sec; 0.229 sec/batch; 19h:48m:43s remains)
INFO - root - 2017-12-17 04:09:10.247074: step 21670, loss = 0.21, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 19h:02m:07s remains)
INFO - root - 2017-12-17 04:09:12.509753: step 21680, loss = 0.19, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 19h:35m:33s remains)
INFO - root - 2017-12-17 04:09:14.798791: step 21690, loss = 0.20, batch loss = 0.12 (34.7 examples/sec; 0.231 sec/batch; 19h:54m:21s remains)
INFO - root - 2017-12-17 04:09:17.069687: step 21700, loss = 0.20, batch loss = 0.12 (34.7 examples/sec; 0.231 sec/batch; 19h:54m:44s remains)
INFO - root - 2017-12-17 04:09:19.504464: step 21710, loss = 0.24, batch loss = 0.16 (35.8 examples/sec; 0.223 sec/batch; 19h:16m:12s remains)
INFO - root - 2017-12-17 04:09:21.804584: step 21720, loss = 0.18, batch loss = 0.11 (33.3 examples/sec; 0.240 sec/batch; 20h:44m:24s remains)
INFO - root - 2017-12-17 04:09:24.120408: step 21730, loss = 0.18, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 20h:02m:41s remains)
INFO - root - 2017-12-17 04:09:26.385537: step 21740, loss = 0.22, batch loss = 0.15 (35.5 examples/sec; 0.225 sec/batch; 19h:27m:07s remains)
INFO - root - 2017-12-17 04:09:28.667287: step 21750, loss = 0.19, batch loss = 0.12 (36.8 examples/sec; 0.218 sec/batch; 18h:46m:38s remains)
INFO - root - 2017-12-17 04:09:30.941880: step 21760, loss = 0.30, batch loss = 0.22 (33.3 examples/sec; 0.240 sec/batch; 20h:43m:25s remains)
INFO - root - 2017-12-17 04:09:33.240191: step 21770, loss = 0.18, batch loss = 0.11 (35.2 examples/sec; 0.227 sec/batch; 19h:37m:49s remains)
INFO - root - 2017-12-17 04:09:35.556840: step 21780, loss = 0.21, batch loss = 0.14 (34.4 examples/sec; 0.232 sec/batch; 20h:03m:35s remains)
INFO - root - 2017-12-17 04:09:37.853098: step 21790, loss = 0.21, batch loss = 0.13 (34.7 examples/sec; 0.230 sec/batch; 19h:52m:10s remains)
INFO - root - 2017-12-17 04:09:40.152723: step 21800, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 19h:30m:59s remains)
INFO - root - 2017-12-17 04:09:42.545101: step 21810, loss = 0.21, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 19h:25m:19s remains)
INFO - root - 2017-12-17 04:09:44.808772: step 21820, loss = 0.19, batch loss = 0.11 (36.3 examples/sec; 0.221 sec/batch; 19h:02m:31s remains)
INFO - root - 2017-12-17 04:09:47.093821: step 21830, loss = 0.27, batch loss = 0.20 (35.0 examples/sec; 0.229 sec/batch; 19h:45m:03s remains)
INFO - root - 2017-12-17 04:09:49.351746: step 21840, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 19h:17m:58s remains)
INFO - root - 2017-12-17 04:09:51.604775: step 21850, loss = 0.21, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 19h:49m:15s remains)
INFO - root - 2017-12-17 04:09:53.883191: step 21860, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 19h:14m:51s remains)
INFO - root - 2017-12-17 04:09:56.124400: step 21870, loss = 0.17, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 19h:21m:34s remains)
INFO - root - 2017-12-17 04:09:58.374373: step 21880, loss = 0.19, batch loss = 0.12 (36.1 examples/sec; 0.221 sec/batch; 19h:05m:53s remains)
INFO - root - 2017-12-17 04:10:00.632462: step 21890, loss = 0.18, batch loss = 0.10 (35.0 examples/sec; 0.228 sec/batch; 19h:41m:42s remains)
INFO - root - 2017-12-17 04:10:02.922068: step 21900, loss = 0.24, batch loss = 0.17 (32.9 examples/sec; 0.243 sec/batch; 20h:59m:42s remains)
INFO - root - 2017-12-17 04:10:05.319974: step 21910, loss = 0.20, batch loss = 0.13 (36.5 examples/sec; 0.219 sec/batch; 18h:54m:57s remains)
INFO - root - 2017-12-17 04:10:07.563612: step 21920, loss = 0.19, batch loss = 0.12 (37.9 examples/sec; 0.211 sec/batch; 18h:11m:23s remains)
INFO - root - 2017-12-17 04:10:09.843614: step 21930, loss = 0.20, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 19h:18m:23s remains)
INFO - root - 2017-12-17 04:10:12.078879: step 21940, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 19h:14m:40s remains)
INFO - root - 2017-12-17 04:10:14.303898: step 21950, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:28m:17s remains)
INFO - root - 2017-12-17 04:10:16.575409: step 21960, loss = 0.21, batch loss = 0.13 (33.8 examples/sec; 0.236 sec/batch; 20h:24m:01s remains)
INFO - root - 2017-12-17 04:10:18.806156: step 21970, loss = 0.19, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 19h:33m:46s remains)
INFO - root - 2017-12-17 04:10:21.069038: step 21980, loss = 0.20, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 19h:12m:11s remains)
INFO - root - 2017-12-17 04:10:23.301854: step 21990, loss = 0.21, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 19h:39m:15s remains)
INFO - root - 2017-12-17 04:10:25.537330: step 22000, loss = 0.18, batch loss = 0.10 (35.0 examples/sec; 0.229 sec/batch; 19h:42m:51s remains)
INFO - root - 2017-12-17 04:10:27.933429: step 22010, loss = 0.20, batch loss = 0.12 (35.6 examples/sec; 0.224 sec/batch; 19h:21m:17s remains)
INFO - root - 2017-12-17 04:10:30.189792: step 22020, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 19h:22m:57s remains)
INFO - root - 2017-12-17 04:10:32.478604: step 22030, loss = 0.18, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 19h:57m:33s remains)
INFO - root - 2017-12-17 04:10:34.723057: step 22040, loss = 0.21, batch loss = 0.13 (35.8 examples/sec; 0.224 sec/batch; 19h:17m:17s remains)
INFO - root - 2017-12-17 04:10:36.956621: step 22050, loss = 0.22, batch loss = 0.14 (35.3 examples/sec; 0.227 sec/batch; 19h:33m:45s remains)
INFO - root - 2017-12-17 04:10:39.196749: step 22060, loss = 0.21, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 19h:40m:38s remains)
INFO - root - 2017-12-17 04:10:41.448882: step 22070, loss = 0.18, batch loss = 0.11 (34.3 examples/sec; 0.233 sec/batch; 20h:07m:14s remains)
INFO - root - 2017-12-17 04:10:43.671207: step 22080, loss = 0.19, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 19h:11m:28s remains)
INFO - root - 2017-12-17 04:10:45.909375: step 22090, loss = 0.20, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 19h:15m:06s remains)
INFO - root - 2017-12-17 04:10:48.158968: step 22100, loss = 0.19, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 19h:25m:42s remains)
INFO - root - 2017-12-17 04:10:50.544425: step 22110, loss = 0.19, batch loss = 0.12 (34.2 examples/sec; 0.234 sec/batch; 20h:11m:45s remains)
INFO - root - 2017-12-17 04:10:52.788957: step 22120, loss = 0.17, batch loss = 0.09 (37.0 examples/sec; 0.216 sec/batch; 18h:38m:13s remains)
INFO - root - 2017-12-17 04:10:55.017072: step 22130, loss = 0.19, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 19h:32m:51s remains)
INFO - root - 2017-12-17 04:10:57.289234: step 22140, loss = 0.20, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 19h:21m:49s remains)
INFO - root - 2017-12-17 04:10:59.571812: step 22150, loss = 0.20, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 19h:08m:26s remains)
INFO - root - 2017-12-17 04:11:01.834695: step 22160, loss = 0.22, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 19h:29m:08s remains)
INFO - root - 2017-12-17 04:11:04.068988: step 22170, loss = 0.20, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 18h:57m:07s remains)
INFO - root - 2017-12-17 04:11:06.314448: step 22180, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.228 sec/batch; 19h:36m:57s remains)
INFO - root - 2017-12-17 04:11:08.614559: step 22190, loss = 0.17, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 19h:02m:57s remains)
INFO - root - 2017-12-17 04:11:10.886165: step 22200, loss = 0.22, batch loss = 0.15 (35.8 examples/sec; 0.223 sec/batch; 19h:14m:13s remains)
INFO - root - 2017-12-17 04:11:13.329376: step 22210, loss = 0.20, batch loss = 0.13 (31.0 examples/sec; 0.258 sec/batch; 22h:14m:57s remains)
INFO - root - 2017-12-17 04:11:15.592466: step 22220, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 19h:23m:01s remains)
INFO - root - 2017-12-17 04:11:17.843387: step 22230, loss = 0.19, batch loss = 0.11 (33.4 examples/sec; 0.239 sec/batch; 20h:37m:28s remains)
INFO - root - 2017-12-17 04:11:20.136808: step 22240, loss = 0.17, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 19h:26m:57s remains)
INFO - root - 2017-12-17 04:11:22.465859: step 22250, loss = 0.18, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 19h:28m:15s remains)
INFO - root - 2017-12-17 04:11:24.721133: step 22260, loss = 0.26, batch loss = 0.18 (34.9 examples/sec; 0.229 sec/batch; 19h:46m:07s remains)
INFO - root - 2017-12-17 04:11:27.049911: step 22270, loss = 0.26, batch loss = 0.18 (36.0 examples/sec; 0.222 sec/batch; 19h:08m:53s remains)
INFO - root - 2017-12-17 04:11:29.333793: step 22280, loss = 0.18, batch loss = 0.11 (35.0 examples/sec; 0.228 sec/batch; 19h:41m:06s remains)
INFO - root - 2017-12-17 04:11:31.574467: step 22290, loss = 0.16, batch loss = 0.09 (35.3 examples/sec; 0.227 sec/batch; 19h:33m:08s remains)
INFO - root - 2017-12-17 04:11:33.883977: step 22300, loss = 0.22, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 19h:07m:50s remains)
INFO - root - 2017-12-17 04:11:36.253621: step 22310, loss = 0.21, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 19h:43m:19s remains)
INFO - root - 2017-12-17 04:11:38.488699: step 22320, loss = 0.17, batch loss = 0.10 (34.5 examples/sec; 0.232 sec/batch; 20h:00m:12s remains)
INFO - root - 2017-12-17 04:11:40.747181: step 22330, loss = 0.22, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 19h:09m:45s remains)
INFO - root - 2017-12-17 04:11:43.046636: step 22340, loss = 0.20, batch loss = 0.12 (35.8 examples/sec; 0.223 sec/batch; 19h:13m:36s remains)
INFO - root - 2017-12-17 04:11:45.303240: step 22350, loss = 0.23, batch loss = 0.15 (34.0 examples/sec; 0.235 sec/batch; 20h:14m:58s remains)
INFO - root - 2017-12-17 04:11:47.621589: step 22360, loss = 0.22, batch loss = 0.14 (34.7 examples/sec; 0.231 sec/batch; 19h:51m:54s remains)
INFO - root - 2017-12-17 04:11:49.921044: step 22370, loss = 0.20, batch loss = 0.12 (33.2 examples/sec; 0.241 sec/batch; 20h:45m:25s remains)
INFO - root - 2017-12-17 04:11:52.162626: step 22380, loss = 0.23, batch loss = 0.16 (34.3 examples/sec; 0.233 sec/batch; 20h:05m:15s remains)
INFO - root - 2017-12-17 04:11:54.441274: step 22390, loss = 0.18, batch loss = 0.10 (35.8 examples/sec; 0.223 sec/batch; 19h:14m:45s remains)
INFO - root - 2017-12-17 04:11:56.698332: step 22400, loss = 0.21, batch loss = 0.13 (36.5 examples/sec; 0.219 sec/batch; 18h:52m:35s remains)
INFO - root - 2017-12-17 04:11:59.080747: step 22410, loss = 0.24, batch loss = 0.16 (36.3 examples/sec; 0.220 sec/batch; 18h:58m:08s remains)
INFO - root - 2017-12-17 04:12:01.325572: step 22420, loss = 0.23, batch loss = 0.15 (35.7 examples/sec; 0.224 sec/batch; 19h:17m:14s remains)
INFO - root - 2017-12-17 04:12:03.560521: step 22430, loss = 0.27, batch loss = 0.19 (35.7 examples/sec; 0.224 sec/batch; 19h:18m:02s remains)
INFO - root - 2017-12-17 04:12:05.815156: step 22440, loss = 0.22, batch loss = 0.15 (35.3 examples/sec; 0.226 sec/batch; 19h:30m:10s remains)
INFO - root - 2017-12-17 04:12:08.095722: step 22450, loss = 0.20, batch loss = 0.12 (34.1 examples/sec; 0.235 sec/batch; 20h:12m:47s remains)
INFO - root - 2017-12-17 04:12:10.404008: step 22460, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 19h:17m:27s remains)
INFO - root - 2017-12-17 04:12:12.679090: step 22470, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 19h:40m:10s remains)
INFO - root - 2017-12-17 04:12:14.955519: step 22480, loss = 0.24, batch loss = 0.16 (36.0 examples/sec; 0.222 sec/batch; 19h:07m:44s remains)
INFO - root - 2017-12-17 04:12:17.173146: step 22490, loss = 0.20, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 19h:23m:26s remains)
INFO - root - 2017-12-17 04:12:19.457262: step 22500, loss = 0.30, batch loss = 0.22 (34.5 examples/sec; 0.232 sec/batch; 19h:58m:25s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-22500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-22500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 04:12:22.539968: step 22510, loss = 0.17, batch loss = 0.10 (34.6 examples/sec; 0.231 sec/batch; 19h:53m:10s remains)
INFO - root - 2017-12-17 04:12:24.784765: step 22520, loss = 0.18, batch loss = 0.10 (34.5 examples/sec; 0.232 sec/batch; 19h:58m:00s remains)
INFO - root - 2017-12-17 04:12:27.059744: step 22530, loss = 0.19, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 19h:00m:32s remains)
INFO - root - 2017-12-17 04:12:29.314487: step 22540, loss = 0.19, batch loss = 0.12 (34.5 examples/sec; 0.232 sec/batch; 19h:59m:11s remains)
INFO - root - 2017-12-17 04:12:31.594054: step 22550, loss = 0.20, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 20h:04m:35s remains)
INFO - root - 2017-12-17 04:12:33.843695: step 22560, loss = 0.20, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 19h:09m:07s remains)
INFO - root - 2017-12-17 04:12:36.095503: step 22570, loss = 0.17, batch loss = 0.09 (36.3 examples/sec; 0.220 sec/batch; 18h:58m:58s remains)
INFO - root - 2017-12-17 04:12:38.378283: step 22580, loss = 0.20, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 19h:53m:49s remains)
INFO - root - 2017-12-17 04:12:40.600390: step 22590, loss = 0.19, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 19h:02m:36s remains)
INFO - root - 2017-12-17 04:12:42.841958: step 22600, loss = 0.20, batch loss = 0.13 (34.4 examples/sec; 0.232 sec/batch; 20h:00m:22s remains)
INFO - root - 2017-12-17 04:12:45.227954: step 22610, loss = 0.16, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 19h:15m:58s remains)
INFO - root - 2017-12-17 04:12:47.497079: step 22620, loss = 0.21, batch loss = 0.14 (34.2 examples/sec; 0.234 sec/batch; 20h:06m:31s remains)
INFO - root - 2017-12-17 04:12:49.749256: step 22630, loss = 0.17, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 19h:08m:19s remains)
INFO - root - 2017-12-17 04:12:52.009254: step 22640, loss = 0.21, batch loss = 0.13 (33.1 examples/sec; 0.242 sec/batch; 20h:48m:30s remains)
INFO - root - 2017-12-17 04:12:54.275062: step 22650, loss = 0.18, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 19h:21m:58s remains)
INFO - root - 2017-12-17 04:12:56.559185: step 22660, loss = 0.21, batch loss = 0.14 (34.4 examples/sec; 0.233 sec/batch; 20h:01m:27s remains)
INFO - root - 2017-12-17 04:12:58.808804: step 22670, loss = 0.23, batch loss = 0.15 (37.5 examples/sec; 0.213 sec/batch; 18h:20m:25s remains)
INFO - root - 2017-12-17 04:13:01.058641: step 22680, loss = 0.22, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 19h:11m:49s remains)
INFO - root - 2017-12-17 04:13:03.360798: step 22690, loss = 0.16, batch loss = 0.09 (33.8 examples/sec; 0.237 sec/batch; 20h:22m:50s remains)
INFO - root - 2017-12-17 04:13:05.656873: step 22700, loss = 0.19, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 19h:56m:07s remains)
INFO - root - 2017-12-17 04:13:08.061801: step 22710, loss = 0.20, batch loss = 0.12 (33.7 examples/sec; 0.238 sec/batch; 20h:26m:15s remains)
INFO - root - 2017-12-17 04:13:10.331513: step 22720, loss = 0.22, batch loss = 0.14 (35.3 examples/sec; 0.227 sec/batch; 19h:31m:39s remains)
INFO - root - 2017-12-17 04:13:12.594094: step 22730, loss = 0.19, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 19h:02m:08s remains)
INFO - root - 2017-12-17 04:13:14.847122: step 22740, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.224 sec/batch; 19h:18m:33s remains)
INFO - root - 2017-12-17 04:13:17.107886: step 22750, loss = 0.23, batch loss = 0.16 (33.5 examples/sec; 0.239 sec/batch; 20h:34m:10s remains)
INFO - root - 2017-12-17 04:13:19.339517: step 22760, loss = 0.19, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 19h:15m:22s remains)
INFO - root - 2017-12-17 04:13:21.605162: step 22770, loss = 0.17, batch loss = 0.10 (35.2 examples/sec; 0.228 sec/batch; 19h:34m:37s remains)
INFO - root - 2017-12-17 04:13:23.866880: step 22780, loss = 0.20, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 19h:35m:58s remains)
INFO - root - 2017-12-17 04:13:26.123380: step 22790, loss = 0.18, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 19h:20m:34s remains)
INFO - root - 2017-12-17 04:13:28.363776: step 22800, loss = 0.19, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 18h:52m:45s remains)
INFO - root - 2017-12-17 04:13:30.750243: step 22810, loss = 0.15, batch loss = 0.08 (34.2 examples/sec; 0.234 sec/batch; 20h:09m:03s remains)
INFO - root - 2017-12-17 04:13:33.003664: step 22820, loss = 0.26, batch loss = 0.18 (33.6 examples/sec; 0.238 sec/batch; 20h:27m:12s remains)
INFO - root - 2017-12-17 04:13:35.266508: step 22830, loss = 0.18, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 19h:27m:45s remains)
INFO - root - 2017-12-17 04:13:37.513146: step 22840, loss = 0.19, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 19h:05m:34s remains)
INFO - root - 2017-12-17 04:13:39.771095: step 22850, loss = 0.19, batch loss = 0.12 (36.1 examples/sec; 0.222 sec/batch; 19h:04m:12s remains)
INFO - root - 2017-12-17 04:13:42.027174: step 22860, loss = 0.17, batch loss = 0.09 (34.5 examples/sec; 0.232 sec/batch; 19h:56m:07s remains)
INFO - root - 2017-12-17 04:13:44.276467: step 22870, loss = 0.22, batch loss = 0.15 (35.3 examples/sec; 0.226 sec/batch; 19h:28m:23s remains)
INFO - root - 2017-12-17 04:13:46.515470: step 22880, loss = 0.21, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 19h:34m:30s remains)
INFO - root - 2017-12-17 04:13:48.774519: step 22890, loss = 0.20, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 19h:55m:49s remains)
INFO - root - 2017-12-17 04:13:51.014796: step 22900, loss = 0.20, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 19h:05m:21s remains)
INFO - root - 2017-12-17 04:13:53.372596: step 22910, loss = 0.20, batch loss = 0.13 (36.5 examples/sec; 0.219 sec/batch; 18h:51m:53s remains)
INFO - root - 2017-12-17 04:13:55.676380: step 22920, loss = 0.17, batch loss = 0.09 (36.7 examples/sec; 0.218 sec/batch; 18h:44m:44s remains)
INFO - root - 2017-12-17 04:13:57.951860: step 22930, loss = 0.22, batch loss = 0.15 (34.8 examples/sec; 0.230 sec/batch; 19h:45m:51s remains)
INFO - root - 2017-12-17 04:14:00.197613: step 22940, loss = 0.22, batch loss = 0.15 (34.9 examples/sec; 0.229 sec/batch; 19h:43m:59s remains)
INFO - root - 2017-12-17 04:14:02.451994: step 22950, loss = 0.17, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 19h:04m:41s remains)
INFO - root - 2017-12-17 04:14:04.690806: step 22960, loss = 0.20, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 19h:37m:48s remains)
INFO - root - 2017-12-17 04:14:06.961984: step 22970, loss = 0.17, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 19h:17m:13s remains)
INFO - root - 2017-12-17 04:14:09.234315: step 22980, loss = 0.18, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 19h:56m:46s remains)
INFO - root - 2017-12-17 04:14:11.484560: step 22990, loss = 0.19, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 19h:06m:53s remains)
INFO - root - 2017-12-17 04:14:13.716046: step 23000, loss = 0.17, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 19h:25m:23s remains)
INFO - root - 2017-12-17 04:14:16.147106: step 23010, loss = 0.27, batch loss = 0.19 (36.2 examples/sec; 0.221 sec/batch; 18h:59m:06s remains)
INFO - root - 2017-12-17 04:14:18.394622: step 23020, loss = 0.20, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 19h:03m:44s remains)
INFO - root - 2017-12-17 04:14:20.637905: step 23030, loss = 0.21, batch loss = 0.14 (35.2 examples/sec; 0.227 sec/batch; 19h:30m:37s remains)
INFO - root - 2017-12-17 04:14:22.936822: step 23040, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:36m:59s remains)
INFO - root - 2017-12-17 04:14:25.212424: step 23050, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 19h:24m:41s remains)
INFO - root - 2017-12-17 04:14:27.462430: step 23060, loss = 0.20, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 18h:49m:53s remains)
INFO - root - 2017-12-17 04:14:29.729286: step 23070, loss = 0.22, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 19h:26m:45s remains)
INFO - root - 2017-12-17 04:14:32.020960: step 23080, loss = 0.19, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 19h:04m:45s remains)
INFO - root - 2017-12-17 04:14:34.260884: step 23090, loss = 0.21, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 19h:33m:52s remains)
INFO - root - 2017-12-17 04:14:36.482834: step 23100, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 19h:14m:21s remains)
INFO - root - 2017-12-17 04:14:38.904287: step 23110, loss = 0.21, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 19h:40m:34s remains)
INFO - root - 2017-12-17 04:14:41.173898: step 23120, loss = 0.23, batch loss = 0.16 (34.1 examples/sec; 0.235 sec/batch; 20h:09m:55s remains)
INFO - root - 2017-12-17 04:14:43.428700: step 23130, loss = 0.20, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 18h:53m:13s remains)
INFO - root - 2017-12-17 04:14:45.723312: step 23140, loss = 0.21, batch loss = 0.14 (35.8 examples/sec; 0.223 sec/batch; 19h:11m:39s remains)
INFO - root - 2017-12-17 04:14:47.979656: step 23150, loss = 0.30, batch loss = 0.23 (35.8 examples/sec; 0.224 sec/batch; 19h:13m:34s remains)
INFO - root - 2017-12-17 04:14:50.256375: step 23160, loss = 0.21, batch loss = 0.13 (34.0 examples/sec; 0.235 sec/batch; 20h:11m:27s remains)
INFO - root - 2017-12-17 04:14:52.498358: step 23170, loss = 0.20, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:34m:07s remains)
INFO - root - 2017-12-17 04:14:54.713058: step 23180, loss = 0.26, batch loss = 0.18 (35.6 examples/sec; 0.225 sec/batch; 19h:18m:12s remains)
INFO - root - 2017-12-17 04:14:56.984992: step 23190, loss = 0.24, batch loss = 0.16 (35.0 examples/sec; 0.228 sec/batch; 19h:37m:15s remains)
INFO - root - 2017-12-17 04:14:59.232999: step 23200, loss = 0.24, batch loss = 0.17 (36.7 examples/sec; 0.218 sec/batch; 18h:42m:57s remains)
INFO - root - 2017-12-17 04:15:01.634567: step 23210, loss = 0.17, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 19h:20m:31s remains)
INFO - root - 2017-12-17 04:15:03.875549: step 23220, loss = 0.22, batch loss = 0.15 (36.5 examples/sec; 0.219 sec/batch; 18h:50m:32s remains)
INFO - root - 2017-12-17 04:15:06.155547: step 23230, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:34m:24s remains)
INFO - root - 2017-12-17 04:15:08.430153: step 23240, loss = 0.20, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 19h:43m:53s remains)
INFO - root - 2017-12-17 04:15:10.752708: step 23250, loss = 0.29, batch loss = 0.22 (35.0 examples/sec; 0.228 sec/batch; 19h:37m:13s remains)
INFO - root - 2017-12-17 04:15:12.990803: step 23260, loss = 0.20, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 19h:14m:04s remains)
INFO - root - 2017-12-17 04:15:15.254959: step 23270, loss = 0.20, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 19h:50m:06s remains)
INFO - root - 2017-12-17 04:15:17.497015: step 23280, loss = 0.19, batch loss = 0.11 (36.8 examples/sec; 0.218 sec/batch; 18h:40m:56s remains)
INFO - root - 2017-12-17 04:15:19.769310: step 23290, loss = 0.21, batch loss = 0.13 (32.7 examples/sec; 0.244 sec/batch; 20h:59m:43s remains)
INFO - root - 2017-12-17 04:15:22.030645: step 23300, loss = 0.20, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 18h:58m:50s remains)
INFO - root - 2017-12-17 04:15:24.473999: step 23310, loss = 0.22, batch loss = 0.15 (35.6 examples/sec; 0.225 sec/batch; 19h:19m:32s remains)
INFO - root - 2017-12-17 04:15:26.732402: step 23320, loss = 0.17, batch loss = 0.10 (35.1 examples/sec; 0.228 sec/batch; 19h:33m:11s remains)
INFO - root - 2017-12-17 04:15:28.996869: step 23330, loss = 0.18, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 19h:02m:26s remains)
INFO - root - 2017-12-17 04:15:31.228852: step 23340, loss = 0.24, batch loss = 0.16 (36.4 examples/sec; 0.220 sec/batch; 18h:51m:34s remains)
INFO - root - 2017-12-17 04:15:33.505369: step 23350, loss = 0.20, batch loss = 0.13 (33.9 examples/sec; 0.236 sec/batch; 20h:14m:10s remains)
INFO - root - 2017-12-17 04:15:35.749106: step 23360, loss = 0.26, batch loss = 0.18 (36.5 examples/sec; 0.219 sec/batch; 18h:48m:18s remains)
INFO - root - 2017-12-17 04:15:38.008191: step 23370, loss = 0.18, batch loss = 0.11 (34.3 examples/sec; 0.233 sec/batch; 20h:00m:46s remains)
INFO - root - 2017-12-17 04:15:40.301182: step 23380, loss = 0.18, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 19h:46m:04s remains)
INFO - root - 2017-12-17 04:15:42.584810: step 23390, loss = 0.23, batch loss = 0.16 (34.6 examples/sec; 0.231 sec/batch; 19h:51m:55s remains)
INFO - root - 2017-12-17 04:15:44.841957: step 23400, loss = 0.18, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 19h:34m:02s remains)
INFO - root - 2017-12-17 04:15:47.242680: step 23410, loss = 0.32, batch loss = 0.25 (35.0 examples/sec; 0.229 sec/batch; 19h:37m:13s remains)
INFO - root - 2017-12-17 04:15:49.539953: step 23420, loss = 0.22, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 18h:55m:50s remains)
INFO - root - 2017-12-17 04:15:51.804506: step 23430, loss = 0.20, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:34m:43s remains)
INFO - root - 2017-12-17 04:15:54.060339: step 23440, loss = 0.19, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 19h:18m:48s remains)
INFO - root - 2017-12-17 04:15:56.361466: step 23450, loss = 0.18, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 19h:52m:47s remains)
INFO - root - 2017-12-17 04:15:58.633802: step 23460, loss = 0.20, batch loss = 0.13 (34.4 examples/sec; 0.233 sec/batch; 19h:58m:15s remains)
INFO - root - 2017-12-17 04:16:00.894275: step 23470, loss = 0.21, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 19h:20m:17s remains)
INFO - root - 2017-12-17 04:16:03.157189: step 23480, loss = 0.20, batch loss = 0.12 (36.1 examples/sec; 0.222 sec/batch; 19h:02m:41s remains)
INFO - root - 2017-12-17 04:16:05.445405: step 23490, loss = 0.26, batch loss = 0.18 (34.8 examples/sec; 0.230 sec/batch; 19h:44m:32s remains)
INFO - root - 2017-12-17 04:16:07.748253: step 23500, loss = 0.20, batch loss = 0.13 (33.7 examples/sec; 0.237 sec/batch; 20h:22m:29s remains)
INFO - root - 2017-12-17 04:16:10.130742: step 23510, loss = 0.20, batch loss = 0.12 (35.3 examples/sec; 0.226 sec/batch; 19h:25m:55s remains)
INFO - root - 2017-12-17 04:16:12.407000: step 23520, loss = 0.20, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 18h:56m:56s remains)
INFO - root - 2017-12-17 04:16:14.718570: step 23530, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 19h:12m:11s remains)
INFO - root - 2017-12-17 04:16:16.999188: step 23540, loss = 0.17, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:06m:47s remains)
INFO - root - 2017-12-17 04:16:19.271603: step 23550, loss = 0.16, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 19h:23m:31s remains)
INFO - root - 2017-12-17 04:16:21.566170: step 23560, loss = 0.21, batch loss = 0.14 (35.2 examples/sec; 0.227 sec/batch; 19h:29m:49s remains)
INFO - root - 2017-12-17 04:16:23.841578: step 23570, loss = 0.19, batch loss = 0.12 (33.9 examples/sec; 0.236 sec/batch; 20h:15m:36s remains)
INFO - root - 2017-12-17 04:16:26.128092: step 23580, loss = 0.27, batch loss = 0.20 (35.3 examples/sec; 0.227 sec/batch; 19h:27m:01s remains)
INFO - root - 2017-12-17 04:16:28.381414: step 23590, loss = 0.17, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:07m:46s remains)
INFO - root - 2017-12-17 04:16:30.659111: step 23600, loss = 0.16, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 19h:06m:04s remains)
INFO - root - 2017-12-17 04:16:33.028192: step 23610, loss = 0.21, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 19h:44m:59s remains)
INFO - root - 2017-12-17 04:16:35.295469: step 23620, loss = 0.22, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 19h:16m:27s remains)
INFO - root - 2017-12-17 04:16:37.535808: step 23630, loss = 0.24, batch loss = 0.17 (36.8 examples/sec; 0.218 sec/batch; 18h:40m:29s remains)
INFO - root - 2017-12-17 04:16:39.825610: step 23640, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 19h:36m:01s remains)
INFO - root - 2017-12-17 04:16:42.125422: step 23650, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 19h:16m:14s remains)
INFO - root - 2017-12-17 04:16:44.402070: step 23660, loss = 0.18, batch loss = 0.10 (35.2 examples/sec; 0.228 sec/batch; 19h:31m:12s remains)
INFO - root - 2017-12-17 04:16:46.726228: step 23670, loss = 0.18, batch loss = 0.11 (34.3 examples/sec; 0.233 sec/batch; 19h:59m:01s remains)
INFO - root - 2017-12-17 04:16:49.023940: step 23680, loss = 0.21, batch loss = 0.14 (34.4 examples/sec; 0.233 sec/batch; 19h:58m:17s remains)
INFO - root - 2017-12-17 04:16:51.283713: step 23690, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 19h:03m:30s remains)
INFO - root - 2017-12-17 04:16:53.543698: step 23700, loss = 0.21, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 19h:15m:32s remains)
INFO - root - 2017-12-17 04:16:55.935509: step 23710, loss = 0.19, batch loss = 0.12 (34.5 examples/sec; 0.232 sec/batch; 19h:54m:32s remains)
INFO - root - 2017-12-17 04:16:58.170970: step 23720, loss = 0.18, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 19h:13m:08s remains)
INFO - root - 2017-12-17 04:17:00.442766: step 23730, loss = 0.20, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 19h:04m:10s remains)
INFO - root - 2017-12-17 04:17:02.660619: step 23740, loss = 0.16, batch loss = 0.09 (36.1 examples/sec; 0.222 sec/batch; 19h:00m:24s remains)
INFO - root - 2017-12-17 04:17:04.929184: step 23750, loss = 0.22, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 19h:06m:31s remains)
INFO - root - 2017-12-17 04:17:07.196600: step 23760, loss = 0.18, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 19h:10m:39s remains)
INFO - root - 2017-12-17 04:17:09.424902: step 23770, loss = 0.22, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 19h:42m:48s remains)
INFO - root - 2017-12-17 04:17:11.690444: step 23780, loss = 0.18, batch loss = 0.11 (34.3 examples/sec; 0.233 sec/batch; 19h:59m:29s remains)
INFO - root - 2017-12-17 04:17:13.963331: step 23790, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 19h:25m:28s remains)
INFO - root - 2017-12-17 04:17:16.234944: step 23800, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:22m:30s remains)
INFO - root - 2017-12-17 04:17:18.686724: step 23810, loss = 0.20, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 19h:41m:22s remains)
INFO - root - 2017-12-17 04:17:20.970530: step 23820, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 19h:12m:25s remains)
INFO - root - 2017-12-17 04:17:23.250623: step 23830, loss = 0.25, batch loss = 0.18 (36.6 examples/sec; 0.218 sec/batch; 18h:43m:13s remains)
INFO - root - 2017-12-17 04:17:25.530436: step 23840, loss = 0.28, batch loss = 0.20 (36.0 examples/sec; 0.222 sec/batch; 19h:03m:41s remains)
INFO - root - 2017-12-17 04:17:27.820465: step 23850, loss = 0.23, batch loss = 0.15 (33.3 examples/sec; 0.240 sec/batch; 20h:35m:55s remains)
INFO - root - 2017-12-17 04:17:30.063370: step 23860, loss = 0.21, batch loss = 0.14 (36.8 examples/sec; 0.218 sec/batch; 18h:39m:19s remains)
INFO - root - 2017-12-17 04:17:32.313840: step 23870, loss = 0.19, batch loss = 0.11 (35.0 examples/sec; 0.229 sec/batch; 19h:36m:59s remains)
INFO - root - 2017-12-17 04:17:34.585008: step 23880, loss = 0.21, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 18h:51m:22s remains)
INFO - root - 2017-12-17 04:17:36.867963: step 23890, loss = 0.21, batch loss = 0.14 (34.9 examples/sec; 0.230 sec/batch; 19h:40m:33s remains)
INFO - root - 2017-12-17 04:17:39.161126: step 23900, loss = 0.21, batch loss = 0.14 (34.3 examples/sec; 0.233 sec/batch; 19h:58m:24s remains)
INFO - root - 2017-12-17 04:17:41.555263: step 23910, loss = 0.18, batch loss = 0.11 (35.8 examples/sec; 0.223 sec/batch; 19h:08m:12s remains)
INFO - root - 2017-12-17 04:17:43.806855: step 23920, loss = 0.23, batch loss = 0.16 (35.1 examples/sec; 0.228 sec/batch; 19h:31m:15s remains)
INFO - root - 2017-12-17 04:17:46.064228: step 23930, loss = 0.20, batch loss = 0.12 (33.8 examples/sec; 0.237 sec/batch; 20h:16m:45s remains)
INFO - root - 2017-12-17 04:17:48.341623: step 23940, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 19h:37m:49s remains)
INFO - root - 2017-12-17 04:17:50.634360: step 23950, loss = 0.16, batch loss = 0.08 (35.8 examples/sec; 0.223 sec/batch; 19h:08m:39s remains)
INFO - root - 2017-12-17 04:17:52.894313: step 23960, loss = 0.21, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 19h:17m:10s remains)
INFO - root - 2017-12-17 04:17:55.179700: step 23970, loss = 0.17, batch loss = 0.10 (34.5 examples/sec; 0.232 sec/batch; 19h:51m:08s remains)
INFO - root - 2017-12-17 04:17:57.441264: step 23980, loss = 0.21, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 19h:17m:32s remains)
INFO - root - 2017-12-17 04:17:59.694976: step 23990, loss = 0.18, batch loss = 0.11 (36.3 examples/sec; 0.221 sec/batch; 18h:54m:29s remains)
INFO - root - 2017-12-17 04:18:01.934648: step 24000, loss = 0.23, batch loss = 0.15 (34.4 examples/sec; 0.233 sec/batch; 19h:57m:10s remains)
INFO - root - 2017-12-17 04:18:04.330828: step 24010, loss = 0.23, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 19h:22m:12s remains)
INFO - root - 2017-12-17 04:18:06.621706: step 24020, loss = 0.23, batch loss = 0.16 (35.6 examples/sec; 0.225 sec/batch; 19h:16m:21s remains)
INFO - root - 2017-12-17 04:18:08.907204: step 24030, loss = 0.16, batch loss = 0.08 (34.6 examples/sec; 0.231 sec/batch; 19h:48m:46s remains)
INFO - root - 2017-12-17 04:18:11.172099: step 24040, loss = 0.16, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 18h:45m:14s remains)
INFO - root - 2017-12-17 04:18:13.420904: step 24050, loss = 0.28, batch loss = 0.21 (34.7 examples/sec; 0.231 sec/batch; 19h:45m:56s remains)
INFO - root - 2017-12-17 04:18:15.688242: step 24060, loss = 0.22, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 19h:48m:58s remains)
INFO - root - 2017-12-17 04:18:17.978207: step 24070, loss = 0.19, batch loss = 0.11 (36.3 examples/sec; 0.221 sec/batch; 18h:54m:15s remains)
INFO - root - 2017-12-17 04:18:20.228757: step 24080, loss = 0.20, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 18h:59m:16s remains)
INFO - root - 2017-12-17 04:18:22.499691: step 24090, loss = 0.18, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 19h:49m:14s remains)
INFO - root - 2017-12-17 04:18:24.750818: step 24100, loss = 0.21, batch loss = 0.14 (34.4 examples/sec; 0.233 sec/batch; 19h:55m:16s remains)
INFO - root - 2017-12-17 04:18:27.108374: step 24110, loss = 0.21, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 19h:01m:11s remains)
INFO - root - 2017-12-17 04:18:29.367411: step 24120, loss = 0.17, batch loss = 0.10 (35.0 examples/sec; 0.229 sec/batch; 19h:34m:31s remains)
INFO - root - 2017-12-17 04:18:31.678211: step 24130, loss = 0.19, batch loss = 0.12 (34.7 examples/sec; 0.230 sec/batch; 19h:43m:46s remains)
INFO - root - 2017-12-17 04:18:33.920572: step 24140, loss = 0.22, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 19h:03m:13s remains)
INFO - root - 2017-12-17 04:18:36.186457: step 24150, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 19h:20m:02s remains)
INFO - root - 2017-12-17 04:18:38.423832: step 24160, loss = 0.24, batch loss = 0.17 (35.6 examples/sec; 0.225 sec/batch; 19h:14m:51s remains)
INFO - root - 2017-12-17 04:18:40.664466: step 24170, loss = 0.22, batch loss = 0.14 (35.3 examples/sec; 0.226 sec/batch; 19h:23m:49s remains)
INFO - root - 2017-12-17 04:18:42.898959: step 24180, loss = 0.17, batch loss = 0.09 (36.9 examples/sec; 0.217 sec/batch; 18h:32m:40s remains)
INFO - root - 2017-12-17 04:18:45.176140: step 24190, loss = 0.23, batch loss = 0.16 (35.2 examples/sec; 0.227 sec/batch; 19h:26m:49s remains)
INFO - root - 2017-12-17 04:18:47.423357: step 24200, loss = 0.16, batch loss = 0.08 (35.0 examples/sec; 0.228 sec/batch; 19h:33m:15s remains)
INFO - root - 2017-12-17 04:18:49.840106: step 24210, loss = 0.20, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 19h:16m:01s remains)
INFO - root - 2017-12-17 04:18:52.083315: step 24220, loss = 0.19, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 19h:42m:40s remains)
INFO - root - 2017-12-17 04:18:54.364480: step 24230, loss = 0.20, batch loss = 0.13 (36.1 examples/sec; 0.221 sec/batch; 18h:57m:15s remains)
INFO - root - 2017-12-17 04:18:56.624224: step 24240, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 19h:04m:59s remains)
INFO - root - 2017-12-17 04:18:58.894436: step 24250, loss = 0.19, batch loss = 0.12 (33.9 examples/sec; 0.236 sec/batch; 20h:11m:37s remains)
INFO - root - 2017-12-17 04:19:01.132067: step 24260, loss = 0.20, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 19h:10m:06s remains)
INFO - root - 2017-12-17 04:19:03.381684: step 24270, loss = 0.17, batch loss = 0.09 (35.1 examples/sec; 0.228 sec/batch; 19h:32m:18s remains)
INFO - root - 2017-12-17 04:19:05.621809: step 24280, loss = 0.19, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 18h:49m:19s remains)
INFO - root - 2017-12-17 04:19:07.938158: step 24290, loss = 0.18, batch loss = 0.11 (33.9 examples/sec; 0.236 sec/batch; 20h:13m:23s remains)
INFO - root - 2017-12-17 04:19:10.210965: step 24300, loss = 0.23, batch loss = 0.16 (32.9 examples/sec; 0.243 sec/batch; 20h:48m:45s remains)
INFO - root - 2017-12-17 04:19:12.631663: step 24310, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:19m:27s remains)
INFO - root - 2017-12-17 04:19:14.904498: step 24320, loss = 0.20, batch loss = 0.13 (33.9 examples/sec; 0.236 sec/batch; 20h:12m:22s remains)
INFO - root - 2017-12-17 04:19:17.157246: step 24330, loss = 0.20, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 18h:56m:00s remains)
INFO - root - 2017-12-17 04:19:19.427789: step 24340, loss = 0.25, batch loss = 0.17 (35.5 examples/sec; 0.225 sec/batch; 19h:17m:42s remains)
INFO - root - 2017-12-17 04:19:21.662115: step 24350, loss = 0.17, batch loss = 0.10 (35.0 examples/sec; 0.228 sec/batch; 19h:33m:24s remains)
INFO - root - 2017-12-17 04:19:23.912281: step 24360, loss = 0.16, batch loss = 0.09 (36.1 examples/sec; 0.222 sec/batch; 18h:57m:39s remains)
INFO - root - 2017-12-17 04:19:26.205406: step 24370, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 19h:23m:13s remains)
INFO - root - 2017-12-17 04:19:28.474464: step 24380, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:21m:16s remains)
INFO - root - 2017-12-17 04:19:30.719679: step 24390, loss = 0.25, batch loss = 0.17 (35.2 examples/sec; 0.227 sec/batch; 19h:25m:29s remains)
INFO - root - 2017-12-17 04:19:32.994937: step 24400, loss = 0.18, batch loss = 0.10 (34.1 examples/sec; 0.235 sec/batch; 20h:06m:27s remains)
INFO - root - 2017-12-17 04:19:35.368389: step 24410, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 19h:08m:31s remains)
INFO - root - 2017-12-17 04:19:37.663978: step 24420, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:59m:47s remains)
INFO - root - 2017-12-17 04:19:39.910557: step 24430, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 19h:16m:34s remains)
INFO - root - 2017-12-17 04:19:42.188129: step 24440, loss = 0.17, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 18h:51m:49s remains)
INFO - root - 2017-12-17 04:19:44.431222: step 24450, loss = 0.18, batch loss = 0.10 (35.1 examples/sec; 0.228 sec/batch; 19h:31m:38s remains)
INFO - root - 2017-12-17 04:19:46.697945: step 24460, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:29m:56s remains)
INFO - root - 2017-12-17 04:19:48.936351: step 24470, loss = 0.20, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 18h:46m:37s remains)
INFO - root - 2017-12-17 04:19:51.188999: step 24480, loss = 0.18, batch loss = 0.10 (35.8 examples/sec; 0.223 sec/batch; 19h:06m:43s remains)
INFO - root - 2017-12-17 04:19:53.475492: step 24490, loss = 0.20, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 19h:40m:11s remains)
INFO - root - 2017-12-17 04:19:55.700143: step 24500, loss = 0.17, batch loss = 0.10 (35.3 examples/sec; 0.226 sec/batch; 19h:22m:39s remains)
INFO - root - 2017-12-17 04:19:58.105500: step 24510, loss = 0.21, batch loss = 0.13 (33.7 examples/sec; 0.238 sec/batch; 20h:19m:40s remains)
INFO - root - 2017-12-17 04:20:00.385129: step 24520, loss = 0.24, batch loss = 0.17 (35.1 examples/sec; 0.228 sec/batch; 19h:31m:13s remains)
INFO - root - 2017-12-17 04:20:02.630974: step 24530, loss = 0.25, batch loss = 0.18 (36.4 examples/sec; 0.220 sec/batch; 18h:49m:34s remains)
INFO - root - 2017-12-17 04:20:04.908486: step 24540, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 19h:15m:08s remains)
INFO - root - 2017-12-17 04:20:07.159611: step 24550, loss = 0.24, batch loss = 0.17 (35.6 examples/sec; 0.225 sec/batch; 19h:12m:54s remains)
INFO - root - 2017-12-17 04:20:09.448449: step 24560, loss = 0.18, batch loss = 0.10 (35.5 examples/sec; 0.226 sec/batch; 19h:17m:58s remains)
INFO - root - 2017-12-17 04:20:11.714142: step 24570, loss = 0.21, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 19h:03m:03s remains)
INFO - root - 2017-12-17 04:20:13.976920: step 24580, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 19h:08m:24s remains)
INFO - root - 2017-12-17 04:20:16.196114: step 24590, loss = 0.20, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:30m:29s remains)
INFO - root - 2017-12-17 04:20:18.472854: step 24600, loss = 0.21, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 19h:14m:03s remains)
INFO - root - 2017-12-17 04:20:20.877480: step 24610, loss = 0.23, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 19h:26m:11s remains)
INFO - root - 2017-12-17 04:20:23.146452: step 24620, loss = 0.17, batch loss = 0.10 (36.7 examples/sec; 0.218 sec/batch; 18h:40m:04s remains)
INFO - root - 2017-12-17 04:20:25.427628: step 24630, loss = 0.23, batch loss = 0.16 (36.1 examples/sec; 0.222 sec/batch; 18h:56m:35s remains)
INFO - root - 2017-12-17 04:20:27.713180: step 24640, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.223 sec/batch; 19h:06m:35s remains)
INFO - root - 2017-12-17 04:20:29.999659: step 24650, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 19h:00m:26s remains)
INFO - root - 2017-12-17 04:20:32.256550: step 24660, loss = 0.18, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 19h:46m:28s remains)
INFO - root - 2017-12-17 04:20:34.541342: step 24670, loss = 0.17, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:03m:54s remains)
INFO - root - 2017-12-17 04:20:36.838904: step 24680, loss = 0.20, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 19h:57m:12s remains)
INFO - root - 2017-12-17 04:20:39.128828: step 24690, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 19h:01m:17s remains)
INFO - root - 2017-12-17 04:20:41.423990: step 24700, loss = 0.20, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 18h:48m:56s remains)
INFO - root - 2017-12-17 04:20:43.846494: step 24710, loss = 0.21, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 18h:49m:11s remains)
INFO - root - 2017-12-17 04:20:46.110705: step 24720, loss = 0.22, batch loss = 0.15 (34.3 examples/sec; 0.234 sec/batch; 19h:58m:08s remains)
INFO - root - 2017-12-17 04:20:48.340323: step 24730, loss = 0.21, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 19h:35m:49s remains)
INFO - root - 2017-12-17 04:20:50.635712: step 24740, loss = 0.21, batch loss = 0.14 (36.1 examples/sec; 0.222 sec/batch; 18h:58m:05s remains)
INFO - root - 2017-12-17 04:20:52.903531: step 24750, loss = 0.20, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 19h:10m:54s remains)
INFO - root - 2017-12-17 04:20:55.149657: step 24760, loss = 0.17, batch loss = 0.09 (36.7 examples/sec; 0.218 sec/batch; 18h:38m:29s remains)
INFO - root - 2017-12-17 04:20:57.434773: step 24770, loss = 0.23, batch loss = 0.16 (35.1 examples/sec; 0.228 sec/batch; 19h:27m:57s remains)
INFO - root - 2017-12-17 04:20:59.681750: step 24780, loss = 0.20, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 18h:47m:53s remains)
INFO - root - 2017-12-17 04:21:02.015481: step 24790, loss = 0.24, batch loss = 0.17 (33.9 examples/sec; 0.236 sec/batch; 20h:11m:53s remains)
INFO - root - 2017-12-17 04:21:04.289310: step 24800, loss = 0.20, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 19h:16m:09s remains)
INFO - root - 2017-12-17 04:21:06.692953: step 24810, loss = 0.18, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 19h:48m:38s remains)
INFO - root - 2017-12-17 04:21:08.976828: step 24820, loss = 0.19, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 19h:14m:56s remains)
INFO - root - 2017-12-17 04:21:11.261010: step 24830, loss = 0.17, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 19h:19m:42s remains)
INFO - root - 2017-12-17 04:21:13.486843: step 24840, loss = 0.19, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 19h:22m:44s remains)
INFO - root - 2017-12-17 04:21:15.707807: step 24850, loss = 0.21, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 19h:03m:41s remains)
INFO - root - 2017-12-17 04:21:17.983386: step 24860, loss = 0.18, batch loss = 0.11 (35.8 examples/sec; 0.223 sec/batch; 19h:05m:13s remains)
INFO - root - 2017-12-17 04:21:20.244060: step 24870, loss = 0.24, batch loss = 0.17 (36.0 examples/sec; 0.222 sec/batch; 18h:59m:28s remains)
INFO - root - 2017-12-17 04:21:22.529525: step 24880, loss = 0.19, batch loss = 0.12 (33.1 examples/sec; 0.242 sec/batch; 20h:40m:45s remains)
INFO - root - 2017-12-17 04:21:24.765142: step 24890, loss = 0.21, batch loss = 0.13 (37.4 examples/sec; 0.214 sec/batch; 18h:16m:56s remains)
INFO - root - 2017-12-17 04:21:27.030641: step 24900, loss = 0.23, batch loss = 0.16 (34.9 examples/sec; 0.229 sec/batch; 19h:33m:45s remains)
INFO - root - 2017-12-17 04:21:29.464874: step 24910, loss = 0.22, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 19h:10m:15s remains)
INFO - root - 2017-12-17 04:21:31.718530: step 24920, loss = 0.25, batch loss = 0.18 (34.4 examples/sec; 0.233 sec/batch; 19h:53m:03s remains)
INFO - root - 2017-12-17 04:21:34.006650: step 24930, loss = 0.22, batch loss = 0.15 (35.8 examples/sec; 0.224 sec/batch; 19h:06m:16s remains)
INFO - root - 2017-12-17 04:21:36.259139: step 24940, loss = 0.20, batch loss = 0.13 (35.0 examples/sec; 0.228 sec/batch; 19h:31m:14s remains)
INFO - root - 2017-12-17 04:21:38.539672: step 24950, loss = 0.16, batch loss = 0.09 (34.2 examples/sec; 0.234 sec/batch; 19h:58m:15s remains)
INFO - root - 2017-12-17 04:21:40.853883: step 24960, loss = 0.20, batch loss = 0.12 (34.0 examples/sec; 0.235 sec/batch; 20h:06m:54s remains)
INFO - root - 2017-12-17 04:21:43.154194: step 24970, loss = 0.16, batch loss = 0.09 (33.8 examples/sec; 0.237 sec/batch; 20h:13m:20s remains)
INFO - root - 2017-12-17 04:21:45.470027: step 24980, loss = 0.21, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 18h:58m:39s remains)
INFO - root - 2017-12-17 04:21:47.711248: step 24990, loss = 0.23, batch loss = 0.16 (35.1 examples/sec; 0.228 sec/batch; 19h:26m:36s remains)
INFO - root - 2017-12-17 04:21:50.014231: step 25000, loss = 0.22, batch loss = 0.14 (35.2 examples/sec; 0.227 sec/batch; 19h:24m:46s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-25000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-25000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 04:21:52.938831: step 25010, loss = 0.18, batch loss = 0.11 (34.7 examples/sec; 0.230 sec/batch; 19h:39m:52s remains)
INFO - root - 2017-12-17 04:21:55.186026: step 25020, loss = 0.17, batch loss = 0.10 (35.0 examples/sec; 0.228 sec/batch; 19h:29m:49s remains)
INFO - root - 2017-12-17 04:21:57.421144: step 25030, loss = 0.20, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 19h:12m:11s remains)
INFO - root - 2017-12-17 04:21:59.676414: step 25040, loss = 0.24, batch loss = 0.16 (35.3 examples/sec; 0.226 sec/batch; 19h:20m:18s remains)
INFO - root - 2017-12-17 04:22:01.927392: step 25050, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 19h:16m:43s remains)
INFO - root - 2017-12-17 04:22:04.197357: step 25060, loss = 0.23, batch loss = 0.15 (34.7 examples/sec; 0.231 sec/batch; 19h:42m:06s remains)
INFO - root - 2017-12-17 04:22:06.470339: step 25070, loss = 0.23, batch loss = 0.16 (36.0 examples/sec; 0.222 sec/batch; 18h:58m:30s remains)
INFO - root - 2017-12-17 04:22:08.727482: step 25080, loss = 0.18, batch loss = 0.11 (35.2 examples/sec; 0.227 sec/batch; 19h:23m:21s remains)
INFO - root - 2017-12-17 04:22:11.006372: step 25090, loss = 0.23, batch loss = 0.16 (33.1 examples/sec; 0.241 sec/batch; 20h:36m:28s remains)
INFO - root - 2017-12-17 04:22:13.329863: step 25100, loss = 0.18, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:03m:10s remains)
INFO - root - 2017-12-17 04:22:15.734575: step 25110, loss = 0.20, batch loss = 0.13 (35.6 examples/sec; 0.224 sec/batch; 19h:09m:59s remains)
INFO - root - 2017-12-17 04:22:17.987610: step 25120, loss = 0.21, batch loss = 0.14 (35.8 examples/sec; 0.224 sec/batch; 19h:05m:39s remains)
INFO - root - 2017-12-17 04:22:20.246919: step 25130, loss = 0.18, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 18h:57m:42s remains)
INFO - root - 2017-12-17 04:22:22.519805: step 25140, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 19h:23m:36s remains)
INFO - root - 2017-12-17 04:22:24.802717: step 25150, loss = 0.17, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 19h:02m:40s remains)
INFO - root - 2017-12-17 04:22:27.041376: step 25160, loss = 0.27, batch loss = 0.20 (35.5 examples/sec; 0.225 sec/batch; 19h:13m:53s remains)
INFO - root - 2017-12-17 04:22:29.329388: step 25170, loss = 0.21, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 19h:24m:43s remains)
INFO - root - 2017-12-17 04:22:31.562775: step 25180, loss = 0.19, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 19h:10m:14s remains)
INFO - root - 2017-12-17 04:22:33.838846: step 25190, loss = 0.15, batch loss = 0.08 (35.6 examples/sec; 0.224 sec/batch; 19h:09m:37s remains)
INFO - root - 2017-12-17 04:22:36.069765: step 25200, loss = 0.18, batch loss = 0.10 (34.6 examples/sec; 0.231 sec/batch; 19h:43m:08s remains)
INFO - root - 2017-12-17 04:22:38.464340: step 25210, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 19h:33m:46s remains)
INFO - root - 2017-12-17 04:22:40.744047: step 25220, loss = 0.21, batch loss = 0.13 (36.5 examples/sec; 0.219 sec/batch; 18h:41m:01s remains)
INFO - root - 2017-12-17 04:22:43.000409: step 25230, loss = 0.24, batch loss = 0.16 (34.4 examples/sec; 0.233 sec/batch; 19h:51m:36s remains)
INFO - root - 2017-12-17 04:22:45.294323: step 25240, loss = 0.20, batch loss = 0.13 (34.2 examples/sec; 0.234 sec/batch; 19h:57m:26s remains)
INFO - root - 2017-12-17 04:22:47.581438: step 25250, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 19h:21m:51s remains)
INFO - root - 2017-12-17 04:22:49.875298: step 25260, loss = 0.18, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 18h:59m:16s remains)
INFO - root - 2017-12-17 04:22:52.119553: step 25270, loss = 0.21, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 19h:37m:09s remains)
INFO - root - 2017-12-17 04:22:54.413815: step 25280, loss = 0.20, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 19h:36m:24s remains)
INFO - root - 2017-12-17 04:22:56.682090: step 25290, loss = 0.21, batch loss = 0.14 (34.4 examples/sec; 0.233 sec/batch; 19h:50m:40s remains)
INFO - root - 2017-12-17 04:22:58.924023: step 25300, loss = 0.21, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 19h:27m:43s remains)
INFO - root - 2017-12-17 04:23:01.302822: step 25310, loss = 0.21, batch loss = 0.14 (34.7 examples/sec; 0.231 sec/batch; 19h:40m:57s remains)
INFO - root - 2017-12-17 04:23:03.577172: step 25320, loss = 0.21, batch loss = 0.13 (34.1 examples/sec; 0.234 sec/batch; 20h:00m:22s remains)
INFO - root - 2017-12-17 04:23:05.852808: step 25330, loss = 0.23, batch loss = 0.15 (35.0 examples/sec; 0.229 sec/batch; 19h:31m:40s remains)
INFO - root - 2017-12-17 04:23:08.153664: step 25340, loss = 0.20, batch loss = 0.12 (35.0 examples/sec; 0.229 sec/batch; 19h:31m:47s remains)
INFO - root - 2017-12-17 04:23:10.456495: step 25350, loss = 0.21, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 19h:10m:42s remains)
INFO - root - 2017-12-17 04:23:12.694604: step 25360, loss = 0.19, batch loss = 0.12 (36.3 examples/sec; 0.221 sec/batch; 18h:49m:22s remains)
INFO - root - 2017-12-17 04:23:14.919863: step 25370, loss = 0.20, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 19h:34m:15s remains)
INFO - root - 2017-12-17 04:23:17.230327: step 25380, loss = 0.19, batch loss = 0.12 (33.3 examples/sec; 0.240 sec/batch; 20h:29m:25s remains)
INFO - root - 2017-12-17 04:23:19.509603: step 25390, loss = 0.22, batch loss = 0.14 (33.3 examples/sec; 0.240 sec/batch; 20h:28m:55s remains)
INFO - root - 2017-12-17 04:23:21.791985: step 25400, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 19h:15m:05s remains)
INFO - root - 2017-12-17 04:23:24.236492: step 25410, loss = 0.25, batch loss = 0.18 (36.0 examples/sec; 0.222 sec/batch; 18h:58m:10s remains)
INFO - root - 2017-12-17 04:23:26.548439: step 25420, loss = 0.22, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 19h:07m:18s remains)
INFO - root - 2017-12-17 04:23:28.791790: step 25430, loss = 0.25, batch loss = 0.18 (36.1 examples/sec; 0.222 sec/batch; 18h:54m:34s remains)
INFO - root - 2017-12-17 04:23:31.059439: step 25440, loss = 0.25, batch loss = 0.17 (36.0 examples/sec; 0.222 sec/batch; 18h:56m:18s remains)
INFO - root - 2017-12-17 04:23:33.300565: step 25450, loss = 0.21, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 18h:42m:11s remains)
INFO - root - 2017-12-17 04:23:35.580005: step 25460, loss = 0.18, batch loss = 0.11 (34.1 examples/sec; 0.235 sec/batch; 20h:00m:33s remains)
INFO - root - 2017-12-17 04:23:37.860812: step 25470, loss = 0.22, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 19h:25m:31s remains)
INFO - root - 2017-12-17 04:23:40.133079: step 25480, loss = 0.21, batch loss = 0.13 (35.3 examples/sec; 0.226 sec/batch; 19h:18m:46s remains)
INFO - root - 2017-12-17 04:23:42.389796: step 25490, loss = 0.20, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 19h:05m:46s remains)
INFO - root - 2017-12-17 04:23:44.671698: step 25500, loss = 0.24, batch loss = 0.17 (36.0 examples/sec; 0.222 sec/batch; 18h:55m:54s remains)
INFO - root - 2017-12-17 04:23:47.100569: step 25510, loss = 0.18, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 18h:54m:38s remains)
INFO - root - 2017-12-17 04:23:49.390676: step 25520, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 19h:33m:41s remains)
INFO - root - 2017-12-17 04:23:51.646952: step 25530, loss = 0.20, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 19h:12m:22s remains)
INFO - root - 2017-12-17 04:23:53.910743: step 25540, loss = 0.23, batch loss = 0.16 (35.5 examples/sec; 0.225 sec/batch; 19h:12m:11s remains)
INFO - root - 2017-12-17 04:23:56.138936: step 25550, loss = 0.22, batch loss = 0.15 (34.7 examples/sec; 0.231 sec/batch; 19h:41m:03s remains)
INFO - root - 2017-12-17 04:23:58.446004: step 25560, loss = 0.25, batch loss = 0.18 (34.6 examples/sec; 0.231 sec/batch; 19h:41m:53s remains)
INFO - root - 2017-12-17 04:24:00.752642: step 25570, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:25m:38s remains)
INFO - root - 2017-12-17 04:24:03.047336: step 25580, loss = 0.20, batch loss = 0.12 (33.7 examples/sec; 0.237 sec/batch; 20h:12m:50s remains)
INFO - root - 2017-12-17 04:24:05.299174: step 25590, loss = 0.25, batch loss = 0.18 (36.3 examples/sec; 0.221 sec/batch; 18h:48m:28s remains)
INFO - root - 2017-12-17 04:24:07.558989: step 25600, loss = 0.21, batch loss = 0.13 (34.2 examples/sec; 0.234 sec/batch; 19h:55m:40s remains)
INFO - root - 2017-12-17 04:24:09.978402: step 25610, loss = 0.19, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 19h:33m:26s remains)
INFO - root - 2017-12-17 04:24:12.205740: step 25620, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 19h:05m:00s remains)
INFO - root - 2017-12-17 04:24:14.494637: step 25630, loss = 0.17, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 18h:38m:45s remains)
INFO - root - 2017-12-17 04:24:16.773748: step 25640, loss = 0.23, batch loss = 0.16 (34.6 examples/sec; 0.232 sec/batch; 19h:44m:07s remains)
INFO - root - 2017-12-17 04:24:19.063113: step 25650, loss = 0.24, batch loss = 0.16 (35.8 examples/sec; 0.223 sec/batch; 19h:01m:17s remains)
INFO - root - 2017-12-17 04:24:21.337718: step 25660, loss = 0.20, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 19h:06m:39s remains)
INFO - root - 2017-12-17 04:24:23.629046: step 25670, loss = 0.22, batch loss = 0.15 (32.6 examples/sec; 0.245 sec/batch; 20h:53m:31s remains)
INFO - root - 2017-12-17 04:24:25.881374: step 25680, loss = 0.21, batch loss = 0.14 (35.2 examples/sec; 0.228 sec/batch; 19h:23m:34s remains)
INFO - root - 2017-12-17 04:24:28.141038: step 25690, loss = 0.22, batch loss = 0.14 (35.5 examples/sec; 0.225 sec/batch; 19h:12m:36s remains)
INFO - root - 2017-12-17 04:24:30.413082: step 25700, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 19h:09m:46s remains)
INFO - root - 2017-12-17 04:24:32.813128: step 25710, loss = 0.18, batch loss = 0.10 (34.5 examples/sec; 0.232 sec/batch; 19h:45m:27s remains)
INFO - root - 2017-12-17 04:24:35.055647: step 25720, loss = 0.16, batch loss = 0.09 (36.3 examples/sec; 0.220 sec/batch; 18h:46m:05s remains)
INFO - root - 2017-12-17 04:24:37.321742: step 25730, loss = 0.20, batch loss = 0.12 (33.6 examples/sec; 0.238 sec/batch; 20h:18m:18s remains)
INFO - root - 2017-12-17 04:24:39.555820: step 25740, loss = 0.27, batch loss = 0.20 (36.0 examples/sec; 0.222 sec/batch; 18h:57m:07s remains)
INFO - root - 2017-12-17 04:24:41.788848: step 25750, loss = 0.20, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 19h:45m:25s remains)
INFO - root - 2017-12-17 04:24:44.036635: step 25760, loss = 0.18, batch loss = 0.11 (36.6 examples/sec; 0.219 sec/batch; 18h:38m:14s remains)
INFO - root - 2017-12-17 04:24:46.294053: step 25770, loss = 0.19, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 19h:11m:12s remains)
INFO - root - 2017-12-17 04:24:48.578569: step 25780, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:14m:25s remains)
INFO - root - 2017-12-17 04:24:50.815892: step 25790, loss = 0.21, batch loss = 0.14 (34.7 examples/sec; 0.231 sec/batch; 19h:38m:50s remains)
INFO - root - 2017-12-17 04:24:53.091944: step 25800, loss = 0.23, batch loss = 0.15 (35.6 examples/sec; 0.225 sec/batch; 19h:08m:54s remains)
INFO - root - 2017-12-17 04:24:55.469561: step 25810, loss = 0.17, batch loss = 0.10 (35.1 examples/sec; 0.228 sec/batch; 19h:25m:47s remains)
INFO - root - 2017-12-17 04:24:57.775934: step 25820, loss = 0.19, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 19h:32m:51s remains)
INFO - root - 2017-12-17 04:25:00.020389: step 25830, loss = 0.17, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 19h:04m:47s remains)
INFO - root - 2017-12-17 04:25:02.299869: step 25840, loss = 0.24, batch loss = 0.16 (32.8 examples/sec; 0.244 sec/batch; 20h:45m:42s remains)
INFO - root - 2017-12-17 04:25:04.616300: step 25850, loss = 0.17, batch loss = 0.10 (34.0 examples/sec; 0.235 sec/batch; 20h:01m:09s remains)
INFO - root - 2017-12-17 04:25:06.890183: step 25860, loss = 0.22, batch loss = 0.14 (32.7 examples/sec; 0.244 sec/batch; 20h:48m:45s remains)
INFO - root - 2017-12-17 04:25:09.224883: step 25870, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.223 sec/batch; 19h:01m:32s remains)
INFO - root - 2017-12-17 04:25:11.512254: step 25880, loss = 0.22, batch loss = 0.15 (35.0 examples/sec; 0.228 sec/batch; 19h:27m:30s remains)
INFO - root - 2017-12-17 04:25:13.813692: step 25890, loss = 0.17, batch loss = 0.09 (35.0 examples/sec; 0.229 sec/batch; 19h:27m:51s remains)
INFO - root - 2017-12-17 04:25:16.063660: step 25900, loss = 0.22, batch loss = 0.14 (35.2 examples/sec; 0.227 sec/batch; 19h:19m:46s remains)
INFO - root - 2017-12-17 04:25:18.473006: step 25910, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 18h:58m:56s remains)
INFO - root - 2017-12-17 04:25:20.731966: step 25920, loss = 0.20, batch loss = 0.13 (36.5 examples/sec; 0.219 sec/batch; 18h:38m:44s remains)
INFO - root - 2017-12-17 04:25:22.998184: step 25930, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:15m:35s remains)
INFO - root - 2017-12-17 04:25:25.241282: step 25940, loss = 0.22, batch loss = 0.15 (36.1 examples/sec; 0.222 sec/batch; 18h:52m:43s remains)
INFO - root - 2017-12-17 04:25:27.542546: step 25950, loss = 0.23, batch loss = 0.16 (34.9 examples/sec; 0.229 sec/batch; 19h:32m:19s remains)
INFO - root - 2017-12-17 04:25:29.805834: step 25960, loss = 0.17, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 18h:36m:23s remains)
INFO - root - 2017-12-17 04:25:32.080785: step 25970, loss = 0.23, batch loss = 0.16 (34.4 examples/sec; 0.232 sec/batch; 19h:46m:50s remains)
INFO - root - 2017-12-17 04:25:34.369999: step 25980, loss = 0.19, batch loss = 0.12 (33.2 examples/sec; 0.241 sec/batch; 20h:29m:29s remains)
INFO - root - 2017-12-17 04:25:36.645167: step 25990, loss = 0.19, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 19h:22m:05s remains)
INFO - root - 2017-12-17 04:25:38.922118: step 26000, loss = 0.22, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 19h:14m:48s remains)
INFO - root - 2017-12-17 04:25:41.314838: step 26010, loss = 0.22, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 19h:23m:10s remains)
INFO - root - 2017-12-17 04:25:43.584063: step 26020, loss = 0.20, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 19h:39m:50s remains)
INFO - root - 2017-12-17 04:25:45.882597: step 26030, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 19h:04m:30s remains)
INFO - root - 2017-12-17 04:25:48.143429: step 26040, loss = 0.19, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 19h:19m:51s remains)
INFO - root - 2017-12-17 04:25:50.442063: step 26050, loss = 0.17, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 19h:09m:06s remains)
INFO - root - 2017-12-17 04:25:52.693472: step 26060, loss = 0.19, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 19h:29m:43s remains)
INFO - root - 2017-12-17 04:25:54.991414: step 26070, loss = 0.19, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 19h:35m:42s remains)
INFO - root - 2017-12-17 04:25:57.242844: step 26080, loss = 0.18, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 18h:42m:03s remains)
INFO - root - 2017-12-17 04:25:59.487497: step 26090, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 19h:31m:32s remains)
INFO - root - 2017-12-17 04:26:01.734362: step 26100, loss = 0.18, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 19h:20m:42s remains)
INFO - root - 2017-12-17 04:26:04.152965: step 26110, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 19h:03m:25s remains)
INFO - root - 2017-12-17 04:26:06.431837: step 26120, loss = 0.19, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 19h:20m:20s remains)
INFO - root - 2017-12-17 04:26:08.704562: step 26130, loss = 0.19, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 19h:22m:50s remains)
INFO - root - 2017-12-17 04:26:10.971896: step 26140, loss = 0.21, batch loss = 0.14 (33.7 examples/sec; 0.237 sec/batch; 20h:11m:29s remains)
INFO - root - 2017-12-17 04:26:13.296393: step 26150, loss = 0.22, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 18h:47m:43s remains)
INFO - root - 2017-12-17 04:26:15.582500: step 26160, loss = 0.22, batch loss = 0.14 (34.2 examples/sec; 0.234 sec/batch; 19h:53m:11s remains)
INFO - root - 2017-12-17 04:26:17.869274: step 26170, loss = 0.26, batch loss = 0.18 (31.9 examples/sec; 0.250 sec/batch; 21h:18m:39s remains)
INFO - root - 2017-12-17 04:26:20.173524: step 26180, loss = 0.22, batch loss = 0.14 (34.3 examples/sec; 0.233 sec/batch; 19h:49m:30s remains)
INFO - root - 2017-12-17 04:26:22.458374: step 26190, loss = 0.22, batch loss = 0.15 (35.8 examples/sec; 0.224 sec/batch; 19h:01m:06s remains)
INFO - root - 2017-12-17 04:26:24.710425: step 26200, loss = 0.24, batch loss = 0.17 (35.8 examples/sec; 0.223 sec/batch; 19h:00m:31s remains)
INFO - root - 2017-12-17 04:26:27.098214: step 26210, loss = 0.23, batch loss = 0.16 (35.6 examples/sec; 0.225 sec/batch; 19h:07m:16s remains)
INFO - root - 2017-12-17 04:26:29.369238: step 26220, loss = 0.19, batch loss = 0.12 (34.0 examples/sec; 0.235 sec/batch; 20h:01m:46s remains)
INFO - root - 2017-12-17 04:26:31.669385: step 26230, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:55m:22s remains)
INFO - root - 2017-12-17 04:26:33.908425: step 26240, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 19h:09m:40s remains)
INFO - root - 2017-12-17 04:26:36.179728: step 26250, loss = 0.21, batch loss = 0.13 (34.7 examples/sec; 0.230 sec/batch; 19h:35m:14s remains)
INFO - root - 2017-12-17 04:26:38.474801: step 26260, loss = 0.15, batch loss = 0.08 (34.3 examples/sec; 0.233 sec/batch; 19h:51m:26s remains)
INFO - root - 2017-12-17 04:26:40.731678: step 26270, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 19h:17m:09s remains)
INFO - root - 2017-12-17 04:26:43.026491: step 26280, loss = 0.21, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 18h:57m:07s remains)
INFO - root - 2017-12-17 04:26:45.303466: step 26290, loss = 0.21, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 18h:55m:43s remains)
INFO - root - 2017-12-17 04:26:47.577670: step 26300, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 19h:14m:23s remains)
INFO - root - 2017-12-17 04:26:50.036683: step 26310, loss = 0.19, batch loss = 0.12 (33.9 examples/sec; 0.236 sec/batch; 20h:05m:02s remains)
INFO - root - 2017-12-17 04:26:52.309456: step 26320, loss = 0.20, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 18h:59m:12s remains)
INFO - root - 2017-12-17 04:26:54.600460: step 26330, loss = 0.17, batch loss = 0.10 (34.0 examples/sec; 0.236 sec/batch; 20h:02m:14s remains)
INFO - root - 2017-12-17 04:26:56.865744: step 26340, loss = 0.24, batch loss = 0.17 (36.4 examples/sec; 0.220 sec/batch; 18h:40m:53s remains)
INFO - root - 2017-12-17 04:26:59.095670: step 26350, loss = 0.17, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 18h:47m:41s remains)
INFO - root - 2017-12-17 04:27:01.392854: step 26360, loss = 0.16, batch loss = 0.09 (33.5 examples/sec; 0.239 sec/batch; 20h:20m:07s remains)
INFO - root - 2017-12-17 04:27:03.635065: step 26370, loss = 0.18, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 18h:52m:03s remains)
INFO - root - 2017-12-17 04:27:05.918031: step 26380, loss = 0.19, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 18h:40m:29s remains)
INFO - root - 2017-12-17 04:27:08.189124: step 26390, loss = 0.17, batch loss = 0.10 (35.1 examples/sec; 0.228 sec/batch; 19h:22m:31s remains)
INFO - root - 2017-12-17 04:27:10.540094: step 26400, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 19h:10m:24s remains)
INFO - root - 2017-12-17 04:27:12.936424: step 26410, loss = 0.17, batch loss = 0.09 (34.8 examples/sec; 0.230 sec/batch; 19h:34m:09s remains)
INFO - root - 2017-12-17 04:27:15.203262: step 26420, loss = 0.20, batch loss = 0.12 (34.5 examples/sec; 0.232 sec/batch; 19h:44m:26s remains)
INFO - root - 2017-12-17 04:27:17.454926: step 26430, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 19h:07m:07s remains)
INFO - root - 2017-12-17 04:27:19.714852: step 26440, loss = 0.18, batch loss = 0.10 (37.2 examples/sec; 0.215 sec/batch; 18h:16m:43s remains)
INFO - root - 2017-12-17 04:27:22.012721: step 26450, loss = 0.23, batch loss = 0.15 (34.3 examples/sec; 0.233 sec/batch; 19h:48m:44s remains)
INFO - root - 2017-12-17 04:27:24.292192: step 26460, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 19h:03m:35s remains)
INFO - root - 2017-12-17 04:27:26.567445: step 26470, loss = 0.16, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 19h:07m:07s remains)
INFO - root - 2017-12-17 04:27:28.822446: step 26480, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 19h:01m:40s remains)
INFO - root - 2017-12-17 04:27:31.064181: step 26490, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 18h:55m:36s remains)
INFO - root - 2017-12-17 04:27:33.316372: step 26500, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 19h:04m:05s remains)
INFO - root - 2017-12-17 04:27:35.768178: step 26510, loss = 0.19, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 18h:57m:22s remains)
INFO - root - 2017-12-17 04:27:38.100435: step 26520, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 19h:28m:57s remains)
INFO - root - 2017-12-17 04:27:40.363248: step 26530, loss = 0.22, batch loss = 0.15 (34.7 examples/sec; 0.231 sec/batch; 19h:36m:24s remains)
INFO - root - 2017-12-17 04:27:42.615512: step 26540, loss = 0.25, batch loss = 0.17 (35.3 examples/sec; 0.227 sec/batch; 19h:16m:09s remains)
INFO - root - 2017-12-17 04:27:44.902678: step 26550, loss = 0.25, batch loss = 0.18 (33.9 examples/sec; 0.236 sec/batch; 20h:03m:15s remains)
INFO - root - 2017-12-17 04:27:47.183770: step 26560, loss = 0.20, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 19h:29m:22s remains)
INFO - root - 2017-12-17 04:27:49.474427: step 26570, loss = 0.18, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 19h:43m:15s remains)
INFO - root - 2017-12-17 04:27:51.725158: step 26580, loss = 0.19, batch loss = 0.12 (36.6 examples/sec; 0.219 sec/batch; 18h:35m:52s remains)
INFO - root - 2017-12-17 04:27:54.006775: step 26590, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:22m:01s remains)
INFO - root - 2017-12-17 04:27:56.265233: step 26600, loss = 0.17, batch loss = 0.09 (34.7 examples/sec; 0.231 sec/batch; 19h:35m:45s remains)
INFO - root - 2017-12-17 04:27:58.640978: step 26610, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 19h:18m:17s remains)
INFO - root - 2017-12-17 04:28:00.908627: step 26620, loss = 0.17, batch loss = 0.10 (35.1 examples/sec; 0.228 sec/batch; 19h:22m:09s remains)
INFO - root - 2017-12-17 04:28:03.169779: step 26630, loss = 0.24, batch loss = 0.17 (35.1 examples/sec; 0.228 sec/batch; 19h:20m:50s remains)
INFO - root - 2017-12-17 04:28:05.449873: step 26640, loss = 0.17, batch loss = 0.10 (35.6 examples/sec; 0.224 sec/batch; 19h:04m:06s remains)
INFO - root - 2017-12-17 04:28:07.756019: step 26650, loss = 0.22, batch loss = 0.15 (31.5 examples/sec; 0.254 sec/batch; 21h:36m:17s remains)
INFO - root - 2017-12-17 04:28:10.035604: step 26660, loss = 0.19, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 19h:14m:56s remains)
INFO - root - 2017-12-17 04:28:12.339323: step 26670, loss = 0.22, batch loss = 0.14 (35.3 examples/sec; 0.227 sec/batch; 19h:16m:13s remains)
INFO - root - 2017-12-17 04:28:14.612872: step 26680, loss = 0.19, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:53m:16s remains)
INFO - root - 2017-12-17 04:28:16.884175: step 26690, loss = 0.20, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:20m:33s remains)
INFO - root - 2017-12-17 04:28:19.161803: step 26700, loss = 0.16, batch loss = 0.09 (35.0 examples/sec; 0.229 sec/batch; 19h:26m:37s remains)
INFO - root - 2017-12-17 04:28:21.533750: step 26710, loss = 0.17, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 18h:53m:28s remains)
INFO - root - 2017-12-17 04:28:23.825089: step 26720, loss = 0.23, batch loss = 0.16 (34.3 examples/sec; 0.233 sec/batch; 19h:48m:12s remains)
INFO - root - 2017-12-17 04:28:26.056804: step 26730, loss = 0.20, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 18h:54m:26s remains)
INFO - root - 2017-12-17 04:28:28.324476: step 26740, loss = 0.22, batch loss = 0.15 (34.3 examples/sec; 0.233 sec/batch; 19h:49m:08s remains)
INFO - root - 2017-12-17 04:28:30.558963: step 26750, loss = 0.22, batch loss = 0.14 (34.7 examples/sec; 0.231 sec/batch; 19h:35m:27s remains)
INFO - root - 2017-12-17 04:28:32.811278: step 26760, loss = 0.21, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 19h:36m:40s remains)
INFO - root - 2017-12-17 04:28:35.122297: step 26770, loss = 0.25, batch loss = 0.18 (34.8 examples/sec; 0.230 sec/batch; 19h:30m:53s remains)
INFO - root - 2017-12-17 04:28:37.395163: step 26780, loss = 0.18, batch loss = 0.11 (33.9 examples/sec; 0.236 sec/batch; 20h:02m:03s remains)
INFO - root - 2017-12-17 04:28:39.729340: step 26790, loss = 0.19, batch loss = 0.12 (34.5 examples/sec; 0.232 sec/batch; 19h:39m:46s remains)
INFO - root - 2017-12-17 04:28:42.008720: step 26800, loss = 0.16, batch loss = 0.09 (35.1 examples/sec; 0.228 sec/batch; 19h:22m:13s remains)
INFO - root - 2017-12-17 04:28:44.399276: step 26810, loss = 0.22, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 18h:52m:26s remains)
INFO - root - 2017-12-17 04:28:46.725114: step 26820, loss = 0.19, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 19h:29m:36s remains)
INFO - root - 2017-12-17 04:28:49.000668: step 26830, loss = 0.18, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 18h:54m:56s remains)
INFO - root - 2017-12-17 04:28:51.263865: step 26840, loss = 0.19, batch loss = 0.12 (34.2 examples/sec; 0.234 sec/batch; 19h:52m:14s remains)
INFO - root - 2017-12-17 04:28:53.517426: step 26850, loss = 0.25, batch loss = 0.18 (35.0 examples/sec; 0.229 sec/batch; 19h:24m:21s remains)
INFO - root - 2017-12-17 04:28:55.762046: step 26860, loss = 0.19, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:50m:37s remains)
INFO - root - 2017-12-17 04:28:58.060717: step 26870, loss = 0.26, batch loss = 0.18 (36.0 examples/sec; 0.222 sec/batch; 18h:51m:44s remains)
INFO - root - 2017-12-17 04:29:00.326992: step 26880, loss = 0.21, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 18h:54m:41s remains)
INFO - root - 2017-12-17 04:29:02.593823: step 26890, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 19h:17m:34s remains)
INFO - root - 2017-12-17 04:29:04.874747: step 26900, loss = 0.17, batch loss = 0.10 (36.3 examples/sec; 0.221 sec/batch; 18h:43m:18s remains)
INFO - root - 2017-12-17 04:29:07.261833: step 26910, loss = 0.16, batch loss = 0.09 (34.8 examples/sec; 0.230 sec/batch; 19h:29m:12s remains)
INFO - root - 2017-12-17 04:29:09.554828: step 26920, loss = 0.21, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 19h:28m:32s remains)
INFO - root - 2017-12-17 04:29:11.857702: step 26930, loss = 0.19, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 19h:17m:30s remains)
INFO - root - 2017-12-17 04:29:14.101576: step 26940, loss = 0.22, batch loss = 0.14 (36.1 examples/sec; 0.222 sec/batch; 18h:48m:39s remains)
INFO - root - 2017-12-17 04:29:16.373217: step 26950, loss = 0.21, batch loss = 0.14 (33.6 examples/sec; 0.238 sec/batch; 20h:12m:56s remains)
INFO - root - 2017-12-17 04:29:18.666189: step 26960, loss = 0.24, batch loss = 0.17 (34.3 examples/sec; 0.233 sec/batch; 19h:47m:21s remains)
INFO - root - 2017-12-17 04:29:20.915341: step 26970, loss = 0.18, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 18h:53m:56s remains)
INFO - root - 2017-12-17 04:29:23.169917: step 26980, loss = 0.18, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 19h:21m:54s remains)
INFO - root - 2017-12-17 04:29:25.423776: step 26990, loss = 0.20, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:19m:41s remains)
INFO - root - 2017-12-17 04:29:27.725126: step 27000, loss = 0.18, batch loss = 0.11 (34.0 examples/sec; 0.235 sec/batch; 19h:58m:11s remains)
INFO - root - 2017-12-17 04:29:30.110343: step 27010, loss = 0.20, batch loss = 0.12 (34.4 examples/sec; 0.233 sec/batch; 19h:44m:30s remains)
INFO - root - 2017-12-17 04:29:32.376826: step 27020, loss = 0.23, batch loss = 0.16 (34.5 examples/sec; 0.232 sec/batch; 19h:42m:14s remains)
INFO - root - 2017-12-17 04:29:34.673408: step 27030, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 19h:11m:30s remains)
INFO - root - 2017-12-17 04:29:36.944691: step 27040, loss = 0.17, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 18h:52m:05s remains)
INFO - root - 2017-12-17 04:29:39.194065: step 27050, loss = 0.23, batch loss = 0.16 (36.0 examples/sec; 0.222 sec/batch; 18h:51m:44s remains)
INFO - root - 2017-12-17 04:29:41.429560: step 27060, loss = 0.15, batch loss = 0.08 (36.5 examples/sec; 0.219 sec/batch; 18h:37m:01s remains)
INFO - root - 2017-12-17 04:29:43.710806: step 27070, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 19h:03m:26s remains)
INFO - root - 2017-12-17 04:29:46.012519: step 27080, loss = 0.28, batch loss = 0.21 (32.9 examples/sec; 0.243 sec/batch; 20h:38m:39s remains)
INFO - root - 2017-12-17 04:29:48.272311: step 27090, loss = 0.23, batch loss = 0.16 (36.6 examples/sec; 0.218 sec/batch; 18h:31m:53s remains)
INFO - root - 2017-12-17 04:29:50.549420: step 27100, loss = 0.18, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 19h:13m:50s remains)
INFO - root - 2017-12-17 04:29:52.912528: step 27110, loss = 0.20, batch loss = 0.13 (34.7 examples/sec; 0.230 sec/batch; 19h:31m:57s remains)
INFO - root - 2017-12-17 04:29:55.156756: step 27120, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 19h:00m:21s remains)
INFO - root - 2017-12-17 04:29:57.400395: step 27130, loss = 0.17, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 18h:38m:22s remains)
INFO - root - 2017-12-17 04:29:59.687760: step 27140, loss = 0.18, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:58m:53s remains)
INFO - root - 2017-12-17 04:30:01.933316: step 27150, loss = 0.25, batch loss = 0.17 (34.6 examples/sec; 0.231 sec/batch; 19h:35m:58s remains)
INFO - root - 2017-12-17 04:30:04.190543: step 27160, loss = 0.19, batch loss = 0.11 (35.2 examples/sec; 0.227 sec/batch; 19h:17m:24s remains)
INFO - root - 2017-12-17 04:30:06.451031: step 27170, loss = 0.18, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 19h:30m:08s remains)
INFO - root - 2017-12-17 04:30:08.749343: step 27180, loss = 0.24, batch loss = 0.17 (35.6 examples/sec; 0.225 sec/batch; 19h:02m:54s remains)
INFO - root - 2017-12-17 04:30:11.036501: step 27190, loss = 0.19, batch loss = 0.12 (33.7 examples/sec; 0.237 sec/batch; 20h:06m:48s remains)
INFO - root - 2017-12-17 04:30:13.286773: step 27200, loss = 0.19, batch loss = 0.11 (35.0 examples/sec; 0.229 sec/batch; 19h:22m:58s remains)
INFO - root - 2017-12-17 04:30:15.673006: step 27210, loss = 0.23, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 19h:16m:31s remains)
INFO - root - 2017-12-17 04:30:17.932489: step 27220, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 19h:01m:39s remains)
INFO - root - 2017-12-17 04:30:20.189561: step 27230, loss = 0.22, batch loss = 0.15 (35.6 examples/sec; 0.224 sec/batch; 19h:01m:48s remains)
INFO - root - 2017-12-17 04:30:22.444485: step 27240, loss = 0.20, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 18h:53m:17s remains)
INFO - root - 2017-12-17 04:30:24.723864: step 27250, loss = 0.17, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 19h:15m:40s remains)
INFO - root - 2017-12-17 04:30:26.998551: step 27260, loss = 0.19, batch loss = 0.12 (36.1 examples/sec; 0.221 sec/batch; 18h:46m:39s remains)
INFO - root - 2017-12-17 04:30:29.294501: step 27270, loss = 0.22, batch loss = 0.15 (34.6 examples/sec; 0.231 sec/batch; 19h:35m:15s remains)
INFO - root - 2017-12-17 04:30:31.606030: step 27280, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 19h:04m:34s remains)
INFO - root - 2017-12-17 04:30:33.865179: step 27290, loss = 0.20, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 19h:24m:11s remains)
INFO - root - 2017-12-17 04:30:36.152020: step 27300, loss = 0.26, batch loss = 0.19 (35.6 examples/sec; 0.225 sec/batch; 19h:04m:14s remains)
INFO - root - 2017-12-17 04:30:38.528243: step 27310, loss = 0.23, batch loss = 0.16 (35.5 examples/sec; 0.226 sec/batch; 19h:07m:33s remains)
INFO - root - 2017-12-17 04:30:40.829448: step 27320, loss = 0.18, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 19h:38m:36s remains)
INFO - root - 2017-12-17 04:30:43.091375: step 27330, loss = 0.20, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 18h:38m:11s remains)
INFO - root - 2017-12-17 04:30:45.372434: step 27340, loss = 0.24, batch loss = 0.17 (35.8 examples/sec; 0.223 sec/batch; 18h:55m:51s remains)
INFO - root - 2017-12-17 04:30:47.631902: step 27350, loss = 0.24, batch loss = 0.16 (36.4 examples/sec; 0.220 sec/batch; 18h:38m:02s remains)
INFO - root - 2017-12-17 04:30:49.879889: step 27360, loss = 0.19, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 19h:19m:02s remains)
INFO - root - 2017-12-17 04:30:52.182203: step 27370, loss = 0.21, batch loss = 0.13 (34.2 examples/sec; 0.234 sec/batch; 19h:48m:10s remains)
INFO - root - 2017-12-17 04:30:54.452386: step 27380, loss = 0.17, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 19h:02m:41s remains)
INFO - root - 2017-12-17 04:30:56.753556: step 27390, loss = 0.21, batch loss = 0.14 (36.3 examples/sec; 0.221 sec/batch; 18h:41m:38s remains)
INFO - root - 2017-12-17 04:30:59.020248: step 27400, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 19h:00m:00s remains)
INFO - root - 2017-12-17 04:31:01.416026: step 27410, loss = 0.21, batch loss = 0.14 (33.5 examples/sec; 0.239 sec/batch; 20h:15m:04s remains)
INFO - root - 2017-12-17 04:31:03.680862: step 27420, loss = 0.21, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 19h:02m:52s remains)
INFO - root - 2017-12-17 04:31:05.924237: step 27430, loss = 0.20, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 18h:42m:39s remains)
INFO - root - 2017-12-17 04:31:08.184671: step 27440, loss = 0.25, batch loss = 0.17 (36.1 examples/sec; 0.222 sec/batch; 18h:48m:14s remains)
INFO - root - 2017-12-17 04:31:10.429451: step 27450, loss = 0.17, batch loss = 0.10 (36.1 examples/sec; 0.221 sec/batch; 18h:45m:19s remains)
INFO - root - 2017-12-17 04:31:12.693173: step 27460, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 19h:16m:18s remains)
INFO - root - 2017-12-17 04:31:14.962143: step 27470, loss = 0.17, batch loss = 0.10 (36.3 examples/sec; 0.221 sec/batch; 18h:41m:55s remains)
INFO - root - 2017-12-17 04:31:17.190014: step 27480, loss = 0.21, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 18h:44m:40s remains)
INFO - root - 2017-12-17 04:31:19.420380: step 27490, loss = 0.26, batch loss = 0.18 (35.7 examples/sec; 0.224 sec/batch; 18h:59m:52s remains)
INFO - root - 2017-12-17 04:31:21.661719: step 27500, loss = 0.19, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 19h:06m:16s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-27500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-27500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 04:31:24.756379: step 27510, loss = 0.17, batch loss = 0.10 (35.5 examples/sec; 0.226 sec/batch; 19h:06m:52s remains)
INFO - root - 2017-12-17 04:31:27.029213: step 27520, loss = 0.20, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 19h:16m:54s remains)
INFO - root - 2017-12-17 04:31:29.305014: step 27530, loss = 0.19, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 18h:28m:08s remains)
INFO - root - 2017-12-17 04:31:31.561738: step 27540, loss = 0.21, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 18h:34m:51s remains)
INFO - root - 2017-12-17 04:31:33.826126: step 27550, loss = 0.21, batch loss = 0.14 (33.2 examples/sec; 0.241 sec/batch; 20h:25m:19s remains)
INFO - root - 2017-12-17 04:31:36.115752: step 27560, loss = 0.20, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 19h:19m:58s remains)
INFO - root - 2017-12-17 04:31:38.380276: step 27570, loss = 0.24, batch loss = 0.16 (35.8 examples/sec; 0.223 sec/batch; 18h:54m:50s remains)
INFO - root - 2017-12-17 04:31:40.679008: step 27580, loss = 0.22, batch loss = 0.15 (34.8 examples/sec; 0.230 sec/batch; 19h:29m:40s remains)
INFO - root - 2017-12-17 04:31:42.927383: step 27590, loss = 0.23, batch loss = 0.16 (35.3 examples/sec; 0.226 sec/batch; 19h:10m:09s remains)
INFO - root - 2017-12-17 04:31:45.188949: step 27600, loss = 0.16, batch loss = 0.08 (34.9 examples/sec; 0.230 sec/batch; 19h:26m:23s remains)
INFO - root - 2017-12-17 04:31:47.614114: step 27610, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 19h:07m:57s remains)
INFO - root - 2017-12-17 04:31:49.852400: step 27620, loss = 0.21, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 18h:50m:57s remains)
INFO - root - 2017-12-17 04:31:52.106549: step 27630, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 19h:26m:04s remains)
INFO - root - 2017-12-17 04:31:54.386970: step 27640, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 19h:14m:08s remains)
INFO - root - 2017-12-17 04:31:56.601024: step 27650, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 18h:42m:20s remains)
INFO - root - 2017-12-17 04:31:58.845878: step 27660, loss = 0.16, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 18h:59m:36s remains)
INFO - root - 2017-12-17 04:32:01.108982: step 27670, loss = 0.17, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 18h:34m:59s remains)
INFO - root - 2017-12-17 04:32:03.362563: step 27680, loss = 0.23, batch loss = 0.15 (36.3 examples/sec; 0.220 sec/batch; 18h:39m:21s remains)
INFO - root - 2017-12-17 04:32:05.622551: step 27690, loss = 0.26, batch loss = 0.18 (35.4 examples/sec; 0.226 sec/batch; 19h:07m:49s remains)
INFO - root - 2017-12-17 04:32:07.856694: step 27700, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:59m:05s remains)
INFO - root - 2017-12-17 04:32:10.226041: step 27710, loss = 0.21, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 19h:23m:29s remains)
INFO - root - 2017-12-17 04:32:12.443305: step 27720, loss = 0.24, batch loss = 0.17 (37.4 examples/sec; 0.214 sec/batch; 18h:06m:25s remains)
INFO - root - 2017-12-17 04:32:14.709540: step 27730, loss = 0.18, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 18h:43m:35s remains)
INFO - root - 2017-12-17 04:32:16.969645: step 27740, loss = 0.20, batch loss = 0.12 (37.0 examples/sec; 0.216 sec/batch; 18h:19m:33s remains)
INFO - root - 2017-12-17 04:32:19.231987: step 27750, loss = 0.22, batch loss = 0.14 (35.0 examples/sec; 0.229 sec/batch; 19h:21m:37s remains)
INFO - root - 2017-12-17 04:32:21.465743: step 27760, loss = 0.21, batch loss = 0.14 (36.9 examples/sec; 0.217 sec/batch; 18h:22m:11s remains)
INFO - root - 2017-12-17 04:32:23.702129: step 27770, loss = 0.24, batch loss = 0.17 (36.1 examples/sec; 0.222 sec/batch; 18h:45m:57s remains)
INFO - root - 2017-12-17 04:32:25.998205: step 27780, loss = 0.22, batch loss = 0.15 (34.7 examples/sec; 0.230 sec/batch; 19h:30m:18s remains)
INFO - root - 2017-12-17 04:32:28.272402: step 27790, loss = 0.20, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:49m:40s remains)
INFO - root - 2017-12-17 04:32:30.554688: step 27800, loss = 0.20, batch loss = 0.13 (36.8 examples/sec; 0.217 sec/batch; 18h:24m:27s remains)
INFO - root - 2017-12-17 04:32:32.947760: step 27810, loss = 0.19, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 18h:39m:09s remains)
INFO - root - 2017-12-17 04:32:35.218510: step 27820, loss = 0.20, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 19h:36m:20s remains)
INFO - root - 2017-12-17 04:32:37.465240: step 27830, loss = 0.17, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 18h:47m:23s remains)
INFO - root - 2017-12-17 04:32:39.747366: step 27840, loss = 0.17, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 19h:12m:00s remains)
INFO - root - 2017-12-17 04:32:42.026297: step 27850, loss = 0.19, batch loss = 0.12 (34.4 examples/sec; 0.233 sec/batch; 19h:42m:11s remains)
INFO - root - 2017-12-17 04:32:44.250376: step 27860, loss = 0.20, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 18h:53m:43s remains)
INFO - root - 2017-12-17 04:32:46.491519: step 27870, loss = 0.23, batch loss = 0.16 (33.4 examples/sec; 0.240 sec/batch; 20h:16m:23s remains)
INFO - root - 2017-12-17 04:32:48.738531: step 27880, loss = 0.19, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 18h:51m:01s remains)
INFO - root - 2017-12-17 04:32:50.972637: step 27890, loss = 0.20, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 18h:34m:26s remains)
INFO - root - 2017-12-17 04:32:53.208612: step 27900, loss = 0.17, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 18h:59m:57s remains)
INFO - root - 2017-12-17 04:32:55.599892: step 27910, loss = 0.22, batch loss = 0.14 (35.6 examples/sec; 0.224 sec/batch; 18h:59m:12s remains)
INFO - root - 2017-12-17 04:32:57.875340: step 27920, loss = 0.25, batch loss = 0.18 (33.8 examples/sec; 0.237 sec/batch; 20h:03m:00s remains)
INFO - root - 2017-12-17 04:33:00.136324: step 27930, loss = 0.24, batch loss = 0.17 (35.6 examples/sec; 0.224 sec/batch; 18h:59m:33s remains)
INFO - root - 2017-12-17 04:33:02.394293: step 27940, loss = 0.19, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 19h:16m:40s remains)
INFO - root - 2017-12-17 04:33:04.698084: step 27950, loss = 0.18, batch loss = 0.11 (32.7 examples/sec; 0.245 sec/batch; 20h:43m:01s remains)
INFO - root - 2017-12-17 04:33:06.958610: step 27960, loss = 0.21, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 19h:04m:33s remains)
INFO - root - 2017-12-17 04:33:09.256012: step 27970, loss = 0.21, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 18h:49m:00s remains)
INFO - root - 2017-12-17 04:33:11.482917: step 27980, loss = 0.23, batch loss = 0.16 (34.3 examples/sec; 0.233 sec/batch; 19h:42m:39s remains)
INFO - root - 2017-12-17 04:33:13.760084: step 27990, loss = 0.21, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 18h:42m:22s remains)
INFO - root - 2017-12-17 04:33:15.994402: step 28000, loss = 0.26, batch loss = 0.19 (36.0 examples/sec; 0.222 sec/batch; 18h:46m:23s remains)
INFO - root - 2017-12-17 04:33:18.383789: step 28010, loss = 0.18, batch loss = 0.10 (37.3 examples/sec; 0.215 sec/batch; 18h:09m:26s remains)
INFO - root - 2017-12-17 04:33:20.628945: step 28020, loss = 0.21, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 19h:22m:53s remains)
INFO - root - 2017-12-17 04:33:22.901357: step 28030, loss = 0.21, batch loss = 0.13 (32.3 examples/sec; 0.248 sec/batch; 20h:58m:03s remains)
INFO - root - 2017-12-17 04:33:25.188079: step 28040, loss = 0.17, batch loss = 0.10 (34.6 examples/sec; 0.231 sec/batch; 19h:32m:17s remains)
INFO - root - 2017-12-17 04:33:27.442383: step 28050, loss = 0.18, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 18h:51m:50s remains)
INFO - root - 2017-12-17 04:33:29.671413: step 28060, loss = 0.18, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 19h:05m:17s remains)
INFO - root - 2017-12-17 04:33:31.899768: step 28070, loss = 0.20, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 19h:10m:21s remains)
INFO - root - 2017-12-17 04:33:34.135762: step 28080, loss = 0.27, batch loss = 0.20 (35.6 examples/sec; 0.225 sec/batch; 19h:01m:11s remains)
INFO - root - 2017-12-17 04:33:36.438368: step 28090, loss = 0.19, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 19h:37m:36s remains)
INFO - root - 2017-12-17 04:33:38.682830: step 28100, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.223 sec/batch; 18h:53m:35s remains)
INFO - root - 2017-12-17 04:33:41.066143: step 28110, loss = 0.22, batch loss = 0.14 (35.5 examples/sec; 0.225 sec/batch; 19h:02m:42s remains)
INFO - root - 2017-12-17 04:33:43.310065: step 28120, loss = 0.16, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 18h:32m:54s remains)
INFO - root - 2017-12-17 04:33:45.554180: step 28130, loss = 0.20, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 18h:59m:19s remains)
INFO - root - 2017-12-17 04:33:47.796528: step 28140, loss = 0.17, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 18h:46m:29s remains)
INFO - root - 2017-12-17 04:33:50.081231: step 28150, loss = 0.18, batch loss = 0.11 (33.8 examples/sec; 0.236 sec/batch; 19h:59m:27s remains)
INFO - root - 2017-12-17 04:33:52.312918: step 28160, loss = 0.17, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 18h:32m:56s remains)
INFO - root - 2017-12-17 04:33:54.544963: step 28170, loss = 0.19, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:47m:37s remains)
INFO - root - 2017-12-17 04:33:56.774336: step 28180, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 19h:03m:03s remains)
INFO - root - 2017-12-17 04:33:59.080250: step 28190, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 18h:59m:18s remains)
INFO - root - 2017-12-17 04:34:01.326934: step 28200, loss = 0.20, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 18h:42m:16s remains)
INFO - root - 2017-12-17 04:34:03.715396: step 28210, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 18h:41m:55s remains)
INFO - root - 2017-12-17 04:34:05.995698: step 28220, loss = 0.17, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 18h:54m:00s remains)
INFO - root - 2017-12-17 04:34:08.260725: step 28230, loss = 0.17, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 18h:55m:33s remains)
INFO - root - 2017-12-17 04:34:10.505094: step 28240, loss = 0.17, batch loss = 0.10 (36.1 examples/sec; 0.221 sec/batch; 18h:42m:43s remains)
INFO - root - 2017-12-17 04:34:12.782016: step 28250, loss = 0.17, batch loss = 0.10 (35.0 examples/sec; 0.228 sec/batch; 19h:17m:35s remains)
INFO - root - 2017-12-17 04:34:15.065457: step 28260, loss = 0.20, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 18h:41m:09s remains)
INFO - root - 2017-12-17 04:34:17.336937: step 28270, loss = 0.19, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 19h:24m:04s remains)
INFO - root - 2017-12-17 04:34:19.584434: step 28280, loss = 0.23, batch loss = 0.16 (34.2 examples/sec; 0.234 sec/batch; 19h:46m:51s remains)
INFO - root - 2017-12-17 04:34:21.825053: step 28290, loss = 0.21, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 18h:40m:10s remains)
INFO - root - 2017-12-17 04:34:24.087141: step 28300, loss = 0.19, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 19h:14m:28s remains)
INFO - root - 2017-12-17 04:34:26.467835: step 28310, loss = 0.22, batch loss = 0.15 (36.7 examples/sec; 0.218 sec/batch; 18h:26m:29s remains)
INFO - root - 2017-12-17 04:34:28.689905: step 28320, loss = 0.20, batch loss = 0.13 (36.5 examples/sec; 0.219 sec/batch; 18h:30m:39s remains)
INFO - root - 2017-12-17 04:34:30.925658: step 28330, loss = 0.17, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 18h:44m:29s remains)
INFO - root - 2017-12-17 04:34:33.177913: step 28340, loss = 0.18, batch loss = 0.10 (35.5 examples/sec; 0.226 sec/batch; 19h:03m:33s remains)
INFO - root - 2017-12-17 04:34:35.401996: step 28350, loss = 0.19, batch loss = 0.12 (37.9 examples/sec; 0.211 sec/batch; 17h:49m:50s remains)
INFO - root - 2017-12-17 04:34:37.654756: step 28360, loss = 0.22, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 19h:06m:54s remains)
INFO - root - 2017-12-17 04:34:39.957676: step 28370, loss = 0.19, batch loss = 0.11 (34.3 examples/sec; 0.234 sec/batch; 19h:43m:34s remains)
INFO - root - 2017-12-17 04:34:42.201631: step 28380, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:05m:50s remains)
INFO - root - 2017-12-17 04:34:44.442137: step 28390, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 19h:00m:40s remains)
INFO - root - 2017-12-17 04:34:46.707892: step 28400, loss = 0.20, batch loss = 0.13 (34.4 examples/sec; 0.232 sec/batch; 19h:37m:27s remains)
INFO - root - 2017-12-17 04:34:49.144752: step 28410, loss = 0.20, batch loss = 0.12 (33.9 examples/sec; 0.236 sec/batch; 19h:57m:31s remains)
INFO - root - 2017-12-17 04:34:51.410681: step 28420, loss = 0.25, batch loss = 0.18 (35.2 examples/sec; 0.227 sec/batch; 19h:12m:29s remains)
INFO - root - 2017-12-17 04:34:53.711380: step 28430, loss = 0.23, batch loss = 0.15 (34.2 examples/sec; 0.234 sec/batch; 19h:45m:42s remains)
INFO - root - 2017-12-17 04:34:55.950310: step 28440, loss = 0.23, batch loss = 0.15 (34.6 examples/sec; 0.231 sec/batch; 19h:32m:48s remains)
INFO - root - 2017-12-17 04:34:58.290800: step 28450, loss = 0.17, batch loss = 0.09 (34.8 examples/sec; 0.230 sec/batch; 19h:25m:56s remains)
INFO - root - 2017-12-17 04:35:00.551856: step 28460, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 18h:54m:02s remains)
INFO - root - 2017-12-17 04:35:02.825208: step 28470, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.226 sec/batch; 19h:07m:06s remains)
INFO - root - 2017-12-17 04:35:05.162279: step 28480, loss = 0.20, batch loss = 0.13 (32.2 examples/sec; 0.248 sec/batch; 20h:57m:24s remains)
INFO - root - 2017-12-17 04:35:07.419083: step 28490, loss = 0.20, batch loss = 0.13 (34.4 examples/sec; 0.233 sec/batch; 19h:38m:09s remains)
INFO - root - 2017-12-17 04:35:09.678736: step 28500, loss = 0.21, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 18h:46m:33s remains)
INFO - root - 2017-12-17 04:35:12.050582: step 28510, loss = 0.21, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 19h:16m:04s remains)
INFO - root - 2017-12-17 04:35:14.298316: step 28520, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 18h:59m:57s remains)
INFO - root - 2017-12-17 04:35:16.538877: step 28530, loss = 0.19, batch loss = 0.12 (34.2 examples/sec; 0.234 sec/batch; 19h:43m:49s remains)
INFO - root - 2017-12-17 04:35:18.808832: step 28540, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 19h:20m:19s remains)
INFO - root - 2017-12-17 04:35:21.072833: step 28550, loss = 0.19, batch loss = 0.12 (33.0 examples/sec; 0.243 sec/batch; 20h:28m:45s remains)
INFO - root - 2017-12-17 04:35:23.353914: step 28560, loss = 0.21, batch loss = 0.13 (34.1 examples/sec; 0.234 sec/batch; 19h:47m:16s remains)
INFO - root - 2017-12-17 04:35:25.658427: step 28570, loss = 0.26, batch loss = 0.19 (34.4 examples/sec; 0.233 sec/batch; 19h:38m:13s remains)
INFO - root - 2017-12-17 04:35:27.906140: step 28580, loss = 0.25, batch loss = 0.18 (35.5 examples/sec; 0.225 sec/batch; 19h:01m:26s remains)
INFO - root - 2017-12-17 04:35:30.141002: step 28590, loss = 0.20, batch loss = 0.12 (36.1 examples/sec; 0.221 sec/batch; 18h:41m:12s remains)
INFO - root - 2017-12-17 04:35:32.406656: step 28600, loss = 0.24, batch loss = 0.16 (37.3 examples/sec; 0.215 sec/batch; 18h:06m:28s remains)
INFO - root - 2017-12-17 04:35:34.752586: step 28610, loss = 0.19, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 18h:48m:56s remains)
INFO - root - 2017-12-17 04:35:37.003278: step 28620, loss = 0.17, batch loss = 0.10 (35.5 examples/sec; 0.226 sec/batch; 19h:02m:37s remains)
INFO - root - 2017-12-17 04:35:39.291174: step 28630, loss = 0.18, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 18h:40m:46s remains)
INFO - root - 2017-12-17 04:35:41.530541: step 28640, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:45m:46s remains)
INFO - root - 2017-12-17 04:35:43.806173: step 28650, loss = 0.23, batch loss = 0.16 (35.6 examples/sec; 0.225 sec/batch; 18h:57m:33s remains)
INFO - root - 2017-12-17 04:35:46.063122: step 28660, loss = 0.20, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 19h:30m:44s remains)
INFO - root - 2017-12-17 04:35:48.324955: step 28670, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 18h:55m:43s remains)
INFO - root - 2017-12-17 04:35:50.606848: step 28680, loss = 0.19, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 18h:24m:14s remains)
INFO - root - 2017-12-17 04:35:52.852080: step 28690, loss = 0.23, batch loss = 0.16 (35.2 examples/sec; 0.227 sec/batch; 19h:10m:25s remains)
INFO - root - 2017-12-17 04:35:55.103186: step 28700, loss = 0.18, batch loss = 0.11 (36.6 examples/sec; 0.219 sec/batch; 18h:26m:47s remains)
INFO - root - 2017-12-17 04:35:57.494059: step 28710, loss = 0.19, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 19h:00m:13s remains)
INFO - root - 2017-12-17 04:35:59.744471: step 28720, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 18h:55m:13s remains)
INFO - root - 2017-12-17 04:36:01.987034: step 28730, loss = 0.20, batch loss = 0.13 (36.7 examples/sec; 0.218 sec/batch; 18h:25m:03s remains)
INFO - root - 2017-12-17 04:36:04.304088: step 28740, loss = 0.18, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 18h:49m:29s remains)
INFO - root - 2017-12-17 04:36:06.584198: step 28750, loss = 0.25, batch loss = 0.18 (36.3 examples/sec; 0.221 sec/batch; 18h:37m:03s remains)
INFO - root - 2017-12-17 04:36:08.872129: step 28760, loss = 0.17, batch loss = 0.10 (34.9 examples/sec; 0.229 sec/batch; 19h:19m:02s remains)
INFO - root - 2017-12-17 04:36:11.143734: step 28770, loss = 0.18, batch loss = 0.11 (35.0 examples/sec; 0.228 sec/batch; 19h:16m:32s remains)
INFO - root - 2017-12-17 04:36:13.387775: step 28780, loss = 0.20, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 18h:41m:54s remains)
INFO - root - 2017-12-17 04:36:15.624012: step 28790, loss = 0.24, batch loss = 0.17 (36.1 examples/sec; 0.222 sec/batch; 18h:41m:41s remains)
INFO - root - 2017-12-17 04:36:17.873964: step 28800, loss = 0.21, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 18h:44m:32s remains)
INFO - root - 2017-12-17 04:36:20.278469: step 28810, loss = 0.20, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 19h:15m:00s remains)
INFO - root - 2017-12-17 04:36:22.512390: step 28820, loss = 0.22, batch loss = 0.15 (35.6 examples/sec; 0.224 sec/batch; 18h:56m:06s remains)
INFO - root - 2017-12-17 04:36:24.754919: step 28830, loss = 0.21, batch loss = 0.14 (33.9 examples/sec; 0.236 sec/batch; 19h:55m:04s remains)
INFO - root - 2017-12-17 04:36:27.035975: step 28840, loss = 0.26, batch loss = 0.18 (33.5 examples/sec; 0.239 sec/batch; 20h:09m:50s remains)
INFO - root - 2017-12-17 04:36:29.300352: step 28850, loss = 0.18, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 19h:02m:33s remains)
INFO - root - 2017-12-17 04:36:31.564628: step 28860, loss = 0.18, batch loss = 0.10 (34.4 examples/sec; 0.233 sec/batch; 19h:36m:40s remains)
INFO - root - 2017-12-17 04:36:33.845591: step 28870, loss = 0.17, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:55m:06s remains)
INFO - root - 2017-12-17 04:36:36.125179: step 28880, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 18h:59m:04s remains)
INFO - root - 2017-12-17 04:36:38.383818: step 28890, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 19h:20m:56s remains)
INFO - root - 2017-12-17 04:36:40.658544: step 28900, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 19h:03m:32s remains)
INFO - root - 2017-12-17 04:36:43.022054: step 28910, loss = 0.17, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 19h:04m:37s remains)
INFO - root - 2017-12-17 04:36:45.288703: step 28920, loss = 0.21, batch loss = 0.14 (35.8 examples/sec; 0.224 sec/batch; 18h:51m:25s remains)
INFO - root - 2017-12-17 04:36:47.561867: step 28930, loss = 0.24, batch loss = 0.17 (34.6 examples/sec; 0.231 sec/batch; 19h:30m:43s remains)
INFO - root - 2017-12-17 04:36:49.814715: step 28940, loss = 0.19, batch loss = 0.12 (34.4 examples/sec; 0.233 sec/batch; 19h:36m:48s remains)
INFO - root - 2017-12-17 04:36:52.062842: step 28950, loss = 0.21, batch loss = 0.13 (36.3 examples/sec; 0.221 sec/batch; 18h:36m:07s remains)
INFO - root - 2017-12-17 04:36:54.311890: step 28960, loss = 0.18, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 18h:41m:29s remains)
INFO - root - 2017-12-17 04:36:56.565612: step 28970, loss = 0.17, batch loss = 0.10 (35.8 examples/sec; 0.223 sec/batch; 18h:50m:11s remains)
INFO - root - 2017-12-17 04:36:58.806959: step 28980, loss = 0.17, batch loss = 0.10 (34.5 examples/sec; 0.232 sec/batch; 19h:33m:35s remains)
INFO - root - 2017-12-17 04:37:01.052452: step 28990, loss = 0.19, batch loss = 0.11 (34.3 examples/sec; 0.233 sec/batch; 19h:39m:54s remains)
INFO - root - 2017-12-17 04:37:03.300552: step 29000, loss = 0.20, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 19h:21m:53s remains)
INFO - root - 2017-12-17 04:37:05.698094: step 29010, loss = 0.21, batch loss = 0.14 (33.9 examples/sec; 0.236 sec/batch; 19h:53m:10s remains)
INFO - root - 2017-12-17 04:37:07.934678: step 29020, loss = 0.18, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 19h:02m:16s remains)
INFO - root - 2017-12-17 04:37:10.185983: step 29030, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 19h:08m:56s remains)
INFO - root - 2017-12-17 04:37:12.479566: step 29040, loss = 0.19, batch loss = 0.12 (34.2 examples/sec; 0.234 sec/batch; 19h:42m:39s remains)
INFO - root - 2017-12-17 04:37:14.732582: step 29050, loss = 0.20, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 18h:33m:42s remains)
INFO - root - 2017-12-17 04:37:17.006905: step 29060, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:11m:53s remains)
INFO - root - 2017-12-17 04:37:19.263131: step 29070, loss = 0.18, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 18h:43m:37s remains)
INFO - root - 2017-12-17 04:37:21.558135: step 29080, loss = 0.21, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 19h:09m:20s remains)
INFO - root - 2017-12-17 04:37:23.827934: step 29090, loss = 0.23, batch loss = 0.16 (35.1 examples/sec; 0.228 sec/batch; 19h:11m:51s remains)
INFO - root - 2017-12-17 04:37:26.120280: step 29100, loss = 0.17, batch loss = 0.10 (35.6 examples/sec; 0.224 sec/batch; 18h:55m:07s remains)
INFO - root - 2017-12-17 04:37:28.542155: step 29110, loss = 0.23, batch loss = 0.15 (34.6 examples/sec; 0.232 sec/batch; 19h:30m:43s remains)
INFO - root - 2017-12-17 04:37:30.831922: step 29120, loss = 0.21, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 19h:23m:12s remains)
INFO - root - 2017-12-17 04:37:33.100439: step 29130, loss = 0.23, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 18h:38m:02s remains)
INFO - root - 2017-12-17 04:37:35.365158: step 29140, loss = 0.22, batch loss = 0.14 (35.3 examples/sec; 0.227 sec/batch; 19h:06m:11s remains)
INFO - root - 2017-12-17 04:37:37.618938: step 29150, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:13m:12s remains)
INFO - root - 2017-12-17 04:37:39.940747: step 29160, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 18h:59m:55s remains)
INFO - root - 2017-12-17 04:37:42.203794: step 29170, loss = 0.23, batch loss = 0.15 (35.0 examples/sec; 0.228 sec/batch; 19h:13m:58s remains)
INFO - root - 2017-12-17 04:37:44.440357: step 29180, loss = 0.21, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 18h:46m:03s remains)
INFO - root - 2017-12-17 04:37:46.701113: step 29190, loss = 0.19, batch loss = 0.12 (36.3 examples/sec; 0.221 sec/batch; 18h:34m:52s remains)
INFO - root - 2017-12-17 04:37:48.950598: step 29200, loss = 0.21, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 19h:32m:07s remains)
INFO - root - 2017-12-17 04:37:51.340427: step 29210, loss = 0.22, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 18h:44m:34s remains)
INFO - root - 2017-12-17 04:37:53.640759: step 29220, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 18h:52m:31s remains)
INFO - root - 2017-12-17 04:37:55.901023: step 29230, loss = 0.21, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 18h:37m:53s remains)
INFO - root - 2017-12-17 04:37:58.182268: step 29240, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:11m:15s remains)
INFO - root - 2017-12-17 04:38:00.466985: step 29250, loss = 0.17, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 18h:47m:37s remains)
INFO - root - 2017-12-17 04:38:02.731879: step 29260, loss = 0.20, batch loss = 0.13 (33.4 examples/sec; 0.239 sec/batch; 20h:09m:54s remains)
INFO - root - 2017-12-17 04:38:05.006816: step 29270, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 18h:53m:18s remains)
INFO - root - 2017-12-17 04:38:07.261330: step 29280, loss = 0.21, batch loss = 0.14 (36.4 examples/sec; 0.220 sec/batch; 18h:29m:35s remains)
INFO - root - 2017-12-17 04:38:09.529601: step 29290, loss = 0.22, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 18h:52m:33s remains)
INFO - root - 2017-12-17 04:38:11.760636: step 29300, loss = 0.26, batch loss = 0.19 (36.5 examples/sec; 0.219 sec/batch; 18h:28m:49s remains)
INFO - root - 2017-12-17 04:38:14.204519: step 29310, loss = 0.19, batch loss = 0.12 (34.7 examples/sec; 0.230 sec/batch; 19h:23m:52s remains)
INFO - root - 2017-12-17 04:38:16.463207: step 29320, loss = 0.20, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:42m:37s remains)
INFO - root - 2017-12-17 04:38:18.715313: step 29330, loss = 0.17, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:52m:41s remains)
INFO - root - 2017-12-17 04:38:21.017270: step 29340, loss = 0.20, batch loss = 0.12 (35.6 examples/sec; 0.224 sec/batch; 18h:54m:11s remains)
INFO - root - 2017-12-17 04:38:23.319989: step 29350, loss = 0.19, batch loss = 0.12 (34.6 examples/sec; 0.232 sec/batch; 19h:29m:46s remains)
INFO - root - 2017-12-17 04:38:25.561699: step 29360, loss = 0.19, batch loss = 0.11 (37.3 examples/sec; 0.215 sec/batch; 18h:04m:31s remains)
INFO - root - 2017-12-17 04:38:27.851284: step 29370, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 19h:19m:22s remains)
INFO - root - 2017-12-17 04:38:30.156459: step 29380, loss = 0.24, batch loss = 0.17 (35.6 examples/sec; 0.225 sec/batch; 18h:55m:03s remains)
INFO - root - 2017-12-17 04:38:32.397434: step 29390, loss = 0.18, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 18h:30m:45s remains)
INFO - root - 2017-12-17 04:38:34.666502: step 29400, loss = 0.22, batch loss = 0.15 (34.6 examples/sec; 0.231 sec/batch; 19h:27m:56s remains)
INFO - root - 2017-12-17 04:38:37.055388: step 29410, loss = 0.22, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 19h:06m:48s remains)
INFO - root - 2017-12-17 04:38:39.296924: step 29420, loss = 0.21, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 18h:36m:35s remains)
INFO - root - 2017-12-17 04:38:41.590516: step 29430, loss = 0.23, batch loss = 0.15 (33.9 examples/sec; 0.236 sec/batch; 19h:51m:58s remains)
INFO - root - 2017-12-17 04:38:43.869170: step 29440, loss = 0.17, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 18h:49m:03s remains)
INFO - root - 2017-12-17 04:38:46.103399: step 29450, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 19h:06m:33s remains)
INFO - root - 2017-12-17 04:38:48.385584: step 29460, loss = 0.19, batch loss = 0.11 (36.8 examples/sec; 0.218 sec/batch; 18h:19m:15s remains)
INFO - root - 2017-12-17 04:38:50.646579: step 29470, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.226 sec/batch; 18h:59m:30s remains)
INFO - root - 2017-12-17 04:38:52.889712: step 29480, loss = 0.19, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 18h:56m:45s remains)
INFO - root - 2017-12-17 04:38:55.172094: step 29490, loss = 0.23, batch loss = 0.16 (35.5 examples/sec; 0.225 sec/batch; 18h:57m:27s remains)
INFO - root - 2017-12-17 04:38:57.422416: step 29500, loss = 0.17, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 18h:43m:54s remains)
INFO - root - 2017-12-17 04:38:59.804953: step 29510, loss = 0.19, batch loss = 0.12 (33.4 examples/sec; 0.240 sec/batch; 20h:10m:55s remains)
INFO - root - 2017-12-17 04:39:02.100025: step 29520, loss = 0.19, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 18h:32m:34s remains)
INFO - root - 2017-12-17 04:39:04.403626: step 29530, loss = 0.20, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 18h:32m:32s remains)
INFO - root - 2017-12-17 04:39:06.670927: step 29540, loss = 0.22, batch loss = 0.15 (36.1 examples/sec; 0.222 sec/batch; 18h:39m:56s remains)
INFO - root - 2017-12-17 04:39:08.942474: step 29550, loss = 0.23, batch loss = 0.16 (34.2 examples/sec; 0.234 sec/batch; 19h:41m:16s remains)
INFO - root - 2017-12-17 04:39:11.209219: step 29560, loss = 0.18, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 18h:25m:30s remains)
INFO - root - 2017-12-17 04:39:13.473051: step 29570, loss = 0.20, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 19h:20m:54s remains)
INFO - root - 2017-12-17 04:39:15.757384: step 29580, loss = 0.21, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 19h:28m:10s remains)
INFO - root - 2017-12-17 04:39:17.999760: step 29590, loss = 0.21, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 18h:53m:23s remains)
INFO - root - 2017-12-17 04:39:20.249433: step 29600, loss = 0.21, batch loss = 0.14 (34.5 examples/sec; 0.232 sec/batch; 19h:32m:00s remains)
INFO - root - 2017-12-17 04:39:22.657207: step 29610, loss = 0.18, batch loss = 0.10 (34.4 examples/sec; 0.233 sec/batch; 19h:35m:37s remains)
INFO - root - 2017-12-17 04:39:24.926867: step 29620, loss = 0.19, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 19h:15m:50s remains)
INFO - root - 2017-12-17 04:39:27.183038: step 29630, loss = 0.18, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 19h:25m:20s remains)
INFO - root - 2017-12-17 04:39:29.448424: step 29640, loss = 0.22, batch loss = 0.14 (34.7 examples/sec; 0.230 sec/batch; 19h:22m:42s remains)
INFO - root - 2017-12-17 04:39:31.684570: step 29650, loss = 0.20, batch loss = 0.13 (36.6 examples/sec; 0.218 sec/batch; 18h:22m:21s remains)
INFO - root - 2017-12-17 04:39:33.964865: step 29660, loss = 0.21, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 19h:19m:17s remains)
INFO - root - 2017-12-17 04:39:36.216490: step 29670, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 18h:55m:16s remains)
INFO - root - 2017-12-17 04:39:38.521471: step 29680, loss = 0.18, batch loss = 0.10 (35.8 examples/sec; 0.223 sec/batch; 18h:47m:26s remains)
INFO - root - 2017-12-17 04:39:40.793647: step 29690, loss = 0.20, batch loss = 0.12 (36.1 examples/sec; 0.222 sec/batch; 18h:38m:47s remains)
INFO - root - 2017-12-17 04:39:43.062022: step 29700, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 19h:00m:29s remains)
INFO - root - 2017-12-17 04:39:45.464292: step 29710, loss = 0.18, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 19h:20m:10s remains)
INFO - root - 2017-12-17 04:39:47.724507: step 29720, loss = 0.26, batch loss = 0.18 (35.2 examples/sec; 0.227 sec/batch; 19h:05m:40s remains)
INFO - root - 2017-12-17 04:39:49.976284: step 29730, loss = 0.20, batch loss = 0.12 (34.5 examples/sec; 0.232 sec/batch; 19h:29m:32s remains)
INFO - root - 2017-12-17 04:39:52.229052: step 29740, loss = 0.22, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 19h:06m:21s remains)
INFO - root - 2017-12-17 04:39:54.497453: step 29750, loss = 0.19, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 18h:45m:23s remains)
INFO - root - 2017-12-17 04:39:56.788900: step 29760, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:08m:25s remains)
INFO - root - 2017-12-17 04:39:59.116394: step 29770, loss = 0.24, batch loss = 0.17 (34.2 examples/sec; 0.234 sec/batch; 19h:40m:10s remains)
INFO - root - 2017-12-17 04:40:01.383108: step 29780, loss = 0.21, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 18h:45m:23s remains)
INFO - root - 2017-12-17 04:40:03.642466: step 29790, loss = 0.28, batch loss = 0.21 (36.0 examples/sec; 0.222 sec/batch; 18h:42m:06s remains)
INFO - root - 2017-12-17 04:40:05.905318: step 29800, loss = 0.18, batch loss = 0.11 (36.1 examples/sec; 0.221 sec/batch; 18h:37m:14s remains)
INFO - root - 2017-12-17 04:40:08.332082: step 29810, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:08m:15s remains)
INFO - root - 2017-12-17 04:40:10.588613: step 29820, loss = 0.17, batch loss = 0.10 (33.9 examples/sec; 0.236 sec/batch; 19h:49m:20s remains)
INFO - root - 2017-12-17 04:40:12.843223: step 29830, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 19h:17m:05s remains)
INFO - root - 2017-12-17 04:40:15.088293: step 29840, loss = 0.22, batch loss = 0.14 (35.0 examples/sec; 0.228 sec/batch; 19h:11m:55s remains)
INFO - root - 2017-12-17 04:40:17.330322: step 29850, loss = 0.21, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 18h:39m:21s remains)
INFO - root - 2017-12-17 04:40:19.595577: step 29860, loss = 0.19, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 19h:18m:44s remains)
INFO - root - 2017-12-17 04:40:21.857878: step 29870, loss = 0.20, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 18h:24m:59s remains)
INFO - root - 2017-12-17 04:40:24.154617: step 29880, loss = 0.20, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 18h:49m:39s remains)
INFO - root - 2017-12-17 04:40:26.423414: step 29890, loss = 0.16, batch loss = 0.08 (36.1 examples/sec; 0.222 sec/batch; 18h:37m:26s remains)
INFO - root - 2017-12-17 04:40:28.658087: step 29900, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 18h:36m:02s remains)
INFO - root - 2017-12-17 04:40:31.090170: step 29910, loss = 0.21, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 18h:30m:28s remains)
INFO - root - 2017-12-17 04:40:33.326403: step 29920, loss = 0.16, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 18h:22m:14s remains)
INFO - root - 2017-12-17 04:40:35.611579: step 29930, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:09m:34s remains)
INFO - root - 2017-12-17 04:40:37.865982: step 29940, loss = 0.23, batch loss = 0.16 (33.9 examples/sec; 0.236 sec/batch; 19h:49m:16s remains)
INFO - root - 2017-12-17 04:40:40.184375: step 29950, loss = 0.26, batch loss = 0.19 (34.4 examples/sec; 0.233 sec/batch; 19h:32m:42s remains)
INFO - root - 2017-12-17 04:40:42.482554: step 29960, loss = 0.17, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 19h:18m:53s remains)
INFO - root - 2017-12-17 04:40:44.736430: step 29970, loss = 0.21, batch loss = 0.14 (36.4 examples/sec; 0.220 sec/batch; 18h:29m:05s remains)
INFO - root - 2017-12-17 04:40:47.019282: step 29980, loss = 0.18, batch loss = 0.10 (33.4 examples/sec; 0.240 sec/batch; 20h:09m:10s remains)
INFO - root - 2017-12-17 04:40:49.305543: step 29990, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 19h:14m:33s remains)
INFO - root - 2017-12-17 04:40:51.608071: step 30000, loss = 0.19, batch loss = 0.12 (32.8 examples/sec; 0.244 sec/batch; 20h:31m:27s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-30000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-30000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 04:40:54.399735: step 30010, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:40m:50s remains)
INFO - root - 2017-12-17 04:40:56.670894: step 30020, loss = 0.22, batch loss = 0.14 (36.4 examples/sec; 0.220 sec/batch; 18h:27m:38s remains)
INFO - root - 2017-12-17 04:40:58.928496: step 30030, loss = 0.20, batch loss = 0.12 (34.0 examples/sec; 0.235 sec/batch; 19h:44m:53s remains)
INFO - root - 2017-12-17 04:41:01.218027: step 30040, loss = 0.20, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 19h:17m:17s remains)
INFO - root - 2017-12-17 04:41:03.509899: step 30050, loss = 0.19, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 19h:29m:26s remains)
INFO - root - 2017-12-17 04:41:05.793410: step 30060, loss = 0.16, batch loss = 0.08 (34.9 examples/sec; 0.229 sec/batch; 19h:16m:00s remains)
INFO - root - 2017-12-17 04:41:08.044746: step 30070, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 19h:00m:30s remains)
INFO - root - 2017-12-17 04:41:10.302506: step 30080, loss = 0.20, batch loss = 0.12 (34.5 examples/sec; 0.232 sec/batch; 19h:27m:35s remains)
INFO - root - 2017-12-17 04:41:12.555507: step 30090, loss = 0.23, batch loss = 0.15 (37.2 examples/sec; 0.215 sec/batch; 18h:05m:08s remains)
INFO - root - 2017-12-17 04:41:14.830055: step 30100, loss = 0.18, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 18h:24m:58s remains)
INFO - root - 2017-12-17 04:41:17.239713: step 30110, loss = 0.22, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 18h:40m:09s remains)
INFO - root - 2017-12-17 04:41:19.483720: step 30120, loss = 0.20, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:40m:39s remains)
INFO - root - 2017-12-17 04:41:21.775547: step 30130, loss = 0.17, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 19h:18m:47s remains)
INFO - root - 2017-12-17 04:41:24.013264: step 30140, loss = 0.25, batch loss = 0.18 (36.5 examples/sec; 0.219 sec/batch; 18h:23m:50s remains)
INFO - root - 2017-12-17 04:41:26.247743: step 30150, loss = 0.19, batch loss = 0.11 (36.9 examples/sec; 0.217 sec/batch; 18h:12m:53s remains)
INFO - root - 2017-12-17 04:41:28.538987: step 30160, loss = 0.20, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 19h:13m:42s remains)
INFO - root - 2017-12-17 04:41:30.832781: step 30170, loss = 0.19, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 19h:25m:36s remains)
INFO - root - 2017-12-17 04:41:33.103221: step 30180, loss = 0.28, batch loss = 0.21 (35.3 examples/sec; 0.226 sec/batch; 19h:01m:00s remains)
INFO - root - 2017-12-17 04:41:35.331865: step 30190, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 18h:55m:19s remains)
INFO - root - 2017-12-17 04:41:37.594955: step 30200, loss = 0.19, batch loss = 0.11 (33.8 examples/sec; 0.236 sec/batch; 19h:51m:26s remains)
INFO - root - 2017-12-17 04:41:39.966482: step 30210, loss = 0.21, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 18h:56m:03s remains)
INFO - root - 2017-12-17 04:41:42.217772: step 30220, loss = 0.22, batch loss = 0.15 (35.0 examples/sec; 0.228 sec/batch; 19h:10m:50s remains)
INFO - root - 2017-12-17 04:41:44.466189: step 30230, loss = 0.20, batch loss = 0.12 (34.5 examples/sec; 0.232 sec/batch; 19h:26m:42s remains)
INFO - root - 2017-12-17 04:41:46.721866: step 30240, loss = 0.17, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 19h:03m:54s remains)
INFO - root - 2017-12-17 04:41:49.062435: step 30250, loss = 0.19, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 19h:24m:30s remains)
INFO - root - 2017-12-17 04:41:51.377931: step 30260, loss = 0.19, batch loss = 0.12 (34.1 examples/sec; 0.235 sec/batch; 19h:43m:11s remains)
INFO - root - 2017-12-17 04:41:53.650151: step 30270, loss = 0.27, batch loss = 0.20 (35.0 examples/sec; 0.228 sec/batch; 19h:10m:28s remains)
INFO - root - 2017-12-17 04:41:55.907969: step 30280, loss = 0.21, batch loss = 0.14 (35.3 examples/sec; 0.227 sec/batch; 19h:02m:28s remains)
INFO - root - 2017-12-17 04:41:58.181405: step 30290, loss = 0.25, batch loss = 0.17 (34.5 examples/sec; 0.232 sec/batch; 19h:29m:31s remains)
INFO - root - 2017-12-17 04:42:00.443608: step 30300, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.223 sec/batch; 18h:45m:14s remains)
INFO - root - 2017-12-17 04:42:02.841984: step 30310, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:38m:27s remains)
INFO - root - 2017-12-17 04:42:05.104566: step 30320, loss = 0.16, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 18h:48m:46s remains)
INFO - root - 2017-12-17 04:42:07.345073: step 30330, loss = 0.20, batch loss = 0.13 (36.0 examples/sec; 0.223 sec/batch; 18h:40m:36s remains)
INFO - root - 2017-12-17 04:42:09.608653: step 30340, loss = 0.20, batch loss = 0.12 (33.7 examples/sec; 0.237 sec/batch; 19h:54m:00s remains)
INFO - root - 2017-12-17 04:42:11.892476: step 30350, loss = 0.18, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 19h:25m:44s remains)
INFO - root - 2017-12-17 04:42:14.182382: step 30360, loss = 0.19, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 19h:18m:52s remains)
INFO - root - 2017-12-17 04:42:16.452337: step 30370, loss = 0.19, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 18h:34m:10s remains)
INFO - root - 2017-12-17 04:42:18.716354: step 30380, loss = 0.20, batch loss = 0.12 (36.3 examples/sec; 0.221 sec/batch; 18h:30m:50s remains)
INFO - root - 2017-12-17 04:42:20.962100: step 30390, loss = 0.22, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 19h:17m:02s remains)
INFO - root - 2017-12-17 04:42:23.245723: step 30400, loss = 0.17, batch loss = 0.10 (33.5 examples/sec; 0.239 sec/batch; 20h:02m:23s remains)
INFO - root - 2017-12-17 04:42:25.680805: step 30410, loss = 0.20, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 18h:47m:43s remains)
INFO - root - 2017-12-17 04:42:27.916179: step 30420, loss = 0.18, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 18h:29m:06s remains)
INFO - root - 2017-12-17 04:42:30.182345: step 30430, loss = 0.18, batch loss = 0.10 (34.7 examples/sec; 0.231 sec/batch; 19h:21m:07s remains)
INFO - root - 2017-12-17 04:42:32.445156: step 30440, loss = 0.17, batch loss = 0.09 (36.7 examples/sec; 0.218 sec/batch; 18h:18m:34s remains)
INFO - root - 2017-12-17 04:42:34.732476: step 30450, loss = 0.21, batch loss = 0.13 (34.2 examples/sec; 0.234 sec/batch; 19h:39m:08s remains)
INFO - root - 2017-12-17 04:42:37.020336: step 30460, loss = 0.22, batch loss = 0.15 (35.8 examples/sec; 0.223 sec/batch; 18h:44m:23s remains)
INFO - root - 2017-12-17 04:42:39.262800: step 30470, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.223 sec/batch; 18h:44m:00s remains)
INFO - root - 2017-12-17 04:42:41.536418: step 30480, loss = 0.20, batch loss = 0.13 (33.9 examples/sec; 0.236 sec/batch; 19h:46m:12s remains)
INFO - root - 2017-12-17 04:42:43.800678: step 30490, loss = 0.24, batch loss = 0.16 (35.4 examples/sec; 0.226 sec/batch; 18h:56m:07s remains)
INFO - root - 2017-12-17 04:42:46.093154: step 30500, loss = 0.23, batch loss = 0.16 (34.6 examples/sec; 0.232 sec/batch; 19h:25m:22s remains)
INFO - root - 2017-12-17 04:42:48.499937: step 30510, loss = 0.20, batch loss = 0.12 (34.2 examples/sec; 0.234 sec/batch; 19h:35m:55s remains)
INFO - root - 2017-12-17 04:42:50.744406: step 30520, loss = 0.20, batch loss = 0.12 (35.8 examples/sec; 0.223 sec/batch; 18h:44m:37s remains)
INFO - root - 2017-12-17 04:42:53.011257: step 30530, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.223 sec/batch; 18h:44m:46s remains)
INFO - root - 2017-12-17 04:42:55.242438: step 30540, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 18h:53m:31s remains)
INFO - root - 2017-12-17 04:42:57.490466: step 30550, loss = 0.18, batch loss = 0.11 (35.0 examples/sec; 0.228 sec/batch; 19h:09m:25s remains)
INFO - root - 2017-12-17 04:42:59.732543: step 30560, loss = 0.22, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 18h:31m:38s remains)
INFO - root - 2017-12-17 04:43:01.969453: step 30570, loss = 0.18, batch loss = 0.10 (32.1 examples/sec; 0.249 sec/batch; 20h:53m:54s remains)
INFO - root - 2017-12-17 04:43:04.224898: step 30580, loss = 0.19, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 19h:01m:42s remains)
INFO - root - 2017-12-17 04:43:06.504562: step 30590, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.226 sec/batch; 18h:54m:57s remains)
INFO - root - 2017-12-17 04:43:08.787156: step 30600, loss = 0.17, batch loss = 0.10 (37.0 examples/sec; 0.216 sec/batch; 18h:09m:12s remains)
INFO - root - 2017-12-17 04:43:11.205153: step 30610, loss = 0.22, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 18h:40m:37s remains)
INFO - root - 2017-12-17 04:43:13.480569: step 30620, loss = 0.18, batch loss = 0.11 (34.4 examples/sec; 0.232 sec/batch; 19h:29m:41s remains)
INFO - root - 2017-12-17 04:43:15.734692: step 30630, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:58m:13s remains)
INFO - root - 2017-12-17 04:43:18.023241: step 30640, loss = 0.19, batch loss = 0.11 (36.6 examples/sec; 0.219 sec/batch; 18h:19m:45s remains)
INFO - root - 2017-12-17 04:43:20.280844: step 30650, loss = 0.21, batch loss = 0.14 (35.0 examples/sec; 0.229 sec/batch; 19h:09m:53s remains)
INFO - root - 2017-12-17 04:43:22.572582: step 30660, loss = 0.22, batch loss = 0.14 (31.9 examples/sec; 0.250 sec/batch; 20h:59m:42s remains)
INFO - root - 2017-12-17 04:43:24.848765: step 30670, loss = 0.21, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 18h:30m:12s remains)
INFO - root - 2017-12-17 04:43:27.095876: step 30680, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 18h:31m:17s remains)
INFO - root - 2017-12-17 04:43:29.360003: step 30690, loss = 0.22, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 18h:32m:19s remains)
INFO - root - 2017-12-17 04:43:31.608634: step 30700, loss = 0.25, batch loss = 0.18 (36.1 examples/sec; 0.222 sec/batch; 18h:34m:35s remains)
INFO - root - 2017-12-17 04:43:33.982091: step 30710, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 18h:50m:08s remains)
INFO - root - 2017-12-17 04:43:36.249261: step 30720, loss = 0.22, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 18h:37m:29s remains)
INFO - root - 2017-12-17 04:43:38.488453: step 30730, loss = 0.35, batch loss = 0.28 (35.8 examples/sec; 0.223 sec/batch; 18h:42m:42s remains)
INFO - root - 2017-12-17 04:43:40.729928: step 30740, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 19h:02m:48s remains)
INFO - root - 2017-12-17 04:43:42.989166: step 30750, loss = 0.24, batch loss = 0.16 (35.0 examples/sec; 0.229 sec/batch; 19h:11m:03s remains)
INFO - root - 2017-12-17 04:43:45.312684: step 30760, loss = 0.22, batch loss = 0.15 (33.8 examples/sec; 0.237 sec/batch; 19h:51m:35s remains)
INFO - root - 2017-12-17 04:43:47.549514: step 30770, loss = 0.23, batch loss = 0.15 (36.3 examples/sec; 0.220 sec/batch; 18h:27m:51s remains)
INFO - root - 2017-12-17 04:43:49.791039: step 30780, loss = 0.18, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 18h:28m:16s remains)
INFO - root - 2017-12-17 04:43:52.034356: step 30790, loss = 0.20, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 18h:49m:15s remains)
INFO - root - 2017-12-17 04:43:54.320568: step 30800, loss = 0.19, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 19h:12m:01s remains)
INFO - root - 2017-12-17 04:43:56.698197: step 30810, loss = 0.19, batch loss = 0.12 (37.0 examples/sec; 0.216 sec/batch; 18h:06m:21s remains)
INFO - root - 2017-12-17 04:43:59.002561: step 30820, loss = 0.21, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 18h:40m:07s remains)
INFO - root - 2017-12-17 04:44:01.263319: step 30830, loss = 0.21, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 18h:26m:32s remains)
INFO - root - 2017-12-17 04:44:03.528096: step 30840, loss = 0.20, batch loss = 0.12 (33.8 examples/sec; 0.237 sec/batch; 19h:49m:21s remains)
INFO - root - 2017-12-17 04:44:05.769923: step 30850, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 18h:53m:09s remains)
INFO - root - 2017-12-17 04:44:08.017818: step 30860, loss = 0.26, batch loss = 0.19 (36.7 examples/sec; 0.218 sec/batch; 18h:14m:51s remains)
INFO - root - 2017-12-17 04:44:10.294317: step 30870, loss = 0.19, batch loss = 0.12 (34.4 examples/sec; 0.233 sec/batch; 19h:28m:55s remains)
INFO - root - 2017-12-17 04:44:12.556020: step 30880, loss = 0.23, batch loss = 0.15 (34.9 examples/sec; 0.229 sec/batch; 19h:12m:02s remains)
INFO - root - 2017-12-17 04:44:14.810752: step 30890, loss = 0.17, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 19h:01m:11s remains)
INFO - root - 2017-12-17 04:44:17.042999: step 30900, loss = 0.18, batch loss = 0.10 (36.8 examples/sec; 0.218 sec/batch; 18h:13m:48s remains)
INFO - root - 2017-12-17 04:44:19.457477: step 30910, loss = 0.20, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:06m:49s remains)
INFO - root - 2017-12-17 04:44:21.716497: step 30920, loss = 0.16, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 18h:56m:58s remains)
INFO - root - 2017-12-17 04:44:24.001413: step 30930, loss = 0.19, batch loss = 0.12 (36.1 examples/sec; 0.221 sec/batch; 18h:32m:59s remains)
INFO - root - 2017-12-17 04:44:26.248243: step 30940, loss = 0.21, batch loss = 0.14 (36.1 examples/sec; 0.222 sec/batch; 18h:35m:17s remains)
INFO - root - 2017-12-17 04:44:28.489989: step 30950, loss = 0.20, batch loss = 0.13 (35.8 examples/sec; 0.224 sec/batch; 18h:44m:13s remains)
INFO - root - 2017-12-17 04:44:30.733320: step 30960, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:36m:16s remains)
INFO - root - 2017-12-17 04:44:32.998178: step 30970, loss = 0.17, batch loss = 0.09 (34.1 examples/sec; 0.235 sec/batch; 19h:40m:15s remains)
INFO - root - 2017-12-17 04:44:35.306568: step 30980, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:46m:29s remains)
INFO - root - 2017-12-17 04:44:37.595537: step 30990, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:37m:30s remains)
INFO - root - 2017-12-17 04:44:39.888241: step 31000, loss = 0.26, batch loss = 0.19 (36.1 examples/sec; 0.222 sec/batch; 18h:34m:52s remains)
INFO - root - 2017-12-17 04:44:42.301396: step 31010, loss = 0.17, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:44m:31s remains)
INFO - root - 2017-12-17 04:44:44.549277: step 31020, loss = 0.21, batch loss = 0.14 (35.3 examples/sec; 0.226 sec/batch; 18h:57m:07s remains)
INFO - root - 2017-12-17 04:44:46.798312: step 31030, loss = 0.20, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 19h:06m:08s remains)
INFO - root - 2017-12-17 04:44:49.094876: step 31040, loss = 0.21, batch loss = 0.13 (36.0 examples/sec; 0.223 sec/batch; 18h:38m:02s remains)
INFO - root - 2017-12-17 04:44:51.359123: step 31050, loss = 0.20, batch loss = 0.13 (33.8 examples/sec; 0.236 sec/batch; 19h:47m:37s remains)
INFO - root - 2017-12-17 04:44:53.622774: step 31060, loss = 0.20, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 19h:06m:49s remains)
INFO - root - 2017-12-17 04:44:55.899354: step 31070, loss = 0.18, batch loss = 0.10 (34.5 examples/sec; 0.232 sec/batch; 19h:25m:45s remains)
INFO - root - 2017-12-17 04:44:58.183579: step 31080, loss = 0.24, batch loss = 0.17 (35.0 examples/sec; 0.229 sec/batch; 19h:08m:33s remains)
INFO - root - 2017-12-17 04:45:00.424968: step 31090, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:54m:23s remains)
INFO - root - 2017-12-17 04:45:02.677867: step 31100, loss = 0.18, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 18h:24m:36s remains)
INFO - root - 2017-12-17 04:45:05.059846: step 31110, loss = 0.17, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 18h:42m:43s remains)
INFO - root - 2017-12-17 04:45:07.308431: step 31120, loss = 0.23, batch loss = 0.16 (36.6 examples/sec; 0.219 sec/batch; 18h:18m:47s remains)
INFO - root - 2017-12-17 04:45:09.592992: step 31130, loss = 0.17, batch loss = 0.10 (33.8 examples/sec; 0.237 sec/batch; 19h:48m:33s remains)
INFO - root - 2017-12-17 04:45:11.886367: step 31140, loss = 0.20, batch loss = 0.13 (33.6 examples/sec; 0.238 sec/batch; 19h:55m:42s remains)
INFO - root - 2017-12-17 04:45:14.142599: step 31150, loss = 0.17, batch loss = 0.10 (35.1 examples/sec; 0.228 sec/batch; 19h:03m:22s remains)
INFO - root - 2017-12-17 04:45:16.433385: step 31160, loss = 0.16, batch loss = 0.08 (34.5 examples/sec; 0.232 sec/batch; 19h:23m:00s remains)
INFO - root - 2017-12-17 04:45:18.715355: step 31170, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 18h:30m:52s remains)
INFO - root - 2017-12-17 04:45:20.972625: step 31180, loss = 0.20, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 19h:20m:39s remains)
INFO - root - 2017-12-17 04:45:23.226206: step 31190, loss = 0.21, batch loss = 0.14 (36.9 examples/sec; 0.217 sec/batch; 18h:09m:08s remains)
INFO - root - 2017-12-17 04:45:25.465118: step 31200, loss = 0.22, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 18h:40m:12s remains)
INFO - root - 2017-12-17 04:45:27.866046: step 31210, loss = 0.17, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 18h:34m:06s remains)
INFO - root - 2017-12-17 04:45:30.124075: step 31220, loss = 0.27, batch loss = 0.20 (36.5 examples/sec; 0.219 sec/batch; 18h:20m:57s remains)
INFO - root - 2017-12-17 04:45:32.404404: step 31230, loss = 0.16, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 18h:24m:39s remains)
INFO - root - 2017-12-17 04:45:34.662098: step 31240, loss = 0.21, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 18h:28m:17s remains)
INFO - root - 2017-12-17 04:45:36.921261: step 31250, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 18h:37m:40s remains)
INFO - root - 2017-12-17 04:45:39.204204: step 31260, loss = 0.19, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 18h:53m:16s remains)
INFO - root - 2017-12-17 04:45:41.464043: step 31270, loss = 0.21, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 18h:49m:42s remains)
INFO - root - 2017-12-17 04:45:43.721319: step 31280, loss = 0.20, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 18h:25m:59s remains)
INFO - root - 2017-12-17 04:45:45.980850: step 31290, loss = 0.18, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 18h:51m:49s remains)
INFO - root - 2017-12-17 04:45:48.247308: step 31300, loss = 0.21, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 19h:09m:32s remains)
INFO - root - 2017-12-17 04:45:50.679829: step 31310, loss = 0.21, batch loss = 0.14 (34.4 examples/sec; 0.233 sec/batch; 19h:28m:57s remains)
INFO - root - 2017-12-17 04:45:52.948808: step 31320, loss = 0.23, batch loss = 0.16 (35.5 examples/sec; 0.226 sec/batch; 18h:52m:09s remains)
INFO - root - 2017-12-17 04:45:55.243683: step 31330, loss = 0.22, batch loss = 0.15 (34.8 examples/sec; 0.230 sec/batch; 19h:13m:50s remains)
INFO - root - 2017-12-17 04:45:57.491566: step 31340, loss = 0.21, batch loss = 0.14 (36.9 examples/sec; 0.217 sec/batch; 18h:09m:05s remains)
INFO - root - 2017-12-17 04:45:59.739976: step 31350, loss = 0.22, batch loss = 0.15 (35.8 examples/sec; 0.224 sec/batch; 18h:41m:55s remains)
INFO - root - 2017-12-17 04:46:01.981879: step 31360, loss = 0.20, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 18h:30m:11s remains)
INFO - root - 2017-12-17 04:46:04.268958: step 31370, loss = 0.24, batch loss = 0.17 (34.8 examples/sec; 0.230 sec/batch; 19h:12m:48s remains)
INFO - root - 2017-12-17 04:46:06.530074: step 31380, loss = 0.18, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 18h:28m:28s remains)
INFO - root - 2017-12-17 04:46:08.779358: step 31390, loss = 0.18, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 18h:16m:50s remains)
INFO - root - 2017-12-17 04:46:11.033930: step 31400, loss = 0.22, batch loss = 0.15 (35.5 examples/sec; 0.225 sec/batch; 18h:50m:13s remains)
INFO - root - 2017-12-17 04:46:13.431233: step 31410, loss = 0.18, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 18h:37m:09s remains)
INFO - root - 2017-12-17 04:46:15.693424: step 31420, loss = 0.16, batch loss = 0.09 (35.2 examples/sec; 0.227 sec/batch; 18h:59m:45s remains)
INFO - root - 2017-12-17 04:46:18.009816: step 31430, loss = 0.21, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 19h:09m:55s remains)
INFO - root - 2017-12-17 04:46:20.289966: step 31440, loss = 0.20, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 18h:45m:21s remains)
INFO - root - 2017-12-17 04:46:22.557571: step 31450, loss = 0.20, batch loss = 0.12 (34.5 examples/sec; 0.232 sec/batch; 19h:22m:32s remains)
INFO - root - 2017-12-17 04:46:24.851177: step 31460, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.226 sec/batch; 18h:51m:30s remains)
INFO - root - 2017-12-17 04:46:27.098596: step 31470, loss = 0.21, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 18h:37m:22s remains)
INFO - root - 2017-12-17 04:46:29.353498: step 31480, loss = 0.23, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 18h:52m:53s remains)
INFO - root - 2017-12-17 04:46:31.623763: step 31490, loss = 0.26, batch loss = 0.19 (35.5 examples/sec; 0.226 sec/batch; 18h:51m:21s remains)
INFO - root - 2017-12-17 04:46:33.869973: step 31500, loss = 0.21, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 18h:25m:20s remains)
INFO - root - 2017-12-17 04:46:36.281827: step 31510, loss = 0.20, batch loss = 0.13 (33.8 examples/sec; 0.237 sec/batch; 19h:46m:46s remains)
INFO - root - 2017-12-17 04:46:38.576130: step 31520, loss = 0.23, batch loss = 0.15 (35.0 examples/sec; 0.229 sec/batch; 19h:07m:24s remains)
INFO - root - 2017-12-17 04:46:40.871357: step 31530, loss = 0.19, batch loss = 0.12 (32.9 examples/sec; 0.243 sec/batch; 20h:18m:37s remains)
INFO - root - 2017-12-17 04:46:43.141558: step 31540, loss = 0.21, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 18h:43m:19s remains)
INFO - root - 2017-12-17 04:46:45.408800: step 31550, loss = 0.22, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 18h:29m:00s remains)
INFO - root - 2017-12-17 04:46:47.634491: step 31560, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 18h:49m:10s remains)
INFO - root - 2017-12-17 04:46:49.871722: step 31570, loss = 0.20, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 18h:42m:27s remains)
INFO - root - 2017-12-17 04:46:52.117282: step 31580, loss = 0.18, batch loss = 0.11 (35.2 examples/sec; 0.227 sec/batch; 18h:59m:53s remains)
INFO - root - 2017-12-17 04:46:54.430389: step 31590, loss = 0.20, batch loss = 0.13 (33.8 examples/sec; 0.237 sec/batch; 19h:48m:45s remains)
INFO - root - 2017-12-17 04:46:56.706253: step 31600, loss = 0.21, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 18h:37m:11s remains)
INFO - root - 2017-12-17 04:46:59.097195: step 31610, loss = 0.22, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 18h:20m:20s remains)
INFO - root - 2017-12-17 04:47:01.337401: step 31620, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.223 sec/batch; 18h:40m:45s remains)
INFO - root - 2017-12-17 04:47:03.585485: step 31630, loss = 0.17, batch loss = 0.10 (34.6 examples/sec; 0.231 sec/batch; 19h:19m:14s remains)
INFO - root - 2017-12-17 04:47:05.845072: step 31640, loss = 0.21, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 19h:23m:56s remains)
INFO - root - 2017-12-17 04:47:08.163688: step 31650, loss = 0.22, batch loss = 0.14 (35.3 examples/sec; 0.226 sec/batch; 18h:55m:13s remains)
INFO - root - 2017-12-17 04:47:10.443146: step 31660, loss = 0.21, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 18h:31m:27s remains)
INFO - root - 2017-12-17 04:47:12.686980: step 31670, loss = 0.28, batch loss = 0.21 (35.6 examples/sec; 0.225 sec/batch; 18h:47m:01s remains)
INFO - root - 2017-12-17 04:47:14.925809: step 31680, loss = 0.21, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 18h:20m:06s remains)
INFO - root - 2017-12-17 04:47:17.169672: step 31690, loss = 0.17, batch loss = 0.10 (35.1 examples/sec; 0.228 sec/batch; 19h:01m:11s remains)
INFO - root - 2017-12-17 04:47:19.425652: step 31700, loss = 0.21, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 18h:33m:25s remains)
INFO - root - 2017-12-17 04:47:21.813308: step 31710, loss = 0.19, batch loss = 0.12 (34.1 examples/sec; 0.235 sec/batch; 19h:37m:37s remains)
INFO - root - 2017-12-17 04:47:24.075717: step 31720, loss = 0.17, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 18h:16m:37s remains)
INFO - root - 2017-12-17 04:47:26.325447: step 31730, loss = 0.25, batch loss = 0.18 (34.8 examples/sec; 0.230 sec/batch; 19h:13m:47s remains)
INFO - root - 2017-12-17 04:47:28.586397: step 31740, loss = 0.19, batch loss = 0.12 (36.1 examples/sec; 0.222 sec/batch; 18h:31m:02s remains)
INFO - root - 2017-12-17 04:47:30.814343: step 31750, loss = 0.20, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 18h:55m:26s remains)
INFO - root - 2017-12-17 04:47:33.080594: step 31760, loss = 0.17, batch loss = 0.10 (33.5 examples/sec; 0.239 sec/batch; 19h:56m:36s remains)
INFO - root - 2017-12-17 04:47:35.308390: step 31770, loss = 0.24, batch loss = 0.17 (34.4 examples/sec; 0.232 sec/batch; 19h:24m:40s remains)
INFO - root - 2017-12-17 04:47:37.559969: step 31780, loss = 0.18, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 18h:57m:04s remains)
INFO - root - 2017-12-17 04:47:39.831587: step 31790, loss = 0.17, batch loss = 0.10 (36.3 examples/sec; 0.221 sec/batch; 18h:25m:36s remains)
INFO - root - 2017-12-17 04:47:42.069759: step 31800, loss = 0.21, batch loss = 0.13 (33.8 examples/sec; 0.237 sec/batch; 19h:46m:50s remains)
INFO - root - 2017-12-17 04:47:44.489642: step 31810, loss = 0.20, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 19h:13m:05s remains)
INFO - root - 2017-12-17 04:47:46.748449: step 31820, loss = 0.23, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 18h:52m:04s remains)
INFO - root - 2017-12-17 04:47:49.038126: step 31830, loss = 0.21, batch loss = 0.14 (35.0 examples/sec; 0.229 sec/batch; 19h:05m:06s remains)
INFO - root - 2017-12-17 04:47:51.279273: step 31840, loss = 0.20, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 18h:19m:47s remains)
INFO - root - 2017-12-17 04:47:53.565880: step 31850, loss = 0.18, batch loss = 0.11 (35.2 examples/sec; 0.227 sec/batch; 18h:57m:13s remains)
INFO - root - 2017-12-17 04:47:55.830092: step 31860, loss = 0.16, batch loss = 0.09 (32.9 examples/sec; 0.243 sec/batch; 20h:17m:48s remains)
INFO - root - 2017-12-17 04:47:58.064843: step 31870, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 18h:42m:38s remains)
INFO - root - 2017-12-17 04:48:00.304854: step 31880, loss = 0.18, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 19h:15m:28s remains)
INFO - root - 2017-12-17 04:48:02.552559: step 31890, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.223 sec/batch; 18h:38m:19s remains)
INFO - root - 2017-12-17 04:48:04.824864: step 31900, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 18h:57m:13s remains)
INFO - root - 2017-12-17 04:48:07.277767: step 31910, loss = 0.22, batch loss = 0.15 (34.4 examples/sec; 0.232 sec/batch; 19h:24m:08s remains)
INFO - root - 2017-12-17 04:48:09.553282: step 31920, loss = 0.17, batch loss = 0.09 (36.6 examples/sec; 0.218 sec/batch; 18h:14m:21s remains)
INFO - root - 2017-12-17 04:48:11.785126: step 31930, loss = 0.23, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 18h:27m:45s remains)
INFO - root - 2017-12-17 04:48:14.070894: step 31940, loss = 0.20, batch loss = 0.12 (34.1 examples/sec; 0.235 sec/batch; 19h:36m:14s remains)
INFO - root - 2017-12-17 04:48:16.347581: step 31950, loss = 0.24, batch loss = 0.16 (35.3 examples/sec; 0.227 sec/batch; 18h:55m:19s remains)
INFO - root - 2017-12-17 04:48:18.609362: step 31960, loss = 0.28, batch loss = 0.21 (36.4 examples/sec; 0.219 sec/batch; 18h:19m:26s remains)
INFO - root - 2017-12-17 04:48:20.845618: step 31970, loss = 0.18, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 18h:26m:00s remains)
INFO - root - 2017-12-17 04:48:23.096549: step 31980, loss = 0.18, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 18h:18m:09s remains)
INFO - root - 2017-12-17 04:48:25.361091: step 31990, loss = 0.17, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 18h:31m:06s remains)
INFO - root - 2017-12-17 04:48:27.617431: step 32000, loss = 0.30, batch loss = 0.23 (34.9 examples/sec; 0.229 sec/batch; 19h:08m:31s remains)
INFO - root - 2017-12-17 04:48:30.059484: step 32010, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 18h:55m:11s remains)
INFO - root - 2017-12-17 04:48:32.322304: step 32020, loss = 0.17, batch loss = 0.10 (34.3 examples/sec; 0.233 sec/batch; 19h:27m:34s remains)
INFO - root - 2017-12-17 04:48:34.597929: step 32030, loss = 0.21, batch loss = 0.14 (32.9 examples/sec; 0.244 sec/batch; 20h:19m:32s remains)
INFO - root - 2017-12-17 04:48:36.925154: step 32040, loss = 0.21, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 19h:20m:35s remains)
INFO - root - 2017-12-17 04:48:39.204469: step 32050, loss = 0.24, batch loss = 0.17 (33.9 examples/sec; 0.236 sec/batch; 19h:42m:11s remains)
INFO - root - 2017-12-17 04:48:41.460486: step 32060, loss = 0.23, batch loss = 0.16 (36.4 examples/sec; 0.220 sec/batch; 18h:21m:38s remains)
INFO - root - 2017-12-17 04:48:43.710512: step 32070, loss = 0.23, batch loss = 0.16 (33.8 examples/sec; 0.237 sec/batch; 19h:46m:20s remains)
INFO - root - 2017-12-17 04:48:45.986889: step 32080, loss = 0.26, batch loss = 0.18 (34.4 examples/sec; 0.233 sec/batch; 19h:24m:29s remains)
INFO - root - 2017-12-17 04:48:48.249527: step 32090, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:40m:55s remains)
INFO - root - 2017-12-17 04:48:50.496287: step 32100, loss = 0.25, batch loss = 0.18 (35.7 examples/sec; 0.224 sec/batch; 18h:43m:25s remains)
INFO - root - 2017-12-17 04:48:52.864114: step 32110, loss = 0.23, batch loss = 0.15 (35.8 examples/sec; 0.223 sec/batch; 18h:37m:30s remains)
INFO - root - 2017-12-17 04:48:55.120636: step 32120, loss = 0.17, batch loss = 0.10 (35.3 examples/sec; 0.226 sec/batch; 18h:53m:48s remains)
INFO - root - 2017-12-17 04:48:57.372465: step 32130, loss = 0.22, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 19h:15m:57s remains)
INFO - root - 2017-12-17 04:48:59.633187: step 32140, loss = 0.27, batch loss = 0.19 (36.2 examples/sec; 0.221 sec/batch; 18h:24m:52s remains)
INFO - root - 2017-12-17 04:49:01.901121: step 32150, loss = 0.19, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 19h:11m:22s remains)
INFO - root - 2017-12-17 04:49:04.174396: step 32160, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 18h:48m:13s remains)
INFO - root - 2017-12-17 04:49:06.460048: step 32170, loss = 0.21, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 19h:01m:36s remains)
INFO - root - 2017-12-17 04:49:08.708473: step 32180, loss = 0.23, batch loss = 0.16 (36.5 examples/sec; 0.219 sec/batch; 18h:15m:59s remains)
INFO - root - 2017-12-17 04:49:10.971731: step 32190, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:30m:43s remains)
INFO - root - 2017-12-17 04:49:13.253936: step 32200, loss = 0.19, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 18h:20m:39s remains)
INFO - root - 2017-12-17 04:49:15.632365: step 32210, loss = 0.19, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 19h:15m:55s remains)
INFO - root - 2017-12-17 04:49:17.876646: step 32220, loss = 0.22, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 18h:31m:00s remains)
INFO - root - 2017-12-17 04:49:20.137976: step 32230, loss = 0.23, batch loss = 0.15 (35.7 examples/sec; 0.224 sec/batch; 18h:40m:40s remains)
INFO - root - 2017-12-17 04:49:22.434628: step 32240, loss = 0.22, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 18h:59m:57s remains)
INFO - root - 2017-12-17 04:49:24.723932: step 32250, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 18h:44m:31s remains)
INFO - root - 2017-12-17 04:49:26.970854: step 32260, loss = 0.22, batch loss = 0.14 (35.3 examples/sec; 0.227 sec/batch; 18h:54m:17s remains)
INFO - root - 2017-12-17 04:49:29.253925: step 32270, loss = 0.18, batch loss = 0.11 (35.0 examples/sec; 0.229 sec/batch; 19h:05m:16s remains)
INFO - root - 2017-12-17 04:49:31.575433: step 32280, loss = 0.16, batch loss = 0.09 (35.5 examples/sec; 0.225 sec/batch; 18h:46m:13s remains)
INFO - root - 2017-12-17 04:49:33.867542: step 32290, loss = 0.17, batch loss = 0.10 (34.3 examples/sec; 0.233 sec/batch; 19h:28m:13s remains)
INFO - root - 2017-12-17 04:49:36.139261: step 32300, loss = 0.22, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 19h:06m:28s remains)
INFO - root - 2017-12-17 04:49:38.549314: step 32310, loss = 0.24, batch loss = 0.17 (35.4 examples/sec; 0.226 sec/batch; 18h:49m:17s remains)
INFO - root - 2017-12-17 04:49:40.816921: step 32320, loss = 0.20, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 19h:26m:15s remains)
INFO - root - 2017-12-17 04:49:43.102405: step 32330, loss = 0.20, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 19h:26m:07s remains)
INFO - root - 2017-12-17 04:49:45.368074: step 32340, loss = 0.18, batch loss = 0.10 (36.1 examples/sec; 0.221 sec/batch; 18h:28m:00s remains)
INFO - root - 2017-12-17 04:49:47.640777: step 32350, loss = 0.33, batch loss = 0.25 (35.5 examples/sec; 0.225 sec/batch; 18h:47m:18s remains)
INFO - root - 2017-12-17 04:49:49.866988: step 32360, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 19h:01m:44s remains)
INFO - root - 2017-12-17 04:49:52.119024: step 32370, loss = 0.23, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 18h:55m:36s remains)
INFO - root - 2017-12-17 04:49:54.392297: step 32380, loss = 0.20, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 19h:10m:53s remains)
INFO - root - 2017-12-17 04:49:56.692769: step 32390, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 18h:43m:10s remains)
INFO - root - 2017-12-17 04:49:58.930068: step 32400, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:32m:18s remains)
INFO - root - 2017-12-17 04:50:01.330312: step 32410, loss = 0.22, batch loss = 0.15 (36.8 examples/sec; 0.217 sec/batch; 18h:07m:35s remains)
INFO - root - 2017-12-17 04:50:03.585183: step 32420, loss = 0.25, batch loss = 0.18 (34.6 examples/sec; 0.231 sec/batch; 19h:17m:20s remains)
INFO - root - 2017-12-17 04:50:05.855118: step 32430, loss = 0.23, batch loss = 0.15 (34.2 examples/sec; 0.234 sec/batch; 19h:29m:55s remains)
INFO - root - 2017-12-17 04:50:08.156340: step 32440, loss = 0.20, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 18h:29m:18s remains)
INFO - root - 2017-12-17 04:50:10.429862: step 32450, loss = 0.21, batch loss = 0.14 (35.2 examples/sec; 0.227 sec/batch; 18h:55m:17s remains)
INFO - root - 2017-12-17 04:50:12.697740: step 32460, loss = 0.22, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 18h:30m:25s remains)
INFO - root - 2017-12-17 04:50:14.957430: step 32470, loss = 0.18, batch loss = 0.11 (35.8 examples/sec; 0.223 sec/batch; 18h:37m:23s remains)
INFO - root - 2017-12-17 04:50:17.244341: step 32480, loss = 0.22, batch loss = 0.15 (35.0 examples/sec; 0.228 sec/batch; 19h:01m:51s remains)
INFO - root - 2017-12-17 04:50:19.483099: step 32490, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:40m:38s remains)
INFO - root - 2017-12-17 04:50:21.723730: step 32500, loss = 0.20, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:30m:14s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-32500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-32500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 04:50:24.689014: step 32510, loss = 0.16, batch loss = 0.09 (34.2 examples/sec; 0.234 sec/batch; 19h:29m:57s remains)
INFO - root - 2017-12-17 04:50:26.966468: step 32520, loss = 0.17, batch loss = 0.10 (35.2 examples/sec; 0.228 sec/batch; 18h:57m:49s remains)
INFO - root - 2017-12-17 04:50:29.219581: step 32530, loss = 0.22, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 18h:25m:42s remains)
INFO - root - 2017-12-17 04:50:31.507439: step 32540, loss = 0.16, batch loss = 0.09 (33.5 examples/sec; 0.239 sec/batch; 19h:55m:33s remains)
INFO - root - 2017-12-17 04:50:33.747104: step 32550, loss = 0.27, batch loss = 0.20 (35.5 examples/sec; 0.225 sec/batch; 18h:47m:08s remains)
INFO - root - 2017-12-17 04:50:36.040627: step 32560, loss = 0.21, batch loss = 0.13 (34.7 examples/sec; 0.231 sec/batch; 19h:13m:20s remains)
INFO - root - 2017-12-17 04:50:38.288949: step 32570, loss = 0.26, batch loss = 0.18 (34.8 examples/sec; 0.230 sec/batch; 19h:09m:32s remains)
INFO - root - 2017-12-17 04:50:40.589738: step 32580, loss = 0.18, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 18h:51m:08s remains)
INFO - root - 2017-12-17 04:50:42.858121: step 32590, loss = 0.20, batch loss = 0.12 (35.3 examples/sec; 0.226 sec/batch; 18h:51m:25s remains)
INFO - root - 2017-12-17 04:50:45.085562: step 32600, loss = 0.19, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 18h:20m:56s remains)
INFO - root - 2017-12-17 04:50:47.457702: step 32610, loss = 0.19, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 19h:14m:07s remains)
INFO - root - 2017-12-17 04:50:49.721487: step 32620, loss = 0.19, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:39m:29s remains)
INFO - root - 2017-12-17 04:50:52.025582: step 32630, loss = 0.19, batch loss = 0.12 (33.3 examples/sec; 0.240 sec/batch; 20h:00m:26s remains)
INFO - root - 2017-12-17 04:50:54.304631: step 32640, loss = 0.20, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 18h:28m:42s remains)
INFO - root - 2017-12-17 04:50:56.568997: step 32650, loss = 0.24, batch loss = 0.16 (34.8 examples/sec; 0.230 sec/batch; 19h:09m:22s remains)
INFO - root - 2017-12-17 04:50:58.859411: step 32660, loss = 0.20, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 18h:53m:17s remains)
INFO - root - 2017-12-17 04:51:01.092855: step 32670, loss = 0.21, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 18h:23m:20s remains)
INFO - root - 2017-12-17 04:51:03.368293: step 32680, loss = 0.16, batch loss = 0.08 (35.6 examples/sec; 0.225 sec/batch; 18h:42m:26s remains)
INFO - root - 2017-12-17 04:51:05.622842: step 32690, loss = 0.23, batch loss = 0.15 (35.0 examples/sec; 0.228 sec/batch; 19h:00m:53s remains)
INFO - root - 2017-12-17 04:51:07.915894: step 32700, loss = 0.26, batch loss = 0.18 (34.6 examples/sec; 0.231 sec/batch; 19h:15m:49s remains)
INFO - root - 2017-12-17 04:51:10.297146: step 32710, loss = 0.18, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 18h:55m:38s remains)
INFO - root - 2017-12-17 04:51:12.552539: step 32720, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:49m:53s remains)
INFO - root - 2017-12-17 04:51:14.852430: step 32730, loss = 0.21, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 18h:48m:58s remains)
INFO - root - 2017-12-17 04:51:17.112130: step 32740, loss = 0.23, batch loss = 0.16 (35.9 examples/sec; 0.223 sec/batch; 18h:34m:12s remains)
INFO - root - 2017-12-17 04:51:19.375255: step 32750, loss = 0.21, batch loss = 0.14 (35.0 examples/sec; 0.229 sec/batch; 19h:02m:46s remains)
INFO - root - 2017-12-17 04:51:21.698267: step 32760, loss = 0.20, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 19h:00m:57s remains)
INFO - root - 2017-12-17 04:51:24.010219: step 32770, loss = 0.19, batch loss = 0.11 (36.3 examples/sec; 0.220 sec/batch; 18h:19m:53s remains)
INFO - root - 2017-12-17 04:51:26.245331: step 32780, loss = 0.23, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 18h:33m:30s remains)
INFO - root - 2017-12-17 04:51:28.512345: step 32790, loss = 0.18, batch loss = 0.10 (33.7 examples/sec; 0.237 sec/batch; 19h:45m:33s remains)
INFO - root - 2017-12-17 04:51:30.794037: step 32800, loss = 0.20, batch loss = 0.13 (33.9 examples/sec; 0.236 sec/batch; 19h:37m:58s remains)
INFO - root - 2017-12-17 04:51:33.195336: step 32810, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.223 sec/batch; 18h:35m:06s remains)
INFO - root - 2017-12-17 04:51:35.448939: step 32820, loss = 0.22, batch loss = 0.14 (35.5 examples/sec; 0.225 sec/batch; 18h:43m:58s remains)
INFO - root - 2017-12-17 04:51:37.717813: step 32830, loss = 0.19, batch loss = 0.12 (34.2 examples/sec; 0.234 sec/batch; 19h:28m:02s remains)
INFO - root - 2017-12-17 04:51:39.970322: step 32840, loss = 0.20, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 18h:30m:28s remains)
INFO - root - 2017-12-17 04:51:42.242776: step 32850, loss = 0.22, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 18h:29m:08s remains)
INFO - root - 2017-12-17 04:51:44.523271: step 32860, loss = 0.18, batch loss = 0.11 (36.6 examples/sec; 0.219 sec/batch; 18h:12m:40s remains)
INFO - root - 2017-12-17 04:51:46.766821: step 32870, loss = 0.21, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 19h:03m:15s remains)
INFO - root - 2017-12-17 04:51:49.039927: step 32880, loss = 0.16, batch loss = 0.09 (36.1 examples/sec; 0.221 sec/batch; 18h:25m:12s remains)
INFO - root - 2017-12-17 04:51:51.313528: step 32890, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 18h:47m:40s remains)
INFO - root - 2017-12-17 04:51:53.561495: step 32900, loss = 0.17, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 18h:23m:55s remains)
INFO - root - 2017-12-17 04:51:55.948178: step 32910, loss = 0.19, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 19h:11m:11s remains)
INFO - root - 2017-12-17 04:51:58.219844: step 32920, loss = 0.24, batch loss = 0.17 (35.6 examples/sec; 0.225 sec/batch; 18h:43m:10s remains)
INFO - root - 2017-12-17 04:52:00.459873: step 32930, loss = 0.22, batch loss = 0.15 (35.6 examples/sec; 0.224 sec/batch; 18h:40m:39s remains)
INFO - root - 2017-12-17 04:52:02.744179: step 32940, loss = 0.24, batch loss = 0.16 (34.7 examples/sec; 0.231 sec/batch; 19h:11m:47s remains)
INFO - root - 2017-12-17 04:52:04.980839: step 32950, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 18h:35m:58s remains)
INFO - root - 2017-12-17 04:52:07.255115: step 32960, loss = 0.17, batch loss = 0.09 (34.5 examples/sec; 0.232 sec/batch; 19h:17m:15s remains)
INFO - root - 2017-12-17 04:52:09.532725: step 32970, loss = 0.18, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 18h:50m:50s remains)
INFO - root - 2017-12-17 04:52:11.785703: step 32980, loss = 0.19, batch loss = 0.11 (34.4 examples/sec; 0.233 sec/batch; 19h:22m:27s remains)
INFO - root - 2017-12-17 04:52:14.058591: step 32990, loss = 0.19, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 18h:19m:00s remains)
INFO - root - 2017-12-17 04:52:16.320005: step 33000, loss = 0.20, batch loss = 0.12 (34.1 examples/sec; 0.234 sec/batch; 19h:29m:53s remains)
INFO - root - 2017-12-17 04:52:18.729771: step 33010, loss = 0.22, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 18h:55m:25s remains)
INFO - root - 2017-12-17 04:52:21.011045: step 33020, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 18h:31m:45s remains)
INFO - root - 2017-12-17 04:52:23.251914: step 33030, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:27m:38s remains)
INFO - root - 2017-12-17 04:52:25.502700: step 33040, loss = 0.22, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 18h:47m:22s remains)
INFO - root - 2017-12-17 04:52:27.782554: step 33050, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 18h:53m:35s remains)
INFO - root - 2017-12-17 04:52:30.036098: step 33060, loss = 0.19, batch loss = 0.12 (33.8 examples/sec; 0.237 sec/batch; 19h:40m:22s remains)
INFO - root - 2017-12-17 04:52:32.328309: step 33070, loss = 0.20, batch loss = 0.13 (34.7 examples/sec; 0.231 sec/batch; 19h:10m:36s remains)
INFO - root - 2017-12-17 04:52:34.599920: step 33080, loss = 0.21, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 18h:42m:42s remains)
INFO - root - 2017-12-17 04:52:36.851932: step 33090, loss = 0.16, batch loss = 0.09 (33.9 examples/sec; 0.236 sec/batch; 19h:38m:31s remains)
INFO - root - 2017-12-17 04:52:39.132401: step 33100, loss = 0.20, batch loss = 0.13 (33.9 examples/sec; 0.236 sec/batch; 19h:38m:10s remains)
INFO - root - 2017-12-17 04:52:41.570417: step 33110, loss = 0.18, batch loss = 0.11 (35.0 examples/sec; 0.229 sec/batch; 19h:01m:53s remains)
INFO - root - 2017-12-17 04:52:43.838416: step 33120, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 18h:53m:16s remains)
INFO - root - 2017-12-17 04:52:46.093652: step 33130, loss = 0.25, batch loss = 0.18 (34.9 examples/sec; 0.229 sec/batch; 19h:03m:13s remains)
INFO - root - 2017-12-17 04:52:48.342327: step 33140, loss = 0.23, batch loss = 0.15 (34.7 examples/sec; 0.231 sec/batch; 19h:10m:05s remains)
INFO - root - 2017-12-17 04:52:50.607580: step 33150, loss = 0.18, batch loss = 0.11 (34.1 examples/sec; 0.234 sec/batch; 19h:29m:44s remains)
INFO - root - 2017-12-17 04:52:52.845865: step 33160, loss = 0.20, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 19h:01m:46s remains)
INFO - root - 2017-12-17 04:52:55.102723: step 33170, loss = 0.23, batch loss = 0.16 (35.7 examples/sec; 0.224 sec/batch; 18h:38m:28s remains)
INFO - root - 2017-12-17 04:52:57.364778: step 33180, loss = 0.17, batch loss = 0.09 (34.6 examples/sec; 0.231 sec/batch; 19h:12m:51s remains)
INFO - root - 2017-12-17 04:52:59.636028: step 33190, loss = 0.19, batch loss = 0.11 (33.1 examples/sec; 0.241 sec/batch; 20h:04m:19s remains)
INFO - root - 2017-12-17 04:53:01.912457: step 33200, loss = 0.19, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 18h:32m:30s remains)
INFO - root - 2017-12-17 04:53:04.301646: step 33210, loss = 0.18, batch loss = 0.11 (36.3 examples/sec; 0.220 sec/batch; 18h:17m:58s remains)
INFO - root - 2017-12-17 04:53:06.558367: step 33220, loss = 0.18, batch loss = 0.11 (35.0 examples/sec; 0.228 sec/batch; 18h:59m:06s remains)
INFO - root - 2017-12-17 04:53:08.842855: step 33230, loss = 0.21, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 19h:13m:33s remains)
INFO - root - 2017-12-17 04:53:11.114300: step 33240, loss = 0.27, batch loss = 0.19 (35.6 examples/sec; 0.224 sec/batch; 18h:39m:40s remains)
INFO - root - 2017-12-17 04:53:13.430841: step 33250, loss = 0.18, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 18h:39m:50s remains)
INFO - root - 2017-12-17 04:53:15.678307: step 33260, loss = 0.19, batch loss = 0.11 (35.6 examples/sec; 0.224 sec/batch; 18h:39m:38s remains)
INFO - root - 2017-12-17 04:53:17.934158: step 33270, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 18h:48m:05s remains)
INFO - root - 2017-12-17 04:53:20.234185: step 33280, loss = 0.19, batch loss = 0.12 (34.4 examples/sec; 0.232 sec/batch; 19h:18m:19s remains)
INFO - root - 2017-12-17 04:53:22.501892: step 33290, loss = 0.17, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 18h:31m:15s remains)
INFO - root - 2017-12-17 04:53:24.752251: step 33300, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 19h:01m:29s remains)
INFO - root - 2017-12-17 04:53:27.122653: step 33310, loss = 0.23, batch loss = 0.15 (36.5 examples/sec; 0.219 sec/batch; 18h:11m:34s remains)
INFO - root - 2017-12-17 04:53:29.352998: step 33320, loss = 0.20, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 18h:22m:50s remains)
INFO - root - 2017-12-17 04:53:31.611236: step 33330, loss = 0.21, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 19h:22m:06s remains)
INFO - root - 2017-12-17 04:53:33.900982: step 33340, loss = 0.18, batch loss = 0.11 (36.3 examples/sec; 0.221 sec/batch; 18h:20m:06s remains)
INFO - root - 2017-12-17 04:53:36.177620: step 33350, loss = 0.17, batch loss = 0.09 (34.1 examples/sec; 0.235 sec/batch; 19h:30m:57s remains)
INFO - root - 2017-12-17 04:53:38.447274: step 33360, loss = 0.19, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 19h:12m:57s remains)
INFO - root - 2017-12-17 04:53:40.703009: step 33370, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 18h:40m:51s remains)
INFO - root - 2017-12-17 04:53:42.983477: step 33380, loss = 0.18, batch loss = 0.11 (34.0 examples/sec; 0.235 sec/batch; 19h:34m:01s remains)
INFO - root - 2017-12-17 04:53:45.270294: step 33390, loss = 0.20, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 18h:35m:24s remains)
INFO - root - 2017-12-17 04:53:47.525064: step 33400, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.224 sec/batch; 18h:35m:24s remains)
INFO - root - 2017-12-17 04:53:49.924389: step 33410, loss = 0.22, batch loss = 0.14 (36.7 examples/sec; 0.218 sec/batch; 18h:07m:06s remains)
INFO - root - 2017-12-17 04:53:52.169626: step 33420, loss = 0.20, batch loss = 0.13 (36.8 examples/sec; 0.217 sec/batch; 18h:04m:00s remains)
INFO - root - 2017-12-17 04:53:54.445607: step 33430, loss = 0.19, batch loss = 0.12 (35.3 examples/sec; 0.226 sec/batch; 18h:48m:04s remains)
INFO - root - 2017-12-17 04:53:56.702895: step 33440, loss = 0.22, batch loss = 0.14 (34.7 examples/sec; 0.231 sec/batch; 19h:09m:22s remains)
INFO - root - 2017-12-17 04:53:58.964887: step 33450, loss = 0.26, batch loss = 0.19 (36.0 examples/sec; 0.222 sec/batch; 18h:27m:31s remains)
INFO - root - 2017-12-17 04:54:01.223557: step 33460, loss = 0.27, batch loss = 0.20 (36.3 examples/sec; 0.220 sec/batch; 18h:18m:51s remains)
INFO - root - 2017-12-17 04:54:03.490844: step 33470, loss = 0.18, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:38m:04s remains)
INFO - root - 2017-12-17 04:54:05.762933: step 33480, loss = 0.18, batch loss = 0.10 (36.1 examples/sec; 0.221 sec/batch; 18h:23m:48s remains)
INFO - root - 2017-12-17 04:54:08.067339: step 33490, loss = 0.22, batch loss = 0.15 (35.8 examples/sec; 0.224 sec/batch; 18h:35m:06s remains)
INFO - root - 2017-12-17 04:54:10.357577: step 33500, loss = 0.22, batch loss = 0.15 (36.1 examples/sec; 0.221 sec/batch; 18h:23m:13s remains)
INFO - root - 2017-12-17 04:54:12.769509: step 33510, loss = 0.23, batch loss = 0.16 (34.7 examples/sec; 0.231 sec/batch; 19h:09m:17s remains)
INFO - root - 2017-12-17 04:54:15.055708: step 33520, loss = 0.18, batch loss = 0.11 (34.4 examples/sec; 0.232 sec/batch; 19h:17m:17s remains)
INFO - root - 2017-12-17 04:54:17.356262: step 33530, loss = 0.19, batch loss = 0.12 (34.4 examples/sec; 0.233 sec/batch; 19h:19m:05s remains)
INFO - root - 2017-12-17 04:54:19.611069: step 33540, loss = 0.20, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 18h:23m:47s remains)
INFO - root - 2017-12-17 04:54:21.872229: step 33550, loss = 0.34, batch loss = 0.26 (35.6 examples/sec; 0.224 sec/batch; 18h:38m:15s remains)
INFO - root - 2017-12-17 04:54:24.125784: step 33560, loss = 0.20, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 19h:05m:38s remains)
INFO - root - 2017-12-17 04:54:26.373821: step 33570, loss = 0.21, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 18h:59m:00s remains)
INFO - root - 2017-12-17 04:54:28.696773: step 33580, loss = 0.17, batch loss = 0.10 (34.7 examples/sec; 0.231 sec/batch; 19h:08m:52s remains)
INFO - root - 2017-12-17 04:54:30.921708: step 33590, loss = 0.18, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 18h:12m:02s remains)
INFO - root - 2017-12-17 04:54:33.158492: step 33600, loss = 0.27, batch loss = 0.20 (36.4 examples/sec; 0.220 sec/batch; 18h:15m:00s remains)
INFO - root - 2017-12-17 04:54:35.533597: step 33610, loss = 0.19, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 19h:04m:01s remains)
INFO - root - 2017-12-17 04:54:37.817774: step 33620, loss = 0.18, batch loss = 0.10 (35.0 examples/sec; 0.228 sec/batch; 18h:57m:49s remains)
INFO - root - 2017-12-17 04:54:40.110974: step 33630, loss = 0.27, batch loss = 0.20 (35.5 examples/sec; 0.225 sec/batch; 18h:41m:51s remains)
INFO - root - 2017-12-17 04:54:42.370949: step 33640, loss = 0.16, batch loss = 0.08 (37.1 examples/sec; 0.215 sec/batch; 17h:52m:40s remains)
INFO - root - 2017-12-17 04:54:44.610781: step 33650, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 19h:01m:27s remains)
INFO - root - 2017-12-17 04:54:46.845263: step 33660, loss = 0.17, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 18h:33m:57s remains)
INFO - root - 2017-12-17 04:54:49.133017: step 33670, loss = 0.18, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 18h:10m:21s remains)
INFO - root - 2017-12-17 04:54:51.364243: step 33680, loss = 0.23, batch loss = 0.15 (35.6 examples/sec; 0.225 sec/batch; 18h:39m:00s remains)
INFO - root - 2017-12-17 04:54:53.637046: step 33690, loss = 0.17, batch loss = 0.09 (34.8 examples/sec; 0.230 sec/batch; 19h:05m:41s remains)
INFO - root - 2017-12-17 04:54:55.899625: step 33700, loss = 0.25, batch loss = 0.18 (34.9 examples/sec; 0.229 sec/batch; 18h:59m:55s remains)
INFO - root - 2017-12-17 04:54:58.261211: step 33710, loss = 0.19, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 18h:16m:58s remains)
INFO - root - 2017-12-17 04:55:00.488116: step 33720, loss = 0.16, batch loss = 0.09 (35.8 examples/sec; 0.224 sec/batch; 18h:33m:33s remains)
INFO - root - 2017-12-17 04:55:02.790562: step 33730, loss = 0.21, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 19h:16m:18s remains)
INFO - root - 2017-12-17 04:55:05.053776: step 33740, loss = 0.22, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 18h:50m:52s remains)
INFO - root - 2017-12-17 04:55:07.347574: step 33750, loss = 0.21, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 18h:36m:04s remains)
INFO - root - 2017-12-17 04:55:09.642041: step 33760, loss = 0.23, batch loss = 0.16 (36.1 examples/sec; 0.221 sec/batch; 18h:22m:17s remains)
INFO - root - 2017-12-17 04:55:11.970157: step 33770, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 18h:53m:46s remains)
INFO - root - 2017-12-17 04:55:14.200381: step 33780, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 18h:34m:21s remains)
INFO - root - 2017-12-17 04:55:16.445375: step 33790, loss = 0.19, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 18h:09m:48s remains)
INFO - root - 2017-12-17 04:55:18.701274: step 33800, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:25m:40s remains)
INFO - root - 2017-12-17 04:55:21.102638: step 33810, loss = 0.26, batch loss = 0.19 (36.1 examples/sec; 0.222 sec/batch; 18h:23m:13s remains)
INFO - root - 2017-12-17 04:55:23.416505: step 33820, loss = 0.16, batch loss = 0.09 (33.3 examples/sec; 0.240 sec/batch; 19h:54m:57s remains)
INFO - root - 2017-12-17 04:55:25.699829: step 33830, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 18h:36m:02s remains)
INFO - root - 2017-12-17 04:55:27.953188: step 33840, loss = 0.32, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 18h:17m:08s remains)
INFO - root - 2017-12-17 04:55:30.191843: step 33850, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:43m:57s remains)
INFO - root - 2017-12-17 04:55:32.453196: step 33860, loss = 0.23, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 18h:20m:39s remains)
INFO - root - 2017-12-17 04:55:34.705482: step 33870, loss = 0.20, batch loss = 0.12 (32.6 examples/sec; 0.245 sec/batch; 20h:19m:46s remains)
INFO - root - 2017-12-17 04:55:36.968933: step 33880, loss = 0.17, batch loss = 0.10 (33.9 examples/sec; 0.236 sec/batch; 19h:35m:59s remains)
INFO - root - 2017-12-17 04:55:39.249575: step 33890, loss = 0.18, batch loss = 0.10 (35.0 examples/sec; 0.229 sec/batch; 18h:57m:42s remains)
INFO - root - 2017-12-17 04:55:41.568632: step 33900, loss = 0.18, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:54m:40s remains)
INFO - root - 2017-12-17 04:55:43.960552: step 33910, loss = 0.21, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 19h:15m:09s remains)
INFO - root - 2017-12-17 04:55:46.237535: step 33920, loss = 0.19, batch loss = 0.11 (36.8 examples/sec; 0.217 sec/batch; 18h:02m:13s remains)
INFO - root - 2017-12-17 04:55:48.511053: step 33930, loss = 0.24, batch loss = 0.17 (35.9 examples/sec; 0.223 sec/batch; 18h:27m:22s remains)
INFO - root - 2017-12-17 04:55:50.751286: step 33940, loss = 0.20, batch loss = 0.13 (35.3 examples/sec; 0.226 sec/batch; 18h:46m:45s remains)
INFO - root - 2017-12-17 04:55:53.039848: step 33950, loss = 0.19, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 19h:00m:19s remains)
INFO - root - 2017-12-17 04:55:55.292742: step 33960, loss = 0.20, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 18h:15m:13s remains)
INFO - root - 2017-12-17 04:55:57.548816: step 33970, loss = 0.16, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 18h:07m:56s remains)
INFO - root - 2017-12-17 04:55:59.782846: step 33980, loss = 0.22, batch loss = 0.15 (37.0 examples/sec; 0.216 sec/batch; 17h:56m:56s remains)
INFO - root - 2017-12-17 04:56:02.108288: step 33990, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 18h:37m:04s remains)
INFO - root - 2017-12-17 04:56:04.372848: step 34000, loss = 0.19, batch loss = 0.11 (36.1 examples/sec; 0.221 sec/batch; 18h:21m:54s remains)
INFO - root - 2017-12-17 04:56:06.765398: step 34010, loss = 0.17, batch loss = 0.10 (33.1 examples/sec; 0.242 sec/batch; 20h:03m:47s remains)
INFO - root - 2017-12-17 04:56:09.038821: step 34020, loss = 0.20, batch loss = 0.12 (35.5 examples/sec; 0.226 sec/batch; 18h:42m:21s remains)
INFO - root - 2017-12-17 04:56:11.364941: step 34030, loss = 0.19, batch loss = 0.12 (34.3 examples/sec; 0.233 sec/batch; 19h:18m:33s remains)
INFO - root - 2017-12-17 04:56:13.618456: step 34040, loss = 0.18, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:53m:35s remains)
INFO - root - 2017-12-17 04:56:15.916584: step 34050, loss = 0.18, batch loss = 0.10 (34.9 examples/sec; 0.230 sec/batch; 19h:01m:34s remains)
INFO - root - 2017-12-17 04:56:18.189787: step 34060, loss = 0.18, batch loss = 0.11 (33.5 examples/sec; 0.239 sec/batch; 19h:48m:54s remains)
INFO - root - 2017-12-17 04:56:20.487625: step 34070, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.228 sec/batch; 18h:51m:42s remains)
INFO - root - 2017-12-17 04:56:22.768496: step 34080, loss = 0.27, batch loss = 0.19 (33.5 examples/sec; 0.239 sec/batch; 19h:47m:59s remains)
INFO - root - 2017-12-17 04:56:25.041507: step 34090, loss = 0.21, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 18h:30m:13s remains)
INFO - root - 2017-12-17 04:56:27.291570: step 34100, loss = 0.20, batch loss = 0.13 (33.5 examples/sec; 0.239 sec/batch; 19h:49m:15s remains)
INFO - root - 2017-12-17 04:56:29.683051: step 34110, loss = 0.21, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 18h:14m:59s remains)
INFO - root - 2017-12-17 04:56:31.948540: step 34120, loss = 0.21, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 18h:27m:40s remains)
INFO - root - 2017-12-17 04:56:34.244313: step 34130, loss = 0.21, batch loss = 0.14 (35.3 examples/sec; 0.226 sec/batch; 18h:45m:36s remains)
INFO - root - 2017-12-17 04:56:36.499476: step 34140, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.223 sec/batch; 18h:29m:53s remains)
INFO - root - 2017-12-17 04:56:38.741178: step 34150, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 18h:50m:19s remains)
INFO - root - 2017-12-17 04:56:40.976427: step 34160, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.224 sec/batch; 18h:36m:00s remains)
INFO - root - 2017-12-17 04:56:43.249528: step 34170, loss = 0.18, batch loss = 0.10 (37.0 examples/sec; 0.216 sec/batch; 17h:54m:23s remains)
INFO - root - 2017-12-17 04:56:45.497758: step 34180, loss = 0.19, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 18h:14m:09s remains)
INFO - root - 2017-12-17 04:56:47.741475: step 34190, loss = 0.24, batch loss = 0.17 (36.1 examples/sec; 0.221 sec/batch; 18h:21m:11s remains)
INFO - root - 2017-12-17 04:56:49.993740: step 34200, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:42m:54s remains)
INFO - root - 2017-12-17 04:56:52.407665: step 34210, loss = 0.17, batch loss = 0.09 (35.2 examples/sec; 0.227 sec/batch; 18h:48m:19s remains)
INFO - root - 2017-12-17 04:56:54.702289: step 34220, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 18h:18m:46s remains)
INFO - root - 2017-12-17 04:56:56.988796: step 34230, loss = 0.22, batch loss = 0.15 (35.6 examples/sec; 0.225 sec/batch; 18h:37m:48s remains)
INFO - root - 2017-12-17 04:56:59.249224: step 34240, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 18h:32m:32s remains)
INFO - root - 2017-12-17 04:57:01.486378: step 34250, loss = 0.20, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 18h:12m:04s remains)
INFO - root - 2017-12-17 04:57:03.782249: step 34260, loss = 0.20, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 19h:07m:54s remains)
INFO - root - 2017-12-17 04:57:06.001514: step 34270, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:23m:21s remains)
INFO - root - 2017-12-17 04:57:08.252785: step 34280, loss = 0.19, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 18h:43m:01s remains)
INFO - root - 2017-12-17 04:57:10.512343: step 34290, loss = 0.20, batch loss = 0.12 (34.1 examples/sec; 0.234 sec/batch; 19h:24m:22s remains)
INFO - root - 2017-12-17 04:57:12.767497: step 34300, loss = 0.29, batch loss = 0.21 (35.9 examples/sec; 0.223 sec/batch; 18h:26m:55s remains)
INFO - root - 2017-12-17 04:57:15.146136: step 34310, loss = 0.20, batch loss = 0.12 (34.7 examples/sec; 0.230 sec/batch; 19h:04m:51s remains)
INFO - root - 2017-12-17 04:57:17.404027: step 34320, loss = 0.20, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 19h:02m:33s remains)
INFO - root - 2017-12-17 04:57:19.651866: step 34330, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 18h:18m:47s remains)
INFO - root - 2017-12-17 04:57:21.928762: step 34340, loss = 0.17, batch loss = 0.10 (35.5 examples/sec; 0.226 sec/batch; 18h:41m:21s remains)
INFO - root - 2017-12-17 04:57:24.202624: step 34350, loss = 0.19, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 18h:43m:28s remains)
INFO - root - 2017-12-17 04:57:26.458370: step 34360, loss = 0.26, batch loss = 0.19 (36.5 examples/sec; 0.219 sec/batch; 18h:10m:27s remains)
INFO - root - 2017-12-17 04:57:28.702546: step 34370, loss = 0.21, batch loss = 0.14 (35.5 examples/sec; 0.225 sec/batch; 18h:39m:23s remains)
INFO - root - 2017-12-17 04:57:30.965829: step 34380, loss = 0.21, batch loss = 0.13 (36.5 examples/sec; 0.219 sec/batch; 18h:09m:47s remains)
INFO - root - 2017-12-17 04:57:33.198018: step 34390, loss = 0.17, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:31m:57s remains)
INFO - root - 2017-12-17 04:57:35.436748: step 34400, loss = 0.19, batch loss = 0.12 (34.1 examples/sec; 0.234 sec/batch; 19h:24m:31s remains)
INFO - root - 2017-12-17 04:57:37.843332: step 34410, loss = 0.16, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 18h:31m:49s remains)
INFO - root - 2017-12-17 04:57:40.132241: step 34420, loss = 0.17, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 18h:35m:24s remains)
INFO - root - 2017-12-17 04:57:42.425873: step 34430, loss = 0.26, batch loss = 0.19 (35.0 examples/sec; 0.229 sec/batch; 18h:55m:41s remains)
INFO - root - 2017-12-17 04:57:44.666112: step 34440, loss = 0.19, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 19h:05m:36s remains)
INFO - root - 2017-12-17 04:57:46.903224: step 34450, loss = 0.18, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 18h:21m:13s remains)
INFO - root - 2017-12-17 04:57:49.166533: step 34460, loss = 0.22, batch loss = 0.15 (36.5 examples/sec; 0.219 sec/batch; 18h:09m:12s remains)
INFO - root - 2017-12-17 04:57:51.408580: step 34470, loss = 0.19, batch loss = 0.11 (36.6 examples/sec; 0.218 sec/batch; 18h:05m:14s remains)
INFO - root - 2017-12-17 04:57:53.677037: step 34480, loss = 0.16, batch loss = 0.09 (35.8 examples/sec; 0.223 sec/batch; 18h:29m:17s remains)
INFO - root - 2017-12-17 04:57:55.963566: step 34490, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 18h:31m:14s remains)
INFO - root - 2017-12-17 04:57:58.230996: step 34500, loss = 0.18, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 18h:21m:43s remains)
INFO - root - 2017-12-17 04:58:00.617301: step 34510, loss = 0.21, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 18h:45m:09s remains)
INFO - root - 2017-12-17 04:58:02.872944: step 34520, loss = 0.17, batch loss = 0.09 (36.8 examples/sec; 0.218 sec/batch; 18h:00m:47s remains)
INFO - root - 2017-12-17 04:58:05.110793: step 34530, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 18h:44m:57s remains)
INFO - root - 2017-12-17 04:58:07.389696: step 34540, loss = 0.23, batch loss = 0.15 (35.7 examples/sec; 0.224 sec/batch; 18h:33m:55s remains)
INFO - root - 2017-12-17 04:58:09.667366: step 34550, loss = 0.18, batch loss = 0.11 (33.9 examples/sec; 0.236 sec/batch; 19h:31m:08s remains)
INFO - root - 2017-12-17 04:58:11.923039: step 34560, loss = 0.18, batch loss = 0.11 (34.2 examples/sec; 0.234 sec/batch; 19h:20m:17s remains)
INFO - root - 2017-12-17 04:58:14.188167: step 34570, loss = 0.22, batch loss = 0.15 (34.4 examples/sec; 0.232 sec/batch; 19h:13m:30s remains)
INFO - root - 2017-12-17 04:58:16.438738: step 34580, loss = 0.21, batch loss = 0.14 (35.8 examples/sec; 0.223 sec/batch; 18h:28m:36s remains)
INFO - root - 2017-12-17 04:58:18.691880: step 34590, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 18h:30m:35s remains)
INFO - root - 2017-12-17 04:58:20.963298: step 34600, loss = 0.20, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 18h:50m:33s remains)
INFO - root - 2017-12-17 04:58:23.367825: step 34610, loss = 0.21, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 18h:56m:19s remains)
INFO - root - 2017-12-17 04:58:25.638954: step 34620, loss = 0.18, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 18h:21m:31s remains)
INFO - root - 2017-12-17 04:58:27.894849: step 34630, loss = 0.21, batch loss = 0.13 (33.8 examples/sec; 0.237 sec/batch; 19h:35m:12s remains)
INFO - root - 2017-12-17 04:58:30.142629: step 34640, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:23m:13s remains)
INFO - root - 2017-12-17 04:58:32.397880: step 34650, loss = 0.26, batch loss = 0.19 (35.6 examples/sec; 0.225 sec/batch; 18h:36m:45s remains)
INFO - root - 2017-12-17 04:58:34.663060: step 34660, loss = 0.20, batch loss = 0.13 (34.7 examples/sec; 0.230 sec/batch; 19h:03m:33s remains)
INFO - root - 2017-12-17 04:58:36.911352: step 34670, loss = 0.18, batch loss = 0.11 (34.3 examples/sec; 0.233 sec/batch; 19h:16m:41s remains)
INFO - root - 2017-12-17 04:58:39.187765: step 34680, loss = 0.20, batch loss = 0.13 (36.5 examples/sec; 0.219 sec/batch; 18h:07m:28s remains)
INFO - root - 2017-12-17 04:58:41.434254: step 34690, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:58m:42s remains)
INFO - root - 2017-12-17 04:58:43.731012: step 34700, loss = 0.18, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:49m:43s remains)
INFO - root - 2017-12-17 04:58:46.118113: step 34710, loss = 0.23, batch loss = 0.15 (36.1 examples/sec; 0.222 sec/batch; 18h:20m:44s remains)
INFO - root - 2017-12-17 04:58:48.382335: step 34720, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 18h:33m:00s remains)
INFO - root - 2017-12-17 04:58:50.620631: step 34730, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.226 sec/batch; 18h:43m:38s remains)
INFO - root - 2017-12-17 04:58:52.850485: step 34740, loss = 0.20, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 18h:52m:06s remains)
INFO - root - 2017-12-17 04:58:55.119852: step 34750, loss = 0.23, batch loss = 0.16 (34.8 examples/sec; 0.230 sec/batch; 18h:59m:37s remains)
INFO - root - 2017-12-17 04:58:57.373645: step 34760, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 18h:30m:23s remains)
INFO - root - 2017-12-17 04:58:59.609853: step 34770, loss = 0.19, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 18h:46m:52s remains)
INFO - root - 2017-12-17 04:59:01.844588: step 34780, loss = 0.26, batch loss = 0.19 (35.9 examples/sec; 0.223 sec/batch; 18h:26m:07s remains)
INFO - root - 2017-12-17 04:59:04.076495: step 34790, loss = 0.17, batch loss = 0.10 (35.0 examples/sec; 0.229 sec/batch; 18h:54m:20s remains)
INFO - root - 2017-12-17 04:59:06.374287: step 34800, loss = 0.16, batch loss = 0.09 (34.7 examples/sec; 0.230 sec/batch; 19h:03m:12s remains)
INFO - root - 2017-12-17 04:59:08.736960: step 34810, loss = 0.19, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 18h:25m:46s remains)
INFO - root - 2017-12-17 04:59:11.017520: step 34820, loss = 0.22, batch loss = 0.15 (33.4 examples/sec; 0.240 sec/batch; 19h:50m:03s remains)
INFO - root - 2017-12-17 04:59:13.315528: step 34830, loss = 0.18, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 18h:59m:32s remains)
INFO - root - 2017-12-17 04:59:15.546484: step 34840, loss = 0.19, batch loss = 0.11 (36.3 examples/sec; 0.220 sec/batch; 18h:12m:25s remains)
INFO - root - 2017-12-17 04:59:17.818281: step 34850, loss = 0.20, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 18h:17m:28s remains)
INFO - root - 2017-12-17 04:59:20.102340: step 34860, loss = 0.16, batch loss = 0.09 (33.9 examples/sec; 0.236 sec/batch; 19h:32m:06s remains)
INFO - root - 2017-12-17 04:59:22.363323: step 34870, loss = 0.21, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 18h:17m:38s remains)
INFO - root - 2017-12-17 04:59:24.615815: step 34880, loss = 0.20, batch loss = 0.12 (34.7 examples/sec; 0.231 sec/batch; 19h:04m:06s remains)
INFO - root - 2017-12-17 04:59:26.886274: step 34890, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:21m:31s remains)
INFO - root - 2017-12-17 04:59:29.113313: step 34900, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 18h:52m:48s remains)
INFO - root - 2017-12-17 04:59:31.466430: step 34910, loss = 0.22, batch loss = 0.15 (37.2 examples/sec; 0.215 sec/batch; 17h:46m:26s remains)
INFO - root - 2017-12-17 04:59:33.715503: step 34920, loss = 0.19, batch loss = 0.11 (34.0 examples/sec; 0.235 sec/batch; 19h:26m:54s remains)
INFO - root - 2017-12-17 04:59:36.015145: step 34930, loss = 0.21, batch loss = 0.14 (34.7 examples/sec; 0.230 sec/batch; 19h:01m:51s remains)
INFO - root - 2017-12-17 04:59:38.273154: step 34940, loss = 0.19, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 18h:02m:09s remains)
INFO - root - 2017-12-17 04:59:40.521909: step 34950, loss = 0.19, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 18h:36m:04s remains)
INFO - root - 2017-12-17 04:59:42.765586: step 34960, loss = 0.21, batch loss = 0.14 (34.0 examples/sec; 0.235 sec/batch; 19h:27m:11s remains)
INFO - root - 2017-12-17 04:59:45.038599: step 34970, loss = 0.25, batch loss = 0.17 (35.6 examples/sec; 0.225 sec/batch; 18h:35m:51s remains)
INFO - root - 2017-12-17 04:59:47.313094: step 34980, loss = 0.17, batch loss = 0.10 (34.3 examples/sec; 0.233 sec/batch; 19h:15m:16s remains)
INFO - root - 2017-12-17 04:59:49.579197: step 34990, loss = 0.20, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 18h:29m:54s remains)
INFO - root - 2017-12-17 04:59:51.844176: step 35000, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.226 sec/batch; 18h:38m:38s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-35000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-35000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 04:59:55.008162: step 35010, loss = 0.21, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 18h:12m:44s remains)
INFO - root - 2017-12-17 04:59:57.288196: step 35020, loss = 0.23, batch loss = 0.16 (37.1 examples/sec; 0.216 sec/batch; 17h:49m:05s remains)
INFO - root - 2017-12-17 04:59:59.563731: step 35030, loss = 0.18, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 19h:08m:20s remains)
INFO - root - 2017-12-17 05:00:01.788854: step 35040, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 18h:39m:38s remains)
INFO - root - 2017-12-17 05:00:04.057556: step 35050, loss = 0.20, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 19h:15m:45s remains)
INFO - root - 2017-12-17 05:00:06.314040: step 35060, loss = 0.17, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 18h:36m:29s remains)
INFO - root - 2017-12-17 05:00:08.668311: step 35070, loss = 0.19, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 19h:07m:33s remains)
INFO - root - 2017-12-17 05:00:10.926853: step 35080, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.226 sec/batch; 18h:42m:42s remains)
INFO - root - 2017-12-17 05:00:13.168136: step 35090, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:21m:37s remains)
INFO - root - 2017-12-17 05:00:15.475430: step 35100, loss = 0.22, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 18h:29m:36s remains)
INFO - root - 2017-12-17 05:00:17.868310: step 35110, loss = 0.19, batch loss = 0.11 (32.9 examples/sec; 0.243 sec/batch; 20h:03m:43s remains)
INFO - root - 2017-12-17 05:00:20.132614: step 35120, loss = 0.21, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 18h:53m:28s remains)
INFO - root - 2017-12-17 05:00:22.379888: step 35130, loss = 0.23, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 18h:16m:35s remains)
INFO - root - 2017-12-17 05:00:24.643001: step 35140, loss = 0.23, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 18h:20m:24s remains)
INFO - root - 2017-12-17 05:00:26.904629: step 35150, loss = 0.23, batch loss = 0.15 (36.4 examples/sec; 0.220 sec/batch; 18h:08m:52s remains)
INFO - root - 2017-12-17 05:00:29.179619: step 35160, loss = 0.22, batch loss = 0.15 (36.9 examples/sec; 0.217 sec/batch; 17h:54m:16s remains)
INFO - root - 2017-12-17 05:00:31.482520: step 35170, loss = 0.23, batch loss = 0.16 (35.8 examples/sec; 0.224 sec/batch; 18h:28m:36s remains)
INFO - root - 2017-12-17 05:00:33.770262: step 35180, loss = 0.19, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 18h:05m:44s remains)
INFO - root - 2017-12-17 05:00:36.026783: step 35190, loss = 0.18, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 18h:24m:04s remains)
INFO - root - 2017-12-17 05:00:38.319152: step 35200, loss = 0.23, batch loss = 0.16 (34.2 examples/sec; 0.234 sec/batch; 19h:18m:30s remains)
INFO - root - 2017-12-17 05:00:40.701470: step 35210, loss = 0.23, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 18h:13m:30s remains)
INFO - root - 2017-12-17 05:00:42.950810: step 35220, loss = 0.20, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 19h:06m:56s remains)
INFO - root - 2017-12-17 05:00:45.204651: step 35230, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:55m:46s remains)
INFO - root - 2017-12-17 05:00:47.529025: step 35240, loss = 0.18, batch loss = 0.10 (34.7 examples/sec; 0.230 sec/batch; 19h:00m:57s remains)
INFO - root - 2017-12-17 05:00:49.767409: step 35250, loss = 0.18, batch loss = 0.11 (35.0 examples/sec; 0.228 sec/batch; 18h:51m:15s remains)
INFO - root - 2017-12-17 05:00:52.013557: step 35260, loss = 0.20, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 18h:22m:48s remains)
INFO - root - 2017-12-17 05:00:54.267701: step 35270, loss = 0.21, batch loss = 0.14 (35.0 examples/sec; 0.228 sec/batch; 18h:51m:22s remains)
INFO - root - 2017-12-17 05:00:56.520016: step 35280, loss = 0.18, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 18h:36m:09s remains)
INFO - root - 2017-12-17 05:00:58.797166: step 35290, loss = 0.17, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 18h:30m:07s remains)
INFO - root - 2017-12-17 05:01:01.075021: step 35300, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:55m:13s remains)
INFO - root - 2017-12-17 05:01:03.524480: step 35310, loss = 0.19, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 19h:05m:28s remains)
INFO - root - 2017-12-17 05:01:05.822688: step 35320, loss = 0.24, batch loss = 0.17 (36.1 examples/sec; 0.222 sec/batch; 18h:18m:14s remains)
INFO - root - 2017-12-17 05:01:08.115383: step 35330, loss = 0.22, batch loss = 0.15 (33.7 examples/sec; 0.237 sec/batch; 19h:34m:31s remains)
INFO - root - 2017-12-17 05:01:10.387534: step 35340, loss = 0.16, batch loss = 0.09 (37.1 examples/sec; 0.215 sec/batch; 17h:47m:01s remains)
INFO - root - 2017-12-17 05:01:12.671376: step 35350, loss = 0.20, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 19h:04m:16s remains)
INFO - root - 2017-12-17 05:01:14.914127: step 35360, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 18h:36m:21s remains)
INFO - root - 2017-12-17 05:01:17.182503: step 35370, loss = 0.24, batch loss = 0.17 (33.5 examples/sec; 0.239 sec/batch; 19h:41m:33s remains)
INFO - root - 2017-12-17 05:01:19.460167: step 35380, loss = 0.21, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 18h:52m:23s remains)
INFO - root - 2017-12-17 05:01:21.710308: step 35390, loss = 0.19, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 18h:42m:59s remains)
INFO - root - 2017-12-17 05:01:23.991865: step 35400, loss = 0.18, batch loss = 0.11 (33.8 examples/sec; 0.236 sec/batch; 19h:30m:16s remains)
INFO - root - 2017-12-17 05:01:26.395799: step 35410, loss = 0.20, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 18h:59m:48s remains)
INFO - root - 2017-12-17 05:01:28.642116: step 35420, loss = 0.19, batch loss = 0.12 (36.6 examples/sec; 0.219 sec/batch; 18h:02m:29s remains)
INFO - root - 2017-12-17 05:01:30.921854: step 35430, loss = 0.18, batch loss = 0.10 (35.5 examples/sec; 0.226 sec/batch; 18h:37m:10s remains)
INFO - root - 2017-12-17 05:01:33.156375: step 35440, loss = 0.17, batch loss = 0.10 (34.0 examples/sec; 0.235 sec/batch; 19h:25m:16s remains)
INFO - root - 2017-12-17 05:01:35.384885: step 35450, loss = 0.21, batch loss = 0.13 (34.7 examples/sec; 0.231 sec/batch; 19h:01m:57s remains)
INFO - root - 2017-12-17 05:01:37.640258: step 35460, loss = 0.21, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 18h:28m:58s remains)
INFO - root - 2017-12-17 05:01:39.892684: step 35470, loss = 0.19, batch loss = 0.12 (33.8 examples/sec; 0.237 sec/batch; 19h:31m:27s remains)
INFO - root - 2017-12-17 05:01:42.174114: step 35480, loss = 0.20, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 18h:48m:14s remains)
INFO - root - 2017-12-17 05:01:44.435126: step 35490, loss = 0.18, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 19h:03m:12s remains)
INFO - root - 2017-12-17 05:01:46.694488: step 35500, loss = 0.20, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 18h:21m:08s remains)
INFO - root - 2017-12-17 05:01:49.118465: step 35510, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 18h:34m:40s remains)
INFO - root - 2017-12-17 05:01:51.365613: step 35520, loss = 0.23, batch loss = 0.16 (34.8 examples/sec; 0.230 sec/batch; 18h:57m:25s remains)
INFO - root - 2017-12-17 05:01:53.630548: step 35530, loss = 0.19, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 18h:44m:22s remains)
INFO - root - 2017-12-17 05:01:55.890929: step 35540, loss = 0.18, batch loss = 0.11 (36.3 examples/sec; 0.221 sec/batch; 18h:11m:23s remains)
INFO - root - 2017-12-17 05:01:58.156618: step 35550, loss = 0.22, batch loss = 0.15 (34.9 examples/sec; 0.229 sec/batch; 18h:54m:09s remains)
INFO - root - 2017-12-17 05:02:00.423809: step 35560, loss = 0.16, batch loss = 0.09 (34.1 examples/sec; 0.235 sec/batch; 19h:21m:02s remains)
INFO - root - 2017-12-17 05:02:02.701671: step 35570, loss = 0.24, batch loss = 0.16 (34.9 examples/sec; 0.229 sec/batch; 18h:53m:45s remains)
INFO - root - 2017-12-17 05:02:04.974055: step 35580, loss = 0.23, batch loss = 0.16 (34.3 examples/sec; 0.234 sec/batch; 19h:15m:49s remains)
INFO - root - 2017-12-17 05:02:07.306011: step 35590, loss = 0.20, batch loss = 0.12 (33.8 examples/sec; 0.237 sec/batch; 19h:31m:39s remains)
INFO - root - 2017-12-17 05:02:09.544107: step 35600, loss = 0.20, batch loss = 0.12 (37.8 examples/sec; 0.212 sec/batch; 17h:27m:13s remains)
INFO - root - 2017-12-17 05:02:11.925277: step 35610, loss = 0.17, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 18h:22m:21s remains)
INFO - root - 2017-12-17 05:02:14.196115: step 35620, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 18h:24m:00s remains)
INFO - root - 2017-12-17 05:02:16.447051: step 35630, loss = 0.21, batch loss = 0.13 (36.3 examples/sec; 0.221 sec/batch; 18h:11m:48s remains)
INFO - root - 2017-12-17 05:02:18.690994: step 35640, loss = 0.17, batch loss = 0.10 (36.8 examples/sec; 0.217 sec/batch; 17h:54m:31s remains)
INFO - root - 2017-12-17 05:02:20.966701: step 35650, loss = 0.19, batch loss = 0.11 (34.6 examples/sec; 0.232 sec/batch; 19h:05m:21s remains)
INFO - root - 2017-12-17 05:02:23.234570: step 35660, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 18h:22m:41s remains)
INFO - root - 2017-12-17 05:02:25.500136: step 35670, loss = 0.18, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 19h:01m:54s remains)
INFO - root - 2017-12-17 05:02:27.780015: step 35680, loss = 0.21, batch loss = 0.13 (34.2 examples/sec; 0.234 sec/batch; 19h:15m:43s remains)
INFO - root - 2017-12-17 05:02:30.025401: step 35690, loss = 0.19, batch loss = 0.11 (34.4 examples/sec; 0.233 sec/batch; 19h:10m:32s remains)
INFO - root - 2017-12-17 05:02:32.291094: step 35700, loss = 0.18, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 18h:56m:48s remains)
INFO - root - 2017-12-17 05:02:34.690773: step 35710, loss = 0.20, batch loss = 0.12 (33.9 examples/sec; 0.236 sec/batch; 19h:26m:48s remains)
INFO - root - 2017-12-17 05:02:36.942547: step 35720, loss = 0.22, batch loss = 0.15 (33.5 examples/sec; 0.239 sec/batch; 19h:39m:55s remains)
INFO - root - 2017-12-17 05:02:39.227619: step 35730, loss = 0.23, batch loss = 0.16 (33.5 examples/sec; 0.239 sec/batch; 19h:40m:51s remains)
INFO - root - 2017-12-17 05:02:41.525077: step 35740, loss = 0.18, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 18h:26m:08s remains)
INFO - root - 2017-12-17 05:02:43.765368: step 35750, loss = 0.23, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 18h:38m:41s remains)
INFO - root - 2017-12-17 05:02:46.026428: step 35760, loss = 0.21, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 18h:27m:34s remains)
INFO - root - 2017-12-17 05:02:48.273123: step 35770, loss = 0.17, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 18h:13m:10s remains)
INFO - root - 2017-12-17 05:02:50.536399: step 35780, loss = 0.22, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 18h:36m:48s remains)
INFO - root - 2017-12-17 05:02:52.821166: step 35790, loss = 0.23, batch loss = 0.15 (34.1 examples/sec; 0.235 sec/batch; 19h:19m:56s remains)
INFO - root - 2017-12-17 05:02:55.077802: step 35800, loss = 0.20, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 18h:51m:51s remains)
INFO - root - 2017-12-17 05:02:57.483040: step 35810, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.224 sec/batch; 18h:26m:23s remains)
INFO - root - 2017-12-17 05:02:59.723722: step 35820, loss = 0.19, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 18h:06m:23s remains)
INFO - root - 2017-12-17 05:03:01.967736: step 35830, loss = 0.18, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 18h:38m:38s remains)
INFO - root - 2017-12-17 05:03:04.252802: step 35840, loss = 0.21, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 18h:12m:13s remains)
INFO - root - 2017-12-17 05:03:06.516386: step 35850, loss = 0.21, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 18h:13m:06s remains)
INFO - root - 2017-12-17 05:03:08.750236: step 35860, loss = 0.21, batch loss = 0.14 (36.7 examples/sec; 0.218 sec/batch; 17h:57m:52s remains)
INFO - root - 2017-12-17 05:03:11.013258: step 35870, loss = 0.18, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 19h:05m:39s remains)
INFO - root - 2017-12-17 05:03:13.247358: step 35880, loss = 0.20, batch loss = 0.13 (36.7 examples/sec; 0.218 sec/batch; 17h:56m:36s remains)
INFO - root - 2017-12-17 05:03:15.533747: step 35890, loss = 0.17, batch loss = 0.09 (36.1 examples/sec; 0.221 sec/batch; 18h:14m:51s remains)
INFO - root - 2017-12-17 05:03:17.834744: step 35900, loss = 0.29, batch loss = 0.22 (34.4 examples/sec; 0.232 sec/batch; 19h:08m:14s remains)
INFO - root - 2017-12-17 05:03:20.269410: step 35910, loss = 0.20, batch loss = 0.13 (34.7 examples/sec; 0.231 sec/batch; 19h:00m:00s remains)
INFO - root - 2017-12-17 05:03:22.531086: step 35920, loss = 0.18, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:47m:35s remains)
INFO - root - 2017-12-17 05:03:24.791970: step 35930, loss = 0.17, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 18h:03m:48s remains)
INFO - root - 2017-12-17 05:03:27.058083: step 35940, loss = 0.19, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 18h:37m:01s remains)
INFO - root - 2017-12-17 05:03:29.371725: step 35950, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.224 sec/batch; 18h:29m:28s remains)
INFO - root - 2017-12-17 05:03:31.636594: step 35960, loss = 0.18, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 18h:08m:41s remains)
INFO - root - 2017-12-17 05:03:33.918640: step 35970, loss = 0.20, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 18h:19m:06s remains)
INFO - root - 2017-12-17 05:03:36.184309: step 35980, loss = 0.24, batch loss = 0.16 (36.0 examples/sec; 0.222 sec/batch; 18h:18m:31s remains)
INFO - root - 2017-12-17 05:03:38.467979: step 35990, loss = 0.26, batch loss = 0.18 (33.8 examples/sec; 0.237 sec/batch; 19h:28m:45s remains)
INFO - root - 2017-12-17 05:03:40.719056: step 36000, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:26m:25s remains)
INFO - root - 2017-12-17 05:03:43.128374: step 36010, loss = 0.20, batch loss = 0.12 (34.1 examples/sec; 0.235 sec/batch; 19h:19m:21s remains)
INFO - root - 2017-12-17 05:03:45.392689: step 36020, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.229 sec/batch; 18h:49m:08s remains)
INFO - root - 2017-12-17 05:03:47.644279: step 36030, loss = 0.19, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 18h:35m:23s remains)
INFO - root - 2017-12-17 05:03:49.888272: step 36040, loss = 0.19, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 18h:35m:13s remains)
INFO - root - 2017-12-17 05:03:52.166101: step 36050, loss = 0.23, batch loss = 0.15 (34.6 examples/sec; 0.231 sec/batch; 19h:01m:30s remains)
INFO - root - 2017-12-17 05:03:54.436923: step 36060, loss = 0.20, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 18h:31m:39s remains)
INFO - root - 2017-12-17 05:03:56.714707: step 36070, loss = 0.18, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 18h:20m:04s remains)
INFO - root - 2017-12-17 05:03:58.994299: step 36080, loss = 0.21, batch loss = 0.14 (32.8 examples/sec; 0.244 sec/batch; 20h:05m:43s remains)
INFO - root - 2017-12-17 05:04:01.228376: step 36090, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 18h:27m:40s remains)
INFO - root - 2017-12-17 05:04:03.493540: step 36100, loss = 0.23, batch loss = 0.15 (36.8 examples/sec; 0.217 sec/batch; 17h:54m:08s remains)
INFO - root - 2017-12-17 05:04:05.868069: step 36110, loss = 0.19, batch loss = 0.11 (34.1 examples/sec; 0.235 sec/batch; 19h:19m:38s remains)
INFO - root - 2017-12-17 05:04:08.134603: step 36120, loss = 0.17, batch loss = 0.09 (34.4 examples/sec; 0.232 sec/batch; 19h:08m:14s remains)
INFO - root - 2017-12-17 05:04:10.371517: step 36130, loss = 0.22, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 18h:11m:45s remains)
INFO - root - 2017-12-17 05:04:12.623382: step 36140, loss = 0.22, batch loss = 0.15 (35.7 examples/sec; 0.224 sec/batch; 18h:27m:33s remains)
INFO - root - 2017-12-17 05:04:14.873791: step 36150, loss = 0.23, batch loss = 0.15 (36.4 examples/sec; 0.220 sec/batch; 18h:05m:22s remains)
INFO - root - 2017-12-17 05:04:17.126119: step 36160, loss = 0.23, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 18h:37m:33s remains)
INFO - root - 2017-12-17 05:04:19.385120: step 36170, loss = 0.18, batch loss = 0.10 (33.4 examples/sec; 0.239 sec/batch; 19h:41m:53s remains)
INFO - root - 2017-12-17 05:04:21.678070: step 36180, loss = 0.21, batch loss = 0.14 (34.4 examples/sec; 0.232 sec/batch; 19h:07m:23s remains)
INFO - root - 2017-12-17 05:04:23.945210: step 36190, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 18h:30m:39s remains)
INFO - root - 2017-12-17 05:04:26.166517: step 36200, loss = 0.23, batch loss = 0.16 (36.4 examples/sec; 0.220 sec/batch; 18h:04m:55s remains)
INFO - root - 2017-12-17 05:04:28.566696: step 36210, loss = 0.21, batch loss = 0.14 (35.3 examples/sec; 0.226 sec/batch; 18h:38m:08s remains)
INFO - root - 2017-12-17 05:04:30.791725: step 36220, loss = 0.18, batch loss = 0.11 (36.3 examples/sec; 0.220 sec/batch; 18h:07m:41s remains)
INFO - root - 2017-12-17 05:04:33.080553: step 36230, loss = 0.21, batch loss = 0.13 (36.8 examples/sec; 0.217 sec/batch; 17h:52m:08s remains)
INFO - root - 2017-12-17 05:04:35.370959: step 36240, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.226 sec/batch; 18h:33m:41s remains)
INFO - root - 2017-12-17 05:04:37.650562: step 36250, loss = 0.19, batch loss = 0.12 (33.6 examples/sec; 0.238 sec/batch; 19h:34m:53s remains)
INFO - root - 2017-12-17 05:04:39.982122: step 36260, loss = 0.17, batch loss = 0.10 (33.6 examples/sec; 0.238 sec/batch; 19h:36m:23s remains)
INFO - root - 2017-12-17 05:04:42.219146: step 36270, loss = 0.26, batch loss = 0.19 (34.7 examples/sec; 0.230 sec/batch; 18h:57m:16s remains)
INFO - root - 2017-12-17 05:04:44.480262: step 36280, loss = 0.22, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 19h:00m:35s remains)
INFO - root - 2017-12-17 05:04:46.721962: step 36290, loss = 0.18, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 19h:00m:51s remains)
INFO - root - 2017-12-17 05:04:49.032803: step 36300, loss = 0.22, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 18h:52m:08s remains)
INFO - root - 2017-12-17 05:04:51.507512: step 36310, loss = 0.19, batch loss = 0.11 (33.8 examples/sec; 0.237 sec/batch; 19h:28m:46s remains)
INFO - root - 2017-12-17 05:04:53.830088: step 36320, loss = 0.19, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 18h:36m:17s remains)
INFO - root - 2017-12-17 05:04:56.071307: step 36330, loss = 0.21, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 18h:41m:44s remains)
INFO - root - 2017-12-17 05:04:58.339039: step 36340, loss = 0.17, batch loss = 0.09 (36.1 examples/sec; 0.222 sec/batch; 18h:14m:53s remains)
INFO - root - 2017-12-17 05:05:00.600413: step 36350, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 18h:40m:12s remains)
INFO - root - 2017-12-17 05:05:02.886446: step 36360, loss = 0.23, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 18h:09m:55s remains)
INFO - root - 2017-12-17 05:05:05.141961: step 36370, loss = 0.21, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 18h:29m:12s remains)
INFO - root - 2017-12-17 05:05:07.409436: step 36380, loss = 0.20, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 18h:54m:53s remains)
INFO - root - 2017-12-17 05:05:09.715571: step 36390, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:26m:55s remains)
INFO - root - 2017-12-17 05:05:11.955576: step 36400, loss = 0.21, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 18h:20m:13s remains)
INFO - root - 2017-12-17 05:05:14.346048: step 36410, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 18h:22m:56s remains)
INFO - root - 2017-12-17 05:05:16.617403: step 36420, loss = 0.19, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 18h:02m:04s remains)
INFO - root - 2017-12-17 05:05:18.859042: step 36430, loss = 0.20, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 18h:51m:35s remains)
INFO - root - 2017-12-17 05:05:21.170236: step 36440, loss = 0.17, batch loss = 0.10 (34.1 examples/sec; 0.235 sec/batch; 19h:17m:46s remains)
INFO - root - 2017-12-17 05:05:23.454381: step 36450, loss = 0.20, batch loss = 0.13 (36.1 examples/sec; 0.221 sec/batch; 18h:12m:31s remains)
INFO - root - 2017-12-17 05:05:25.702833: step 36460, loss = 0.17, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 17h:59m:16s remains)
INFO - root - 2017-12-17 05:05:27.971060: step 36470, loss = 0.22, batch loss = 0.14 (36.6 examples/sec; 0.219 sec/batch; 17h:59m:14s remains)
INFO - root - 2017-12-17 05:05:30.211440: step 36480, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 18h:39m:47s remains)
INFO - root - 2017-12-17 05:05:32.502567: step 36490, loss = 0.20, batch loss = 0.13 (34.1 examples/sec; 0.234 sec/batch; 19h:16m:25s remains)
INFO - root - 2017-12-17 05:05:34.741172: step 36500, loss = 0.23, batch loss = 0.16 (36.0 examples/sec; 0.223 sec/batch; 18h:17m:41s remains)
INFO - root - 2017-12-17 05:05:37.097560: step 36510, loss = 0.18, batch loss = 0.11 (36.6 examples/sec; 0.219 sec/batch; 17h:59m:03s remains)
INFO - root - 2017-12-17 05:05:39.393204: step 36520, loss = 0.20, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 19h:10m:33s remains)
INFO - root - 2017-12-17 05:05:41.642034: step 36530, loss = 0.20, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 19h:03m:42s remains)
INFO - root - 2017-12-17 05:05:43.882616: step 36540, loss = 0.21, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 19h:01m:08s remains)
INFO - root - 2017-12-17 05:05:46.148576: step 36550, loss = 0.19, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 18h:59m:11s remains)
INFO - root - 2017-12-17 05:05:48.424762: step 36560, loss = 0.18, batch loss = 0.10 (34.9 examples/sec; 0.229 sec/batch; 18h:49m:03s remains)
INFO - root - 2017-12-17 05:05:50.692811: step 36570, loss = 0.21, batch loss = 0.14 (36.1 examples/sec; 0.222 sec/batch; 18h:14m:19s remains)
INFO - root - 2017-12-17 05:05:52.971517: step 36580, loss = 0.17, batch loss = 0.10 (34.4 examples/sec; 0.232 sec/batch; 19h:05m:50s remains)
INFO - root - 2017-12-17 05:05:55.246811: step 36590, loss = 0.20, batch loss = 0.13 (35.3 examples/sec; 0.226 sec/batch; 18h:36m:07s remains)
INFO - root - 2017-12-17 05:05:57.499381: step 36600, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 18h:24m:34s remains)
INFO - root - 2017-12-17 05:05:59.937958: step 36610, loss = 0.18, batch loss = 0.10 (34.3 examples/sec; 0.233 sec/batch; 19h:09m:18s remains)
INFO - root - 2017-12-17 05:06:02.208586: step 36620, loss = 0.20, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 18h:28m:40s remains)
INFO - root - 2017-12-17 05:06:04.471981: step 36630, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 18h:50m:49s remains)
INFO - root - 2017-12-17 05:06:06.772739: step 36640, loss = 0.25, batch loss = 0.18 (34.1 examples/sec; 0.235 sec/batch; 19h:16m:19s remains)
INFO - root - 2017-12-17 05:06:09.065800: step 36650, loss = 0.22, batch loss = 0.15 (34.1 examples/sec; 0.235 sec/batch; 19h:17m:37s remains)
INFO - root - 2017-12-17 05:06:11.311465: step 36660, loss = 0.21, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 19h:00m:56s remains)
INFO - root - 2017-12-17 05:06:13.567305: step 36670, loss = 0.21, batch loss = 0.13 (36.8 examples/sec; 0.217 sec/batch; 17h:52m:00s remains)
INFO - root - 2017-12-17 05:06:15.811709: step 36680, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 18h:31m:00s remains)
INFO - root - 2017-12-17 05:06:18.052755: step 36690, loss = 0.21, batch loss = 0.14 (34.7 examples/sec; 0.230 sec/batch; 18h:55m:54s remains)
INFO - root - 2017-12-17 05:06:20.310626: step 36700, loss = 0.16, batch loss = 0.08 (36.4 examples/sec; 0.220 sec/batch; 18h:03m:34s remains)
INFO - root - 2017-12-17 05:06:22.699844: step 36710, loss = 0.22, batch loss = 0.14 (36.4 examples/sec; 0.220 sec/batch; 18h:02m:09s remains)
INFO - root - 2017-12-17 05:06:24.984149: step 36720, loss = 0.18, batch loss = 0.11 (33.9 examples/sec; 0.236 sec/batch; 19h:21m:50s remains)
INFO - root - 2017-12-17 05:06:27.251586: step 36730, loss = 0.25, batch loss = 0.18 (33.5 examples/sec; 0.238 sec/batch; 19h:35m:29s remains)
INFO - root - 2017-12-17 05:06:29.504949: step 36740, loss = 0.21, batch loss = 0.14 (35.0 examples/sec; 0.229 sec/batch; 18h:47m:30s remains)
INFO - root - 2017-12-17 05:06:31.777613: step 36750, loss = 0.20, batch loss = 0.12 (34.3 examples/sec; 0.233 sec/batch; 19h:10m:52s remains)
INFO - root - 2017-12-17 05:06:34.060440: step 36760, loss = 0.28, batch loss = 0.21 (35.2 examples/sec; 0.227 sec/batch; 18h:39m:42s remains)
INFO - root - 2017-12-17 05:06:36.313680: step 36770, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 18h:28m:50s remains)
INFO - root - 2017-12-17 05:06:38.551830: step 36780, loss = 0.24, batch loss = 0.17 (35.7 examples/sec; 0.224 sec/batch; 18h:23m:30s remains)
INFO - root - 2017-12-17 05:06:40.787163: step 36790, loss = 0.21, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 18h:15m:06s remains)
INFO - root - 2017-12-17 05:06:43.033085: step 36800, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 18h:37m:04s remains)
INFO - root - 2017-12-17 05:06:45.427855: step 36810, loss = 0.19, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 17h:59m:53s remains)
INFO - root - 2017-12-17 05:06:47.699547: step 36820, loss = 0.23, batch loss = 0.15 (35.6 examples/sec; 0.224 sec/batch; 18h:25m:58s remains)
INFO - root - 2017-12-17 05:06:49.980649: step 36830, loss = 0.16, batch loss = 0.08 (34.9 examples/sec; 0.229 sec/batch; 18h:50m:43s remains)
INFO - root - 2017-12-17 05:06:52.277587: step 36840, loss = 0.22, batch loss = 0.15 (32.5 examples/sec; 0.246 sec/batch; 20h:13m:00s remains)
INFO - root - 2017-12-17 05:06:54.592046: step 36850, loss = 0.21, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 18h:05m:27s remains)
INFO - root - 2017-12-17 05:06:56.884172: step 36860, loss = 0.18, batch loss = 0.10 (34.1 examples/sec; 0.234 sec/batch; 19h:14m:27s remains)
INFO - root - 2017-12-17 05:06:59.180261: step 36870, loss = 0.18, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 17h:56m:38s remains)
INFO - root - 2017-12-17 05:07:01.444202: step 36880, loss = 0.21, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 18h:16m:38s remains)
INFO - root - 2017-12-17 05:07:03.693708: step 36890, loss = 0.20, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 18h:23m:57s remains)
INFO - root - 2017-12-17 05:07:05.942867: step 36900, loss = 0.16, batch loss = 0.09 (35.3 examples/sec; 0.227 sec/batch; 18h:35m:54s remains)
INFO - root - 2017-12-17 05:07:08.332599: step 36910, loss = 0.17, batch loss = 0.09 (35.5 examples/sec; 0.225 sec/batch; 18h:30m:49s remains)
INFO - root - 2017-12-17 05:07:10.596133: step 36920, loss = 0.15, batch loss = 0.08 (35.7 examples/sec; 0.224 sec/batch; 18h:24m:08s remains)
INFO - root - 2017-12-17 05:07:12.848250: step 36930, loss = 0.21, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 18h:58m:21s remains)
INFO - root - 2017-12-17 05:07:15.123381: step 36940, loss = 0.23, batch loss = 0.15 (36.5 examples/sec; 0.219 sec/batch; 18h:00m:31s remains)
INFO - root - 2017-12-17 05:07:17.393919: step 36950, loss = 0.17, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 18h:35m:51s remains)
INFO - root - 2017-12-17 05:07:19.637523: step 36960, loss = 0.18, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:41m:22s remains)
INFO - root - 2017-12-17 05:07:21.899603: step 36970, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 18h:29m:56s remains)
INFO - root - 2017-12-17 05:07:24.200774: step 36980, loss = 0.17, batch loss = 0.10 (34.0 examples/sec; 0.235 sec/batch; 19h:19m:05s remains)
INFO - root - 2017-12-17 05:07:26.456857: step 36990, loss = 0.23, batch loss = 0.16 (35.9 examples/sec; 0.223 sec/batch; 18h:18m:08s remains)
INFO - root - 2017-12-17 05:07:28.734852: step 37000, loss = 0.23, batch loss = 0.16 (35.7 examples/sec; 0.224 sec/batch; 18h:23m:49s remains)
INFO - root - 2017-12-17 05:07:31.127021: step 37010, loss = 0.21, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 18h:42m:40s remains)
INFO - root - 2017-12-17 05:07:33.387365: step 37020, loss = 0.19, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 18h:53m:13s remains)
INFO - root - 2017-12-17 05:07:35.691924: step 37030, loss = 0.25, batch loss = 0.18 (36.3 examples/sec; 0.220 sec/batch; 18h:04m:37s remains)
INFO - root - 2017-12-17 05:07:37.978555: step 37040, loss = 0.21, batch loss = 0.14 (31.8 examples/sec; 0.252 sec/batch; 20h:39m:59s remains)
INFO - root - 2017-12-17 05:07:40.231881: step 37050, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 18h:40m:06s remains)
INFO - root - 2017-12-17 05:07:42.593253: step 37060, loss = 0.18, batch loss = 0.11 (34.7 examples/sec; 0.230 sec/batch; 18h:54m:48s remains)
INFO - root - 2017-12-17 05:07:44.834103: step 37070, loss = 0.23, batch loss = 0.16 (34.5 examples/sec; 0.232 sec/batch; 19h:01m:04s remains)
INFO - root - 2017-12-17 05:07:47.104806: step 37080, loss = 0.18, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 18h:16m:55s remains)
INFO - root - 2017-12-17 05:07:49.380013: step 37090, loss = 0.18, batch loss = 0.10 (35.0 examples/sec; 0.229 sec/batch; 18h:46m:07s remains)
INFO - root - 2017-12-17 05:07:51.661616: step 37100, loss = 0.22, batch loss = 0.15 (34.9 examples/sec; 0.229 sec/batch; 18h:47m:40s remains)
INFO - root - 2017-12-17 05:07:54.089333: step 37110, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 18h:21m:06s remains)
INFO - root - 2017-12-17 05:07:56.335203: step 37120, loss = 0.22, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 18h:24m:28s remains)
INFO - root - 2017-12-17 05:07:58.614002: step 37130, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:48m:27s remains)
INFO - root - 2017-12-17 05:08:00.883174: step 37140, loss = 0.20, batch loss = 0.13 (34.7 examples/sec; 0.230 sec/batch; 18h:53m:54s remains)
INFO - root - 2017-12-17 05:08:03.127360: step 37150, loss = 0.20, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 17h:54m:28s remains)
INFO - root - 2017-12-17 05:08:05.378133: step 37160, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 18h:28m:57s remains)
INFO - root - 2017-12-17 05:08:07.621034: step 37170, loss = 0.26, batch loss = 0.19 (34.3 examples/sec; 0.233 sec/batch; 19h:06m:49s remains)
INFO - root - 2017-12-17 05:08:09.911555: step 37180, loss = 0.19, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:41m:55s remains)
INFO - root - 2017-12-17 05:08:12.189991: step 37190, loss = 0.17, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 18h:36m:53s remains)
INFO - root - 2017-12-17 05:08:14.436449: step 37200, loss = 0.17, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 18h:13m:14s remains)
INFO - root - 2017-12-17 05:08:16.870300: step 37210, loss = 0.18, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 18h:36m:35s remains)
INFO - root - 2017-12-17 05:08:19.142501: step 37220, loss = 0.22, batch loss = 0.15 (37.2 examples/sec; 0.215 sec/batch; 17h:37m:12s remains)
INFO - root - 2017-12-17 05:08:21.410030: step 37230, loss = 0.18, batch loss = 0.11 (33.8 examples/sec; 0.237 sec/batch; 19h:24m:30s remains)
INFO - root - 2017-12-17 05:08:23.678634: step 37240, loss = 0.29, batch loss = 0.21 (33.4 examples/sec; 0.239 sec/batch; 19h:37m:07s remains)
INFO - root - 2017-12-17 05:08:25.967012: step 37250, loss = 0.22, batch loss = 0.15 (37.1 examples/sec; 0.216 sec/batch; 17h:42m:15s remains)
INFO - root - 2017-12-17 05:08:28.278440: step 37260, loss = 0.19, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 18h:54m:55s remains)
INFO - root - 2017-12-17 05:08:30.535628: step 37270, loss = 0.18, batch loss = 0.10 (36.6 examples/sec; 0.218 sec/batch; 17h:54m:05s remains)
INFO - root - 2017-12-17 05:08:32.795186: step 37280, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:23m:44s remains)
INFO - root - 2017-12-17 05:08:35.042103: step 37290, loss = 0.22, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 17h:59m:06s remains)
INFO - root - 2017-12-17 05:08:37.348248: step 37300, loss = 0.18, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 18h:52m:38s remains)
INFO - root - 2017-12-17 05:08:39.752028: step 37310, loss = 0.21, batch loss = 0.13 (33.9 examples/sec; 0.236 sec/batch; 19h:20m:27s remains)
INFO - root - 2017-12-17 05:08:41.999723: step 37320, loss = 0.22, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 18h:17m:18s remains)
INFO - root - 2017-12-17 05:08:44.223444: step 37330, loss = 0.16, batch loss = 0.09 (35.6 examples/sec; 0.224 sec/batch; 18h:24m:08s remains)
INFO - root - 2017-12-17 05:08:46.478032: step 37340, loss = 0.22, batch loss = 0.15 (35.3 examples/sec; 0.227 sec/batch; 18h:35m:46s remains)
INFO - root - 2017-12-17 05:08:48.727747: step 37350, loss = 0.20, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 18h:36m:19s remains)
INFO - root - 2017-12-17 05:08:50.986679: step 37360, loss = 0.16, batch loss = 0.09 (37.7 examples/sec; 0.212 sec/batch; 17h:24m:45s remains)
INFO - root - 2017-12-17 05:08:53.223702: step 37370, loss = 0.30, batch loss = 0.23 (35.8 examples/sec; 0.223 sec/batch; 18h:17m:49s remains)
INFO - root - 2017-12-17 05:08:55.472315: step 37380, loss = 0.18, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 18h:28m:41s remains)
INFO - root - 2017-12-17 05:08:57.741286: step 37390, loss = 0.17, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 18h:15m:28s remains)
INFO - root - 2017-12-17 05:08:59.984092: step 37400, loss = 0.24, batch loss = 0.17 (36.0 examples/sec; 0.222 sec/batch; 18h:12m:17s remains)
INFO - root - 2017-12-17 05:09:02.393057: step 37410, loss = 0.22, batch loss = 0.15 (34.5 examples/sec; 0.232 sec/batch; 18h:59m:27s remains)
INFO - root - 2017-12-17 05:09:04.690233: step 37420, loss = 0.19, batch loss = 0.12 (33.9 examples/sec; 0.236 sec/batch; 19h:20m:47s remains)
INFO - root - 2017-12-17 05:09:06.920607: step 37430, loss = 0.24, batch loss = 0.17 (36.8 examples/sec; 0.217 sec/batch; 17h:49m:14s remains)
INFO - root - 2017-12-17 05:09:09.201115: step 37440, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.226 sec/batch; 18h:29m:34s remains)
INFO - root - 2017-12-17 05:09:11.476910: step 37450, loss = 0.18, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 18h:54m:52s remains)
INFO - root - 2017-12-17 05:09:13.738529: step 37460, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.223 sec/batch; 18h:18m:23s remains)
INFO - root - 2017-12-17 05:09:15.983325: step 37470, loss = 0.18, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 18h:15m:55s remains)
INFO - root - 2017-12-17 05:09:18.211554: step 37480, loss = 0.23, batch loss = 0.16 (36.4 examples/sec; 0.220 sec/batch; 18h:00m:55s remains)
INFO - root - 2017-12-17 05:09:20.490140: step 37490, loss = 0.18, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 18h:51m:42s remains)
INFO - root - 2017-12-17 05:09:22.759636: step 37500, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 18h:36m:26s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-37500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-37500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 05:09:25.651645: step 37510, loss = 0.23, batch loss = 0.16 (34.9 examples/sec; 0.229 sec/batch; 18h:45m:28s remains)
INFO - root - 2017-12-17 05:09:27.948780: step 37520, loss = 0.20, batch loss = 0.12 (34.7 examples/sec; 0.231 sec/batch; 18h:54m:28s remains)
INFO - root - 2017-12-17 05:09:30.180294: step 37530, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 18h:19m:30s remains)
INFO - root - 2017-12-17 05:09:32.453310: step 37540, loss = 0.22, batch loss = 0.15 (32.8 examples/sec; 0.244 sec/batch; 20h:00m:06s remains)
INFO - root - 2017-12-17 05:09:34.723513: step 37550, loss = 0.20, batch loss = 0.13 (36.8 examples/sec; 0.217 sec/batch; 17h:47m:25s remains)
INFO - root - 2017-12-17 05:09:36.967973: step 37560, loss = 0.18, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:38m:52s remains)
INFO - root - 2017-12-17 05:09:39.275480: step 37570, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.226 sec/batch; 18h:29m:02s remains)
INFO - root - 2017-12-17 05:09:41.573859: step 37580, loss = 0.21, batch loss = 0.13 (34.7 examples/sec; 0.231 sec/batch; 18h:54m:00s remains)
INFO - root - 2017-12-17 05:09:43.824432: step 37590, loss = 0.16, batch loss = 0.08 (36.3 examples/sec; 0.220 sec/batch; 18h:02m:47s remains)
INFO - root - 2017-12-17 05:09:46.126190: step 37600, loss = 0.19, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:41m:01s remains)
INFO - root - 2017-12-17 05:09:48.531896: step 37610, loss = 0.22, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 18h:39m:22s remains)
INFO - root - 2017-12-17 05:09:50.795694: step 37620, loss = 0.23, batch loss = 0.15 (35.3 examples/sec; 0.226 sec/batch; 18h:32m:58s remains)
INFO - root - 2017-12-17 05:09:53.070736: step 37630, loss = 0.23, batch loss = 0.15 (36.1 examples/sec; 0.222 sec/batch; 18h:10m:19s remains)
INFO - root - 2017-12-17 05:09:55.375788: step 37640, loss = 0.20, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 18h:21m:54s remains)
INFO - root - 2017-12-17 05:09:57.639652: step 37650, loss = 0.17, batch loss = 0.10 (34.7 examples/sec; 0.230 sec/batch; 18h:52m:26s remains)
INFO - root - 2017-12-17 05:09:59.897426: step 37660, loss = 0.18, batch loss = 0.11 (35.0 examples/sec; 0.228 sec/batch; 18h:41m:52s remains)
INFO - root - 2017-12-17 05:10:02.171382: step 37670, loss = 0.20, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 18h:55m:07s remains)
INFO - root - 2017-12-17 05:10:04.447347: step 37680, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 18h:24m:23s remains)
INFO - root - 2017-12-17 05:10:06.734853: step 37690, loss = 0.22, batch loss = 0.14 (33.0 examples/sec; 0.242 sec/batch; 19h:49m:40s remains)
INFO - root - 2017-12-17 05:10:08.983746: step 37700, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:45m:26s remains)
INFO - root - 2017-12-17 05:10:11.357005: step 37710, loss = 0.18, batch loss = 0.10 (35.0 examples/sec; 0.229 sec/batch; 18h:44m:13s remains)
INFO - root - 2017-12-17 05:10:13.641744: step 37720, loss = 0.19, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 18h:02m:20s remains)
INFO - root - 2017-12-17 05:10:15.908200: step 37730, loss = 0.21, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 18h:16m:36s remains)
INFO - root - 2017-12-17 05:10:18.173505: step 37740, loss = 0.20, batch loss = 0.12 (34.4 examples/sec; 0.232 sec/batch; 19h:01m:23s remains)
INFO - root - 2017-12-17 05:10:20.421520: step 37750, loss = 0.27, batch loss = 0.20 (35.2 examples/sec; 0.227 sec/batch; 18h:35m:13s remains)
INFO - root - 2017-12-17 05:10:22.712830: step 37760, loss = 0.18, batch loss = 0.11 (34.4 examples/sec; 0.232 sec/batch; 19h:01m:45s remains)
INFO - root - 2017-12-17 05:10:24.985916: step 37770, loss = 0.17, batch loss = 0.10 (35.3 examples/sec; 0.226 sec/batch; 18h:32m:23s remains)
INFO - root - 2017-12-17 05:10:27.250006: step 37780, loss = 0.19, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 17h:51m:33s remains)
INFO - root - 2017-12-17 05:10:29.559239: step 37790, loss = 0.26, batch loss = 0.19 (34.3 examples/sec; 0.233 sec/batch; 19h:05m:58s remains)
INFO - root - 2017-12-17 05:10:31.802332: step 37800, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 18h:31m:09s remains)
INFO - root - 2017-12-17 05:10:34.229609: step 37810, loss = 0.24, batch loss = 0.17 (36.4 examples/sec; 0.220 sec/batch; 17h:59m:34s remains)
INFO - root - 2017-12-17 05:10:36.511245: step 37820, loss = 0.21, batch loss = 0.14 (34.0 examples/sec; 0.235 sec/batch; 19h:16m:02s remains)
INFO - root - 2017-12-17 05:10:38.763175: step 37830, loss = 0.16, batch loss = 0.09 (34.6 examples/sec; 0.231 sec/batch; 18h:55m:03s remains)
INFO - root - 2017-12-17 05:10:41.032055: step 37840, loss = 0.17, batch loss = 0.10 (34.5 examples/sec; 0.232 sec/batch; 18h:59m:50s remains)
INFO - root - 2017-12-17 05:10:43.297559: step 37850, loss = 0.22, batch loss = 0.15 (34.2 examples/sec; 0.234 sec/batch; 19h:09m:28s remains)
INFO - root - 2017-12-17 05:10:45.601932: step 37860, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 18h:20m:43s remains)
INFO - root - 2017-12-17 05:10:47.833163: step 37870, loss = 0.19, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 17h:59m:36s remains)
INFO - root - 2017-12-17 05:10:50.080299: step 37880, loss = 0.26, batch loss = 0.19 (36.3 examples/sec; 0.220 sec/batch; 18h:00m:55s remains)
INFO - root - 2017-12-17 05:10:52.308097: step 37890, loss = 0.18, batch loss = 0.11 (36.3 examples/sec; 0.220 sec/batch; 18h:01m:53s remains)
INFO - root - 2017-12-17 05:10:54.601726: step 37900, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:46m:22s remains)
INFO - root - 2017-12-17 05:10:57.053502: step 37910, loss = 0.22, batch loss = 0.14 (34.2 examples/sec; 0.234 sec/batch; 19h:08m:47s remains)
INFO - root - 2017-12-17 05:10:59.352572: step 37920, loss = 0.25, batch loss = 0.18 (34.7 examples/sec; 0.231 sec/batch; 18h:51m:43s remains)
INFO - root - 2017-12-17 05:11:01.644105: step 37930, loss = 0.26, batch loss = 0.19 (36.1 examples/sec; 0.221 sec/batch; 18h:06m:39s remains)
INFO - root - 2017-12-17 05:11:03.941699: step 37940, loss = 0.18, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 18h:34m:18s remains)
INFO - root - 2017-12-17 05:11:06.217248: step 37950, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:18m:43s remains)
INFO - root - 2017-12-17 05:11:08.473829: step 37960, loss = 0.24, batch loss = 0.17 (35.5 examples/sec; 0.225 sec/batch; 18h:25m:48s remains)
INFO - root - 2017-12-17 05:11:10.768027: step 37970, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.224 sec/batch; 18h:21m:58s remains)
INFO - root - 2017-12-17 05:11:12.994439: step 37980, loss = 0.23, batch loss = 0.15 (36.6 examples/sec; 0.219 sec/batch; 17h:52m:35s remains)
INFO - root - 2017-12-17 05:11:15.258950: step 37990, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.224 sec/batch; 18h:17m:59s remains)
INFO - root - 2017-12-17 05:11:17.491963: step 38000, loss = 0.21, batch loss = 0.13 (35.8 examples/sec; 0.224 sec/batch; 18h:17m:59s remains)
INFO - root - 2017-12-17 05:11:19.870693: step 38010, loss = 0.16, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 18h:23m:12s remains)
INFO - root - 2017-12-17 05:11:22.091741: step 38020, loss = 0.20, batch loss = 0.12 (36.6 examples/sec; 0.219 sec/batch; 17h:52m:48s remains)
INFO - root - 2017-12-17 05:11:24.330131: step 38030, loss = 0.17, batch loss = 0.10 (37.9 examples/sec; 0.211 sec/batch; 17h:15m:33s remains)
INFO - root - 2017-12-17 05:11:26.589997: step 38040, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 18h:23m:27s remains)
INFO - root - 2017-12-17 05:11:28.826813: step 38050, loss = 0.17, batch loss = 0.10 (36.7 examples/sec; 0.218 sec/batch; 17h:49m:33s remains)
INFO - root - 2017-12-17 05:11:31.048186: step 38060, loss = 0.18, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:37m:03s remains)
INFO - root - 2017-12-17 05:11:33.275150: step 38070, loss = 0.16, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 18h:05m:04s remains)
INFO - root - 2017-12-17 05:11:35.512081: step 38080, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 18h:36m:05s remains)
INFO - root - 2017-12-17 05:11:37.788337: step 38090, loss = 0.24, batch loss = 0.17 (33.8 examples/sec; 0.236 sec/batch; 19h:19m:40s remains)
INFO - root - 2017-12-17 05:11:40.041066: step 38100, loss = 0.20, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 18h:41m:14s remains)
INFO - root - 2017-12-17 05:11:42.419908: step 38110, loss = 0.23, batch loss = 0.15 (36.8 examples/sec; 0.217 sec/batch; 17h:46m:41s remains)
INFO - root - 2017-12-17 05:11:44.668907: step 38120, loss = 0.19, batch loss = 0.11 (36.8 examples/sec; 0.217 sec/batch; 17h:45m:59s remains)
INFO - root - 2017-12-17 05:11:46.902446: step 38130, loss = 0.22, batch loss = 0.15 (36.9 examples/sec; 0.217 sec/batch; 17h:43m:36s remains)
INFO - root - 2017-12-17 05:11:49.124095: step 38140, loss = 0.23, batch loss = 0.15 (36.8 examples/sec; 0.217 sec/batch; 17h:45m:09s remains)
INFO - root - 2017-12-17 05:11:51.369889: step 38150, loss = 0.22, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 18h:00m:32s remains)
INFO - root - 2017-12-17 05:11:53.641887: step 38160, loss = 0.25, batch loss = 0.18 (34.3 examples/sec; 0.234 sec/batch; 19h:05m:29s remains)
INFO - root - 2017-12-17 05:11:55.897878: step 38170, loss = 0.19, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 18h:44m:23s remains)
INFO - root - 2017-12-17 05:11:58.158503: step 38180, loss = 0.18, batch loss = 0.11 (35.0 examples/sec; 0.229 sec/batch; 18h:40m:52s remains)
INFO - root - 2017-12-17 05:12:00.413410: step 38190, loss = 0.17, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 17h:59m:57s remains)
INFO - root - 2017-12-17 05:12:02.696697: step 38200, loss = 0.19, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 18h:55m:51s remains)
INFO - root - 2017-12-17 05:12:05.093817: step 38210, loss = 0.23, batch loss = 0.16 (35.4 examples/sec; 0.226 sec/batch; 18h:27m:13s remains)
INFO - root - 2017-12-17 05:12:07.339281: step 38220, loss = 0.18, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 18h:52m:13s remains)
INFO - root - 2017-12-17 05:12:09.603814: step 38230, loss = 0.19, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 18h:32m:33s remains)
INFO - root - 2017-12-17 05:12:11.819308: step 38240, loss = 0.18, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 18h:31m:56s remains)
INFO - root - 2017-12-17 05:12:14.073259: step 38250, loss = 0.18, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 18h:04m:31s remains)
INFO - root - 2017-12-17 05:12:16.317251: step 38260, loss = 0.25, batch loss = 0.17 (35.6 examples/sec; 0.224 sec/batch; 18h:20m:40s remains)
INFO - root - 2017-12-17 05:12:18.574576: step 38270, loss = 0.18, batch loss = 0.11 (34.1 examples/sec; 0.234 sec/batch; 19h:09m:55s remains)
INFO - root - 2017-12-17 05:12:20.854698: step 38280, loss = 0.22, batch loss = 0.15 (34.5 examples/sec; 0.232 sec/batch; 18h:55m:26s remains)
INFO - root - 2017-12-17 05:12:23.108460: step 38290, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 18h:44m:08s remains)
INFO - root - 2017-12-17 05:12:25.342668: step 38300, loss = 0.21, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 18h:06m:11s remains)
INFO - root - 2017-12-17 05:12:27.790312: step 38310, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 18h:28m:04s remains)
INFO - root - 2017-12-17 05:12:30.037646: step 38320, loss = 0.19, batch loss = 0.12 (34.2 examples/sec; 0.234 sec/batch; 19h:06m:19s remains)
INFO - root - 2017-12-17 05:12:32.309684: step 38330, loss = 0.20, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 17h:53m:50s remains)
INFO - root - 2017-12-17 05:12:34.575134: step 38340, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 18h:36m:09s remains)
INFO - root - 2017-12-17 05:12:36.882181: step 38350, loss = 0.17, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 18h:16m:29s remains)
INFO - root - 2017-12-17 05:12:39.130890: step 38360, loss = 0.17, batch loss = 0.10 (36.7 examples/sec; 0.218 sec/batch; 17h:47m:41s remains)
INFO - root - 2017-12-17 05:12:41.396996: step 38370, loss = 0.26, batch loss = 0.19 (35.8 examples/sec; 0.224 sec/batch; 18h:16m:26s remains)
INFO - root - 2017-12-17 05:12:43.652830: step 38380, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 18h:21m:50s remains)
INFO - root - 2017-12-17 05:12:45.906229: step 38390, loss = 0.22, batch loss = 0.14 (35.5 examples/sec; 0.226 sec/batch; 18h:25m:43s remains)
INFO - root - 2017-12-17 05:12:48.156277: step 38400, loss = 0.22, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 18h:52m:53s remains)
INFO - root - 2017-12-17 05:12:50.537609: step 38410, loss = 0.18, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 18h:07m:13s remains)
INFO - root - 2017-12-17 05:12:52.800410: step 38420, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:17m:21s remains)
INFO - root - 2017-12-17 05:12:55.065586: step 38430, loss = 0.17, batch loss = 0.09 (36.1 examples/sec; 0.222 sec/batch; 18h:06m:26s remains)
INFO - root - 2017-12-17 05:12:57.351306: step 38440, loss = 0.27, batch loss = 0.19 (36.8 examples/sec; 0.217 sec/batch; 17h:44m:48s remains)
INFO - root - 2017-12-17 05:12:59.670766: step 38450, loss = 0.23, batch loss = 0.15 (34.2 examples/sec; 0.234 sec/batch; 19h:04m:57s remains)
INFO - root - 2017-12-17 05:13:01.916992: step 38460, loss = 0.18, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 17h:54m:19s remains)
INFO - root - 2017-12-17 05:13:04.179757: step 38470, loss = 0.20, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:09m:15s remains)
INFO - root - 2017-12-17 05:13:06.465592: step 38480, loss = 0.19, batch loss = 0.12 (33.0 examples/sec; 0.242 sec/batch; 19h:47m:13s remains)
INFO - root - 2017-12-17 05:13:08.736788: step 38490, loss = 0.20, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 18h:39m:43s remains)
INFO - root - 2017-12-17 05:13:10.982731: step 38500, loss = 0.25, batch loss = 0.18 (36.6 examples/sec; 0.218 sec/batch; 17h:49m:41s remains)
INFO - root - 2017-12-17 05:13:13.376086: step 38510, loss = 0.18, batch loss = 0.11 (35.2 examples/sec; 0.227 sec/batch; 18h:33m:46s remains)
INFO - root - 2017-12-17 05:13:15.622613: step 38520, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 18h:20m:34s remains)
INFO - root - 2017-12-17 05:13:17.875786: step 38530, loss = 0.18, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 18h:31m:25s remains)
INFO - root - 2017-12-17 05:13:20.122767: step 38540, loss = 0.18, batch loss = 0.10 (35.1 examples/sec; 0.228 sec/batch; 18h:35m:35s remains)
INFO - root - 2017-12-17 05:13:22.356248: step 38550, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 18h:23m:58s remains)
INFO - root - 2017-12-17 05:13:24.642292: step 38560, loss = 0.23, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 18h:01m:44s remains)
INFO - root - 2017-12-17 05:13:26.917977: step 38570, loss = 0.23, batch loss = 0.16 (35.2 examples/sec; 0.227 sec/batch; 18h:33m:46s remains)
INFO - root - 2017-12-17 05:13:29.168829: step 38580, loss = 0.18, batch loss = 0.11 (36.6 examples/sec; 0.219 sec/batch; 17h:51m:32s remains)
INFO - root - 2017-12-17 05:13:31.429920: step 38590, loss = 0.23, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 18h:34m:53s remains)
INFO - root - 2017-12-17 05:13:33.685632: step 38600, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:43m:57s remains)
INFO - root - 2017-12-17 05:13:36.084717: step 38610, loss = 0.24, batch loss = 0.17 (36.4 examples/sec; 0.220 sec/batch; 17h:57m:39s remains)
INFO - root - 2017-12-17 05:13:38.321559: step 38620, loss = 0.20, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 18h:36m:18s remains)
INFO - root - 2017-12-17 05:13:40.556236: step 38630, loss = 0.20, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 18h:13m:34s remains)
INFO - root - 2017-12-17 05:13:42.820082: step 38640, loss = 0.20, batch loss = 0.12 (35.0 examples/sec; 0.229 sec/batch; 18h:39m:45s remains)
INFO - root - 2017-12-17 05:13:45.089545: step 38650, loss = 0.18, batch loss = 0.10 (35.5 examples/sec; 0.226 sec/batch; 18h:24m:24s remains)
INFO - root - 2017-12-17 05:13:47.356374: step 38660, loss = 0.17, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 18h:01m:13s remains)
INFO - root - 2017-12-17 05:13:49.608733: step 38670, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 18h:33m:53s remains)
INFO - root - 2017-12-17 05:13:51.846056: step 38680, loss = 0.23, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 18h:37m:19s remains)
INFO - root - 2017-12-17 05:13:54.098288: step 38690, loss = 0.21, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 18h:21m:41s remains)
INFO - root - 2017-12-17 05:13:56.351478: step 38700, loss = 0.17, batch loss = 0.10 (33.8 examples/sec; 0.236 sec/batch; 19h:17m:34s remains)
INFO - root - 2017-12-17 05:13:58.758264: step 38710, loss = 0.18, batch loss = 0.10 (34.9 examples/sec; 0.229 sec/batch; 18h:42m:42s remains)
INFO - root - 2017-12-17 05:14:01.075117: step 38720, loss = 0.17, batch loss = 0.10 (31.8 examples/sec; 0.252 sec/batch; 20h:33m:01s remains)
INFO - root - 2017-12-17 05:14:03.350566: step 38730, loss = 0.17, batch loss = 0.09 (36.1 examples/sec; 0.221 sec/batch; 18h:03m:48s remains)
INFO - root - 2017-12-17 05:14:05.603738: step 38740, loss = 0.19, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 18h:44m:25s remains)
INFO - root - 2017-12-17 05:14:07.846788: step 38750, loss = 0.22, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 17h:54m:26s remains)
INFO - root - 2017-12-17 05:14:10.127961: step 38760, loss = 0.23, batch loss = 0.16 (34.9 examples/sec; 0.229 sec/batch; 18h:42m:57s remains)
INFO - root - 2017-12-17 05:14:12.362196: step 38770, loss = 0.19, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 18h:10m:04s remains)
INFO - root - 2017-12-17 05:14:14.601513: step 38780, loss = 0.18, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 18h:11m:16s remains)
INFO - root - 2017-12-17 05:14:16.814451: step 38790, loss = 0.22, batch loss = 0.15 (36.3 examples/sec; 0.220 sec/batch; 17h:58m:28s remains)
INFO - root - 2017-12-17 05:14:19.066678: step 38800, loss = 0.18, batch loss = 0.10 (33.2 examples/sec; 0.241 sec/batch; 19h:37m:46s remains)
INFO - root - 2017-12-17 05:14:21.459868: step 38810, loss = 0.24, batch loss = 0.17 (35.6 examples/sec; 0.225 sec/batch; 18h:20m:09s remains)
INFO - root - 2017-12-17 05:14:23.696561: step 38820, loss = 0.23, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 18h:02m:32s remains)
INFO - root - 2017-12-17 05:14:25.987453: step 38830, loss = 0.18, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 18h:26m:55s remains)
INFO - root - 2017-12-17 05:14:28.253633: step 38840, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:25m:12s remains)
INFO - root - 2017-12-17 05:14:30.530020: step 38850, loss = 0.17, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 18h:25m:59s remains)
INFO - root - 2017-12-17 05:14:32.792625: step 38860, loss = 0.17, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 18h:45m:24s remains)
INFO - root - 2017-12-17 05:14:35.059081: step 38870, loss = 0.24, batch loss = 0.17 (35.1 examples/sec; 0.228 sec/batch; 18h:35m:52s remains)
INFO - root - 2017-12-17 05:14:37.325234: step 38880, loss = 0.19, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:07m:16s remains)
INFO - root - 2017-12-17 05:14:39.651090: step 38890, loss = 0.20, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 18h:16m:25s remains)
INFO - root - 2017-12-17 05:14:41.913499: step 38900, loss = 0.21, batch loss = 0.14 (36.9 examples/sec; 0.217 sec/batch; 17h:41m:42s remains)
INFO - root - 2017-12-17 05:14:44.344486: step 38910, loss = 0.17, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 18h:09m:21s remains)
INFO - root - 2017-12-17 05:14:46.581959: step 38920, loss = 0.20, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 17h:57m:41s remains)
INFO - root - 2017-12-17 05:14:48.848348: step 38930, loss = 0.20, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 18h:22m:24s remains)
INFO - root - 2017-12-17 05:14:51.122122: step 38940, loss = 0.23, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 18h:26m:18s remains)
INFO - root - 2017-12-17 05:14:53.417415: step 38950, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 18h:22m:08s remains)
INFO - root - 2017-12-17 05:14:55.700148: step 38960, loss = 0.25, batch loss = 0.18 (32.9 examples/sec; 0.243 sec/batch; 19h:48m:52s remains)
INFO - root - 2017-12-17 05:14:57.986495: step 38970, loss = 0.22, batch loss = 0.15 (36.4 examples/sec; 0.220 sec/batch; 17h:56m:20s remains)
INFO - root - 2017-12-17 05:15:00.280593: step 38980, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:05m:59s remains)
INFO - root - 2017-12-17 05:15:02.533733: step 38990, loss = 0.20, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 18h:29m:01s remains)
INFO - root - 2017-12-17 05:15:04.804830: step 39000, loss = 0.23, batch loss = 0.15 (36.9 examples/sec; 0.217 sec/batch; 17h:39m:20s remains)
INFO - root - 2017-12-17 05:15:07.221749: step 39010, loss = 0.24, batch loss = 0.17 (35.6 examples/sec; 0.225 sec/batch; 18h:20m:19s remains)
INFO - root - 2017-12-17 05:15:09.485949: step 39020, loss = 0.18, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 18h:13m:40s remains)
INFO - root - 2017-12-17 05:15:11.741666: step 39030, loss = 0.24, batch loss = 0.17 (36.3 examples/sec; 0.220 sec/batch; 17h:57m:31s remains)
INFO - root - 2017-12-17 05:15:13.992881: step 39040, loss = 0.19, batch loss = 0.12 (37.0 examples/sec; 0.216 sec/batch; 17h:37m:00s remains)
INFO - root - 2017-12-17 05:15:16.243585: step 39050, loss = 0.18, batch loss = 0.11 (34.7 examples/sec; 0.230 sec/batch; 18h:47m:15s remains)
INFO - root - 2017-12-17 05:15:18.517928: step 39060, loss = 0.22, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 18h:25m:31s remains)
INFO - root - 2017-12-17 05:15:20.796170: step 39070, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 18h:23m:55s remains)
INFO - root - 2017-12-17 05:15:23.066303: step 39080, loss = 0.21, batch loss = 0.13 (35.8 examples/sec; 0.224 sec/batch; 18h:13m:51s remains)
INFO - root - 2017-12-17 05:15:25.331571: step 39090, loss = 0.18, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 18h:05m:04s remains)
INFO - root - 2017-12-17 05:15:27.574918: step 39100, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 18h:20m:42s remains)
INFO - root - 2017-12-17 05:15:29.930758: step 39110, loss = 0.19, batch loss = 0.12 (36.6 examples/sec; 0.218 sec/batch; 17h:47m:30s remains)
INFO - root - 2017-12-17 05:15:32.231732: step 39120, loss = 0.17, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 18h:30m:59s remains)
INFO - root - 2017-12-17 05:15:34.505215: step 39130, loss = 0.19, batch loss = 0.11 (34.3 examples/sec; 0.233 sec/batch; 18h:59m:00s remains)
INFO - root - 2017-12-17 05:15:36.759271: step 39140, loss = 0.17, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 17h:49m:04s remains)
INFO - root - 2017-12-17 05:15:39.012922: step 39150, loss = 0.20, batch loss = 0.12 (34.3 examples/sec; 0.233 sec/batch; 19h:00m:22s remains)
INFO - root - 2017-12-17 05:15:41.277247: step 39160, loss = 0.19, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 18h:31m:42s remains)
INFO - root - 2017-12-17 05:15:43.529447: step 39170, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:26m:17s remains)
INFO - root - 2017-12-17 05:15:45.812673: step 39180, loss = 0.20, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 18h:14m:20s remains)
INFO - root - 2017-12-17 05:15:48.028032: step 39190, loss = 0.23, batch loss = 0.16 (34.9 examples/sec; 0.230 sec/batch; 18h:42m:01s remains)
INFO - root - 2017-12-17 05:15:50.281196: step 39200, loss = 0.21, batch loss = 0.14 (36.6 examples/sec; 0.219 sec/batch; 17h:48m:13s remains)
INFO - root - 2017-12-17 05:15:52.660249: step 39210, loss = 0.21, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 17h:55m:56s remains)
INFO - root - 2017-12-17 05:15:54.918355: step 39220, loss = 0.18, batch loss = 0.11 (35.0 examples/sec; 0.229 sec/batch; 18h:37m:30s remains)
INFO - root - 2017-12-17 05:15:57.202420: step 39230, loss = 0.24, batch loss = 0.16 (35.2 examples/sec; 0.227 sec/batch; 18h:31m:06s remains)
INFO - root - 2017-12-17 05:15:59.466179: step 39240, loss = 0.18, batch loss = 0.10 (34.9 examples/sec; 0.229 sec/batch; 18h:41m:21s remains)
INFO - root - 2017-12-17 05:16:01.720773: step 39250, loss = 0.23, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 18h:25m:34s remains)
INFO - root - 2017-12-17 05:16:03.980603: step 39260, loss = 0.19, batch loss = 0.12 (36.6 examples/sec; 0.219 sec/batch; 17h:49m:09s remains)
INFO - root - 2017-12-17 05:16:06.222498: step 39270, loss = 0.25, batch loss = 0.18 (35.6 examples/sec; 0.225 sec/batch; 18h:18m:56s remains)
INFO - root - 2017-12-17 05:16:08.501825: step 39280, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 18h:22m:53s remains)
INFO - root - 2017-12-17 05:16:10.805432: step 39290, loss = 0.21, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 18h:09m:59s remains)
INFO - root - 2017-12-17 05:16:13.084991: step 39300, loss = 0.18, batch loss = 0.11 (33.8 examples/sec; 0.237 sec/batch; 19h:15m:44s remains)
INFO - root - 2017-12-17 05:16:15.482573: step 39310, loss = 0.18, batch loss = 0.10 (32.6 examples/sec; 0.245 sec/batch; 19h:58m:34s remains)
INFO - root - 2017-12-17 05:16:17.727527: step 39320, loss = 0.17, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 17h:48m:29s remains)
INFO - root - 2017-12-17 05:16:19.968453: step 39330, loss = 0.17, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 17h:54m:35s remains)
INFO - root - 2017-12-17 05:16:22.262825: step 39340, loss = 0.23, batch loss = 0.15 (35.5 examples/sec; 0.226 sec/batch; 18h:22m:31s remains)
INFO - root - 2017-12-17 05:16:24.532893: step 39350, loss = 0.21, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 17h:59m:56s remains)
INFO - root - 2017-12-17 05:16:26.780817: step 39360, loss = 0.17, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 18h:05m:06s remains)
INFO - root - 2017-12-17 05:16:29.056492: step 39370, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 18h:27m:51s remains)
INFO - root - 2017-12-17 05:16:31.287354: step 39380, loss = 0.20, batch loss = 0.13 (36.6 examples/sec; 0.218 sec/batch; 17h:46m:46s remains)
INFO - root - 2017-12-17 05:16:33.577469: step 39390, loss = 0.18, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 17h:49m:49s remains)
INFO - root - 2017-12-17 05:16:35.827751: step 39400, loss = 0.19, batch loss = 0.12 (33.0 examples/sec; 0.243 sec/batch; 19h:45m:15s remains)
INFO - root - 2017-12-17 05:16:38.273873: step 39410, loss = 0.21, batch loss = 0.14 (34.7 examples/sec; 0.230 sec/batch; 18h:45m:27s remains)
INFO - root - 2017-12-17 05:16:40.548238: step 39420, loss = 0.22, batch loss = 0.15 (35.5 examples/sec; 0.226 sec/batch; 18h:21m:50s remains)
INFO - root - 2017-12-17 05:16:42.800088: step 39430, loss = 0.17, batch loss = 0.10 (35.8 examples/sec; 0.223 sec/batch; 18h:11m:09s remains)
INFO - root - 2017-12-17 05:16:45.068849: step 39440, loss = 0.18, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 18h:42m:59s remains)
INFO - root - 2017-12-17 05:16:47.337495: step 39450, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:13m:31s remains)
INFO - root - 2017-12-17 05:16:49.578134: step 39460, loss = 0.17, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 17h:54m:01s remains)
INFO - root - 2017-12-17 05:16:51.851162: step 39470, loss = 0.17, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 17h:59m:22s remains)
INFO - root - 2017-12-17 05:16:54.155382: step 39480, loss = 0.23, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 18h:33m:43s remains)
INFO - root - 2017-12-17 05:16:56.435810: step 39490, loss = 0.20, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 18h:43m:43s remains)
INFO - root - 2017-12-17 05:16:58.709881: step 39500, loss = 0.21, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 18h:17m:23s remains)
INFO - root - 2017-12-17 05:17:01.099285: step 39510, loss = 0.21, batch loss = 0.14 (37.1 examples/sec; 0.216 sec/batch; 17h:33m:17s remains)
INFO - root - 2017-12-17 05:17:03.367894: step 39520, loss = 0.25, batch loss = 0.17 (34.5 examples/sec; 0.232 sec/batch; 18h:53m:41s remains)
INFO - root - 2017-12-17 05:17:05.614407: step 39530, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 18h:35m:14s remains)
INFO - root - 2017-12-17 05:17:07.891718: step 39540, loss = 0.17, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 18h:18m:03s remains)
INFO - root - 2017-12-17 05:17:10.133178: step 39550, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 18h:19m:36s remains)
INFO - root - 2017-12-17 05:17:12.392039: step 39560, loss = 0.19, batch loss = 0.12 (36.1 examples/sec; 0.222 sec/batch; 18h:01m:54s remains)
INFO - root - 2017-12-17 05:17:14.678681: step 39570, loss = 0.18, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:33m:11s remains)
INFO - root - 2017-12-17 05:17:16.947590: step 39580, loss = 0.18, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 18h:52m:03s remains)
INFO - root - 2017-12-17 05:17:19.201309: step 39590, loss = 0.25, batch loss = 0.17 (36.3 examples/sec; 0.220 sec/batch; 17h:55m:25s remains)
INFO - root - 2017-12-17 05:17:21.440118: step 39600, loss = 0.24, batch loss = 0.17 (35.5 examples/sec; 0.225 sec/batch; 18h:19m:15s remains)
INFO - root - 2017-12-17 05:17:23.889150: step 39610, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:14m:04s remains)
INFO - root - 2017-12-17 05:17:26.162992: step 39620, loss = 0.21, batch loss = 0.14 (36.1 examples/sec; 0.222 sec/batch; 18h:01m:56s remains)
INFO - root - 2017-12-17 05:17:28.475931: step 39630, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 18h:35m:12s remains)
INFO - root - 2017-12-17 05:17:30.747248: step 39640, loss = 0.20, batch loss = 0.12 (34.3 examples/sec; 0.233 sec/batch; 18h:58m:53s remains)
INFO - root - 2017-12-17 05:17:33.008840: step 39650, loss = 0.18, batch loss = 0.10 (33.9 examples/sec; 0.236 sec/batch; 19h:12m:28s remains)
INFO - root - 2017-12-17 05:17:35.256716: step 39660, loss = 0.22, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 18h:33m:21s remains)
INFO - root - 2017-12-17 05:17:37.505519: step 39670, loss = 0.19, batch loss = 0.11 (36.9 examples/sec; 0.217 sec/batch; 17h:36m:40s remains)
INFO - root - 2017-12-17 05:17:39.815148: step 39680, loss = 0.20, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 17h:51m:35s remains)
INFO - root - 2017-12-17 05:17:42.068800: step 39690, loss = 0.16, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 18h:08m:40s remains)
INFO - root - 2017-12-17 05:17:44.317025: step 39700, loss = 0.18, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 17h:59m:50s remains)
INFO - root - 2017-12-17 05:17:46.766355: step 39710, loss = 0.18, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 18h:06m:10s remains)
INFO - root - 2017-12-17 05:17:49.006594: step 39720, loss = 0.19, batch loss = 0.11 (34.3 examples/sec; 0.233 sec/batch; 18h:57m:08s remains)
INFO - root - 2017-12-17 05:17:51.279219: step 39730, loss = 0.19, batch loss = 0.11 (35.0 examples/sec; 0.228 sec/batch; 18h:34m:54s remains)
INFO - root - 2017-12-17 05:17:53.579109: step 39740, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 18h:25m:34s remains)
INFO - root - 2017-12-17 05:17:55.833967: step 39750, loss = 0.23, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 18h:31m:31s remains)
INFO - root - 2017-12-17 05:17:58.094127: step 39760, loss = 0.26, batch loss = 0.19 (36.5 examples/sec; 0.219 sec/batch; 17h:48m:39s remains)
INFO - root - 2017-12-17 05:18:00.407543: step 39770, loss = 0.16, batch loss = 0.09 (34.2 examples/sec; 0.234 sec/batch; 19h:02m:49s remains)
INFO - root - 2017-12-17 05:18:02.674949: step 39780, loss = 0.22, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 18h:49m:03s remains)
INFO - root - 2017-12-17 05:18:04.901999: step 39790, loss = 0.24, batch loss = 0.17 (35.9 examples/sec; 0.223 sec/batch; 18h:07m:11s remains)
INFO - root - 2017-12-17 05:18:07.184573: step 39800, loss = 0.20, batch loss = 0.12 (35.5 examples/sec; 0.226 sec/batch; 18h:20m:04s remains)
INFO - root - 2017-12-17 05:18:09.577793: step 39810, loss = 0.18, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 18h:20m:58s remains)
INFO - root - 2017-12-17 05:18:11.842972: step 39820, loss = 0.25, batch loss = 0.18 (36.5 examples/sec; 0.219 sec/batch; 17h:48m:33s remains)
INFO - root - 2017-12-17 05:18:14.109090: step 39830, loss = 0.27, batch loss = 0.19 (35.4 examples/sec; 0.226 sec/batch; 18h:23m:48s remains)
INFO - root - 2017-12-17 05:18:16.373007: step 39840, loss = 0.18, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 18h:20m:53s remains)
INFO - root - 2017-12-17 05:18:18.639062: step 39850, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 18h:18m:18s remains)
INFO - root - 2017-12-17 05:18:20.934000: step 39860, loss = 0.19, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 18h:46m:20s remains)
INFO - root - 2017-12-17 05:18:23.170555: step 39870, loss = 0.20, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 17h:51m:20s remains)
INFO - root - 2017-12-17 05:18:25.458558: step 39880, loss = 0.19, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 18h:40m:57s remains)
INFO - root - 2017-12-17 05:18:27.730057: step 39890, loss = 0.22, batch loss = 0.15 (34.9 examples/sec; 0.229 sec/batch; 18h:36m:56s remains)
INFO - root - 2017-12-17 05:18:30.004555: step 39900, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 18h:23m:30s remains)
INFO - root - 2017-12-17 05:18:32.377167: step 39910, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:03m:51s remains)
INFO - root - 2017-12-17 05:18:34.630024: step 39920, loss = 0.18, batch loss = 0.10 (34.6 examples/sec; 0.231 sec/batch; 18h:46m:54s remains)
INFO - root - 2017-12-17 05:18:36.862840: step 39930, loss = 0.19, batch loss = 0.12 (36.8 examples/sec; 0.217 sec/batch; 17h:38m:56s remains)
INFO - root - 2017-12-17 05:18:39.147918: step 39940, loss = 0.18, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 17h:56m:19s remains)
INFO - root - 2017-12-17 05:18:41.397941: step 39950, loss = 0.16, batch loss = 0.09 (34.4 examples/sec; 0.233 sec/batch; 18h:54m:10s remains)
INFO - root - 2017-12-17 05:18:43.655955: step 39960, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 18h:23m:04s remains)
INFO - root - 2017-12-17 05:18:45.906283: step 39970, loss = 0.21, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 17h:49m:02s remains)
INFO - root - 2017-12-17 05:18:48.222001: step 39980, loss = 0.23, batch loss = 0.16 (35.5 examples/sec; 0.225 sec/batch; 18h:17m:51s remains)
INFO - root - 2017-12-17 05:18:50.531857: step 39990, loss = 0.22, batch loss = 0.15 (33.2 examples/sec; 0.241 sec/batch; 19h:34m:37s remains)
INFO - root - 2017-12-17 05:18:52.770886: step 40000, loss = 0.22, batch loss = 0.14 (36.6 examples/sec; 0.219 sec/batch; 17h:46m:21s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-40000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-40000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 05:18:55.843837: step 40010, loss = 0.19, batch loss = 0.11 (33.1 examples/sec; 0.242 sec/batch; 19h:39m:32s remains)
INFO - root - 2017-12-17 05:18:58.117320: step 40020, loss = 0.24, batch loss = 0.17 (35.1 examples/sec; 0.228 sec/batch; 18h:31m:36s remains)
INFO - root - 2017-12-17 05:19:00.364753: step 40030, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 18h:12m:02s remains)
INFO - root - 2017-12-17 05:19:02.629478: step 40040, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:03m:37s remains)
INFO - root - 2017-12-17 05:19:04.889964: step 40050, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:38m:07s remains)
INFO - root - 2017-12-17 05:19:07.168009: step 40060, loss = 0.23, batch loss = 0.15 (33.3 examples/sec; 0.240 sec/batch; 19h:30m:28s remains)
INFO - root - 2017-12-17 05:19:09.471588: step 40070, loss = 0.19, batch loss = 0.12 (34.7 examples/sec; 0.230 sec/batch; 18h:43m:15s remains)
INFO - root - 2017-12-17 05:19:11.735687: step 40080, loss = 0.19, batch loss = 0.12 (36.1 examples/sec; 0.222 sec/batch; 18h:00m:45s remains)
INFO - root - 2017-12-17 05:19:14.020699: step 40090, loss = 0.26, batch loss = 0.18 (36.1 examples/sec; 0.221 sec/batch; 17h:59m:23s remains)
INFO - root - 2017-12-17 05:19:16.247297: step 40100, loss = 0.24, batch loss = 0.17 (36.3 examples/sec; 0.221 sec/batch; 17h:55m:10s remains)
INFO - root - 2017-12-17 05:19:18.609961: step 40110, loss = 0.21, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 17h:52m:53s remains)
INFO - root - 2017-12-17 05:19:20.875897: step 40120, loss = 0.19, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 18h:47m:40s remains)
INFO - root - 2017-12-17 05:19:23.139425: step 40130, loss = 0.18, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 17h:51m:45s remains)
INFO - root - 2017-12-17 05:19:25.462016: step 40140, loss = 0.17, batch loss = 0.10 (34.4 examples/sec; 0.232 sec/batch; 18h:51m:38s remains)
INFO - root - 2017-12-17 05:19:27.681550: step 40150, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.223 sec/batch; 18h:07m:40s remains)
INFO - root - 2017-12-17 05:19:29.947569: step 40160, loss = 0.27, batch loss = 0.20 (34.1 examples/sec; 0.234 sec/batch; 19h:02m:18s remains)
INFO - root - 2017-12-17 05:19:32.220884: step 40170, loss = 0.22, batch loss = 0.14 (34.5 examples/sec; 0.232 sec/batch; 18h:50m:19s remains)
INFO - root - 2017-12-17 05:19:34.490721: step 40180, loss = 0.18, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 17h:59m:57s remains)
INFO - root - 2017-12-17 05:19:36.756956: step 40190, loss = 0.23, batch loss = 0.16 (33.7 examples/sec; 0.237 sec/batch; 19h:16m:00s remains)
INFO - root - 2017-12-17 05:19:39.016251: step 40200, loss = 0.17, batch loss = 0.10 (36.7 examples/sec; 0.218 sec/batch; 17h:42m:43s remains)
INFO - root - 2017-12-17 05:19:41.406764: step 40210, loss = 0.21, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 18h:01m:29s remains)
INFO - root - 2017-12-17 05:19:43.662841: step 40220, loss = 0.21, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 18h:20m:10s remains)
INFO - root - 2017-12-17 05:19:45.926030: step 40230, loss = 0.18, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:30m:25s remains)
INFO - root - 2017-12-17 05:19:48.230188: step 40240, loss = 0.17, batch loss = 0.09 (34.6 examples/sec; 0.231 sec/batch; 18h:44m:40s remains)
INFO - root - 2017-12-17 05:19:50.480529: step 40250, loss = 0.21, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 18h:20m:46s remains)
INFO - root - 2017-12-17 05:19:52.765462: step 40260, loss = 0.18, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:31m:15s remains)
INFO - root - 2017-12-17 05:19:55.012052: step 40270, loss = 0.22, batch loss = 0.15 (35.7 examples/sec; 0.224 sec/batch; 18h:11m:21s remains)
INFO - root - 2017-12-17 05:19:57.265863: step 40280, loss = 0.23, batch loss = 0.15 (35.5 examples/sec; 0.225 sec/batch; 18h:18m:12s remains)
INFO - root - 2017-12-17 05:19:59.541252: step 40290, loss = 0.20, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 18h:15m:22s remains)
INFO - root - 2017-12-17 05:20:01.843871: step 40300, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:01m:16s remains)
INFO - root - 2017-12-17 05:20:04.210552: step 40310, loss = 0.19, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 18h:01m:38s remains)
INFO - root - 2017-12-17 05:20:06.470628: step 40320, loss = 0.20, batch loss = 0.13 (36.4 examples/sec; 0.219 sec/batch; 17h:48m:50s remains)
INFO - root - 2017-12-17 05:20:08.754438: step 40330, loss = 0.23, batch loss = 0.16 (34.3 examples/sec; 0.233 sec/batch; 18h:54m:45s remains)
INFO - root - 2017-12-17 05:20:11.032152: step 40340, loss = 0.20, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 17h:55m:34s remains)
INFO - root - 2017-12-17 05:20:13.276972: step 40350, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 18h:31m:11s remains)
INFO - root - 2017-12-17 05:20:15.587734: step 40360, loss = 0.19, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:11m:31s remains)
INFO - root - 2017-12-17 05:20:17.827797: step 40370, loss = 0.23, batch loss = 0.16 (34.8 examples/sec; 0.230 sec/batch; 18h:39m:30s remains)
INFO - root - 2017-12-17 05:20:20.066759: step 40380, loss = 0.18, batch loss = 0.10 (34.7 examples/sec; 0.231 sec/batch; 18h:43m:56s remains)
INFO - root - 2017-12-17 05:20:22.352313: step 40390, loss = 0.17, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 17h:47m:31s remains)
INFO - root - 2017-12-17 05:20:24.610132: step 40400, loss = 0.17, batch loss = 0.10 (34.6 examples/sec; 0.231 sec/batch; 18h:44m:41s remains)
INFO - root - 2017-12-17 05:20:27.019825: step 40410, loss = 0.28, batch loss = 0.20 (34.8 examples/sec; 0.230 sec/batch; 18h:37m:59s remains)
INFO - root - 2017-12-17 05:20:29.302667: step 40420, loss = 0.21, batch loss = 0.14 (36.6 examples/sec; 0.218 sec/batch; 17h:43m:15s remains)
INFO - root - 2017-12-17 05:20:31.566686: step 40430, loss = 0.19, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 18h:43m:51s remains)
INFO - root - 2017-12-17 05:20:33.855339: step 40440, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:19m:05s remains)
INFO - root - 2017-12-17 05:20:36.111075: step 40450, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 18h:09m:24s remains)
INFO - root - 2017-12-17 05:20:38.369847: step 40460, loss = 0.18, batch loss = 0.10 (33.1 examples/sec; 0.242 sec/batch; 19h:37m:26s remains)
INFO - root - 2017-12-17 05:20:40.644194: step 40470, loss = 0.22, batch loss = 0.15 (35.8 examples/sec; 0.224 sec/batch; 18h:09m:06s remains)
INFO - root - 2017-12-17 05:20:42.905365: step 40480, loss = 0.16, batch loss = 0.09 (36.6 examples/sec; 0.219 sec/batch; 17h:44m:29s remains)
INFO - root - 2017-12-17 05:20:45.175107: step 40490, loss = 0.17, batch loss = 0.10 (34.2 examples/sec; 0.234 sec/batch; 18h:57m:37s remains)
INFO - root - 2017-12-17 05:20:47.417070: step 40500, loss = 0.18, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 18h:47m:35s remains)
INFO - root - 2017-12-17 05:20:49.827999: step 40510, loss = 0.19, batch loss = 0.12 (33.9 examples/sec; 0.236 sec/batch; 19h:07m:33s remains)
INFO - root - 2017-12-17 05:20:52.097950: step 40520, loss = 0.17, batch loss = 0.10 (36.1 examples/sec; 0.221 sec/batch; 17h:57m:26s remains)
INFO - root - 2017-12-17 05:20:54.377627: step 40530, loss = 0.21, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 18h:22m:40s remains)
INFO - root - 2017-12-17 05:20:56.645249: step 40540, loss = 0.20, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 18h:09m:09s remains)
INFO - root - 2017-12-17 05:20:58.924128: step 40550, loss = 0.19, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 17h:49m:45s remains)
INFO - root - 2017-12-17 05:21:01.198115: step 40560, loss = 0.19, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 18h:23m:00s remains)
INFO - root - 2017-12-17 05:21:03.461640: step 40570, loss = 0.16, batch loss = 0.08 (36.2 examples/sec; 0.221 sec/batch; 17h:54m:36s remains)
INFO - root - 2017-12-17 05:21:05.728293: step 40580, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:34m:26s remains)
INFO - root - 2017-12-17 05:21:08.027945: step 40590, loss = 0.23, batch loss = 0.16 (34.9 examples/sec; 0.229 sec/batch; 18h:35m:36s remains)
INFO - root - 2017-12-17 05:21:10.317631: step 40600, loss = 0.18, batch loss = 0.11 (36.6 examples/sec; 0.218 sec/batch; 17h:42m:10s remains)
INFO - root - 2017-12-17 05:21:12.753437: step 40610, loss = 0.20, batch loss = 0.13 (34.7 examples/sec; 0.230 sec/batch; 18h:40m:28s remains)
INFO - root - 2017-12-17 05:21:15.062699: step 40620, loss = 0.19, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 18h:18m:58s remains)
INFO - root - 2017-12-17 05:21:17.369622: step 40630, loss = 0.28, batch loss = 0.21 (31.5 examples/sec; 0.254 sec/batch; 20h:33m:31s remains)
INFO - root - 2017-12-17 05:21:19.622854: step 40640, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 18h:00m:18s remains)
INFO - root - 2017-12-17 05:21:21.894729: step 40650, loss = 0.22, batch loss = 0.14 (34.7 examples/sec; 0.230 sec/batch; 18h:39m:54s remains)
INFO - root - 2017-12-17 05:21:24.156943: step 40660, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 18h:26m:07s remains)
INFO - root - 2017-12-17 05:21:26.430863: step 40670, loss = 0.17, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 18h:08m:17s remains)
INFO - root - 2017-12-17 05:21:28.729509: step 40680, loss = 0.22, batch loss = 0.15 (34.7 examples/sec; 0.231 sec/batch; 18h:41m:52s remains)
INFO - root - 2017-12-17 05:21:30.999452: step 40690, loss = 0.26, batch loss = 0.19 (35.9 examples/sec; 0.223 sec/batch; 18h:04m:05s remains)
INFO - root - 2017-12-17 05:21:33.277051: step 40700, loss = 0.24, batch loss = 0.16 (36.1 examples/sec; 0.221 sec/batch; 17h:56m:29s remains)
INFO - root - 2017-12-17 05:21:35.662008: step 40710, loss = 0.20, batch loss = 0.13 (36.6 examples/sec; 0.219 sec/batch; 17h:43m:00s remains)
INFO - root - 2017-12-17 05:21:37.938679: step 40720, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 18h:13m:03s remains)
INFO - root - 2017-12-17 05:21:40.233048: step 40730, loss = 0.22, batch loss = 0.14 (34.7 examples/sec; 0.230 sec/batch; 18h:40m:00s remains)
INFO - root - 2017-12-17 05:21:42.487770: step 40740, loss = 0.20, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 17h:48m:42s remains)
INFO - root - 2017-12-17 05:21:44.766339: step 40750, loss = 0.20, batch loss = 0.13 (33.4 examples/sec; 0.239 sec/batch; 19h:23m:39s remains)
INFO - root - 2017-12-17 05:21:47.055815: step 40760, loss = 0.25, batch loss = 0.17 (35.3 examples/sec; 0.227 sec/batch; 18h:23m:24s remains)
INFO - root - 2017-12-17 05:21:49.310812: step 40770, loss = 0.18, batch loss = 0.10 (35.2 examples/sec; 0.228 sec/batch; 18h:26m:24s remains)
INFO - root - 2017-12-17 05:21:51.593690: step 40780, loss = 0.23, batch loss = 0.15 (36.1 examples/sec; 0.221 sec/batch; 17h:56m:00s remains)
INFO - root - 2017-12-17 05:21:53.879042: step 40790, loss = 0.20, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 18h:21m:47s remains)
INFO - root - 2017-12-17 05:21:56.161428: step 40800, loss = 0.22, batch loss = 0.14 (35.5 examples/sec; 0.226 sec/batch; 18h:16m:38s remains)
INFO - root - 2017-12-17 05:21:58.569370: step 40810, loss = 0.20, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 18h:43m:28s remains)
INFO - root - 2017-12-17 05:22:00.822366: step 40820, loss = 0.18, batch loss = 0.10 (36.4 examples/sec; 0.219 sec/batch; 17h:47m:03s remains)
INFO - root - 2017-12-17 05:22:03.072000: step 40830, loss = 0.17, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 17h:49m:03s remains)
INFO - root - 2017-12-17 05:22:05.367519: step 40840, loss = 0.18, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 18h:47m:52s remains)
INFO - root - 2017-12-17 05:22:07.684368: step 40850, loss = 0.19, batch loss = 0.12 (34.2 examples/sec; 0.234 sec/batch; 18h:58m:17s remains)
INFO - root - 2017-12-17 05:22:09.982740: step 40860, loss = 0.21, batch loss = 0.14 (35.0 examples/sec; 0.229 sec/batch; 18h:31m:23s remains)
INFO - root - 2017-12-17 05:22:12.258413: step 40870, loss = 0.22, batch loss = 0.14 (36.6 examples/sec; 0.219 sec/batch; 17h:42m:36s remains)
INFO - root - 2017-12-17 05:22:14.542033: step 40880, loss = 0.19, batch loss = 0.12 (36.9 examples/sec; 0.217 sec/batch; 17h:34m:03s remains)
INFO - root - 2017-12-17 05:22:16.792035: step 40890, loss = 0.21, batch loss = 0.13 (35.8 examples/sec; 0.224 sec/batch; 18h:07m:19s remains)
INFO - root - 2017-12-17 05:22:19.062058: step 40900, loss = 0.17, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 17h:48m:24s remains)
INFO - root - 2017-12-17 05:22:21.471809: step 40910, loss = 0.21, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 18h:37m:05s remains)
INFO - root - 2017-12-17 05:22:23.769314: step 40920, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 18h:08m:35s remains)
INFO - root - 2017-12-17 05:22:26.016731: step 40930, loss = 0.21, batch loss = 0.13 (33.4 examples/sec; 0.240 sec/batch; 19h:24m:09s remains)
INFO - root - 2017-12-17 05:22:28.282273: step 40940, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 18h:16m:39s remains)
INFO - root - 2017-12-17 05:22:30.597824: step 40950, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:17m:11s remains)
INFO - root - 2017-12-17 05:22:32.854612: step 40960, loss = 0.23, batch loss = 0.15 (36.1 examples/sec; 0.222 sec/batch; 17h:57m:29s remains)
INFO - root - 2017-12-17 05:22:35.135760: step 40970, loss = 0.19, batch loss = 0.12 (33.4 examples/sec; 0.239 sec/batch; 19h:22m:34s remains)
INFO - root - 2017-12-17 05:22:37.440491: step 40980, loss = 0.15, batch loss = 0.08 (34.5 examples/sec; 0.232 sec/batch; 18h:45m:19s remains)
INFO - root - 2017-12-17 05:22:39.720356: step 40990, loss = 0.18, batch loss = 0.10 (32.7 examples/sec; 0.245 sec/batch; 19h:48m:31s remains)
INFO - root - 2017-12-17 05:22:41.999321: step 41000, loss = 0.20, batch loss = 0.12 (34.7 examples/sec; 0.231 sec/batch; 18h:41m:04s remains)
INFO - root - 2017-12-17 05:22:44.402893: step 41010, loss = 0.18, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 18h:23m:46s remains)
INFO - root - 2017-12-17 05:22:46.665626: step 41020, loss = 0.17, batch loss = 0.10 (36.9 examples/sec; 0.217 sec/batch; 17h:32m:58s remains)
INFO - root - 2017-12-17 05:22:48.926181: step 41030, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:17m:45s remains)
INFO - root - 2017-12-17 05:22:51.184379: step 41040, loss = 0.20, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 18h:20m:25s remains)
INFO - root - 2017-12-17 05:22:53.476636: step 41050, loss = 0.17, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 18h:20m:30s remains)
INFO - root - 2017-12-17 05:22:55.750580: step 41060, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 18h:14m:57s remains)
INFO - root - 2017-12-17 05:22:58.024895: step 41070, loss = 0.20, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 17h:58m:12s remains)
INFO - root - 2017-12-17 05:23:00.295252: step 41080, loss = 0.20, batch loss = 0.12 (33.8 examples/sec; 0.236 sec/batch; 19h:08m:01s remains)
INFO - root - 2017-12-17 05:23:02.600105: step 41090, loss = 0.19, batch loss = 0.12 (33.9 examples/sec; 0.236 sec/batch; 19h:04m:54s remains)
INFO - root - 2017-12-17 05:23:04.873323: step 41100, loss = 0.15, batch loss = 0.08 (34.6 examples/sec; 0.231 sec/batch; 18h:43m:00s remains)
INFO - root - 2017-12-17 05:23:07.253878: step 41110, loss = 0.18, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 18h:03m:39s remains)
INFO - root - 2017-12-17 05:23:09.570299: step 41120, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:16m:32s remains)
INFO - root - 2017-12-17 05:23:11.817206: step 41130, loss = 0.21, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 18h:01m:23s remains)
INFO - root - 2017-12-17 05:23:14.106849: step 41140, loss = 0.21, batch loss = 0.14 (35.5 examples/sec; 0.226 sec/batch; 18h:15m:22s remains)
INFO - root - 2017-12-17 05:23:16.381636: step 41150, loss = 0.20, batch loss = 0.13 (32.8 examples/sec; 0.244 sec/batch; 19h:43m:11s remains)
INFO - root - 2017-12-17 05:23:18.672064: step 41160, loss = 0.24, batch loss = 0.16 (35.9 examples/sec; 0.223 sec/batch; 18h:02m:36s remains)
INFO - root - 2017-12-17 05:23:20.976499: step 41170, loss = 0.18, batch loss = 0.11 (36.3 examples/sec; 0.221 sec/batch; 17h:51m:01s remains)
INFO - root - 2017-12-17 05:23:23.279497: step 41180, loss = 0.23, batch loss = 0.16 (35.3 examples/sec; 0.226 sec/batch; 18h:18m:49s remains)
INFO - root - 2017-12-17 05:23:25.577244: step 41190, loss = 0.26, batch loss = 0.19 (35.8 examples/sec; 0.224 sec/batch; 18h:05m:59s remains)
INFO - root - 2017-12-17 05:23:27.871062: step 41200, loss = 0.20, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 18h:05m:04s remains)
INFO - root - 2017-12-17 05:23:30.299039: step 41210, loss = 0.25, batch loss = 0.17 (34.6 examples/sec; 0.231 sec/batch; 18h:40m:59s remains)
INFO - root - 2017-12-17 05:23:32.569433: step 41220, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 18h:17m:29s remains)
INFO - root - 2017-12-17 05:23:34.829261: step 41230, loss = 0.26, batch loss = 0.19 (35.6 examples/sec; 0.225 sec/batch; 18h:11m:34s remains)
INFO - root - 2017-12-17 05:23:37.099499: step 41240, loss = 0.17, batch loss = 0.09 (34.6 examples/sec; 0.231 sec/batch; 18h:41m:53s remains)
INFO - root - 2017-12-17 05:23:39.388383: step 41250, loss = 0.19, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:06m:37s remains)
INFO - root - 2017-12-17 05:23:41.636253: step 41260, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 18h:32m:45s remains)
INFO - root - 2017-12-17 05:23:43.913093: step 41270, loss = 0.18, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 18h:17m:47s remains)
INFO - root - 2017-12-17 05:23:46.171667: step 41280, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.226 sec/batch; 18h:14m:32s remains)
INFO - root - 2017-12-17 05:23:48.455470: step 41290, loss = 0.19, batch loss = 0.12 (33.8 examples/sec; 0.237 sec/batch; 19h:08m:19s remains)
INFO - root - 2017-12-17 05:23:50.680633: step 41300, loss = 0.21, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 18h:50m:27s remains)
INFO - root - 2017-12-17 05:23:53.071141: step 41310, loss = 0.21, batch loss = 0.14 (35.2 examples/sec; 0.227 sec/batch; 18h:22m:53s remains)
INFO - root - 2017-12-17 05:23:55.352175: step 41320, loss = 0.17, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 18h:34m:43s remains)
INFO - root - 2017-12-17 05:23:57.613900: step 41330, loss = 0.22, batch loss = 0.14 (34.5 examples/sec; 0.232 sec/batch; 18h:43m:45s remains)
INFO - root - 2017-12-17 05:23:59.897143: step 41340, loss = 0.25, batch loss = 0.17 (33.4 examples/sec; 0.239 sec/batch; 19h:21m:18s remains)
INFO - root - 2017-12-17 05:24:02.155189: step 41350, loss = 0.27, batch loss = 0.20 (35.6 examples/sec; 0.225 sec/batch; 18h:11m:26s remains)
INFO - root - 2017-12-17 05:24:04.441370: step 41360, loss = 0.23, batch loss = 0.16 (35.4 examples/sec; 0.226 sec/batch; 18h:15m:57s remains)
INFO - root - 2017-12-17 05:24:06.697697: step 41370, loss = 0.17, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 18h:13m:28s remains)
INFO - root - 2017-12-17 05:24:08.997257: step 41380, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 18h:28m:33s remains)
INFO - root - 2017-12-17 05:24:11.280074: step 41390, loss = 0.23, batch loss = 0.16 (34.2 examples/sec; 0.234 sec/batch; 18h:53m:48s remains)
INFO - root - 2017-12-17 05:24:13.578846: step 41400, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 17h:58m:44s remains)
INFO - root - 2017-12-17 05:24:15.944190: step 41410, loss = 0.20, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 18h:26m:05s remains)
INFO - root - 2017-12-17 05:24:18.218709: step 41420, loss = 0.18, batch loss = 0.11 (33.4 examples/sec; 0.239 sec/batch; 19h:21m:28s remains)
INFO - root - 2017-12-17 05:24:20.543577: step 41430, loss = 0.22, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 18h:32m:53s remains)
INFO - root - 2017-12-17 05:24:22.814241: step 41440, loss = 0.21, batch loss = 0.14 (36.9 examples/sec; 0.217 sec/batch; 17h:33m:04s remains)
INFO - root - 2017-12-17 05:24:25.093750: step 41450, loss = 0.22, batch loss = 0.15 (35.3 examples/sec; 0.227 sec/batch; 18h:19m:42s remains)
INFO - root - 2017-12-17 05:24:27.367269: step 41460, loss = 0.17, batch loss = 0.10 (35.0 examples/sec; 0.229 sec/batch; 18h:29m:28s remains)
INFO - root - 2017-12-17 05:24:29.661104: step 41470, loss = 0.21, batch loss = 0.14 (36.1 examples/sec; 0.222 sec/batch; 17h:55m:52s remains)
INFO - root - 2017-12-17 05:24:31.912220: step 41480, loss = 0.21, batch loss = 0.14 (35.2 examples/sec; 0.228 sec/batch; 18h:23m:39s remains)
INFO - root - 2017-12-17 05:24:34.158542: step 41490, loss = 0.18, batch loss = 0.10 (34.0 examples/sec; 0.236 sec/batch; 19h:02m:17s remains)
INFO - root - 2017-12-17 05:24:36.421832: step 41500, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:05m:56s remains)
INFO - root - 2017-12-17 05:24:38.834383: step 41510, loss = 0.22, batch loss = 0.15 (35.8 examples/sec; 0.224 sec/batch; 18h:04m:05s remains)
INFO - root - 2017-12-17 05:24:41.096652: step 41520, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.226 sec/batch; 18h:13m:54s remains)
INFO - root - 2017-12-17 05:24:43.408550: step 41530, loss = 0.18, batch loss = 0.11 (34.0 examples/sec; 0.235 sec/batch; 19h:00m:46s remains)
INFO - root - 2017-12-17 05:24:45.685007: step 41540, loss = 0.17, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:06m:30s remains)
INFO - root - 2017-12-17 05:24:47.949034: step 41550, loss = 0.22, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 17h:58m:31s remains)
INFO - root - 2017-12-17 05:24:50.243845: step 41560, loss = 0.16, batch loss = 0.09 (34.0 examples/sec; 0.235 sec/batch; 18h:59m:37s remains)
INFO - root - 2017-12-17 05:24:52.489079: step 41570, loss = 0.22, batch loss = 0.15 (36.4 examples/sec; 0.220 sec/batch; 17h:46m:42s remains)
INFO - root - 2017-12-17 05:24:54.765032: step 41580, loss = 0.21, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 18h:35m:45s remains)
INFO - root - 2017-12-17 05:24:57.015229: step 41590, loss = 0.17, batch loss = 0.09 (35.2 examples/sec; 0.227 sec/batch; 18h:21m:39s remains)
INFO - root - 2017-12-17 05:24:59.302190: step 41600, loss = 0.19, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 17h:36m:43s remains)
INFO - root - 2017-12-17 05:25:01.719718: step 41610, loss = 0.25, batch loss = 0.18 (33.8 examples/sec; 0.237 sec/batch; 19h:08m:21s remains)
INFO - root - 2017-12-17 05:25:03.988734: step 41620, loss = 0.18, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 18h:17m:01s remains)
INFO - root - 2017-12-17 05:25:06.226284: step 41630, loss = 0.18, batch loss = 0.11 (36.6 examples/sec; 0.218 sec/batch; 17h:38m:13s remains)
INFO - root - 2017-12-17 05:25:08.521153: step 41640, loss = 0.19, batch loss = 0.11 (32.9 examples/sec; 0.243 sec/batch; 19h:38m:37s remains)
INFO - root - 2017-12-17 05:25:10.772893: step 41650, loss = 0.21, batch loss = 0.14 (35.2 examples/sec; 0.227 sec/batch; 18h:20m:31s remains)
INFO - root - 2017-12-17 05:25:13.044786: step 41660, loss = 0.19, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 17h:54m:08s remains)
INFO - root - 2017-12-17 05:25:15.308005: step 41670, loss = 0.21, batch loss = 0.14 (34.1 examples/sec; 0.235 sec/batch; 18h:56m:52s remains)
INFO - root - 2017-12-17 05:25:17.566045: step 41680, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:14m:20s remains)
INFO - root - 2017-12-17 05:25:19.818079: step 41690, loss = 0.19, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 17h:59m:11s remains)
INFO - root - 2017-12-17 05:25:22.078211: step 41700, loss = 0.22, batch loss = 0.15 (35.8 examples/sec; 0.223 sec/batch; 18h:01m:56s remains)
INFO - root - 2017-12-17 05:25:24.466528: step 41710, loss = 0.21, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 18h:09m:28s remains)
INFO - root - 2017-12-17 05:25:26.763159: step 41720, loss = 0.20, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 18h:44m:08s remains)
INFO - root - 2017-12-17 05:25:29.122779: step 41730, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:30m:17s remains)
INFO - root - 2017-12-17 05:25:31.393899: step 41740, loss = 0.23, batch loss = 0.15 (35.0 examples/sec; 0.229 sec/batch; 18h:28m:13s remains)
INFO - root - 2017-12-17 05:25:33.633943: step 41750, loss = 0.18, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 17h:58m:24s remains)
INFO - root - 2017-12-17 05:25:35.920975: step 41760, loss = 0.20, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 17h:51m:05s remains)
INFO - root - 2017-12-17 05:25:38.223980: step 41770, loss = 0.22, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 18h:39m:03s remains)
INFO - root - 2017-12-17 05:25:40.512925: step 41780, loss = 0.18, batch loss = 0.10 (34.5 examples/sec; 0.232 sec/batch; 18h:42m:08s remains)
INFO - root - 2017-12-17 05:25:42.781469: step 41790, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 18h:00m:46s remains)
INFO - root - 2017-12-17 05:25:45.018020: step 41800, loss = 0.26, batch loss = 0.18 (35.5 examples/sec; 0.226 sec/batch; 18h:13m:15s remains)
INFO - root - 2017-12-17 05:25:47.446805: step 41810, loss = 0.18, batch loss = 0.10 (34.9 examples/sec; 0.229 sec/batch; 18h:31m:34s remains)
INFO - root - 2017-12-17 05:25:49.699892: step 41820, loss = 0.18, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 17h:56m:44s remains)
INFO - root - 2017-12-17 05:25:51.993819: step 41830, loss = 0.21, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 18h:34m:33s remains)
INFO - root - 2017-12-17 05:25:54.243300: step 41840, loss = 0.20, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 18h:30m:59s remains)
INFO - root - 2017-12-17 05:25:56.544217: step 41850, loss = 0.23, batch loss = 0.16 (35.6 examples/sec; 0.224 sec/batch; 18h:07m:20s remains)
INFO - root - 2017-12-17 05:25:58.822905: step 41860, loss = 0.20, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 17h:53m:26s remains)
INFO - root - 2017-12-17 05:26:01.104278: step 41870, loss = 0.21, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 18h:28m:51s remains)
INFO - root - 2017-12-17 05:26:03.424652: step 41880, loss = 0.18, batch loss = 0.10 (33.4 examples/sec; 0.240 sec/batch; 19h:21m:22s remains)
INFO - root - 2017-12-17 05:26:05.672728: step 41890, loss = 0.18, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:04m:40s remains)
INFO - root - 2017-12-17 05:26:07.977018: step 41900, loss = 0.22, batch loss = 0.14 (33.2 examples/sec; 0.241 sec/batch; 19h:26m:30s remains)
INFO - root - 2017-12-17 05:26:10.378527: step 41910, loss = 0.18, batch loss = 0.11 (33.3 examples/sec; 0.240 sec/batch; 19h:24m:37s remains)
INFO - root - 2017-12-17 05:26:12.670092: step 41920, loss = 0.20, batch loss = 0.12 (34.3 examples/sec; 0.233 sec/batch; 18h:48m:55s remains)
INFO - root - 2017-12-17 05:26:14.917995: step 41930, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 18h:05m:23s remains)
INFO - root - 2017-12-17 05:26:17.160968: step 41940, loss = 0.17, batch loss = 0.10 (35.8 examples/sec; 0.223 sec/batch; 18h:01m:06s remains)
INFO - root - 2017-12-17 05:26:19.411874: step 41950, loss = 0.21, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 18h:39m:50s remains)
INFO - root - 2017-12-17 05:26:21.678315: step 41960, loss = 0.19, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 18h:37m:59s remains)
INFO - root - 2017-12-17 05:26:23.973670: step 41970, loss = 0.19, batch loss = 0.12 (36.1 examples/sec; 0.221 sec/batch; 17h:51m:36s remains)
INFO - root - 2017-12-17 05:26:26.259057: step 41980, loss = 0.20, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 18h:17m:56s remains)
INFO - root - 2017-12-17 05:26:28.520205: step 41990, loss = 0.24, batch loss = 0.17 (33.6 examples/sec; 0.238 sec/batch; 19h:11m:09s remains)
INFO - root - 2017-12-17 05:26:30.768669: step 42000, loss = 0.17, batch loss = 0.09 (36.1 examples/sec; 0.222 sec/batch; 17h:53m:45s remains)
INFO - root - 2017-12-17 05:26:33.148312: step 42010, loss = 0.31, batch loss = 0.23 (35.7 examples/sec; 0.224 sec/batch; 18h:04m:25s remains)
INFO - root - 2017-12-17 05:26:35.395628: step 42020, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 17h:59m:30s remains)
INFO - root - 2017-12-17 05:26:37.661455: step 42030, loss = 0.19, batch loss = 0.11 (34.3 examples/sec; 0.233 sec/batch; 18h:48m:47s remains)
INFO - root - 2017-12-17 05:26:39.920026: step 42040, loss = 0.17, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 17h:50m:14s remains)
INFO - root - 2017-12-17 05:26:42.244179: step 42050, loss = 0.19, batch loss = 0.11 (34.0 examples/sec; 0.236 sec/batch; 19h:00m:25s remains)
INFO - root - 2017-12-17 05:26:44.507798: step 42060, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.226 sec/batch; 18h:12m:06s remains)
INFO - root - 2017-12-17 05:26:46.785045: step 42070, loss = 0.25, batch loss = 0.18 (33.8 examples/sec; 0.237 sec/batch; 19h:07m:00s remains)
INFO - root - 2017-12-17 05:26:49.078605: step 42080, loss = 0.23, batch loss = 0.16 (35.5 examples/sec; 0.225 sec/batch; 18h:09m:56s remains)
INFO - root - 2017-12-17 05:26:51.364104: step 42090, loss = 0.28, batch loss = 0.21 (34.9 examples/sec; 0.229 sec/batch; 18h:28m:32s remains)
INFO - root - 2017-12-17 05:26:53.656018: step 42100, loss = 0.17, batch loss = 0.09 (35.0 examples/sec; 0.229 sec/batch; 18h:26m:36s remains)
INFO - root - 2017-12-17 05:26:56.052058: step 42110, loss = 0.20, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 18h:02m:37s remains)
INFO - root - 2017-12-17 05:26:58.309833: step 42120, loss = 0.19, batch loss = 0.12 (34.7 examples/sec; 0.230 sec/batch; 18h:35m:08s remains)
INFO - root - 2017-12-17 05:27:00.582203: step 42130, loss = 0.20, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 18h:40m:20s remains)
INFO - root - 2017-12-17 05:27:02.823602: step 42140, loss = 0.17, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 18h:09m:10s remains)
INFO - root - 2017-12-17 05:27:05.086975: step 42150, loss = 0.22, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 18h:18m:30s remains)
INFO - root - 2017-12-17 05:27:07.329433: step 42160, loss = 0.25, batch loss = 0.18 (36.1 examples/sec; 0.222 sec/batch; 17h:52m:01s remains)
INFO - root - 2017-12-17 05:27:09.650358: step 42170, loss = 0.27, batch loss = 0.19 (36.2 examples/sec; 0.221 sec/batch; 17h:50m:02s remains)
INFO - root - 2017-12-17 05:27:11.876586: step 42180, loss = 0.16, batch loss = 0.08 (35.0 examples/sec; 0.228 sec/batch; 18h:25m:17s remains)
INFO - root - 2017-12-17 05:27:14.144954: step 42190, loss = 0.18, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 18h:09m:28s remains)
INFO - root - 2017-12-17 05:27:16.424712: step 42200, loss = 0.20, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 17h:50m:37s remains)
INFO - root - 2017-12-17 05:27:18.791360: step 42210, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 18h:07m:36s remains)
INFO - root - 2017-12-17 05:27:21.086238: step 42220, loss = 0.17, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 18h:08m:58s remains)
INFO - root - 2017-12-17 05:27:23.377597: step 42230, loss = 0.21, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 18h:33m:41s remains)
INFO - root - 2017-12-17 05:27:25.686883: step 42240, loss = 0.24, batch loss = 0.17 (34.8 examples/sec; 0.230 sec/batch; 18h:31m:53s remains)
INFO - root - 2017-12-17 05:27:27.957474: step 42250, loss = 0.19, batch loss = 0.12 (34.4 examples/sec; 0.232 sec/batch; 18h:43m:47s remains)
INFO - root - 2017-12-17 05:27:30.242780: step 42260, loss = 0.20, batch loss = 0.12 (36.3 examples/sec; 0.221 sec/batch; 17h:47m:27s remains)
INFO - root - 2017-12-17 05:27:32.538571: step 42270, loss = 0.18, batch loss = 0.11 (34.7 examples/sec; 0.230 sec/batch; 18h:34m:50s remains)
INFO - root - 2017-12-17 05:27:34.797358: step 42280, loss = 0.19, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 18h:06m:06s remains)
INFO - root - 2017-12-17 05:27:37.103430: step 42290, loss = 0.17, batch loss = 0.09 (33.0 examples/sec; 0.242 sec/batch; 19h:31m:47s remains)
INFO - root - 2017-12-17 05:27:39.386132: step 42300, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 18h:09m:09s remains)
INFO - root - 2017-12-17 05:27:41.777750: step 42310, loss = 0.22, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 18h:39m:17s remains)
INFO - root - 2017-12-17 05:27:44.045194: step 42320, loss = 0.19, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 18h:34m:47s remains)
INFO - root - 2017-12-17 05:27:46.320182: step 42330, loss = 0.19, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 17h:41m:00s remains)
INFO - root - 2017-12-17 05:27:48.596940: step 42340, loss = 0.20, batch loss = 0.13 (35.0 examples/sec; 0.228 sec/batch; 18h:24m:36s remains)
INFO - root - 2017-12-17 05:27:50.860530: step 42350, loss = 0.21, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 18h:22m:48s remains)
INFO - root - 2017-12-17 05:27:53.120786: step 42360, loss = 0.19, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 18h:04m:47s remains)
INFO - root - 2017-12-17 05:27:55.403289: step 42370, loss = 0.23, batch loss = 0.15 (34.3 examples/sec; 0.233 sec/batch; 18h:47m:13s remains)
INFO - root - 2017-12-17 05:27:57.701355: step 42380, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 18h:18m:39s remains)
INFO - root - 2017-12-17 05:27:59.939852: step 42390, loss = 0.22, batch loss = 0.15 (36.3 examples/sec; 0.220 sec/batch; 17h:45m:18s remains)
INFO - root - 2017-12-17 05:28:02.190074: step 42400, loss = 0.22, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 17h:48m:24s remains)
INFO - root - 2017-12-17 05:28:04.644769: step 42410, loss = 0.21, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 18h:30m:17s remains)
INFO - root - 2017-12-17 05:28:06.894875: step 42420, loss = 0.23, batch loss = 0.15 (33.9 examples/sec; 0.236 sec/batch; 18h:59m:52s remains)
INFO - root - 2017-12-17 05:28:09.176286: step 42430, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 18h:12m:24s remains)
INFO - root - 2017-12-17 05:28:11.423669: step 42440, loss = 0.19, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 18h:37m:24s remains)
INFO - root - 2017-12-17 05:28:13.685923: step 42450, loss = 0.18, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 18h:41m:44s remains)
INFO - root - 2017-12-17 05:28:16.008128: step 42460, loss = 0.19, batch loss = 0.12 (33.6 examples/sec; 0.238 sec/batch; 19h:12m:33s remains)
INFO - root - 2017-12-17 05:28:18.299452: step 42470, loss = 0.19, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 17h:33m:50s remains)
INFO - root - 2017-12-17 05:28:20.568823: step 42480, loss = 0.18, batch loss = 0.11 (36.8 examples/sec; 0.218 sec/batch; 17h:32m:02s remains)
INFO - root - 2017-12-17 05:28:22.860619: step 42490, loss = 0.20, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 18h:37m:09s remains)
INFO - root - 2017-12-17 05:28:25.137521: step 42500, loss = 0.21, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 18h:29m:08s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-42500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-42500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 05:28:27.927659: step 42510, loss = 0.17, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 18h:31m:21s remains)
INFO - root - 2017-12-17 05:28:30.188703: step 42520, loss = 0.19, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 17h:58m:20s remains)
INFO - root - 2017-12-17 05:28:32.458228: step 42530, loss = 0.18, batch loss = 0.10 (35.5 examples/sec; 0.226 sec/batch; 18h:09m:51s remains)
INFO - root - 2017-12-17 05:28:34.693842: step 42540, loss = 0.19, batch loss = 0.11 (34.4 examples/sec; 0.233 sec/batch; 18h:44m:40s remains)
INFO - root - 2017-12-17 05:28:36.960514: step 42550, loss = 0.23, batch loss = 0.16 (35.8 examples/sec; 0.223 sec/batch; 17h:58m:43s remains)
INFO - root - 2017-12-17 05:28:39.237498: step 42560, loss = 0.19, batch loss = 0.11 (35.2 examples/sec; 0.227 sec/batch; 18h:18m:47s remains)
INFO - root - 2017-12-17 05:28:41.532839: step 42570, loss = 0.18, batch loss = 0.10 (34.9 examples/sec; 0.229 sec/batch; 18h:28m:28s remains)
INFO - root - 2017-12-17 05:28:43.807967: step 42580, loss = 0.16, batch loss = 0.08 (33.9 examples/sec; 0.236 sec/batch; 18h:59m:45s remains)
INFO - root - 2017-12-17 05:28:46.056378: step 42590, loss = 0.19, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 17h:54m:34s remains)
INFO - root - 2017-12-17 05:28:48.304964: step 42600, loss = 0.19, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 18h:37m:04s remains)
INFO - root - 2017-12-17 05:28:50.714646: step 42610, loss = 0.17, batch loss = 0.09 (36.1 examples/sec; 0.222 sec/batch; 17h:50m:51s remains)
INFO - root - 2017-12-17 05:28:52.975101: step 42620, loss = 0.16, batch loss = 0.09 (34.4 examples/sec; 0.232 sec/batch; 18h:43m:15s remains)
INFO - root - 2017-12-17 05:28:55.236370: step 42630, loss = 0.18, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 17h:48m:00s remains)
INFO - root - 2017-12-17 05:28:57.525255: step 42640, loss = 0.22, batch loss = 0.15 (33.9 examples/sec; 0.236 sec/batch; 19h:00m:11s remains)
INFO - root - 2017-12-17 05:28:59.766747: step 42650, loss = 0.17, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:02m:43s remains)
INFO - root - 2017-12-17 05:29:02.015073: step 42660, loss = 0.19, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 17h:57m:19s remains)
INFO - root - 2017-12-17 05:29:04.292229: step 42670, loss = 0.22, batch loss = 0.14 (34.3 examples/sec; 0.233 sec/batch; 18h:47m:24s remains)
INFO - root - 2017-12-17 05:29:06.603929: step 42680, loss = 0.24, batch loss = 0.16 (36.1 examples/sec; 0.222 sec/batch; 17h:51m:22s remains)
INFO - root - 2017-12-17 05:29:08.877842: step 42690, loss = 0.21, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 18h:20m:01s remains)
INFO - root - 2017-12-17 05:29:11.169306: step 42700, loss = 0.20, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 18h:14m:25s remains)
INFO - root - 2017-12-17 05:29:13.545724: step 42710, loss = 0.20, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 18h:07m:05s remains)
INFO - root - 2017-12-17 05:29:15.821525: step 42720, loss = 0.16, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 17h:54m:59s remains)
INFO - root - 2017-12-17 05:29:18.093852: step 42730, loss = 0.20, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 18h:26m:46s remains)
INFO - root - 2017-12-17 05:29:20.347703: step 42740, loss = 0.21, batch loss = 0.14 (36.1 examples/sec; 0.222 sec/batch; 17h:51m:11s remains)
INFO - root - 2017-12-17 05:29:22.619241: step 42750, loss = 0.17, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 18h:14m:49s remains)
INFO - root - 2017-12-17 05:29:24.903996: step 42760, loss = 0.18, batch loss = 0.11 (33.8 examples/sec; 0.237 sec/batch; 19h:02m:36s remains)
INFO - root - 2017-12-17 05:29:27.210842: step 42770, loss = 0.20, batch loss = 0.12 (33.0 examples/sec; 0.242 sec/batch; 19h:30m:45s remains)
INFO - root - 2017-12-17 05:29:29.500016: step 42780, loss = 0.19, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 18h:07m:00s remains)
INFO - root - 2017-12-17 05:29:31.767361: step 42790, loss = 0.18, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 17h:46m:38s remains)
INFO - root - 2017-12-17 05:29:34.026549: step 42800, loss = 0.20, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 17h:48m:16s remains)
INFO - root - 2017-12-17 05:29:36.398564: step 42810, loss = 0.19, batch loss = 0.12 (34.2 examples/sec; 0.234 sec/batch; 18h:49m:41s remains)
INFO - root - 2017-12-17 05:29:38.699687: step 42820, loss = 0.25, batch loss = 0.18 (34.7 examples/sec; 0.231 sec/batch; 18h:33m:50s remains)
INFO - root - 2017-12-17 05:29:40.973102: step 42830, loss = 0.19, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 18h:17m:20s remains)
INFO - root - 2017-12-17 05:29:43.270741: step 42840, loss = 0.25, batch loss = 0.17 (35.9 examples/sec; 0.223 sec/batch; 17h:54m:53s remains)
INFO - root - 2017-12-17 05:29:45.558421: step 42850, loss = 0.18, batch loss = 0.11 (35.2 examples/sec; 0.227 sec/batch; 18h:16m:12s remains)
INFO - root - 2017-12-17 05:29:47.806973: step 42860, loss = 0.19, batch loss = 0.12 (33.3 examples/sec; 0.240 sec/batch; 19h:19m:18s remains)
INFO - root - 2017-12-17 05:29:50.101934: step 42870, loss = 0.18, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 18h:28m:52s remains)
INFO - root - 2017-12-17 05:29:52.342636: step 42880, loss = 0.21, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 17h:46m:09s remains)
INFO - root - 2017-12-17 05:29:54.597942: step 42890, loss = 0.19, batch loss = 0.12 (34.0 examples/sec; 0.235 sec/batch; 18h:54m:38s remains)
INFO - root - 2017-12-17 05:29:56.871510: step 42900, loss = 0.17, batch loss = 0.09 (37.1 examples/sec; 0.216 sec/batch; 17h:20m:31s remains)
INFO - root - 2017-12-17 05:29:59.282135: step 42910, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 18h:09m:43s remains)
INFO - root - 2017-12-17 05:30:01.530121: step 42920, loss = 0.19, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 18h:14m:42s remains)
INFO - root - 2017-12-17 05:30:03.819026: step 42930, loss = 0.18, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 18h:17m:42s remains)
INFO - root - 2017-12-17 05:30:06.138481: step 42940, loss = 0.20, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 18h:21m:30s remains)
INFO - root - 2017-12-17 05:30:08.386991: step 42950, loss = 0.17, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 17h:47m:50s remains)
INFO - root - 2017-12-17 05:30:10.645782: step 42960, loss = 0.21, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 18h:19m:42s remains)
INFO - root - 2017-12-17 05:30:12.938963: step 42970, loss = 0.20, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 18h:27m:24s remains)
INFO - root - 2017-12-17 05:30:15.217895: step 42980, loss = 0.23, batch loss = 0.15 (35.5 examples/sec; 0.226 sec/batch; 18h:08m:10s remains)
INFO - root - 2017-12-17 05:30:17.506744: step 42990, loss = 0.20, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 18h:37m:53s remains)
INFO - root - 2017-12-17 05:30:19.764742: step 43000, loss = 0.20, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 18h:13m:17s remains)
INFO - root - 2017-12-17 05:30:22.167274: step 43010, loss = 0.17, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 18h:00m:13s remains)
INFO - root - 2017-12-17 05:30:24.429304: step 43020, loss = 0.18, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 18h:17m:33s remains)
INFO - root - 2017-12-17 05:30:26.714346: step 43030, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 18h:16m:47s remains)
INFO - root - 2017-12-17 05:30:28.982630: step 43040, loss = 0.23, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 17h:47m:17s remains)
INFO - root - 2017-12-17 05:30:31.250443: step 43050, loss = 0.22, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 18h:10m:40s remains)
INFO - root - 2017-12-17 05:30:33.532168: step 43060, loss = 0.27, batch loss = 0.20 (35.5 examples/sec; 0.226 sec/batch; 18h:07m:51s remains)
INFO - root - 2017-12-17 05:30:35.785685: step 43070, loss = 0.24, batch loss = 0.16 (36.1 examples/sec; 0.222 sec/batch; 17h:49m:05s remains)
INFO - root - 2017-12-17 05:30:38.057361: step 43080, loss = 0.21, batch loss = 0.14 (33.2 examples/sec; 0.241 sec/batch; 19h:22m:37s remains)
INFO - root - 2017-12-17 05:30:40.350117: step 43090, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 18h:04m:37s remains)
INFO - root - 2017-12-17 05:30:42.619559: step 43100, loss = 0.18, batch loss = 0.10 (35.3 examples/sec; 0.226 sec/batch; 18h:11m:36s remains)
INFO - root - 2017-12-17 05:30:45.063560: step 43110, loss = 0.18, batch loss = 0.10 (33.8 examples/sec; 0.237 sec/batch; 19h:03m:06s remains)
INFO - root - 2017-12-17 05:30:47.355386: step 43120, loss = 0.21, batch loss = 0.13 (35.0 examples/sec; 0.228 sec/batch; 18h:21m:28s remains)
INFO - root - 2017-12-17 05:30:49.602747: step 43130, loss = 0.18, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 18h:14m:32s remains)
INFO - root - 2017-12-17 05:30:51.894592: step 43140, loss = 0.20, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 18h:03m:13s remains)
INFO - root - 2017-12-17 05:30:54.194659: step 43150, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 17h:50m:44s remains)
INFO - root - 2017-12-17 05:30:56.486221: step 43160, loss = 0.17, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 17h:55m:26s remains)
INFO - root - 2017-12-17 05:30:58.759738: step 43170, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 17h:58m:35s remains)
INFO - root - 2017-12-17 05:31:01.051114: step 43180, loss = 0.20, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 18h:36m:39s remains)
INFO - root - 2017-12-17 05:31:03.388362: step 43190, loss = 0.18, batch loss = 0.10 (34.7 examples/sec; 0.230 sec/batch; 18h:31m:20s remains)
INFO - root - 2017-12-17 05:31:05.659104: step 43200, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 18h:04m:42s remains)
INFO - root - 2017-12-17 05:31:08.036092: step 43210, loss = 0.31, batch loss = 0.24 (35.8 examples/sec; 0.224 sec/batch; 17h:58m:09s remains)
INFO - root - 2017-12-17 05:31:10.267541: step 43220, loss = 0.16, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 17h:39m:21s remains)
INFO - root - 2017-12-17 05:31:12.497480: step 43230, loss = 0.18, batch loss = 0.10 (37.1 examples/sec; 0.216 sec/batch; 17h:20m:16s remains)
INFO - root - 2017-12-17 05:31:14.826117: step 43240, loss = 0.23, batch loss = 0.16 (34.1 examples/sec; 0.235 sec/batch; 18h:51m:43s remains)
INFO - root - 2017-12-17 05:31:17.107802: step 43250, loss = 0.23, batch loss = 0.16 (34.1 examples/sec; 0.234 sec/batch; 18h:49m:44s remains)
INFO - root - 2017-12-17 05:31:19.367837: step 43260, loss = 0.21, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 17h:49m:25s remains)
INFO - root - 2017-12-17 05:31:21.609168: step 43270, loss = 0.18, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 18h:35m:46s remains)
INFO - root - 2017-12-17 05:31:23.904535: step 43280, loss = 0.25, batch loss = 0.18 (34.7 examples/sec; 0.231 sec/batch; 18h:31m:11s remains)
INFO - root - 2017-12-17 05:31:26.145512: step 43290, loss = 0.19, batch loss = 0.12 (33.3 examples/sec; 0.240 sec/batch; 19h:18m:29s remains)
INFO - root - 2017-12-17 05:31:28.427835: step 43300, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.229 sec/batch; 18h:22m:28s remains)
INFO - root - 2017-12-17 05:31:30.881628: step 43310, loss = 0.22, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 18h:08m:47s remains)
INFO - root - 2017-12-17 05:31:33.139946: step 43320, loss = 0.23, batch loss = 0.15 (36.7 examples/sec; 0.218 sec/batch; 17h:30m:25s remains)
INFO - root - 2017-12-17 05:31:35.412112: step 43330, loss = 0.22, batch loss = 0.15 (35.6 examples/sec; 0.225 sec/batch; 18h:03m:08s remains)
INFO - root - 2017-12-17 05:31:37.664369: step 43340, loss = 0.23, batch loss = 0.16 (35.4 examples/sec; 0.226 sec/batch; 18h:08m:26s remains)
INFO - root - 2017-12-17 05:31:39.948596: step 43350, loss = 0.21, batch loss = 0.14 (34.2 examples/sec; 0.234 sec/batch; 18h:46m:12s remains)
INFO - root - 2017-12-17 05:31:42.238722: step 43360, loss = 0.24, batch loss = 0.17 (35.4 examples/sec; 0.226 sec/batch; 18h:09m:22s remains)
INFO - root - 2017-12-17 05:31:44.490022: step 43370, loss = 0.25, batch loss = 0.18 (36.8 examples/sec; 0.218 sec/batch; 17h:28m:22s remains)
INFO - root - 2017-12-17 05:31:46.744223: step 43380, loss = 0.19, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 17h:43m:32s remains)
INFO - root - 2017-12-17 05:31:48.999712: step 43390, loss = 0.18, batch loss = 0.10 (35.2 examples/sec; 0.227 sec/batch; 18h:15m:03s remains)
INFO - root - 2017-12-17 05:31:51.260554: step 43400, loss = 0.21, batch loss = 0.14 (35.5 examples/sec; 0.225 sec/batch; 18h:05m:07s remains)
INFO - root - 2017-12-17 05:31:53.633173: step 43410, loss = 0.17, batch loss = 0.10 (34.9 examples/sec; 0.229 sec/batch; 18h:25m:28s remains)
INFO - root - 2017-12-17 05:31:55.917172: step 43420, loss = 0.24, batch loss = 0.17 (34.0 examples/sec; 0.235 sec/batch; 18h:53m:30s remains)
INFO - root - 2017-12-17 05:31:58.176418: step 43430, loss = 0.22, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 18h:26m:46s remains)
INFO - root - 2017-12-17 05:32:00.472036: step 43440, loss = 0.22, batch loss = 0.15 (34.8 examples/sec; 0.230 sec/batch; 18h:26m:57s remains)
INFO - root - 2017-12-17 05:32:02.730965: step 43450, loss = 0.28, batch loss = 0.21 (36.3 examples/sec; 0.221 sec/batch; 17h:42m:38s remains)
INFO - root - 2017-12-17 05:32:04.978750: step 43460, loss = 0.25, batch loss = 0.17 (35.3 examples/sec; 0.227 sec/batch; 18h:12m:44s remains)
INFO - root - 2017-12-17 05:32:07.240052: step 43470, loss = 0.20, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 18h:20m:16s remains)
INFO - root - 2017-12-17 05:32:09.522851: step 43480, loss = 0.21, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 18h:22m:37s remains)
INFO - root - 2017-12-17 05:32:11.836890: step 43490, loss = 0.21, batch loss = 0.14 (34.5 examples/sec; 0.232 sec/batch; 18h:37m:42s remains)
INFO - root - 2017-12-17 05:32:14.132565: step 43500, loss = 0.20, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 18h:20m:09s remains)
INFO - root - 2017-12-17 05:32:16.506151: step 43510, loss = 0.20, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 17h:48m:14s remains)
INFO - root - 2017-12-17 05:32:18.781555: step 43520, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:08m:39s remains)
INFO - root - 2017-12-17 05:32:21.061602: step 43530, loss = 0.18, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 18h:08m:37s remains)
INFO - root - 2017-12-17 05:32:23.323733: step 43540, loss = 0.24, batch loss = 0.17 (36.7 examples/sec; 0.218 sec/batch; 17h:29m:18s remains)
INFO - root - 2017-12-17 05:32:25.640814: step 43550, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 18h:14m:45s remains)
INFO - root - 2017-12-17 05:32:27.913523: step 43560, loss = 0.24, batch loss = 0.16 (35.6 examples/sec; 0.225 sec/batch; 18h:03m:20s remains)
INFO - root - 2017-12-17 05:32:30.166223: step 43570, loss = 0.24, batch loss = 0.17 (36.3 examples/sec; 0.220 sec/batch; 17h:40m:08s remains)
INFO - root - 2017-12-17 05:32:32.414467: step 43580, loss = 0.19, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 17h:41m:07s remains)
INFO - root - 2017-12-17 05:32:34.688729: step 43590, loss = 0.21, batch loss = 0.14 (36.1 examples/sec; 0.222 sec/batch; 17h:47m:03s remains)
INFO - root - 2017-12-17 05:32:36.953425: step 43600, loss = 0.17, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 17h:58m:30s remains)
INFO - root - 2017-12-17 05:32:39.382915: step 43610, loss = 0.20, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 17h:50m:19s remains)
INFO - root - 2017-12-17 05:32:41.653993: step 43620, loss = 0.17, batch loss = 0.10 (35.1 examples/sec; 0.228 sec/batch; 18h:17m:53s remains)
INFO - root - 2017-12-17 05:32:43.931000: step 43630, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 18h:02m:05s remains)
INFO - root - 2017-12-17 05:32:46.192046: step 43640, loss = 0.22, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 17h:49m:57s remains)
INFO - root - 2017-12-17 05:32:48.441617: step 43650, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 17h:48m:31s remains)
INFO - root - 2017-12-17 05:32:50.682654: step 43660, loss = 0.16, batch loss = 0.09 (36.7 examples/sec; 0.218 sec/batch; 17h:29m:44s remains)
INFO - root - 2017-12-17 05:32:52.938253: step 43670, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 18h:12m:57s remains)
INFO - root - 2017-12-17 05:32:55.201167: step 43680, loss = 0.21, batch loss = 0.13 (36.1 examples/sec; 0.221 sec/batch; 17h:45m:40s remains)
INFO - root - 2017-12-17 05:32:57.449385: step 43690, loss = 0.18, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 18h:07m:24s remains)
INFO - root - 2017-12-17 05:32:59.728940: step 43700, loss = 0.19, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 18h:04m:12s remains)
INFO - root - 2017-12-17 05:33:02.108264: step 43710, loss = 0.21, batch loss = 0.13 (34.7 examples/sec; 0.230 sec/batch; 18h:28m:33s remains)
INFO - root - 2017-12-17 05:33:04.390782: step 43720, loss = 0.17, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 17h:52m:18s remains)
INFO - root - 2017-12-17 05:33:06.667800: step 43730, loss = 0.23, batch loss = 0.16 (34.8 examples/sec; 0.230 sec/batch; 18h:27m:19s remains)
INFO - root - 2017-12-17 05:33:08.939420: step 43740, loss = 0.22, batch loss = 0.15 (35.5 examples/sec; 0.226 sec/batch; 18h:05m:45s remains)
INFO - root - 2017-12-17 05:33:11.175877: step 43750, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 17h:50m:18s remains)
INFO - root - 2017-12-17 05:33:13.431850: step 43760, loss = 0.20, batch loss = 0.13 (34.4 examples/sec; 0.232 sec/batch; 18h:38m:21s remains)
INFO - root - 2017-12-17 05:33:15.699510: step 43770, loss = 0.23, batch loss = 0.16 (33.4 examples/sec; 0.240 sec/batch; 19h:12m:48s remains)
INFO - root - 2017-12-17 05:33:17.991488: step 43780, loss = 0.18, batch loss = 0.10 (33.4 examples/sec; 0.239 sec/batch; 19h:10m:57s remains)
INFO - root - 2017-12-17 05:33:20.226736: step 43790, loss = 0.16, batch loss = 0.09 (35.2 examples/sec; 0.227 sec/batch; 18h:12m:27s remains)
INFO - root - 2017-12-17 05:33:22.546523: step 43800, loss = 0.22, batch loss = 0.14 (31.5 examples/sec; 0.254 sec/batch; 20h:21m:15s remains)
INFO - root - 2017-12-17 05:33:24.983557: step 43810, loss = 0.20, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 18h:11m:44s remains)
INFO - root - 2017-12-17 05:33:27.246433: step 43820, loss = 0.19, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 17h:36m:19s remains)
INFO - root - 2017-12-17 05:33:29.472944: step 43830, loss = 0.17, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 17h:38m:27s remains)
INFO - root - 2017-12-17 05:33:31.707318: step 43840, loss = 0.21, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 17h:51m:59s remains)
INFO - root - 2017-12-17 05:33:33.979417: step 43850, loss = 0.24, batch loss = 0.16 (34.5 examples/sec; 0.232 sec/batch; 18h:35m:06s remains)
INFO - root - 2017-12-17 05:33:36.223843: step 43860, loss = 0.18, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 17h:55m:35s remains)
INFO - root - 2017-12-17 05:33:38.477229: step 43870, loss = 0.19, batch loss = 0.12 (36.6 examples/sec; 0.219 sec/batch; 17h:31m:11s remains)
INFO - root - 2017-12-17 05:33:40.750288: step 43880, loss = 0.19, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 18h:12m:02s remains)
INFO - root - 2017-12-17 05:33:43.030544: step 43890, loss = 0.22, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 18h:15m:41s remains)
INFO - root - 2017-12-17 05:33:45.271580: step 43900, loss = 0.22, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 17h:43m:53s remains)
INFO - root - 2017-12-17 05:33:47.658872: step 43910, loss = 0.18, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 17h:49m:54s remains)
INFO - root - 2017-12-17 05:33:49.898474: step 43920, loss = 0.20, batch loss = 0.13 (36.6 examples/sec; 0.218 sec/batch; 17h:30m:37s remains)
INFO - root - 2017-12-17 05:33:52.169036: step 43930, loss = 0.18, batch loss = 0.10 (34.7 examples/sec; 0.230 sec/batch; 18h:28m:31s remains)
INFO - root - 2017-12-17 05:33:54.465559: step 43940, loss = 0.22, batch loss = 0.15 (35.0 examples/sec; 0.229 sec/batch; 18h:19m:17s remains)
INFO - root - 2017-12-17 05:33:56.723976: step 43950, loss = 0.18, batch loss = 0.11 (35.0 examples/sec; 0.229 sec/batch; 18h:20m:08s remains)
INFO - root - 2017-12-17 05:33:58.964544: step 43960, loss = 0.22, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 17h:43m:54s remains)
INFO - root - 2017-12-17 05:34:01.235827: step 43970, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 17h:42m:03s remains)
INFO - root - 2017-12-17 05:34:03.524060: step 43980, loss = 0.22, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 17h:51m:57s remains)
INFO - root - 2017-12-17 05:34:05.768680: step 43990, loss = 0.21, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 18h:25m:00s remains)
INFO - root - 2017-12-17 05:34:08.027531: step 44000, loss = 0.20, batch loss = 0.12 (35.0 examples/sec; 0.229 sec/batch; 18h:20m:07s remains)
INFO - root - 2017-12-17 05:34:10.397088: step 44010, loss = 0.20, batch loss = 0.12 (36.6 examples/sec; 0.219 sec/batch; 17h:31m:52s remains)
INFO - root - 2017-12-17 05:34:12.691694: step 44020, loss = 0.23, batch loss = 0.16 (35.1 examples/sec; 0.228 sec/batch; 18h:17m:12s remains)
INFO - root - 2017-12-17 05:34:14.949694: step 44030, loss = 0.27, batch loss = 0.19 (36.2 examples/sec; 0.221 sec/batch; 17h:42m:07s remains)
INFO - root - 2017-12-17 05:34:17.188212: step 44040, loss = 0.16, batch loss = 0.08 (35.6 examples/sec; 0.224 sec/batch; 17h:59m:16s remains)
INFO - root - 2017-12-17 05:34:19.447650: step 44050, loss = 0.21, batch loss = 0.14 (34.3 examples/sec; 0.233 sec/batch; 18h:41m:36s remains)
INFO - root - 2017-12-17 05:34:21.737931: step 44060, loss = 0.17, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 17h:37m:35s remains)
INFO - root - 2017-12-17 05:34:24.054965: step 44070, loss = 0.22, batch loss = 0.14 (30.7 examples/sec; 0.261 sec/batch; 20h:52m:18s remains)
INFO - root - 2017-12-17 05:34:26.309388: step 44080, loss = 0.19, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 17h:35m:31s remains)
INFO - root - 2017-12-17 05:34:28.561345: step 44090, loss = 0.17, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 17h:36m:23s remains)
INFO - root - 2017-12-17 05:34:30.813395: step 44100, loss = 0.18, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 18h:31m:02s remains)
INFO - root - 2017-12-17 05:34:33.210940: step 44110, loss = 0.24, batch loss = 0.16 (35.3 examples/sec; 0.227 sec/batch; 18h:09m:57s remains)
INFO - root - 2017-12-17 05:34:35.496400: step 44120, loss = 0.24, batch loss = 0.17 (34.5 examples/sec; 0.232 sec/batch; 18h:34m:04s remains)
INFO - root - 2017-12-17 05:34:37.805376: step 44130, loss = 0.16, batch loss = 0.08 (35.9 examples/sec; 0.223 sec/batch; 17h:51m:02s remains)
INFO - root - 2017-12-17 05:34:40.078741: step 44140, loss = 0.22, batch loss = 0.14 (36.1 examples/sec; 0.221 sec/batch; 17h:44m:19s remains)
INFO - root - 2017-12-17 05:34:42.321634: step 44150, loss = 0.21, batch loss = 0.14 (36.8 examples/sec; 0.218 sec/batch; 17h:26m:08s remains)
INFO - root - 2017-12-17 05:34:44.610502: step 44160, loss = 0.19, batch loss = 0.12 (34.4 examples/sec; 0.232 sec/batch; 18h:36m:00s remains)
INFO - root - 2017-12-17 05:34:46.868215: step 44170, loss = 0.18, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 17h:58m:59s remains)
INFO - root - 2017-12-17 05:34:49.106724: step 44180, loss = 0.19, batch loss = 0.12 (35.3 examples/sec; 0.226 sec/batch; 18h:07m:53s remains)
INFO - root - 2017-12-17 05:34:51.377559: step 44190, loss = 0.20, batch loss = 0.12 (34.3 examples/sec; 0.233 sec/batch; 18h:40m:37s remains)
INFO - root - 2017-12-17 05:34:53.616592: step 44200, loss = 0.18, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 17h:50m:01s remains)
INFO - root - 2017-12-17 05:34:56.025725: step 44210, loss = 0.24, batch loss = 0.17 (34.2 examples/sec; 0.234 sec/batch; 18h:42m:59s remains)
INFO - root - 2017-12-17 05:34:58.263553: step 44220, loss = 0.18, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 17h:35m:38s remains)
INFO - root - 2017-12-17 05:35:00.520303: step 44230, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:20m:27s remains)
INFO - root - 2017-12-17 05:35:02.780835: step 44240, loss = 0.20, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 17h:35m:26s remains)
INFO - root - 2017-12-17 05:35:05.032731: step 44250, loss = 0.19, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:16m:18s remains)
INFO - root - 2017-12-17 05:35:07.317054: step 44260, loss = 0.29, batch loss = 0.21 (36.0 examples/sec; 0.222 sec/batch; 17h:48m:35s remains)
INFO - root - 2017-12-17 05:35:09.595844: step 44270, loss = 0.19, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 17h:57m:53s remains)
INFO - root - 2017-12-17 05:35:11.874322: step 44280, loss = 0.20, batch loss = 0.13 (34.7 examples/sec; 0.230 sec/batch; 18h:26m:47s remains)
INFO - root - 2017-12-17 05:35:14.136890: step 44290, loss = 0.20, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 18h:20m:18s remains)
INFO - root - 2017-12-17 05:35:16.450561: step 44300, loss = 0.17, batch loss = 0.09 (33.7 examples/sec; 0.237 sec/batch; 19h:00m:09s remains)
INFO - root - 2017-12-17 05:35:18.876042: step 44310, loss = 0.19, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 17h:51m:19s remains)
INFO - root - 2017-12-17 05:35:21.162069: step 44320, loss = 0.18, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 17h:50m:38s remains)
INFO - root - 2017-12-17 05:35:23.445827: step 44330, loss = 0.21, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 18h:40m:47s remains)
INFO - root - 2017-12-17 05:35:25.747178: step 44340, loss = 0.23, batch loss = 0.16 (35.4 examples/sec; 0.226 sec/batch; 18h:05m:10s remains)
INFO - root - 2017-12-17 05:35:28.004808: step 44350, loss = 0.19, batch loss = 0.12 (35.2 examples/sec; 0.228 sec/batch; 18h:12m:53s remains)
INFO - root - 2017-12-17 05:35:30.283366: step 44360, loss = 0.17, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 17h:56m:20s remains)
INFO - root - 2017-12-17 05:35:32.546405: step 44370, loss = 0.20, batch loss = 0.13 (34.7 examples/sec; 0.230 sec/batch; 18h:25m:54s remains)
INFO - root - 2017-12-17 05:35:34.834520: step 44380, loss = 0.22, batch loss = 0.14 (34.4 examples/sec; 0.232 sec/batch; 18h:36m:02s remains)
INFO - root - 2017-12-17 05:35:37.092974: step 44390, loss = 0.23, batch loss = 0.15 (36.6 examples/sec; 0.219 sec/batch; 17h:30m:58s remains)
INFO - root - 2017-12-17 05:35:39.377579: step 44400, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 17h:55m:09s remains)
INFO - root - 2017-12-17 05:35:41.795821: step 44410, loss = 0.22, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 17h:55m:30s remains)
INFO - root - 2017-12-17 05:35:44.085025: step 44420, loss = 0.17, batch loss = 0.10 (32.9 examples/sec; 0.243 sec/batch; 19h:26m:25s remains)
INFO - root - 2017-12-17 05:35:46.362189: step 44430, loss = 0.20, batch loss = 0.12 (34.0 examples/sec; 0.235 sec/batch; 18h:49m:45s remains)
INFO - root - 2017-12-17 05:35:48.601154: step 44440, loss = 0.16, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 17h:32m:53s remains)
INFO - root - 2017-12-17 05:35:50.863235: step 44450, loss = 0.18, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 18h:04m:16s remains)
INFO - root - 2017-12-17 05:35:53.145807: step 44460, loss = 0.21, batch loss = 0.13 (33.8 examples/sec; 0.237 sec/batch; 18h:55m:42s remains)
INFO - root - 2017-12-17 05:35:55.410288: step 44470, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.226 sec/batch; 18h:02m:32s remains)
INFO - root - 2017-12-17 05:35:57.682055: step 44480, loss = 0.17, batch loss = 0.09 (36.0 examples/sec; 0.223 sec/batch; 17h:48m:05s remains)
INFO - root - 2017-12-17 05:36:00.002775: step 44490, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.226 sec/batch; 18h:02m:58s remains)
INFO - root - 2017-12-17 05:36:02.281037: step 44500, loss = 0.17, batch loss = 0.10 (34.9 examples/sec; 0.229 sec/batch; 18h:19m:14s remains)
INFO - root - 2017-12-17 05:36:04.695420: step 44510, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:03m:35s remains)
INFO - root - 2017-12-17 05:36:06.950730: step 44520, loss = 0.22, batch loss = 0.15 (35.6 examples/sec; 0.225 sec/batch; 17h:58m:51s remains)
INFO - root - 2017-12-17 05:36:09.260336: step 44530, loss = 0.19, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 18h:07m:16s remains)
INFO - root - 2017-12-17 05:36:11.516860: step 44540, loss = 0.19, batch loss = 0.12 (33.8 examples/sec; 0.237 sec/batch; 18h:57m:05s remains)
INFO - root - 2017-12-17 05:36:13.759379: step 44550, loss = 0.17, batch loss = 0.10 (36.7 examples/sec; 0.218 sec/batch; 17h:26m:45s remains)
INFO - root - 2017-12-17 05:36:16.047215: step 44560, loss = 0.21, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 17h:58m:02s remains)
INFO - root - 2017-12-17 05:36:18.310449: step 44570, loss = 0.19, batch loss = 0.11 (34.4 examples/sec; 0.232 sec/batch; 18h:35m:18s remains)
INFO - root - 2017-12-17 05:36:20.607102: step 44580, loss = 0.17, batch loss = 0.09 (34.3 examples/sec; 0.233 sec/batch; 18h:39m:03s remains)
INFO - root - 2017-12-17 05:36:22.880627: step 44590, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:20m:08s remains)
INFO - root - 2017-12-17 05:36:25.179936: step 44600, loss = 0.20, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 17h:47m:16s remains)
INFO - root - 2017-12-17 05:36:27.563743: step 44610, loss = 0.21, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 17h:48m:31s remains)
INFO - root - 2017-12-17 05:36:29.873716: step 44620, loss = 0.21, batch loss = 0.14 (33.9 examples/sec; 0.236 sec/batch; 18h:52m:56s remains)
INFO - root - 2017-12-17 05:36:32.119542: step 44630, loss = 0.19, batch loss = 0.12 (33.6 examples/sec; 0.238 sec/batch; 19h:02m:52s remains)
INFO - root - 2017-12-17 05:36:34.386265: step 44640, loss = 0.29, batch loss = 0.22 (34.4 examples/sec; 0.233 sec/batch; 18h:36m:39s remains)
INFO - root - 2017-12-17 05:36:36.653381: step 44650, loss = 0.26, batch loss = 0.19 (34.9 examples/sec; 0.229 sec/batch; 18h:19m:55s remains)
INFO - root - 2017-12-17 05:36:38.955653: step 44660, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 17h:58m:27s remains)
INFO - root - 2017-12-17 05:36:41.215415: step 44670, loss = 0.18, batch loss = 0.10 (34.4 examples/sec; 0.232 sec/batch; 18h:34m:06s remains)
INFO - root - 2017-12-17 05:36:43.461951: step 44680, loss = 0.24, batch loss = 0.17 (35.7 examples/sec; 0.224 sec/batch; 17h:55m:32s remains)
INFO - root - 2017-12-17 05:36:45.737932: step 44690, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 17h:55m:37s remains)
INFO - root - 2017-12-17 05:36:47.996889: step 44700, loss = 0.20, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 17h:48m:14s remains)
INFO - root - 2017-12-17 05:36:50.392808: step 44710, loss = 0.18, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:12m:26s remains)
INFO - root - 2017-12-17 05:36:52.649775: step 44720, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 17h:57m:32s remains)
INFO - root - 2017-12-17 05:36:54.895583: step 44730, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:03m:44s remains)
INFO - root - 2017-12-17 05:36:57.161301: step 44740, loss = 0.19, batch loss = 0.12 (34.6 examples/sec; 0.232 sec/batch; 18h:30m:18s remains)
INFO - root - 2017-12-17 05:36:59.426060: step 44750, loss = 0.21, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 17h:59m:17s remains)
INFO - root - 2017-12-17 05:37:01.667373: step 44760, loss = 0.20, batch loss = 0.12 (35.5 examples/sec; 0.226 sec/batch; 18h:01m:27s remains)
INFO - root - 2017-12-17 05:37:03.932392: step 44770, loss = 0.17, batch loss = 0.09 (33.3 examples/sec; 0.240 sec/batch; 19h:10m:37s remains)
INFO - root - 2017-12-17 05:37:06.205345: step 44780, loss = 0.16, batch loss = 0.09 (34.8 examples/sec; 0.230 sec/batch; 18h:22m:15s remains)
INFO - root - 2017-12-17 05:37:08.475704: step 44790, loss = 0.23, batch loss = 0.16 (36.1 examples/sec; 0.222 sec/batch; 17h:42m:29s remains)
INFO - root - 2017-12-17 05:37:10.739750: step 44800, loss = 0.22, batch loss = 0.14 (35.5 examples/sec; 0.225 sec/batch; 18h:01m:01s remains)
INFO - root - 2017-12-17 05:37:13.123701: step 44810, loss = 0.22, batch loss = 0.15 (35.3 examples/sec; 0.227 sec/batch; 18h:07m:42s remains)
INFO - root - 2017-12-17 05:37:15.387471: step 44820, loss = 0.24, batch loss = 0.17 (35.2 examples/sec; 0.227 sec/batch; 18h:08m:11s remains)
INFO - root - 2017-12-17 05:37:17.644736: step 44830, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 18h:02m:41s remains)
INFO - root - 2017-12-17 05:37:19.897146: step 44840, loss = 0.20, batch loss = 0.12 (36.6 examples/sec; 0.218 sec/batch; 17h:26m:45s remains)
INFO - root - 2017-12-17 05:37:22.153166: step 44850, loss = 0.17, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 18h:06m:23s remains)
INFO - root - 2017-12-17 05:37:24.448274: step 44860, loss = 0.20, batch loss = 0.12 (36.8 examples/sec; 0.218 sec/batch; 17h:23m:33s remains)
INFO - root - 2017-12-17 05:37:26.719357: step 44870, loss = 0.20, batch loss = 0.13 (34.7 examples/sec; 0.231 sec/batch; 18h:26m:26s remains)
INFO - root - 2017-12-17 05:37:29.006826: step 44880, loss = 0.18, batch loss = 0.11 (36.3 examples/sec; 0.220 sec/batch; 17h:36m:21s remains)
INFO - root - 2017-12-17 05:37:31.271089: step 44890, loss = 0.18, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 17h:43m:19s remains)
INFO - root - 2017-12-17 05:37:33.549596: step 44900, loss = 0.19, batch loss = 0.12 (34.0 examples/sec; 0.235 sec/batch; 18h:46m:13s remains)
INFO - root - 2017-12-17 05:37:35.919498: step 44910, loss = 0.22, batch loss = 0.14 (35.8 examples/sec; 0.224 sec/batch; 17h:52m:31s remains)
INFO - root - 2017-12-17 05:37:38.203970: step 44920, loss = 0.19, batch loss = 0.12 (31.9 examples/sec; 0.251 sec/batch; 20h:03m:34s remains)
INFO - root - 2017-12-17 05:37:40.505708: step 44930, loss = 0.26, batch loss = 0.19 (35.8 examples/sec; 0.223 sec/batch; 17h:50m:43s remains)
INFO - root - 2017-12-17 05:37:42.778260: step 44940, loss = 0.19, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 17h:47m:28s remains)
INFO - root - 2017-12-17 05:37:45.048581: step 44950, loss = 0.24, batch loss = 0.16 (35.3 examples/sec; 0.226 sec/batch; 18h:05m:29s remains)
INFO - root - 2017-12-17 05:37:47.324284: step 44960, loss = 0.26, batch loss = 0.19 (34.6 examples/sec; 0.231 sec/batch; 18h:28m:57s remains)
INFO - root - 2017-12-17 05:37:49.620454: step 44970, loss = 0.19, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 18h:06m:58s remains)
INFO - root - 2017-12-17 05:37:51.876234: step 44980, loss = 0.20, batch loss = 0.13 (36.3 examples/sec; 0.220 sec/batch; 17h:35m:36s remains)
INFO - root - 2017-12-17 05:37:54.165922: step 44990, loss = 0.24, batch loss = 0.16 (33.8 examples/sec; 0.236 sec/batch; 18h:53m:11s remains)
INFO - root - 2017-12-17 05:37:56.463794: step 45000, loss = 0.21, batch loss = 0.14 (36.8 examples/sec; 0.217 sec/batch; 17h:21m:31s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-45000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-45000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 05:37:59.529551: step 45010, loss = 0.24, batch loss = 0.16 (35.4 examples/sec; 0.226 sec/batch; 18h:02m:03s remains)
INFO - root - 2017-12-17 05:38:01.788100: step 45020, loss = 0.21, batch loss = 0.14 (35.0 examples/sec; 0.229 sec/batch; 18h:16m:20s remains)
INFO - root - 2017-12-17 05:38:04.072269: step 45030, loss = 0.18, batch loss = 0.10 (36.3 examples/sec; 0.221 sec/batch; 17h:36m:28s remains)
INFO - root - 2017-12-17 05:38:06.333705: step 45040, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 18h:02m:43s remains)
INFO - root - 2017-12-17 05:38:08.583746: step 45050, loss = 0.19, batch loss = 0.12 (36.6 examples/sec; 0.219 sec/batch; 17h:28m:12s remains)
INFO - root - 2017-12-17 05:38:10.837323: step 45060, loss = 0.17, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 17h:47m:20s remains)
INFO - root - 2017-12-17 05:38:13.078844: step 45070, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 17h:38m:12s remains)
INFO - root - 2017-12-17 05:38:15.330930: step 45080, loss = 0.20, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 17h:50m:00s remains)
INFO - root - 2017-12-17 05:38:17.605128: step 45090, loss = 0.21, batch loss = 0.14 (34.7 examples/sec; 0.231 sec/batch; 18h:25m:29s remains)
INFO - root - 2017-12-17 05:38:19.876683: step 45100, loss = 0.17, batch loss = 0.09 (34.5 examples/sec; 0.232 sec/batch; 18h:30m:00s remains)
INFO - root - 2017-12-17 05:38:22.277664: step 45110, loss = 0.22, batch loss = 0.14 (33.7 examples/sec; 0.237 sec/batch; 18h:56m:24s remains)
INFO - root - 2017-12-17 05:38:24.557939: step 45120, loss = 0.20, batch loss = 0.12 (36.7 examples/sec; 0.218 sec/batch; 17h:23m:40s remains)
INFO - root - 2017-12-17 05:38:26.853729: step 45130, loss = 0.16, batch loss = 0.09 (33.2 examples/sec; 0.241 sec/batch; 19h:14m:09s remains)
INFO - root - 2017-12-17 05:38:29.158259: step 45140, loss = 0.16, batch loss = 0.09 (35.5 examples/sec; 0.225 sec/batch; 17h:59m:00s remains)
INFO - root - 2017-12-17 05:38:31.410985: step 45150, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 18h:06m:36s remains)
INFO - root - 2017-12-17 05:38:33.700685: step 45160, loss = 0.21, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 18h:27m:21s remains)
INFO - root - 2017-12-17 05:38:35.963371: step 45170, loss = 0.21, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 17h:55m:31s remains)
INFO - root - 2017-12-17 05:38:38.262521: step 45180, loss = 0.20, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 18h:12m:54s remains)
INFO - root - 2017-12-17 05:38:40.546526: step 45190, loss = 0.21, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 17h:47m:13s remains)
INFO - root - 2017-12-17 05:38:42.828464: step 45200, loss = 0.33, batch loss = 0.25 (35.6 examples/sec; 0.224 sec/batch; 17h:54m:35s remains)
INFO - root - 2017-12-17 05:38:45.272091: step 45210, loss = 0.23, batch loss = 0.16 (36.4 examples/sec; 0.220 sec/batch; 17h:32m:20s remains)
INFO - root - 2017-12-17 05:38:47.542314: step 45220, loss = 0.23, batch loss = 0.16 (35.1 examples/sec; 0.228 sec/batch; 18h:12m:17s remains)
INFO - root - 2017-12-17 05:38:49.804071: step 45230, loss = 0.24, batch loss = 0.16 (35.1 examples/sec; 0.228 sec/batch; 18h:12m:22s remains)
INFO - root - 2017-12-17 05:38:52.106780: step 45240, loss = 0.17, batch loss = 0.09 (34.7 examples/sec; 0.230 sec/batch; 18h:23m:18s remains)
INFO - root - 2017-12-17 05:38:54.375494: step 45250, loss = 0.18, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 18h:25m:15s remains)
INFO - root - 2017-12-17 05:38:56.659143: step 45260, loss = 0.17, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 18h:02m:58s remains)
INFO - root - 2017-12-17 05:38:58.960300: step 45270, loss = 0.20, batch loss = 0.12 (34.1 examples/sec; 0.234 sec/batch; 18h:42m:33s remains)
INFO - root - 2017-12-17 05:39:01.254160: step 45280, loss = 0.20, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 18h:25m:17s remains)
INFO - root - 2017-12-17 05:39:03.516280: step 45290, loss = 0.16, batch loss = 0.09 (35.3 examples/sec; 0.227 sec/batch; 18h:05m:11s remains)
INFO - root - 2017-12-17 05:39:05.758515: step 45300, loss = 0.22, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 18h:12m:24s remains)
INFO - root - 2017-12-17 05:39:08.168554: step 45310, loss = 0.20, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 18h:21m:06s remains)
INFO - root - 2017-12-17 05:39:10.453648: step 45320, loss = 0.18, batch loss = 0.10 (35.0 examples/sec; 0.228 sec/batch; 18h:13m:13s remains)
INFO - root - 2017-12-17 05:39:12.736502: step 45330, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 18h:01m:21s remains)
INFO - root - 2017-12-17 05:39:15.016183: step 45340, loss = 0.25, batch loss = 0.17 (36.5 examples/sec; 0.219 sec/batch; 17h:27m:58s remains)
INFO - root - 2017-12-17 05:39:17.291516: step 45350, loss = 0.18, batch loss = 0.11 (34.2 examples/sec; 0.234 sec/batch; 18h:40m:41s remains)
INFO - root - 2017-12-17 05:39:19.571715: step 45360, loss = 0.16, batch loss = 0.09 (34.3 examples/sec; 0.234 sec/batch; 18h:37m:38s remains)
INFO - root - 2017-12-17 05:39:21.825697: step 45370, loss = 0.21, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 18h:06m:40s remains)
INFO - root - 2017-12-17 05:39:24.074609: step 45380, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:16m:40s remains)
INFO - root - 2017-12-17 05:39:26.351689: step 45390, loss = 0.22, batch loss = 0.14 (34.8 examples/sec; 0.230 sec/batch; 18h:21m:31s remains)
INFO - root - 2017-12-17 05:39:28.636829: step 45400, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 18h:02m:18s remains)
INFO - root - 2017-12-17 05:39:31.035236: step 45410, loss = 0.26, batch loss = 0.19 (36.1 examples/sec; 0.222 sec/batch; 17h:41m:40s remains)
INFO - root - 2017-12-17 05:39:33.280172: step 45420, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 17h:42m:59s remains)
INFO - root - 2017-12-17 05:39:35.542533: step 45430, loss = 0.16, batch loss = 0.09 (33.6 examples/sec; 0.238 sec/batch; 19h:00m:34s remains)
INFO - root - 2017-12-17 05:39:37.818078: step 45440, loss = 0.21, batch loss = 0.13 (34.0 examples/sec; 0.235 sec/batch; 18h:44m:17s remains)
INFO - root - 2017-12-17 05:39:40.079731: step 45450, loss = 0.24, batch loss = 0.16 (33.9 examples/sec; 0.236 sec/batch; 18h:48m:43s remains)
INFO - root - 2017-12-17 05:39:42.349829: step 45460, loss = 0.23, batch loss = 0.15 (35.2 examples/sec; 0.228 sec/batch; 18h:08m:42s remains)
INFO - root - 2017-12-17 05:39:44.627975: step 45470, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 18h:01m:16s remains)
INFO - root - 2017-12-17 05:39:46.871711: step 45480, loss = 0.23, batch loss = 0.15 (34.1 examples/sec; 0.234 sec/batch; 18h:40m:48s remains)
INFO - root - 2017-12-17 05:39:49.169052: step 45490, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 17h:59m:41s remains)
INFO - root - 2017-12-17 05:39:51.469322: step 45500, loss = 0.19, batch loss = 0.11 (33.1 examples/sec; 0.242 sec/batch; 19h:16m:42s remains)
INFO - root - 2017-12-17 05:39:53.842754: step 45510, loss = 0.17, batch loss = 0.09 (36.2 examples/sec; 0.221 sec/batch; 17h:36m:42s remains)
INFO - root - 2017-12-17 05:39:56.130345: step 45520, loss = 0.20, batch loss = 0.13 (33.5 examples/sec; 0.239 sec/batch; 19h:03m:28s remains)
INFO - root - 2017-12-17 05:39:58.424543: step 45530, loss = 0.22, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 18h:10m:02s remains)
INFO - root - 2017-12-17 05:40:00.722384: step 45540, loss = 0.20, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 18h:16m:54s remains)
INFO - root - 2017-12-17 05:40:02.992517: step 45550, loss = 0.18, batch loss = 0.10 (33.2 examples/sec; 0.241 sec/batch; 19h:12m:49s remains)
INFO - root - 2017-12-17 05:40:05.257528: step 45560, loss = 0.22, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 17h:37m:02s remains)
INFO - root - 2017-12-17 05:40:07.502253: step 45570, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 18h:03m:13s remains)
INFO - root - 2017-12-17 05:40:09.808378: step 45580, loss = 0.20, batch loss = 0.13 (33.9 examples/sec; 0.236 sec/batch; 18h:48m:54s remains)
INFO - root - 2017-12-17 05:40:12.077900: step 45590, loss = 0.18, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 17h:46m:16s remains)
INFO - root - 2017-12-17 05:40:14.386165: step 45600, loss = 0.19, batch loss = 0.12 (31.9 examples/sec; 0.250 sec/batch; 19h:57m:33s remains)
INFO - root - 2017-12-17 05:40:16.784277: step 45610, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 17h:37m:04s remains)
INFO - root - 2017-12-17 05:40:19.054152: step 45620, loss = 0.18, batch loss = 0.11 (33.4 examples/sec; 0.240 sec/batch; 19h:06m:01s remains)
INFO - root - 2017-12-17 05:40:21.331588: step 45630, loss = 0.18, batch loss = 0.10 (36.7 examples/sec; 0.218 sec/batch; 17h:23m:36s remains)
INFO - root - 2017-12-17 05:40:23.626199: step 45640, loss = 0.22, batch loss = 0.15 (35.8 examples/sec; 0.223 sec/batch; 17h:47m:22s remains)
INFO - root - 2017-12-17 05:40:25.913393: step 45650, loss = 0.18, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 18h:28m:14s remains)
INFO - root - 2017-12-17 05:40:28.165100: step 45660, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 17h:56m:17s remains)
INFO - root - 2017-12-17 05:40:30.434675: step 45670, loss = 0.31, batch loss = 0.23 (35.6 examples/sec; 0.225 sec/batch; 17h:54m:41s remains)
INFO - root - 2017-12-17 05:40:32.710725: step 45680, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 17h:42m:35s remains)
INFO - root - 2017-12-17 05:40:35.001974: step 45690, loss = 0.21, batch loss = 0.13 (36.5 examples/sec; 0.219 sec/batch; 17h:27m:19s remains)
INFO - root - 2017-12-17 05:40:37.292622: step 45700, loss = 0.24, batch loss = 0.17 (34.8 examples/sec; 0.230 sec/batch; 18h:17m:18s remains)
INFO - root - 2017-12-17 05:40:39.732613: step 45710, loss = 0.18, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 17h:50m:35s remains)
INFO - root - 2017-12-17 05:40:41.954710: step 45720, loss = 0.20, batch loss = 0.12 (36.9 examples/sec; 0.217 sec/batch; 17h:16m:24s remains)
INFO - root - 2017-12-17 05:40:44.239510: step 45730, loss = 0.21, batch loss = 0.14 (35.8 examples/sec; 0.224 sec/batch; 17h:49m:13s remains)
INFO - root - 2017-12-17 05:40:46.524192: step 45740, loss = 0.17, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 17h:54m:03s remains)
INFO - root - 2017-12-17 05:40:48.787150: step 45750, loss = 0.17, batch loss = 0.10 (34.6 examples/sec; 0.231 sec/batch; 18h:24m:10s remains)
INFO - root - 2017-12-17 05:40:51.061121: step 45760, loss = 0.30, batch loss = 0.22 (34.9 examples/sec; 0.229 sec/batch; 18h:15m:12s remains)
INFO - root - 2017-12-17 05:40:53.315934: step 45770, loss = 0.17, batch loss = 0.10 (35.3 examples/sec; 0.227 sec/batch; 18h:02m:59s remains)
INFO - root - 2017-12-17 05:40:55.567158: step 45780, loss = 0.18, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 17h:59m:40s remains)
INFO - root - 2017-12-17 05:40:57.830076: step 45790, loss = 0.21, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 17h:40m:15s remains)
INFO - root - 2017-12-17 05:41:00.070478: step 45800, loss = 0.22, batch loss = 0.15 (33.7 examples/sec; 0.237 sec/batch; 18h:54m:22s remains)
INFO - root - 2017-12-17 05:41:02.454105: step 45810, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 17h:43m:23s remains)
INFO - root - 2017-12-17 05:41:04.720434: step 45820, loss = 0.21, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 18h:27m:06s remains)
INFO - root - 2017-12-17 05:41:06.983213: step 45830, loss = 0.21, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 17h:40m:21s remains)
INFO - root - 2017-12-17 05:41:09.257634: step 45840, loss = 0.19, batch loss = 0.12 (35.3 examples/sec; 0.226 sec/batch; 18h:01m:40s remains)
INFO - root - 2017-12-17 05:41:11.524559: step 45850, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 18h:04m:30s remains)
INFO - root - 2017-12-17 05:41:13.779466: step 45860, loss = 0.22, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 17h:42m:01s remains)
INFO - root - 2017-12-17 05:41:16.015605: step 45870, loss = 0.19, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 17h:28m:02s remains)
INFO - root - 2017-12-17 05:41:18.271847: step 45880, loss = 0.17, batch loss = 0.10 (36.8 examples/sec; 0.217 sec/batch; 17h:17m:08s remains)
INFO - root - 2017-12-17 05:41:20.574768: step 45890, loss = 0.18, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 18h:17m:36s remains)
INFO - root - 2017-12-17 05:41:22.885443: step 45900, loss = 0.19, batch loss = 0.11 (33.7 examples/sec; 0.237 sec/batch; 18h:53m:38s remains)
INFO - root - 2017-12-17 05:41:25.324047: step 45910, loss = 0.19, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 18h:23m:34s remains)
INFO - root - 2017-12-17 05:41:27.573227: step 45920, loss = 0.16, batch loss = 0.08 (35.3 examples/sec; 0.226 sec/batch; 18h:00m:56s remains)
INFO - root - 2017-12-17 05:41:29.823842: step 45930, loss = 0.16, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 17h:40m:21s remains)
INFO - root - 2017-12-17 05:41:32.073202: step 45940, loss = 0.17, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 17h:36m:22s remains)
INFO - root - 2017-12-17 05:41:34.303445: step 45950, loss = 0.22, batch loss = 0.15 (34.6 examples/sec; 0.231 sec/batch; 18h:24m:50s remains)
INFO - root - 2017-12-17 05:41:36.590679: step 45960, loss = 0.25, batch loss = 0.18 (35.6 examples/sec; 0.224 sec/batch; 17h:51m:57s remains)
INFO - root - 2017-12-17 05:41:38.948303: step 45970, loss = 0.25, batch loss = 0.17 (35.1 examples/sec; 0.228 sec/batch; 18h:07m:06s remains)
INFO - root - 2017-12-17 05:41:41.176930: step 45980, loss = 0.18, batch loss = 0.11 (36.6 examples/sec; 0.219 sec/batch; 17h:23m:30s remains)
INFO - root - 2017-12-17 05:41:43.401196: step 45990, loss = 0.20, batch loss = 0.13 (36.7 examples/sec; 0.218 sec/batch; 17h:19m:47s remains)
INFO - root - 2017-12-17 05:41:45.652229: step 46000, loss = 0.22, batch loss = 0.14 (34.4 examples/sec; 0.233 sec/batch; 18h:30m:33s remains)
INFO - root - 2017-12-17 05:41:48.063424: step 46010, loss = 0.19, batch loss = 0.11 (34.4 examples/sec; 0.232 sec/batch; 18h:29m:43s remains)
INFO - root - 2017-12-17 05:41:50.313674: step 46020, loss = 0.20, batch loss = 0.12 (36.6 examples/sec; 0.218 sec/batch; 17h:22m:40s remains)
INFO - root - 2017-12-17 05:41:52.591027: step 46030, loss = 0.20, batch loss = 0.13 (33.3 examples/sec; 0.240 sec/batch; 19h:08m:06s remains)
INFO - root - 2017-12-17 05:41:54.874600: step 46040, loss = 0.23, batch loss = 0.15 (35.3 examples/sec; 0.226 sec/batch; 18h:00m:50s remains)
INFO - root - 2017-12-17 05:41:57.127848: step 46050, loss = 0.17, batch loss = 0.09 (34.3 examples/sec; 0.233 sec/batch; 18h:34m:03s remains)
INFO - root - 2017-12-17 05:41:59.399399: step 46060, loss = 0.20, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 18h:28m:09s remains)
INFO - root - 2017-12-17 05:42:01.693371: step 46070, loss = 0.19, batch loss = 0.12 (34.4 examples/sec; 0.233 sec/batch; 18h:30m:49s remains)
INFO - root - 2017-12-17 05:42:03.932547: step 46080, loss = 0.17, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 18h:17m:25s remains)
INFO - root - 2017-12-17 05:42:06.197585: step 46090, loss = 0.24, batch loss = 0.16 (33.8 examples/sec; 0.237 sec/batch; 18h:49m:23s remains)
INFO - root - 2017-12-17 05:42:08.453918: step 46100, loss = 0.18, batch loss = 0.10 (37.0 examples/sec; 0.216 sec/batch; 17h:12m:35s remains)
INFO - root - 2017-12-17 05:42:10.851808: step 46110, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 17h:58m:42s remains)
INFO - root - 2017-12-17 05:42:13.115170: step 46120, loss = 0.16, batch loss = 0.09 (34.4 examples/sec; 0.232 sec/batch; 18h:29m:21s remains)
INFO - root - 2017-12-17 05:42:15.376962: step 46130, loss = 0.23, batch loss = 0.16 (36.1 examples/sec; 0.222 sec/batch; 17h:39m:02s remains)
INFO - root - 2017-12-17 05:42:17.636536: step 46140, loss = 0.16, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 17h:48m:15s remains)
INFO - root - 2017-12-17 05:42:19.886092: step 46150, loss = 0.17, batch loss = 0.10 (35.5 examples/sec; 0.226 sec/batch; 17h:56m:35s remains)
INFO - root - 2017-12-17 05:42:22.109105: step 46160, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 18h:02m:10s remains)
INFO - root - 2017-12-17 05:42:24.357772: step 46170, loss = 0.25, batch loss = 0.18 (35.6 examples/sec; 0.225 sec/batch; 17h:53m:38s remains)
INFO - root - 2017-12-17 05:42:26.571619: step 46180, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 17h:52m:14s remains)
INFO - root - 2017-12-17 05:42:28.827579: step 46190, loss = 0.18, batch loss = 0.10 (34.6 examples/sec; 0.231 sec/batch; 18h:22m:36s remains)
INFO - root - 2017-12-17 05:42:31.114482: step 46200, loss = 0.18, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 17h:48m:59s remains)
INFO - root - 2017-12-17 05:42:33.521251: step 46210, loss = 0.18, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 17h:26m:38s remains)
INFO - root - 2017-12-17 05:42:35.765135: step 46220, loss = 0.24, batch loss = 0.17 (36.7 examples/sec; 0.218 sec/batch; 17h:20m:16s remains)
INFO - root - 2017-12-17 05:42:38.019009: step 46230, loss = 0.24, batch loss = 0.17 (36.2 examples/sec; 0.221 sec/batch; 17h:33m:26s remains)
INFO - root - 2017-12-17 05:42:40.242956: step 46240, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.223 sec/batch; 17h:41m:36s remains)
INFO - root - 2017-12-17 05:42:42.471319: step 46250, loss = 0.17, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 17h:39m:49s remains)
INFO - root - 2017-12-17 05:42:44.793903: step 46260, loss = 0.16, batch loss = 0.09 (34.0 examples/sec; 0.235 sec/batch; 18h:41m:16s remains)
INFO - root - 2017-12-17 05:42:47.101615: step 46270, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 17h:48m:57s remains)
INFO - root - 2017-12-17 05:42:49.396268: step 46280, loss = 0.17, batch loss = 0.10 (35.5 examples/sec; 0.226 sec/batch; 17h:56m:01s remains)
INFO - root - 2017-12-17 05:42:51.620474: step 46290, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 17h:58m:30s remains)
INFO - root - 2017-12-17 05:42:53.904591: step 46300, loss = 0.18, batch loss = 0.11 (35.0 examples/sec; 0.229 sec/batch; 18h:10m:45s remains)
INFO - root - 2017-12-17 05:42:56.290390: step 46310, loss = 0.20, batch loss = 0.13 (36.1 examples/sec; 0.221 sec/batch; 17h:36m:10s remains)
INFO - root - 2017-12-17 05:42:58.528231: step 46320, loss = 0.19, batch loss = 0.12 (35.3 examples/sec; 0.227 sec/batch; 18h:00m:39s remains)
INFO - root - 2017-12-17 05:43:00.774717: step 46330, loss = 0.21, batch loss = 0.14 (36.1 examples/sec; 0.222 sec/batch; 17h:36m:49s remains)
INFO - root - 2017-12-17 05:43:03.062038: step 46340, loss = 0.23, batch loss = 0.16 (33.9 examples/sec; 0.236 sec/batch; 18h:45m:15s remains)
INFO - root - 2017-12-17 05:43:05.325394: step 46350, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:13m:29s remains)
INFO - root - 2017-12-17 05:43:07.551426: step 46360, loss = 0.19, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 17h:31m:06s remains)
INFO - root - 2017-12-17 05:43:09.798877: step 46370, loss = 0.19, batch loss = 0.12 (34.7 examples/sec; 0.230 sec/batch; 18h:18m:34s remains)
INFO - root - 2017-12-17 05:43:12.046430: step 46380, loss = 0.19, batch loss = 0.12 (34.1 examples/sec; 0.234 sec/batch; 18h:37m:27s remains)
INFO - root - 2017-12-17 05:43:14.329279: step 46390, loss = 0.19, batch loss = 0.12 (36.3 examples/sec; 0.221 sec/batch; 17h:31m:44s remains)
INFO - root - 2017-12-17 05:43:16.582381: step 46400, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 18h:08m:06s remains)
INFO - root - 2017-12-17 05:43:18.984932: step 46410, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 17h:54m:38s remains)
INFO - root - 2017-12-17 05:43:21.207638: step 46420, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 17h:32m:51s remains)
INFO - root - 2017-12-17 05:43:23.445687: step 46430, loss = 0.18, batch loss = 0.10 (36.9 examples/sec; 0.217 sec/batch; 17h:12m:40s remains)
INFO - root - 2017-12-17 05:43:25.677633: step 46440, loss = 0.28, batch loss = 0.21 (35.3 examples/sec; 0.226 sec/batch; 17h:59m:43s remains)
INFO - root - 2017-12-17 05:43:27.899462: step 46450, loss = 0.19, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 17h:50m:26s remains)
INFO - root - 2017-12-17 05:43:30.163415: step 46460, loss = 0.17, batch loss = 0.09 (35.8 examples/sec; 0.224 sec/batch; 17h:46m:21s remains)
INFO - root - 2017-12-17 05:43:32.396114: step 46470, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 17h:33m:20s remains)
INFO - root - 2017-12-17 05:43:34.682733: step 46480, loss = 0.21, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 18h:12m:14s remains)
INFO - root - 2017-12-17 05:43:36.944307: step 46490, loss = 0.22, batch loss = 0.15 (36.4 examples/sec; 0.220 sec/batch; 17h:26m:40s remains)
INFO - root - 2017-12-17 05:43:39.236687: step 46500, loss = 0.22, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 17h:56m:32s remains)
INFO - root - 2017-12-17 05:43:41.665234: step 46510, loss = 0.20, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 17h:32m:28s remains)
INFO - root - 2017-12-17 05:43:43.921625: step 46520, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 17h:56m:21s remains)
INFO - root - 2017-12-17 05:43:46.167360: step 46530, loss = 0.18, batch loss = 0.11 (36.3 examples/sec; 0.220 sec/batch; 17h:29m:07s remains)
INFO - root - 2017-12-17 05:43:48.407304: step 46540, loss = 0.25, batch loss = 0.18 (35.2 examples/sec; 0.227 sec/batch; 18h:03m:57s remains)
INFO - root - 2017-12-17 05:43:50.675214: step 46550, loss = 0.20, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 18h:12m:00s remains)
INFO - root - 2017-12-17 05:43:52.917890: step 46560, loss = 0.23, batch loss = 0.15 (35.7 examples/sec; 0.224 sec/batch; 17h:46m:31s remains)
INFO - root - 2017-12-17 05:43:55.182649: step 46570, loss = 0.20, batch loss = 0.12 (36.1 examples/sec; 0.222 sec/batch; 17h:36m:20s remains)
INFO - root - 2017-12-17 05:43:57.475692: step 46580, loss = 0.25, batch loss = 0.18 (34.6 examples/sec; 0.231 sec/batch; 18h:22m:26s remains)
INFO - root - 2017-12-17 05:43:59.756337: step 46590, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 17h:42m:04s remains)
INFO - root - 2017-12-17 05:44:01.992634: step 46600, loss = 0.21, batch loss = 0.14 (36.7 examples/sec; 0.218 sec/batch; 17h:19m:57s remains)
INFO - root - 2017-12-17 05:44:04.369680: step 46610, loss = 0.24, batch loss = 0.17 (35.3 examples/sec; 0.227 sec/batch; 18h:00m:14s remains)
INFO - root - 2017-12-17 05:44:06.586546: step 46620, loss = 0.23, batch loss = 0.16 (35.7 examples/sec; 0.224 sec/batch; 17h:46m:53s remains)
INFO - root - 2017-12-17 05:44:08.897099: step 46630, loss = 0.25, batch loss = 0.17 (36.1 examples/sec; 0.222 sec/batch; 17h:37m:10s remains)
INFO - root - 2017-12-17 05:44:11.172303: step 46640, loss = 0.20, batch loss = 0.12 (35.5 examples/sec; 0.226 sec/batch; 17h:54m:35s remains)
INFO - root - 2017-12-17 05:44:13.436092: step 46650, loss = 0.17, batch loss = 0.09 (34.6 examples/sec; 0.231 sec/batch; 18h:20m:16s remains)
INFO - root - 2017-12-17 05:44:15.690693: step 46660, loss = 0.20, batch loss = 0.13 (36.6 examples/sec; 0.219 sec/batch; 17h:21m:33s remains)
INFO - root - 2017-12-17 05:44:17.925508: step 46670, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 17h:58m:01s remains)
INFO - root - 2017-12-17 05:44:20.180259: step 46680, loss = 0.26, batch loss = 0.19 (35.4 examples/sec; 0.226 sec/batch; 17h:56m:51s remains)
INFO - root - 2017-12-17 05:44:22.475586: step 46690, loss = 0.20, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 17h:24m:48s remains)
INFO - root - 2017-12-17 05:44:24.748658: step 46700, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 18h:07m:52s remains)
INFO - root - 2017-12-17 05:44:27.174177: step 46710, loss = 0.19, batch loss = 0.12 (37.0 examples/sec; 0.216 sec/batch; 17h:09m:50s remains)
INFO - root - 2017-12-17 05:44:29.424099: step 46720, loss = 0.21, batch loss = 0.13 (34.7 examples/sec; 0.231 sec/batch; 18h:19m:38s remains)
INFO - root - 2017-12-17 05:44:31.670038: step 46730, loss = 0.24, batch loss = 0.17 (34.7 examples/sec; 0.230 sec/batch; 18h:17m:09s remains)
INFO - root - 2017-12-17 05:44:33.962936: step 46740, loss = 0.23, batch loss = 0.16 (34.6 examples/sec; 0.231 sec/batch; 18h:21m:48s remains)
INFO - root - 2017-12-17 05:44:36.235272: step 46750, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 17h:37m:05s remains)
INFO - root - 2017-12-17 05:44:38.477813: step 46760, loss = 0.20, batch loss = 0.12 (34.5 examples/sec; 0.232 sec/batch; 18h:24m:22s remains)
INFO - root - 2017-12-17 05:44:40.715717: step 46770, loss = 0.19, batch loss = 0.11 (34.7 examples/sec; 0.231 sec/batch; 18h:19m:03s remains)
INFO - root - 2017-12-17 05:44:42.994356: step 46780, loss = 0.19, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 17h:49m:59s remains)
INFO - root - 2017-12-17 05:44:45.254869: step 46790, loss = 0.27, batch loss = 0.20 (34.2 examples/sec; 0.234 sec/batch; 18h:33m:17s remains)
INFO - root - 2017-12-17 05:44:47.505044: step 46800, loss = 0.22, batch loss = 0.15 (36.3 examples/sec; 0.221 sec/batch; 17h:30m:05s remains)
INFO - root - 2017-12-17 05:44:49.895892: step 46810, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 17h:46m:39s remains)
INFO - root - 2017-12-17 05:44:52.158967: step 46820, loss = 0.20, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 17h:26m:02s remains)
INFO - root - 2017-12-17 05:44:54.436015: step 46830, loss = 0.24, batch loss = 0.17 (36.7 examples/sec; 0.218 sec/batch; 17h:17m:47s remains)
INFO - root - 2017-12-17 05:44:56.679424: step 46840, loss = 0.23, batch loss = 0.16 (36.2 examples/sec; 0.221 sec/batch; 17h:32m:43s remains)
INFO - root - 2017-12-17 05:44:58.952003: step 46850, loss = 0.21, batch loss = 0.14 (35.3 examples/sec; 0.226 sec/batch; 17h:57m:46s remains)
INFO - root - 2017-12-17 05:45:01.204829: step 46860, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 17h:52m:02s remains)
INFO - root - 2017-12-17 05:45:03.448758: step 46870, loss = 0.18, batch loss = 0.11 (37.2 examples/sec; 0.215 sec/batch; 17h:04m:28s remains)
INFO - root - 2017-12-17 05:45:05.684545: step 46880, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.228 sec/batch; 18h:06m:42s remains)
INFO - root - 2017-12-17 05:45:07.918730: step 46890, loss = 0.20, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 17h:23m:09s remains)
INFO - root - 2017-12-17 05:45:10.162433: step 46900, loss = 0.21, batch loss = 0.14 (35.2 examples/sec; 0.227 sec/batch; 18h:00m:22s remains)
INFO - root - 2017-12-17 05:45:12.569436: step 46910, loss = 0.24, batch loss = 0.16 (35.3 examples/sec; 0.227 sec/batch; 17h:58m:45s remains)
INFO - root - 2017-12-17 05:45:14.812374: step 46920, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:11m:13s remains)
INFO - root - 2017-12-17 05:45:17.081548: step 46930, loss = 0.18, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 18h:12m:39s remains)
INFO - root - 2017-12-17 05:45:19.340168: step 46940, loss = 0.19, batch loss = 0.11 (33.6 examples/sec; 0.238 sec/batch; 18h:53m:52s remains)
INFO - root - 2017-12-17 05:45:21.616479: step 46950, loss = 0.18, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 17h:55m:55s remains)
INFO - root - 2017-12-17 05:45:23.865395: step 46960, loss = 0.19, batch loss = 0.11 (34.5 examples/sec; 0.232 sec/batch; 18h:22m:17s remains)
INFO - root - 2017-12-17 05:45:26.114966: step 46970, loss = 0.20, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 18h:13m:30s remains)
INFO - root - 2017-12-17 05:45:28.370354: step 46980, loss = 0.18, batch loss = 0.10 (36.8 examples/sec; 0.217 sec/batch; 17h:14m:33s remains)
INFO - root - 2017-12-17 05:45:30.644362: step 46990, loss = 0.19, batch loss = 0.12 (34.0 examples/sec; 0.235 sec/batch; 18h:39m:52s remains)
INFO - root - 2017-12-17 05:45:32.896350: step 47000, loss = 0.20, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 17h:47m:18s remains)
INFO - root - 2017-12-17 05:45:35.299031: step 47010, loss = 0.19, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 18h:14m:24s remains)
INFO - root - 2017-12-17 05:45:37.554674: step 47020, loss = 0.18, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 17h:41m:45s remains)
INFO - root - 2017-12-17 05:45:39.798073: step 47030, loss = 0.21, batch loss = 0.14 (36.7 examples/sec; 0.218 sec/batch; 17h:17m:33s remains)
INFO - root - 2017-12-17 05:45:42.071953: step 47040, loss = 0.19, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 18h:11m:30s remains)
INFO - root - 2017-12-17 05:45:44.333364: step 47050, loss = 0.17, batch loss = 0.10 (35.3 examples/sec; 0.226 sec/batch; 17h:57m:01s remains)
INFO - root - 2017-12-17 05:45:46.582157: step 47060, loss = 0.18, batch loss = 0.11 (34.4 examples/sec; 0.233 sec/batch; 18h:27m:44s remains)
INFO - root - 2017-12-17 05:45:48.812019: step 47070, loss = 0.20, batch loss = 0.13 (36.4 examples/sec; 0.220 sec/batch; 17h:25m:23s remains)
INFO - root - 2017-12-17 05:45:51.115230: step 47080, loss = 0.18, batch loss = 0.10 (33.9 examples/sec; 0.236 sec/batch; 18h:43m:49s remains)
INFO - root - 2017-12-17 05:45:53.389008: step 47090, loss = 0.21, batch loss = 0.14 (35.8 examples/sec; 0.224 sec/batch; 17h:43m:23s remains)
INFO - root - 2017-12-17 05:45:55.651380: step 47100, loss = 0.17, batch loss = 0.10 (35.1 examples/sec; 0.228 sec/batch; 18h:03m:22s remains)
INFO - root - 2017-12-17 05:45:58.084868: step 47110, loss = 0.24, batch loss = 0.16 (35.1 examples/sec; 0.228 sec/batch; 18h:04m:36s remains)
INFO - root - 2017-12-17 05:46:00.328084: step 47120, loss = 0.21, batch loss = 0.14 (35.3 examples/sec; 0.227 sec/batch; 17h:58m:41s remains)
INFO - root - 2017-12-17 05:46:02.614531: step 47130, loss = 0.31, batch loss = 0.24 (34.7 examples/sec; 0.230 sec/batch; 18h:15m:34s remains)
INFO - root - 2017-12-17 05:46:04.893461: step 47140, loss = 0.19, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 18h:03m:02s remains)
INFO - root - 2017-12-17 05:46:07.191580: step 47150, loss = 0.21, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 17h:51m:41s remains)
INFO - root - 2017-12-17 05:46:09.467179: step 47160, loss = 0.19, batch loss = 0.11 (36.6 examples/sec; 0.219 sec/batch; 17h:19m:57s remains)
INFO - root - 2017-12-17 05:46:11.740240: step 47170, loss = 0.17, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 17h:35m:42s remains)
INFO - root - 2017-12-17 05:46:13.984342: step 47180, loss = 0.21, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 17h:36m:20s remains)
INFO - root - 2017-12-17 05:46:16.218602: step 47190, loss = 0.17, batch loss = 0.10 (36.7 examples/sec; 0.218 sec/batch; 17h:17m:46s remains)
INFO - root - 2017-12-17 05:46:18.511913: step 47200, loss = 0.17, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 17h:40m:47s remains)
INFO - root - 2017-12-17 05:46:20.934325: step 47210, loss = 0.17, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 17h:50m:08s remains)
INFO - root - 2017-12-17 05:46:23.204250: step 47220, loss = 0.22, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 17h:36m:30s remains)
INFO - root - 2017-12-17 05:46:25.476447: step 47230, loss = 0.16, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 17h:49m:19s remains)
INFO - root - 2017-12-17 05:46:27.772986: step 47240, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 17h:35m:39s remains)
INFO - root - 2017-12-17 05:46:30.030713: step 47250, loss = 0.22, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 17h:21m:46s remains)
INFO - root - 2017-12-17 05:46:32.276749: step 47260, loss = 0.20, batch loss = 0.13 (35.3 examples/sec; 0.226 sec/batch; 17h:56m:08s remains)
INFO - root - 2017-12-17 05:46:34.540847: step 47270, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 17h:47m:25s remains)
INFO - root - 2017-12-17 05:46:36.818232: step 47280, loss = 0.20, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 17h:35m:57s remains)
INFO - root - 2017-12-17 05:46:39.145846: step 47290, loss = 0.20, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 17h:39m:49s remains)
INFO - root - 2017-12-17 05:46:41.443573: step 47300, loss = 0.22, batch loss = 0.14 (35.0 examples/sec; 0.228 sec/batch; 18h:06m:02s remains)
INFO - root - 2017-12-17 05:46:43.881279: step 47310, loss = 0.20, batch loss = 0.13 (33.4 examples/sec; 0.239 sec/batch; 18h:57m:26s remains)
INFO - root - 2017-12-17 05:46:46.166344: step 47320, loss = 0.18, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 18h:11m:32s remains)
INFO - root - 2017-12-17 05:46:48.423428: step 47330, loss = 0.22, batch loss = 0.14 (35.2 examples/sec; 0.228 sec/batch; 18h:01m:35s remains)
INFO - root - 2017-12-17 05:46:50.671369: step 47340, loss = 0.17, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 17h:27m:08s remains)
INFO - root - 2017-12-17 05:46:52.923549: step 47350, loss = 0.26, batch loss = 0.19 (35.8 examples/sec; 0.223 sec/batch; 17h:40m:32s remains)
INFO - root - 2017-12-17 05:46:55.160539: step 47360, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 17h:29m:36s remains)
INFO - root - 2017-12-17 05:46:57.405690: step 47370, loss = 0.17, batch loss = 0.09 (35.5 examples/sec; 0.226 sec/batch; 17h:51m:55s remains)
INFO - root - 2017-12-17 05:46:59.650235: step 47380, loss = 0.19, batch loss = 0.11 (35.6 examples/sec; 0.224 sec/batch; 17h:46m:24s remains)
INFO - root - 2017-12-17 05:47:01.898498: step 47390, loss = 0.17, batch loss = 0.10 (34.7 examples/sec; 0.230 sec/batch; 18h:14m:55s remains)
INFO - root - 2017-12-17 05:47:04.188290: step 47400, loss = 0.18, batch loss = 0.10 (36.7 examples/sec; 0.218 sec/batch; 17h:16m:50s remains)
INFO - root - 2017-12-17 05:47:06.580995: step 47410, loss = 0.20, batch loss = 0.12 (36.5 examples/sec; 0.219 sec/batch; 17h:21m:20s remains)
INFO - root - 2017-12-17 05:47:08.873619: step 47420, loss = 0.21, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 18h:13m:45s remains)
INFO - root - 2017-12-17 05:47:11.130233: step 47430, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 17h:53m:54s remains)
INFO - root - 2017-12-17 05:47:13.406547: step 47440, loss = 0.19, batch loss = 0.12 (34.4 examples/sec; 0.232 sec/batch; 18h:23m:44s remains)
INFO - root - 2017-12-17 05:47:15.745480: step 47450, loss = 0.21, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 18h:04m:16s remains)
INFO - root - 2017-12-17 05:47:18.019858: step 47460, loss = 0.18, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 17h:37m:13s remains)
INFO - root - 2017-12-17 05:47:20.302804: step 47470, loss = 0.20, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 18h:08m:32s remains)
INFO - root - 2017-12-17 05:47:22.552169: step 47480, loss = 0.24, batch loss = 0.17 (36.5 examples/sec; 0.219 sec/batch; 17h:20m:54s remains)
INFO - root - 2017-12-17 05:47:24.844899: step 47490, loss = 0.18, batch loss = 0.10 (34.7 examples/sec; 0.231 sec/batch; 18h:16m:10s remains)
INFO - root - 2017-12-17 05:47:27.115202: step 47500, loss = 0.22, batch loss = 0.14 (35.0 examples/sec; 0.228 sec/batch; 18h:05m:14s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-47500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-47500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 05:47:30.046100: step 47510, loss = 0.23, batch loss = 0.15 (35.8 examples/sec; 0.224 sec/batch; 17h:41m:36s remains)
INFO - root - 2017-12-17 05:47:32.309040: step 47520, loss = 0.18, batch loss = 0.10 (34.2 examples/sec; 0.234 sec/batch; 18h:29m:26s remains)
INFO - root - 2017-12-17 05:47:34.559335: step 47530, loss = 0.23, batch loss = 0.15 (34.7 examples/sec; 0.230 sec/batch; 18h:13m:52s remains)
INFO - root - 2017-12-17 05:47:36.847781: step 47540, loss = 0.18, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 17h:52m:39s remains)
INFO - root - 2017-12-17 05:47:39.117672: step 47550, loss = 0.21, batch loss = 0.14 (34.1 examples/sec; 0.235 sec/batch; 18h:33m:53s remains)
INFO - root - 2017-12-17 05:47:41.381137: step 47560, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 17h:35m:57s remains)
INFO - root - 2017-12-17 05:47:43.666897: step 47570, loss = 0.21, batch loss = 0.14 (35.5 examples/sec; 0.226 sec/batch; 17h:51m:27s remains)
INFO - root - 2017-12-17 05:47:45.911033: step 47580, loss = 0.22, batch loss = 0.15 (34.8 examples/sec; 0.230 sec/batch; 18h:10m:44s remains)
INFO - root - 2017-12-17 05:47:48.204701: step 47590, loss = 0.19, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 18h:10m:13s remains)
INFO - root - 2017-12-17 05:47:50.475956: step 47600, loss = 0.21, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 17h:35m:08s remains)
INFO - root - 2017-12-17 05:47:52.903733: step 47610, loss = 0.19, batch loss = 0.12 (34.7 examples/sec; 0.231 sec/batch; 18h:14m:44s remains)
INFO - root - 2017-12-17 05:47:55.148004: step 47620, loss = 0.17, batch loss = 0.10 (37.1 examples/sec; 0.216 sec/batch; 17h:03m:46s remains)
INFO - root - 2017-12-17 05:47:57.395819: step 47630, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.226 sec/batch; 17h:54m:56s remains)
INFO - root - 2017-12-17 05:47:59.640486: step 47640, loss = 0.20, batch loss = 0.13 (36.2 examples/sec; 0.221 sec/batch; 17h:30m:26s remains)
INFO - root - 2017-12-17 05:48:01.902091: step 47650, loss = 0.21, batch loss = 0.14 (34.3 examples/sec; 0.233 sec/batch; 18h:27m:50s remains)
INFO - root - 2017-12-17 05:48:04.202262: step 47660, loss = 0.22, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 18h:02m:02s remains)
INFO - root - 2017-12-17 05:48:06.441398: step 47670, loss = 0.20, batch loss = 0.12 (35.8 examples/sec; 0.223 sec/batch; 17h:40m:10s remains)
INFO - root - 2017-12-17 05:48:08.714340: step 47680, loss = 0.18, batch loss = 0.11 (36.7 examples/sec; 0.218 sec/batch; 17h:13m:36s remains)
INFO - root - 2017-12-17 05:48:11.016269: step 47690, loss = 0.23, batch loss = 0.15 (34.3 examples/sec; 0.233 sec/batch; 18h:25m:45s remains)
INFO - root - 2017-12-17 05:48:13.292086: step 47700, loss = 0.20, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 18h:02m:16s remains)
INFO - root - 2017-12-17 05:48:15.635470: step 47710, loss = 0.26, batch loss = 0.19 (37.2 examples/sec; 0.215 sec/batch; 17h:02m:06s remains)
INFO - root - 2017-12-17 05:48:17.900630: step 47720, loss = 0.19, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 17h:32m:17s remains)
INFO - root - 2017-12-17 05:48:20.154071: step 47730, loss = 0.19, batch loss = 0.12 (35.3 examples/sec; 0.226 sec/batch; 17h:54m:59s remains)
INFO - root - 2017-12-17 05:48:22.417542: step 47740, loss = 0.17, batch loss = 0.10 (34.1 examples/sec; 0.235 sec/batch; 18h:34m:01s remains)
INFO - root - 2017-12-17 05:48:24.661326: step 47750, loss = 0.19, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 17h:48m:50s remains)
INFO - root - 2017-12-17 05:48:26.911528: step 47760, loss = 0.20, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 18h:15m:58s remains)
INFO - root - 2017-12-17 05:48:29.216161: step 47770, loss = 0.18, batch loss = 0.11 (34.7 examples/sec; 0.230 sec/batch; 18h:13m:24s remains)
INFO - root - 2017-12-17 05:48:31.486394: step 47780, loss = 0.20, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 18h:27m:00s remains)
INFO - root - 2017-12-17 05:48:33.721399: step 47790, loss = 0.22, batch loss = 0.15 (36.3 examples/sec; 0.220 sec/batch; 17h:25m:00s remains)
INFO - root - 2017-12-17 05:48:36.004939: step 47800, loss = 0.18, batch loss = 0.11 (34.0 examples/sec; 0.235 sec/batch; 18h:37m:23s remains)
INFO - root - 2017-12-17 05:48:38.394831: step 47810, loss = 0.18, batch loss = 0.11 (35.8 examples/sec; 0.223 sec/batch; 17h:39m:45s remains)
INFO - root - 2017-12-17 05:48:40.695752: step 47820, loss = 0.18, batch loss = 0.10 (34.9 examples/sec; 0.229 sec/batch; 18h:06m:16s remains)
INFO - root - 2017-12-17 05:48:42.950662: step 47830, loss = 0.21, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 17h:35m:17s remains)
INFO - root - 2017-12-17 05:48:45.198739: step 47840, loss = 0.22, batch loss = 0.15 (35.6 examples/sec; 0.224 sec/batch; 17h:44m:56s remains)
INFO - root - 2017-12-17 05:48:47.464347: step 47850, loss = 0.20, batch loss = 0.13 (35.3 examples/sec; 0.226 sec/batch; 17h:54m:11s remains)
INFO - root - 2017-12-17 05:48:49.715743: step 47860, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 17h:35m:03s remains)
INFO - root - 2017-12-17 05:48:52.003306: step 47870, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 17h:42m:51s remains)
INFO - root - 2017-12-17 05:48:54.290570: step 47880, loss = 0.20, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 17h:35m:13s remains)
INFO - root - 2017-12-17 05:48:56.529547: step 47890, loss = 0.19, batch loss = 0.12 (36.2 examples/sec; 0.221 sec/batch; 17h:28m:22s remains)
INFO - root - 2017-12-17 05:48:58.789630: step 47900, loss = 0.19, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 17h:29m:29s remains)
INFO - root - 2017-12-17 05:49:01.178186: step 47910, loss = 0.19, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 17h:50m:43s remains)
INFO - root - 2017-12-17 05:49:03.446698: step 47920, loss = 0.23, batch loss = 0.15 (34.1 examples/sec; 0.234 sec/batch; 18h:31m:26s remains)
INFO - root - 2017-12-17 05:49:05.718916: step 47930, loss = 0.19, batch loss = 0.12 (36.1 examples/sec; 0.222 sec/batch; 17h:31m:43s remains)
INFO - root - 2017-12-17 05:49:07.999939: step 47940, loss = 0.18, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 17h:19m:35s remains)
INFO - root - 2017-12-17 05:49:10.293302: step 47950, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 17h:51m:33s remains)
INFO - root - 2017-12-17 05:49:12.540782: step 47960, loss = 0.25, batch loss = 0.17 (35.4 examples/sec; 0.226 sec/batch; 17h:52m:54s remains)
INFO - root - 2017-12-17 05:49:14.805312: step 47970, loss = 0.17, batch loss = 0.10 (34.9 examples/sec; 0.229 sec/batch; 18h:06m:21s remains)
INFO - root - 2017-12-17 05:49:17.068819: step 47980, loss = 0.19, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 17h:24m:07s remains)
INFO - root - 2017-12-17 05:49:19.315397: step 47990, loss = 0.22, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 17h:52m:15s remains)
INFO - root - 2017-12-17 05:49:21.596848: step 48000, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 17h:47m:23s remains)
INFO - root - 2017-12-17 05:49:23.977045: step 48010, loss = 0.22, batch loss = 0.14 (34.7 examples/sec; 0.231 sec/batch; 18h:13m:44s remains)
INFO - root - 2017-12-17 05:49:26.220713: step 48020, loss = 0.21, batch loss = 0.14 (36.0 examples/sec; 0.222 sec/batch; 17h:34m:39s remains)
INFO - root - 2017-12-17 05:49:28.481641: step 48030, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 17h:40m:42s remains)
INFO - root - 2017-12-17 05:49:30.736301: step 48040, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 17h:34m:48s remains)
INFO - root - 2017-12-17 05:49:33.006043: step 48050, loss = 0.18, batch loss = 0.11 (32.7 examples/sec; 0.245 sec/batch; 19h:19m:12s remains)
INFO - root - 2017-12-17 05:49:35.293392: step 48060, loss = 0.20, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 18h:10m:11s remains)
INFO - root - 2017-12-17 05:49:37.541597: step 48070, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 17h:32m:52s remains)
INFO - root - 2017-12-17 05:49:39.874423: step 48080, loss = 0.17, batch loss = 0.10 (33.6 examples/sec; 0.238 sec/batch; 18h:48m:43s remains)
INFO - root - 2017-12-17 05:49:42.166246: step 48090, loss = 0.21, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 17h:28m:03s remains)
INFO - root - 2017-12-17 05:49:44.475165: step 48100, loss = 0.18, batch loss = 0.10 (34.4 examples/sec; 0.233 sec/batch; 18h:22m:29s remains)
INFO - root - 2017-12-17 05:49:46.875265: step 48110, loss = 0.18, batch loss = 0.10 (34.5 examples/sec; 0.232 sec/batch; 18h:18m:18s remains)
INFO - root - 2017-12-17 05:49:49.154184: step 48120, loss = 0.18, batch loss = 0.11 (35.0 examples/sec; 0.229 sec/batch; 18h:03m:16s remains)
INFO - root - 2017-12-17 05:49:51.380579: step 48130, loss = 0.22, batch loss = 0.14 (35.5 examples/sec; 0.226 sec/batch; 17h:49m:01s remains)
INFO - root - 2017-12-17 05:49:53.636315: step 48140, loss = 0.19, batch loss = 0.12 (37.0 examples/sec; 0.216 sec/batch; 17h:04m:58s remains)
INFO - root - 2017-12-17 05:49:55.895715: step 48150, loss = 0.22, batch loss = 0.14 (35.6 examples/sec; 0.225 sec/batch; 17h:45m:47s remains)
INFO - root - 2017-12-17 05:49:58.149986: step 48160, loss = 0.23, batch loss = 0.16 (35.5 examples/sec; 0.226 sec/batch; 17h:48m:41s remains)
INFO - root - 2017-12-17 05:50:00.397858: step 48170, loss = 0.23, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 17h:56m:19s remains)
INFO - root - 2017-12-17 05:50:02.667311: step 48180, loss = 0.26, batch loss = 0.18 (35.2 examples/sec; 0.227 sec/batch; 17h:56m:45s remains)
INFO - root - 2017-12-17 05:50:04.971237: step 48190, loss = 0.18, batch loss = 0.10 (33.3 examples/sec; 0.240 sec/batch; 18h:56m:45s remains)
INFO - root - 2017-12-17 05:50:07.255763: step 48200, loss = 0.26, batch loss = 0.19 (35.2 examples/sec; 0.227 sec/batch; 17h:56m:19s remains)
INFO - root - 2017-12-17 05:50:09.659813: step 48210, loss = 0.19, batch loss = 0.11 (34.1 examples/sec; 0.235 sec/batch; 18h:31m:27s remains)
INFO - root - 2017-12-17 05:50:11.964501: step 48220, loss = 0.16, batch loss = 0.09 (35.2 examples/sec; 0.227 sec/batch; 17h:57m:51s remains)
INFO - root - 2017-12-17 05:50:14.222903: step 48230, loss = 0.20, batch loss = 0.13 (35.0 examples/sec; 0.228 sec/batch; 18h:02m:17s remains)
INFO - root - 2017-12-17 05:50:16.466290: step 48240, loss = 0.18, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 17h:24m:04s remains)
INFO - root - 2017-12-17 05:50:18.726455: step 48250, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.225 sec/batch; 17h:46m:09s remains)
INFO - root - 2017-12-17 05:50:20.966127: step 48260, loss = 0.17, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 17h:16m:45s remains)
INFO - root - 2017-12-17 05:50:23.248353: step 48270, loss = 0.21, batch loss = 0.13 (36.6 examples/sec; 0.219 sec/batch; 17h:15m:59s remains)
INFO - root - 2017-12-17 05:50:25.514026: step 48280, loss = 0.21, batch loss = 0.13 (34.0 examples/sec; 0.235 sec/batch; 18h:35m:08s remains)
INFO - root - 2017-12-17 05:50:27.768135: step 48290, loss = 0.20, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 17h:37m:04s remains)
INFO - root - 2017-12-17 05:50:30.016309: step 48300, loss = 0.17, batch loss = 0.10 (34.9 examples/sec; 0.229 sec/batch; 18h:05m:11s remains)
INFO - root - 2017-12-17 05:50:32.411741: step 48310, loss = 0.19, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 18h:06m:07s remains)
INFO - root - 2017-12-17 05:50:34.697349: step 48320, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 17h:33m:29s remains)
INFO - root - 2017-12-17 05:50:36.970722: step 48330, loss = 0.20, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 17h:43m:31s remains)
INFO - root - 2017-12-17 05:50:39.244117: step 48340, loss = 0.23, batch loss = 0.16 (36.4 examples/sec; 0.220 sec/batch; 17h:20m:23s remains)
INFO - root - 2017-12-17 05:50:41.498944: step 48350, loss = 0.19, batch loss = 0.12 (35.3 examples/sec; 0.226 sec/batch; 17h:52m:03s remains)
INFO - root - 2017-12-17 05:50:43.767646: step 48360, loss = 0.22, batch loss = 0.15 (34.8 examples/sec; 0.230 sec/batch; 18h:08m:07s remains)
INFO - root - 2017-12-17 05:50:46.044115: step 48370, loss = 0.20, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 17h:58m:02s remains)
INFO - root - 2017-12-17 05:50:48.317676: step 48380, loss = 0.18, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 17h:40m:11s remains)
INFO - root - 2017-12-17 05:50:50.577026: step 48390, loss = 0.16, batch loss = 0.09 (35.2 examples/sec; 0.227 sec/batch; 17h:56m:16s remains)
INFO - root - 2017-12-17 05:50:52.831443: step 48400, loss = 0.22, batch loss = 0.15 (35.6 examples/sec; 0.225 sec/batch; 17h:44m:36s remains)
INFO - root - 2017-12-17 05:50:55.202720: step 48410, loss = 0.18, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 17h:29m:06s remains)
INFO - root - 2017-12-17 05:50:57.469248: step 48420, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 17h:58m:31s remains)
INFO - root - 2017-12-17 05:50:59.734049: step 48430, loss = 0.25, batch loss = 0.18 (35.6 examples/sec; 0.225 sec/batch; 17h:45m:04s remains)
INFO - root - 2017-12-17 05:51:01.989360: step 48440, loss = 0.22, batch loss = 0.15 (34.7 examples/sec; 0.231 sec/batch; 18h:12m:20s remains)
INFO - root - 2017-12-17 05:51:04.246968: step 48450, loss = 0.18, batch loss = 0.10 (36.9 examples/sec; 0.217 sec/batch; 17h:06m:53s remains)
INFO - root - 2017-12-17 05:51:06.516331: step 48460, loss = 0.16, batch loss = 0.09 (35.0 examples/sec; 0.228 sec/batch; 18h:01m:42s remains)
INFO - root - 2017-12-17 05:51:08.774311: step 48470, loss = 0.18, batch loss = 0.11 (33.8 examples/sec; 0.237 sec/batch; 18h:40m:26s remains)
INFO - root - 2017-12-17 05:51:11.020258: step 48480, loss = 0.18, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 17h:53m:08s remains)
INFO - root - 2017-12-17 05:51:13.346352: step 48490, loss = 0.17, batch loss = 0.10 (33.9 examples/sec; 0.236 sec/batch; 18h:37m:03s remains)
INFO - root - 2017-12-17 05:51:15.617283: step 48500, loss = 0.21, batch loss = 0.14 (34.5 examples/sec; 0.232 sec/batch; 18h:19m:02s remains)
INFO - root - 2017-12-17 05:51:18.023537: step 48510, loss = 0.26, batch loss = 0.19 (36.1 examples/sec; 0.221 sec/batch; 17h:27m:38s remains)
INFO - root - 2017-12-17 05:51:20.283497: step 48520, loss = 0.21, batch loss = 0.14 (34.7 examples/sec; 0.231 sec/batch; 18h:11m:13s remains)
INFO - root - 2017-12-17 05:51:22.540706: step 48530, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.226 sec/batch; 17h:47m:21s remains)
INFO - root - 2017-12-17 05:51:24.831672: step 48540, loss = 0.19, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:03m:52s remains)
INFO - root - 2017-12-17 05:51:27.068635: step 48550, loss = 0.26, batch loss = 0.18 (36.0 examples/sec; 0.222 sec/batch; 17h:32m:18s remains)
INFO - root - 2017-12-17 05:51:29.352359: step 48560, loss = 0.23, batch loss = 0.16 (35.2 examples/sec; 0.228 sec/batch; 17h:56m:53s remains)
INFO - root - 2017-12-17 05:51:31.616887: step 48570, loss = 0.23, batch loss = 0.15 (34.9 examples/sec; 0.229 sec/batch; 18h:05m:35s remains)
INFO - root - 2017-12-17 05:51:33.856083: step 48580, loss = 0.21, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 17h:49m:39s remains)
INFO - root - 2017-12-17 05:51:36.138953: step 48590, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 17h:31m:29s remains)
INFO - root - 2017-12-17 05:51:38.395941: step 48600, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.229 sec/batch; 18h:01m:34s remains)
INFO - root - 2017-12-17 05:51:40.803275: step 48610, loss = 0.24, batch loss = 0.17 (35.9 examples/sec; 0.223 sec/batch; 17h:33m:35s remains)
INFO - root - 2017-12-17 05:51:43.048800: step 48620, loss = 0.20, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 17h:38m:43s remains)
INFO - root - 2017-12-17 05:51:45.334237: step 48630, loss = 0.20, batch loss = 0.13 (34.7 examples/sec; 0.230 sec/batch; 18h:10m:22s remains)
INFO - root - 2017-12-17 05:51:47.604217: step 48640, loss = 0.18, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 17h:40m:00s remains)
INFO - root - 2017-12-17 05:51:49.897676: step 48650, loss = 0.23, batch loss = 0.16 (33.8 examples/sec; 0.236 sec/batch; 18h:38m:27s remains)
INFO - root - 2017-12-17 05:51:52.152106: step 48660, loss = 0.20, batch loss = 0.12 (35.3 examples/sec; 0.226 sec/batch; 17h:50m:58s remains)
INFO - root - 2017-12-17 05:51:54.425755: step 48670, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 17h:47m:46s remains)
INFO - root - 2017-12-17 05:51:56.689159: step 48680, loss = 0.17, batch loss = 0.10 (35.5 examples/sec; 0.226 sec/batch; 17h:47m:12s remains)
INFO - root - 2017-12-17 05:51:58.930491: step 48690, loss = 0.23, batch loss = 0.16 (36.4 examples/sec; 0.220 sec/batch; 17h:18m:43s remains)
INFO - root - 2017-12-17 05:52:01.220218: step 48700, loss = 0.27, batch loss = 0.20 (36.1 examples/sec; 0.221 sec/batch; 17h:27m:33s remains)
INFO - root - 2017-12-17 05:52:03.579891: step 48710, loss = 0.16, batch loss = 0.09 (35.9 examples/sec; 0.223 sec/batch; 17h:34m:43s remains)
INFO - root - 2017-12-17 05:52:05.829332: step 48720, loss = 0.23, batch loss = 0.16 (34.6 examples/sec; 0.231 sec/batch; 18h:14m:23s remains)
INFO - root - 2017-12-17 05:52:08.080114: step 48730, loss = 0.17, batch loss = 0.10 (37.2 examples/sec; 0.215 sec/batch; 16h:58m:00s remains)
INFO - root - 2017-12-17 05:52:10.382282: step 48740, loss = 0.19, batch loss = 0.12 (33.0 examples/sec; 0.242 sec/batch; 19h:06m:02s remains)
INFO - root - 2017-12-17 05:52:12.647492: step 48750, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 17h:37m:36s remains)
INFO - root - 2017-12-17 05:52:14.951247: step 48760, loss = 0.16, batch loss = 0.09 (36.4 examples/sec; 0.220 sec/batch; 17h:19m:07s remains)
INFO - root - 2017-12-17 05:52:17.229836: step 48770, loss = 0.17, batch loss = 0.09 (34.8 examples/sec; 0.230 sec/batch; 18h:05m:42s remains)
INFO - root - 2017-12-17 05:52:19.465004: step 48780, loss = 0.18, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 17h:36m:58s remains)
INFO - root - 2017-12-17 05:52:21.713361: step 48790, loss = 0.21, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 17h:27m:48s remains)
INFO - root - 2017-12-17 05:52:23.994353: step 48800, loss = 0.20, batch loss = 0.13 (33.3 examples/sec; 0.240 sec/batch; 18h:54m:51s remains)
INFO - root - 2017-12-17 05:52:26.385350: step 48810, loss = 0.22, batch loss = 0.15 (36.1 examples/sec; 0.222 sec/batch; 17h:27m:39s remains)
INFO - root - 2017-12-17 05:52:28.654643: step 48820, loss = 0.20, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 17h:53m:27s remains)
INFO - root - 2017-12-17 05:52:30.933827: step 48830, loss = 0.18, batch loss = 0.11 (32.0 examples/sec; 0.250 sec/batch; 19h:43m:48s remains)
INFO - root - 2017-12-17 05:52:33.262904: step 48840, loss = 0.17, batch loss = 0.10 (33.1 examples/sec; 0.241 sec/batch; 19h:01m:07s remains)
INFO - root - 2017-12-17 05:52:35.578347: step 48850, loss = 0.22, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 17h:32m:49s remains)
INFO - root - 2017-12-17 05:52:37.822236: step 48860, loss = 0.21, batch loss = 0.13 (35.6 examples/sec; 0.224 sec/batch; 17h:41m:09s remains)
INFO - root - 2017-12-17 05:52:40.135120: step 48870, loss = 0.20, batch loss = 0.13 (33.5 examples/sec; 0.239 sec/batch; 18h:48m:36s remains)
INFO - root - 2017-12-17 05:52:42.441901: step 48880, loss = 0.22, batch loss = 0.15 (35.8 examples/sec; 0.224 sec/batch; 17h:36m:55s remains)
INFO - root - 2017-12-17 05:52:44.702112: step 48890, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 17h:38m:53s remains)
INFO - root - 2017-12-17 05:52:46.942195: step 48900, loss = 0.18, batch loss = 0.11 (36.6 examples/sec; 0.219 sec/batch; 17h:12m:51s remains)
INFO - root - 2017-12-17 05:52:49.359892: step 48910, loss = 0.17, batch loss = 0.10 (33.0 examples/sec; 0.242 sec/batch; 19h:05m:50s remains)
INFO - root - 2017-12-17 05:52:51.652050: step 48920, loss = 0.19, batch loss = 0.11 (34.7 examples/sec; 0.230 sec/batch; 18h:08m:55s remains)
INFO - root - 2017-12-17 05:52:53.878348: step 48930, loss = 0.17, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 17h:27m:39s remains)
INFO - root - 2017-12-17 05:52:56.142035: step 48940, loss = 0.19, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 17h:19m:24s remains)
INFO - root - 2017-12-17 05:52:58.429434: step 48950, loss = 0.22, batch loss = 0.15 (34.1 examples/sec; 0.234 sec/batch; 18h:27m:19s remains)
INFO - root - 2017-12-17 05:53:00.734834: step 48960, loss = 0.21, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 17h:55m:35s remains)
INFO - root - 2017-12-17 05:53:03.022443: step 48970, loss = 0.19, batch loss = 0.12 (35.0 examples/sec; 0.229 sec/batch; 18h:01m:09s remains)
INFO - root - 2017-12-17 05:53:05.288995: step 48980, loss = 0.17, batch loss = 0.09 (35.7 examples/sec; 0.224 sec/batch; 17h:37m:28s remains)
INFO - root - 2017-12-17 05:53:07.540721: step 48990, loss = 0.20, batch loss = 0.13 (33.7 examples/sec; 0.237 sec/batch; 18h:40m:38s remains)
INFO - root - 2017-12-17 05:53:09.829995: step 49000, loss = 0.19, batch loss = 0.11 (33.9 examples/sec; 0.236 sec/batch; 18h:35m:38s remains)
INFO - root - 2017-12-17 05:53:12.282396: step 49010, loss = 0.20, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 17h:59m:49s remains)
INFO - root - 2017-12-17 05:53:14.527173: step 49020, loss = 0.19, batch loss = 0.12 (36.9 examples/sec; 0.217 sec/batch; 17h:03m:07s remains)
INFO - root - 2017-12-17 05:53:16.770905: step 49030, loss = 0.17, batch loss = 0.10 (36.4 examples/sec; 0.220 sec/batch; 17h:17m:59s remains)
INFO - root - 2017-12-17 05:53:19.031514: step 49040, loss = 0.17, batch loss = 0.10 (34.1 examples/sec; 0.234 sec/batch; 18h:26m:58s remains)
INFO - root - 2017-12-17 05:53:21.368768: step 49050, loss = 0.18, batch loss = 0.10 (34.6 examples/sec; 0.231 sec/batch; 18h:11m:48s remains)
INFO - root - 2017-12-17 05:53:23.637391: step 49060, loss = 0.18, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 17h:38m:53s remains)
INFO - root - 2017-12-17 05:53:25.912723: step 49070, loss = 0.18, batch loss = 0.10 (34.6 examples/sec; 0.231 sec/batch; 18h:12m:04s remains)
INFO - root - 2017-12-17 05:53:28.188176: step 49080, loss = 0.19, batch loss = 0.12 (34.3 examples/sec; 0.233 sec/batch; 18h:21m:34s remains)
INFO - root - 2017-12-17 05:53:30.410280: step 49090, loss = 0.16, batch loss = 0.09 (34.3 examples/sec; 0.234 sec/batch; 18h:23m:01s remains)
INFO - root - 2017-12-17 05:53:32.670914: step 49100, loss = 0.21, batch loss = 0.14 (36.4 examples/sec; 0.220 sec/batch; 17h:18m:43s remains)
INFO - root - 2017-12-17 05:53:35.081069: step 49110, loss = 0.18, batch loss = 0.11 (36.3 examples/sec; 0.220 sec/batch; 17h:20m:21s remains)
INFO - root - 2017-12-17 05:53:37.380614: step 49120, loss = 0.19, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 17h:32m:42s remains)
INFO - root - 2017-12-17 05:53:39.635912: step 49130, loss = 0.18, batch loss = 0.11 (36.9 examples/sec; 0.217 sec/batch; 17h:02m:34s remains)
INFO - root - 2017-12-17 05:53:41.960925: step 49140, loss = 0.19, batch loss = 0.12 (32.3 examples/sec; 0.248 sec/batch; 19h:29m:34s remains)
INFO - root - 2017-12-17 05:53:44.211741: step 49150, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 17h:40m:44s remains)
INFO - root - 2017-12-17 05:53:46.467464: step 49160, loss = 0.20, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 17h:45m:54s remains)
INFO - root - 2017-12-17 05:53:48.728259: step 49170, loss = 0.25, batch loss = 0.18 (34.6 examples/sec; 0.232 sec/batch; 18h:13m:23s remains)
INFO - root - 2017-12-17 05:53:51.033209: step 49180, loss = 0.21, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 18h:06m:36s remains)
INFO - root - 2017-12-17 05:53:53.309951: step 49190, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 17h:54m:46s remains)
INFO - root - 2017-12-17 05:53:55.543842: step 49200, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 17h:43m:12s remains)
INFO - root - 2017-12-17 05:53:57.923050: step 49210, loss = 0.18, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 17h:41m:38s remains)
INFO - root - 2017-12-17 05:54:00.166051: step 49220, loss = 0.18, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 17h:18m:10s remains)
INFO - root - 2017-12-17 05:54:02.405864: step 49230, loss = 0.23, batch loss = 0.15 (36.4 examples/sec; 0.220 sec/batch; 17h:17m:47s remains)
INFO - root - 2017-12-17 05:54:04.672861: step 49240, loss = 0.25, batch loss = 0.18 (36.3 examples/sec; 0.220 sec/batch; 17h:19m:50s remains)
INFO - root - 2017-12-17 05:54:06.978271: step 49250, loss = 0.22, batch loss = 0.15 (34.6 examples/sec; 0.231 sec/batch; 18h:10m:45s remains)
INFO - root - 2017-12-17 05:54:09.240976: step 49260, loss = 0.18, batch loss = 0.10 (35.8 examples/sec; 0.223 sec/batch; 17h:34m:04s remains)
INFO - root - 2017-12-17 05:54:11.519496: step 49270, loss = 0.24, batch loss = 0.16 (36.1 examples/sec; 0.222 sec/batch; 17h:27m:14s remains)
INFO - root - 2017-12-17 05:54:13.784298: step 49280, loss = 0.21, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 17h:56m:47s remains)
INFO - root - 2017-12-17 05:54:16.057764: step 49290, loss = 0.19, batch loss = 0.12 (34.5 examples/sec; 0.232 sec/batch; 18h:13m:35s remains)
INFO - root - 2017-12-17 05:54:18.308078: step 49300, loss = 0.22, batch loss = 0.15 (34.0 examples/sec; 0.236 sec/batch; 18h:31m:55s remains)
INFO - root - 2017-12-17 05:54:20.754296: step 49310, loss = 0.20, batch loss = 0.12 (34.4 examples/sec; 0.233 sec/batch; 18h:18m:08s remains)
INFO - root - 2017-12-17 05:54:23.037410: step 49320, loss = 0.18, batch loss = 0.11 (34.9 examples/sec; 0.229 sec/batch; 18h:02m:33s remains)
INFO - root - 2017-12-17 05:54:25.283873: step 49330, loss = 0.18, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 18h:10m:53s remains)
INFO - root - 2017-12-17 05:54:27.592265: step 49340, loss = 0.19, batch loss = 0.11 (35.1 examples/sec; 0.228 sec/batch; 17h:56m:44s remains)
INFO - root - 2017-12-17 05:54:29.845360: step 49350, loss = 0.18, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 17h:13m:24s remains)
INFO - root - 2017-12-17 05:54:32.135361: step 49360, loss = 0.21, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 17h:54m:39s remains)
INFO - root - 2017-12-17 05:54:34.372811: step 49370, loss = 0.18, batch loss = 0.10 (36.6 examples/sec; 0.219 sec/batch; 17h:11m:30s remains)
INFO - root - 2017-12-17 05:54:36.655674: step 49380, loss = 0.16, batch loss = 0.09 (34.8 examples/sec; 0.230 sec/batch; 18h:05m:53s remains)
INFO - root - 2017-12-17 05:54:38.953075: step 49390, loss = 0.21, batch loss = 0.13 (35.4 examples/sec; 0.226 sec/batch; 17h:44m:49s remains)
INFO - root - 2017-12-17 05:54:41.230237: step 49400, loss = 0.23, batch loss = 0.15 (35.4 examples/sec; 0.226 sec/batch; 17h:44m:50s remains)
INFO - root - 2017-12-17 05:54:43.605391: step 49410, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.226 sec/batch; 17h:44m:29s remains)
INFO - root - 2017-12-17 05:54:45.854418: step 49420, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 17h:27m:27s remains)
INFO - root - 2017-12-17 05:54:48.113895: step 49430, loss = 0.20, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 17h:31m:18s remains)
INFO - root - 2017-12-17 05:54:50.353904: step 49440, loss = 0.20, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 17h:39m:36s remains)
INFO - root - 2017-12-17 05:54:52.629020: step 49450, loss = 0.24, batch loss = 0.16 (33.2 examples/sec; 0.241 sec/batch; 18h:56m:49s remains)
INFO - root - 2017-12-17 05:54:54.904113: step 49460, loss = 0.17, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 17h:34m:48s remains)
INFO - root - 2017-12-17 05:54:57.163565: step 49470, loss = 0.23, batch loss = 0.15 (35.7 examples/sec; 0.224 sec/batch; 17h:38m:27s remains)
INFO - root - 2017-12-17 05:54:59.435211: step 49480, loss = 0.22, batch loss = 0.15 (36.4 examples/sec; 0.220 sec/batch; 17h:17m:17s remains)
INFO - root - 2017-12-17 05:55:01.691629: step 49490, loss = 0.18, batch loss = 0.11 (36.5 examples/sec; 0.219 sec/batch; 17h:12m:24s remains)
INFO - root - 2017-12-17 05:55:03.941985: step 49500, loss = 0.15, batch loss = 0.08 (35.4 examples/sec; 0.226 sec/batch; 17h:46m:38s remains)
INFO - root - 2017-12-17 05:55:06.341560: step 49510, loss = 0.22, batch loss = 0.15 (34.9 examples/sec; 0.229 sec/batch; 18h:01m:55s remains)
INFO - root - 2017-12-17 05:55:08.662225: step 49520, loss = 0.23, batch loss = 0.16 (34.7 examples/sec; 0.230 sec/batch; 18h:06m:50s remains)
INFO - root - 2017-12-17 05:55:10.958144: step 49530, loss = 0.20, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 18h:03m:21s remains)
INFO - root - 2017-12-17 05:55:13.222984: step 49540, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 17h:28m:27s remains)
INFO - root - 2017-12-17 05:55:15.546220: step 49550, loss = 0.23, batch loss = 0.16 (33.5 examples/sec; 0.239 sec/batch; 18h:47m:02s remains)
INFO - root - 2017-12-17 05:55:17.823571: step 49560, loss = 0.19, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 17h:59m:52s remains)
INFO - root - 2017-12-17 05:55:20.079979: step 49570, loss = 0.19, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 18h:03m:50s remains)
INFO - root - 2017-12-17 05:55:22.374854: step 49580, loss = 0.18, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 17h:44m:58s remains)
INFO - root - 2017-12-17 05:55:24.645758: step 49590, loss = 0.20, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 17h:27m:46s remains)
INFO - root - 2017-12-17 05:55:26.927334: step 49600, loss = 0.20, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 17h:56m:08s remains)
INFO - root - 2017-12-17 05:55:29.333374: step 49610, loss = 0.17, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 18h:03m:05s remains)
INFO - root - 2017-12-17 05:55:31.590423: step 49620, loss = 0.26, batch loss = 0.18 (34.6 examples/sec; 0.231 sec/batch; 18h:10m:17s remains)
INFO - root - 2017-12-17 05:55:33.882092: step 49630, loss = 0.18, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 17h:31m:37s remains)
INFO - root - 2017-12-17 05:55:36.128704: step 49640, loss = 0.20, batch loss = 0.12 (36.6 examples/sec; 0.219 sec/batch; 17h:11m:43s remains)
INFO - root - 2017-12-17 05:55:38.404672: step 49650, loss = 0.22, batch loss = 0.15 (34.4 examples/sec; 0.232 sec/batch; 18h:15m:13s remains)
INFO - root - 2017-12-17 05:55:40.712008: step 49660, loss = 0.20, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 17h:34m:02s remains)
INFO - root - 2017-12-17 05:55:42.951516: step 49670, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 17h:37m:33s remains)
INFO - root - 2017-12-17 05:55:45.226285: step 49680, loss = 0.22, batch loss = 0.15 (34.0 examples/sec; 0.235 sec/batch; 18h:28m:19s remains)
INFO - root - 2017-12-17 05:55:47.475622: step 49690, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 17h:27m:54s remains)
INFO - root - 2017-12-17 05:55:49.748346: step 49700, loss = 0.19, batch loss = 0.11 (33.4 examples/sec; 0.240 sec/batch; 18h:49m:04s remains)
INFO - root - 2017-12-17 05:55:52.132472: step 49710, loss = 0.22, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 17h:54m:09s remains)
INFO - root - 2017-12-17 05:55:54.372111: step 49720, loss = 0.19, batch loss = 0.12 (35.2 examples/sec; 0.227 sec/batch; 17h:50m:02s remains)
INFO - root - 2017-12-17 05:55:56.640033: step 49730, loss = 0.22, batch loss = 0.15 (35.1 examples/sec; 0.228 sec/batch; 17h:53m:33s remains)
INFO - root - 2017-12-17 05:55:58.924976: step 49740, loss = 0.21, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 17h:22m:22s remains)
INFO - root - 2017-12-17 05:56:01.173859: step 49750, loss = 0.22, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 17h:31m:30s remains)
INFO - root - 2017-12-17 05:56:03.440068: step 49760, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 17h:36m:43s remains)
INFO - root - 2017-12-17 05:56:05.682111: step 49770, loss = 0.20, batch loss = 0.12 (36.1 examples/sec; 0.222 sec/batch; 17h:24m:47s remains)
INFO - root - 2017-12-17 05:56:07.972315: step 49780, loss = 0.23, batch loss = 0.15 (36.5 examples/sec; 0.219 sec/batch; 17h:14m:00s remains)
INFO - root - 2017-12-17 05:56:10.246181: step 49790, loss = 0.25, batch loss = 0.17 (33.4 examples/sec; 0.240 sec/batch; 18h:50m:00s remains)
INFO - root - 2017-12-17 05:56:12.502051: step 49800, loss = 0.21, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 17h:34m:52s remains)
INFO - root - 2017-12-17 05:56:14.901646: step 49810, loss = 0.19, batch loss = 0.12 (33.9 examples/sec; 0.236 sec/batch; 18h:32m:30s remains)
INFO - root - 2017-12-17 05:56:17.184081: step 49820, loss = 0.21, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 18h:19m:33s remains)
INFO - root - 2017-12-17 05:56:19.474632: step 49830, loss = 0.18, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 17h:23m:37s remains)
INFO - root - 2017-12-17 05:56:21.739835: step 49840, loss = 0.23, batch loss = 0.16 (36.1 examples/sec; 0.222 sec/batch; 17h:24m:11s remains)
INFO - root - 2017-12-17 05:56:24.019703: step 49850, loss = 0.26, batch loss = 0.18 (36.1 examples/sec; 0.222 sec/batch; 17h:24m:14s remains)
INFO - root - 2017-12-17 05:56:26.254443: step 49860, loss = 0.22, batch loss = 0.14 (36.6 examples/sec; 0.219 sec/batch; 17h:10m:35s remains)
INFO - root - 2017-12-17 05:56:28.527376: step 49870, loss = 0.21, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 17h:28m:15s remains)
INFO - root - 2017-12-17 05:56:30.770848: step 49880, loss = 0.23, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 17h:29m:02s remains)
INFO - root - 2017-12-17 05:56:33.075303: step 49890, loss = 0.17, batch loss = 0.10 (34.9 examples/sec; 0.229 sec/batch; 17h:58m:14s remains)
INFO - root - 2017-12-17 05:56:35.323141: step 49900, loss = 0.23, batch loss = 0.16 (35.8 examples/sec; 0.224 sec/batch; 17h:33m:47s remains)
INFO - root - 2017-12-17 05:56:37.701235: step 49910, loss = 0.17, batch loss = 0.09 (35.5 examples/sec; 0.226 sec/batch; 17h:42m:45s remains)
INFO - root - 2017-12-17 05:56:39.984246: step 49920, loss = 0.22, batch loss = 0.14 (35.3 examples/sec; 0.227 sec/batch; 17h:47m:18s remains)
INFO - root - 2017-12-17 05:56:42.250644: step 49930, loss = 0.20, batch loss = 0.12 (36.4 examples/sec; 0.220 sec/batch; 17h:15m:18s remains)
INFO - root - 2017-12-17 05:56:44.516305: step 49940, loss = 0.17, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 17h:23m:23s remains)
INFO - root - 2017-12-17 05:56:46.765675: step 49950, loss = 0.24, batch loss = 0.17 (33.8 examples/sec; 0.237 sec/batch; 18h:35m:15s remains)
INFO - root - 2017-12-17 05:56:49.042112: step 49960, loss = 0.15, batch loss = 0.08 (35.2 examples/sec; 0.227 sec/batch; 17h:49m:22s remains)
INFO - root - 2017-12-17 05:56:51.300283: step 49970, loss = 0.24, batch loss = 0.17 (36.4 examples/sec; 0.220 sec/batch; 17h:16m:16s remains)
INFO - root - 2017-12-17 05:56:53.641887: step 49980, loss = 0.25, batch loss = 0.18 (34.7 examples/sec; 0.231 sec/batch; 18h:06m:58s remains)
INFO - root - 2017-12-17 05:56:55.908621: step 49990, loss = 0.20, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 18h:11m:30s remains)
INFO - root - 2017-12-17 05:56:58.203755: step 50000, loss = 0.24, batch loss = 0.16 (34.8 examples/sec; 0.230 sec/batch; 18h:01m:30s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-50000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-50000 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 05:57:01.133608: step 50010, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 17h:34m:41s remains)
INFO - root - 2017-12-17 05:57:03.405016: step 50020, loss = 0.24, batch loss = 0.17 (35.0 examples/sec; 0.229 sec/batch; 17h:56m:55s remains)
INFO - root - 2017-12-17 05:57:05.679856: step 50030, loss = 0.19, batch loss = 0.12 (36.6 examples/sec; 0.218 sec/batch; 17h:08m:15s remains)
INFO - root - 2017-12-17 05:57:07.952749: step 50040, loss = 0.19, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 18h:00m:55s remains)
INFO - root - 2017-12-17 05:57:10.282577: step 50050, loss = 0.21, batch loss = 0.14 (34.1 examples/sec; 0.235 sec/batch; 18h:25m:10s remains)
INFO - root - 2017-12-17 05:57:12.519340: step 50060, loss = 0.23, batch loss = 0.15 (36.7 examples/sec; 0.218 sec/batch; 17h:06m:07s remains)
INFO - root - 2017-12-17 05:57:14.763078: step 50070, loss = 0.23, batch loss = 0.15 (36.3 examples/sec; 0.221 sec/batch; 17h:18m:29s remains)
INFO - root - 2017-12-17 05:57:17.045209: step 50080, loss = 0.24, batch loss = 0.17 (34.8 examples/sec; 0.230 sec/batch; 18h:00m:46s remains)
INFO - root - 2017-12-17 05:57:19.294830: step 50090, loss = 0.16, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 17h:38m:41s remains)
INFO - root - 2017-12-17 05:57:21.597832: step 50100, loss = 0.19, batch loss = 0.12 (34.2 examples/sec; 0.234 sec/batch; 18h:21m:08s remains)
INFO - root - 2017-12-17 05:57:24.018546: step 50110, loss = 0.20, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 18h:01m:21s remains)
INFO - root - 2017-12-17 05:57:26.268541: step 50120, loss = 0.17, batch loss = 0.10 (36.4 examples/sec; 0.219 sec/batch; 17h:13m:01s remains)
INFO - root - 2017-12-17 05:57:28.507012: step 50130, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.223 sec/batch; 17h:30m:16s remains)
INFO - root - 2017-12-17 05:57:30.757705: step 50140, loss = 0.17, batch loss = 0.10 (34.7 examples/sec; 0.230 sec/batch; 18h:04m:28s remains)
INFO - root - 2017-12-17 05:57:33.046870: step 50150, loss = 0.23, batch loss = 0.15 (35.0 examples/sec; 0.229 sec/batch; 17h:55m:46s remains)
INFO - root - 2017-12-17 05:57:35.298941: step 50160, loss = 0.18, batch loss = 0.10 (35.4 examples/sec; 0.226 sec/batch; 17h:42m:21s remains)
INFO - root - 2017-12-17 05:57:37.551241: step 50170, loss = 0.18, batch loss = 0.11 (33.2 examples/sec; 0.241 sec/batch; 18h:55m:14s remains)
INFO - root - 2017-12-17 05:57:39.829576: step 50180, loss = 0.20, batch loss = 0.13 (34.0 examples/sec; 0.235 sec/batch; 18h:26m:32s remains)
INFO - root - 2017-12-17 05:57:42.086694: step 50190, loss = 0.20, batch loss = 0.12 (35.8 examples/sec; 0.223 sec/batch; 17h:30m:41s remains)
INFO - root - 2017-12-17 05:57:44.368016: step 50200, loss = 0.20, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 18h:01m:47s remains)
INFO - root - 2017-12-17 05:57:46.766091: step 50210, loss = 0.21, batch loss = 0.14 (34.7 examples/sec; 0.231 sec/batch; 18h:04m:59s remains)
INFO - root - 2017-12-17 05:57:49.028558: step 50220, loss = 0.20, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 17h:16m:36s remains)
INFO - root - 2017-12-17 05:57:51.313493: step 50230, loss = 0.17, batch loss = 0.10 (34.5 examples/sec; 0.232 sec/batch; 18h:10m:54s remains)
INFO - root - 2017-12-17 05:57:53.577349: step 50240, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.226 sec/batch; 17h:41m:31s remains)
INFO - root - 2017-12-17 05:57:55.838535: step 50250, loss = 0.17, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 17h:16m:39s remains)
INFO - root - 2017-12-17 05:57:58.084748: step 50260, loss = 0.20, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 17h:34m:04s remains)
INFO - root - 2017-12-17 05:58:00.333088: step 50270, loss = 0.18, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 17h:18m:34s remains)
INFO - root - 2017-12-17 05:58:02.587443: step 50280, loss = 0.22, batch loss = 0.14 (36.3 examples/sec; 0.220 sec/batch; 17h:16m:49s remains)
INFO - root - 2017-12-17 05:58:04.831291: step 50290, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 17h:24m:50s remains)
INFO - root - 2017-12-17 05:58:07.069830: step 50300, loss = 0.21, batch loss = 0.14 (35.0 examples/sec; 0.229 sec/batch; 17h:56m:11s remains)
INFO - root - 2017-12-17 05:58:09.523433: step 50310, loss = 0.19, batch loss = 0.11 (33.7 examples/sec; 0.237 sec/batch; 18h:36m:07s remains)
INFO - root - 2017-12-17 05:58:11.803535: step 50320, loss = 0.16, batch loss = 0.08 (34.6 examples/sec; 0.231 sec/batch; 18h:07m:38s remains)
INFO - root - 2017-12-17 05:58:14.075116: step 50330, loss = 0.18, batch loss = 0.10 (36.1 examples/sec; 0.222 sec/batch; 17h:23m:13s remains)
INFO - root - 2017-12-17 05:58:16.335655: step 50340, loss = 0.22, batch loss = 0.15 (34.2 examples/sec; 0.234 sec/batch; 18h:20m:20s remains)
INFO - root - 2017-12-17 05:58:18.599546: step 50350, loss = 0.21, batch loss = 0.13 (35.3 examples/sec; 0.227 sec/batch; 17h:46m:36s remains)
INFO - root - 2017-12-17 05:58:20.840431: step 50360, loss = 0.18, batch loss = 0.11 (36.1 examples/sec; 0.222 sec/batch; 17h:22m:22s remains)
INFO - root - 2017-12-17 05:58:23.133283: step 50370, loss = 0.20, batch loss = 0.12 (34.1 examples/sec; 0.235 sec/batch; 18h:23m:24s remains)
INFO - root - 2017-12-17 05:58:25.385236: step 50380, loss = 0.19, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 17h:15m:52s remains)
INFO - root - 2017-12-17 05:58:27.638493: step 50390, loss = 0.23, batch loss = 0.16 (34.4 examples/sec; 0.233 sec/batch; 18h:13m:25s remains)
INFO - root - 2017-12-17 05:58:29.933715: step 50400, loss = 0.21, batch loss = 0.13 (35.8 examples/sec; 0.224 sec/batch; 17h:31m:56s remains)
INFO - root - 2017-12-17 05:58:32.332573: step 50410, loss = 0.29, batch loss = 0.21 (36.3 examples/sec; 0.220 sec/batch; 17h:15m:49s remains)
INFO - root - 2017-12-17 05:58:34.585063: step 50420, loss = 0.21, batch loss = 0.14 (33.5 examples/sec; 0.239 sec/batch; 18h:43m:02s remains)
INFO - root - 2017-12-17 05:58:36.852672: step 50430, loss = 0.17, batch loss = 0.09 (34.8 examples/sec; 0.230 sec/batch; 18h:00m:04s remains)
INFO - root - 2017-12-17 05:58:39.172227: step 50440, loss = 0.22, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 17h:58m:03s remains)
INFO - root - 2017-12-17 05:58:41.411534: step 50450, loss = 0.21, batch loss = 0.14 (36.1 examples/sec; 0.221 sec/batch; 17h:20m:31s remains)
INFO - root - 2017-12-17 05:58:43.681261: step 50460, loss = 0.24, batch loss = 0.17 (35.6 examples/sec; 0.224 sec/batch; 17h:35m:14s remains)
INFO - root - 2017-12-17 05:58:45.968012: step 50470, loss = 0.25, batch loss = 0.17 (35.5 examples/sec; 0.225 sec/batch; 17h:38m:31s remains)
INFO - root - 2017-12-17 05:58:48.231952: step 50480, loss = 0.21, batch loss = 0.13 (36.0 examples/sec; 0.222 sec/batch; 17h:24m:00s remains)
INFO - root - 2017-12-17 05:58:50.483665: step 50490, loss = 0.18, batch loss = 0.11 (36.6 examples/sec; 0.218 sec/batch; 17h:06m:13s remains)
INFO - root - 2017-12-17 05:58:52.767907: step 50500, loss = 0.18, batch loss = 0.10 (33.6 examples/sec; 0.238 sec/batch; 18h:38m:30s remains)
INFO - root - 2017-12-17 05:58:55.203010: step 50510, loss = 0.29, batch loss = 0.21 (35.9 examples/sec; 0.223 sec/batch; 17h:26m:53s remains)
INFO - root - 2017-12-17 05:58:57.470254: step 50520, loss = 0.17, batch loss = 0.10 (34.0 examples/sec; 0.235 sec/batch; 18h:25m:52s remains)
INFO - root - 2017-12-17 05:58:59.739337: step 50530, loss = 0.18, batch loss = 0.11 (35.7 examples/sec; 0.224 sec/batch; 17h:33m:59s remains)
INFO - root - 2017-12-17 05:59:02.002943: step 50540, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 17h:33m:27s remains)
INFO - root - 2017-12-17 05:59:04.293153: step 50550, loss = 0.21, batch loss = 0.14 (32.6 examples/sec; 0.246 sec/batch; 19h:14m:19s remains)
INFO - root - 2017-12-17 05:59:06.601208: step 50560, loss = 0.21, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 18h:05m:03s remains)
INFO - root - 2017-12-17 05:59:08.856822: step 50570, loss = 0.16, batch loss = 0.09 (36.0 examples/sec; 0.222 sec/batch; 17h:24m:15s remains)
INFO - root - 2017-12-17 05:59:11.089675: step 50580, loss = 0.19, batch loss = 0.11 (35.9 examples/sec; 0.223 sec/batch; 17h:26m:30s remains)
INFO - root - 2017-12-17 05:59:13.340522: step 50590, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 17h:50m:41s remains)
INFO - root - 2017-12-17 05:59:15.597138: step 50600, loss = 0.17, batch loss = 0.10 (36.9 examples/sec; 0.217 sec/batch; 16h:57m:34s remains)
INFO - root - 2017-12-17 05:59:18.000056: step 50610, loss = 0.18, batch loss = 0.11 (34.1 examples/sec; 0.235 sec/batch; 18h:22m:58s remains)
INFO - root - 2017-12-17 05:59:20.310327: step 50620, loss = 0.23, batch loss = 0.15 (34.8 examples/sec; 0.230 sec/batch; 18h:00m:34s remains)
INFO - root - 2017-12-17 05:59:22.555549: step 50630, loss = 0.18, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 17h:17m:25s remains)
INFO - root - 2017-12-17 05:59:24.840424: step 50640, loss = 0.33, batch loss = 0.25 (36.3 examples/sec; 0.220 sec/batch; 17h:14m:54s remains)
INFO - root - 2017-12-17 05:59:27.128029: step 50650, loss = 0.21, batch loss = 0.13 (33.8 examples/sec; 0.237 sec/batch; 18h:32m:15s remains)
INFO - root - 2017-12-17 05:59:29.400587: step 50660, loss = 0.20, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 17h:51m:22s remains)
INFO - root - 2017-12-17 05:59:31.676482: step 50670, loss = 0.17, batch loss = 0.10 (33.5 examples/sec; 0.239 sec/batch; 18h:40m:37s remains)
INFO - root - 2017-12-17 05:59:33.958749: step 50680, loss = 0.25, batch loss = 0.18 (35.4 examples/sec; 0.226 sec/batch; 17h:42m:42s remains)
INFO - root - 2017-12-17 05:59:36.225406: step 50690, loss = 0.20, batch loss = 0.13 (35.8 examples/sec; 0.224 sec/batch; 17h:29m:56s remains)
INFO - root - 2017-12-17 05:59:38.506164: step 50700, loss = 0.17, batch loss = 0.10 (33.6 examples/sec; 0.238 sec/batch; 18h:36m:46s remains)
INFO - root - 2017-12-17 05:59:40.901144: step 50710, loss = 0.17, batch loss = 0.10 (35.8 examples/sec; 0.224 sec/batch; 17h:30m:06s remains)
INFO - root - 2017-12-17 05:59:43.207825: step 50720, loss = 0.21, batch loss = 0.13 (34.8 examples/sec; 0.230 sec/batch; 18h:00m:41s remains)
INFO - root - 2017-12-17 05:59:45.451553: step 50730, loss = 0.19, batch loss = 0.12 (36.6 examples/sec; 0.218 sec/batch; 17h:05m:23s remains)
INFO - root - 2017-12-17 05:59:47.719126: step 50740, loss = 0.23, batch loss = 0.16 (34.6 examples/sec; 0.231 sec/batch; 18h:04m:46s remains)
INFO - root - 2017-12-17 05:59:50.025757: step 50750, loss = 0.21, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 17h:50m:31s remains)
INFO - root - 2017-12-17 05:59:52.284020: step 50760, loss = 0.16, batch loss = 0.09 (35.5 examples/sec; 0.225 sec/batch; 17h:38m:38s remains)
INFO - root - 2017-12-17 05:59:54.599615: step 50770, loss = 0.23, batch loss = 0.16 (35.4 examples/sec; 0.226 sec/batch; 17h:41m:20s remains)
INFO - root - 2017-12-17 05:59:56.864894: step 50780, loss = 0.18, batch loss = 0.10 (36.8 examples/sec; 0.217 sec/batch; 16h:59m:22s remains)
INFO - root - 2017-12-17 05:59:59.164567: step 50790, loss = 0.16, batch loss = 0.09 (34.8 examples/sec; 0.230 sec/batch; 17h:59m:13s remains)
INFO - root - 2017-12-17 06:00:01.445270: step 50800, loss = 0.16, batch loss = 0.09 (34.3 examples/sec; 0.233 sec/batch; 18h:15m:16s remains)
INFO - root - 2017-12-17 06:00:03.857417: step 50810, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.223 sec/batch; 17h:28m:02s remains)
INFO - root - 2017-12-17 06:00:06.121324: step 50820, loss = 0.23, batch loss = 0.15 (36.1 examples/sec; 0.222 sec/batch; 17h:20m:57s remains)
INFO - root - 2017-12-17 06:00:08.391916: step 50830, loss = 0.17, batch loss = 0.10 (35.1 examples/sec; 0.228 sec/batch; 17h:49m:46s remains)
INFO - root - 2017-12-17 06:00:10.684576: step 50840, loss = 0.21, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 17h:56m:13s remains)
INFO - root - 2017-12-17 06:00:12.964258: step 50850, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.225 sec/batch; 17h:36m:22s remains)
INFO - root - 2017-12-17 06:00:15.222876: step 50860, loss = 0.21, batch loss = 0.14 (35.0 examples/sec; 0.229 sec/batch; 17h:53m:31s remains)
INFO - root - 2017-12-17 06:00:17.468068: step 50870, loss = 0.21, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 17h:18m:08s remains)
INFO - root - 2017-12-17 06:00:19.756000: step 50880, loss = 0.17, batch loss = 0.10 (33.7 examples/sec; 0.237 sec/batch; 18h:32m:35s remains)
INFO - root - 2017-12-17 06:00:22.021635: step 50890, loss = 0.18, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 17h:22m:53s remains)
INFO - root - 2017-12-17 06:00:24.252687: step 50900, loss = 0.18, batch loss = 0.11 (36.4 examples/sec; 0.220 sec/batch; 17h:12m:41s remains)
INFO - root - 2017-12-17 06:00:26.665650: step 50910, loss = 0.20, batch loss = 0.13 (34.5 examples/sec; 0.232 sec/batch; 18h:06m:48s remains)
INFO - root - 2017-12-17 06:00:28.930424: step 50920, loss = 0.24, batch loss = 0.17 (34.3 examples/sec; 0.233 sec/batch; 18h:13m:58s remains)
INFO - root - 2017-12-17 06:00:31.188910: step 50930, loss = 0.28, batch loss = 0.21 (35.5 examples/sec; 0.225 sec/batch; 17h:36m:40s remains)
INFO - root - 2017-12-17 06:00:33.460364: step 50940, loss = 0.16, batch loss = 0.08 (36.0 examples/sec; 0.222 sec/batch; 17h:21m:51s remains)
INFO - root - 2017-12-17 06:00:35.725248: step 50950, loss = 0.17, batch loss = 0.10 (35.3 examples/sec; 0.226 sec/batch; 17h:42m:45s remains)
INFO - root - 2017-12-17 06:00:38.005625: step 50960, loss = 0.26, batch loss = 0.19 (33.8 examples/sec; 0.237 sec/batch; 18h:30m:56s remains)
INFO - root - 2017-12-17 06:00:40.252687: step 50970, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.227 sec/batch; 17h:46m:06s remains)
INFO - root - 2017-12-17 06:00:42.542970: step 50980, loss = 0.19, batch loss = 0.11 (32.9 examples/sec; 0.243 sec/batch; 19h:00m:18s remains)
INFO - root - 2017-12-17 06:00:44.785680: step 50990, loss = 0.21, batch loss = 0.13 (36.1 examples/sec; 0.222 sec/batch; 17h:19m:35s remains)
INFO - root - 2017-12-17 06:00:47.072835: step 51000, loss = 0.21, batch loss = 0.13 (33.0 examples/sec; 0.243 sec/batch; 18h:58m:02s remains)
INFO - root - 2017-12-17 06:00:49.480493: step 51010, loss = 0.21, batch loss = 0.13 (34.9 examples/sec; 0.229 sec/batch; 17h:56m:20s remains)
INFO - root - 2017-12-17 06:00:51.740612: step 51020, loss = 0.18, batch loss = 0.11 (34.6 examples/sec; 0.231 sec/batch; 18h:03m:55s remains)
INFO - root - 2017-12-17 06:00:54.025702: step 51030, loss = 0.20, batch loss = 0.12 (35.3 examples/sec; 0.226 sec/batch; 17h:42m:11s remains)
INFO - root - 2017-12-17 06:00:56.269800: step 51040, loss = 0.22, batch loss = 0.15 (36.3 examples/sec; 0.221 sec/batch; 17h:15m:12s remains)
INFO - root - 2017-12-17 06:00:58.534683: step 51050, loss = 0.19, batch loss = 0.12 (33.4 examples/sec; 0.240 sec/batch; 18h:44m:23s remains)
INFO - root - 2017-12-17 06:01:00.818338: step 51060, loss = 0.18, batch loss = 0.10 (34.8 examples/sec; 0.230 sec/batch; 17h:57m:24s remains)
INFO - root - 2017-12-17 06:01:03.071919: step 51070, loss = 0.16, batch loss = 0.09 (36.5 examples/sec; 0.219 sec/batch; 17h:08m:02s remains)
INFO - root - 2017-12-17 06:01:05.331493: step 51080, loss = 0.20, batch loss = 0.13 (34.3 examples/sec; 0.233 sec/batch; 18h:12m:52s remains)
INFO - root - 2017-12-17 06:01:07.583005: step 51090, loss = 0.18, batch loss = 0.11 (34.8 examples/sec; 0.230 sec/batch; 17h:59m:23s remains)
INFO - root - 2017-12-17 06:01:09.828607: step 51100, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 17h:47m:59s remains)
INFO - root - 2017-12-17 06:01:12.177957: step 51110, loss = 0.17, batch loss = 0.10 (36.2 examples/sec; 0.221 sec/batch; 17h:16m:06s remains)
INFO - root - 2017-12-17 06:01:14.413907: step 51120, loss = 0.22, batch loss = 0.15 (36.5 examples/sec; 0.219 sec/batch; 17h:08m:40s remains)
INFO - root - 2017-12-17 06:01:16.654015: step 51130, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 17h:34m:39s remains)
INFO - root - 2017-12-17 06:01:18.923192: step 51140, loss = 0.18, batch loss = 0.10 (37.2 examples/sec; 0.215 sec/batch; 16h:48m:35s remains)
INFO - root - 2017-12-17 06:01:21.169033: step 51150, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 17h:24m:20s remains)
INFO - root - 2017-12-17 06:01:23.444372: step 51160, loss = 0.21, batch loss = 0.14 (34.9 examples/sec; 0.229 sec/batch; 17h:55m:50s remains)
INFO - root - 2017-12-17 06:01:25.721276: step 51170, loss = 0.18, batch loss = 0.10 (34.5 examples/sec; 0.232 sec/batch; 18h:05m:49s remains)
INFO - root - 2017-12-17 06:01:28.042239: step 51180, loss = 0.18, batch loss = 0.10 (35.6 examples/sec; 0.225 sec/batch; 17h:34m:18s remains)
INFO - root - 2017-12-17 06:01:30.332738: step 51190, loss = 0.17, batch loss = 0.10 (35.8 examples/sec; 0.223 sec/batch; 17h:26m:42s remains)
INFO - root - 2017-12-17 06:01:32.597854: step 51200, loss = 0.17, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 17h:29m:28s remains)
INFO - root - 2017-12-17 06:01:34.966787: step 51210, loss = 0.17, batch loss = 0.10 (34.7 examples/sec; 0.230 sec/batch; 18h:00m:35s remains)
INFO - root - 2017-12-17 06:01:37.221350: step 51220, loss = 0.20, batch loss = 0.12 (35.4 examples/sec; 0.226 sec/batch; 17h:40m:03s remains)
INFO - root - 2017-12-17 06:01:39.530334: step 51230, loss = 0.19, batch loss = 0.11 (35.4 examples/sec; 0.226 sec/batch; 17h:39m:06s remains)
INFO - root - 2017-12-17 06:01:41.797992: step 51240, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 17h:25m:29s remains)
INFO - root - 2017-12-17 06:01:44.076322: step 51250, loss = 0.20, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 17h:53m:45s remains)
INFO - root - 2017-12-17 06:01:46.340527: step 51260, loss = 0.23, batch loss = 0.16 (35.8 examples/sec; 0.224 sec/batch; 17h:28m:18s remains)
INFO - root - 2017-12-17 06:01:48.591904: step 51270, loss = 0.22, batch loss = 0.15 (34.9 examples/sec; 0.229 sec/batch; 17h:52m:59s remains)
INFO - root - 2017-12-17 06:01:50.815532: step 51280, loss = 0.20, batch loss = 0.12 (36.6 examples/sec; 0.219 sec/batch; 17h:04m:10s remains)
INFO - root - 2017-12-17 06:01:53.082208: step 51290, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 17h:30m:45s remains)
INFO - root - 2017-12-17 06:01:55.349962: step 51300, loss = 0.19, batch loss = 0.11 (34.7 examples/sec; 0.230 sec/batch; 18h:00m:05s remains)
INFO - root - 2017-12-17 06:01:57.746994: step 51310, loss = 0.20, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 17h:34m:19s remains)
INFO - root - 2017-12-17 06:01:59.991429: step 51320, loss = 0.19, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 17h:14m:30s remains)
INFO - root - 2017-12-17 06:02:02.269680: step 51330, loss = 0.19, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 18h:04m:37s remains)
INFO - root - 2017-12-17 06:02:04.542043: step 51340, loss = 0.20, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 18h:02m:31s remains)
INFO - root - 2017-12-17 06:02:06.845653: step 51350, loss = 0.17, batch loss = 0.10 (35.0 examples/sec; 0.229 sec/batch; 17h:52m:20s remains)
INFO - root - 2017-12-17 06:02:09.179369: step 51360, loss = 0.22, batch loss = 0.14 (33.6 examples/sec; 0.238 sec/batch; 18h:37m:04s remains)
INFO - root - 2017-12-17 06:02:11.442064: step 51370, loss = 0.19, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 17h:58m:22s remains)
INFO - root - 2017-12-17 06:02:13.737769: step 51380, loss = 0.20, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 17h:48m:35s remains)
INFO - root - 2017-12-17 06:02:16.013492: step 51390, loss = 0.21, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 17h:33m:48s remains)
INFO - root - 2017-12-17 06:02:18.255012: step 51400, loss = 0.20, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 17h:28m:07s remains)
INFO - root - 2017-12-17 06:02:20.625276: step 51410, loss = 0.22, batch loss = 0.15 (34.4 examples/sec; 0.233 sec/batch; 18h:10m:24s remains)
INFO - root - 2017-12-17 06:02:22.965479: step 51420, loss = 0.20, batch loss = 0.13 (35.5 examples/sec; 0.226 sec/batch; 17h:36m:46s remains)
INFO - root - 2017-12-17 06:02:25.220173: step 51430, loss = 0.16, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 17h:33m:57s remains)
INFO - root - 2017-12-17 06:02:27.455721: step 51440, loss = 0.21, batch loss = 0.14 (35.4 examples/sec; 0.226 sec/batch; 17h:38m:19s remains)
INFO - root - 2017-12-17 06:02:29.719803: step 51450, loss = 0.28, batch loss = 0.21 (35.6 examples/sec; 0.225 sec/batch; 17h:31m:39s remains)
INFO - root - 2017-12-17 06:02:31.999516: step 51460, loss = 0.23, batch loss = 0.15 (34.9 examples/sec; 0.229 sec/batch; 17h:54m:13s remains)
INFO - root - 2017-12-17 06:02:34.254133: step 51470, loss = 0.19, batch loss = 0.11 (36.0 examples/sec; 0.222 sec/batch; 17h:20m:16s remains)
INFO - root - 2017-12-17 06:02:36.538243: step 51480, loss = 0.28, batch loss = 0.20 (35.3 examples/sec; 0.227 sec/batch; 17h:42m:36s remains)
INFO - root - 2017-12-17 06:02:38.794475: step 51490, loss = 0.23, batch loss = 0.15 (34.7 examples/sec; 0.230 sec/batch; 17h:58m:48s remains)
INFO - root - 2017-12-17 06:02:41.084369: step 51500, loss = 0.17, batch loss = 0.10 (34.7 examples/sec; 0.231 sec/batch; 18h:00m:36s remains)
INFO - root - 2017-12-17 06:02:43.522847: step 51510, loss = 0.16, batch loss = 0.09 (37.1 examples/sec; 0.216 sec/batch; 16h:50m:19s remains)
INFO - root - 2017-12-17 06:02:45.810673: step 51520, loss = 0.18, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 17h:14m:19s remains)
INFO - root - 2017-12-17 06:02:48.070851: step 51530, loss = 0.19, batch loss = 0.12 (35.8 examples/sec; 0.224 sec/batch; 17h:26m:53s remains)
INFO - root - 2017-12-17 06:02:50.352281: step 51540, loss = 0.19, batch loss = 0.11 (33.7 examples/sec; 0.238 sec/batch; 18h:32m:09s remains)
INFO - root - 2017-12-17 06:02:52.601390: step 51550, loss = 0.24, batch loss = 0.16 (34.9 examples/sec; 0.229 sec/batch; 17h:54m:04s remains)
INFO - root - 2017-12-17 06:02:54.865262: step 51560, loss = 0.19, batch loss = 0.11 (33.8 examples/sec; 0.237 sec/batch; 18h:29m:29s remains)
INFO - root - 2017-12-17 06:02:57.144309: step 51570, loss = 0.25, batch loss = 0.18 (33.6 examples/sec; 0.238 sec/batch; 18h:36m:24s remains)
INFO - root - 2017-12-17 06:02:59.392334: step 51580, loss = 0.24, batch loss = 0.17 (34.9 examples/sec; 0.230 sec/batch; 17h:54m:31s remains)
INFO - root - 2017-12-17 06:03:01.675981: step 51590, loss = 0.17, batch loss = 0.10 (35.7 examples/sec; 0.224 sec/batch; 17h:30m:15s remains)
INFO - root - 2017-12-17 06:03:03.934785: step 51600, loss = 0.20, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 17h:25m:27s remains)
INFO - root - 2017-12-17 06:03:06.380154: step 51610, loss = 0.22, batch loss = 0.14 (34.6 examples/sec; 0.231 sec/batch; 18h:03m:01s remains)
INFO - root - 2017-12-17 06:03:08.627551: step 51620, loss = 0.18, batch loss = 0.11 (35.0 examples/sec; 0.229 sec/batch; 17h:51m:11s remains)
INFO - root - 2017-12-17 06:03:10.900107: step 51630, loss = 0.19, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 18h:02m:34s remains)
INFO - root - 2017-12-17 06:03:13.186531: step 51640, loss = 0.29, batch loss = 0.21 (35.4 examples/sec; 0.226 sec/batch; 17h:39m:04s remains)
INFO - root - 2017-12-17 06:03:15.437010: step 51650, loss = 0.21, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 17h:46m:26s remains)
INFO - root - 2017-12-17 06:03:17.709390: step 51660, loss = 0.20, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 17h:28m:36s remains)
INFO - root - 2017-12-17 06:03:20.007766: step 51670, loss = 0.22, batch loss = 0.14 (34.5 examples/sec; 0.232 sec/batch; 18h:05m:56s remains)
INFO - root - 2017-12-17 06:03:22.277297: step 51680, loss = 0.20, batch loss = 0.13 (36.5 examples/sec; 0.219 sec/batch; 17h:05m:40s remains)
INFO - root - 2017-12-17 06:03:24.574134: step 51690, loss = 0.19, batch loss = 0.11 (36.2 examples/sec; 0.221 sec/batch; 17h:13m:11s remains)
INFO - root - 2017-12-17 06:03:26.822243: step 51700, loss = 0.18, batch loss = 0.11 (35.2 examples/sec; 0.227 sec/batch; 17h:43m:21s remains)
INFO - root - 2017-12-17 06:03:29.170809: step 51710, loss = 0.17, batch loss = 0.10 (36.1 examples/sec; 0.221 sec/batch; 17h:15m:45s remains)
INFO - root - 2017-12-17 06:03:31.397809: step 51720, loss = 0.28, batch loss = 0.20 (37.7 examples/sec; 0.212 sec/batch; 16h:33m:21s remains)
INFO - root - 2017-12-17 06:03:33.698427: step 51730, loss = 0.20, batch loss = 0.13 (35.9 examples/sec; 0.223 sec/batch; 17h:24m:00s remains)
INFO - root - 2017-12-17 06:03:36.009449: step 51740, loss = 0.19, batch loss = 0.12 (32.6 examples/sec; 0.246 sec/batch; 19h:09m:15s remains)
INFO - root - 2017-12-17 06:03:38.251432: step 51750, loss = 0.17, batch loss = 0.10 (36.3 examples/sec; 0.220 sec/batch; 17h:11m:18s remains)
INFO - root - 2017-12-17 06:03:40.496995: step 51760, loss = 0.20, batch loss = 0.12 (35.5 examples/sec; 0.226 sec/batch; 17h:35m:06s remains)
INFO - root - 2017-12-17 06:03:42.737956: step 51770, loss = 0.20, batch loss = 0.13 (35.7 examples/sec; 0.224 sec/batch; 17h:29m:05s remains)
INFO - root - 2017-12-17 06:03:45.013844: step 51780, loss = 0.23, batch loss = 0.15 (36.0 examples/sec; 0.222 sec/batch; 17h:20m:36s remains)
INFO - root - 2017-12-17 06:03:47.270676: step 51790, loss = 0.22, batch loss = 0.14 (36.2 examples/sec; 0.221 sec/batch; 17h:13m:14s remains)
INFO - root - 2017-12-17 06:03:49.518175: step 51800, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 17h:29m:35s remains)
INFO - root - 2017-12-17 06:03:51.927182: step 51810, loss = 0.19, batch loss = 0.12 (34.9 examples/sec; 0.229 sec/batch; 17h:51m:56s remains)
INFO - root - 2017-12-17 06:03:54.161291: step 51820, loss = 0.21, batch loss = 0.13 (35.0 examples/sec; 0.229 sec/batch; 17h:50m:08s remains)
INFO - root - 2017-12-17 06:03:56.438535: step 51830, loss = 0.26, batch loss = 0.19 (35.4 examples/sec; 0.226 sec/batch; 17h:36m:03s remains)
INFO - root - 2017-12-17 06:03:58.715666: step 51840, loss = 0.21, batch loss = 0.13 (35.8 examples/sec; 0.223 sec/batch; 17h:24m:14s remains)
INFO - root - 2017-12-17 06:04:00.998068: step 51850, loss = 0.21, batch loss = 0.14 (35.9 examples/sec; 0.223 sec/batch; 17h:23m:29s remains)
INFO - root - 2017-12-17 06:04:03.287250: step 51860, loss = 0.16, batch loss = 0.09 (35.6 examples/sec; 0.225 sec/batch; 17h:30m:58s remains)
INFO - root - 2017-12-17 06:04:05.552448: step 51870, loss = 0.21, batch loss = 0.14 (37.2 examples/sec; 0.215 sec/batch; 16h:46m:47s remains)
INFO - root - 2017-12-17 06:04:07.841357: step 51880, loss = 0.17, batch loss = 0.10 (34.9 examples/sec; 0.230 sec/batch; 17h:53m:25s remains)
INFO - root - 2017-12-17 06:04:10.118742: step 51890, loss = 0.17, batch loss = 0.10 (36.5 examples/sec; 0.219 sec/batch; 17h:03m:57s remains)
INFO - root - 2017-12-17 06:04:12.420509: step 51900, loss = 0.21, batch loss = 0.13 (35.1 examples/sec; 0.228 sec/batch; 17h:46m:26s remains)
INFO - root - 2017-12-17 06:04:14.806195: step 51910, loss = 0.21, batch loss = 0.14 (34.2 examples/sec; 0.234 sec/batch; 18h:13m:18s remains)
INFO - root - 2017-12-17 06:04:17.068802: step 51920, loss = 0.19, batch loss = 0.12 (36.3 examples/sec; 0.220 sec/batch; 17h:09m:13s remains)
INFO - root - 2017-12-17 06:04:19.294113: step 51930, loss = 0.16, batch loss = 0.09 (36.7 examples/sec; 0.218 sec/batch; 16h:58m:58s remains)
INFO - root - 2017-12-17 06:04:21.606886: step 51940, loss = 0.19, batch loss = 0.12 (33.1 examples/sec; 0.242 sec/batch; 18h:49m:42s remains)
INFO - root - 2017-12-17 06:04:23.911691: step 51950, loss = 0.22, batch loss = 0.15 (35.7 examples/sec; 0.224 sec/batch; 17h:29m:11s remains)
INFO - root - 2017-12-17 06:04:26.155743: step 51960, loss = 0.18, batch loss = 0.11 (36.6 examples/sec; 0.218 sec/batch; 17h:01m:00s remains)
INFO - root - 2017-12-17 06:04:28.402852: step 51970, loss = 0.23, batch loss = 0.15 (35.2 examples/sec; 0.227 sec/batch; 17h:42m:48s remains)
INFO - root - 2017-12-17 06:04:30.682122: step 51980, loss = 0.18, batch loss = 0.11 (35.6 examples/sec; 0.225 sec/batch; 17h:30m:01s remains)
INFO - root - 2017-12-17 06:04:32.945295: step 51990, loss = 0.20, batch loss = 0.12 (35.5 examples/sec; 0.225 sec/batch; 17h:32m:27s remains)
INFO - root - 2017-12-17 06:04:35.180226: step 52000, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 17h:30m:49s remains)
INFO - root - 2017-12-17 06:04:37.649842: step 52010, loss = 0.19, batch loss = 0.12 (36.0 examples/sec; 0.222 sec/batch; 17h:18m:44s remains)
INFO - root - 2017-12-17 06:04:39.952068: step 52020, loss = 0.16, batch loss = 0.09 (35.5 examples/sec; 0.225 sec/batch; 17h:33m:04s remains)
INFO - root - 2017-12-17 06:04:42.230133: step 52030, loss = 0.20, batch loss = 0.13 (31.5 examples/sec; 0.254 sec/batch; 19h:45m:53s remains)
INFO - root - 2017-12-17 06:04:44.493736: step 52040, loss = 0.24, batch loss = 0.16 (35.6 examples/sec; 0.225 sec/batch; 17h:30m:03s remains)
INFO - root - 2017-12-17 06:04:46.775566: step 52050, loss = 0.18, batch loss = 0.10 (36.0 examples/sec; 0.222 sec/batch; 17h:19m:12s remains)
INFO - root - 2017-12-17 06:04:49.074314: step 52060, loss = 0.22, batch loss = 0.15 (36.2 examples/sec; 0.221 sec/batch; 17h:13m:58s remains)
INFO - root - 2017-12-17 06:04:51.361600: step 52070, loss = 0.24, batch loss = 0.16 (34.1 examples/sec; 0.235 sec/batch; 18h:17m:42s remains)
INFO - root - 2017-12-17 06:04:53.621775: step 52080, loss = 0.21, batch loss = 0.14 (35.1 examples/sec; 0.228 sec/batch; 17h:45m:56s remains)
INFO - root - 2017-12-17 06:04:55.877714: step 52090, loss = 0.19, batch loss = 0.12 (33.5 examples/sec; 0.239 sec/batch; 18h:35m:39s remains)
INFO - root - 2017-12-17 06:04:58.157585: step 52100, loss = 0.17, batch loss = 0.10 (35.8 examples/sec; 0.223 sec/batch; 17h:23m:07s remains)
INFO - root - 2017-12-17 06:05:00.524563: step 52110, loss = 0.19, batch loss = 0.12 (35.7 examples/sec; 0.224 sec/batch; 17h:26m:58s remains)
INFO - root - 2017-12-17 06:05:02.771158: step 52120, loss = 0.24, batch loss = 0.17 (32.9 examples/sec; 0.243 sec/batch; 18h:55m:23s remains)
INFO - root - 2017-12-17 06:05:05.077550: step 52130, loss = 0.19, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 17h:44m:53s remains)
INFO - root - 2017-12-17 06:05:07.380006: step 52140, loss = 0.21, batch loss = 0.13 (34.7 examples/sec; 0.231 sec/batch; 17h:57m:36s remains)
INFO - root - 2017-12-17 06:05:09.639781: step 52150, loss = 0.19, batch loss = 0.12 (34.8 examples/sec; 0.230 sec/batch; 17h:54m:10s remains)
INFO - root - 2017-12-17 06:05:11.936068: step 52160, loss = 0.18, batch loss = 0.11 (35.5 examples/sec; 0.226 sec/batch; 17h:34m:20s remains)
INFO - root - 2017-12-17 06:05:14.170660: step 52170, loss = 0.24, batch loss = 0.16 (35.9 examples/sec; 0.223 sec/batch; 17h:19m:55s remains)
INFO - root - 2017-12-17 06:05:16.418396: step 52180, loss = 0.23, batch loss = 0.16 (35.6 examples/sec; 0.225 sec/batch; 17h:30m:23s remains)
INFO - root - 2017-12-17 06:05:18.682085: step 52190, loss = 0.22, batch loss = 0.14 (36.5 examples/sec; 0.219 sec/batch; 17h:02m:44s remains)
INFO - root - 2017-12-17 06:05:20.955716: step 52200, loss = 0.24, batch loss = 0.17 (34.8 examples/sec; 0.230 sec/batch; 17h:54m:51s remains)
INFO - root - 2017-12-17 06:05:23.344713: step 52210, loss = 0.16, batch loss = 0.09 (33.9 examples/sec; 0.236 sec/batch; 18h:22m:20s remains)
INFO - root - 2017-12-17 06:05:25.632026: step 52220, loss = 0.17, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 17h:35m:22s remains)
INFO - root - 2017-12-17 06:05:27.965947: step 52230, loss = 0.17, batch loss = 0.10 (35.8 examples/sec; 0.223 sec/batch; 17h:23m:29s remains)
INFO - root - 2017-12-17 06:05:30.214230: step 52240, loss = 0.24, batch loss = 0.17 (35.5 examples/sec; 0.225 sec/batch; 17h:32m:50s remains)
INFO - root - 2017-12-17 06:05:32.466427: step 52250, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.224 sec/batch; 17h:24m:40s remains)
INFO - root - 2017-12-17 06:05:34.728745: step 52260, loss = 0.18, batch loss = 0.11 (36.1 examples/sec; 0.221 sec/batch; 17h:14m:28s remains)
INFO - root - 2017-12-17 06:05:37.025310: step 52270, loss = 0.20, batch loss = 0.13 (35.2 examples/sec; 0.228 sec/batch; 17h:42m:44s remains)
INFO - root - 2017-12-17 06:05:39.285418: step 52280, loss = 0.21, batch loss = 0.13 (35.0 examples/sec; 0.228 sec/batch; 17h:46m:08s remains)
INFO - root - 2017-12-17 06:05:41.537260: step 52290, loss = 0.27, batch loss = 0.20 (35.9 examples/sec; 0.223 sec/batch; 17h:20m:56s remains)
INFO - root - 2017-12-17 06:05:43.817862: step 52300, loss = 0.21, batch loss = 0.13 (33.8 examples/sec; 0.237 sec/batch; 18h:26m:45s remains)
INFO - root - 2017-12-17 06:05:46.201287: step 52310, loss = 0.17, batch loss = 0.09 (35.4 examples/sec; 0.226 sec/batch; 17h:36m:49s remains)
INFO - root - 2017-12-17 06:05:48.455237: step 52320, loss = 0.19, batch loss = 0.11 (35.3 examples/sec; 0.227 sec/batch; 17h:39m:23s remains)
INFO - root - 2017-12-17 06:05:50.724729: step 52330, loss = 0.22, batch loss = 0.15 (35.9 examples/sec; 0.223 sec/batch; 17h:19m:07s remains)
INFO - root - 2017-12-17 06:05:53.022519: step 52340, loss = 0.17, batch loss = 0.10 (35.5 examples/sec; 0.225 sec/batch; 17h:32m:36s remains)
INFO - root - 2017-12-17 06:05:55.280785: step 52350, loss = 0.19, batch loss = 0.12 (34.7 examples/sec; 0.230 sec/batch; 17h:55m:09s remains)
INFO - root - 2017-12-17 06:05:57.535321: step 52360, loss = 0.16, batch loss = 0.09 (35.8 examples/sec; 0.223 sec/batch; 17h:23m:14s remains)
INFO - root - 2017-12-17 06:05:59.792874: step 52370, loss = 0.20, batch loss = 0.13 (34.6 examples/sec; 0.231 sec/batch; 17h:58m:32s remains)
INFO - root - 2017-12-17 06:06:02.038969: step 52380, loss = 0.17, batch loss = 0.10 (35.9 examples/sec; 0.223 sec/batch; 17h:19m:42s remains)
INFO - root - 2017-12-17 06:06:04.294739: step 52390, loss = 0.20, batch loss = 0.12 (34.6 examples/sec; 0.231 sec/batch; 18h:00m:22s remains)
INFO - root - 2017-12-17 06:06:06.579211: step 52400, loss = 0.26, batch loss = 0.19 (35.3 examples/sec; 0.226 sec/batch; 17h:37m:06s remains)
INFO - root - 2017-12-17 06:06:08.995936: step 52410, loss = 0.19, batch loss = 0.11 (35.8 examples/sec; 0.223 sec/batch; 17h:22m:31s remains)
INFO - root - 2017-12-17 06:06:11.258614: step 52420, loss = 0.27, batch loss = 0.20 (35.6 examples/sec; 0.225 sec/batch; 17h:28m:34s remains)
INFO - root - 2017-12-17 06:06:13.510387: step 52430, loss = 0.22, batch loss = 0.15 (34.1 examples/sec; 0.235 sec/batch; 18h:15m:38s remains)
INFO - root - 2017-12-17 06:06:15.760223: step 52440, loss = 0.20, batch loss = 0.13 (35.6 examples/sec; 0.225 sec/batch; 17h:29m:52s remains)
INFO - root - 2017-12-17 06:06:18.018515: step 52450, loss = 0.19, batch loss = 0.12 (35.9 examples/sec; 0.223 sec/batch; 17h:20m:39s remains)
INFO - root - 2017-12-17 06:06:20.290455: step 52460, loss = 0.21, batch loss = 0.14 (35.0 examples/sec; 0.229 sec/batch; 17h:46m:50s remains)
INFO - root - 2017-12-17 06:06:22.532963: step 52470, loss = 0.19, batch loss = 0.12 (37.3 examples/sec; 0.214 sec/batch; 16h:39m:58s remains)
INFO - root - 2017-12-17 06:06:24.784833: step 52480, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 17h:29m:20s remains)
INFO - root - 2017-12-17 06:06:27.059624: step 52490, loss = 0.17, batch loss = 0.10 (34.0 examples/sec; 0.235 sec/batch; 18h:18m:29s remains)
INFO - root - 2017-12-17 06:06:29.307089: step 52500, loss = 0.18, batch loss = 0.10 (32.7 examples/sec; 0.245 sec/batch; 19h:03m:03s remains)
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-52500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-clip-10-10-test/model.ckpt-52500 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-17 06:06:32.371277: step 52510, loss = 0.18, batch loss = 0.11 (36.8 examples/sec; 0.218 sec/batch; 16h:55m:13s remains)
INFO - root - 2017-12-17 06:06:34.638392: step 52520, loss = 0.21, batch loss = 0.14 (35.7 examples/sec; 0.224 sec/batch; 17h:25m:26s remains)
INFO - root - 2017-12-17 06:06:36.983421: step 52530, loss = 0.19, batch loss = 0.11 (35.2 examples/sec; 0.228 sec/batch; 17h:41m:40s remains)
INFO - root - 2017-12-17 06:06:39.285010: step 52540, loss = 0.20, batch loss = 0.12 (35.1 examples/sec; 0.228 sec/batch; 17h:42m:22s remains)
INFO - root - 2017-12-17 06:06:41.542260: step 52550, loss = 0.22, batch loss = 0.14 (35.3 examples/sec; 0.226 sec/batch; 17h:36m:47s remains)
INFO - root - 2017-12-17 06:06:43.777460: step 52560, loss = 0.17, batch loss = 0.10 (36.8 examples/sec; 0.217 sec/batch; 16h:53m:26s remains)
INFO - root - 2017-12-17 06:06:46.053747: step 52570, loss = 0.18, batch loss = 0.10 (34.6 examples/sec; 0.231 sec/batch; 17h:57m:49s remains)
INFO - root - 2017-12-17 06:06:48.324920: step 52580, loss = 0.19, batch loss = 0.12 (35.6 examples/sec; 0.225 sec/batch; 17h:27m:57s remains)
INFO - root - 2017-12-17 06:06:50.630097: step 52590, loss = 0.22, batch loss = 0.15 (34.6 examples/sec; 0.231 sec/batch; 17h:59m:28s remains)
INFO - root - 2017-12-17 06:06:52.912395: step 52600, loss = 0.21, batch loss = 0.14 (33.8 examples/sec; 0.237 sec/batch; 18h:25m:30s remains)
