INFO - Siam-FC - Running command 'main'
INFO - Siam-FC - Started run with ID "146"
INFO - root - Creating training directory: /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-2-momentum-lr0.001
INFO - root - preproces -- siamese_fc_color
WARNING - root - root is not explicitly specified, using default value: None
INFO - root - For training, we use instance size 255 - 2 * 8 ...
WARNING - root - init_method is not explicitly specified, using default value: None
INFO - root - Model moving average is disabled since decay factor is 0
2017-12-07 10:25:10.418802: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-07 10:25:10.418840: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-07 10:25:10.418846: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-07 10:25:10.418850: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-07 10:25:10.418854: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-07 10:25:14.837008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 6bee:00:00.0
Total memory: 11.17GiB
Free memory: 6.45GiB
2017-12-07 10:25:14.837042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-12-07 10:25:14.837049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-12-07 10:25:14.837057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 6bee:00:00.0)
sdiufhasudf Tensor("siamese_fc/conv5/split:0", shape=(8, 8, 8, 192), dtype=float32)
Tensor("siamese_fc/conv5/def/transpose:0", shape=(8, 192, 8, 8), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(128, 192, 3, 3) dtype=float32_ref> Tensor("siamese_fc/conv5/def/transpose_1:0", shape=(8, 72, 8, 8), dtype=float32)
ddd Tensor("siamese_fc/conv5/def/b1/transpose:0", shape=(8, 6, 6, 128), dtype=float32)
Tensor("siamese_fc/conv5/def/transpose_2:0", shape=(8, 192, 8, 8), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b2/weights:0' shape=(128, 192, 3, 3) dtype=float32_ref> Tensor("siamese_fc/conv5/def/transpose_3:0", shape=(8, 72, 8, 8), dtype=float32)
sdiufhasudf Tensor("siamese_fc_1/conv5/split:0", shape=(8, 22, 22, 192), dtype=float32)
Tensor("siamese_fc_1/conv5/def/transpose:0", shape=(8, 192, 22, 22), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b1/weights:0' shape=(128, 192, 3, 3) dtype=float32_ref> Tensor("siamese_fc_1/conv5/def/transpose_1:0", shape=(8, 72, 22, 22), dtype=float32)
ddd Tensor("siamese_fc_1/conv5/def/b1/transpose:0", shape=(8, 20, 20, 128), dtype=float32)
Tensor("siamese_fc_1/conv5/def/transpose_2:0", shape=(8, 192, 22, 22), dtype=float32) <tf.Variable 'siamese_fc/conv5/def/b2/weights:0' shape=(128, 192, 3, 3) dtype=float32_ref> Tensor("siamese_fc_1/conv5/def/transpose_3:0", shape=(8, 72, 22, 22), dtype=float32)
Tensor("detection/add:0", shape=(8, 15, 15), dtype=float32)
INFO:tensorflow:Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO - tensorflow - Restoring parameters from /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-only/model.ckpt-150000
INFO - root - Starting threads 0 ...

INFO - root - training for 332500 steps
[<tf.Variable 'siamese_fc/conv1/weights:0' shape=(11, 11, 3, 96) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv1/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv1/BatchNorm/gamma:0' shape=(96,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv1/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv1/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv2/b1/weights:0' shape=(5, 5, 48, 128) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv2/b1/BatchNorm/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv2/b1/BatchNorm/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv2/b1/BatchNorm/moving_mean:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv2/b1/BatchNorm/moving_variance:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv2/b2/weights:0' shape=(5, 5, 48, 128) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv2/b2/BatchNorm/beta:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv2/b2/BatchNorm/gamma:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv2/b2/BatchNorm/moving_mean:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv2/b2/BatchNorm/moving_variance:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv3/weights:0' shape=(3, 3, 256, 384) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv3/BatchNorm/beta:0' shape=(384,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv3/BatchNorm/gamma:0' shape=(384,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv3/BatchNorm/moving_mean:0' shape=(384,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv3/BatchNorm/moving_variance:0' shape=(384,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b1/weights:0' shape=(3, 3, 192, 192) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b1/BatchNorm/beta:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b1/BatchNorm/gamma:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b1/BatchNorm/moving_mean:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b1/BatchNorm/moving_variance:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b2/weights:0' shape=(3, 3, 192, 192) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b2/BatchNorm/beta:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b2/BatchNorm/gamma:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b2/BatchNorm/moving_mean:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'siamese_fc/conv4/b2/BatchNorm/moving_variance:0' shape=(192,) dtype=float32_ref>, <tf.Variable 'detection/biases:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'global_step:0' shape=() dtype=int32_ref>]
INFO - root - 2017-12-07 10:25:34.894228: step 0, loss = 2.03, batch loss = 1.97 (0.6 examples/sec; 13.688 sec/batch; 1264h:15m:39s remains)
2017-12-07 10:25:35.672918: I tensorflow/core/kernels/logging_ops.cc:79] [[[-4.3335352 -4.3310628 -4.3310347 -4.3311625 -4.3276944 -4.3151455 -4.2952342 -4.2691436 -4.2415967 -4.22651 -4.231111 -4.2465706 -4.2697659 -4.2994437 -4.322804][-4.3306518 -4.3286314 -4.3301883 -4.3297992 -4.3216348 -4.2987857 -4.2646904 -4.2225614 -4.183702 -4.1647358 -4.175549 -4.2033572 -4.2398543 -4.2800241 -4.309598][-4.3238397 -4.32282 -4.3253202 -4.3221655 -4.3033333 -4.263247 -4.2088614 -4.1458178 -4.0910087 -4.069149 -4.0909185 -4.1381454 -4.196321 -4.252965 -4.2925282][-4.3096881 -4.3112807 -4.3161254 -4.3122072 -4.2830486 -4.2283072 -4.1565895 -4.0677495 -3.990375 -3.9647155 -4.0015054 -4.0685644 -4.1504154 -4.2252784 -4.2764421][-4.2923651 -4.2976584 -4.3046074 -4.3001208 -4.2622218 -4.1947947 -4.1007719 -3.9813685 -3.8735101 -3.8482656 -3.9102716 -4.0018034 -4.1083789 -4.2001448 -4.2637982][-4.2725482 -4.2801256 -4.2871547 -4.2796526 -4.234035 -4.1554627 -4.0370755 -3.8837907 -3.7435012 -3.7343767 -3.8343143 -3.9538507 -4.0814862 -4.1838207 -4.2556252][-4.2574887 -4.2629824 -4.2650266 -4.2504644 -4.1977873 -4.1102376 -3.9718871 -3.7913308 -3.6334689 -3.6644073 -3.8082697 -3.9479105 -4.0815363 -4.1832647 -4.2561][-4.2495303 -4.2476449 -4.2393827 -4.2166252 -4.165606 -4.0856938 -3.9579587 -3.7895942 -3.661648 -3.7349 -3.884064 -4.0068679 -4.1164784 -4.2010355 -4.2647648][-4.243309 -4.2306976 -4.2137847 -4.1895461 -4.1522765 -4.1000519 -4.0101933 -3.8943751 -3.8234305 -3.8965716 -4.005434 -4.0867515 -4.159554 -4.2237463 -4.2764888][-4.2377906 -4.217639 -4.1968927 -4.1745825 -4.1525469 -4.125824 -4.0746288 -4.0064969 -3.9700279 -4.0218062 -4.0910897 -4.1381974 -4.1835556 -4.2364359 -4.284934][-4.2294617 -4.2070727 -4.1857104 -4.1667452 -4.1520333 -4.1402307 -4.1157236 -4.0776229 -4.0581112 -4.0910554 -4.1350355 -4.1635361 -4.1973805 -4.2473054 -4.2938471][-4.2240419 -4.2047896 -4.1879745 -4.1735187 -4.1655722 -4.1652846 -4.1579504 -4.1376724 -4.1237197 -4.1379561 -4.1628981 -4.1809363 -4.2109447 -4.2603483 -4.3034854][-4.2312069 -4.222681 -4.2165251 -4.2091713 -4.2061863 -4.2103333 -4.2088675 -4.1911192 -4.1705465 -4.1676536 -4.1778207 -4.1888304 -4.2182236 -4.26809 -4.3091955][-4.2413497 -4.2430062 -4.2477455 -4.2491207 -4.2487106 -4.2502942 -4.24312 -4.2170582 -4.1863937 -4.1729412 -4.1748819 -4.1851053 -4.2169275 -4.2686934 -4.3099794][-4.2362065 -4.2440133 -4.2557015 -4.2624631 -4.2632036 -4.2624235 -4.2480617 -4.2111721 -4.1698565 -4.1539044 -4.1579995 -4.1729536 -4.2100143 -4.2644777 -4.3065343]]...]
INFO:tensorflow:/home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-2-momentum-lr0.001/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
INFO - tensorflow - /home/v-chaoqw/MYSFC-ORI/track_model_checkpoints/SFC-2-momentum-lr0.001/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
INFO - root - 2017-12-07 10:25:41.443172: step 10, loss = 2.06, batch loss = 2.00 (16.4 examples/sec; 0.486 sec/batch; 44h:55m:27s remains)
INFO - root - 2017-12-07 10:25:45.987218: step 20, loss = 2.05, batch loss = 1.99 (16.4 examples/sec; 0.489 sec/batch; 45h:10m:49s remains)
INFO - root - 2017-12-07 10:25:50.559502: step 30, loss = 2.07, batch loss = 2.01 (17.2 examples/sec; 0.465 sec/batch; 42h:59m:08s remains)
INFO - root - 2017-12-07 10:25:55.108719: step 40, loss = 2.07, batch loss = 2.02 (17.7 examples/sec; 0.453 sec/batch; 41h:47m:49s remains)
INFO - root - 2017-12-07 10:25:59.628411: step 50, loss = 2.08, batch loss = 2.02 (19.1 examples/sec; 0.419 sec/batch; 38h:40m:44s remains)
INFO - root - 2017-12-07 10:26:04.189878: step 60, loss = 2.10, batch loss = 2.04 (18.7 examples/sec; 0.427 sec/batch; 39h:28m:06s remains)
INFO - root - 2017-12-07 10:26:08.821766: step 70, loss = 2.06, batch loss = 2.00 (17.5 examples/sec; 0.457 sec/batch; 42h:11m:00s remains)
INFO - root - 2017-12-07 10:26:13.412593: step 80, loss = 2.06, batch loss = 2.00 (17.8 examples/sec; 0.449 sec/batch; 41h:28m:31s remains)
INFO - root - 2017-12-07 10:26:17.982288: step 90, loss = 2.09, batch loss = 2.03 (16.1 examples/sec; 0.496 sec/batch; 45h:50m:27s remains)
INFO - root - 2017-12-07 10:26:22.732400: step 100, loss = 2.06, batch loss = 2.01 (16.8 examples/sec; 0.476 sec/batch; 43h:55m:00s remains)
2017-12-07 10:26:23.231231: I tensorflow/core/kernels/logging_ops.cc:79] [[[-4.2407918 -4.2161007 -4.1933 -4.1788297 -4.1732388 -4.1824203 -4.1969185 -4.2097077 -4.2257628 -4.2337627 -4.225419 -4.2210402 -4.2169061 -4.1993 -4.1790237][-4.2514882 -4.2205529 -4.1854057 -4.1552038 -4.1345844 -4.1384888 -4.1576433 -4.1735168 -4.1883678 -4.1976647 -4.1953363 -4.1992588 -4.200428 -4.18416 -4.1678896][-4.2584891 -4.2217522 -4.1773796 -4.1365423 -4.1080651 -4.1072855 -4.1262722 -4.1411743 -4.1521759 -4.1636224 -4.1696057 -4.1778655 -4.1802316 -4.1655579 -4.1520967][-4.2609768 -4.2197056 -4.171946 -4.1291637 -4.1014814 -4.098906 -4.1159821 -4.12986 -4.1386795 -4.1529541 -4.1649508 -4.1719618 -4.1712732 -4.1568184 -4.1424627][-4.2598968 -4.2169123 -4.1699038 -4.1280351 -4.1011286 -4.095655 -4.1101127 -4.1237674 -4.1314111 -4.1480169 -4.1643291 -4.1703634 -4.1675119 -4.1567674 -4.14364][-4.2558193 -4.213573 -4.1699157 -4.1304154 -4.1018276 -4.0892968 -4.0959873 -4.1024065 -4.1024628 -4.1185184 -4.1416521 -4.1530495 -4.154448 -4.1492848 -4.1411085][-4.2508726 -4.2104096 -4.1701345 -4.1307 -4.0982218 -4.0771084 -4.0742869 -4.0676546 -4.0527172 -4.0659995 -4.0999384 -4.1225653 -4.1327434 -4.134799 -4.1331844][-4.2448592 -4.20443 -4.163238 -4.1194081 -4.0826044 -4.058548 -4.0514927 -4.0377579 -4.0120564 -4.0220952 -4.0636215 -4.092751 -4.1083055 -4.1174555 -4.1218815][-4.2419424 -4.2019787 -4.1593962 -4.1122713 -4.0759506 -4.0574827 -4.0527754 -4.0398688 -4.0160561 -4.0257664 -4.0630217 -4.087184 -4.0983343 -4.1095252 -4.1154995][-4.2412796 -4.2013097 -4.1579127 -4.110333 -4.0776854 -4.0658274 -4.0642862 -4.0562539 -4.0424447 -4.055943 -4.0848727 -4.0979066 -4.0999174 -4.1052947 -4.1092215][-4.2461643 -4.2056217 -4.1616096 -4.1149445 -4.0855637 -4.0778437 -4.0756321 -4.068574 -4.0625238 -4.0823932 -4.1081867 -4.1127968 -4.1061392 -4.1047888 -4.1057639][-4.2579589 -4.218852 -4.1763721 -4.1343207 -4.1105428 -4.1076946 -4.1070933 -4.1024942 -4.1009059 -4.1190157 -4.1389174 -4.1390676 -4.1293416 -4.1253309 -4.1245461][-4.2719717 -4.2361622 -4.1976981 -4.1629829 -4.1461573 -4.1484852 -4.154407 -4.1569161 -4.1591825 -4.1710668 -4.1828475 -4.1813107 -4.1713686 -4.165822 -4.1636748][-4.2903657 -4.260818 -4.2299509 -4.2035532 -4.19094 -4.1944323 -4.2046256 -4.2146993 -4.2228703 -4.2314305 -4.2362957 -4.2321024 -4.221952 -4.2154479 -4.2134881][-4.3115625 -4.2923951 -4.2724996 -4.2555161 -4.2455916 -4.2459493 -4.2547846 -4.2662153 -4.2756338 -4.2816834 -4.2825246 -4.277338 -4.2691741 -4.2643061 -4.2641482]]...]
INFO - root - 2017-12-07 10:26:29.300289: step 110, loss = 2.06, batch loss = 2.00 (18.6 examples/sec; 0.430 sec/batch; 39h:41m:36s remains)
INFO - root - 2017-12-07 10:26:35.942322: step 120, loss = 2.05, batch loss = 1.99 (11.4 examples/sec; 0.701 sec/batch; 64h:44m:46s remains)
INFO - root - 2017-12-07 10:26:42.794026: step 130, loss = 2.05, batch loss = 1.99 (11.2 examples/sec; 0.717 sec/batch; 66h:14m:19s remains)
INFO - root - 2017-12-07 10:26:49.455491: step 140, loss = 2.05, batch loss = 1.99 (10.9 examples/sec; 0.733 sec/batch; 67h:42m:11s remains)
INFO - root - 2017-12-07 10:26:56.138797: step 150, loss = 2.10, batch loss = 2.04 (11.9 examples/sec; 0.671 sec/batch; 61h:57m:48s remains)
INFO - root - 2017-12-07 10:27:02.585013: step 160, loss = 2.05, batch loss = 2.00 (12.4 examples/sec; 0.647 sec/batch; 59h:45m:41s remains)
INFO - root - 2017-12-07 10:27:09.283664: step 170, loss = 2.08, batch loss = 2.02 (12.4 examples/sec; 0.645 sec/batch; 59h:33m:51s remains)
INFO - root - 2017-12-07 10:27:15.987817: step 180, loss = 2.06, batch loss = 2.00 (12.0 examples/sec; 0.667 sec/batch; 61h:33m:30s remains)
INFO - root - 2017-12-07 10:27:22.657057: step 190, loss = 2.08, batch loss = 2.02 (12.0 examples/sec; 0.666 sec/batch; 61h:30m:05s remains)
INFO - root - 2017-12-07 10:27:29.505059: step 200, loss = 2.06, batch loss = 2.00 (11.6 examples/sec; 0.689 sec/batch; 63h:35m:20s remains)
2017-12-07 10:27:30.269057: I tensorflow/core/kernels/logging_ops.cc:79] [[[-4.2729287 -4.2552481 -4.2425942 -4.2486181 -4.2483521 -4.2468023 -4.2439218 -4.2376204 -4.2337174 -4.2357693 -4.2378144 -4.2383013 -4.2381234 -4.2420225 -4.2443371][-4.2725272 -4.2570443 -4.2441378 -4.2474971 -4.2465611 -4.2439785 -4.2377906 -4.2321181 -4.2298164 -4.2313051 -4.22806 -4.2252021 -4.2266583 -4.2338548 -4.2357731][-4.2495284 -4.2440729 -4.24059 -4.2394905 -4.2319074 -4.2252765 -4.2150726 -4.2177176 -4.2259722 -4.2308736 -4.2195182 -4.2069249 -4.203033 -4.2092657 -4.2098689][-4.2206454 -4.2237272 -4.2274375 -4.2234435 -4.2128453 -4.2025757 -4.1863322 -4.1989169 -4.2215271 -4.2314811 -4.2145491 -4.1918383 -4.1780314 -4.1746054 -4.1731668][-4.1883154 -4.1969495 -4.208797 -4.2037339 -4.1886864 -4.1628079 -4.1331749 -4.1567011 -4.197011 -4.2174315 -4.2041807 -4.1800661 -4.1579471 -4.1420279 -4.1428366][-4.1605368 -4.1658225 -4.1826477 -4.1756511 -4.1467233 -4.0868959 -4.02614 -4.0655675 -4.1416745 -4.1828442 -4.1825595 -4.1617966 -4.1382651 -4.1213727 -4.1358089][-4.1400356 -4.1315141 -4.1517105 -4.1485877 -4.0996552 -3.982352 -3.8656211 -3.9308138 -4.0625587 -4.1373229 -4.1534562 -4.1331959 -4.11258 -4.1121993 -4.1466765][-4.1335917 -4.1222987 -4.151825 -4.1638985 -4.1108475 -3.9682257 -3.8231237 -3.8897815 -4.0441823 -4.1380525 -4.1652813 -4.1468482 -4.1254888 -4.1282678 -4.1645112][-4.1493592 -4.146853 -4.1831322 -4.2078977 -4.1751165 -4.0733542 -3.9747112 -4.0066328 -4.1122856 -4.1904068 -4.2190638 -4.2083139 -4.186408 -4.1824908 -4.20333][-4.19595 -4.1939387 -4.2213564 -4.2454724 -4.2270236 -4.163754 -4.1062884 -4.115932 -4.1785035 -4.2375488 -4.260468 -4.2491984 -4.2295961 -4.2215219 -4.2293668][-4.236897 -4.2347956 -4.2491417 -4.2633553 -4.2496138 -4.2048616 -4.1663342 -4.1651788 -4.2007642 -4.2469997 -4.2687092 -4.2608562 -4.2443523 -4.2306776 -4.2347765][-4.2601676 -4.2558737 -4.2658839 -4.270577 -4.2633376 -4.2361503 -4.2117982 -4.2072763 -4.2233891 -4.2565622 -4.2760334 -4.2713461 -4.2580543 -4.2437339 -4.2459974][-4.2672663 -4.2640862 -4.2729287 -4.2728558 -4.2729163 -4.263288 -4.2468262 -4.2409153 -4.2462888 -4.2706127 -4.2861967 -4.2831206 -4.2734857 -4.25997 -4.25903][-4.2702236 -4.2712779 -4.2755671 -4.2735567 -4.2763109 -4.2728653 -4.2586565 -4.2533474 -4.2563391 -4.273191 -4.2862649 -4.2826624 -4.2747574 -4.2653751 -4.2630081][-4.2709141 -4.2730513 -4.2743969 -4.2742648 -4.2767453 -4.2734804 -4.2600956 -4.2538519 -4.255055 -4.2646384 -4.2747803 -4.2725663 -4.2639222 -4.2561665 -4.2552028]]...]
